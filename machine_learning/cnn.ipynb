{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8c5x5HQKqZrD"
   },
   "source": [
    "#CNN\n",
    "温度データから内部欠陥の位置と大きさを推定するプログラム"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DRCMhk76mJ5W"
   },
   "outputs": [],
   "source": [
    "## 必要なライブラリのimport\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OYynpYksKrYc"
   },
   "outputs": [],
   "source": [
    "## データについて\n",
    "\n",
    "### データファイルのpath\n",
    "no_hole_path = './../tmp_simulation/tmp_data/no_hole_data.csv'\n",
    "one_hole_size_path = './../tmp_simulation/tmp_data/one_hole_size_data.csv'\n",
    "one_hole_position_path = './../tmp_simulation/tmp_data/one_hole_position_data.csv'\n",
    "four_holes_size_path = './../tmp_simulation/tmp_data/four_holes_size_data.csv'\n",
    "four_holes_position_path = './../tmp_simulation/tmp_data/four_holes_position_data.csv'\n",
    "nine_holes_size_path = './../tmp_simulation/tmp_data/nine_holes_size_data.csv'\n",
    "nine_holes_position_path = './../tmp_simulation/tmp_data/nine_holes_position_data.csv'\n",
    "sixteen_holes_size_path = './../tmp_simulation/tmp_data/sixteen_holes_size_data.csv'\n",
    "sixteen_holes_position_path = './../tmp_simulation/tmp_data/sixteen_holes_position_data.csv'\n",
    "twentyfive_holes_size_path = './../tmp_simulation/tmp_data/twentyfive_holes_size_data.csv'\n",
    "twentyfive_holes_position_path = './../tmp_simulation/tmp_data/twentyfive_holes_position_data.csv'\n",
    "\n",
    "### 入力データと正解データ\n",
    "no_hole_data = []\n",
    "size_x_data = []\n",
    "size_y_data = []\n",
    "position_x_data = []\n",
    "position_y_data = []\n",
    "\n",
    "### ファイル読み込み\n",
    "\n",
    "#### 欠陥がない場合の温度データ\n",
    "with open(no_hole_path) as f:\n",
    "    for line in f:\n",
    "        no_hole_data = line.split(',')[:-1]\n",
    "\n",
    "#### 大きさに関するデータ\n",
    "with open(one_hole_size_path) as fs1:\n",
    "  for line in fs1:\n",
    "    data_array = line.split(',')\n",
    "    size_x_data.append(data_array[1:-1])\n",
    "    size_y_data.append(data_array[0])\n",
    "with open(four_holes_size_path) as fs2:\n",
    "  for line in fs2:\n",
    "    data_array = line.split(',')\n",
    "    size_x_data.append(data_array[1:-1])\n",
    "    size_y_data.append(data_array[0])\n",
    "with open(nine_holes_size_path) as fs3:\n",
    "  for line in fs3:\n",
    "    data_array = line.split(',')\n",
    "    size_x_data.append(data_array[1:-1])\n",
    "    size_y_data.append(data_array[0])\n",
    "with open(sixteen_holes_size_path) as fs4:\n",
    "  for line in fs4:\n",
    "    data_array = line.split(',')\n",
    "    size_x_data.append(data_array[1:-1])\n",
    "    size_y_data.append(data_array[0])\n",
    "with open(twentyfive_holes_size_path) as fs5:\n",
    "  for line in fs5:\n",
    "    data_array = line.split(',')\n",
    "    size_x_data.append(data_array[1:-1])\n",
    "    size_y_data.append(data_array[0])\n",
    "\n",
    "#### 位置に関するデータ\n",
    "with open(one_hole_position_path) as fp1:\n",
    "  for line in fp1:\n",
    "    data_array = line.split(',')\n",
    "    position_x_data.append(data_array[1:-1])\n",
    "    position_y_data.append(data_array[0])\n",
    "with open(four_holes_position_path) as fp2:\n",
    "  for line in fp2:\n",
    "    data_array = line.split(',')\n",
    "    position_x_data.append(data_array[1:-1])\n",
    "    position_y_data.append(data_array[0])\n",
    "with open(nine_holes_position_path) as fp3:\n",
    "  for line in fp3:\n",
    "    data_array = line.split(',')\n",
    "    position_x_data.append(data_array[1:-1])\n",
    "    position_y_data.append(data_array[0])\n",
    "with open(sixteen_holes_position_path) as fp4:\n",
    "  for line in fp4:\n",
    "    data_array = line.split(',')\n",
    "    position_x_data.append(data_array[1:-1])\n",
    "    position_y_data.append(data_array[0])\n",
    "with open(twentyfive_holes_position_path) as fp5:\n",
    "  for line in fp5:\n",
    "    data_array = line.split(',')\n",
    "    position_x_data.append(data_array[1:-1])\n",
    "    position_y_data.append(data_array[0])\n",
    "\n",
    "### 各配列をnp.array型にして各要素を型変換\n",
    "no_hole_data = np.array(no_hole_data, dtype=float)\n",
    "size_x_data = np.array(size_x_data, dtype=float)\n",
    "size_y_data = np.array(size_y_data, dtype=int)\n",
    "position_x_data = np.array(position_x_data, dtype=float)\n",
    "position_y_data = np.array(position_y_data, dtype=int)\n",
    "\n",
    "### データの加工\n",
    "size_x_data = (size_x_data-no_hole_data)\n",
    "position_x_data = (position_x_data-no_hole_data)\n",
    "size_y_data = keras.utils.to_categorical(size_y_data, 6)\n",
    "position_y_data = (position_y_data-1)\n",
    "position_y_data = keras.utils.to_categorical(position_y_data, 25)\n",
    "\n",
    "### train用とtest用に分割(4:1)\n",
    "size_x_train, size_x_test, size_y_train, size_y_test = train_test_split(size_x_data, size_y_data, test_size=0.20)\n",
    "position_x_train, position_x_test, position_y_train, position_y_test = train_test_split(position_x_data, position_y_data, test_size=0.20)\n",
    "\n",
    "\n",
    "### reshape\n",
    "size_x_train = size_x_train.reshape(8108, 50, 1)\n",
    "size_x_test = size_x_test.reshape(2027, 50, 1)\n",
    "position_x_train = position_x_train.reshape(8108, 50, 1)\n",
    "position_x_test = position_x_test.reshape(2027, 50, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "b5AdrpJXqHQL",
    "outputId": "3f4a94d1-fc97-4033-ee8d-917c1ebab287"
   },
   "outputs": [],
   "source": [
    "## CNN(大きさ)\n",
    "\n",
    "### modelの作成\n",
    "size_model = Sequential()\n",
    "### 畳み込み層\n",
    "size_model.add(Conv1D(32, 3, padding='same', activation='relu', input_shape=(50, 1)))\n",
    "### プーリング層\n",
    "size_model.add(MaxPooling1D(2, padding='same'))\n",
    "### Flatten層\n",
    "size_model.add(Flatten())\n",
    "### 全結合層\n",
    "size_model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "### optimizer\n",
    "adam = keras.optimizers.Adam()\n",
    "\n",
    "###modelのコンパイル\n",
    "size_model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aApCY1awsFWg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8108 samples, validate on 2027 samples\n",
      "Epoch 1/1000\n",
      "8108/8108 [==============================] - 0s 42us/step - loss: 1.6043 - accuracy: 0.2884 - val_loss: 1.5445 - val_accuracy: 0.3680\n",
      "Epoch 2/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 1.5089 - accuracy: 0.4137 - val_loss: 1.4858 - val_accuracy: 0.4050\n",
      "Epoch 3/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 1.4454 - accuracy: 0.4174 - val_loss: 1.4174 - val_accuracy: 0.3680\n",
      "Epoch 4/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 1.3907 - accuracy: 0.4315 - val_loss: 1.3746 - val_accuracy: 0.5220\n",
      "Epoch 5/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 1.3543 - accuracy: 0.4628 - val_loss: 1.3431 - val_accuracy: 0.4608\n",
      "Epoch 6/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 1.3212 - accuracy: 0.4948 - val_loss: 1.3229 - val_accuracy: 0.3996\n",
      "Epoch 7/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 1.3002 - accuracy: 0.4679 - val_loss: 1.3151 - val_accuracy: 0.4026\n",
      "Epoch 8/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 1.2800 - accuracy: 0.4846 - val_loss: 1.2965 - val_accuracy: 0.3725\n",
      "Epoch 9/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 1.2563 - accuracy: 0.5134 - val_loss: 1.2537 - val_accuracy: 0.5772\n",
      "Epoch 10/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 1.2371 - accuracy: 0.5223 - val_loss: 1.2441 - val_accuracy: 0.6241\n",
      "Epoch 11/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 1.2181 - accuracy: 0.5370 - val_loss: 1.2345 - val_accuracy: 0.5298\n",
      "Epoch 12/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 1.2020 - accuracy: 0.5455 - val_loss: 1.2115 - val_accuracy: 0.6216\n",
      "Epoch 13/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 1.1890 - accuracy: 0.5557 - val_loss: 1.2021 - val_accuracy: 0.5146\n",
      "Epoch 14/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 1.1791 - accuracy: 0.5493 - val_loss: 1.1987 - val_accuracy: 0.5210\n",
      "Epoch 15/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 1.1643 - accuracy: 0.5546 - val_loss: 1.1678 - val_accuracy: 0.5915\n",
      "Epoch 16/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 1.1576 - accuracy: 0.5525 - val_loss: 1.1978 - val_accuracy: 0.6127\n",
      "Epoch 17/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.1388 - accuracy: 0.5592 - val_loss: 1.1472 - val_accuracy: 0.5461\n",
      "Epoch 18/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 1.1190 - accuracy: 0.5797 - val_loss: 1.1566 - val_accuracy: 0.6305\n",
      "Epoch 19/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 1.1180 - accuracy: 0.5852 - val_loss: 1.1335 - val_accuracy: 0.5343\n",
      "Epoch 20/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.1016 - accuracy: 0.5874 - val_loss: 1.1126 - val_accuracy: 0.6122\n",
      "Epoch 21/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 1.0914 - accuracy: 0.6026 - val_loss: 1.1265 - val_accuracy: 0.5160\n",
      "Epoch 22/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 1.0785 - accuracy: 0.5932 - val_loss: 1.1016 - val_accuracy: 0.6093\n",
      "Epoch 23/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 1.0636 - accuracy: 0.6110 - val_loss: 1.0971 - val_accuracy: 0.6764\n",
      "Epoch 24/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 1.0559 - accuracy: 0.6252 - val_loss: 1.0990 - val_accuracy: 0.6177\n",
      "Epoch 25/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 1.0458 - accuracy: 0.6300 - val_loss: 1.0859 - val_accuracy: 0.6680\n",
      "Epoch 26/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 1.0422 - accuracy: 0.6232 - val_loss: 1.0965 - val_accuracy: 0.5664\n",
      "Epoch 27/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 1.0253 - accuracy: 0.6330 - val_loss: 1.0615 - val_accuracy: 0.6290\n",
      "Epoch 28/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 1.0179 - accuracy: 0.6274 - val_loss: 1.0359 - val_accuracy: 0.6241\n",
      "Epoch 29/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 1.0099 - accuracy: 0.6207 - val_loss: 1.0513 - val_accuracy: 0.6186\n",
      "Epoch 30/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.9957 - accuracy: 0.6527 - val_loss: 1.0277 - val_accuracy: 0.6083\n",
      "Epoch 31/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.9905 - accuracy: 0.6515 - val_loss: 1.0179 - val_accuracy: 0.6364\n",
      "Epoch 32/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.9784 - accuracy: 0.6464 - val_loss: 1.0361 - val_accuracy: 0.5614\n",
      "Epoch 33/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.9746 - accuracy: 0.6442 - val_loss: 1.0134 - val_accuracy: 0.5876\n",
      "Epoch 34/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.9701 - accuracy: 0.6491 - val_loss: 1.0015 - val_accuracy: 0.6912\n",
      "Epoch 35/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.9710 - accuracy: 0.6444 - val_loss: 1.0361 - val_accuracy: 0.6852\n",
      "Epoch 36/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.9506 - accuracy: 0.6484 - val_loss: 0.9989 - val_accuracy: 0.7065\n",
      "Epoch 37/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.9447 - accuracy: 0.6589 - val_loss: 0.9790 - val_accuracy: 0.6788\n",
      "Epoch 38/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.9372 - accuracy: 0.6637 - val_loss: 0.9873 - val_accuracy: 0.6394\n",
      "Epoch 39/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.9436 - accuracy: 0.6417 - val_loss: 0.9613 - val_accuracy: 0.6892\n",
      "Epoch 40/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.9254 - accuracy: 0.6553 - val_loss: 0.9875 - val_accuracy: 0.5619\n",
      "Epoch 41/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.9139 - accuracy: 0.6711 - val_loss: 0.9589 - val_accuracy: 0.6660\n",
      "Epoch 42/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.9104 - accuracy: 0.6754 - val_loss: 1.0006 - val_accuracy: 0.5807\n",
      "Epoch 43/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.9126 - accuracy: 0.6775 - val_loss: 0.9447 - val_accuracy: 0.6912\n",
      "Epoch 44/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.8967 - accuracy: 0.6808 - val_loss: 0.9304 - val_accuracy: 0.6912\n",
      "Epoch 45/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.8909 - accuracy: 0.6891 - val_loss: 0.9379 - val_accuracy: 0.7129\n",
      "Epoch 46/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.8835 - accuracy: 0.6896 - val_loss: 0.9472 - val_accuracy: 0.7232\n",
      "Epoch 47/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.8849 - accuracy: 0.6762 - val_loss: 0.9213 - val_accuracy: 0.7227\n",
      "Epoch 48/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.8688 - accuracy: 0.6981 - val_loss: 0.9124 - val_accuracy: 0.6833\n",
      "Epoch 49/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.8578 - accuracy: 0.7014 - val_loss: 0.9047 - val_accuracy: 0.7198\n",
      "Epoch 50/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.8679 - accuracy: 0.6888 - val_loss: 0.9056 - val_accuracy: 0.6882\n",
      "Epoch 51/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.8622 - accuracy: 0.6822 - val_loss: 0.8951 - val_accuracy: 0.7114\n",
      "Epoch 52/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.8538 - accuracy: 0.6913 - val_loss: 0.9098 - val_accuracy: 0.7045\n",
      "Epoch 53/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.8487 - accuracy: 0.6806 - val_loss: 0.8842 - val_accuracy: 0.6976\n",
      "Epoch 54/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.8417 - accuracy: 0.7052 - val_loss: 0.9133 - val_accuracy: 0.6976\n",
      "Epoch 55/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.8377 - accuracy: 0.7063 - val_loss: 0.8806 - val_accuracy: 0.6897\n",
      "Epoch 56/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.8404 - accuracy: 0.6996 - val_loss: 0.9057 - val_accuracy: 0.7237\n",
      "Epoch 57/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 0.8236 - accuracy: 0.7091 - val_loss: 0.8644 - val_accuracy: 0.7213\n",
      "Epoch 58/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 0.8235 - accuracy: 0.7070 - val_loss: 0.8884 - val_accuracy: 0.6922\n",
      "Epoch 59/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.8192 - accuracy: 0.7109 - val_loss: 0.8616 - val_accuracy: 0.7139\n",
      "Epoch 60/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.8114 - accuracy: 0.7056 - val_loss: 0.8580 - val_accuracy: 0.7331\n",
      "Epoch 61/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.8016 - accuracy: 0.7152 - val_loss: 0.8707 - val_accuracy: 0.7222\n",
      "Epoch 62/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.7989 - accuracy: 0.7232 - val_loss: 0.8557 - val_accuracy: 0.7425\n",
      "Epoch 63/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.7931 - accuracy: 0.7189 - val_loss: 0.8369 - val_accuracy: 0.7385\n",
      "Epoch 64/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.8128 - accuracy: 0.7094 - val_loss: 0.8606 - val_accuracy: 0.7390\n",
      "Epoch 65/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.7838 - accuracy: 0.7236 - val_loss: 0.8328 - val_accuracy: 0.7089\n",
      "Epoch 66/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.7809 - accuracy: 0.7203 - val_loss: 0.8682 - val_accuracy: 0.7375\n",
      "Epoch 67/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.7861 - accuracy: 0.7200 - val_loss: 0.8240 - val_accuracy: 0.7148\n",
      "Epoch 68/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.7714 - accuracy: 0.7181 - val_loss: 0.8306 - val_accuracy: 0.7247\n",
      "Epoch 69/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.7804 - accuracy: 0.7218 - val_loss: 0.8552 - val_accuracy: 0.7415\n",
      "Epoch 70/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.7703 - accuracy: 0.7227 - val_loss: 0.8084 - val_accuracy: 0.7252\n",
      "Epoch 71/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.7575 - accuracy: 0.7282 - val_loss: 0.8065 - val_accuracy: 0.7370\n",
      "Epoch 72/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.7670 - accuracy: 0.7225 - val_loss: 0.8104 - val_accuracy: 0.7124\n",
      "Epoch 73/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.7763 - accuracy: 0.7065 - val_loss: 0.8119 - val_accuracy: 0.7306\n",
      "Epoch 74/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.7602 - accuracy: 0.7224 - val_loss: 0.7995 - val_accuracy: 0.7148\n",
      "Epoch 75/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.7550 - accuracy: 0.7283 - val_loss: 0.7888 - val_accuracy: 0.7405\n",
      "Epoch 76/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.7444 - accuracy: 0.7255 - val_loss: 0.8020 - val_accuracy: 0.7375\n",
      "Epoch 77/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.7429 - accuracy: 0.7282 - val_loss: 0.7949 - val_accuracy: 0.7183\n",
      "Epoch 78/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.7379 - accuracy: 0.7317 - val_loss: 0.8003 - val_accuracy: 0.7213\n",
      "Epoch 79/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.7376 - accuracy: 0.7320 - val_loss: 0.8173 - val_accuracy: 0.7474\n",
      "Epoch 80/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.7357 - accuracy: 0.7298 - val_loss: 0.7762 - val_accuracy: 0.7459\n",
      "Epoch 81/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.7362 - accuracy: 0.7351 - val_loss: 0.7738 - val_accuracy: 0.7430\n",
      "Epoch 82/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.7264 - accuracy: 0.7316 - val_loss: 0.7920 - val_accuracy: 0.7336\n",
      "Epoch 83/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.7235 - accuracy: 0.7370 - val_loss: 0.8037 - val_accuracy: 0.7183\n",
      "Epoch 84/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.7294 - accuracy: 0.7298 - val_loss: 0.7755 - val_accuracy: 0.7385\n",
      "Epoch 85/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.7348 - accuracy: 0.7308 - val_loss: 0.7803 - val_accuracy: 0.7183\n",
      "Epoch 86/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.7123 - accuracy: 0.7356 - val_loss: 0.7808 - val_accuracy: 0.7553\n",
      "Epoch 87/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.7177 - accuracy: 0.7332 - val_loss: 0.7700 - val_accuracy: 0.7366\n",
      "Epoch 88/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.7120 - accuracy: 0.7306 - val_loss: 0.7552 - val_accuracy: 0.7504\n",
      "Epoch 89/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.7041 - accuracy: 0.7372 - val_loss: 0.7448 - val_accuracy: 0.7538\n",
      "Epoch 90/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.7042 - accuracy: 0.7368 - val_loss: 0.7692 - val_accuracy: 0.7306\n",
      "Epoch 91/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.7134 - accuracy: 0.7398 - val_loss: 0.7899 - val_accuracy: 0.7499\n",
      "Epoch 92/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.7006 - accuracy: 0.7393 - val_loss: 0.7735 - val_accuracy: 0.7454\n",
      "Epoch 93/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.7007 - accuracy: 0.7353 - val_loss: 0.7607 - val_accuracy: 0.7420\n",
      "Epoch 94/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.7052 - accuracy: 0.7412 - val_loss: 0.7703 - val_accuracy: 0.7178\n",
      "Epoch 95/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.6935 - accuracy: 0.7380 - val_loss: 0.7570 - val_accuracy: 0.7390\n",
      "Epoch 96/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.7052 - accuracy: 0.7396 - val_loss: 0.7448 - val_accuracy: 0.7420\n",
      "Epoch 97/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.6866 - accuracy: 0.7400 - val_loss: 0.7483 - val_accuracy: 0.7479\n",
      "Epoch 98/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.6857 - accuracy: 0.7428 - val_loss: 0.7368 - val_accuracy: 0.7361\n",
      "Epoch 99/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.6867 - accuracy: 0.7335 - val_loss: 0.7387 - val_accuracy: 0.7380\n",
      "Epoch 100/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.6887 - accuracy: 0.7367 - val_loss: 0.7383 - val_accuracy: 0.7267\n",
      "Epoch 101/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.6838 - accuracy: 0.7358 - val_loss: 0.7596 - val_accuracy: 0.7454\n",
      "Epoch 102/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.6789 - accuracy: 0.7412 - val_loss: 0.7255 - val_accuracy: 0.7474\n",
      "Epoch 103/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.6721 - accuracy: 0.7440 - val_loss: 0.7567 - val_accuracy: 0.7425\n",
      "Epoch 104/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.6692 - accuracy: 0.7465 - val_loss: 0.7239 - val_accuracy: 0.7415\n",
      "Epoch 105/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.6657 - accuracy: 0.7477 - val_loss: 0.7434 - val_accuracy: 0.7390\n",
      "Epoch 106/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.6682 - accuracy: 0.7373 - val_loss: 0.7142 - val_accuracy: 0.7415\n",
      "Epoch 107/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.6710 - accuracy: 0.7422 - val_loss: 0.7336 - val_accuracy: 0.7440\n",
      "Epoch 108/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.6741 - accuracy: 0.7444 - val_loss: 0.7542 - val_accuracy: 0.7474\n",
      "Epoch 109/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.6665 - accuracy: 0.7395 - val_loss: 0.7125 - val_accuracy: 0.7519\n",
      "Epoch 110/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.6581 - accuracy: 0.7485 - val_loss: 0.7169 - val_accuracy: 0.7489\n",
      "Epoch 111/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.6633 - accuracy: 0.7409 - val_loss: 0.7495 - val_accuracy: 0.7469\n",
      "Epoch 112/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.6512 - accuracy: 0.7447 - val_loss: 0.7312 - val_accuracy: 0.7568\n",
      "Epoch 113/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.6531 - accuracy: 0.7493 - val_loss: 0.7082 - val_accuracy: 0.7602\n",
      "Epoch 114/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.6562 - accuracy: 0.7474 - val_loss: 0.7084 - val_accuracy: 0.7597\n",
      "Epoch 115/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.6533 - accuracy: 0.7449 - val_loss: 0.6922 - val_accuracy: 0.7494\n",
      "Epoch 116/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.6515 - accuracy: 0.7353 - val_loss: 0.7083 - val_accuracy: 0.7494\n",
      "Epoch 117/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.6516 - accuracy: 0.7474 - val_loss: 0.6998 - val_accuracy: 0.7454\n",
      "Epoch 118/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.6489 - accuracy: 0.7483 - val_loss: 0.7145 - val_accuracy: 0.7632\n",
      "Epoch 119/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.6411 - accuracy: 0.7437 - val_loss: 0.6856 - val_accuracy: 0.7583\n",
      "Epoch 120/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.6405 - accuracy: 0.7461 - val_loss: 0.7235 - val_accuracy: 0.7341\n",
      "Epoch 121/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.6498 - accuracy: 0.7441 - val_loss: 0.7485 - val_accuracy: 0.7222\n",
      "Epoch 122/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.6567 - accuracy: 0.7473 - val_loss: 0.6842 - val_accuracy: 0.7504\n",
      "Epoch 123/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.6467 - accuracy: 0.7467 - val_loss: 0.7218 - val_accuracy: 0.7346\n",
      "Epoch 124/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.6333 - accuracy: 0.7475 - val_loss: 0.6862 - val_accuracy: 0.7647\n",
      "Epoch 125/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.6324 - accuracy: 0.7517 - val_loss: 0.6789 - val_accuracy: 0.7504\n",
      "Epoch 126/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.6354 - accuracy: 0.7505 - val_loss: 0.7283 - val_accuracy: 0.7361\n",
      "Epoch 127/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.6398 - accuracy: 0.7457 - val_loss: 0.6685 - val_accuracy: 0.7568\n",
      "Epoch 128/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.6251 - accuracy: 0.7501 - val_loss: 0.6897 - val_accuracy: 0.7617\n",
      "Epoch 129/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.6352 - accuracy: 0.7494 - val_loss: 0.6682 - val_accuracy: 0.7514\n",
      "Epoch 130/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.6208 - accuracy: 0.7510 - val_loss: 0.6813 - val_accuracy: 0.7597\n",
      "Epoch 131/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.6202 - accuracy: 0.7514 - val_loss: 0.6728 - val_accuracy: 0.7607\n",
      "Epoch 132/1000\n",
      "8108/8108 [==============================] - 0s 23us/step - loss: 0.6223 - accuracy: 0.7490 - val_loss: 0.6726 - val_accuracy: 0.7602\n",
      "Epoch 133/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.6173 - accuracy: 0.7511 - val_loss: 0.7012 - val_accuracy: 0.7454\n",
      "Epoch 134/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.6307 - accuracy: 0.7511 - val_loss: 0.6813 - val_accuracy: 0.7593\n",
      "Epoch 135/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.6208 - accuracy: 0.7474 - val_loss: 0.6701 - val_accuracy: 0.7410\n",
      "Epoch 136/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.6216 - accuracy: 0.7480 - val_loss: 0.6616 - val_accuracy: 0.7514\n",
      "Epoch 137/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.6144 - accuracy: 0.7548 - val_loss: 0.7294 - val_accuracy: 0.7449\n",
      "Epoch 138/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.6277 - accuracy: 0.7481 - val_loss: 0.6624 - val_accuracy: 0.7514\n",
      "Epoch 139/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.6112 - accuracy: 0.7537 - val_loss: 0.6724 - val_accuracy: 0.7405\n",
      "Epoch 140/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.6127 - accuracy: 0.7506 - val_loss: 0.6698 - val_accuracy: 0.7617\n",
      "Epoch 141/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.6094 - accuracy: 0.7574 - val_loss: 0.6615 - val_accuracy: 0.7509\n",
      "Epoch 142/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.6070 - accuracy: 0.7578 - val_loss: 0.6602 - val_accuracy: 0.7479\n",
      "Epoch 143/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.6022 - accuracy: 0.7495 - val_loss: 0.6538 - val_accuracy: 0.7509\n",
      "Epoch 144/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.6035 - accuracy: 0.7505 - val_loss: 0.6497 - val_accuracy: 0.7602\n",
      "Epoch 145/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.5982 - accuracy: 0.7463 - val_loss: 0.6493 - val_accuracy: 0.7671\n",
      "Epoch 146/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5992 - accuracy: 0.7537 - val_loss: 0.7026 - val_accuracy: 0.7509\n",
      "Epoch 147/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.6045 - accuracy: 0.7526 - val_loss: 0.6551 - val_accuracy: 0.7681\n",
      "Epoch 148/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.5938 - accuracy: 0.7544 - val_loss: 0.6456 - val_accuracy: 0.7686\n",
      "Epoch 149/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.5917 - accuracy: 0.7533 - val_loss: 0.6560 - val_accuracy: 0.7657\n",
      "Epoch 150/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.5945 - accuracy: 0.7486 - val_loss: 0.6581 - val_accuracy: 0.7652\n",
      "Epoch 151/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.5999 - accuracy: 0.7505 - val_loss: 0.6983 - val_accuracy: 0.7627\n",
      "Epoch 152/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.5923 - accuracy: 0.7580 - val_loss: 0.6422 - val_accuracy: 0.7642\n",
      "Epoch 153/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.5957 - accuracy: 0.7495 - val_loss: 0.6699 - val_accuracy: 0.7321\n",
      "Epoch 154/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.5977 - accuracy: 0.7519 - val_loss: 0.6392 - val_accuracy: 0.7662\n",
      "Epoch 155/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5958 - accuracy: 0.7574 - val_loss: 0.6608 - val_accuracy: 0.7652\n",
      "Epoch 156/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.5892 - accuracy: 0.7493 - val_loss: 0.6316 - val_accuracy: 0.7662\n",
      "Epoch 157/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5813 - accuracy: 0.7528 - val_loss: 0.6330 - val_accuracy: 0.7647\n",
      "Epoch 158/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.5907 - accuracy: 0.7502 - val_loss: 0.6265 - val_accuracy: 0.7499\n",
      "Epoch 159/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5931 - accuracy: 0.7486 - val_loss: 0.6494 - val_accuracy: 0.7607\n",
      "Epoch 160/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5889 - accuracy: 0.7477 - val_loss: 0.6541 - val_accuracy: 0.7627\n",
      "Epoch 161/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.5928 - accuracy: 0.7541 - val_loss: 0.6648 - val_accuracy: 0.7509\n",
      "Epoch 162/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 0.5846 - accuracy: 0.7548 - val_loss: 0.6221 - val_accuracy: 0.7632\n",
      "Epoch 163/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.5747 - accuracy: 0.7586 - val_loss: 0.6399 - val_accuracy: 0.7593\n",
      "Epoch 164/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5805 - accuracy: 0.7526 - val_loss: 0.6696 - val_accuracy: 0.7642\n",
      "Epoch 165/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.5936 - accuracy: 0.7573 - val_loss: 0.6240 - val_accuracy: 0.7662\n",
      "Epoch 166/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.5799 - accuracy: 0.7564 - val_loss: 0.6344 - val_accuracy: 0.7514\n",
      "Epoch 167/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.5776 - accuracy: 0.7523 - val_loss: 0.6552 - val_accuracy: 0.7602\n",
      "Epoch 168/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5820 - accuracy: 0.7501 - val_loss: 0.6262 - val_accuracy: 0.7696\n",
      "Epoch 169/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5865 - accuracy: 0.7523 - val_loss: 0.6518 - val_accuracy: 0.7691\n",
      "Epoch 170/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.5792 - accuracy: 0.7538 - val_loss: 0.6257 - val_accuracy: 0.7588\n",
      "Epoch 171/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.5733 - accuracy: 0.7565 - val_loss: 0.6093 - val_accuracy: 0.7642\n",
      "Epoch 172/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.5700 - accuracy: 0.7591 - val_loss: 0.6275 - val_accuracy: 0.7459\n",
      "Epoch 173/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5695 - accuracy: 0.7579 - val_loss: 0.6209 - val_accuracy: 0.7538\n",
      "Epoch 174/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.5683 - accuracy: 0.7546 - val_loss: 0.6624 - val_accuracy: 0.7671\n",
      "Epoch 175/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.5642 - accuracy: 0.7586 - val_loss: 0.6139 - val_accuracy: 0.7533\n",
      "Epoch 176/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5646 - accuracy: 0.7591 - val_loss: 0.6185 - val_accuracy: 0.7617\n",
      "Epoch 177/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5622 - accuracy: 0.7602 - val_loss: 0.6206 - val_accuracy: 0.7597\n",
      "Epoch 178/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5642 - accuracy: 0.7544 - val_loss: 0.6130 - val_accuracy: 0.7696\n",
      "Epoch 179/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5626 - accuracy: 0.7638 - val_loss: 0.6123 - val_accuracy: 0.7671\n",
      "Epoch 180/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5643 - accuracy: 0.7589 - val_loss: 0.6037 - val_accuracy: 0.7657\n",
      "Epoch 181/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5670 - accuracy: 0.7565 - val_loss: 0.6161 - val_accuracy: 0.7627\n",
      "Epoch 182/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.5644 - accuracy: 0.7594 - val_loss: 0.6201 - val_accuracy: 0.7662\n",
      "Epoch 183/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5562 - accuracy: 0.7625 - val_loss: 0.6188 - val_accuracy: 0.7657\n",
      "Epoch 184/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5579 - accuracy: 0.7580 - val_loss: 0.6028 - val_accuracy: 0.7662\n",
      "Epoch 185/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5567 - accuracy: 0.7520 - val_loss: 0.6247 - val_accuracy: 0.7489\n",
      "Epoch 186/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5571 - accuracy: 0.7572 - val_loss: 0.6020 - val_accuracy: 0.7652\n",
      "Epoch 187/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5500 - accuracy: 0.7590 - val_loss: 0.5967 - val_accuracy: 0.7676\n",
      "Epoch 188/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.5661 - accuracy: 0.7589 - val_loss: 0.5953 - val_accuracy: 0.7686\n",
      "Epoch 189/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5589 - accuracy: 0.7542 - val_loss: 0.6005 - val_accuracy: 0.7627\n",
      "Epoch 190/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.5538 - accuracy: 0.7576 - val_loss: 0.6011 - val_accuracy: 0.7568\n",
      "Epoch 191/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5521 - accuracy: 0.7596 - val_loss: 0.5995 - val_accuracy: 0.7681\n",
      "Epoch 192/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 0.5569 - accuracy: 0.7600 - val_loss: 0.6092 - val_accuracy: 0.7523\n",
      "Epoch 193/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.5490 - accuracy: 0.7633 - val_loss: 0.6042 - val_accuracy: 0.7667\n",
      "Epoch 194/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5543 - accuracy: 0.7579 - val_loss: 0.5896 - val_accuracy: 0.7593\n",
      "Epoch 195/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5562 - accuracy: 0.7591 - val_loss: 0.6166 - val_accuracy: 0.7588\n",
      "Epoch 196/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5599 - accuracy: 0.7595 - val_loss: 0.5912 - val_accuracy: 0.7652\n",
      "Epoch 197/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5470 - accuracy: 0.7617 - val_loss: 0.6438 - val_accuracy: 0.7528\n",
      "Epoch 198/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5539 - accuracy: 0.7537 - val_loss: 0.5950 - val_accuracy: 0.7509\n",
      "Epoch 199/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5427 - accuracy: 0.7595 - val_loss: 0.5878 - val_accuracy: 0.7716\n",
      "Epoch 200/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5385 - accuracy: 0.7621 - val_loss: 0.6082 - val_accuracy: 0.7627\n",
      "Epoch 201/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5391 - accuracy: 0.7663 - val_loss: 0.5899 - val_accuracy: 0.7573\n",
      "Epoch 202/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5405 - accuracy: 0.7641 - val_loss: 0.5858 - val_accuracy: 0.7637\n",
      "Epoch 203/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5428 - accuracy: 0.7557 - val_loss: 0.5918 - val_accuracy: 0.7671\n",
      "Epoch 204/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5574 - accuracy: 0.7517 - val_loss: 0.6406 - val_accuracy: 0.7479\n",
      "Epoch 205/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5416 - accuracy: 0.7581 - val_loss: 0.5950 - val_accuracy: 0.7563\n",
      "Epoch 206/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5318 - accuracy: 0.7681 - val_loss: 0.5834 - val_accuracy: 0.7676\n",
      "Epoch 207/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5473 - accuracy: 0.7528 - val_loss: 0.6106 - val_accuracy: 0.7676\n",
      "Epoch 208/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5382 - accuracy: 0.7572 - val_loss: 0.5812 - val_accuracy: 0.7726\n",
      "Epoch 209/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5418 - accuracy: 0.7525 - val_loss: 0.5787 - val_accuracy: 0.7726\n",
      "Epoch 210/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5359 - accuracy: 0.7553 - val_loss: 0.5790 - val_accuracy: 0.7681\n",
      "Epoch 211/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5340 - accuracy: 0.7612 - val_loss: 0.5828 - val_accuracy: 0.7706\n",
      "Epoch 212/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5387 - accuracy: 0.7573 - val_loss: 0.5776 - val_accuracy: 0.7637\n",
      "Epoch 213/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5407 - accuracy: 0.7601 - val_loss: 0.5992 - val_accuracy: 0.7543\n",
      "Epoch 214/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5336 - accuracy: 0.7630 - val_loss: 0.5830 - val_accuracy: 0.7637\n",
      "Epoch 215/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.5438 - accuracy: 0.7623 - val_loss: 0.5844 - val_accuracy: 0.7736\n",
      "Epoch 216/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5293 - accuracy: 0.7623 - val_loss: 0.5971 - val_accuracy: 0.7464\n",
      "Epoch 217/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.5293 - accuracy: 0.7644 - val_loss: 0.5733 - val_accuracy: 0.7667\n",
      "Epoch 218/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5281 - accuracy: 0.7646 - val_loss: 0.6003 - val_accuracy: 0.7469\n",
      "Epoch 219/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5377 - accuracy: 0.7591 - val_loss: 0.5764 - val_accuracy: 0.7632\n",
      "Epoch 220/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5352 - accuracy: 0.7636 - val_loss: 0.5793 - val_accuracy: 0.7716\n",
      "Epoch 221/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5412 - accuracy: 0.7594 - val_loss: 0.5772 - val_accuracy: 0.7519\n",
      "Epoch 222/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5374 - accuracy: 0.7552 - val_loss: 0.5857 - val_accuracy: 0.7681\n",
      "Epoch 223/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5254 - accuracy: 0.7628 - val_loss: 0.5929 - val_accuracy: 0.7504\n",
      "Epoch 224/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5267 - accuracy: 0.7599 - val_loss: 0.5580 - val_accuracy: 0.7686\n",
      "Epoch 225/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5219 - accuracy: 0.7602 - val_loss: 0.5591 - val_accuracy: 0.7741\n",
      "Epoch 226/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5286 - accuracy: 0.7638 - val_loss: 0.5688 - val_accuracy: 0.7553\n",
      "Epoch 227/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5202 - accuracy: 0.7601 - val_loss: 0.5605 - val_accuracy: 0.7642\n",
      "Epoch 228/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5212 - accuracy: 0.7638 - val_loss: 0.5720 - val_accuracy: 0.7499\n",
      "Epoch 229/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5352 - accuracy: 0.7591 - val_loss: 0.6043 - val_accuracy: 0.7444\n",
      "Epoch 230/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5474 - accuracy: 0.7549 - val_loss: 0.5711 - val_accuracy: 0.7652\n",
      "Epoch 231/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5225 - accuracy: 0.7638 - val_loss: 0.5676 - val_accuracy: 0.7558\n",
      "Epoch 232/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.5182 - accuracy: 0.7643 - val_loss: 0.5857 - val_accuracy: 0.7573\n",
      "Epoch 233/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 0.5270 - accuracy: 0.7621 - val_loss: 0.6024 - val_accuracy: 0.7691\n",
      "Epoch 234/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.5278 - accuracy: 0.7626 - val_loss: 0.5707 - val_accuracy: 0.7563\n",
      "Epoch 235/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.5225 - accuracy: 0.7605 - val_loss: 0.5592 - val_accuracy: 0.7647\n",
      "Epoch 236/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5156 - accuracy: 0.7652 - val_loss: 0.5599 - val_accuracy: 0.7711\n",
      "Epoch 237/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5182 - accuracy: 0.7626 - val_loss: 0.5559 - val_accuracy: 0.7597\n",
      "Epoch 238/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5096 - accuracy: 0.7689 - val_loss: 0.5655 - val_accuracy: 0.7750\n",
      "Epoch 239/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5133 - accuracy: 0.7638 - val_loss: 0.5525 - val_accuracy: 0.7671\n",
      "Epoch 240/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5194 - accuracy: 0.7613 - val_loss: 0.5718 - val_accuracy: 0.7573\n",
      "Epoch 241/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5132 - accuracy: 0.7686 - val_loss: 0.5502 - val_accuracy: 0.7726\n",
      "Epoch 242/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5153 - accuracy: 0.7657 - val_loss: 0.5619 - val_accuracy: 0.7721\n",
      "Epoch 243/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.5052 - accuracy: 0.7699 - val_loss: 0.5632 - val_accuracy: 0.7671\n",
      "Epoch 244/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.5132 - accuracy: 0.7646 - val_loss: 0.5648 - val_accuracy: 0.7721\n",
      "Epoch 245/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5108 - accuracy: 0.7623 - val_loss: 0.5568 - val_accuracy: 0.7543\n",
      "Epoch 246/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5124 - accuracy: 0.7627 - val_loss: 0.5498 - val_accuracy: 0.7711\n",
      "Epoch 247/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.5142 - accuracy: 0.7697 - val_loss: 0.5534 - val_accuracy: 0.7652\n",
      "Epoch 248/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5133 - accuracy: 0.7575 - val_loss: 0.5641 - val_accuracy: 0.7578\n",
      "Epoch 249/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.5147 - accuracy: 0.7604 - val_loss: 0.5935 - val_accuracy: 0.7745\n",
      "Epoch 250/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.5122 - accuracy: 0.7663 - val_loss: 0.5531 - val_accuracy: 0.7622\n",
      "Epoch 251/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5212 - accuracy: 0.7596 - val_loss: 0.5951 - val_accuracy: 0.7514\n",
      "Epoch 252/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5303 - accuracy: 0.7680 - val_loss: 0.5599 - val_accuracy: 0.7494\n",
      "Epoch 253/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.5113 - accuracy: 0.7616 - val_loss: 0.5457 - val_accuracy: 0.7706\n",
      "Epoch 254/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5094 - accuracy: 0.7653 - val_loss: 0.5649 - val_accuracy: 0.7474\n",
      "Epoch 255/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5045 - accuracy: 0.7650 - val_loss: 0.5556 - val_accuracy: 0.7775\n",
      "Epoch 256/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.5072 - accuracy: 0.7705 - val_loss: 0.5602 - val_accuracy: 0.7760\n",
      "Epoch 257/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.5049 - accuracy: 0.7660 - val_loss: 0.5379 - val_accuracy: 0.7686\n",
      "Epoch 258/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.5089 - accuracy: 0.7664 - val_loss: 0.5437 - val_accuracy: 0.7627\n",
      "Epoch 259/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5088 - accuracy: 0.7723 - val_loss: 0.5467 - val_accuracy: 0.7533\n",
      "Epoch 260/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.5031 - accuracy: 0.7654 - val_loss: 0.5539 - val_accuracy: 0.7642\n",
      "Epoch 261/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5107 - accuracy: 0.7605 - val_loss: 0.5363 - val_accuracy: 0.7667\n",
      "Epoch 262/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4998 - accuracy: 0.7641 - val_loss: 0.5623 - val_accuracy: 0.7681\n",
      "Epoch 263/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.5030 - accuracy: 0.7649 - val_loss: 0.5423 - val_accuracy: 0.7558\n",
      "Epoch 264/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 0.5119 - accuracy: 0.7634 - val_loss: 0.5498 - val_accuracy: 0.7647\n",
      "Epoch 265/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.5057 - accuracy: 0.7668 - val_loss: 0.5381 - val_accuracy: 0.7696\n",
      "Epoch 266/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.5015 - accuracy: 0.7644 - val_loss: 0.5359 - val_accuracy: 0.7800\n",
      "Epoch 267/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5061 - accuracy: 0.7664 - val_loss: 0.5602 - val_accuracy: 0.7553\n",
      "Epoch 268/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.5008 - accuracy: 0.7616 - val_loss: 0.5376 - val_accuracy: 0.7711\n",
      "Epoch 269/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4991 - accuracy: 0.7655 - val_loss: 0.5336 - val_accuracy: 0.7647\n",
      "Epoch 270/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.5024 - accuracy: 0.7621 - val_loss: 0.5386 - val_accuracy: 0.7667\n",
      "Epoch 271/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.5008 - accuracy: 0.7628 - val_loss: 0.5299 - val_accuracy: 0.7755\n",
      "Epoch 272/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.5002 - accuracy: 0.7673 - val_loss: 0.5450 - val_accuracy: 0.7676\n",
      "Epoch 273/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4976 - accuracy: 0.7599 - val_loss: 0.5295 - val_accuracy: 0.7770\n",
      "Epoch 274/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.5035 - accuracy: 0.7646 - val_loss: 0.5466 - val_accuracy: 0.7553\n",
      "Epoch 275/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.5034 - accuracy: 0.7643 - val_loss: 0.5323 - val_accuracy: 0.7671\n",
      "Epoch 276/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4963 - accuracy: 0.7673 - val_loss: 0.5464 - val_accuracy: 0.7597\n",
      "Epoch 277/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.4973 - accuracy: 0.7700 - val_loss: 0.5347 - val_accuracy: 0.7686\n",
      "Epoch 278/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4924 - accuracy: 0.7653 - val_loss: 0.5366 - val_accuracy: 0.7770\n",
      "Epoch 279/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4905 - accuracy: 0.7727 - val_loss: 0.5445 - val_accuracy: 0.7790\n",
      "Epoch 280/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 0.4950 - accuracy: 0.7670 - val_loss: 0.5318 - val_accuracy: 0.7593\n",
      "Epoch 281/1000\n",
      "8108/8108 [==============================] - 0s 37us/step - loss: 0.4860 - accuracy: 0.7716 - val_loss: 0.5250 - val_accuracy: 0.7760\n",
      "Epoch 282/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 0.4957 - accuracy: 0.7632 - val_loss: 0.5314 - val_accuracy: 0.7588\n",
      "Epoch 283/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4991 - accuracy: 0.7680 - val_loss: 0.5298 - val_accuracy: 0.7726\n",
      "Epoch 284/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.4958 - accuracy: 0.7664 - val_loss: 0.5685 - val_accuracy: 0.7578\n",
      "Epoch 285/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.5012 - accuracy: 0.7652 - val_loss: 0.5313 - val_accuracy: 0.7755\n",
      "Epoch 286/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4940 - accuracy: 0.7648 - val_loss: 0.5295 - val_accuracy: 0.7745\n",
      "Epoch 287/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.4938 - accuracy: 0.7636 - val_loss: 0.5392 - val_accuracy: 0.7593\n",
      "Epoch 288/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4904 - accuracy: 0.7665 - val_loss: 0.5312 - val_accuracy: 0.7760\n",
      "Epoch 289/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.4868 - accuracy: 0.7699 - val_loss: 0.5284 - val_accuracy: 0.7745\n",
      "Epoch 290/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4896 - accuracy: 0.7755 - val_loss: 0.5422 - val_accuracy: 0.7548\n",
      "Epoch 291/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.4992 - accuracy: 0.7633 - val_loss: 0.5221 - val_accuracy: 0.7726\n",
      "Epoch 292/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4865 - accuracy: 0.7742 - val_loss: 0.5263 - val_accuracy: 0.7770\n",
      "Epoch 293/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.4980 - accuracy: 0.7657 - val_loss: 0.5237 - val_accuracy: 0.7667\n",
      "Epoch 294/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4877 - accuracy: 0.7702 - val_loss: 0.5447 - val_accuracy: 0.7736\n",
      "Epoch 295/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.4853 - accuracy: 0.7706 - val_loss: 0.5495 - val_accuracy: 0.7602\n",
      "Epoch 296/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4868 - accuracy: 0.7652 - val_loss: 0.5365 - val_accuracy: 0.7765\n",
      "Epoch 297/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4902 - accuracy: 0.7638 - val_loss: 0.5158 - val_accuracy: 0.7736\n",
      "Epoch 298/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4854 - accuracy: 0.7663 - val_loss: 0.5231 - val_accuracy: 0.7721\n",
      "Epoch 299/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4912 - accuracy: 0.7650 - val_loss: 0.5494 - val_accuracy: 0.7785\n",
      "Epoch 300/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4854 - accuracy: 0.7650 - val_loss: 0.5179 - val_accuracy: 0.7741\n",
      "Epoch 301/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4783 - accuracy: 0.7705 - val_loss: 0.5368 - val_accuracy: 0.7711\n",
      "Epoch 302/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4839 - accuracy: 0.7662 - val_loss: 0.5347 - val_accuracy: 0.7662\n",
      "Epoch 303/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4916 - accuracy: 0.7664 - val_loss: 0.5350 - val_accuracy: 0.7662\n",
      "Epoch 304/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4880 - accuracy: 0.7727 - val_loss: 0.5485 - val_accuracy: 0.7573\n",
      "Epoch 305/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4859 - accuracy: 0.7687 - val_loss: 0.5501 - val_accuracy: 0.7745\n",
      "Epoch 306/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.4882 - accuracy: 0.7671 - val_loss: 0.5384 - val_accuracy: 0.7691\n",
      "Epoch 307/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4790 - accuracy: 0.7647 - val_loss: 0.5279 - val_accuracy: 0.7593\n",
      "Epoch 308/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4830 - accuracy: 0.7626 - val_loss: 0.5216 - val_accuracy: 0.7810\n",
      "Epoch 309/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4823 - accuracy: 0.7686 - val_loss: 0.5135 - val_accuracy: 0.7731\n",
      "Epoch 310/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4843 - accuracy: 0.7710 - val_loss: 0.5287 - val_accuracy: 0.7637\n",
      "Epoch 311/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4746 - accuracy: 0.7707 - val_loss: 0.5237 - val_accuracy: 0.7741\n",
      "Epoch 312/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4768 - accuracy: 0.7701 - val_loss: 0.5079 - val_accuracy: 0.7755\n",
      "Epoch 313/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4792 - accuracy: 0.7711 - val_loss: 0.5160 - val_accuracy: 0.7607\n",
      "Epoch 314/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4803 - accuracy: 0.7638 - val_loss: 0.5112 - val_accuracy: 0.7741\n",
      "Epoch 315/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4863 - accuracy: 0.7664 - val_loss: 0.5221 - val_accuracy: 0.7726\n",
      "Epoch 316/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4740 - accuracy: 0.7689 - val_loss: 0.5145 - val_accuracy: 0.7736\n",
      "Epoch 317/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4730 - accuracy: 0.7707 - val_loss: 0.5184 - val_accuracy: 0.7647\n",
      "Epoch 318/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4723 - accuracy: 0.7696 - val_loss: 0.5133 - val_accuracy: 0.7790\n",
      "Epoch 319/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4722 - accuracy: 0.7724 - val_loss: 0.5095 - val_accuracy: 0.7780\n",
      "Epoch 320/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4763 - accuracy: 0.7710 - val_loss: 0.5136 - val_accuracy: 0.7676\n",
      "Epoch 321/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4729 - accuracy: 0.7679 - val_loss: 0.5296 - val_accuracy: 0.7800\n",
      "Epoch 322/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4765 - accuracy: 0.7721 - val_loss: 0.5302 - val_accuracy: 0.7736\n",
      "Epoch 323/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4776 - accuracy: 0.7671 - val_loss: 0.5010 - val_accuracy: 0.7755\n",
      "Epoch 324/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4750 - accuracy: 0.7699 - val_loss: 0.5050 - val_accuracy: 0.7731\n",
      "Epoch 325/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4736 - accuracy: 0.7741 - val_loss: 0.5164 - val_accuracy: 0.7760\n",
      "Epoch 326/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4719 - accuracy: 0.7708 - val_loss: 0.5366 - val_accuracy: 0.7775\n",
      "Epoch 327/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4935 - accuracy: 0.7652 - val_loss: 0.5346 - val_accuracy: 0.7558\n",
      "Epoch 328/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4712 - accuracy: 0.7710 - val_loss: 0.5279 - val_accuracy: 0.7755\n",
      "Epoch 329/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4807 - accuracy: 0.7736 - val_loss: 0.5099 - val_accuracy: 0.7716\n",
      "Epoch 330/1000\n",
      "8108/8108 [==============================] - ETA: 0s - loss: 0.4827 - accuracy: 0.76 - 0s 25us/step - loss: 0.4772 - accuracy: 0.7701 - val_loss: 0.5312 - val_accuracy: 0.7765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4703 - accuracy: 0.7755 - val_loss: 0.5166 - val_accuracy: 0.7607\n",
      "Epoch 332/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4728 - accuracy: 0.7708 - val_loss: 0.5219 - val_accuracy: 0.7711\n",
      "Epoch 333/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4710 - accuracy: 0.7697 - val_loss: 0.5098 - val_accuracy: 0.7716\n",
      "Epoch 334/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4723 - accuracy: 0.7733 - val_loss: 0.5150 - val_accuracy: 0.7741\n",
      "Epoch 335/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4651 - accuracy: 0.7737 - val_loss: 0.5132 - val_accuracy: 0.7755\n",
      "Epoch 336/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4828 - accuracy: 0.7711 - val_loss: 0.5304 - val_accuracy: 0.7514\n",
      "Epoch 337/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4683 - accuracy: 0.7722 - val_loss: 0.4974 - val_accuracy: 0.7731\n",
      "Epoch 338/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4685 - accuracy: 0.7713 - val_loss: 0.4992 - val_accuracy: 0.7706\n",
      "Epoch 339/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4681 - accuracy: 0.7657 - val_loss: 0.5028 - val_accuracy: 0.7765\n",
      "Epoch 340/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4723 - accuracy: 0.7627 - val_loss: 0.4965 - val_accuracy: 0.7736\n",
      "Epoch 341/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4603 - accuracy: 0.7731 - val_loss: 0.5138 - val_accuracy: 0.7602\n",
      "Epoch 342/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4684 - accuracy: 0.7742 - val_loss: 0.5012 - val_accuracy: 0.7765\n",
      "Epoch 343/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4687 - accuracy: 0.7700 - val_loss: 0.5091 - val_accuracy: 0.7741\n",
      "Epoch 344/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4661 - accuracy: 0.7721 - val_loss: 0.5053 - val_accuracy: 0.7741\n",
      "Epoch 345/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4645 - accuracy: 0.7721 - val_loss: 0.5225 - val_accuracy: 0.7770\n",
      "Epoch 346/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4677 - accuracy: 0.7766 - val_loss: 0.5156 - val_accuracy: 0.7785\n",
      "Epoch 347/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4656 - accuracy: 0.7754 - val_loss: 0.5156 - val_accuracy: 0.7652\n",
      "Epoch 348/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4754 - accuracy: 0.7741 - val_loss: 0.5181 - val_accuracy: 0.7563\n",
      "Epoch 349/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4618 - accuracy: 0.7704 - val_loss: 0.5022 - val_accuracy: 0.7795\n",
      "Epoch 350/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4650 - accuracy: 0.7700 - val_loss: 0.5059 - val_accuracy: 0.7721\n",
      "Epoch 351/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4723 - accuracy: 0.7705 - val_loss: 0.4972 - val_accuracy: 0.7790\n",
      "Epoch 352/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4601 - accuracy: 0.7715 - val_loss: 0.4980 - val_accuracy: 0.7775\n",
      "Epoch 353/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4699 - accuracy: 0.7716 - val_loss: 0.4966 - val_accuracy: 0.7706\n",
      "Epoch 354/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4612 - accuracy: 0.7658 - val_loss: 0.5086 - val_accuracy: 0.7790\n",
      "Epoch 355/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4640 - accuracy: 0.7678 - val_loss: 0.4989 - val_accuracy: 0.7736\n",
      "Epoch 356/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4657 - accuracy: 0.7705 - val_loss: 0.4907 - val_accuracy: 0.7716\n",
      "Epoch 357/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4600 - accuracy: 0.7720 - val_loss: 0.5148 - val_accuracy: 0.7800\n",
      "Epoch 358/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4688 - accuracy: 0.7737 - val_loss: 0.5008 - val_accuracy: 0.7741\n",
      "Epoch 359/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4615 - accuracy: 0.7726 - val_loss: 0.5252 - val_accuracy: 0.7716\n",
      "Epoch 360/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4661 - accuracy: 0.7689 - val_loss: 0.4873 - val_accuracy: 0.7721\n",
      "Epoch 361/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4688 - accuracy: 0.7664 - val_loss: 0.4892 - val_accuracy: 0.7765\n",
      "Epoch 362/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4642 - accuracy: 0.7663 - val_loss: 0.4863 - val_accuracy: 0.7701\n",
      "Epoch 363/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4547 - accuracy: 0.7766 - val_loss: 0.5531 - val_accuracy: 0.7558\n",
      "Epoch 364/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4629 - accuracy: 0.7732 - val_loss: 0.4925 - val_accuracy: 0.7696\n",
      "Epoch 365/1000\n",
      "8108/8108 [==============================] - 0s 43us/step - loss: 0.4712 - accuracy: 0.7676 - val_loss: 0.4912 - val_accuracy: 0.7780\n",
      "Epoch 366/1000\n",
      "8108/8108 [==============================] - 0s 37us/step - loss: 0.4686 - accuracy: 0.7648 - val_loss: 0.4946 - val_accuracy: 0.7760\n",
      "Epoch 367/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 0.4565 - accuracy: 0.7679 - val_loss: 0.5037 - val_accuracy: 0.7593\n",
      "Epoch 368/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.4574 - accuracy: 0.7768 - val_loss: 0.5040 - val_accuracy: 0.7736\n",
      "Epoch 369/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4567 - accuracy: 0.7721 - val_loss: 0.5135 - val_accuracy: 0.7760\n",
      "Epoch 370/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4584 - accuracy: 0.7710 - val_loss: 0.5004 - val_accuracy: 0.7686\n",
      "Epoch 371/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4605 - accuracy: 0.7718 - val_loss: 0.4917 - val_accuracy: 0.7780\n",
      "Epoch 372/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4595 - accuracy: 0.7733 - val_loss: 0.4892 - val_accuracy: 0.7824\n",
      "Epoch 373/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4573 - accuracy: 0.7699 - val_loss: 0.4886 - val_accuracy: 0.7607\n",
      "Epoch 374/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4597 - accuracy: 0.7676 - val_loss: 0.4946 - val_accuracy: 0.7755\n",
      "Epoch 375/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4550 - accuracy: 0.7755 - val_loss: 0.4884 - val_accuracy: 0.7741\n",
      "Epoch 376/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4521 - accuracy: 0.7755 - val_loss: 0.4929 - val_accuracy: 0.7726\n",
      "Epoch 377/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4539 - accuracy: 0.7712 - val_loss: 0.4828 - val_accuracy: 0.7731\n",
      "Epoch 378/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4666 - accuracy: 0.7696 - val_loss: 0.5116 - val_accuracy: 0.7760\n",
      "Epoch 379/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4711 - accuracy: 0.7681 - val_loss: 0.4889 - val_accuracy: 0.7775\n",
      "Epoch 380/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4565 - accuracy: 0.7707 - val_loss: 0.4828 - val_accuracy: 0.7736\n",
      "Epoch 381/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.4573 - accuracy: 0.7702 - val_loss: 0.5265 - val_accuracy: 0.7755\n",
      "Epoch 382/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4530 - accuracy: 0.7774 - val_loss: 0.4870 - val_accuracy: 0.7805\n",
      "Epoch 383/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4528 - accuracy: 0.7748 - val_loss: 0.4835 - val_accuracy: 0.7627\n",
      "Epoch 384/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4503 - accuracy: 0.7769 - val_loss: 0.4859 - val_accuracy: 0.7686\n",
      "Epoch 385/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4583 - accuracy: 0.7664 - val_loss: 0.4880 - val_accuracy: 0.7824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4527 - accuracy: 0.7754 - val_loss: 0.5012 - val_accuracy: 0.7667\n",
      "Epoch 387/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4565 - accuracy: 0.7738 - val_loss: 0.4796 - val_accuracy: 0.7765\n",
      "Epoch 388/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4556 - accuracy: 0.7754 - val_loss: 0.4865 - val_accuracy: 0.7731\n",
      "Epoch 389/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4604 - accuracy: 0.7736 - val_loss: 0.4841 - val_accuracy: 0.7785\n",
      "Epoch 390/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4603 - accuracy: 0.7674 - val_loss: 0.4974 - val_accuracy: 0.7795\n",
      "Epoch 391/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4592 - accuracy: 0.7734 - val_loss: 0.5212 - val_accuracy: 0.7602\n",
      "Epoch 392/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4495 - accuracy: 0.7780 - val_loss: 0.4757 - val_accuracy: 0.7696\n",
      "Epoch 393/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.4544 - accuracy: 0.7723 - val_loss: 0.4818 - val_accuracy: 0.7785\n",
      "Epoch 394/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4549 - accuracy: 0.7753 - val_loss: 0.4855 - val_accuracy: 0.7642\n",
      "Epoch 395/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4618 - accuracy: 0.7687 - val_loss: 0.4953 - val_accuracy: 0.7795\n",
      "Epoch 396/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4551 - accuracy: 0.7680 - val_loss: 0.4885 - val_accuracy: 0.7805\n",
      "Epoch 397/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4646 - accuracy: 0.7748 - val_loss: 0.4890 - val_accuracy: 0.7632\n",
      "Epoch 398/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4472 - accuracy: 0.7721 - val_loss: 0.4743 - val_accuracy: 0.7790\n",
      "Epoch 399/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.4489 - accuracy: 0.7675 - val_loss: 0.4825 - val_accuracy: 0.7745\n",
      "Epoch 400/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.4487 - accuracy: 0.7726 - val_loss: 0.4839 - val_accuracy: 0.7775\n",
      "Epoch 401/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.4468 - accuracy: 0.7699 - val_loss: 0.4834 - val_accuracy: 0.7760\n",
      "Epoch 402/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.4492 - accuracy: 0.7678 - val_loss: 0.4807 - val_accuracy: 0.7711\n",
      "Epoch 403/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.4540 - accuracy: 0.7739 - val_loss: 0.4875 - val_accuracy: 0.7810\n",
      "Epoch 404/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.4466 - accuracy: 0.7700 - val_loss: 0.4938 - val_accuracy: 0.7780\n",
      "Epoch 405/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4487 - accuracy: 0.7723 - val_loss: 0.5047 - val_accuracy: 0.7839\n",
      "Epoch 406/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4441 - accuracy: 0.7854 - val_loss: 0.4862 - val_accuracy: 0.7622\n",
      "Epoch 407/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4530 - accuracy: 0.7705 - val_loss: 0.4755 - val_accuracy: 0.7745\n",
      "Epoch 408/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4428 - accuracy: 0.7782 - val_loss: 0.4752 - val_accuracy: 0.7731\n",
      "Epoch 409/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4531 - accuracy: 0.7761 - val_loss: 0.4738 - val_accuracy: 0.7829\n",
      "Epoch 410/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4436 - accuracy: 0.7757 - val_loss: 0.5032 - val_accuracy: 0.7617\n",
      "Epoch 411/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4494 - accuracy: 0.7720 - val_loss: 0.4694 - val_accuracy: 0.7805\n",
      "Epoch 412/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4521 - accuracy: 0.7737 - val_loss: 0.4768 - val_accuracy: 0.7647\n",
      "Epoch 413/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4449 - accuracy: 0.7737 - val_loss: 0.4745 - val_accuracy: 0.7819\n",
      "Epoch 414/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4485 - accuracy: 0.7784 - val_loss: 0.4743 - val_accuracy: 0.7736\n",
      "Epoch 415/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4421 - accuracy: 0.7745 - val_loss: 0.4905 - val_accuracy: 0.7627\n",
      "Epoch 416/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4527 - accuracy: 0.7718 - val_loss: 0.5137 - val_accuracy: 0.7597\n",
      "Epoch 417/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4598 - accuracy: 0.7685 - val_loss: 0.4763 - val_accuracy: 0.7785\n",
      "Epoch 418/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4458 - accuracy: 0.7764 - val_loss: 0.4820 - val_accuracy: 0.7750\n",
      "Epoch 419/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.4493 - accuracy: 0.7712 - val_loss: 0.4715 - val_accuracy: 0.7834\n",
      "Epoch 420/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4455 - accuracy: 0.7771 - val_loss: 0.4717 - val_accuracy: 0.7775\n",
      "Epoch 421/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4482 - accuracy: 0.7724 - val_loss: 0.4809 - val_accuracy: 0.7765\n",
      "Epoch 422/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4453 - accuracy: 0.7742 - val_loss: 0.4722 - val_accuracy: 0.7691\n",
      "Epoch 423/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4425 - accuracy: 0.7790 - val_loss: 0.4871 - val_accuracy: 0.7593\n",
      "Epoch 424/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4539 - accuracy: 0.7681 - val_loss: 0.4714 - val_accuracy: 0.7671\n",
      "Epoch 425/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4449 - accuracy: 0.7664 - val_loss: 0.4736 - val_accuracy: 0.7819\n",
      "Epoch 426/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4454 - accuracy: 0.7736 - val_loss: 0.5003 - val_accuracy: 0.7617\n",
      "Epoch 427/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4399 - accuracy: 0.7801 - val_loss: 0.4724 - val_accuracy: 0.7686\n",
      "Epoch 428/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4434 - accuracy: 0.7736 - val_loss: 0.4692 - val_accuracy: 0.7775\n",
      "Epoch 429/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4399 - accuracy: 0.7795 - val_loss: 0.4869 - val_accuracy: 0.7815\n",
      "Epoch 430/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4525 - accuracy: 0.7770 - val_loss: 0.4875 - val_accuracy: 0.7760\n",
      "Epoch 431/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4501 - accuracy: 0.7744 - val_loss: 0.4676 - val_accuracy: 0.7780\n",
      "Epoch 432/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4372 - accuracy: 0.7773 - val_loss: 0.4834 - val_accuracy: 0.7790\n",
      "Epoch 433/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4473 - accuracy: 0.7710 - val_loss: 0.4765 - val_accuracy: 0.7810\n",
      "Epoch 434/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4391 - accuracy: 0.7791 - val_loss: 0.4755 - val_accuracy: 0.7819\n",
      "Epoch 435/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4377 - accuracy: 0.7742 - val_loss: 0.4880 - val_accuracy: 0.7627\n",
      "Epoch 436/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4419 - accuracy: 0.7754 - val_loss: 0.4656 - val_accuracy: 0.7790\n",
      "Epoch 437/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4391 - accuracy: 0.7757 - val_loss: 0.4872 - val_accuracy: 0.7632\n",
      "Epoch 438/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4466 - accuracy: 0.7717 - val_loss: 0.4802 - val_accuracy: 0.7607\n",
      "Epoch 439/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4420 - accuracy: 0.7750 - val_loss: 0.4649 - val_accuracy: 0.7760\n",
      "Epoch 440/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4398 - accuracy: 0.7744 - val_loss: 0.4945 - val_accuracy: 0.7805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4394 - accuracy: 0.7780 - val_loss: 0.4809 - val_accuracy: 0.7810\n",
      "Epoch 442/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4370 - accuracy: 0.7781 - val_loss: 0.4685 - val_accuracy: 0.7810\n",
      "Epoch 443/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4427 - accuracy: 0.7716 - val_loss: 0.4673 - val_accuracy: 0.7745\n",
      "Epoch 444/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4441 - accuracy: 0.7748 - val_loss: 0.4680 - val_accuracy: 0.7819\n",
      "Epoch 445/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4321 - accuracy: 0.7773 - val_loss: 0.4630 - val_accuracy: 0.7790\n",
      "Epoch 446/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4414 - accuracy: 0.7718 - val_loss: 0.4629 - val_accuracy: 0.7805\n",
      "Epoch 447/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4494 - accuracy: 0.7781 - val_loss: 0.4833 - val_accuracy: 0.7770\n",
      "Epoch 448/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4430 - accuracy: 0.7764 - val_loss: 0.4602 - val_accuracy: 0.7839\n",
      "Epoch 449/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4384 - accuracy: 0.7749 - val_loss: 0.5049 - val_accuracy: 0.7815\n",
      "Epoch 450/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4354 - accuracy: 0.7796 - val_loss: 0.4596 - val_accuracy: 0.7790\n",
      "Epoch 451/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4348 - accuracy: 0.7749 - val_loss: 0.4607 - val_accuracy: 0.7834\n",
      "Epoch 452/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4415 - accuracy: 0.7739 - val_loss: 0.4762 - val_accuracy: 0.7750\n",
      "Epoch 453/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4402 - accuracy: 0.7757 - val_loss: 0.4937 - val_accuracy: 0.7617\n",
      "Epoch 454/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4472 - accuracy: 0.7733 - val_loss: 0.4566 - val_accuracy: 0.7741\n",
      "Epoch 455/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4422 - accuracy: 0.7712 - val_loss: 0.4642 - val_accuracy: 0.7785\n",
      "Epoch 456/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4316 - accuracy: 0.7775 - val_loss: 0.4607 - val_accuracy: 0.7810\n",
      "Epoch 457/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.4380 - accuracy: 0.7737 - val_loss: 0.4958 - val_accuracy: 0.7602\n",
      "Epoch 458/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4334 - accuracy: 0.7779 - val_loss: 0.5317 - val_accuracy: 0.7819\n",
      "Epoch 459/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4434 - accuracy: 0.7716 - val_loss: 0.4621 - val_accuracy: 0.7721\n",
      "Epoch 460/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4306 - accuracy: 0.7844 - val_loss: 0.4581 - val_accuracy: 0.7765\n",
      "Epoch 461/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.4287 - accuracy: 0.7802 - val_loss: 0.4572 - val_accuracy: 0.7780\n",
      "Epoch 462/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.4317 - accuracy: 0.7769 - val_loss: 0.4778 - val_accuracy: 0.7770\n",
      "Epoch 463/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.4310 - accuracy: 0.7770 - val_loss: 0.4820 - val_accuracy: 0.7815\n",
      "Epoch 464/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4388 - accuracy: 0.7757 - val_loss: 0.4591 - val_accuracy: 0.7815\n",
      "Epoch 465/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4306 - accuracy: 0.7828 - val_loss: 0.4557 - val_accuracy: 0.7819\n",
      "Epoch 466/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4315 - accuracy: 0.7805 - val_loss: 0.4759 - val_accuracy: 0.7795\n",
      "Epoch 467/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4281 - accuracy: 0.7838 - val_loss: 0.4748 - val_accuracy: 0.7834\n",
      "Epoch 468/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4315 - accuracy: 0.7810 - val_loss: 0.4581 - val_accuracy: 0.7775\n",
      "Epoch 469/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4343 - accuracy: 0.7723 - val_loss: 0.4592 - val_accuracy: 0.7824\n",
      "Epoch 470/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4379 - accuracy: 0.7750 - val_loss: 0.4780 - val_accuracy: 0.7647\n",
      "Epoch 471/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4401 - accuracy: 0.7743 - val_loss: 0.4616 - val_accuracy: 0.7726\n",
      "Epoch 472/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4271 - accuracy: 0.7712 - val_loss: 0.4649 - val_accuracy: 0.7750\n",
      "Epoch 473/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4359 - accuracy: 0.7779 - val_loss: 0.4783 - val_accuracy: 0.7622\n",
      "Epoch 474/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4405 - accuracy: 0.7741 - val_loss: 0.4635 - val_accuracy: 0.7785\n",
      "Epoch 475/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4309 - accuracy: 0.7800 - val_loss: 0.4614 - val_accuracy: 0.7701\n",
      "Epoch 476/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4315 - accuracy: 0.7745 - val_loss: 0.4631 - val_accuracy: 0.7657\n",
      "Epoch 477/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4394 - accuracy: 0.7774 - val_loss: 0.5811 - val_accuracy: 0.7642\n",
      "Epoch 478/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 0.4671 - accuracy: 0.7753 - val_loss: 0.4562 - val_accuracy: 0.7755\n",
      "Epoch 479/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 0.4253 - accuracy: 0.7774 - val_loss: 0.4800 - val_accuracy: 0.7800\n",
      "Epoch 480/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 0.4297 - accuracy: 0.7811 - val_loss: 0.4492 - val_accuracy: 0.7815\n",
      "Epoch 481/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 0.4231 - accuracy: 0.7764 - val_loss: 0.4589 - val_accuracy: 0.7691\n",
      "Epoch 482/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.4313 - accuracy: 0.7769 - val_loss: 0.4605 - val_accuracy: 0.7829\n",
      "Epoch 483/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4280 - accuracy: 0.7797 - val_loss: 0.4571 - val_accuracy: 0.7765\n",
      "Epoch 484/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4317 - accuracy: 0.7794 - val_loss: 0.4788 - val_accuracy: 0.7810\n",
      "Epoch 485/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4279 - accuracy: 0.7771 - val_loss: 0.4562 - val_accuracy: 0.7736\n",
      "Epoch 486/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.4310 - accuracy: 0.7800 - val_loss: 0.4656 - val_accuracy: 0.7805\n",
      "Epoch 487/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4355 - accuracy: 0.7773 - val_loss: 0.4583 - val_accuracy: 0.7849\n",
      "Epoch 488/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4348 - accuracy: 0.7691 - val_loss: 0.4749 - val_accuracy: 0.7760\n",
      "Epoch 489/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4319 - accuracy: 0.7776 - val_loss: 0.4648 - val_accuracy: 0.7839\n",
      "Epoch 490/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4268 - accuracy: 0.7850 - val_loss: 0.4743 - val_accuracy: 0.7819\n",
      "Epoch 491/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.4343 - accuracy: 0.7816 - val_loss: 0.4838 - val_accuracy: 0.7819\n",
      "Epoch 492/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.4273 - accuracy: 0.7752 - val_loss: 0.4823 - val_accuracy: 0.7632\n",
      "Epoch 493/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.4308 - accuracy: 0.7826 - val_loss: 0.4623 - val_accuracy: 0.7706\n",
      "Epoch 494/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.4273 - accuracy: 0.7837 - val_loss: 0.4495 - val_accuracy: 0.7824\n",
      "Epoch 495/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.4294 - accuracy: 0.7728 - val_loss: 0.4491 - val_accuracy: 0.7810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.4199 - accuracy: 0.7843 - val_loss: 0.4507 - val_accuracy: 0.7834\n",
      "Epoch 497/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.4211 - accuracy: 0.7812 - val_loss: 0.4452 - val_accuracy: 0.7741\n",
      "Epoch 498/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.4292 - accuracy: 0.7773 - val_loss: 0.4747 - val_accuracy: 0.7815\n",
      "Epoch 499/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.4345 - accuracy: 0.7822 - val_loss: 0.4537 - val_accuracy: 0.7829\n",
      "Epoch 500/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.4460 - accuracy: 0.7734 - val_loss: 0.4551 - val_accuracy: 0.7691\n",
      "Epoch 501/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.4257 - accuracy: 0.7794 - val_loss: 0.4493 - val_accuracy: 0.7731\n",
      "Epoch 502/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.4212 - accuracy: 0.7800 - val_loss: 0.4668 - val_accuracy: 0.7667\n",
      "Epoch 503/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4420 - accuracy: 0.7696 - val_loss: 0.4577 - val_accuracy: 0.7824\n",
      "Epoch 504/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.4356 - accuracy: 0.7712 - val_loss: 0.4767 - val_accuracy: 0.7681\n",
      "Epoch 505/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.4277 - accuracy: 0.7724 - val_loss: 0.4558 - val_accuracy: 0.7745\n",
      "Epoch 506/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 0.4192 - accuracy: 0.7818 - val_loss: 0.4521 - val_accuracy: 0.7810\n",
      "Epoch 507/1000\n",
      "8108/8108 [==============================] - 0s 39us/step - loss: 0.4278 - accuracy: 0.7750 - val_loss: 0.4474 - val_accuracy: 0.7760\n",
      "Epoch 508/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 0.4246 - accuracy: 0.7776 - val_loss: 0.4612 - val_accuracy: 0.7676\n",
      "Epoch 509/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4202 - accuracy: 0.7842 - val_loss: 0.4627 - val_accuracy: 0.7819\n",
      "Epoch 510/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4271 - accuracy: 0.7759 - val_loss: 0.4648 - val_accuracy: 0.7681\n",
      "Epoch 511/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.4257 - accuracy: 0.7739 - val_loss: 0.4868 - val_accuracy: 0.7652\n",
      "Epoch 512/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.4380 - accuracy: 0.7731 - val_loss: 0.4445 - val_accuracy: 0.7795\n",
      "Epoch 513/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4242 - accuracy: 0.7776 - val_loss: 0.4625 - val_accuracy: 0.7676\n",
      "Epoch 514/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4323 - accuracy: 0.7721 - val_loss: 0.4544 - val_accuracy: 0.7696\n",
      "Epoch 515/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4250 - accuracy: 0.7776 - val_loss: 0.4459 - val_accuracy: 0.7834\n",
      "Epoch 516/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4196 - accuracy: 0.7834 - val_loss: 0.4541 - val_accuracy: 0.7839\n",
      "Epoch 517/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4205 - accuracy: 0.7813 - val_loss: 0.4638 - val_accuracy: 0.7657\n",
      "Epoch 518/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.4177 - accuracy: 0.7795 - val_loss: 0.4638 - val_accuracy: 0.7671\n",
      "Epoch 519/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4247 - accuracy: 0.7761 - val_loss: 0.4576 - val_accuracy: 0.7800\n",
      "Epoch 520/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4243 - accuracy: 0.7816 - val_loss: 0.5188 - val_accuracy: 0.7667\n",
      "Epoch 521/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.4266 - accuracy: 0.7813 - val_loss: 0.4481 - val_accuracy: 0.7701\n",
      "Epoch 522/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4329 - accuracy: 0.7784 - val_loss: 0.4549 - val_accuracy: 0.7819\n",
      "Epoch 523/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4265 - accuracy: 0.7763 - val_loss: 0.4678 - val_accuracy: 0.7681\n",
      "Epoch 524/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4182 - accuracy: 0.7796 - val_loss: 0.4455 - val_accuracy: 0.7819\n",
      "Epoch 525/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4191 - accuracy: 0.7773 - val_loss: 0.4469 - val_accuracy: 0.7800\n",
      "Epoch 526/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.4183 - accuracy: 0.7771 - val_loss: 0.4414 - val_accuracy: 0.7844\n",
      "Epoch 527/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4214 - accuracy: 0.7829 - val_loss: 0.4473 - val_accuracy: 0.7711\n",
      "Epoch 528/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4220 - accuracy: 0.7781 - val_loss: 0.4570 - val_accuracy: 0.7642\n",
      "Epoch 529/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.4129 - accuracy: 0.7821 - val_loss: 0.4450 - val_accuracy: 0.7800\n",
      "Epoch 530/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.4322 - accuracy: 0.7757 - val_loss: 0.4564 - val_accuracy: 0.7829\n",
      "Epoch 531/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4257 - accuracy: 0.7806 - val_loss: 0.4576 - val_accuracy: 0.7671\n",
      "Epoch 532/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4230 - accuracy: 0.7712 - val_loss: 0.5588 - val_accuracy: 0.7854\n",
      "Epoch 533/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4330 - accuracy: 0.7726 - val_loss: 0.4424 - val_accuracy: 0.7711\n",
      "Epoch 534/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4170 - accuracy: 0.7813 - val_loss: 0.4579 - val_accuracy: 0.7681\n",
      "Epoch 535/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.4260 - accuracy: 0.7728 - val_loss: 0.4626 - val_accuracy: 0.7676\n",
      "Epoch 536/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4197 - accuracy: 0.7796 - val_loss: 0.4404 - val_accuracy: 0.7785\n",
      "Epoch 537/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4149 - accuracy: 0.7845 - val_loss: 0.4476 - val_accuracy: 0.7657\n",
      "Epoch 538/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4133 - accuracy: 0.7821 - val_loss: 0.4481 - val_accuracy: 0.7681\n",
      "Epoch 539/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4227 - accuracy: 0.7787 - val_loss: 0.4402 - val_accuracy: 0.7760\n",
      "Epoch 540/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4146 - accuracy: 0.7791 - val_loss: 0.4479 - val_accuracy: 0.7839\n",
      "Epoch 541/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4150 - accuracy: 0.7827 - val_loss: 0.4391 - val_accuracy: 0.7750\n",
      "Epoch 542/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4216 - accuracy: 0.7779 - val_loss: 0.4408 - val_accuracy: 0.7829\n",
      "Epoch 543/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4254 - accuracy: 0.7776 - val_loss: 0.4555 - val_accuracy: 0.7839\n",
      "Epoch 544/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4168 - accuracy: 0.7805 - val_loss: 0.4474 - val_accuracy: 0.7864\n",
      "Epoch 545/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4212 - accuracy: 0.7805 - val_loss: 0.4738 - val_accuracy: 0.7834\n",
      "Epoch 546/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4225 - accuracy: 0.7827 - val_loss: 0.4490 - val_accuracy: 0.7760\n",
      "Epoch 547/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4147 - accuracy: 0.7766 - val_loss: 0.4393 - val_accuracy: 0.7834\n",
      "Epoch 548/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4141 - accuracy: 0.7810 - val_loss: 0.4404 - val_accuracy: 0.7810\n",
      "Epoch 549/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4194 - accuracy: 0.7815 - val_loss: 0.4449 - val_accuracy: 0.7721\n",
      "Epoch 550/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4100 - accuracy: 0.7808 - val_loss: 0.4439 - val_accuracy: 0.7810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 551/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4166 - accuracy: 0.7759 - val_loss: 0.4652 - val_accuracy: 0.7854\n",
      "Epoch 552/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4217 - accuracy: 0.7803 - val_loss: 0.4775 - val_accuracy: 0.7637\n",
      "Epoch 553/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4199 - accuracy: 0.7790 - val_loss: 0.4489 - val_accuracy: 0.7686\n",
      "Epoch 554/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4227 - accuracy: 0.7741 - val_loss: 0.4601 - val_accuracy: 0.7844\n",
      "Epoch 555/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4145 - accuracy: 0.7801 - val_loss: 0.4479 - val_accuracy: 0.7829\n",
      "Epoch 556/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4119 - accuracy: 0.7780 - val_loss: 0.4409 - val_accuracy: 0.7834\n",
      "Epoch 557/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4118 - accuracy: 0.7749 - val_loss: 0.4678 - val_accuracy: 0.7889\n",
      "Epoch 558/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4190 - accuracy: 0.7794 - val_loss: 0.4464 - val_accuracy: 0.7780\n",
      "Epoch 559/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4186 - accuracy: 0.7859 - val_loss: 0.4514 - val_accuracy: 0.7819\n",
      "Epoch 560/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4132 - accuracy: 0.7779 - val_loss: 0.4412 - val_accuracy: 0.7854\n",
      "Epoch 561/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4187 - accuracy: 0.7738 - val_loss: 0.4378 - val_accuracy: 0.7829\n",
      "Epoch 562/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4181 - accuracy: 0.7786 - val_loss: 0.4576 - val_accuracy: 0.7691\n",
      "Epoch 563/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4199 - accuracy: 0.7773 - val_loss: 0.4357 - val_accuracy: 0.7844\n",
      "Epoch 564/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4203 - accuracy: 0.7795 - val_loss: 0.4410 - val_accuracy: 0.7765\n",
      "Epoch 565/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4108 - accuracy: 0.7773 - val_loss: 0.4462 - val_accuracy: 0.7790\n",
      "Epoch 566/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4185 - accuracy: 0.7818 - val_loss: 0.4390 - val_accuracy: 0.7844\n",
      "Epoch 567/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4073 - accuracy: 0.7843 - val_loss: 0.4345 - val_accuracy: 0.7770\n",
      "Epoch 568/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4108 - accuracy: 0.7835 - val_loss: 0.4495 - val_accuracy: 0.7696\n",
      "Epoch 569/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4159 - accuracy: 0.7795 - val_loss: 0.4396 - val_accuracy: 0.7775\n",
      "Epoch 570/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4203 - accuracy: 0.7791 - val_loss: 0.4398 - val_accuracy: 0.7741\n",
      "Epoch 571/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.4214 - accuracy: 0.7749 - val_loss: 0.4412 - val_accuracy: 0.7829\n",
      "Epoch 572/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4107 - accuracy: 0.7764 - val_loss: 0.4505 - val_accuracy: 0.7800\n",
      "Epoch 573/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4122 - accuracy: 0.7868 - val_loss: 0.4399 - val_accuracy: 0.7819\n",
      "Epoch 574/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4152 - accuracy: 0.7794 - val_loss: 0.4992 - val_accuracy: 0.7681\n",
      "Epoch 575/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4186 - accuracy: 0.7812 - val_loss: 0.4324 - val_accuracy: 0.7750\n",
      "Epoch 576/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4233 - accuracy: 0.7796 - val_loss: 0.4758 - val_accuracy: 0.7647\n",
      "Epoch 577/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4168 - accuracy: 0.7818 - val_loss: 0.4355 - val_accuracy: 0.7770\n",
      "Epoch 578/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4181 - accuracy: 0.7797 - val_loss: 0.4415 - val_accuracy: 0.7696\n",
      "Epoch 579/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4133 - accuracy: 0.7770 - val_loss: 0.4336 - val_accuracy: 0.7829\n",
      "Epoch 580/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4055 - accuracy: 0.7848 - val_loss: 0.4406 - val_accuracy: 0.7691\n",
      "Epoch 581/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.4042 - accuracy: 0.7848 - val_loss: 0.4523 - val_accuracy: 0.7726\n",
      "Epoch 582/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4154 - accuracy: 0.7806 - val_loss: 0.4591 - val_accuracy: 0.7810\n",
      "Epoch 583/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.4099 - accuracy: 0.7831 - val_loss: 0.4500 - val_accuracy: 0.7681\n",
      "Epoch 584/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4088 - accuracy: 0.7782 - val_loss: 0.4409 - val_accuracy: 0.7844\n",
      "Epoch 585/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4192 - accuracy: 0.7755 - val_loss: 0.4316 - val_accuracy: 0.7765\n",
      "Epoch 586/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4064 - accuracy: 0.7863 - val_loss: 0.4360 - val_accuracy: 0.7731\n",
      "Epoch 587/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4118 - accuracy: 0.7843 - val_loss: 0.4439 - val_accuracy: 0.7686\n",
      "Epoch 588/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.4052 - accuracy: 0.7844 - val_loss: 0.4425 - val_accuracy: 0.7824\n",
      "Epoch 589/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4062 - accuracy: 0.7812 - val_loss: 0.4397 - val_accuracy: 0.7716\n",
      "Epoch 590/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4167 - accuracy: 0.7764 - val_loss: 0.4714 - val_accuracy: 0.7854\n",
      "Epoch 591/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.4111 - accuracy: 0.7859 - val_loss: 0.4301 - val_accuracy: 0.7819\n",
      "Epoch 592/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4105 - accuracy: 0.7803 - val_loss: 0.4317 - val_accuracy: 0.7854\n",
      "Epoch 593/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4215 - accuracy: 0.7796 - val_loss: 0.4406 - val_accuracy: 0.7706\n",
      "Epoch 594/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4068 - accuracy: 0.7810 - val_loss: 0.4278 - val_accuracy: 0.7745\n",
      "Epoch 595/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4040 - accuracy: 0.7874 - val_loss: 0.4450 - val_accuracy: 0.7711\n",
      "Epoch 596/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4060 - accuracy: 0.7807 - val_loss: 0.4489 - val_accuracy: 0.7696\n",
      "Epoch 597/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4082 - accuracy: 0.7810 - val_loss: 0.4346 - val_accuracy: 0.7736\n",
      "Epoch 598/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4149 - accuracy: 0.7817 - val_loss: 0.4366 - val_accuracy: 0.7681\n",
      "Epoch 599/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4199 - accuracy: 0.7784 - val_loss: 0.4343 - val_accuracy: 0.7864\n",
      "Epoch 600/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4052 - accuracy: 0.7781 - val_loss: 0.4396 - val_accuracy: 0.7859\n",
      "Epoch 601/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4022 - accuracy: 0.7844 - val_loss: 0.4307 - val_accuracy: 0.7805\n",
      "Epoch 602/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.4041 - accuracy: 0.7837 - val_loss: 0.4595 - val_accuracy: 0.7859\n",
      "Epoch 603/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 0.4203 - accuracy: 0.7761 - val_loss: 0.4306 - val_accuracy: 0.7829\n",
      "Epoch 604/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 0.4105 - accuracy: 0.7779 - val_loss: 0.4324 - val_accuracy: 0.7815\n",
      "Epoch 605/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4096 - accuracy: 0.7764 - val_loss: 0.4347 - val_accuracy: 0.7844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 606/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4014 - accuracy: 0.7855 - val_loss: 0.4529 - val_accuracy: 0.7884\n",
      "Epoch 607/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4067 - accuracy: 0.7824 - val_loss: 0.4314 - val_accuracy: 0.7706\n",
      "Epoch 608/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4035 - accuracy: 0.7863 - val_loss: 0.4270 - val_accuracy: 0.7849\n",
      "Epoch 609/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4116 - accuracy: 0.7819 - val_loss: 0.4711 - val_accuracy: 0.7844\n",
      "Epoch 610/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4152 - accuracy: 0.7790 - val_loss: 0.4616 - val_accuracy: 0.7834\n",
      "Epoch 611/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4072 - accuracy: 0.7798 - val_loss: 0.4658 - val_accuracy: 0.7844\n",
      "Epoch 612/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4103 - accuracy: 0.7818 - val_loss: 0.4290 - val_accuracy: 0.7736\n",
      "Epoch 613/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4065 - accuracy: 0.7781 - val_loss: 0.4316 - val_accuracy: 0.7815\n",
      "Epoch 614/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4063 - accuracy: 0.7849 - val_loss: 0.4394 - val_accuracy: 0.7859\n",
      "Epoch 615/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3994 - accuracy: 0.7872 - val_loss: 0.4293 - val_accuracy: 0.7815\n",
      "Epoch 616/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4031 - accuracy: 0.7805 - val_loss: 0.4365 - val_accuracy: 0.7879\n",
      "Epoch 617/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4013 - accuracy: 0.7822 - val_loss: 0.4300 - val_accuracy: 0.7815\n",
      "Epoch 618/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4042 - accuracy: 0.7822 - val_loss: 0.4291 - val_accuracy: 0.7839\n",
      "Epoch 619/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4054 - accuracy: 0.7875 - val_loss: 0.4263 - val_accuracy: 0.7854\n",
      "Epoch 620/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4081 - accuracy: 0.7800 - val_loss: 0.4345 - val_accuracy: 0.7819\n",
      "Epoch 621/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4013 - accuracy: 0.7815 - val_loss: 0.4275 - val_accuracy: 0.7859\n",
      "Epoch 622/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4033 - accuracy: 0.7838 - val_loss: 0.4359 - val_accuracy: 0.7726\n",
      "Epoch 623/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4024 - accuracy: 0.7817 - val_loss: 0.4393 - val_accuracy: 0.7859\n",
      "Epoch 624/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4018 - accuracy: 0.7832 - val_loss: 0.4296 - val_accuracy: 0.7736\n",
      "Epoch 625/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3975 - accuracy: 0.7818 - val_loss: 0.4354 - val_accuracy: 0.7691\n",
      "Epoch 626/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4011 - accuracy: 0.7800 - val_loss: 0.4527 - val_accuracy: 0.7706\n",
      "Epoch 627/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.4061 - accuracy: 0.7794 - val_loss: 0.4360 - val_accuracy: 0.7770\n",
      "Epoch 628/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4087 - accuracy: 0.7786 - val_loss: 0.4283 - val_accuracy: 0.7805\n",
      "Epoch 629/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4111 - accuracy: 0.7787 - val_loss: 0.4497 - val_accuracy: 0.7716\n",
      "Epoch 630/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4017 - accuracy: 0.7813 - val_loss: 0.4334 - val_accuracy: 0.7716\n",
      "Epoch 631/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.3979 - accuracy: 0.7858 - val_loss: 0.4421 - val_accuracy: 0.7721\n",
      "Epoch 632/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3976 - accuracy: 0.7890 - val_loss: 0.4460 - val_accuracy: 0.7701\n",
      "Epoch 633/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4007 - accuracy: 0.7837 - val_loss: 0.4283 - val_accuracy: 0.7864\n",
      "Epoch 634/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4004 - accuracy: 0.7837 - val_loss: 0.4299 - val_accuracy: 0.7869\n",
      "Epoch 635/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3968 - accuracy: 0.7887 - val_loss: 0.4267 - val_accuracy: 0.7815\n",
      "Epoch 636/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3991 - accuracy: 0.7837 - val_loss: 0.4493 - val_accuracy: 0.7716\n",
      "Epoch 637/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4026 - accuracy: 0.7822 - val_loss: 0.4247 - val_accuracy: 0.7864\n",
      "Epoch 638/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3982 - accuracy: 0.7838 - val_loss: 0.4420 - val_accuracy: 0.7844\n",
      "Epoch 639/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4012 - accuracy: 0.7875 - val_loss: 0.4255 - val_accuracy: 0.7844\n",
      "Epoch 640/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3999 - accuracy: 0.7832 - val_loss: 0.4322 - val_accuracy: 0.7859\n",
      "Epoch 641/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3969 - accuracy: 0.7819 - val_loss: 0.4436 - val_accuracy: 0.7785\n",
      "Epoch 642/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4013 - accuracy: 0.7750 - val_loss: 0.4229 - val_accuracy: 0.7829\n",
      "Epoch 643/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3994 - accuracy: 0.7803 - val_loss: 0.4293 - val_accuracy: 0.7790\n",
      "Epoch 644/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4026 - accuracy: 0.7845 - val_loss: 0.4277 - val_accuracy: 0.7785\n",
      "Epoch 645/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4037 - accuracy: 0.7834 - val_loss: 0.4315 - val_accuracy: 0.7736\n",
      "Epoch 646/1000\n",
      "8108/8108 [==============================] - ETA: 0s - loss: 0.3963 - accuracy: 0.78 - 0s 24us/step - loss: 0.3936 - accuracy: 0.7856 - val_loss: 0.4330 - val_accuracy: 0.7711\n",
      "Epoch 647/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4051 - accuracy: 0.7801 - val_loss: 0.4282 - val_accuracy: 0.7810\n",
      "Epoch 648/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3976 - accuracy: 0.7802 - val_loss: 0.4489 - val_accuracy: 0.7874\n",
      "Epoch 649/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.4122 - accuracy: 0.7859 - val_loss: 0.4362 - val_accuracy: 0.7815\n",
      "Epoch 650/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3925 - accuracy: 0.7907 - val_loss: 0.4577 - val_accuracy: 0.7839\n",
      "Epoch 651/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4006 - accuracy: 0.7858 - val_loss: 0.4237 - val_accuracy: 0.7874\n",
      "Epoch 652/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3970 - accuracy: 0.7869 - val_loss: 0.4318 - val_accuracy: 0.7824\n",
      "Epoch 653/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4015 - accuracy: 0.7821 - val_loss: 0.4223 - val_accuracy: 0.7859\n",
      "Epoch 654/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3963 - accuracy: 0.7831 - val_loss: 0.4378 - val_accuracy: 0.7731\n",
      "Epoch 655/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4143 - accuracy: 0.7736 - val_loss: 0.4226 - val_accuracy: 0.7834\n",
      "Epoch 656/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3979 - accuracy: 0.7853 - val_loss: 0.4182 - val_accuracy: 0.7834\n",
      "Epoch 657/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4028 - accuracy: 0.7839 - val_loss: 0.4199 - val_accuracy: 0.7810\n",
      "Epoch 658/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4038 - accuracy: 0.7870 - val_loss: 0.4409 - val_accuracy: 0.7879\n",
      "Epoch 659/1000\n",
      "8108/8108 [==============================] - ETA: 0s - loss: 0.3935 - accuracy: 0.78 - 0s 25us/step - loss: 0.3939 - accuracy: 0.7879 - val_loss: 0.4242 - val_accuracy: 0.7854\n",
      "Epoch 660/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4014 - accuracy: 0.7855 - val_loss: 0.4174 - val_accuracy: 0.7839\n",
      "Epoch 661/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3957 - accuracy: 0.7835 - val_loss: 0.4292 - val_accuracy: 0.7869\n",
      "Epoch 662/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4044 - accuracy: 0.7833 - val_loss: 0.4522 - val_accuracy: 0.7711\n",
      "Epoch 663/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3970 - accuracy: 0.7826 - val_loss: 0.4432 - val_accuracy: 0.7884\n",
      "Epoch 664/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3982 - accuracy: 0.7861 - val_loss: 0.4262 - val_accuracy: 0.7741\n",
      "Epoch 665/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3979 - accuracy: 0.7811 - val_loss: 0.4230 - val_accuracy: 0.7810\n",
      "Epoch 666/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3945 - accuracy: 0.7840 - val_loss: 0.4350 - val_accuracy: 0.7736\n",
      "Epoch 667/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3954 - accuracy: 0.7845 - val_loss: 0.4217 - val_accuracy: 0.7795\n",
      "Epoch 668/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3962 - accuracy: 0.7855 - val_loss: 0.4460 - val_accuracy: 0.7849\n",
      "Epoch 669/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3950 - accuracy: 0.7840 - val_loss: 0.4389 - val_accuracy: 0.7884\n",
      "Epoch 670/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3934 - accuracy: 0.7838 - val_loss: 0.4356 - val_accuracy: 0.7824\n",
      "Epoch 671/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3921 - accuracy: 0.7858 - val_loss: 0.4225 - val_accuracy: 0.7849\n",
      "Epoch 672/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3968 - accuracy: 0.7806 - val_loss: 0.4613 - val_accuracy: 0.7681\n",
      "Epoch 673/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3963 - accuracy: 0.7833 - val_loss: 0.4328 - val_accuracy: 0.7726\n",
      "Epoch 674/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4020 - accuracy: 0.7833 - val_loss: 0.4429 - val_accuracy: 0.7869\n",
      "Epoch 675/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3965 - accuracy: 0.7848 - val_loss: 0.4304 - val_accuracy: 0.7859\n",
      "Epoch 676/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.4001 - accuracy: 0.7789 - val_loss: 0.4267 - val_accuracy: 0.7854\n",
      "Epoch 677/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3995 - accuracy: 0.7855 - val_loss: 0.4297 - val_accuracy: 0.7834\n",
      "Epoch 678/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4001 - accuracy: 0.7861 - val_loss: 0.4479 - val_accuracy: 0.7824\n",
      "Epoch 679/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3924 - accuracy: 0.7840 - val_loss: 0.4159 - val_accuracy: 0.7849\n",
      "Epoch 680/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3869 - accuracy: 0.7900 - val_loss: 0.4291 - val_accuracy: 0.7884\n",
      "Epoch 681/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.4008 - accuracy: 0.7824 - val_loss: 0.4283 - val_accuracy: 0.7844\n",
      "Epoch 682/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3977 - accuracy: 0.7824 - val_loss: 0.4492 - val_accuracy: 0.7731\n",
      "Epoch 683/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3965 - accuracy: 0.7875 - val_loss: 0.4387 - val_accuracy: 0.7864\n",
      "Epoch 684/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3906 - accuracy: 0.7887 - val_loss: 0.4295 - val_accuracy: 0.7869\n",
      "Epoch 685/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3891 - accuracy: 0.7913 - val_loss: 0.4345 - val_accuracy: 0.7884\n",
      "Epoch 686/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3921 - accuracy: 0.7847 - val_loss: 0.4374 - val_accuracy: 0.7879\n",
      "Epoch 687/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3894 - accuracy: 0.7834 - val_loss: 0.4246 - val_accuracy: 0.7750\n",
      "Epoch 688/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3896 - accuracy: 0.7887 - val_loss: 0.4284 - val_accuracy: 0.7716\n",
      "Epoch 689/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3893 - accuracy: 0.7877 - val_loss: 0.4267 - val_accuracy: 0.7775\n",
      "Epoch 690/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3968 - accuracy: 0.7815 - val_loss: 0.4493 - val_accuracy: 0.7893\n",
      "Epoch 691/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3976 - accuracy: 0.7826 - val_loss: 0.4198 - val_accuracy: 0.7884\n",
      "Epoch 692/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3955 - accuracy: 0.7870 - val_loss: 0.4221 - val_accuracy: 0.7869\n",
      "Epoch 693/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3842 - accuracy: 0.7932 - val_loss: 0.4299 - val_accuracy: 0.7790\n",
      "Epoch 694/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.3976 - accuracy: 0.7801 - val_loss: 0.4190 - val_accuracy: 0.7770\n",
      "Epoch 695/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3949 - accuracy: 0.7885 - val_loss: 0.4829 - val_accuracy: 0.7874\n",
      "Epoch 696/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.4113 - accuracy: 0.7807 - val_loss: 0.4338 - val_accuracy: 0.7731\n",
      "Epoch 697/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3953 - accuracy: 0.7776 - val_loss: 0.4224 - val_accuracy: 0.7790\n",
      "Epoch 698/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3919 - accuracy: 0.7898 - val_loss: 0.4222 - val_accuracy: 0.7889\n",
      "Epoch 699/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4104 - accuracy: 0.7815 - val_loss: 0.4595 - val_accuracy: 0.7706\n",
      "Epoch 700/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3969 - accuracy: 0.7806 - val_loss: 0.4156 - val_accuracy: 0.7879\n",
      "Epoch 701/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3891 - accuracy: 0.7844 - val_loss: 0.4289 - val_accuracy: 0.7810\n",
      "Epoch 702/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 0.3950 - accuracy: 0.7833 - val_loss: 0.4192 - val_accuracy: 0.7864\n",
      "Epoch 703/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 0.3875 - accuracy: 0.7876 - val_loss: 0.4355 - val_accuracy: 0.7854\n",
      "Epoch 704/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3930 - accuracy: 0.7852 - val_loss: 0.4238 - val_accuracy: 0.7844\n",
      "Epoch 705/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3921 - accuracy: 0.7879 - val_loss: 0.4206 - val_accuracy: 0.7770\n",
      "Epoch 706/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3868 - accuracy: 0.7835 - val_loss: 0.4760 - val_accuracy: 0.7869\n",
      "Epoch 707/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3984 - accuracy: 0.7828 - val_loss: 0.4168 - val_accuracy: 0.7829\n",
      "Epoch 708/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3853 - accuracy: 0.7919 - val_loss: 0.4149 - val_accuracy: 0.7879\n",
      "Epoch 709/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4006 - accuracy: 0.7792 - val_loss: 0.4344 - val_accuracy: 0.7755\n",
      "Epoch 710/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.4041 - accuracy: 0.7831 - val_loss: 0.4215 - val_accuracy: 0.7790\n",
      "Epoch 711/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3933 - accuracy: 0.7853 - val_loss: 0.4345 - val_accuracy: 0.7859\n",
      "Epoch 712/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3934 - accuracy: 0.7863 - val_loss: 0.4173 - val_accuracy: 0.7879\n",
      "Epoch 713/1000\n",
      "8108/8108 [==============================] - ETA: 0s - loss: 0.3877 - accuracy: 0.78 - 0s 25us/step - loss: 0.3881 - accuracy: 0.7853 - val_loss: 0.4137 - val_accuracy: 0.7790\n",
      "Epoch 714/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3863 - accuracy: 0.7860 - val_loss: 0.4135 - val_accuracy: 0.7829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 715/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3907 - accuracy: 0.7868 - val_loss: 0.4504 - val_accuracy: 0.7839\n",
      "Epoch 716/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3905 - accuracy: 0.7869 - val_loss: 0.4252 - val_accuracy: 0.7844\n",
      "Epoch 717/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3903 - accuracy: 0.7849 - val_loss: 0.4326 - val_accuracy: 0.7884\n",
      "Epoch 718/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3907 - accuracy: 0.7881 - val_loss: 0.4341 - val_accuracy: 0.7795\n",
      "Epoch 719/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3996 - accuracy: 0.7859 - val_loss: 0.4143 - val_accuracy: 0.7874\n",
      "Epoch 720/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3888 - accuracy: 0.7864 - val_loss: 0.4199 - val_accuracy: 0.7805\n",
      "Epoch 721/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3867 - accuracy: 0.7844 - val_loss: 0.4189 - val_accuracy: 0.7844\n",
      "Epoch 722/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.3921 - accuracy: 0.7831 - val_loss: 0.4371 - val_accuracy: 0.7903\n",
      "Epoch 723/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3994 - accuracy: 0.7771 - val_loss: 0.4249 - val_accuracy: 0.7864\n",
      "Epoch 724/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.3879 - accuracy: 0.7806 - val_loss: 0.4215 - val_accuracy: 0.7800\n",
      "Epoch 725/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3862 - accuracy: 0.7847 - val_loss: 0.4187 - val_accuracy: 0.7824\n",
      "Epoch 726/1000\n",
      "8108/8108 [==============================] - ETA: 0s - loss: 0.3914 - accuracy: 0.78 - 0s 25us/step - loss: 0.3936 - accuracy: 0.7860 - val_loss: 0.4115 - val_accuracy: 0.7810\n",
      "Epoch 727/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3822 - accuracy: 0.7882 - val_loss: 0.4181 - val_accuracy: 0.7893\n",
      "Epoch 728/1000\n",
      "8108/8108 [==============================] - 0s 24us/step - loss: 0.3846 - accuracy: 0.7875 - val_loss: 0.4142 - val_accuracy: 0.7869\n",
      "Epoch 729/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3848 - accuracy: 0.7932 - val_loss: 0.4239 - val_accuracy: 0.7819\n",
      "Epoch 730/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3878 - accuracy: 0.7870 - val_loss: 0.4502 - val_accuracy: 0.7736\n",
      "Epoch 731/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3879 - accuracy: 0.7879 - val_loss: 0.4173 - val_accuracy: 0.7854\n",
      "Epoch 732/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3835 - accuracy: 0.7826 - val_loss: 0.4120 - val_accuracy: 0.7869\n",
      "Epoch 733/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3995 - accuracy: 0.7827 - val_loss: 0.4187 - val_accuracy: 0.7864\n",
      "Epoch 734/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3866 - accuracy: 0.7924 - val_loss: 0.4513 - val_accuracy: 0.7686\n",
      "Epoch 735/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3834 - accuracy: 0.7881 - val_loss: 0.4174 - val_accuracy: 0.7741\n",
      "Epoch 736/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 0.3824 - accuracy: 0.7937 - val_loss: 0.4388 - val_accuracy: 0.7701\n",
      "Epoch 737/1000\n",
      "8108/8108 [==============================] - 0s 38us/step - loss: 0.3871 - accuracy: 0.7838 - val_loss: 0.4178 - val_accuracy: 0.7834\n",
      "Epoch 738/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 0.3862 - accuracy: 0.7850 - val_loss: 0.4299 - val_accuracy: 0.7864\n",
      "Epoch 739/1000\n",
      "8108/8108 [==============================] - 0s 36us/step - loss: 0.3833 - accuracy: 0.7914 - val_loss: 0.4113 - val_accuracy: 0.7859\n",
      "Epoch 740/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 0.3853 - accuracy: 0.7860 - val_loss: 0.4442 - val_accuracy: 0.7884\n",
      "Epoch 741/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 0.3845 - accuracy: 0.7924 - val_loss: 0.4350 - val_accuracy: 0.7716\n",
      "Epoch 742/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 0.3859 - accuracy: 0.7876 - val_loss: 0.4294 - val_accuracy: 0.7716\n",
      "Epoch 743/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 0.3837 - accuracy: 0.7901 - val_loss: 0.4234 - val_accuracy: 0.7884\n",
      "Epoch 744/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3891 - accuracy: 0.7863 - val_loss: 0.4291 - val_accuracy: 0.7874\n",
      "Epoch 745/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3849 - accuracy: 0.7885 - val_loss: 0.4157 - val_accuracy: 0.7815\n",
      "Epoch 746/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 0.3802 - accuracy: 0.7872 - val_loss: 0.4377 - val_accuracy: 0.7889\n",
      "Epoch 747/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 0.3845 - accuracy: 0.7892 - val_loss: 0.4106 - val_accuracy: 0.7824\n",
      "Epoch 748/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3909 - accuracy: 0.7879 - val_loss: 0.4184 - val_accuracy: 0.7874\n",
      "Epoch 749/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3826 - accuracy: 0.7901 - val_loss: 0.4427 - val_accuracy: 0.7711\n",
      "Epoch 750/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3839 - accuracy: 0.7875 - val_loss: 0.4164 - val_accuracy: 0.7913\n",
      "Epoch 751/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.4035 - accuracy: 0.7871 - val_loss: 0.4086 - val_accuracy: 0.7874\n",
      "Epoch 752/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3830 - accuracy: 0.7863 - val_loss: 0.4166 - val_accuracy: 0.7884\n",
      "Epoch 753/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3848 - accuracy: 0.7856 - val_loss: 0.4148 - val_accuracy: 0.7893\n",
      "Epoch 754/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3802 - accuracy: 0.7918 - val_loss: 0.4214 - val_accuracy: 0.7750\n",
      "Epoch 755/1000\n",
      "8108/8108 [==============================] - 0s 41us/step - loss: 0.3872 - accuracy: 0.7849 - val_loss: 0.4143 - val_accuracy: 0.7810\n",
      "Epoch 756/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3814 - accuracy: 0.7874 - val_loss: 0.4197 - val_accuracy: 0.7874\n",
      "Epoch 757/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3849 - accuracy: 0.7929 - val_loss: 0.4519 - val_accuracy: 0.7839\n",
      "Epoch 758/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3869 - accuracy: 0.7879 - val_loss: 0.4157 - val_accuracy: 0.7903\n",
      "Epoch 759/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 0.3821 - accuracy: 0.7926 - val_loss: 0.4202 - val_accuracy: 0.7741\n",
      "Epoch 760/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 0.3793 - accuracy: 0.7901 - val_loss: 0.4075 - val_accuracy: 0.7819\n",
      "Epoch 761/1000\n",
      "8108/8108 [==============================] - 0s 38us/step - loss: 0.3815 - accuracy: 0.7933 - val_loss: 0.4248 - val_accuracy: 0.7869\n",
      "Epoch 762/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3856 - accuracy: 0.7863 - val_loss: 0.4314 - val_accuracy: 0.7790\n",
      "Epoch 763/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 0.4001 - accuracy: 0.7786 - val_loss: 0.4108 - val_accuracy: 0.7800\n",
      "Epoch 764/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3835 - accuracy: 0.7834 - val_loss: 0.4132 - val_accuracy: 0.7874\n",
      "Epoch 765/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3815 - accuracy: 0.7914 - val_loss: 0.4121 - val_accuracy: 0.7884\n",
      "Epoch 766/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3820 - accuracy: 0.7869 - val_loss: 0.4505 - val_accuracy: 0.7889\n",
      "Epoch 767/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3916 - accuracy: 0.7823 - val_loss: 0.4106 - val_accuracy: 0.7884\n",
      "Epoch 768/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3810 - accuracy: 0.7901 - val_loss: 0.4292 - val_accuracy: 0.7893\n",
      "Epoch 769/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3801 - accuracy: 0.7917 - val_loss: 0.4112 - val_accuracy: 0.7898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 770/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3813 - accuracy: 0.7905 - val_loss: 0.4166 - val_accuracy: 0.7839\n",
      "Epoch 771/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3826 - accuracy: 0.7865 - val_loss: 0.4235 - val_accuracy: 0.7726\n",
      "Epoch 772/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3839 - accuracy: 0.7812 - val_loss: 0.4122 - val_accuracy: 0.7829\n",
      "Epoch 773/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3805 - accuracy: 0.7903 - val_loss: 0.4143 - val_accuracy: 0.7795\n",
      "Epoch 774/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3864 - accuracy: 0.7832 - val_loss: 0.4146 - val_accuracy: 0.7903\n",
      "Epoch 775/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3838 - accuracy: 0.7877 - val_loss: 0.4087 - val_accuracy: 0.7854\n",
      "Epoch 776/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3857 - accuracy: 0.7875 - val_loss: 0.4286 - val_accuracy: 0.7859\n",
      "Epoch 777/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3817 - accuracy: 0.7870 - val_loss: 0.4100 - val_accuracy: 0.7884\n",
      "Epoch 778/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3923 - accuracy: 0.7796 - val_loss: 0.4358 - val_accuracy: 0.7745\n",
      "Epoch 779/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3929 - accuracy: 0.7858 - val_loss: 0.4356 - val_accuracy: 0.7923\n",
      "Epoch 780/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3920 - accuracy: 0.7880 - val_loss: 0.4173 - val_accuracy: 0.7790\n",
      "Epoch 781/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 0.3895 - accuracy: 0.7897 - val_loss: 0.4205 - val_accuracy: 0.7750\n",
      "Epoch 782/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3831 - accuracy: 0.7930 - val_loss: 0.4164 - val_accuracy: 0.7859\n",
      "Epoch 783/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3820 - accuracy: 0.7861 - val_loss: 0.4082 - val_accuracy: 0.7874\n",
      "Epoch 784/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3778 - accuracy: 0.7880 - val_loss: 0.4211 - val_accuracy: 0.7731\n",
      "Epoch 785/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3873 - accuracy: 0.7821 - val_loss: 0.4438 - val_accuracy: 0.7706\n",
      "Epoch 786/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3826 - accuracy: 0.7855 - val_loss: 0.4281 - val_accuracy: 0.7741\n",
      "Epoch 787/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 0.3882 - accuracy: 0.7858 - val_loss: 0.4072 - val_accuracy: 0.7879\n",
      "Epoch 788/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3795 - accuracy: 0.7895 - val_loss: 0.4169 - val_accuracy: 0.7775\n",
      "Epoch 789/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3785 - accuracy: 0.7916 - val_loss: 0.4079 - val_accuracy: 0.7810\n",
      "Epoch 790/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3810 - accuracy: 0.7909 - val_loss: 0.4179 - val_accuracy: 0.7903\n",
      "Epoch 791/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3774 - accuracy: 0.7895 - val_loss: 0.4115 - val_accuracy: 0.7898\n",
      "Epoch 792/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3833 - accuracy: 0.7872 - val_loss: 0.4153 - val_accuracy: 0.7805\n",
      "Epoch 793/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3859 - accuracy: 0.7863 - val_loss: 0.4190 - val_accuracy: 0.7815\n",
      "Epoch 794/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3792 - accuracy: 0.7837 - val_loss: 0.4110 - val_accuracy: 0.7879\n",
      "Epoch 795/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3784 - accuracy: 0.7900 - val_loss: 0.4163 - val_accuracy: 0.7815\n",
      "Epoch 796/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3819 - accuracy: 0.7844 - val_loss: 0.4405 - val_accuracy: 0.7854\n",
      "Epoch 797/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3957 - accuracy: 0.7838 - val_loss: 0.4099 - val_accuracy: 0.7884\n",
      "Epoch 798/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 0.3741 - accuracy: 0.7933 - val_loss: 0.4148 - val_accuracy: 0.7889\n",
      "Epoch 799/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3751 - accuracy: 0.7908 - val_loss: 0.4147 - val_accuracy: 0.7770\n",
      "Epoch 800/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3833 - accuracy: 0.7909 - val_loss: 0.4090 - val_accuracy: 0.7884\n",
      "Epoch 801/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3792 - accuracy: 0.7895 - val_loss: 0.4212 - val_accuracy: 0.7844\n",
      "Epoch 802/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 0.3791 - accuracy: 0.7880 - val_loss: 0.4548 - val_accuracy: 0.7874\n",
      "Epoch 803/1000\n",
      "8108/8108 [==============================] - 0s 37us/step - loss: 0.3930 - accuracy: 0.7839 - val_loss: 0.4297 - val_accuracy: 0.7745\n",
      "Epoch 804/1000\n",
      "8108/8108 [==============================] - 0s 42us/step - loss: 0.3811 - accuracy: 0.7822 - val_loss: 0.4087 - val_accuracy: 0.7869\n",
      "Epoch 805/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3751 - accuracy: 0.7865 - val_loss: 0.4555 - val_accuracy: 0.7893\n",
      "Epoch 806/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3858 - accuracy: 0.7876 - val_loss: 0.4097 - val_accuracy: 0.7795\n",
      "Epoch 807/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 0.3795 - accuracy: 0.7860 - val_loss: 0.4187 - val_accuracy: 0.7755\n",
      "Epoch 808/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 0.3799 - accuracy: 0.7898 - val_loss: 0.4207 - val_accuracy: 0.7741\n",
      "Epoch 809/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3834 - accuracy: 0.7816 - val_loss: 0.4107 - val_accuracy: 0.7854\n",
      "Epoch 810/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3749 - accuracy: 0.7869 - val_loss: 0.4074 - val_accuracy: 0.7874\n",
      "Epoch 811/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3844 - accuracy: 0.7835 - val_loss: 0.4236 - val_accuracy: 0.7829\n",
      "Epoch 812/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3836 - accuracy: 0.7853 - val_loss: 0.4255 - val_accuracy: 0.7745\n",
      "Epoch 813/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3840 - accuracy: 0.7859 - val_loss: 0.4148 - val_accuracy: 0.7864\n",
      "Epoch 814/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3739 - accuracy: 0.7911 - val_loss: 0.4182 - val_accuracy: 0.7864\n",
      "Epoch 815/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 0.3746 - accuracy: 0.7912 - val_loss: 0.4022 - val_accuracy: 0.7884\n",
      "Epoch 816/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 0.3870 - accuracy: 0.7876 - val_loss: 0.4090 - val_accuracy: 0.7879\n",
      "Epoch 817/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 0.3787 - accuracy: 0.7927 - val_loss: 0.4036 - val_accuracy: 0.7854\n",
      "Epoch 818/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3757 - accuracy: 0.7870 - val_loss: 0.4084 - val_accuracy: 0.7864\n",
      "Epoch 819/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3842 - accuracy: 0.7861 - val_loss: 0.4072 - val_accuracy: 0.7839\n",
      "Epoch 820/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3753 - accuracy: 0.7917 - val_loss: 0.4090 - val_accuracy: 0.7795\n",
      "Epoch 821/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3743 - accuracy: 0.7900 - val_loss: 0.5488 - val_accuracy: 0.7884\n",
      "Epoch 822/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3863 - accuracy: 0.7887 - val_loss: 0.4168 - val_accuracy: 0.7775\n",
      "Epoch 823/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3840 - accuracy: 0.7855 - val_loss: 0.4151 - val_accuracy: 0.7869\n",
      "Epoch 824/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 0.3777 - accuracy: 0.7879 - val_loss: 0.4079 - val_accuracy: 0.7859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 825/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3711 - accuracy: 0.7946 - val_loss: 0.4078 - val_accuracy: 0.7834\n",
      "Epoch 826/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3791 - accuracy: 0.7824 - val_loss: 0.4285 - val_accuracy: 0.7829\n",
      "Epoch 827/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3800 - accuracy: 0.7917 - val_loss: 0.4221 - val_accuracy: 0.7760\n",
      "Epoch 828/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 0.3861 - accuracy: 0.7856 - val_loss: 0.4076 - val_accuracy: 0.7849\n",
      "Epoch 829/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3709 - accuracy: 0.7955 - val_loss: 0.4076 - val_accuracy: 0.7810\n",
      "Epoch 830/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3946 - accuracy: 0.7827 - val_loss: 0.4083 - val_accuracy: 0.7810\n",
      "Epoch 831/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3788 - accuracy: 0.7847 - val_loss: 0.4112 - val_accuracy: 0.7810\n",
      "Epoch 832/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3763 - accuracy: 0.7912 - val_loss: 0.4302 - val_accuracy: 0.7755\n",
      "Epoch 833/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3873 - accuracy: 0.7937 - val_loss: 0.4063 - val_accuracy: 0.7844\n",
      "Epoch 834/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3755 - accuracy: 0.7889 - val_loss: 0.4143 - val_accuracy: 0.7874\n",
      "Epoch 835/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3725 - accuracy: 0.7901 - val_loss: 0.4126 - val_accuracy: 0.7908\n",
      "Epoch 836/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3747 - accuracy: 0.7872 - val_loss: 0.4135 - val_accuracy: 0.7884\n",
      "Epoch 837/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3797 - accuracy: 0.7877 - val_loss: 0.4178 - val_accuracy: 0.7805\n",
      "Epoch 838/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3769 - accuracy: 0.7877 - val_loss: 0.4194 - val_accuracy: 0.7736\n",
      "Epoch 839/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3816 - accuracy: 0.7881 - val_loss: 0.4089 - val_accuracy: 0.7859\n",
      "Epoch 840/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3805 - accuracy: 0.7852 - val_loss: 0.4366 - val_accuracy: 0.7923\n",
      "Epoch 841/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3763 - accuracy: 0.7935 - val_loss: 0.4321 - val_accuracy: 0.7923\n",
      "Epoch 842/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3859 - accuracy: 0.7874 - val_loss: 0.4239 - val_accuracy: 0.7923\n",
      "Epoch 843/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3836 - accuracy: 0.7864 - val_loss: 0.4097 - val_accuracy: 0.7824\n",
      "Epoch 844/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3791 - accuracy: 0.7834 - val_loss: 0.4244 - val_accuracy: 0.7844\n",
      "Epoch 845/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3783 - accuracy: 0.7847 - val_loss: 0.4098 - val_accuracy: 0.7859\n",
      "Epoch 846/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3786 - accuracy: 0.7945 - val_loss: 0.4154 - val_accuracy: 0.7844\n",
      "Epoch 847/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3733 - accuracy: 0.7887 - val_loss: 0.4177 - val_accuracy: 0.7884\n",
      "Epoch 848/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3734 - accuracy: 0.7903 - val_loss: 0.4114 - val_accuracy: 0.7829\n",
      "Epoch 849/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3702 - accuracy: 0.7927 - val_loss: 0.4068 - val_accuracy: 0.7834\n",
      "Epoch 850/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3770 - accuracy: 0.7889 - val_loss: 0.4111 - val_accuracy: 0.7765\n",
      "Epoch 851/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3723 - accuracy: 0.7905 - val_loss: 0.4054 - val_accuracy: 0.7834\n",
      "Epoch 852/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3722 - accuracy: 0.7907 - val_loss: 0.4102 - val_accuracy: 0.7815\n",
      "Epoch 853/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 0.3643 - accuracy: 0.7977 - val_loss: 0.4077 - val_accuracy: 0.7903\n",
      "Epoch 854/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3719 - accuracy: 0.7908 - val_loss: 0.4496 - val_accuracy: 0.7908\n",
      "Epoch 855/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3851 - accuracy: 0.7906 - val_loss: 0.4079 - val_accuracy: 0.7849\n",
      "Epoch 856/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3747 - accuracy: 0.7869 - val_loss: 0.4040 - val_accuracy: 0.7864\n",
      "Epoch 857/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 0.3734 - accuracy: 0.7892 - val_loss: 0.4041 - val_accuracy: 0.7800\n",
      "Epoch 858/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 0.3797 - accuracy: 0.7840 - val_loss: 0.4056 - val_accuracy: 0.7879\n",
      "Epoch 859/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 0.3702 - accuracy: 0.7916 - val_loss: 0.4090 - val_accuracy: 0.7859\n",
      "Epoch 860/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3771 - accuracy: 0.7948 - val_loss: 0.4116 - val_accuracy: 0.7908\n",
      "Epoch 861/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3760 - accuracy: 0.7842 - val_loss: 0.4027 - val_accuracy: 0.7869\n",
      "Epoch 862/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3725 - accuracy: 0.7880 - val_loss: 0.4067 - val_accuracy: 0.7805\n",
      "Epoch 863/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3734 - accuracy: 0.7934 - val_loss: 0.4161 - val_accuracy: 0.7879\n",
      "Epoch 864/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3760 - accuracy: 0.7881 - val_loss: 0.4126 - val_accuracy: 0.7884\n",
      "Epoch 865/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 0.3849 - accuracy: 0.7876 - val_loss: 0.4465 - val_accuracy: 0.7696\n",
      "Epoch 866/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3784 - accuracy: 0.7942 - val_loss: 0.4084 - val_accuracy: 0.7898\n",
      "Epoch 867/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3716 - accuracy: 0.7893 - val_loss: 0.4435 - val_accuracy: 0.7918\n",
      "Epoch 868/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3740 - accuracy: 0.7872 - val_loss: 0.4072 - val_accuracy: 0.7893\n",
      "Epoch 869/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3675 - accuracy: 0.7924 - val_loss: 0.4055 - val_accuracy: 0.7874\n",
      "Epoch 870/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3742 - accuracy: 0.7892 - val_loss: 0.4099 - val_accuracy: 0.7893\n",
      "Epoch 871/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 0.3767 - accuracy: 0.7839 - val_loss: 0.4494 - val_accuracy: 0.7731\n",
      "Epoch 872/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3677 - accuracy: 0.7924 - val_loss: 0.4057 - val_accuracy: 0.7859\n",
      "Epoch 873/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3723 - accuracy: 0.7923 - val_loss: 0.4139 - val_accuracy: 0.7859\n",
      "Epoch 874/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3754 - accuracy: 0.7891 - val_loss: 0.4456 - val_accuracy: 0.7928\n",
      "Epoch 875/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 0.3882 - accuracy: 0.7866 - val_loss: 0.4092 - val_accuracy: 0.7760\n",
      "Epoch 876/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 0.3717 - accuracy: 0.7900 - val_loss: 0.4035 - val_accuracy: 0.7903\n",
      "Epoch 877/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 0.3672 - accuracy: 0.7948 - val_loss: 0.4885 - val_accuracy: 0.7721\n",
      "Epoch 878/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3767 - accuracy: 0.7938 - val_loss: 0.4358 - val_accuracy: 0.7736\n",
      "Epoch 879/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3717 - accuracy: 0.7863 - val_loss: 0.4117 - val_accuracy: 0.7844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 880/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3681 - accuracy: 0.7939 - val_loss: 0.4070 - val_accuracy: 0.7854\n",
      "Epoch 881/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3676 - accuracy: 0.7845 - val_loss: 0.4012 - val_accuracy: 0.7884\n",
      "Epoch 882/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3759 - accuracy: 0.7896 - val_loss: 0.4033 - val_accuracy: 0.7874\n",
      "Epoch 883/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3683 - accuracy: 0.7956 - val_loss: 0.4001 - val_accuracy: 0.7898\n",
      "Epoch 884/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3670 - accuracy: 0.7882 - val_loss: 0.4057 - val_accuracy: 0.7893\n",
      "Epoch 885/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3741 - accuracy: 0.7901 - val_loss: 0.4480 - val_accuracy: 0.7889\n",
      "Epoch 886/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3773 - accuracy: 0.7898 - val_loss: 0.4145 - val_accuracy: 0.7805\n",
      "Epoch 887/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3697 - accuracy: 0.7917 - val_loss: 0.4257 - val_accuracy: 0.7765\n",
      "Epoch 888/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3784 - accuracy: 0.7877 - val_loss: 0.4001 - val_accuracy: 0.7889\n",
      "Epoch 889/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3700 - accuracy: 0.7871 - val_loss: 0.3990 - val_accuracy: 0.7889\n",
      "Epoch 890/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3689 - accuracy: 0.7896 - val_loss: 0.4023 - val_accuracy: 0.7834\n",
      "Epoch 891/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3618 - accuracy: 0.7946 - val_loss: 0.4105 - val_accuracy: 0.7908\n",
      "Epoch 892/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3692 - accuracy: 0.7898 - val_loss: 0.4174 - val_accuracy: 0.7933\n",
      "Epoch 893/1000\n",
      "8108/8108 [==============================] - 0s 36us/step - loss: 0.3838 - accuracy: 0.7903 - val_loss: 0.4127 - val_accuracy: 0.7810\n",
      "Epoch 894/1000\n",
      "8108/8108 [==============================] - 0s 37us/step - loss: 0.3659 - accuracy: 0.7906 - val_loss: 0.4054 - val_accuracy: 0.7889\n",
      "Epoch 895/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 0.3678 - accuracy: 0.7889 - val_loss: 0.4172 - val_accuracy: 0.7765\n",
      "Epoch 896/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 0.3804 - accuracy: 0.7858 - val_loss: 0.4048 - val_accuracy: 0.7800\n",
      "Epoch 897/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3706 - accuracy: 0.7901 - val_loss: 0.4021 - val_accuracy: 0.7889\n",
      "Epoch 898/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3694 - accuracy: 0.7935 - val_loss: 0.4012 - val_accuracy: 0.7844\n",
      "Epoch 899/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3775 - accuracy: 0.7845 - val_loss: 0.4133 - val_accuracy: 0.7898\n",
      "Epoch 900/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3775 - accuracy: 0.7908 - val_loss: 0.4113 - val_accuracy: 0.7874\n",
      "Epoch 901/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 0.3777 - accuracy: 0.7869 - val_loss: 0.4022 - val_accuracy: 0.7879\n",
      "Epoch 902/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3697 - accuracy: 0.7924 - val_loss: 0.4387 - val_accuracy: 0.7879\n",
      "Epoch 903/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3701 - accuracy: 0.7937 - val_loss: 0.4434 - val_accuracy: 0.7741\n",
      "Epoch 904/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3747 - accuracy: 0.7856 - val_loss: 0.4250 - val_accuracy: 0.7908\n",
      "Epoch 905/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3765 - accuracy: 0.7908 - val_loss: 0.3978 - val_accuracy: 0.7829\n",
      "Epoch 906/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3739 - accuracy: 0.7858 - val_loss: 0.4340 - val_accuracy: 0.7889\n",
      "Epoch 907/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 0.3735 - accuracy: 0.7891 - val_loss: 0.4169 - val_accuracy: 0.7770\n",
      "Epoch 908/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3803 - accuracy: 0.7882 - val_loss: 0.4346 - val_accuracy: 0.7923\n",
      "Epoch 909/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 0.3722 - accuracy: 0.7889 - val_loss: 0.3971 - val_accuracy: 0.7889\n",
      "Epoch 910/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3680 - accuracy: 0.7942 - val_loss: 0.4009 - val_accuracy: 0.7874\n",
      "Epoch 911/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 0.3736 - accuracy: 0.7889 - val_loss: 0.4122 - val_accuracy: 0.7790\n",
      "Epoch 912/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 0.3743 - accuracy: 0.7955 - val_loss: 0.4136 - val_accuracy: 0.7790\n",
      "Epoch 913/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 0.3652 - accuracy: 0.7930 - val_loss: 0.4087 - val_accuracy: 0.7815\n",
      "Epoch 914/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3695 - accuracy: 0.7891 - val_loss: 0.4351 - val_accuracy: 0.7869\n",
      "Epoch 915/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3713 - accuracy: 0.7905 - val_loss: 0.4093 - val_accuracy: 0.7839\n",
      "Epoch 916/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3723 - accuracy: 0.7807 - val_loss: 0.4029 - val_accuracy: 0.7879\n",
      "Epoch 917/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3738 - accuracy: 0.7895 - val_loss: 0.4038 - val_accuracy: 0.7859\n",
      "Epoch 918/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 0.3743 - accuracy: 0.7863 - val_loss: 0.4196 - val_accuracy: 0.7948\n",
      "Epoch 919/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 0.3694 - accuracy: 0.7913 - val_loss: 0.4121 - val_accuracy: 0.7933\n",
      "Epoch 920/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3661 - accuracy: 0.7913 - val_loss: 0.4253 - val_accuracy: 0.7928\n",
      "Epoch 921/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3731 - accuracy: 0.7929 - val_loss: 0.4124 - val_accuracy: 0.7780\n",
      "Epoch 922/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3691 - accuracy: 0.7871 - val_loss: 0.4112 - val_accuracy: 0.7908\n",
      "Epoch 923/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3678 - accuracy: 0.7923 - val_loss: 0.4048 - val_accuracy: 0.7770\n",
      "Epoch 924/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3802 - accuracy: 0.7905 - val_loss: 0.4102 - val_accuracy: 0.7898\n",
      "Epoch 925/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3784 - accuracy: 0.7860 - val_loss: 0.4331 - val_accuracy: 0.7933\n",
      "Epoch 926/1000\n",
      "8108/8108 [==============================] - 0s 25us/step - loss: 0.3727 - accuracy: 0.7927 - val_loss: 0.4002 - val_accuracy: 0.7893\n",
      "Epoch 927/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3664 - accuracy: 0.7907 - val_loss: 0.4061 - val_accuracy: 0.7805\n",
      "Epoch 928/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3669 - accuracy: 0.7893 - val_loss: 0.4048 - val_accuracy: 0.7770\n",
      "Epoch 929/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3651 - accuracy: 0.7950 - val_loss: 0.4108 - val_accuracy: 0.7903\n",
      "Epoch 930/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3708 - accuracy: 0.7913 - val_loss: 0.4108 - val_accuracy: 0.7834\n",
      "Epoch 931/1000\n",
      "8108/8108 [==============================] - 0s 26us/step - loss: 0.3653 - accuracy: 0.7884 - val_loss: 0.3965 - val_accuracy: 0.7849\n",
      "Epoch 932/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3646 - accuracy: 0.7909 - val_loss: 0.4197 - val_accuracy: 0.7854\n",
      "Epoch 933/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3986 - accuracy: 0.7918 - val_loss: 0.4680 - val_accuracy: 0.7745\n",
      "Epoch 934/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3653 - accuracy: 0.7927 - val_loss: 0.4300 - val_accuracy: 0.7923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 935/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3743 - accuracy: 0.7863 - val_loss: 0.4235 - val_accuracy: 0.7716\n",
      "Epoch 936/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 0.3664 - accuracy: 0.7932 - val_loss: 0.4196 - val_accuracy: 0.7908\n",
      "Epoch 937/1000\n",
      "8108/8108 [==============================] - 0s 37us/step - loss: 0.3681 - accuracy: 0.7863 - val_loss: 0.4015 - val_accuracy: 0.7893\n",
      "Epoch 938/1000\n",
      "8108/8108 [==============================] - 0s 39us/step - loss: 0.3631 - accuracy: 0.7961 - val_loss: 0.4006 - val_accuracy: 0.7795\n",
      "Epoch 939/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3635 - accuracy: 0.7937 - val_loss: 0.4206 - val_accuracy: 0.7780\n",
      "Epoch 940/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3771 - accuracy: 0.7919 - val_loss: 0.3971 - val_accuracy: 0.7889\n",
      "Epoch 941/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3674 - accuracy: 0.7927 - val_loss: 0.4064 - val_accuracy: 0.7898\n",
      "Epoch 942/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3641 - accuracy: 0.7903 - val_loss: 0.4180 - val_accuracy: 0.7745\n",
      "Epoch 943/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3657 - accuracy: 0.7889 - val_loss: 0.4100 - val_accuracy: 0.7854\n",
      "Epoch 944/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3634 - accuracy: 0.7912 - val_loss: 0.3966 - val_accuracy: 0.7903\n",
      "Epoch 945/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3663 - accuracy: 0.7930 - val_loss: 0.4308 - val_accuracy: 0.7953\n",
      "Epoch 946/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3776 - accuracy: 0.7907 - val_loss: 0.4073 - val_accuracy: 0.7810\n",
      "Epoch 947/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3615 - accuracy: 0.7928 - val_loss: 0.4581 - val_accuracy: 0.7903\n",
      "Epoch 948/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 0.3728 - accuracy: 0.7950 - val_loss: 0.4005 - val_accuracy: 0.7908\n",
      "Epoch 949/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 0.3662 - accuracy: 0.7892 - val_loss: 0.4000 - val_accuracy: 0.7859\n",
      "Epoch 950/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3655 - accuracy: 0.7918 - val_loss: 0.4102 - val_accuracy: 0.7864\n",
      "Epoch 951/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3644 - accuracy: 0.7879 - val_loss: 0.4106 - val_accuracy: 0.7800\n",
      "Epoch 952/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3641 - accuracy: 0.7937 - val_loss: 0.4028 - val_accuracy: 0.7854\n",
      "Epoch 953/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3679 - accuracy: 0.7882 - val_loss: 0.4241 - val_accuracy: 0.7721\n",
      "Epoch 954/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3616 - accuracy: 0.7942 - val_loss: 0.3938 - val_accuracy: 0.7879\n",
      "Epoch 955/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3600 - accuracy: 0.7927 - val_loss: 0.4747 - val_accuracy: 0.7943\n",
      "Epoch 956/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3709 - accuracy: 0.7900 - val_loss: 0.3955 - val_accuracy: 0.7854\n",
      "Epoch 957/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3604 - accuracy: 0.7960 - val_loss: 0.4006 - val_accuracy: 0.7913\n",
      "Epoch 958/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3617 - accuracy: 0.7955 - val_loss: 0.4045 - val_accuracy: 0.7898\n",
      "Epoch 959/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3663 - accuracy: 0.7896 - val_loss: 0.4141 - val_accuracy: 0.7933\n",
      "Epoch 960/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3656 - accuracy: 0.7942 - val_loss: 0.4134 - val_accuracy: 0.7780\n",
      "Epoch 961/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3709 - accuracy: 0.7893 - val_loss: 0.4031 - val_accuracy: 0.7810\n",
      "Epoch 962/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3610 - accuracy: 0.7986 - val_loss: 0.4005 - val_accuracy: 0.7913\n",
      "Epoch 963/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3611 - accuracy: 0.7975 - val_loss: 0.4049 - val_accuracy: 0.7913\n",
      "Epoch 964/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3720 - accuracy: 0.7918 - val_loss: 0.4051 - val_accuracy: 0.7859\n",
      "Epoch 965/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3645 - accuracy: 0.7924 - val_loss: 0.4266 - val_accuracy: 0.7884\n",
      "Epoch 966/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3664 - accuracy: 0.7950 - val_loss: 0.4037 - val_accuracy: 0.7893\n",
      "Epoch 967/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3763 - accuracy: 0.7845 - val_loss: 0.4150 - val_accuracy: 0.7874\n",
      "Epoch 968/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3717 - accuracy: 0.7953 - val_loss: 0.4069 - val_accuracy: 0.7844\n",
      "Epoch 969/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3728 - accuracy: 0.7870 - val_loss: 0.4146 - val_accuracy: 0.7780\n",
      "Epoch 970/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3691 - accuracy: 0.7848 - val_loss: 0.3963 - val_accuracy: 0.7834\n",
      "Epoch 971/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3697 - accuracy: 0.7879 - val_loss: 0.4000 - val_accuracy: 0.7889\n",
      "Epoch 972/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3621 - accuracy: 0.7932 - val_loss: 0.4088 - val_accuracy: 0.7918\n",
      "Epoch 973/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3586 - accuracy: 0.7956 - val_loss: 0.4187 - val_accuracy: 0.7854\n",
      "Epoch 974/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3645 - accuracy: 0.7900 - val_loss: 0.4235 - val_accuracy: 0.7795\n",
      "Epoch 975/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3630 - accuracy: 0.7896 - val_loss: 0.3988 - val_accuracy: 0.7849\n",
      "Epoch 976/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3632 - accuracy: 0.7959 - val_loss: 0.4023 - val_accuracy: 0.7800\n",
      "Epoch 977/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3684 - accuracy: 0.7864 - val_loss: 0.3945 - val_accuracy: 0.7884\n",
      "Epoch 978/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3729 - accuracy: 0.7945 - val_loss: 0.4354 - val_accuracy: 0.7750\n",
      "Epoch 979/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3671 - accuracy: 0.7959 - val_loss: 0.4159 - val_accuracy: 0.7849\n",
      "Epoch 980/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3634 - accuracy: 0.7938 - val_loss: 0.4332 - val_accuracy: 0.7800\n",
      "Epoch 981/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3631 - accuracy: 0.7923 - val_loss: 0.4005 - val_accuracy: 0.7928\n",
      "Epoch 982/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3571 - accuracy: 0.7951 - val_loss: 0.4027 - val_accuracy: 0.7864\n",
      "Epoch 983/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3659 - accuracy: 0.7927 - val_loss: 0.3944 - val_accuracy: 0.7869\n",
      "Epoch 984/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 0.3618 - accuracy: 0.7974 - val_loss: 0.4119 - val_accuracy: 0.7805\n",
      "Epoch 985/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3622 - accuracy: 0.7970 - val_loss: 0.4471 - val_accuracy: 0.7716\n",
      "Epoch 986/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3592 - accuracy: 0.7886 - val_loss: 0.3959 - val_accuracy: 0.7923\n",
      "Epoch 987/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3634 - accuracy: 0.7872 - val_loss: 0.4038 - val_accuracy: 0.7790\n",
      "Epoch 988/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3596 - accuracy: 0.7919 - val_loss: 0.3977 - val_accuracy: 0.7928\n",
      "Epoch 989/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3625 - accuracy: 0.7896 - val_loss: 0.4059 - val_accuracy: 0.7859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 990/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3629 - accuracy: 0.7935 - val_loss: 0.4290 - val_accuracy: 0.7721\n",
      "Epoch 991/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3643 - accuracy: 0.7907 - val_loss: 0.4014 - val_accuracy: 0.7913\n",
      "Epoch 992/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3595 - accuracy: 0.7950 - val_loss: 0.4156 - val_accuracy: 0.7908\n",
      "Epoch 993/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3595 - accuracy: 0.7955 - val_loss: 0.4014 - val_accuracy: 0.7844\n",
      "Epoch 994/1000\n",
      "8108/8108 [==============================] - 0s 27us/step - loss: 0.3638 - accuracy: 0.7854 - val_loss: 0.4156 - val_accuracy: 0.7953\n",
      "Epoch 995/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3674 - accuracy: 0.7895 - val_loss: 0.4100 - val_accuracy: 0.7834\n",
      "Epoch 996/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3626 - accuracy: 0.7872 - val_loss: 0.4052 - val_accuracy: 0.7933\n",
      "Epoch 997/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3587 - accuracy: 0.7916 - val_loss: 0.3999 - val_accuracy: 0.7923\n",
      "Epoch 998/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3625 - accuracy: 0.7879 - val_loss: 0.3947 - val_accuracy: 0.7849\n",
      "Epoch 999/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 0.3679 - accuracy: 0.7900 - val_loss: 0.4105 - val_accuracy: 0.7928\n",
      "Epoch 1000/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 0.3602 - accuracy: 0.7942 - val_loss: 0.4237 - val_accuracy: 0.7884\n"
     ]
    }
   ],
   "source": [
    "# 学習(大きさ)\n",
    "epochs = 1000\n",
    "batch_size = 128\n",
    "size_history = size_model.fit(size_x_train, size_y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(size_x_test, size_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r9jHxfiOwcPt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2027/2027 [==============================] - 0s 37us/step\n",
      "Test loss: 0.42370019972941886\n",
      "Test accuracy: 0.7883571982383728\n"
     ]
    }
   ],
   "source": [
    "# モデルの評価(大きさ)\n",
    "size_score = size_model.evaluate(size_x_test, size_y_test, verbose=1)\n",
    "print('Test loss:', size_score[0])\n",
    "print('Test accuracy:', size_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jI7PrbsTxHse"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 学習経過の可視化(大きさ)\n",
    "size_loss     = size_history.history['loss']\n",
    "size_val_loss = size_history.history['val_loss']\n",
    "\n",
    "nb_epoch = len(size_loss)\n",
    "plt.plot(range(nb_epoch), size_loss,     marker='.', label='size_loss')\n",
    "plt.plot(range(nb_epoch), size_val_loss, marker='.', label='size_val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rUvUJw2EySUa"
   },
   "outputs": [],
   "source": [
    "## CNN(位置)\n",
    "\n",
    "### modelの作成\n",
    "position_model = Sequential()\n",
    "### 畳み込み層\n",
    "position_model.add(Conv1D(32, 3, padding='same', activation='relu', input_shape=(50, 1)))\n",
    "### プーリング層\n",
    "position_model.add(MaxPooling1D(2, padding='same'))\n",
    "### Flatten層\n",
    "position_model.add(Flatten())\n",
    "### 全結合層\n",
    "position_model.add(Dense(25, activation='softmax'))\n",
    "\n",
    "### optimizer\n",
    "adam = keras.optimizers.Adam()\n",
    "\n",
    "###modelのコンパイル\n",
    "position_model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a_hrL7eEwsbj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8108 samples, validate on 2027 samples\n",
      "Epoch 1/1000\n",
      "8108/8108 [==============================] - 0s 44us/step - loss: 3.1456 - accuracy: 0.0889 - val_loss: 3.1234 - val_accuracy: 0.0740\n",
      "Epoch 2/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 3.0453 - accuracy: 0.1190 - val_loss: 3.0713 - val_accuracy: 0.1095\n",
      "Epoch 3/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.9758 - accuracy: 0.1401 - val_loss: 3.0084 - val_accuracy: 0.1450\n",
      "Epoch 4/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.9203 - accuracy: 0.1481 - val_loss: 2.9411 - val_accuracy: 0.1638\n",
      "Epoch 5/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 2.8680 - accuracy: 0.1738 - val_loss: 2.9134 - val_accuracy: 0.1584\n",
      "Epoch 6/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.8244 - accuracy: 0.1815 - val_loss: 2.8474 - val_accuracy: 0.1968\n",
      "Epoch 7/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.7834 - accuracy: 0.1859 - val_loss: 2.8707 - val_accuracy: 0.1737\n",
      "Epoch 8/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 2.7544 - accuracy: 0.1892 - val_loss: 2.8319 - val_accuracy: 0.1549\n",
      "Epoch 9/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 2.7238 - accuracy: 0.1993 - val_loss: 2.7584 - val_accuracy: 0.1870\n",
      "Epoch 10/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.7061 - accuracy: 0.2003 - val_loss: 2.7530 - val_accuracy: 0.1978\n",
      "Epoch 11/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.6712 - accuracy: 0.2179 - val_loss: 2.7367 - val_accuracy: 0.1727\n",
      "Epoch 12/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 2.6449 - accuracy: 0.2230 - val_loss: 2.7041 - val_accuracy: 0.1801\n",
      "Epoch 13/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 2.6309 - accuracy: 0.2185 - val_loss: 2.6637 - val_accuracy: 0.2240\n",
      "Epoch 14/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.6222 - accuracy: 0.2190 - val_loss: 2.6831 - val_accuracy: 0.2131\n",
      "Epoch 15/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.6008 - accuracy: 0.2272 - val_loss: 2.6624 - val_accuracy: 0.1845\n",
      "Epoch 16/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.5845 - accuracy: 0.2290 - val_loss: 2.6297 - val_accuracy: 0.2151\n",
      "Epoch 17/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.5660 - accuracy: 0.2361 - val_loss: 2.6294 - val_accuracy: 0.2156\n",
      "Epoch 18/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.5463 - accuracy: 0.2452 - val_loss: 2.5890 - val_accuracy: 0.2092\n",
      "Epoch 19/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 2.5202 - accuracy: 0.2526 - val_loss: 2.5792 - val_accuracy: 0.2644\n",
      "Epoch 20/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 2.5202 - accuracy: 0.2558 - val_loss: 2.5628 - val_accuracy: 0.2511\n",
      "Epoch 21/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 2.5002 - accuracy: 0.2622 - val_loss: 2.5818 - val_accuracy: 0.2496\n",
      "Epoch 22/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.4893 - accuracy: 0.2668 - val_loss: 2.5273 - val_accuracy: 0.2733\n",
      "Epoch 23/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.4690 - accuracy: 0.2632 - val_loss: 2.5291 - val_accuracy: 0.2763\n",
      "Epoch 24/1000\n",
      "8108/8108 [==============================] - 0s 43us/step - loss: 2.4535 - accuracy: 0.2747 - val_loss: 2.4826 - val_accuracy: 0.3078\n",
      "Epoch 25/1000\n",
      "8108/8108 [==============================] - 0s 46us/step - loss: 2.4316 - accuracy: 0.2817 - val_loss: 2.5067 - val_accuracy: 0.2324\n",
      "Epoch 26/1000\n",
      "8108/8108 [==============================] - 0s 42us/step - loss: 2.4385 - accuracy: 0.2907 - val_loss: 2.5062 - val_accuracy: 0.2639\n",
      "Epoch 27/1000\n",
      "8108/8108 [==============================] - 0s 38us/step - loss: 2.4319 - accuracy: 0.2929 - val_loss: 2.5359 - val_accuracy: 0.2585\n",
      "Epoch 28/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 2.4216 - accuracy: 0.2757 - val_loss: 2.4781 - val_accuracy: 0.2536\n",
      "Epoch 29/1000\n",
      "8108/8108 [==============================] - 0s 38us/step - loss: 2.3965 - accuracy: 0.2908 - val_loss: 2.4635 - val_accuracy: 0.2605\n",
      "Epoch 30/1000\n",
      "8108/8108 [==============================] - 0s 37us/step - loss: 2.3712 - accuracy: 0.2950 - val_loss: 2.4300 - val_accuracy: 0.2778\n",
      "Epoch 31/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 2.3707 - accuracy: 0.2988 - val_loss: 2.4155 - val_accuracy: 0.2930\n",
      "Epoch 32/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.3526 - accuracy: 0.3049 - val_loss: 2.4242 - val_accuracy: 0.2852\n",
      "Epoch 33/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.3570 - accuracy: 0.2992 - val_loss: 2.3940 - val_accuracy: 0.3029\n",
      "Epoch 34/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 2.3411 - accuracy: 0.2975 - val_loss: 2.4283 - val_accuracy: 0.3103\n",
      "Epoch 35/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 2.3417 - accuracy: 0.3009 - val_loss: 2.3762 - val_accuracy: 0.3024\n",
      "Epoch 36/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 2.3104 - accuracy: 0.3144 - val_loss: 2.3854 - val_accuracy: 0.3133\n",
      "Epoch 37/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 2.3201 - accuracy: 0.3120 - val_loss: 2.3440 - val_accuracy: 0.3429\n",
      "Epoch 38/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.3021 - accuracy: 0.3186 - val_loss: 2.3892 - val_accuracy: 0.2886\n",
      "Epoch 39/1000\n",
      "8108/8108 [==============================] - 0s 46us/step - loss: 2.2940 - accuracy: 0.3233 - val_loss: 2.3555 - val_accuracy: 0.3148\n",
      "Epoch 40/1000\n",
      "8108/8108 [==============================] - 0s 37us/step - loss: 2.2776 - accuracy: 0.3235 - val_loss: 2.3186 - val_accuracy: 0.3128\n",
      "Epoch 41/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 2.2764 - accuracy: 0.3185 - val_loss: 2.3608 - val_accuracy: 0.2758\n",
      "Epoch 42/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.2697 - accuracy: 0.3144 - val_loss: 2.3448 - val_accuracy: 0.3039\n",
      "Epoch 43/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.2519 - accuracy: 0.3212 - val_loss: 2.3033 - val_accuracy: 0.3054\n",
      "Epoch 44/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.2611 - accuracy: 0.3185 - val_loss: 2.3258 - val_accuracy: 0.2847\n",
      "Epoch 45/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.2283 - accuracy: 0.3366 - val_loss: 2.2879 - val_accuracy: 0.3483\n",
      "Epoch 46/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 2.2243 - accuracy: 0.3399 - val_loss: 2.2578 - val_accuracy: 0.3241\n",
      "Epoch 47/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 2.2159 - accuracy: 0.3392 - val_loss: 2.2874 - val_accuracy: 0.2886\n",
      "Epoch 48/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.2130 - accuracy: 0.3349 - val_loss: 2.3100 - val_accuracy: 0.2620\n",
      "Epoch 49/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 2.2038 - accuracy: 0.3489 - val_loss: 2.2746 - val_accuracy: 0.3049\n",
      "Epoch 50/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 2.1965 - accuracy: 0.3430 - val_loss: 2.2856 - val_accuracy: 0.3064\n",
      "Epoch 51/1000\n",
      "8108/8108 [==============================] - 0s 39us/step - loss: 2.1815 - accuracy: 0.3498 - val_loss: 2.2382 - val_accuracy: 0.3004\n",
      "Epoch 52/1000\n",
      "8108/8108 [==============================] - 0s 36us/step - loss: 2.1904 - accuracy: 0.3386 - val_loss: 2.2505 - val_accuracy: 0.3587\n",
      "Epoch 53/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 2.1898 - accuracy: 0.3403 - val_loss: 2.2586 - val_accuracy: 0.2876\n",
      "Epoch 54/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 2.1676 - accuracy: 0.3535 - val_loss: 2.2508 - val_accuracy: 0.3093\n",
      "Epoch 55/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 2.1466 - accuracy: 0.3527 - val_loss: 2.2197 - val_accuracy: 0.3592\n",
      "Epoch 56/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8108/8108 [==============================] - 0s 31us/step - loss: 2.1684 - accuracy: 0.3505 - val_loss: 2.2218 - val_accuracy: 0.3690\n",
      "Epoch 57/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.1599 - accuracy: 0.3462 - val_loss: 2.2146 - val_accuracy: 0.3138\n",
      "Epoch 58/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 2.1404 - accuracy: 0.3516 - val_loss: 2.2005 - val_accuracy: 0.3513\n",
      "Epoch 59/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.1477 - accuracy: 0.3510 - val_loss: 2.1789 - val_accuracy: 0.3557\n",
      "Epoch 60/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 2.1297 - accuracy: 0.3632 - val_loss: 2.1787 - val_accuracy: 0.3409\n",
      "Epoch 61/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 2.1328 - accuracy: 0.3592 - val_loss: 2.2306 - val_accuracy: 0.3320\n",
      "Epoch 62/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.1268 - accuracy: 0.3575 - val_loss: 2.1714 - val_accuracy: 0.3991\n",
      "Epoch 63/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 2.1087 - accuracy: 0.3656 - val_loss: 2.1565 - val_accuracy: 0.3384\n",
      "Epoch 64/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.1120 - accuracy: 0.3594 - val_loss: 2.2397 - val_accuracy: 0.3049\n",
      "Epoch 65/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 2.1190 - accuracy: 0.3599 - val_loss: 2.1995 - val_accuracy: 0.3695\n",
      "Epoch 66/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 2.1196 - accuracy: 0.3553 - val_loss: 2.1589 - val_accuracy: 0.3468\n",
      "Epoch 67/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 2.1049 - accuracy: 0.3508 - val_loss: 2.1255 - val_accuracy: 0.3764\n",
      "Epoch 68/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.0889 - accuracy: 0.3622 - val_loss: 2.1691 - val_accuracy: 0.3305\n",
      "Epoch 69/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.0874 - accuracy: 0.3667 - val_loss: 2.1721 - val_accuracy: 0.3389\n",
      "Epoch 70/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 2.0950 - accuracy: 0.3585 - val_loss: 2.1585 - val_accuracy: 0.3596\n",
      "Epoch 71/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.0793 - accuracy: 0.3764 - val_loss: 2.1220 - val_accuracy: 0.3892\n",
      "Epoch 72/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 2.0724 - accuracy: 0.3756 - val_loss: 2.1268 - val_accuracy: 0.3888\n",
      "Epoch 73/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 2.0676 - accuracy: 0.3652 - val_loss: 2.1247 - val_accuracy: 0.3592\n",
      "Epoch 74/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 2.0579 - accuracy: 0.3706 - val_loss: 2.1393 - val_accuracy: 0.3557\n",
      "Epoch 75/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 2.0473 - accuracy: 0.3781 - val_loss: 2.1446 - val_accuracy: 0.3439\n",
      "Epoch 76/1000\n",
      "8108/8108 [==============================] - 0s 28us/step - loss: 2.0554 - accuracy: 0.3672 - val_loss: 2.0987 - val_accuracy: 0.3483\n",
      "Epoch 77/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 2.0469 - accuracy: 0.3777 - val_loss: 2.1364 - val_accuracy: 0.3236\n",
      "Epoch 78/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 2.0445 - accuracy: 0.3746 - val_loss: 2.1330 - val_accuracy: 0.3473\n",
      "Epoch 79/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.0424 - accuracy: 0.3733 - val_loss: 2.1216 - val_accuracy: 0.3552\n",
      "Epoch 80/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 2.0293 - accuracy: 0.3758 - val_loss: 2.0961 - val_accuracy: 0.3626\n",
      "Epoch 81/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 2.0238 - accuracy: 0.3831 - val_loss: 2.1035 - val_accuracy: 0.3656\n",
      "Epoch 82/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 2.0373 - accuracy: 0.3820 - val_loss: 2.1300 - val_accuracy: 0.3434\n",
      "Epoch 83/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 2.0241 - accuracy: 0.3769 - val_loss: 2.0761 - val_accuracy: 0.3863\n",
      "Epoch 84/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 2.0121 - accuracy: 0.3906 - val_loss: 2.1764 - val_accuracy: 0.3261\n",
      "Epoch 85/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 2.0160 - accuracy: 0.3838 - val_loss: 2.0828 - val_accuracy: 0.3883\n",
      "Epoch 86/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.0291 - accuracy: 0.3758 - val_loss: 2.1117 - val_accuracy: 0.3493\n",
      "Epoch 87/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.0184 - accuracy: 0.3871 - val_loss: 2.0611 - val_accuracy: 0.4075\n",
      "Epoch 88/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.0210 - accuracy: 0.3758 - val_loss: 2.1088 - val_accuracy: 0.4006\n",
      "Epoch 89/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 2.0058 - accuracy: 0.3901 - val_loss: 2.1002 - val_accuracy: 0.3601\n",
      "Epoch 90/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.0006 - accuracy: 0.3777 - val_loss: 2.0792 - val_accuracy: 0.3631\n",
      "Epoch 91/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 2.0016 - accuracy: 0.3815 - val_loss: 2.1365 - val_accuracy: 0.3661\n",
      "Epoch 92/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.9933 - accuracy: 0.3806 - val_loss: 2.0485 - val_accuracy: 0.3537\n",
      "Epoch 93/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.9921 - accuracy: 0.3785 - val_loss: 2.0587 - val_accuracy: 0.3572\n",
      "Epoch 94/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.9943 - accuracy: 0.3920 - val_loss: 2.0429 - val_accuracy: 0.4100\n",
      "Epoch 95/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.9986 - accuracy: 0.3837 - val_loss: 2.0712 - val_accuracy: 0.3680\n",
      "Epoch 96/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.9907 - accuracy: 0.3910 - val_loss: 2.0188 - val_accuracy: 0.3986\n",
      "Epoch 97/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.9725 - accuracy: 0.3934 - val_loss: 2.0479 - val_accuracy: 0.3340\n",
      "Epoch 98/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.9788 - accuracy: 0.3757 - val_loss: 2.0823 - val_accuracy: 0.3823\n",
      "Epoch 99/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.9807 - accuracy: 0.3865 - val_loss: 2.1287 - val_accuracy: 0.3404\n",
      "Epoch 100/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.9789 - accuracy: 0.3825 - val_loss: 2.0721 - val_accuracy: 0.3631\n",
      "Epoch 101/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.9737 - accuracy: 0.3939 - val_loss: 2.0263 - val_accuracy: 0.3828\n",
      "Epoch 102/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.9621 - accuracy: 0.3981 - val_loss: 2.0289 - val_accuracy: 0.3878\n",
      "Epoch 103/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.9797 - accuracy: 0.3847 - val_loss: 2.0559 - val_accuracy: 0.3399\n",
      "Epoch 104/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.9722 - accuracy: 0.3858 - val_loss: 2.0323 - val_accuracy: 0.3981\n",
      "Epoch 105/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.9719 - accuracy: 0.3860 - val_loss: 1.9691 - val_accuracy: 0.3937\n",
      "Epoch 106/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.9620 - accuracy: 0.3890 - val_loss: 2.0222 - val_accuracy: 0.3651\n",
      "Epoch 107/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.9411 - accuracy: 0.3952 - val_loss: 2.0274 - val_accuracy: 0.4006\n",
      "Epoch 108/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.9342 - accuracy: 0.4022 - val_loss: 2.0369 - val_accuracy: 0.3389\n",
      "Epoch 109/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.9582 - accuracy: 0.3860 - val_loss: 2.0259 - val_accuracy: 0.3927\n",
      "Epoch 110/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.9681 - accuracy: 0.3950 - val_loss: 2.0222 - val_accuracy: 0.3483\n",
      "Epoch 111/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.9518 - accuracy: 0.4026 - val_loss: 1.9951 - val_accuracy: 0.3596\n",
      "Epoch 112/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.9331 - accuracy: 0.3991 - val_loss: 2.0364 - val_accuracy: 0.3794\n",
      "Epoch 113/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.9367 - accuracy: 0.3971 - val_loss: 1.9768 - val_accuracy: 0.4100\n",
      "Epoch 114/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.9395 - accuracy: 0.3960 - val_loss: 1.9676 - val_accuracy: 0.4164\n",
      "Epoch 115/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.9217 - accuracy: 0.4011 - val_loss: 1.9678 - val_accuracy: 0.4415\n",
      "Epoch 116/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.9277 - accuracy: 0.4061 - val_loss: 1.9839 - val_accuracy: 0.3873\n",
      "Epoch 117/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.9180 - accuracy: 0.4012 - val_loss: 2.0126 - val_accuracy: 0.4045\n",
      "Epoch 118/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.9283 - accuracy: 0.4042 - val_loss: 1.9746 - val_accuracy: 0.4386\n",
      "Epoch 119/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.9190 - accuracy: 0.4031 - val_loss: 1.9518 - val_accuracy: 0.3957\n",
      "Epoch 120/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.9204 - accuracy: 0.4059 - val_loss: 1.9906 - val_accuracy: 0.3567\n",
      "Epoch 121/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.9169 - accuracy: 0.4064 - val_loss: 2.0021 - val_accuracy: 0.3991\n",
      "Epoch 122/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.9012 - accuracy: 0.4093 - val_loss: 1.9760 - val_accuracy: 0.3838\n",
      "Epoch 123/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.9181 - accuracy: 0.4027 - val_loss: 1.9405 - val_accuracy: 0.4228\n",
      "Epoch 124/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.9027 - accuracy: 0.4133 - val_loss: 1.9892 - val_accuracy: 0.4110\n",
      "Epoch 125/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.8963 - accuracy: 0.4156 - val_loss: 2.0188 - val_accuracy: 0.3814\n",
      "Epoch 126/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.9165 - accuracy: 0.4033 - val_loss: 1.9916 - val_accuracy: 0.3611\n",
      "Epoch 127/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.8926 - accuracy: 0.4092 - val_loss: 1.9859 - val_accuracy: 0.4351\n",
      "Epoch 128/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.8997 - accuracy: 0.4037 - val_loss: 1.9984 - val_accuracy: 0.3527\n",
      "Epoch 129/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.8943 - accuracy: 0.4070 - val_loss: 1.9636 - val_accuracy: 0.3695\n",
      "Epoch 130/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.9018 - accuracy: 0.4081 - val_loss: 2.0729 - val_accuracy: 0.3271\n",
      "Epoch 131/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.9092 - accuracy: 0.3995 - val_loss: 1.9254 - val_accuracy: 0.4317\n",
      "Epoch 132/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.8793 - accuracy: 0.4129 - val_loss: 1.9656 - val_accuracy: 0.3952\n",
      "Epoch 133/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.8911 - accuracy: 0.4145 - val_loss: 1.9664 - val_accuracy: 0.3710\n",
      "Epoch 134/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.8932 - accuracy: 0.4058 - val_loss: 1.9823 - val_accuracy: 0.3986\n",
      "Epoch 135/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.8995 - accuracy: 0.4061 - val_loss: 1.9451 - val_accuracy: 0.4193\n",
      "Epoch 136/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.8811 - accuracy: 0.4148 - val_loss: 2.0019 - val_accuracy: 0.3764\n",
      "Epoch 137/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.8861 - accuracy: 0.4058 - val_loss: 1.9209 - val_accuracy: 0.4134\n",
      "Epoch 138/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.8935 - accuracy: 0.4024 - val_loss: 2.0431 - val_accuracy: 0.3636\n",
      "Epoch 139/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.8840 - accuracy: 0.4096 - val_loss: 2.0115 - val_accuracy: 0.3784\n",
      "Epoch 140/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.8666 - accuracy: 0.4155 - val_loss: 1.9600 - val_accuracy: 0.4114\n",
      "Epoch 141/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.9050 - accuracy: 0.3960 - val_loss: 1.9506 - val_accuracy: 0.3902\n",
      "Epoch 142/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.8621 - accuracy: 0.4212 - val_loss: 1.9377 - val_accuracy: 0.3710\n",
      "Epoch 143/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.8737 - accuracy: 0.4186 - val_loss: 1.9348 - val_accuracy: 0.4144\n",
      "Epoch 144/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.8656 - accuracy: 0.4103 - val_loss: 1.9948 - val_accuracy: 0.3818\n",
      "Epoch 145/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.8738 - accuracy: 0.4092 - val_loss: 1.8769 - val_accuracy: 0.4549\n",
      "Epoch 146/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.8727 - accuracy: 0.4160 - val_loss: 1.9620 - val_accuracy: 0.3749\n",
      "Epoch 147/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.8548 - accuracy: 0.4228 - val_loss: 1.9913 - val_accuracy: 0.3666\n",
      "Epoch 148/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.8597 - accuracy: 0.4330 - val_loss: 1.8952 - val_accuracy: 0.3937\n",
      "Epoch 149/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.8342 - accuracy: 0.4332 - val_loss: 1.9252 - val_accuracy: 0.4484\n",
      "Epoch 150/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.8645 - accuracy: 0.4218 - val_loss: 1.9211 - val_accuracy: 0.4016\n",
      "Epoch 151/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.8405 - accuracy: 0.4148 - val_loss: 1.9339 - val_accuracy: 0.4006\n",
      "Epoch 152/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.8522 - accuracy: 0.4128 - val_loss: 1.9385 - val_accuracy: 0.4031\n",
      "Epoch 153/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.8538 - accuracy: 0.4143 - val_loss: 1.8978 - val_accuracy: 0.4218\n",
      "Epoch 154/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.8303 - accuracy: 0.4192 - val_loss: 1.9480 - val_accuracy: 0.4070\n",
      "Epoch 155/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.8364 - accuracy: 0.4195 - val_loss: 1.9198 - val_accuracy: 0.4045\n",
      "Epoch 156/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.8444 - accuracy: 0.4171 - val_loss: 1.9356 - val_accuracy: 0.4001\n",
      "Epoch 157/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.8306 - accuracy: 0.4224 - val_loss: 1.9388 - val_accuracy: 0.4228\n",
      "Epoch 158/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.8504 - accuracy: 0.4192 - val_loss: 1.9006 - val_accuracy: 0.4110\n",
      "Epoch 159/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.8488 - accuracy: 0.4138 - val_loss: 1.9379 - val_accuracy: 0.4322\n",
      "Epoch 160/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.8357 - accuracy: 0.4222 - val_loss: 1.9674 - val_accuracy: 0.3917\n",
      "Epoch 161/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.8359 - accuracy: 0.4180 - val_loss: 1.9279 - val_accuracy: 0.3873\n",
      "Epoch 162/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.8205 - accuracy: 0.4295 - val_loss: 1.9285 - val_accuracy: 0.4129\n",
      "Epoch 163/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.8423 - accuracy: 0.4148 - val_loss: 1.9272 - val_accuracy: 0.3799\n",
      "Epoch 164/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.8392 - accuracy: 0.4253 - val_loss: 1.9087 - val_accuracy: 0.3927\n",
      "Epoch 165/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.8189 - accuracy: 0.4216 - val_loss: 1.8527 - val_accuracy: 0.4327\n",
      "Epoch 166/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.8452 - accuracy: 0.4212 - val_loss: 1.9557 - val_accuracy: 0.3902\n",
      "Epoch 167/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.8143 - accuracy: 0.4248 - val_loss: 1.9133 - val_accuracy: 0.4050\n",
      "Epoch 168/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.7985 - accuracy: 0.4403 - val_loss: 1.9224 - val_accuracy: 0.3873\n",
      "Epoch 169/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.8478 - accuracy: 0.4175 - val_loss: 1.8830 - val_accuracy: 0.4391\n",
      "Epoch 170/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.8124 - accuracy: 0.4340 - val_loss: 1.9273 - val_accuracy: 0.3902\n",
      "Epoch 171/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.8294 - accuracy: 0.4207 - val_loss: 1.9397 - val_accuracy: 0.3962\n",
      "Epoch 172/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.8103 - accuracy: 0.4234 - val_loss: 1.8752 - val_accuracy: 0.4129\n",
      "Epoch 173/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.8157 - accuracy: 0.4155 - val_loss: 1.8628 - val_accuracy: 0.4366\n",
      "Epoch 174/1000\n",
      "8108/8108 [==============================] - 0s 36us/step - loss: 1.8237 - accuracy: 0.4229 - val_loss: 1.8916 - val_accuracy: 0.3947\n",
      "Epoch 175/1000\n",
      "8108/8108 [==============================] - 0s 37us/step - loss: 1.8172 - accuracy: 0.4221 - val_loss: 1.9271 - val_accuracy: 0.4085\n",
      "Epoch 176/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.8118 - accuracy: 0.4251 - val_loss: 1.9125 - val_accuracy: 0.3917\n",
      "Epoch 177/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.8012 - accuracy: 0.4345 - val_loss: 1.9021 - val_accuracy: 0.4075\n",
      "Epoch 178/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.7843 - accuracy: 0.4346 - val_loss: 1.8729 - val_accuracy: 0.4198\n",
      "Epoch 179/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.7977 - accuracy: 0.4401 - val_loss: 1.8997 - val_accuracy: 0.3498\n",
      "Epoch 180/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.8057 - accuracy: 0.4266 - val_loss: 1.8353 - val_accuracy: 0.4228\n",
      "Epoch 181/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.7994 - accuracy: 0.4388 - val_loss: 1.8244 - val_accuracy: 0.4425\n",
      "Epoch 182/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.8172 - accuracy: 0.4165 - val_loss: 1.8675 - val_accuracy: 0.4203\n",
      "Epoch 183/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.8204 - accuracy: 0.4147 - val_loss: 1.8705 - val_accuracy: 0.3892\n",
      "Epoch 184/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.7985 - accuracy: 0.4350 - val_loss: 1.8678 - val_accuracy: 0.3823\n",
      "Epoch 185/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.8038 - accuracy: 0.4372 - val_loss: 1.8409 - val_accuracy: 0.4164\n",
      "Epoch 186/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.7963 - accuracy: 0.4296 - val_loss: 1.8284 - val_accuracy: 0.4154\n",
      "Epoch 187/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.7899 - accuracy: 0.4345 - val_loss: 1.8257 - val_accuracy: 0.4805\n",
      "Epoch 188/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.7878 - accuracy: 0.4339 - val_loss: 1.8631 - val_accuracy: 0.4253\n",
      "Epoch 189/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.7752 - accuracy: 0.4415 - val_loss: 1.8575 - val_accuracy: 0.4228\n",
      "Epoch 190/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.7972 - accuracy: 0.4250 - val_loss: 1.9187 - val_accuracy: 0.3675\n",
      "Epoch 191/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.8041 - accuracy: 0.4217 - val_loss: 1.8218 - val_accuracy: 0.4435\n",
      "Epoch 192/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.7751 - accuracy: 0.4295 - val_loss: 1.8704 - val_accuracy: 0.4060\n",
      "Epoch 193/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.7864 - accuracy: 0.4291 - val_loss: 1.8705 - val_accuracy: 0.4228\n",
      "Epoch 194/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.7775 - accuracy: 0.4409 - val_loss: 1.8232 - val_accuracy: 0.4563\n",
      "Epoch 195/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.7939 - accuracy: 0.4313 - val_loss: 1.8811 - val_accuracy: 0.3922\n",
      "Epoch 196/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.7763 - accuracy: 0.4386 - val_loss: 1.8809 - val_accuracy: 0.3774\n",
      "Epoch 197/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.7892 - accuracy: 0.4238 - val_loss: 1.8414 - val_accuracy: 0.4356\n",
      "Epoch 198/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.7682 - accuracy: 0.4434 - val_loss: 1.8553 - val_accuracy: 0.3828\n",
      "Epoch 199/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.7741 - accuracy: 0.4364 - val_loss: 1.8494 - val_accuracy: 0.4193\n",
      "Epoch 200/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.7612 - accuracy: 0.4457 - val_loss: 1.8307 - val_accuracy: 0.4031\n",
      "Epoch 201/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.7785 - accuracy: 0.4270 - val_loss: 1.8189 - val_accuracy: 0.4258\n",
      "Epoch 202/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.7724 - accuracy: 0.4407 - val_loss: 1.8555 - val_accuracy: 0.4470\n",
      "Epoch 203/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.7655 - accuracy: 0.4375 - val_loss: 1.8724 - val_accuracy: 0.4544\n",
      "Epoch 204/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.7643 - accuracy: 0.4388 - val_loss: 1.9166 - val_accuracy: 0.4040\n",
      "Epoch 205/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.7933 - accuracy: 0.4311 - val_loss: 1.8177 - val_accuracy: 0.4386\n",
      "Epoch 206/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.7430 - accuracy: 0.4512 - val_loss: 1.8196 - val_accuracy: 0.4243\n",
      "Epoch 207/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.7640 - accuracy: 0.4361 - val_loss: 1.8660 - val_accuracy: 0.3848\n",
      "Epoch 208/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.7615 - accuracy: 0.4417 - val_loss: 1.8137 - val_accuracy: 0.4489\n",
      "Epoch 209/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.7629 - accuracy: 0.4366 - val_loss: 1.8263 - val_accuracy: 0.4277\n",
      "Epoch 210/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.7741 - accuracy: 0.4254 - val_loss: 1.8344 - val_accuracy: 0.4455\n",
      "Epoch 211/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.7873 - accuracy: 0.4304 - val_loss: 1.8310 - val_accuracy: 0.4193\n",
      "Epoch 212/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.7578 - accuracy: 0.4441 - val_loss: 1.8350 - val_accuracy: 0.4040\n",
      "Epoch 213/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.7506 - accuracy: 0.4426 - val_loss: 1.8641 - val_accuracy: 0.4613\n",
      "Epoch 214/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.7492 - accuracy: 0.4381 - val_loss: 1.8226 - val_accuracy: 0.4040\n",
      "Epoch 215/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.7392 - accuracy: 0.4460 - val_loss: 1.8304 - val_accuracy: 0.4119\n",
      "Epoch 216/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.7616 - accuracy: 0.4372 - val_loss: 1.8313 - val_accuracy: 0.4169\n",
      "Epoch 217/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.7826 - accuracy: 0.4245 - val_loss: 1.8504 - val_accuracy: 0.4026\n",
      "Epoch 218/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.7739 - accuracy: 0.4317 - val_loss: 1.7813 - val_accuracy: 0.4302\n",
      "Epoch 219/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.7497 - accuracy: 0.4345 - val_loss: 1.8621 - val_accuracy: 0.4233\n",
      "Epoch 220/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.7596 - accuracy: 0.4397 - val_loss: 1.8114 - val_accuracy: 0.4258\n",
      "Epoch 221/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.7447 - accuracy: 0.4456 - val_loss: 1.9138 - val_accuracy: 0.3927\n",
      "Epoch 222/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.7465 - accuracy: 0.4387 - val_loss: 1.8321 - val_accuracy: 0.4277\n",
      "Epoch 223/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.7522 - accuracy: 0.4418 - val_loss: 1.8248 - val_accuracy: 0.4095\n",
      "Epoch 224/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.7647 - accuracy: 0.4288 - val_loss: 1.8636 - val_accuracy: 0.3784\n",
      "Epoch 225/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.7575 - accuracy: 0.4452 - val_loss: 1.8076 - val_accuracy: 0.4371\n",
      "Epoch 226/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.7531 - accuracy: 0.4352 - val_loss: 1.8290 - val_accuracy: 0.4420\n",
      "Epoch 227/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.7228 - accuracy: 0.4556 - val_loss: 1.8540 - val_accuracy: 0.4198\n",
      "Epoch 228/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.7813 - accuracy: 0.4277 - val_loss: 1.8192 - val_accuracy: 0.4198\n",
      "Epoch 229/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.7527 - accuracy: 0.4327 - val_loss: 1.8055 - val_accuracy: 0.4430\n",
      "Epoch 230/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.7728 - accuracy: 0.4325 - val_loss: 1.8333 - val_accuracy: 0.4124\n",
      "Epoch 231/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.7422 - accuracy: 0.4424 - val_loss: 1.8953 - val_accuracy: 0.4110\n",
      "Epoch 232/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.7342 - accuracy: 0.4436 - val_loss: 1.8081 - val_accuracy: 0.4031\n",
      "Epoch 233/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.7462 - accuracy: 0.4370 - val_loss: 1.8816 - val_accuracy: 0.4317\n",
      "Epoch 234/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.7469 - accuracy: 0.4414 - val_loss: 1.7794 - val_accuracy: 0.4494\n",
      "Epoch 235/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.7314 - accuracy: 0.4488 - val_loss: 1.8010 - val_accuracy: 0.4480\n",
      "Epoch 236/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.7410 - accuracy: 0.4369 - val_loss: 1.8324 - val_accuracy: 0.4011\n",
      "Epoch 237/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.7797 - accuracy: 0.4261 - val_loss: 1.8030 - val_accuracy: 0.4040\n",
      "Epoch 238/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.7528 - accuracy: 0.4349 - val_loss: 1.7963 - val_accuracy: 0.4203\n",
      "Epoch 239/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.7340 - accuracy: 0.4410 - val_loss: 1.8474 - val_accuracy: 0.4149\n",
      "Epoch 240/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.7305 - accuracy: 0.4433 - val_loss: 1.8297 - val_accuracy: 0.4228\n",
      "Epoch 241/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.7450 - accuracy: 0.4394 - val_loss: 1.8041 - val_accuracy: 0.4401\n",
      "Epoch 242/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.7286 - accuracy: 0.4514 - val_loss: 1.7729 - val_accuracy: 0.4470\n",
      "Epoch 243/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.7137 - accuracy: 0.4498 - val_loss: 1.7825 - val_accuracy: 0.4366\n",
      "Epoch 244/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.7282 - accuracy: 0.4423 - val_loss: 1.8033 - val_accuracy: 0.4484\n",
      "Epoch 245/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.7279 - accuracy: 0.4343 - val_loss: 1.7637 - val_accuracy: 0.4198\n",
      "Epoch 246/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.7365 - accuracy: 0.4444 - val_loss: 1.7217 - val_accuracy: 0.4795\n",
      "Epoch 247/1000\n",
      "8108/8108 [==============================] - 0s 40us/step - loss: 1.7026 - accuracy: 0.4595 - val_loss: 1.7705 - val_accuracy: 0.4544\n",
      "Epoch 248/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.6991 - accuracy: 0.4591 - val_loss: 1.7721 - val_accuracy: 0.4228\n",
      "Epoch 249/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.7182 - accuracy: 0.4460 - val_loss: 1.7683 - val_accuracy: 0.3912\n",
      "Epoch 250/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 1.7239 - accuracy: 0.4467 - val_loss: 1.7922 - val_accuracy: 0.4336\n",
      "Epoch 251/1000\n",
      "8108/8108 [==============================] - 0s 40us/step - loss: 1.7144 - accuracy: 0.4478 - val_loss: 1.8043 - val_accuracy: 0.4243\n",
      "Epoch 252/1000\n",
      "8108/8108 [==============================] - 0s 37us/step - loss: 1.7205 - accuracy: 0.4491 - val_loss: 1.7545 - val_accuracy: 0.4554\n",
      "Epoch 253/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 1.7212 - accuracy: 0.4466 - val_loss: 1.8131 - val_accuracy: 0.4302\n",
      "Epoch 254/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 1.7041 - accuracy: 0.4576 - val_loss: 1.8365 - val_accuracy: 0.4297\n",
      "Epoch 255/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6987 - accuracy: 0.4567 - val_loss: 1.7562 - val_accuracy: 0.4396\n",
      "Epoch 256/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.7087 - accuracy: 0.4478 - val_loss: 1.7569 - val_accuracy: 0.4815\n",
      "Epoch 257/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.6946 - accuracy: 0.4644 - val_loss: 1.7293 - val_accuracy: 0.4672\n",
      "Epoch 258/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.7331 - accuracy: 0.4415 - val_loss: 1.8136 - val_accuracy: 0.4218\n",
      "Epoch 259/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.7087 - accuracy: 0.4493 - val_loss: 1.7629 - val_accuracy: 0.4332\n",
      "Epoch 260/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6942 - accuracy: 0.4518 - val_loss: 1.7260 - val_accuracy: 0.4657\n",
      "Epoch 261/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 1.6951 - accuracy: 0.4531 - val_loss: 1.7193 - val_accuracy: 0.4494\n",
      "Epoch 262/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.6885 - accuracy: 0.4684 - val_loss: 1.7646 - val_accuracy: 0.4410\n",
      "Epoch 263/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 1.7207 - accuracy: 0.4514 - val_loss: 1.8210 - val_accuracy: 0.4267\n",
      "Epoch 264/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.6977 - accuracy: 0.4600 - val_loss: 1.7959 - val_accuracy: 0.4381\n",
      "Epoch 265/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.7030 - accuracy: 0.4563 - val_loss: 1.8404 - val_accuracy: 0.4272\n",
      "Epoch 266/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.7075 - accuracy: 0.4533 - val_loss: 1.8153 - val_accuracy: 0.3888\n",
      "Epoch 267/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.7180 - accuracy: 0.4396 - val_loss: 1.8038 - val_accuracy: 0.3833\n",
      "Epoch 268/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.7005 - accuracy: 0.4537 - val_loss: 1.8022 - val_accuracy: 0.4282\n",
      "Epoch 269/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 1.7221 - accuracy: 0.4491 - val_loss: 1.8303 - val_accuracy: 0.3883\n",
      "Epoch 270/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.6917 - accuracy: 0.4565 - val_loss: 1.7808 - val_accuracy: 0.4514\n",
      "Epoch 271/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.7103 - accuracy: 0.4549 - val_loss: 1.7686 - val_accuracy: 0.4154\n",
      "Epoch 272/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.6666 - accuracy: 0.4630 - val_loss: 1.7612 - val_accuracy: 0.4376\n",
      "Epoch 273/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.6820 - accuracy: 0.4594 - val_loss: 1.7316 - val_accuracy: 0.4544\n",
      "Epoch 274/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.6854 - accuracy: 0.4626 - val_loss: 1.7710 - val_accuracy: 0.4282\n",
      "Epoch 275/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.6802 - accuracy: 0.4602 - val_loss: 1.7443 - val_accuracy: 0.4080\n",
      "Epoch 276/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.6958 - accuracy: 0.4502 - val_loss: 1.7547 - val_accuracy: 0.4381\n",
      "Epoch 277/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6834 - accuracy: 0.4503 - val_loss: 1.7713 - val_accuracy: 0.4415\n",
      "Epoch 278/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.7058 - accuracy: 0.4499 - val_loss: 1.8255 - val_accuracy: 0.4144\n",
      "Epoch 279/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.6901 - accuracy: 0.4541 - val_loss: 1.7800 - val_accuracy: 0.4312\n",
      "Epoch 280/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.6693 - accuracy: 0.4661 - val_loss: 1.7476 - val_accuracy: 0.4262\n",
      "Epoch 281/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.6723 - accuracy: 0.4673 - val_loss: 1.7894 - val_accuracy: 0.4198\n",
      "Epoch 282/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.6806 - accuracy: 0.4586 - val_loss: 1.7699 - val_accuracy: 0.4322\n",
      "Epoch 283/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.6770 - accuracy: 0.4519 - val_loss: 1.7843 - val_accuracy: 0.4282\n",
      "Epoch 284/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.6777 - accuracy: 0.4554 - val_loss: 1.7453 - val_accuracy: 0.4815\n",
      "Epoch 285/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.6739 - accuracy: 0.4639 - val_loss: 1.7253 - val_accuracy: 0.4919\n",
      "Epoch 286/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.6805 - accuracy: 0.4589 - val_loss: 1.7912 - val_accuracy: 0.4036\n",
      "Epoch 287/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.6808 - accuracy: 0.4535 - val_loss: 1.7621 - val_accuracy: 0.4050\n",
      "Epoch 288/1000\n",
      "8108/8108 [==============================] - 0s 36us/step - loss: 1.6794 - accuracy: 0.4604 - val_loss: 1.7817 - val_accuracy: 0.4544\n",
      "Epoch 289/1000\n",
      "8108/8108 [==============================] - 0s 44us/step - loss: 1.6759 - accuracy: 0.4571 - val_loss: 1.7699 - val_accuracy: 0.4258\n",
      "Epoch 290/1000\n",
      "8108/8108 [==============================] - 0s 39us/step - loss: 1.6923 - accuracy: 0.4539 - val_loss: 1.7141 - val_accuracy: 0.5027\n",
      "Epoch 291/1000\n",
      "8108/8108 [==============================] - 0s 36us/step - loss: 1.6699 - accuracy: 0.4676 - val_loss: 1.7734 - val_accuracy: 0.3981\n",
      "Epoch 292/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 1.6993 - accuracy: 0.4482 - val_loss: 1.7784 - val_accuracy: 0.3952\n",
      "Epoch 293/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.7038 - accuracy: 0.4494 - val_loss: 1.8038 - val_accuracy: 0.4040\n",
      "Epoch 294/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.6614 - accuracy: 0.4684 - val_loss: 1.7431 - val_accuracy: 0.4317\n",
      "Epoch 295/1000\n",
      "8108/8108 [==============================] - 0s 36us/step - loss: 1.6842 - accuracy: 0.4529 - val_loss: 1.8848 - val_accuracy: 0.4114\n",
      "Epoch 296/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6781 - accuracy: 0.4551 - val_loss: 1.7772 - val_accuracy: 0.4317\n",
      "Epoch 297/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.6742 - accuracy: 0.4556 - val_loss: 1.7324 - val_accuracy: 0.4415\n",
      "Epoch 298/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6723 - accuracy: 0.4587 - val_loss: 1.7612 - val_accuracy: 0.4475\n",
      "Epoch 299/1000\n",
      "8108/8108 [==============================] - 0s 36us/step - loss: 1.6720 - accuracy: 0.4549 - val_loss: 1.7447 - val_accuracy: 0.4233\n",
      "Epoch 300/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 1.6749 - accuracy: 0.4570 - val_loss: 1.7377 - val_accuracy: 0.4805\n",
      "Epoch 301/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.6624 - accuracy: 0.4665 - val_loss: 1.6925 - val_accuracy: 0.4766\n",
      "Epoch 302/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.6833 - accuracy: 0.4561 - val_loss: 1.7757 - val_accuracy: 0.4475\n",
      "Epoch 303/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6763 - accuracy: 0.4509 - val_loss: 1.7894 - val_accuracy: 0.4327\n",
      "Epoch 304/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.6627 - accuracy: 0.4557 - val_loss: 1.7216 - val_accuracy: 0.4277\n",
      "Epoch 305/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6620 - accuracy: 0.4608 - val_loss: 1.7604 - val_accuracy: 0.4011\n",
      "Epoch 306/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.6737 - accuracy: 0.4579 - val_loss: 1.7271 - val_accuracy: 0.4835\n",
      "Epoch 307/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6714 - accuracy: 0.4519 - val_loss: 1.7274 - val_accuracy: 0.4618\n",
      "Epoch 308/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6561 - accuracy: 0.4682 - val_loss: 1.7468 - val_accuracy: 0.4149\n",
      "Epoch 309/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6677 - accuracy: 0.4492 - val_loss: 1.7452 - val_accuracy: 0.4346\n",
      "Epoch 310/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6680 - accuracy: 0.4570 - val_loss: 1.7680 - val_accuracy: 0.4277\n",
      "Epoch 311/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6704 - accuracy: 0.4529 - val_loss: 1.6746 - val_accuracy: 0.4637\n",
      "Epoch 312/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6309 - accuracy: 0.4732 - val_loss: 1.7177 - val_accuracy: 0.4613\n",
      "Epoch 313/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6720 - accuracy: 0.4504 - val_loss: 1.6983 - val_accuracy: 0.4519\n",
      "Epoch 314/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6460 - accuracy: 0.4677 - val_loss: 1.7347 - val_accuracy: 0.4450\n",
      "Epoch 315/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.6484 - accuracy: 0.4692 - val_loss: 1.7506 - val_accuracy: 0.4366\n",
      "Epoch 316/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6713 - accuracy: 0.4558 - val_loss: 1.7904 - val_accuracy: 0.4095\n",
      "Epoch 317/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6506 - accuracy: 0.4674 - val_loss: 1.8117 - val_accuracy: 0.4312\n",
      "Epoch 318/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6538 - accuracy: 0.4663 - val_loss: 1.7264 - val_accuracy: 0.4524\n",
      "Epoch 319/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.6513 - accuracy: 0.4762 - val_loss: 1.7025 - val_accuracy: 0.4682\n",
      "Epoch 320/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.6330 - accuracy: 0.4679 - val_loss: 1.7278 - val_accuracy: 0.4282\n",
      "Epoch 321/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.6512 - accuracy: 0.4629 - val_loss: 1.7430 - val_accuracy: 0.4489\n",
      "Epoch 322/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.6399 - accuracy: 0.4702 - val_loss: 1.6678 - val_accuracy: 0.4795\n",
      "Epoch 323/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6596 - accuracy: 0.4609 - val_loss: 1.7557 - val_accuracy: 0.4470\n",
      "Epoch 324/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.6637 - accuracy: 0.4586 - val_loss: 1.7491 - val_accuracy: 0.4336\n",
      "Epoch 325/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.6582 - accuracy: 0.4598 - val_loss: 1.8589 - val_accuracy: 0.3695\n",
      "Epoch 326/1000\n",
      "8108/8108 [==============================] - 0s 36us/step - loss: 1.6743 - accuracy: 0.4554 - val_loss: 1.7070 - val_accuracy: 0.4519\n",
      "Epoch 327/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.6346 - accuracy: 0.4710 - val_loss: 1.7445 - val_accuracy: 0.4563\n",
      "Epoch 328/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6709 - accuracy: 0.4519 - val_loss: 1.7818 - val_accuracy: 0.4090\n",
      "Epoch 329/1000\n",
      "8108/8108 [==============================] - 0s 37us/step - loss: 1.6516 - accuracy: 0.4637 - val_loss: 1.7931 - val_accuracy: 0.3942\n",
      "Epoch 330/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.6723 - accuracy: 0.4574 - val_loss: 1.8202 - val_accuracy: 0.4317\n",
      "Epoch 331/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.6502 - accuracy: 0.4650 - val_loss: 1.6334 - val_accuracy: 0.5106\n",
      "Epoch 332/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.6164 - accuracy: 0.4761 - val_loss: 1.7207 - val_accuracy: 0.4613\n",
      "Epoch 333/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.6338 - accuracy: 0.4655 - val_loss: 1.7864 - val_accuracy: 0.4307\n",
      "Epoch 334/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6483 - accuracy: 0.4630 - val_loss: 1.7325 - val_accuracy: 0.4672\n",
      "Epoch 335/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6417 - accuracy: 0.4631 - val_loss: 1.7428 - val_accuracy: 0.4253\n",
      "Epoch 336/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6297 - accuracy: 0.4681 - val_loss: 1.7485 - val_accuracy: 0.4450\n",
      "Epoch 337/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.6519 - accuracy: 0.4541 - val_loss: 1.6623 - val_accuracy: 0.4933\n",
      "Epoch 338/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6220 - accuracy: 0.4731 - val_loss: 1.7424 - val_accuracy: 0.4159\n",
      "Epoch 339/1000\n",
      "8108/8108 [==============================] - 0s 36us/step - loss: 1.6168 - accuracy: 0.4756 - val_loss: 1.6736 - val_accuracy: 0.4450\n",
      "Epoch 340/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.6257 - accuracy: 0.4768 - val_loss: 1.7417 - val_accuracy: 0.4124\n",
      "Epoch 341/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.6506 - accuracy: 0.4579 - val_loss: 1.7245 - val_accuracy: 0.4351\n",
      "Epoch 342/1000\n",
      "8108/8108 [==============================] - 0s 37us/step - loss: 1.6262 - accuracy: 0.4778 - val_loss: 1.7336 - val_accuracy: 0.4499\n",
      "Epoch 343/1000\n",
      "8108/8108 [==============================] - 0s 36us/step - loss: 1.6139 - accuracy: 0.4705 - val_loss: 1.6805 - val_accuracy: 0.4756\n",
      "Epoch 344/1000\n",
      "8108/8108 [==============================] - 0s 38us/step - loss: 1.6126 - accuracy: 0.4757 - val_loss: 1.8117 - val_accuracy: 0.4060\n",
      "Epoch 345/1000\n",
      "8108/8108 [==============================] - 0s 36us/step - loss: 1.6312 - accuracy: 0.4699 - val_loss: 1.7354 - val_accuracy: 0.4164\n",
      "Epoch 346/1000\n",
      "8108/8108 [==============================] - 0s 38us/step - loss: 1.6463 - accuracy: 0.4677 - val_loss: 1.6855 - val_accuracy: 0.4632\n",
      "Epoch 347/1000\n",
      "8108/8108 [==============================] - 0s 37us/step - loss: 1.6335 - accuracy: 0.4767 - val_loss: 1.6989 - val_accuracy: 0.4583\n",
      "Epoch 348/1000\n",
      "8108/8108 [==============================] - 0s 37us/step - loss: 1.6248 - accuracy: 0.4694 - val_loss: 1.7154 - val_accuracy: 0.4425\n",
      "Epoch 349/1000\n",
      "8108/8108 [==============================] - 0s 36us/step - loss: 1.6476 - accuracy: 0.4581 - val_loss: 1.7497 - val_accuracy: 0.4203\n",
      "Epoch 350/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.6227 - accuracy: 0.4736 - val_loss: 1.7517 - val_accuracy: 0.4272\n",
      "Epoch 351/1000\n",
      "8108/8108 [==============================] - 0s 38us/step - loss: 1.6497 - accuracy: 0.4587 - val_loss: 1.6665 - val_accuracy: 0.4854\n",
      "Epoch 352/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.6384 - accuracy: 0.4647 - val_loss: 1.7128 - val_accuracy: 0.4351\n",
      "Epoch 353/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.6261 - accuracy: 0.4753 - val_loss: 1.7564 - val_accuracy: 0.4376\n",
      "Epoch 354/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.6650 - accuracy: 0.4566 - val_loss: 1.7377 - val_accuracy: 0.4445\n",
      "Epoch 355/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.6081 - accuracy: 0.4672 - val_loss: 1.6479 - val_accuracy: 0.4529\n",
      "Epoch 356/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5992 - accuracy: 0.4799 - val_loss: 1.6658 - val_accuracy: 0.4573\n",
      "Epoch 357/1000\n",
      "8108/8108 [==============================] - 0s 37us/step - loss: 1.6269 - accuracy: 0.4688 - val_loss: 1.7163 - val_accuracy: 0.4632\n",
      "Epoch 358/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6410 - accuracy: 0.4584 - val_loss: 1.7170 - val_accuracy: 0.4386\n",
      "Epoch 359/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.6418 - accuracy: 0.4666 - val_loss: 1.7053 - val_accuracy: 0.4267\n",
      "Epoch 360/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.6206 - accuracy: 0.4708 - val_loss: 1.6879 - val_accuracy: 0.4302\n",
      "Epoch 361/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.6114 - accuracy: 0.4704 - val_loss: 1.6944 - val_accuracy: 0.4484\n",
      "Epoch 362/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6304 - accuracy: 0.4688 - val_loss: 1.6725 - val_accuracy: 0.4795\n",
      "Epoch 363/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 1.6050 - accuracy: 0.4826 - val_loss: 1.6611 - val_accuracy: 0.4440\n",
      "Epoch 364/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.6173 - accuracy: 0.4677 - val_loss: 1.7420 - val_accuracy: 0.4100\n",
      "Epoch 365/1000\n",
      "8108/8108 [==============================] - 0s 39us/step - loss: 1.6292 - accuracy: 0.4655 - val_loss: 1.6977 - val_accuracy: 0.4322\n",
      "Epoch 366/1000\n",
      "8108/8108 [==============================] - 0s 37us/step - loss: 1.6296 - accuracy: 0.4681 - val_loss: 1.7202 - val_accuracy: 0.4509\n",
      "Epoch 367/1000\n",
      "8108/8108 [==============================] - 0s 39us/step - loss: 1.6512 - accuracy: 0.4656 - val_loss: 1.6774 - val_accuracy: 0.4899\n",
      "Epoch 368/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 1.6151 - accuracy: 0.4722 - val_loss: 1.6596 - val_accuracy: 0.4716\n",
      "Epoch 369/1000\n",
      "8108/8108 [==============================] - 0s 39us/step - loss: 1.5846 - accuracy: 0.4884 - val_loss: 1.6737 - val_accuracy: 0.4514\n",
      "Epoch 370/1000\n",
      "8108/8108 [==============================] - 0s 36us/step - loss: 1.6009 - accuracy: 0.4679 - val_loss: 1.6869 - val_accuracy: 0.4489\n",
      "Epoch 371/1000\n",
      "8108/8108 [==============================] - 0s 37us/step - loss: 1.6056 - accuracy: 0.4705 - val_loss: 1.6788 - val_accuracy: 0.4613\n",
      "Epoch 372/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.6387 - accuracy: 0.4671 - val_loss: 1.7484 - val_accuracy: 0.4420\n",
      "Epoch 373/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 1.6010 - accuracy: 0.4761 - val_loss: 1.6656 - val_accuracy: 0.4647\n",
      "Epoch 374/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.6483 - accuracy: 0.4540 - val_loss: 1.7720 - val_accuracy: 0.4282\n",
      "Epoch 375/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 1.6281 - accuracy: 0.4639 - val_loss: 1.7098 - val_accuracy: 0.4110\n",
      "Epoch 376/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 1.6254 - accuracy: 0.4753 - val_loss: 1.6799 - val_accuracy: 0.4484\n",
      "Epoch 377/1000\n",
      "8108/8108 [==============================] - 0s 37us/step - loss: 1.5995 - accuracy: 0.4811 - val_loss: 1.6360 - val_accuracy: 0.4948\n",
      "Epoch 378/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.5992 - accuracy: 0.4874 - val_loss: 1.6316 - val_accuracy: 0.4958\n",
      "Epoch 379/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.5896 - accuracy: 0.4763 - val_loss: 1.6645 - val_accuracy: 0.4761\n",
      "Epoch 380/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.6179 - accuracy: 0.4644 - val_loss: 1.6669 - val_accuracy: 0.4558\n",
      "Epoch 381/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6147 - accuracy: 0.4720 - val_loss: 1.6538 - val_accuracy: 0.4864\n",
      "Epoch 382/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5991 - accuracy: 0.4852 - val_loss: 1.6521 - val_accuracy: 0.4924\n",
      "Epoch 383/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6206 - accuracy: 0.4657 - val_loss: 1.6439 - val_accuracy: 0.4736\n",
      "Epoch 384/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6010 - accuracy: 0.4742 - val_loss: 1.7003 - val_accuracy: 0.4292\n",
      "Epoch 385/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6044 - accuracy: 0.4722 - val_loss: 1.6190 - val_accuracy: 0.5096\n",
      "Epoch 386/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6119 - accuracy: 0.4795 - val_loss: 1.7069 - val_accuracy: 0.4188\n",
      "Epoch 387/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5895 - accuracy: 0.4734 - val_loss: 1.6907 - val_accuracy: 0.4415\n",
      "Epoch 388/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6264 - accuracy: 0.4628 - val_loss: 1.6325 - val_accuracy: 0.4958\n",
      "Epoch 389/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 1.6045 - accuracy: 0.4715 - val_loss: 1.6216 - val_accuracy: 0.4993\n",
      "Epoch 390/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.5904 - accuracy: 0.4912 - val_loss: 1.6927 - val_accuracy: 0.4401\n",
      "Epoch 391/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5939 - accuracy: 0.4709 - val_loss: 1.6553 - val_accuracy: 0.4652\n",
      "Epoch 392/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 1.6104 - accuracy: 0.4697 - val_loss: 1.7071 - val_accuracy: 0.4356\n",
      "Epoch 393/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5767 - accuracy: 0.4863 - val_loss: 1.7179 - val_accuracy: 0.4509\n",
      "Epoch 394/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5760 - accuracy: 0.4910 - val_loss: 1.7114 - val_accuracy: 0.4430\n",
      "Epoch 395/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6154 - accuracy: 0.4679 - val_loss: 1.6245 - val_accuracy: 0.4593\n",
      "Epoch 396/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.6034 - accuracy: 0.4753 - val_loss: 1.6806 - val_accuracy: 0.4746\n",
      "Epoch 397/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.6123 - accuracy: 0.4727 - val_loss: 1.7003 - val_accuracy: 0.4667\n",
      "Epoch 398/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6031 - accuracy: 0.4790 - val_loss: 1.7162 - val_accuracy: 0.4248\n",
      "Epoch 399/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5915 - accuracy: 0.4825 - val_loss: 1.6224 - val_accuracy: 0.4914\n",
      "Epoch 400/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5824 - accuracy: 0.4869 - val_loss: 1.6680 - val_accuracy: 0.4850\n",
      "Epoch 401/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.5755 - accuracy: 0.4887 - val_loss: 1.7124 - val_accuracy: 0.4381\n",
      "Epoch 402/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.6191 - accuracy: 0.4731 - val_loss: 1.6438 - val_accuracy: 0.4544\n",
      "Epoch 403/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 1.5716 - accuracy: 0.4878 - val_loss: 1.6346 - val_accuracy: 0.4869\n",
      "Epoch 404/1000\n",
      "8108/8108 [==============================] - 0s 48us/step - loss: 1.5676 - accuracy: 0.4817 - val_loss: 1.6469 - val_accuracy: 0.4854\n",
      "Epoch 405/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5927 - accuracy: 0.4719 - val_loss: 1.7191 - val_accuracy: 0.4480\n",
      "Epoch 406/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5835 - accuracy: 0.4832 - val_loss: 1.7283 - val_accuracy: 0.4238\n",
      "Epoch 407/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5877 - accuracy: 0.4763 - val_loss: 1.6316 - val_accuracy: 0.4509\n",
      "Epoch 408/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5998 - accuracy: 0.4709 - val_loss: 1.7366 - val_accuracy: 0.4539\n",
      "Epoch 409/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.6084 - accuracy: 0.4710 - val_loss: 1.6504 - val_accuracy: 0.4702\n",
      "Epoch 410/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5850 - accuracy: 0.4750 - val_loss: 1.5975 - val_accuracy: 0.5136\n",
      "Epoch 411/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5786 - accuracy: 0.4805 - val_loss: 1.7103 - val_accuracy: 0.4509\n",
      "Epoch 412/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6000 - accuracy: 0.4793 - val_loss: 1.7111 - val_accuracy: 0.4174\n",
      "Epoch 413/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5804 - accuracy: 0.4824 - val_loss: 1.6367 - val_accuracy: 0.4706\n",
      "Epoch 414/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5952 - accuracy: 0.4703 - val_loss: 1.6518 - val_accuracy: 0.4430\n",
      "Epoch 415/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5834 - accuracy: 0.4756 - val_loss: 1.6239 - val_accuracy: 0.5215\n",
      "Epoch 416/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6007 - accuracy: 0.4731 - val_loss: 1.6301 - val_accuracy: 0.4835\n",
      "Epoch 417/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5887 - accuracy: 0.4858 - val_loss: 1.6709 - val_accuracy: 0.4430\n",
      "Epoch 418/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5882 - accuracy: 0.4773 - val_loss: 1.6230 - val_accuracy: 0.4623\n",
      "Epoch 419/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5871 - accuracy: 0.4852 - val_loss: 1.6126 - val_accuracy: 0.4835\n",
      "Epoch 420/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5709 - accuracy: 0.4842 - val_loss: 1.7120 - val_accuracy: 0.4366\n",
      "Epoch 421/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5665 - accuracy: 0.4836 - val_loss: 1.6916 - val_accuracy: 0.4484\n",
      "Epoch 422/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5708 - accuracy: 0.4890 - val_loss: 1.7243 - val_accuracy: 0.4524\n",
      "Epoch 423/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5916 - accuracy: 0.4714 - val_loss: 1.6435 - val_accuracy: 0.4588\n",
      "Epoch 424/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5630 - accuracy: 0.4889 - val_loss: 1.7041 - val_accuracy: 0.4381\n",
      "Epoch 425/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.6021 - accuracy: 0.4803 - val_loss: 1.6935 - val_accuracy: 0.4381\n",
      "Epoch 426/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5744 - accuracy: 0.4813 - val_loss: 1.6233 - val_accuracy: 0.4509\n",
      "Epoch 427/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5847 - accuracy: 0.4788 - val_loss: 1.6120 - val_accuracy: 0.4879\n",
      "Epoch 428/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5818 - accuracy: 0.4716 - val_loss: 1.6388 - val_accuracy: 0.4790\n",
      "Epoch 429/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5569 - accuracy: 0.4981 - val_loss: 1.6926 - val_accuracy: 0.5081\n",
      "Epoch 430/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5903 - accuracy: 0.4752 - val_loss: 1.6832 - val_accuracy: 0.4588\n",
      "Epoch 431/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5666 - accuracy: 0.4879 - val_loss: 1.5713 - val_accuracy: 0.5111\n",
      "Epoch 432/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5774 - accuracy: 0.4745 - val_loss: 1.6491 - val_accuracy: 0.4711\n",
      "Epoch 433/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5866 - accuracy: 0.4759 - val_loss: 1.6112 - val_accuracy: 0.5525\n",
      "Epoch 434/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5705 - accuracy: 0.4772 - val_loss: 1.7072 - val_accuracy: 0.4361\n",
      "Epoch 435/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5829 - accuracy: 0.4774 - val_loss: 1.6583 - val_accuracy: 0.4667\n",
      "Epoch 436/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5774 - accuracy: 0.4763 - val_loss: 1.6622 - val_accuracy: 0.4544\n",
      "Epoch 437/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5620 - accuracy: 0.4896 - val_loss: 1.6544 - val_accuracy: 0.4415\n",
      "Epoch 438/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5745 - accuracy: 0.4879 - val_loss: 1.6809 - val_accuracy: 0.4534\n",
      "Epoch 439/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5652 - accuracy: 0.4782 - val_loss: 1.6596 - val_accuracy: 0.4549\n",
      "Epoch 440/1000\n",
      "8108/8108 [==============================] - 0s 39us/step - loss: 1.5763 - accuracy: 0.4763 - val_loss: 1.5678 - val_accuracy: 0.5096\n",
      "Epoch 441/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8108/8108 [==============================] - 0s 36us/step - loss: 1.5782 - accuracy: 0.4794 - val_loss: 1.6179 - val_accuracy: 0.4780\n",
      "Epoch 442/1000\n",
      "8108/8108 [==============================] - 0s 37us/step - loss: 1.5671 - accuracy: 0.4793 - val_loss: 1.6261 - val_accuracy: 0.4968\n",
      "Epoch 443/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 1.5656 - accuracy: 0.4873 - val_loss: 1.6284 - val_accuracy: 0.4514\n",
      "Epoch 444/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.5792 - accuracy: 0.4810 - val_loss: 1.6391 - val_accuracy: 0.4618\n",
      "Epoch 445/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5517 - accuracy: 0.4919 - val_loss: 1.6055 - val_accuracy: 0.4874\n",
      "Epoch 446/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.5622 - accuracy: 0.4837 - val_loss: 1.6670 - val_accuracy: 0.4549\n",
      "Epoch 447/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.5729 - accuracy: 0.4779 - val_loss: 1.7319 - val_accuracy: 0.4460\n",
      "Epoch 448/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.6072 - accuracy: 0.4678 - val_loss: 1.6791 - val_accuracy: 0.4297\n",
      "Epoch 449/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.5670 - accuracy: 0.4840 - val_loss: 1.5632 - val_accuracy: 0.5057\n",
      "Epoch 450/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.5401 - accuracy: 0.4943 - val_loss: 1.6640 - val_accuracy: 0.4854\n",
      "Epoch 451/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 1.5515 - accuracy: 0.4878 - val_loss: 1.7036 - val_accuracy: 0.4381\n",
      "Epoch 452/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 1.5658 - accuracy: 0.4832 - val_loss: 1.6485 - val_accuracy: 0.4267\n",
      "Epoch 453/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 1.5572 - accuracy: 0.4831 - val_loss: 1.6422 - val_accuracy: 0.4835\n",
      "Epoch 454/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.5393 - accuracy: 0.4931 - val_loss: 1.6856 - val_accuracy: 0.4420\n",
      "Epoch 455/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.5499 - accuracy: 0.4836 - val_loss: 1.5943 - val_accuracy: 0.4884\n",
      "Epoch 456/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.5469 - accuracy: 0.4877 - val_loss: 1.6386 - val_accuracy: 0.4420\n",
      "Epoch 457/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.5577 - accuracy: 0.4788 - val_loss: 1.6833 - val_accuracy: 0.4470\n",
      "Epoch 458/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5860 - accuracy: 0.4806 - val_loss: 1.6318 - val_accuracy: 0.5249\n",
      "Epoch 459/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.5516 - accuracy: 0.4932 - val_loss: 1.6033 - val_accuracy: 0.4889\n",
      "Epoch 460/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.5401 - accuracy: 0.4922 - val_loss: 1.6017 - val_accuracy: 0.4983\n",
      "Epoch 461/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.5435 - accuracy: 0.4880 - val_loss: 1.5948 - val_accuracy: 0.4948\n",
      "Epoch 462/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5512 - accuracy: 0.4793 - val_loss: 1.5774 - val_accuracy: 0.4884\n",
      "Epoch 463/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5691 - accuracy: 0.4773 - val_loss: 1.6856 - val_accuracy: 0.4179\n",
      "Epoch 464/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5565 - accuracy: 0.4783 - val_loss: 1.5838 - val_accuracy: 0.5136\n",
      "Epoch 465/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5518 - accuracy: 0.4927 - val_loss: 1.5976 - val_accuracy: 0.4810\n",
      "Epoch 466/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5607 - accuracy: 0.4806 - val_loss: 1.5999 - val_accuracy: 0.4810\n",
      "Epoch 467/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5406 - accuracy: 0.4928 - val_loss: 1.6306 - val_accuracy: 0.4401\n",
      "Epoch 468/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5469 - accuracy: 0.4927 - val_loss: 1.5997 - val_accuracy: 0.4889\n",
      "Epoch 469/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5514 - accuracy: 0.4930 - val_loss: 1.6656 - val_accuracy: 0.4706\n",
      "Epoch 470/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5799 - accuracy: 0.4736 - val_loss: 1.6556 - val_accuracy: 0.4785\n",
      "Epoch 471/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.5663 - accuracy: 0.4826 - val_loss: 1.5754 - val_accuracy: 0.4790\n",
      "Epoch 472/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.5489 - accuracy: 0.4863 - val_loss: 1.6137 - val_accuracy: 0.4642\n",
      "Epoch 473/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5406 - accuracy: 0.4905 - val_loss: 1.6084 - val_accuracy: 0.4608\n",
      "Epoch 474/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5422 - accuracy: 0.4911 - val_loss: 1.6078 - val_accuracy: 0.4924\n",
      "Epoch 475/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5552 - accuracy: 0.4774 - val_loss: 1.6178 - val_accuracy: 0.4583\n",
      "Epoch 476/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.5480 - accuracy: 0.4894 - val_loss: 1.5863 - val_accuracy: 0.4711\n",
      "Epoch 477/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.5261 - accuracy: 0.4941 - val_loss: 1.6150 - val_accuracy: 0.4795\n",
      "Epoch 478/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.5625 - accuracy: 0.4896 - val_loss: 1.6009 - val_accuracy: 0.5422\n",
      "Epoch 479/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.5409 - accuracy: 0.4829 - val_loss: 1.5967 - val_accuracy: 0.4731\n",
      "Epoch 480/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.5506 - accuracy: 0.4747 - val_loss: 1.6049 - val_accuracy: 0.4702\n",
      "Epoch 481/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.5203 - accuracy: 0.4988 - val_loss: 1.6013 - val_accuracy: 0.4835\n",
      "Epoch 482/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5455 - accuracy: 0.4814 - val_loss: 1.6451 - val_accuracy: 0.4706\n",
      "Epoch 483/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5528 - accuracy: 0.4799 - val_loss: 1.6373 - val_accuracy: 0.4692\n",
      "Epoch 484/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5780 - accuracy: 0.4776 - val_loss: 1.7020 - val_accuracy: 0.4287\n",
      "Epoch 485/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5556 - accuracy: 0.4783 - val_loss: 1.6937 - val_accuracy: 0.4558\n",
      "Epoch 486/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5542 - accuracy: 0.4880 - val_loss: 1.7396 - val_accuracy: 0.4179\n",
      "Epoch 487/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5538 - accuracy: 0.4810 - val_loss: 1.6203 - val_accuracy: 0.4662\n",
      "Epoch 488/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5146 - accuracy: 0.5009 - val_loss: 1.6445 - val_accuracy: 0.4642\n",
      "Epoch 489/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5423 - accuracy: 0.4944 - val_loss: 1.6184 - val_accuracy: 0.4573\n",
      "Epoch 490/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5430 - accuracy: 0.4935 - val_loss: 1.6175 - val_accuracy: 0.4746\n",
      "Epoch 491/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5420 - accuracy: 0.4925 - val_loss: 1.6674 - val_accuracy: 0.4588\n",
      "Epoch 492/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5191 - accuracy: 0.5023 - val_loss: 1.5951 - val_accuracy: 0.4859\n",
      "Epoch 493/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5384 - accuracy: 0.4899 - val_loss: 1.6919 - val_accuracy: 0.4341\n",
      "Epoch 494/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5587 - accuracy: 0.4759 - val_loss: 1.6785 - val_accuracy: 0.4302\n",
      "Epoch 495/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5367 - accuracy: 0.4796 - val_loss: 1.5887 - val_accuracy: 0.4928\n",
      "Epoch 496/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5472 - accuracy: 0.4942 - val_loss: 1.5909 - val_accuracy: 0.4588\n",
      "Epoch 497/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5267 - accuracy: 0.4924 - val_loss: 1.6172 - val_accuracy: 0.4815\n",
      "Epoch 498/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5360 - accuracy: 0.4867 - val_loss: 1.6225 - val_accuracy: 0.4662\n",
      "Epoch 499/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5236 - accuracy: 0.4928 - val_loss: 1.6645 - val_accuracy: 0.4455\n",
      "Epoch 500/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5257 - accuracy: 0.4905 - val_loss: 1.5906 - val_accuracy: 0.4928\n",
      "Epoch 501/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5262 - accuracy: 0.4866 - val_loss: 1.6315 - val_accuracy: 0.4800\n",
      "Epoch 502/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5334 - accuracy: 0.4936 - val_loss: 1.5868 - val_accuracy: 0.4682\n",
      "Epoch 503/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5443 - accuracy: 0.4827 - val_loss: 1.6212 - val_accuracy: 0.4603\n",
      "Epoch 504/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5486 - accuracy: 0.4843 - val_loss: 1.5975 - val_accuracy: 0.4869\n",
      "Epoch 505/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5204 - accuracy: 0.4910 - val_loss: 1.5759 - val_accuracy: 0.4692\n",
      "Epoch 506/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5257 - accuracy: 0.4943 - val_loss: 1.6288 - val_accuracy: 0.4795\n",
      "Epoch 507/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5329 - accuracy: 0.4827 - val_loss: 1.5984 - val_accuracy: 0.4790\n",
      "Epoch 508/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5161 - accuracy: 0.4967 - val_loss: 1.5830 - val_accuracy: 0.4805\n",
      "Epoch 509/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5381 - accuracy: 0.4917 - val_loss: 1.5650 - val_accuracy: 0.5057\n",
      "Epoch 510/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5264 - accuracy: 0.4914 - val_loss: 1.5688 - val_accuracy: 0.4953\n",
      "Epoch 511/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5018 - accuracy: 0.5081 - val_loss: 1.6699 - val_accuracy: 0.4716\n",
      "Epoch 512/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5481 - accuracy: 0.4927 - val_loss: 1.6369 - val_accuracy: 0.4687\n",
      "Epoch 513/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5230 - accuracy: 0.5030 - val_loss: 1.5744 - val_accuracy: 0.4652\n",
      "Epoch 514/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5225 - accuracy: 0.4988 - val_loss: 1.6062 - val_accuracy: 0.4415\n",
      "Epoch 515/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5378 - accuracy: 0.4833 - val_loss: 1.5488 - val_accuracy: 0.4904\n",
      "Epoch 516/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5348 - accuracy: 0.4843 - val_loss: 1.6801 - val_accuracy: 0.4484\n",
      "Epoch 517/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5127 - accuracy: 0.5009 - val_loss: 1.5727 - val_accuracy: 0.4983\n",
      "Epoch 518/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5073 - accuracy: 0.4951 - val_loss: 1.6143 - val_accuracy: 0.4672\n",
      "Epoch 519/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5423 - accuracy: 0.4956 - val_loss: 1.5509 - val_accuracy: 0.4879\n",
      "Epoch 520/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5278 - accuracy: 0.4916 - val_loss: 1.5177 - val_accuracy: 0.5146\n",
      "Epoch 521/1000\n",
      "8108/8108 [==============================] - 0s 36us/step - loss: 1.5160 - accuracy: 0.4948 - val_loss: 1.6076 - val_accuracy: 0.4766\n",
      "Epoch 522/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.5176 - accuracy: 0.4930 - val_loss: 1.6416 - val_accuracy: 0.4598\n",
      "Epoch 523/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.5174 - accuracy: 0.5033 - val_loss: 1.5571 - val_accuracy: 0.4667\n",
      "Epoch 524/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.5140 - accuracy: 0.4981 - val_loss: 1.6429 - val_accuracy: 0.4628\n",
      "Epoch 525/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5254 - accuracy: 0.4928 - val_loss: 1.6084 - val_accuracy: 0.4307\n",
      "Epoch 526/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5036 - accuracy: 0.4957 - val_loss: 1.6334 - val_accuracy: 0.4401\n",
      "Epoch 527/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5364 - accuracy: 0.4921 - val_loss: 1.5884 - val_accuracy: 0.4346\n",
      "Epoch 528/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5227 - accuracy: 0.4932 - val_loss: 1.7114 - val_accuracy: 0.4223\n",
      "Epoch 529/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5246 - accuracy: 0.4996 - val_loss: 1.6087 - val_accuracy: 0.4455\n",
      "Epoch 530/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5325 - accuracy: 0.4843 - val_loss: 1.5628 - val_accuracy: 0.4938\n",
      "Epoch 531/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5255 - accuracy: 0.4850 - val_loss: 1.5657 - val_accuracy: 0.4504\n",
      "Epoch 532/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5072 - accuracy: 0.5074 - val_loss: 1.6185 - val_accuracy: 0.4711\n",
      "Epoch 533/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5285 - accuracy: 0.4952 - val_loss: 1.6307 - val_accuracy: 0.4914\n",
      "Epoch 534/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5284 - accuracy: 0.4898 - val_loss: 1.6131 - val_accuracy: 0.4706\n",
      "Epoch 535/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5090 - accuracy: 0.4961 - val_loss: 1.5820 - val_accuracy: 0.4854\n",
      "Epoch 536/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5064 - accuracy: 0.4986 - val_loss: 1.6032 - val_accuracy: 0.4731\n",
      "Epoch 537/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4995 - accuracy: 0.4991 - val_loss: 1.5996 - val_accuracy: 0.4889\n",
      "Epoch 538/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5107 - accuracy: 0.4969 - val_loss: 1.5710 - val_accuracy: 0.4420\n",
      "Epoch 539/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5091 - accuracy: 0.4903 - val_loss: 1.5608 - val_accuracy: 0.5442\n",
      "Epoch 540/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4897 - accuracy: 0.4989 - val_loss: 1.6029 - val_accuracy: 0.4573\n",
      "Epoch 541/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5072 - accuracy: 0.4965 - val_loss: 1.5574 - val_accuracy: 0.4884\n",
      "Epoch 542/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5426 - accuracy: 0.4799 - val_loss: 1.6221 - val_accuracy: 0.4489\n",
      "Epoch 543/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5181 - accuracy: 0.4894 - val_loss: 1.6002 - val_accuracy: 0.4637\n",
      "Epoch 544/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5089 - accuracy: 0.5015 - val_loss: 1.5278 - val_accuracy: 0.5007\n",
      "Epoch 545/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5063 - accuracy: 0.4968 - val_loss: 1.6616 - val_accuracy: 0.4716\n",
      "Epoch 546/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5316 - accuracy: 0.4985 - val_loss: 1.5164 - val_accuracy: 0.5190\n",
      "Epoch 547/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5427 - accuracy: 0.4837 - val_loss: 1.5254 - val_accuracy: 0.4869\n",
      "Epoch 548/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5218 - accuracy: 0.4932 - val_loss: 1.6051 - val_accuracy: 0.4805\n",
      "Epoch 549/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5104 - accuracy: 0.4981 - val_loss: 1.5326 - val_accuracy: 0.5155\n",
      "Epoch 550/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4903 - accuracy: 0.5062 - val_loss: 1.5514 - val_accuracy: 0.4850\n",
      "Epoch 551/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5063 - accuracy: 0.4989 - val_loss: 1.6437 - val_accuracy: 0.4361\n",
      "Epoch 552/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5031 - accuracy: 0.5090 - val_loss: 1.6111 - val_accuracy: 0.4618\n",
      "Epoch 553/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5274 - accuracy: 0.4931 - val_loss: 1.6088 - val_accuracy: 0.4711\n",
      "Epoch 554/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5123 - accuracy: 0.4920 - val_loss: 1.6064 - val_accuracy: 0.4391\n",
      "Epoch 555/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5014 - accuracy: 0.5042 - val_loss: 1.5964 - val_accuracy: 0.5037\n",
      "Epoch 556/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5066 - accuracy: 0.5001 - val_loss: 1.6189 - val_accuracy: 0.4381\n",
      "Epoch 557/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5157 - accuracy: 0.4900 - val_loss: 1.6195 - val_accuracy: 0.4558\n",
      "Epoch 558/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.5074 - accuracy: 0.4988 - val_loss: 1.5113 - val_accuracy: 0.5062\n",
      "Epoch 559/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5196 - accuracy: 0.4924 - val_loss: 1.6342 - val_accuracy: 0.4262\n",
      "Epoch 560/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.5030 - accuracy: 0.4983 - val_loss: 1.5888 - val_accuracy: 0.4692\n",
      "Epoch 561/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.4869 - accuracy: 0.5060 - val_loss: 1.5076 - val_accuracy: 0.5343\n",
      "Epoch 562/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.4916 - accuracy: 0.5006 - val_loss: 1.5385 - val_accuracy: 0.4928\n",
      "Epoch 563/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.4995 - accuracy: 0.5054 - val_loss: 1.5839 - val_accuracy: 0.4805\n",
      "Epoch 564/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.5207 - accuracy: 0.4841 - val_loss: 1.5521 - val_accuracy: 0.4840\n",
      "Epoch 565/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.5163 - accuracy: 0.4895 - val_loss: 1.5737 - val_accuracy: 0.4662\n",
      "Epoch 566/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4957 - accuracy: 0.5085 - val_loss: 1.6290 - val_accuracy: 0.4706\n",
      "Epoch 567/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5000 - accuracy: 0.4943 - val_loss: 1.5724 - val_accuracy: 0.4598\n",
      "Epoch 568/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4914 - accuracy: 0.4998 - val_loss: 1.5272 - val_accuracy: 0.4869\n",
      "Epoch 569/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5022 - accuracy: 0.4961 - val_loss: 1.5539 - val_accuracy: 0.4859\n",
      "Epoch 570/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5062 - accuracy: 0.5025 - val_loss: 1.5686 - val_accuracy: 0.4805\n",
      "Epoch 571/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4997 - accuracy: 0.4975 - val_loss: 1.6741 - val_accuracy: 0.4238\n",
      "Epoch 572/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4980 - accuracy: 0.4930 - val_loss: 1.5665 - val_accuracy: 0.4716\n",
      "Epoch 573/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5011 - accuracy: 0.4974 - val_loss: 1.5565 - val_accuracy: 0.4850\n",
      "Epoch 574/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4983 - accuracy: 0.4993 - val_loss: 1.5851 - val_accuracy: 0.4721\n",
      "Epoch 575/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4899 - accuracy: 0.5052 - val_loss: 1.5207 - val_accuracy: 0.4968\n",
      "Epoch 576/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4929 - accuracy: 0.5090 - val_loss: 1.5803 - val_accuracy: 0.4509\n",
      "Epoch 577/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4963 - accuracy: 0.5012 - val_loss: 1.5831 - val_accuracy: 0.4756\n",
      "Epoch 578/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5040 - accuracy: 0.4979 - val_loss: 1.6599 - val_accuracy: 0.4568\n",
      "Epoch 579/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4916 - accuracy: 0.5026 - val_loss: 1.5534 - val_accuracy: 0.4825\n",
      "Epoch 580/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4969 - accuracy: 0.4980 - val_loss: 1.5600 - val_accuracy: 0.4835\n",
      "Epoch 581/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4916 - accuracy: 0.5023 - val_loss: 1.5045 - val_accuracy: 0.5239\n",
      "Epoch 582/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5000 - accuracy: 0.4944 - val_loss: 1.5874 - val_accuracy: 0.4652\n",
      "Epoch 583/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4868 - accuracy: 0.5010 - val_loss: 1.5907 - val_accuracy: 0.4519\n",
      "Epoch 584/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4766 - accuracy: 0.5030 - val_loss: 1.5857 - val_accuracy: 0.4840\n",
      "Epoch 585/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4922 - accuracy: 0.4964 - val_loss: 1.5704 - val_accuracy: 0.4672\n",
      "Epoch 586/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.5037 - accuracy: 0.4899 - val_loss: 1.6409 - val_accuracy: 0.4544\n",
      "Epoch 587/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4864 - accuracy: 0.4991 - val_loss: 1.5075 - val_accuracy: 0.5111\n",
      "Epoch 588/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4749 - accuracy: 0.5060 - val_loss: 1.5841 - val_accuracy: 0.4884\n",
      "Epoch 589/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5187 - accuracy: 0.4879 - val_loss: 1.5691 - val_accuracy: 0.4978\n",
      "Epoch 590/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4782 - accuracy: 0.5007 - val_loss: 1.5337 - val_accuracy: 0.4741\n",
      "Epoch 591/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4855 - accuracy: 0.5078 - val_loss: 1.4779 - val_accuracy: 0.5476\n",
      "Epoch 592/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4650 - accuracy: 0.5117 - val_loss: 1.6068 - val_accuracy: 0.4662\n",
      "Epoch 593/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.5090 - accuracy: 0.4798 - val_loss: 1.5256 - val_accuracy: 0.4741\n",
      "Epoch 594/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4742 - accuracy: 0.5067 - val_loss: 1.5434 - val_accuracy: 0.4726\n",
      "Epoch 595/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4677 - accuracy: 0.5081 - val_loss: 1.5539 - val_accuracy: 0.4746\n",
      "Epoch 596/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4743 - accuracy: 0.5079 - val_loss: 1.5380 - val_accuracy: 0.4613\n",
      "Epoch 597/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4860 - accuracy: 0.5025 - val_loss: 1.5363 - val_accuracy: 0.4879\n",
      "Epoch 598/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4755 - accuracy: 0.5086 - val_loss: 1.6177 - val_accuracy: 0.4465\n",
      "Epoch 599/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4849 - accuracy: 0.5002 - val_loss: 1.5020 - val_accuracy: 0.4924\n",
      "Epoch 600/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.5012 - accuracy: 0.4937 - val_loss: 1.6463 - val_accuracy: 0.4628\n",
      "Epoch 601/1000\n",
      "8108/8108 [==============================] - 0s 39us/step - loss: 1.4896 - accuracy: 0.5019 - val_loss: 1.5305 - val_accuracy: 0.4771\n",
      "Epoch 602/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.4609 - accuracy: 0.5136 - val_loss: 1.5032 - val_accuracy: 0.4968\n",
      "Epoch 603/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5040 - accuracy: 0.4986 - val_loss: 1.5645 - val_accuracy: 0.4776\n",
      "Epoch 604/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4647 - accuracy: 0.5079 - val_loss: 1.5926 - val_accuracy: 0.4785\n",
      "Epoch 605/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4681 - accuracy: 0.5064 - val_loss: 1.5444 - val_accuracy: 0.5027\n",
      "Epoch 606/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4948 - accuracy: 0.4917 - val_loss: 1.4849 - val_accuracy: 0.5057\n",
      "Epoch 607/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4717 - accuracy: 0.5042 - val_loss: 1.4942 - val_accuracy: 0.4953\n",
      "Epoch 608/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4898 - accuracy: 0.5091 - val_loss: 1.5295 - val_accuracy: 0.5126\n",
      "Epoch 609/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4650 - accuracy: 0.5165 - val_loss: 1.5544 - val_accuracy: 0.4504\n",
      "Epoch 610/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4857 - accuracy: 0.4973 - val_loss: 1.5787 - val_accuracy: 0.4598\n",
      "Epoch 611/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4783 - accuracy: 0.4951 - val_loss: 1.5405 - val_accuracy: 0.4800\n",
      "Epoch 612/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4872 - accuracy: 0.4981 - val_loss: 1.5649 - val_accuracy: 0.5136\n",
      "Epoch 613/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4833 - accuracy: 0.5053 - val_loss: 1.5754 - val_accuracy: 0.4519\n",
      "Epoch 614/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4907 - accuracy: 0.4972 - val_loss: 1.5949 - val_accuracy: 0.4776\n",
      "Epoch 615/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4726 - accuracy: 0.5035 - val_loss: 1.5868 - val_accuracy: 0.4692\n",
      "Epoch 616/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4813 - accuracy: 0.5017 - val_loss: 1.5151 - val_accuracy: 0.4993\n",
      "Epoch 617/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4702 - accuracy: 0.5080 - val_loss: 1.5075 - val_accuracy: 0.4924\n",
      "Epoch 618/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4510 - accuracy: 0.5180 - val_loss: 1.5172 - val_accuracy: 0.4800\n",
      "Epoch 619/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.4702 - accuracy: 0.5023 - val_loss: 1.5626 - val_accuracy: 0.5042\n",
      "Epoch 620/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4781 - accuracy: 0.5049 - val_loss: 1.5353 - val_accuracy: 0.4721\n",
      "Epoch 621/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.4731 - accuracy: 0.4990 - val_loss: 1.4991 - val_accuracy: 0.5150\n",
      "Epoch 622/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4660 - accuracy: 0.5015 - val_loss: 1.5556 - val_accuracy: 0.4652\n",
      "Epoch 623/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4832 - accuracy: 0.4910 - val_loss: 1.5133 - val_accuracy: 0.4963\n",
      "Epoch 624/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4599 - accuracy: 0.5039 - val_loss: 1.5210 - val_accuracy: 0.4874\n",
      "Epoch 625/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4879 - accuracy: 0.5021 - val_loss: 1.5814 - val_accuracy: 0.4751\n",
      "Epoch 626/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4878 - accuracy: 0.5052 - val_loss: 1.5561 - val_accuracy: 0.4785\n",
      "Epoch 627/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4637 - accuracy: 0.5111 - val_loss: 1.4918 - val_accuracy: 0.4869\n",
      "Epoch 628/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4536 - accuracy: 0.5104 - val_loss: 1.5276 - val_accuracy: 0.5042\n",
      "Epoch 629/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4607 - accuracy: 0.5128 - val_loss: 1.5203 - val_accuracy: 0.4933\n",
      "Epoch 630/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4683 - accuracy: 0.4956 - val_loss: 1.5742 - val_accuracy: 0.4554\n",
      "Epoch 631/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.5042 - accuracy: 0.4884 - val_loss: 1.5585 - val_accuracy: 0.4662\n",
      "Epoch 632/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4871 - accuracy: 0.4938 - val_loss: 1.5161 - val_accuracy: 0.4993\n",
      "Epoch 633/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4834 - accuracy: 0.5000 - val_loss: 1.4985 - val_accuracy: 0.5210\n",
      "Epoch 634/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4560 - accuracy: 0.5155 - val_loss: 1.4937 - val_accuracy: 0.5210\n",
      "Epoch 635/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4767 - accuracy: 0.5030 - val_loss: 1.4809 - val_accuracy: 0.5057\n",
      "Epoch 636/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4631 - accuracy: 0.5086 - val_loss: 1.5247 - val_accuracy: 0.4889\n",
      "Epoch 637/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4717 - accuracy: 0.4964 - val_loss: 1.5049 - val_accuracy: 0.5096\n",
      "Epoch 638/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4647 - accuracy: 0.5023 - val_loss: 1.5385 - val_accuracy: 0.4928\n",
      "Epoch 639/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4690 - accuracy: 0.5048 - val_loss: 1.5015 - val_accuracy: 0.5190\n",
      "Epoch 640/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.4675 - accuracy: 0.5152 - val_loss: 1.5392 - val_accuracy: 0.4884\n",
      "Epoch 641/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.4536 - accuracy: 0.5093 - val_loss: 1.4974 - val_accuracy: 0.4998\n",
      "Epoch 642/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4618 - accuracy: 0.5080 - val_loss: 1.5388 - val_accuracy: 0.5096\n",
      "Epoch 643/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4491 - accuracy: 0.5120 - val_loss: 1.5190 - val_accuracy: 0.5239\n",
      "Epoch 644/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.4680 - accuracy: 0.5125 - val_loss: 1.4694 - val_accuracy: 0.5417\n",
      "Epoch 645/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4488 - accuracy: 0.5141 - val_loss: 1.5823 - val_accuracy: 0.4603\n",
      "Epoch 646/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4702 - accuracy: 0.4949 - val_loss: 1.5047 - val_accuracy: 0.5279\n",
      "Epoch 647/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4677 - accuracy: 0.5014 - val_loss: 1.5261 - val_accuracy: 0.4766\n",
      "Epoch 648/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4537 - accuracy: 0.5118 - val_loss: 1.5487 - val_accuracy: 0.4914\n",
      "Epoch 649/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4624 - accuracy: 0.5125 - val_loss: 1.4898 - val_accuracy: 0.5131\n",
      "Epoch 650/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4607 - accuracy: 0.5116 - val_loss: 1.5330 - val_accuracy: 0.4884\n",
      "Epoch 651/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4613 - accuracy: 0.5117 - val_loss: 1.5607 - val_accuracy: 0.4835\n",
      "Epoch 652/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4605 - accuracy: 0.5100 - val_loss: 1.5731 - val_accuracy: 0.4593\n",
      "Epoch 653/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4837 - accuracy: 0.4989 - val_loss: 1.5575 - val_accuracy: 0.4948\n",
      "Epoch 654/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4584 - accuracy: 0.5090 - val_loss: 1.4872 - val_accuracy: 0.5067\n",
      "Epoch 655/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4868 - accuracy: 0.5004 - val_loss: 1.5308 - val_accuracy: 0.4869\n",
      "Epoch 656/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4672 - accuracy: 0.5011 - val_loss: 1.5757 - val_accuracy: 0.4356\n",
      "Epoch 657/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4460 - accuracy: 0.5236 - val_loss: 1.5147 - val_accuracy: 0.5017\n",
      "Epoch 658/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4476 - accuracy: 0.5147 - val_loss: 1.4569 - val_accuracy: 0.4958\n",
      "Epoch 659/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4648 - accuracy: 0.4927 - val_loss: 1.5134 - val_accuracy: 0.4746\n",
      "Epoch 660/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4387 - accuracy: 0.5134 - val_loss: 1.5069 - val_accuracy: 0.4628\n",
      "Epoch 661/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4336 - accuracy: 0.5131 - val_loss: 1.5413 - val_accuracy: 0.4317\n",
      "Epoch 662/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4531 - accuracy: 0.4999 - val_loss: 1.5079 - val_accuracy: 0.4790\n",
      "Epoch 663/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4496 - accuracy: 0.5127 - val_loss: 1.5180 - val_accuracy: 0.5062\n",
      "Epoch 664/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4426 - accuracy: 0.5133 - val_loss: 1.5992 - val_accuracy: 0.4608\n",
      "Epoch 665/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4683 - accuracy: 0.5001 - val_loss: 1.5404 - val_accuracy: 0.4721\n",
      "Epoch 666/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4391 - accuracy: 0.5184 - val_loss: 1.5297 - val_accuracy: 0.5096\n",
      "Epoch 667/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4494 - accuracy: 0.5117 - val_loss: 1.4903 - val_accuracy: 0.4943\n",
      "Epoch 668/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4578 - accuracy: 0.5059 - val_loss: 1.5193 - val_accuracy: 0.4909\n",
      "Epoch 669/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4413 - accuracy: 0.5148 - val_loss: 1.5609 - val_accuracy: 0.4632\n",
      "Epoch 670/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4588 - accuracy: 0.5038 - val_loss: 1.4906 - val_accuracy: 0.5150\n",
      "Epoch 671/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4680 - accuracy: 0.4989 - val_loss: 1.4965 - val_accuracy: 0.5062\n",
      "Epoch 672/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4585 - accuracy: 0.5035 - val_loss: 1.4904 - val_accuracy: 0.5294\n",
      "Epoch 673/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4608 - accuracy: 0.5060 - val_loss: 1.5142 - val_accuracy: 0.5027\n",
      "Epoch 674/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.4370 - accuracy: 0.5106 - val_loss: 1.5317 - val_accuracy: 0.4859\n",
      "Epoch 675/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.4452 - accuracy: 0.5085 - val_loss: 1.5107 - val_accuracy: 0.4598\n",
      "Epoch 676/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.4436 - accuracy: 0.5091 - val_loss: 1.4991 - val_accuracy: 0.4958\n",
      "Epoch 677/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.4313 - accuracy: 0.5236 - val_loss: 1.4813 - val_accuracy: 0.5076\n",
      "Epoch 678/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.4342 - accuracy: 0.5224 - val_loss: 1.5632 - val_accuracy: 0.4514\n",
      "Epoch 679/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.4404 - accuracy: 0.5146 - val_loss: 1.5518 - val_accuracy: 0.4904\n",
      "Epoch 680/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4492 - accuracy: 0.5106 - val_loss: 1.5563 - val_accuracy: 0.4425\n",
      "Epoch 681/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4583 - accuracy: 0.5085 - val_loss: 1.4782 - val_accuracy: 0.4943\n",
      "Epoch 682/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4308 - accuracy: 0.5287 - val_loss: 1.5138 - val_accuracy: 0.4830\n",
      "Epoch 683/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4527 - accuracy: 0.5088 - val_loss: 1.4853 - val_accuracy: 0.4928\n",
      "Epoch 684/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4675 - accuracy: 0.4994 - val_loss: 1.6053 - val_accuracy: 0.4470\n",
      "Epoch 685/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4808 - accuracy: 0.5017 - val_loss: 1.4591 - val_accuracy: 0.4968\n",
      "Epoch 686/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4485 - accuracy: 0.5126 - val_loss: 1.5389 - val_accuracy: 0.4854\n",
      "Epoch 687/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4297 - accuracy: 0.5233 - val_loss: 1.4974 - val_accuracy: 0.4820\n",
      "Epoch 688/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4558 - accuracy: 0.5068 - val_loss: 1.5353 - val_accuracy: 0.4711\n",
      "Epoch 689/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4341 - accuracy: 0.5093 - val_loss: 1.5413 - val_accuracy: 0.4578\n",
      "Epoch 690/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4339 - accuracy: 0.5121 - val_loss: 1.5407 - val_accuracy: 0.4948\n",
      "Epoch 691/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4304 - accuracy: 0.5201 - val_loss: 1.5387 - val_accuracy: 0.4706\n",
      "Epoch 692/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4522 - accuracy: 0.5070 - val_loss: 1.4752 - val_accuracy: 0.5042\n",
      "Epoch 693/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4576 - accuracy: 0.5021 - val_loss: 1.4692 - val_accuracy: 0.5313\n",
      "Epoch 694/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4469 - accuracy: 0.5117 - val_loss: 1.5295 - val_accuracy: 0.4884\n",
      "Epoch 695/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4397 - accuracy: 0.5159 - val_loss: 1.5400 - val_accuracy: 0.4968\n",
      "Epoch 696/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4303 - accuracy: 0.5170 - val_loss: 1.5305 - val_accuracy: 0.4874\n",
      "Epoch 697/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4382 - accuracy: 0.5113 - val_loss: 1.4717 - val_accuracy: 0.5131\n",
      "Epoch 698/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3992 - accuracy: 0.5368 - val_loss: 1.5376 - val_accuracy: 0.4854\n",
      "Epoch 699/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4296 - accuracy: 0.5231 - val_loss: 1.5124 - val_accuracy: 0.5062\n",
      "Epoch 700/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4558 - accuracy: 0.5012 - val_loss: 1.5002 - val_accuracy: 0.5200\n",
      "Epoch 701/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4572 - accuracy: 0.5041 - val_loss: 1.4850 - val_accuracy: 0.4780\n",
      "Epoch 702/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4383 - accuracy: 0.5169 - val_loss: 1.4587 - val_accuracy: 0.5081\n",
      "Epoch 703/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.4305 - accuracy: 0.5138 - val_loss: 1.5581 - val_accuracy: 0.4884\n",
      "Epoch 704/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4273 - accuracy: 0.5238 - val_loss: 1.5102 - val_accuracy: 0.5007\n",
      "Epoch 705/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4369 - accuracy: 0.5150 - val_loss: 1.4865 - val_accuracy: 0.4909\n",
      "Epoch 706/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4208 - accuracy: 0.5205 - val_loss: 1.5101 - val_accuracy: 0.5294\n",
      "Epoch 707/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4287 - accuracy: 0.5215 - val_loss: 1.4589 - val_accuracy: 0.5229\n",
      "Epoch 708/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4315 - accuracy: 0.5106 - val_loss: 1.4634 - val_accuracy: 0.4988\n",
      "Epoch 709/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4342 - accuracy: 0.5234 - val_loss: 1.4781 - val_accuracy: 0.5141\n",
      "Epoch 710/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4222 - accuracy: 0.5191 - val_loss: 1.4615 - val_accuracy: 0.5259\n",
      "Epoch 711/1000\n",
      "8108/8108 [==============================] - 0s 39us/step - loss: 1.4712 - accuracy: 0.4911 - val_loss: 1.4970 - val_accuracy: 0.4938\n",
      "Epoch 712/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.4480 - accuracy: 0.5096 - val_loss: 1.5217 - val_accuracy: 0.4702\n",
      "Epoch 713/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4352 - accuracy: 0.5150 - val_loss: 1.5335 - val_accuracy: 0.4780\n",
      "Epoch 714/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4441 - accuracy: 0.5065 - val_loss: 1.5047 - val_accuracy: 0.5146\n",
      "Epoch 715/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4264 - accuracy: 0.5191 - val_loss: 1.4618 - val_accuracy: 0.5269\n",
      "Epoch 716/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4522 - accuracy: 0.5042 - val_loss: 1.5033 - val_accuracy: 0.4776\n",
      "Epoch 717/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4297 - accuracy: 0.5173 - val_loss: 1.5363 - val_accuracy: 0.4628\n",
      "Epoch 718/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4322 - accuracy: 0.5130 - val_loss: 1.4812 - val_accuracy: 0.4988\n",
      "Epoch 719/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4311 - accuracy: 0.5142 - val_loss: 1.4656 - val_accuracy: 0.4785\n",
      "Epoch 720/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4133 - accuracy: 0.5187 - val_loss: 1.4956 - val_accuracy: 0.4973\n",
      "Epoch 721/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4634 - accuracy: 0.5020 - val_loss: 1.5490 - val_accuracy: 0.4499\n",
      "Epoch 722/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4343 - accuracy: 0.5136 - val_loss: 1.4685 - val_accuracy: 0.4963\n",
      "Epoch 723/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4299 - accuracy: 0.5162 - val_loss: 1.4589 - val_accuracy: 0.5254\n",
      "Epoch 724/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4284 - accuracy: 0.5149 - val_loss: 1.5376 - val_accuracy: 0.4692\n",
      "Epoch 725/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4197 - accuracy: 0.5160 - val_loss: 1.5464 - val_accuracy: 0.4894\n",
      "Epoch 726/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4353 - accuracy: 0.5195 - val_loss: 1.4751 - val_accuracy: 0.5106\n",
      "Epoch 727/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4013 - accuracy: 0.5244 - val_loss: 1.4784 - val_accuracy: 0.5160\n",
      "Epoch 728/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4144 - accuracy: 0.5186 - val_loss: 1.4427 - val_accuracy: 0.5121\n",
      "Epoch 729/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4293 - accuracy: 0.5102 - val_loss: 1.5104 - val_accuracy: 0.4544\n",
      "Epoch 730/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4267 - accuracy: 0.5134 - val_loss: 1.5030 - val_accuracy: 0.5017\n",
      "Epoch 731/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4332 - accuracy: 0.5171 - val_loss: 1.4981 - val_accuracy: 0.5185\n",
      "Epoch 732/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4316 - accuracy: 0.5127 - val_loss: 1.4373 - val_accuracy: 0.5313\n",
      "Epoch 733/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4272 - accuracy: 0.5141 - val_loss: 1.5143 - val_accuracy: 0.4953\n",
      "Epoch 734/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.4271 - accuracy: 0.5196 - val_loss: 1.4656 - val_accuracy: 0.5141\n",
      "Epoch 735/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4291 - accuracy: 0.5062 - val_loss: 1.5006 - val_accuracy: 0.4726\n",
      "Epoch 736/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.4101 - accuracy: 0.5231 - val_loss: 1.5287 - val_accuracy: 0.4795\n",
      "Epoch 737/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.3992 - accuracy: 0.5285 - val_loss: 1.4542 - val_accuracy: 0.4968\n",
      "Epoch 738/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 1.4295 - accuracy: 0.5162 - val_loss: 1.5717 - val_accuracy: 0.4598\n",
      "Epoch 739/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 1.4304 - accuracy: 0.5070 - val_loss: 1.4797 - val_accuracy: 0.4904\n",
      "Epoch 740/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 1.4296 - accuracy: 0.5141 - val_loss: 1.4587 - val_accuracy: 0.5116\n",
      "Epoch 741/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 1.4233 - accuracy: 0.5104 - val_loss: 1.4541 - val_accuracy: 0.5096\n",
      "Epoch 742/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 1.4193 - accuracy: 0.5263 - val_loss: 1.4375 - val_accuracy: 0.5062\n",
      "Epoch 743/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.4345 - accuracy: 0.4989 - val_loss: 1.4728 - val_accuracy: 0.5101\n",
      "Epoch 744/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 1.4312 - accuracy: 0.5063 - val_loss: 1.4652 - val_accuracy: 0.4948\n",
      "Epoch 745/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.4051 - accuracy: 0.5202 - val_loss: 1.4664 - val_accuracy: 0.4963\n",
      "Epoch 746/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.4037 - accuracy: 0.5292 - val_loss: 1.5091 - val_accuracy: 0.4687\n",
      "Epoch 747/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 1.4334 - accuracy: 0.5126 - val_loss: 1.4810 - val_accuracy: 0.4909\n",
      "Epoch 748/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.4391 - accuracy: 0.5104 - val_loss: 1.4680 - val_accuracy: 0.5086\n",
      "Epoch 749/1000\n",
      "8108/8108 [==============================] - 0s 36us/step - loss: 1.4096 - accuracy: 0.5264 - val_loss: 1.5831 - val_accuracy: 0.4524\n",
      "Epoch 750/1000\n",
      "8108/8108 [==============================] - 0s 38us/step - loss: 1.4325 - accuracy: 0.5113 - val_loss: 1.5575 - val_accuracy: 0.4978\n",
      "Epoch 751/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 1.4217 - accuracy: 0.5171 - val_loss: 1.5175 - val_accuracy: 0.4953\n",
      "Epoch 752/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 1.4355 - accuracy: 0.5041 - val_loss: 1.4524 - val_accuracy: 0.5234\n",
      "Epoch 753/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 1.3993 - accuracy: 0.5223 - val_loss: 1.4404 - val_accuracy: 0.5136\n",
      "Epoch 754/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.4240 - accuracy: 0.5127 - val_loss: 1.4829 - val_accuracy: 0.5106\n",
      "Epoch 755/1000\n",
      "8108/8108 [==============================] - 0s 37us/step - loss: 1.4420 - accuracy: 0.5051 - val_loss: 1.5578 - val_accuracy: 0.4558\n",
      "Epoch 756/1000\n",
      "8108/8108 [==============================] - 0s 35us/step - loss: 1.3984 - accuracy: 0.5249 - val_loss: 1.4735 - val_accuracy: 0.4988\n",
      "Epoch 757/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.3997 - accuracy: 0.5199 - val_loss: 1.4914 - val_accuracy: 0.4988\n",
      "Epoch 758/1000\n",
      "8108/8108 [==============================] - 0s 39us/step - loss: 1.4075 - accuracy: 0.5255 - val_loss: 1.4485 - val_accuracy: 0.5042\n",
      "Epoch 759/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4155 - accuracy: 0.5152 - val_loss: 1.5133 - val_accuracy: 0.4657\n",
      "Epoch 760/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.4223 - accuracy: 0.5125 - val_loss: 1.4502 - val_accuracy: 0.5550\n",
      "Epoch 761/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.4216 - accuracy: 0.5179 - val_loss: 1.4807 - val_accuracy: 0.5170\n",
      "Epoch 762/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.4076 - accuracy: 0.5245 - val_loss: 1.4591 - val_accuracy: 0.5111\n",
      "Epoch 763/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.3960 - accuracy: 0.5261 - val_loss: 1.4187 - val_accuracy: 0.5417\n",
      "Epoch 764/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.3952 - accuracy: 0.5307 - val_loss: 1.4438 - val_accuracy: 0.5269\n",
      "Epoch 765/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4029 - accuracy: 0.5295 - val_loss: 1.5018 - val_accuracy: 0.4845\n",
      "Epoch 766/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.4181 - accuracy: 0.5074 - val_loss: 1.5108 - val_accuracy: 0.4776\n",
      "Epoch 767/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.4156 - accuracy: 0.5210 - val_loss: 1.4382 - val_accuracy: 0.5037\n",
      "Epoch 768/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.3976 - accuracy: 0.5339 - val_loss: 1.4885 - val_accuracy: 0.4864\n",
      "Epoch 769/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3947 - accuracy: 0.5244 - val_loss: 1.4937 - val_accuracy: 0.4919\n",
      "Epoch 770/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4091 - accuracy: 0.5210 - val_loss: 1.4868 - val_accuracy: 0.5091\n",
      "Epoch 771/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4274 - accuracy: 0.5088 - val_loss: 1.4848 - val_accuracy: 0.4785\n",
      "Epoch 772/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.4018 - accuracy: 0.5206 - val_loss: 1.4506 - val_accuracy: 0.5081\n",
      "Epoch 773/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4176 - accuracy: 0.5111 - val_loss: 1.4263 - val_accuracy: 0.4914\n",
      "Epoch 774/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3999 - accuracy: 0.5212 - val_loss: 1.4580 - val_accuracy: 0.5136\n",
      "Epoch 775/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4221 - accuracy: 0.5221 - val_loss: 1.4195 - val_accuracy: 0.5594\n",
      "Epoch 776/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4070 - accuracy: 0.5224 - val_loss: 1.4984 - val_accuracy: 0.4899\n",
      "Epoch 777/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4157 - accuracy: 0.5171 - val_loss: 1.5154 - val_accuracy: 0.4593\n",
      "Epoch 778/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4028 - accuracy: 0.5196 - val_loss: 1.4214 - val_accuracy: 0.5348\n",
      "Epoch 779/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4156 - accuracy: 0.5138 - val_loss: 1.4517 - val_accuracy: 0.5150\n",
      "Epoch 780/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4082 - accuracy: 0.5237 - val_loss: 1.4893 - val_accuracy: 0.4884\n",
      "Epoch 781/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3990 - accuracy: 0.5260 - val_loss: 1.4472 - val_accuracy: 0.5303\n",
      "Epoch 782/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4263 - accuracy: 0.5121 - val_loss: 1.4647 - val_accuracy: 0.5313\n",
      "Epoch 783/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4516 - accuracy: 0.4891 - val_loss: 1.4696 - val_accuracy: 0.4928\n",
      "Epoch 784/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4268 - accuracy: 0.5181 - val_loss: 1.3965 - val_accuracy: 0.5412\n",
      "Epoch 785/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4168 - accuracy: 0.5192 - val_loss: 1.4596 - val_accuracy: 0.5012\n",
      "Epoch 786/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3943 - accuracy: 0.5270 - val_loss: 1.4844 - val_accuracy: 0.5550\n",
      "Epoch 787/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3797 - accuracy: 0.5318 - val_loss: 1.4352 - val_accuracy: 0.5372\n",
      "Epoch 788/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4118 - accuracy: 0.5131 - val_loss: 1.4048 - val_accuracy: 0.5126\n",
      "Epoch 789/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4108 - accuracy: 0.5259 - val_loss: 1.5568 - val_accuracy: 0.4346\n",
      "Epoch 790/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4062 - accuracy: 0.5242 - val_loss: 1.4604 - val_accuracy: 0.4958\n",
      "Epoch 791/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3926 - accuracy: 0.5269 - val_loss: 1.4520 - val_accuracy: 0.5091\n",
      "Epoch 792/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3989 - accuracy: 0.5221 - val_loss: 1.5026 - val_accuracy: 0.4558\n",
      "Epoch 793/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.3966 - accuracy: 0.5291 - val_loss: 1.4511 - val_accuracy: 0.5269\n",
      "Epoch 794/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.4010 - accuracy: 0.5173 - val_loss: 1.4433 - val_accuracy: 0.5091\n",
      "Epoch 795/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.3886 - accuracy: 0.5210 - val_loss: 1.4219 - val_accuracy: 0.4978\n",
      "Epoch 796/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.4366 - accuracy: 0.5026 - val_loss: 1.5438 - val_accuracy: 0.4889\n",
      "Epoch 797/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.4300 - accuracy: 0.5059 - val_loss: 1.5059 - val_accuracy: 0.4578\n",
      "Epoch 798/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.4129 - accuracy: 0.5170 - val_loss: 1.4812 - val_accuracy: 0.4904\n",
      "Epoch 799/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4100 - accuracy: 0.5199 - val_loss: 1.4759 - val_accuracy: 0.5027\n",
      "Epoch 800/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3821 - accuracy: 0.5423 - val_loss: 1.4029 - val_accuracy: 0.5446\n",
      "Epoch 801/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4164 - accuracy: 0.5128 - val_loss: 1.4878 - val_accuracy: 0.5234\n",
      "Epoch 802/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4178 - accuracy: 0.5181 - val_loss: 1.5072 - val_accuracy: 0.5052\n",
      "Epoch 803/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4009 - accuracy: 0.5253 - val_loss: 1.4259 - val_accuracy: 0.5150\n",
      "Epoch 804/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3874 - accuracy: 0.5331 - val_loss: 1.4944 - val_accuracy: 0.4573\n",
      "Epoch 805/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4130 - accuracy: 0.5190 - val_loss: 1.5083 - val_accuracy: 0.4741\n",
      "Epoch 806/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4264 - accuracy: 0.5158 - val_loss: 1.4275 - val_accuracy: 0.5180\n",
      "Epoch 807/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4118 - accuracy: 0.5118 - val_loss: 1.4882 - val_accuracy: 0.4618\n",
      "Epoch 808/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3975 - accuracy: 0.5238 - val_loss: 1.5004 - val_accuracy: 0.4825\n",
      "Epoch 809/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4158 - accuracy: 0.5192 - val_loss: 1.5093 - val_accuracy: 0.4948\n",
      "Epoch 810/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4172 - accuracy: 0.5043 - val_loss: 1.5687 - val_accuracy: 0.4494\n",
      "Epoch 811/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4056 - accuracy: 0.5276 - val_loss: 1.4661 - val_accuracy: 0.4938\n",
      "Epoch 812/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4275 - accuracy: 0.5094 - val_loss: 1.5061 - val_accuracy: 0.4662\n",
      "Epoch 813/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3792 - accuracy: 0.5321 - val_loss: 1.4549 - val_accuracy: 0.5318\n",
      "Epoch 814/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4011 - accuracy: 0.5295 - val_loss: 1.4614 - val_accuracy: 0.5012\n",
      "Epoch 815/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4161 - accuracy: 0.5127 - val_loss: 1.4303 - val_accuracy: 0.4850\n",
      "Epoch 816/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4011 - accuracy: 0.5231 - val_loss: 1.3946 - val_accuracy: 0.5412\n",
      "Epoch 817/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3921 - accuracy: 0.5292 - val_loss: 1.4014 - val_accuracy: 0.5254\n",
      "Epoch 818/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3861 - accuracy: 0.5275 - val_loss: 1.4240 - val_accuracy: 0.5190\n",
      "Epoch 819/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3996 - accuracy: 0.5153 - val_loss: 1.4867 - val_accuracy: 0.4736\n",
      "Epoch 820/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3881 - accuracy: 0.5274 - val_loss: 1.4452 - val_accuracy: 0.5165\n",
      "Epoch 821/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3934 - accuracy: 0.5215 - val_loss: 1.4587 - val_accuracy: 0.4973\n",
      "Epoch 822/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4013 - accuracy: 0.5220 - val_loss: 1.4363 - val_accuracy: 0.4771\n",
      "Epoch 823/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3716 - accuracy: 0.5428 - val_loss: 1.4430 - val_accuracy: 0.4988\n",
      "Epoch 824/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3962 - accuracy: 0.5238 - val_loss: 1.4668 - val_accuracy: 0.4850\n",
      "Epoch 825/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3974 - accuracy: 0.5152 - val_loss: 1.4703 - val_accuracy: 0.4845\n",
      "Epoch 826/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4179 - accuracy: 0.5063 - val_loss: 1.4365 - val_accuracy: 0.4657\n",
      "Epoch 827/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3986 - accuracy: 0.5187 - val_loss: 1.5022 - val_accuracy: 0.5047\n",
      "Epoch 828/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4185 - accuracy: 0.5115 - val_loss: 1.4481 - val_accuracy: 0.5002\n",
      "Epoch 829/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4053 - accuracy: 0.5216 - val_loss: 1.4041 - val_accuracy: 0.4884\n",
      "Epoch 830/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3706 - accuracy: 0.5222 - val_loss: 1.4392 - val_accuracy: 0.5269\n",
      "Epoch 831/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3606 - accuracy: 0.5402 - val_loss: 1.4790 - val_accuracy: 0.4780\n",
      "Epoch 832/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4132 - accuracy: 0.5079 - val_loss: 1.4440 - val_accuracy: 0.5141\n",
      "Epoch 833/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.3872 - accuracy: 0.5243 - val_loss: 1.4302 - val_accuracy: 0.5417\n",
      "Epoch 834/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4064 - accuracy: 0.5104 - val_loss: 1.4229 - val_accuracy: 0.5037\n",
      "Epoch 835/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3877 - accuracy: 0.5227 - val_loss: 1.4033 - val_accuracy: 0.4998\n",
      "Epoch 836/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3909 - accuracy: 0.5252 - val_loss: 1.5467 - val_accuracy: 0.4598\n",
      "Epoch 837/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3944 - accuracy: 0.5222 - val_loss: 1.3665 - val_accuracy: 0.5520\n",
      "Epoch 838/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3649 - accuracy: 0.5368 - val_loss: 1.4396 - val_accuracy: 0.4928\n",
      "Epoch 839/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4042 - accuracy: 0.5229 - val_loss: 1.4719 - val_accuracy: 0.4766\n",
      "Epoch 840/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3808 - accuracy: 0.5312 - val_loss: 1.4508 - val_accuracy: 0.5121\n",
      "Epoch 841/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3736 - accuracy: 0.5350 - val_loss: 1.5240 - val_accuracy: 0.5116\n",
      "Epoch 842/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3887 - accuracy: 0.5226 - val_loss: 1.4601 - val_accuracy: 0.4938\n",
      "Epoch 843/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3823 - accuracy: 0.5224 - val_loss: 1.4513 - val_accuracy: 0.4854\n",
      "Epoch 844/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3825 - accuracy: 0.5229 - val_loss: 1.4443 - val_accuracy: 0.4800\n",
      "Epoch 845/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3835 - accuracy: 0.5265 - val_loss: 1.4352 - val_accuracy: 0.5022\n",
      "Epoch 846/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3596 - accuracy: 0.5401 - val_loss: 1.4079 - val_accuracy: 0.5363\n",
      "Epoch 847/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3918 - accuracy: 0.5232 - val_loss: 1.4680 - val_accuracy: 0.4998\n",
      "Epoch 848/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.3918 - accuracy: 0.5196 - val_loss: 1.5330 - val_accuracy: 0.4327\n",
      "Epoch 849/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.4084 - accuracy: 0.5097 - val_loss: 1.4432 - val_accuracy: 0.5269\n",
      "Epoch 850/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3771 - accuracy: 0.5220 - val_loss: 1.3913 - val_accuracy: 0.5442\n",
      "Epoch 851/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3649 - accuracy: 0.5358 - val_loss: 1.4357 - val_accuracy: 0.4933\n",
      "Epoch 852/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3640 - accuracy: 0.5393 - val_loss: 1.4805 - val_accuracy: 0.4899\n",
      "Epoch 853/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4026 - accuracy: 0.5174 - val_loss: 1.4257 - val_accuracy: 0.5091\n",
      "Epoch 854/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3875 - accuracy: 0.5244 - val_loss: 1.4280 - val_accuracy: 0.5328\n",
      "Epoch 855/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3774 - accuracy: 0.5278 - val_loss: 1.4472 - val_accuracy: 0.5160\n",
      "Epoch 856/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3993 - accuracy: 0.5107 - val_loss: 1.4497 - val_accuracy: 0.4549\n",
      "Epoch 857/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3853 - accuracy: 0.5298 - val_loss: 1.4568 - val_accuracy: 0.4845\n",
      "Epoch 858/1000\n",
      "8108/8108 [==============================] - 0s 29us/step - loss: 1.4049 - accuracy: 0.5115 - val_loss: 1.4496 - val_accuracy: 0.4766\n",
      "Epoch 859/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3785 - accuracy: 0.5254 - val_loss: 1.5230 - val_accuracy: 0.4568\n",
      "Epoch 860/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4158 - accuracy: 0.5131 - val_loss: 1.3901 - val_accuracy: 0.5289\n",
      "Epoch 861/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3646 - accuracy: 0.5334 - val_loss: 1.4167 - val_accuracy: 0.4998\n",
      "Epoch 862/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3699 - accuracy: 0.5297 - val_loss: 1.3713 - val_accuracy: 0.5639\n",
      "Epoch 863/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3840 - accuracy: 0.5278 - val_loss: 1.4145 - val_accuracy: 0.5027\n",
      "Epoch 864/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3969 - accuracy: 0.5157 - val_loss: 1.4338 - val_accuracy: 0.5338\n",
      "Epoch 865/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3814 - accuracy: 0.5380 - val_loss: 1.4051 - val_accuracy: 0.5062\n",
      "Epoch 866/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3721 - accuracy: 0.5253 - val_loss: 1.4317 - val_accuracy: 0.4874\n",
      "Epoch 867/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3781 - accuracy: 0.5332 - val_loss: 1.4093 - val_accuracy: 0.4933\n",
      "Epoch 868/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3589 - accuracy: 0.5397 - val_loss: 1.4376 - val_accuracy: 0.5096\n",
      "Epoch 869/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3854 - accuracy: 0.5260 - val_loss: 1.4514 - val_accuracy: 0.5200\n",
      "Epoch 870/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3941 - accuracy: 0.5218 - val_loss: 1.4551 - val_accuracy: 0.4983\n",
      "Epoch 871/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3741 - accuracy: 0.5279 - val_loss: 1.4410 - val_accuracy: 0.5215\n",
      "Epoch 872/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3722 - accuracy: 0.5303 - val_loss: 1.5124 - val_accuracy: 0.4706\n",
      "Epoch 873/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3894 - accuracy: 0.5141 - val_loss: 1.4223 - val_accuracy: 0.4953\n",
      "Epoch 874/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.3880 - accuracy: 0.5259 - val_loss: 1.4563 - val_accuracy: 0.5313\n",
      "Epoch 875/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.3887 - accuracy: 0.5296 - val_loss: 1.4472 - val_accuracy: 0.5052\n",
      "Epoch 876/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.3796 - accuracy: 0.5276 - val_loss: 1.3701 - val_accuracy: 0.5392\n",
      "Epoch 877/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.3701 - accuracy: 0.5260 - val_loss: 1.4135 - val_accuracy: 0.5392\n",
      "Epoch 878/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.3654 - accuracy: 0.5324 - val_loss: 1.5603 - val_accuracy: 0.4805\n",
      "Epoch 879/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.3697 - accuracy: 0.5376 - val_loss: 1.4008 - val_accuracy: 0.5037\n",
      "Epoch 880/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3514 - accuracy: 0.5419 - val_loss: 1.4094 - val_accuracy: 0.5205\n",
      "Epoch 881/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3753 - accuracy: 0.5234 - val_loss: 1.4323 - val_accuracy: 0.5530\n",
      "Epoch 882/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3687 - accuracy: 0.5269 - val_loss: 1.4888 - val_accuracy: 0.5057\n",
      "Epoch 883/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3609 - accuracy: 0.5316 - val_loss: 1.3646 - val_accuracy: 0.5491\n",
      "Epoch 884/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3881 - accuracy: 0.5217 - val_loss: 1.4631 - val_accuracy: 0.4854\n",
      "Epoch 885/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3988 - accuracy: 0.5152 - val_loss: 1.3968 - val_accuracy: 0.4988\n",
      "Epoch 886/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3760 - accuracy: 0.5258 - val_loss: 1.3958 - val_accuracy: 0.5170\n",
      "Epoch 887/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3645 - accuracy: 0.5278 - val_loss: 1.3830 - val_accuracy: 0.5328\n",
      "Epoch 888/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3634 - accuracy: 0.5298 - val_loss: 1.4136 - val_accuracy: 0.5002\n",
      "Epoch 889/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3563 - accuracy: 0.5350 - val_loss: 1.4756 - val_accuracy: 0.4800\n",
      "Epoch 890/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3547 - accuracy: 0.5382 - val_loss: 1.4121 - val_accuracy: 0.4909\n",
      "Epoch 891/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.3770 - accuracy: 0.5200 - val_loss: 1.4094 - val_accuracy: 0.4938\n",
      "Epoch 892/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3792 - accuracy: 0.5239 - val_loss: 1.4303 - val_accuracy: 0.4899\n",
      "Epoch 893/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3788 - accuracy: 0.5202 - val_loss: 1.4342 - val_accuracy: 0.4859\n",
      "Epoch 894/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3662 - accuracy: 0.5313 - val_loss: 1.3743 - val_accuracy: 0.5397\n",
      "Epoch 895/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3863 - accuracy: 0.5242 - val_loss: 1.4781 - val_accuracy: 0.4859\n",
      "Epoch 896/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3767 - accuracy: 0.5205 - val_loss: 1.3902 - val_accuracy: 0.5086\n",
      "Epoch 897/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3523 - accuracy: 0.5401 - val_loss: 1.4151 - val_accuracy: 0.5224\n",
      "Epoch 898/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3793 - accuracy: 0.5217 - val_loss: 1.5089 - val_accuracy: 0.4726\n",
      "Epoch 899/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3622 - accuracy: 0.5331 - val_loss: 1.4567 - val_accuracy: 0.5096\n",
      "Epoch 900/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3561 - accuracy: 0.5350 - val_loss: 1.4419 - val_accuracy: 0.4795\n",
      "Epoch 901/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3558 - accuracy: 0.5374 - val_loss: 1.5013 - val_accuracy: 0.5017\n",
      "Epoch 902/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3840 - accuracy: 0.5307 - val_loss: 1.3859 - val_accuracy: 0.5348\n",
      "Epoch 903/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3555 - accuracy: 0.5412 - val_loss: 1.4903 - val_accuracy: 0.4391\n",
      "Epoch 904/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3683 - accuracy: 0.5271 - val_loss: 1.4493 - val_accuracy: 0.5037\n",
      "Epoch 905/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3808 - accuracy: 0.5285 - val_loss: 1.4511 - val_accuracy: 0.4924\n",
      "Epoch 906/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3762 - accuracy: 0.5294 - val_loss: 1.3703 - val_accuracy: 0.5619\n",
      "Epoch 907/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3604 - accuracy: 0.5305 - val_loss: 1.5240 - val_accuracy: 0.4662\n",
      "Epoch 908/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3571 - accuracy: 0.5348 - val_loss: 1.4009 - val_accuracy: 0.5387\n",
      "Epoch 909/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.3601 - accuracy: 0.5386 - val_loss: 1.4477 - val_accuracy: 0.5170\n",
      "Epoch 910/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3917 - accuracy: 0.5228 - val_loss: 1.4546 - val_accuracy: 0.4657\n",
      "Epoch 911/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3438 - accuracy: 0.5372 - val_loss: 1.4064 - val_accuracy: 0.5037\n",
      "Epoch 912/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3507 - accuracy: 0.5393 - val_loss: 1.4394 - val_accuracy: 0.5076\n",
      "Epoch 913/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.4029 - accuracy: 0.5192 - val_loss: 1.4934 - val_accuracy: 0.4776\n",
      "Epoch 914/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.3411 - accuracy: 0.5397 - val_loss: 1.4489 - val_accuracy: 0.4613\n",
      "Epoch 915/1000\n",
      "8108/8108 [==============================] - 0s 37us/step - loss: 1.3610 - accuracy: 0.5287 - val_loss: 1.4297 - val_accuracy: 0.4993\n",
      "Epoch 916/1000\n",
      "8108/8108 [==============================] - 0s 34us/step - loss: 1.3763 - accuracy: 0.5236 - val_loss: 1.4348 - val_accuracy: 0.4924\n",
      "Epoch 917/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3517 - accuracy: 0.5382 - val_loss: 1.3943 - val_accuracy: 0.5442\n",
      "Epoch 918/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3605 - accuracy: 0.5432 - val_loss: 1.4285 - val_accuracy: 0.4953\n",
      "Epoch 919/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.3950 - accuracy: 0.5231 - val_loss: 1.4003 - val_accuracy: 0.5116\n",
      "Epoch 920/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.3410 - accuracy: 0.5387 - val_loss: 1.4197 - val_accuracy: 0.5392\n",
      "Epoch 921/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3856 - accuracy: 0.5168 - val_loss: 1.4758 - val_accuracy: 0.4702\n",
      "Epoch 922/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3600 - accuracy: 0.5359 - val_loss: 1.4902 - val_accuracy: 0.4953\n",
      "Epoch 923/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3890 - accuracy: 0.5257 - val_loss: 1.3913 - val_accuracy: 0.5412\n",
      "Epoch 924/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3633 - accuracy: 0.5295 - val_loss: 1.4385 - val_accuracy: 0.4983\n",
      "Epoch 925/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3885 - accuracy: 0.5164 - val_loss: 1.3691 - val_accuracy: 0.5718\n",
      "Epoch 926/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3614 - accuracy: 0.5408 - val_loss: 1.3719 - val_accuracy: 0.5239\n",
      "Epoch 927/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3588 - accuracy: 0.5429 - val_loss: 1.3680 - val_accuracy: 0.5831\n",
      "Epoch 928/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3570 - accuracy: 0.5260 - val_loss: 1.3930 - val_accuracy: 0.5348\n",
      "Epoch 929/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3489 - accuracy: 0.5377 - val_loss: 1.4778 - val_accuracy: 0.5101\n",
      "Epoch 930/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3746 - accuracy: 0.5305 - val_loss: 1.4215 - val_accuracy: 0.5313\n",
      "Epoch 931/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3605 - accuracy: 0.5305 - val_loss: 1.4052 - val_accuracy: 0.5437\n",
      "Epoch 932/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3611 - accuracy: 0.5306 - val_loss: 1.3968 - val_accuracy: 0.5308\n",
      "Epoch 933/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3677 - accuracy: 0.5350 - val_loss: 1.3853 - val_accuracy: 0.4899\n",
      "Epoch 934/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3557 - accuracy: 0.5408 - val_loss: 1.4115 - val_accuracy: 0.5121\n",
      "Epoch 935/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3931 - accuracy: 0.5192 - val_loss: 1.4583 - val_accuracy: 0.4854\n",
      "Epoch 936/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3792 - accuracy: 0.5217 - val_loss: 1.4294 - val_accuracy: 0.5062\n",
      "Epoch 937/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3568 - accuracy: 0.5333 - val_loss: 1.4421 - val_accuracy: 0.4815\n",
      "Epoch 938/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3584 - accuracy: 0.5319 - val_loss: 1.4163 - val_accuracy: 0.5121\n",
      "Epoch 939/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3643 - accuracy: 0.5273 - val_loss: 1.4027 - val_accuracy: 0.5358\n",
      "Epoch 940/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3622 - accuracy: 0.5337 - val_loss: 1.4437 - val_accuracy: 0.5047\n",
      "Epoch 941/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3460 - accuracy: 0.5307 - val_loss: 1.4477 - val_accuracy: 0.5323\n",
      "Epoch 942/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3460 - accuracy: 0.5398 - val_loss: 1.3788 - val_accuracy: 0.5417\n",
      "Epoch 943/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3435 - accuracy: 0.5376 - val_loss: 1.4178 - val_accuracy: 0.4835\n",
      "Epoch 944/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3395 - accuracy: 0.5408 - val_loss: 1.3935 - val_accuracy: 0.5155\n",
      "Epoch 945/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3600 - accuracy: 0.5389 - val_loss: 1.4705 - val_accuracy: 0.4692\n",
      "Epoch 946/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3720 - accuracy: 0.5233 - val_loss: 1.4448 - val_accuracy: 0.5442\n",
      "Epoch 947/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3543 - accuracy: 0.5342 - val_loss: 1.4499 - val_accuracy: 0.4830\n",
      "Epoch 948/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.3635 - accuracy: 0.5280 - val_loss: 1.3646 - val_accuracy: 0.4919\n",
      "Epoch 949/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3835 - accuracy: 0.5170 - val_loss: 1.4690 - val_accuracy: 0.5062\n",
      "Epoch 950/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3679 - accuracy: 0.5231 - val_loss: 1.3964 - val_accuracy: 0.5461\n",
      "Epoch 951/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3498 - accuracy: 0.5385 - val_loss: 1.4259 - val_accuracy: 0.4756\n",
      "Epoch 952/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3479 - accuracy: 0.5333 - val_loss: 1.4299 - val_accuracy: 0.5106\n",
      "Epoch 953/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3416 - accuracy: 0.5435 - val_loss: 1.3863 - val_accuracy: 0.5042\n",
      "Epoch 954/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.3457 - accuracy: 0.5328 - val_loss: 1.4049 - val_accuracy: 0.5160\n",
      "Epoch 955/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3435 - accuracy: 0.5396 - val_loss: 1.4701 - val_accuracy: 0.5047\n",
      "Epoch 956/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3558 - accuracy: 0.5354 - val_loss: 1.4064 - val_accuracy: 0.5072\n",
      "Epoch 957/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3372 - accuracy: 0.5356 - val_loss: 1.3969 - val_accuracy: 0.5170\n",
      "Epoch 958/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3447 - accuracy: 0.5276 - val_loss: 1.4751 - val_accuracy: 0.5353\n",
      "Epoch 959/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3534 - accuracy: 0.5382 - val_loss: 1.4318 - val_accuracy: 0.5175\n",
      "Epoch 960/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3587 - accuracy: 0.5269 - val_loss: 1.3923 - val_accuracy: 0.5437\n",
      "Epoch 961/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3424 - accuracy: 0.5401 - val_loss: 1.4814 - val_accuracy: 0.5284\n",
      "Epoch 962/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3485 - accuracy: 0.5400 - val_loss: 1.4258 - val_accuracy: 0.5072\n",
      "Epoch 963/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3612 - accuracy: 0.5381 - val_loss: 1.3956 - val_accuracy: 0.5165\n",
      "Epoch 964/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3510 - accuracy: 0.5334 - val_loss: 1.4055 - val_accuracy: 0.5096\n",
      "Epoch 965/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.3528 - accuracy: 0.5365 - val_loss: 1.4595 - val_accuracy: 0.4904\n",
      "Epoch 966/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3499 - accuracy: 0.5281 - val_loss: 1.3867 - val_accuracy: 0.5111\n",
      "Epoch 967/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3490 - accuracy: 0.5340 - val_loss: 1.4281 - val_accuracy: 0.5146\n",
      "Epoch 968/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3329 - accuracy: 0.5438 - val_loss: 1.5029 - val_accuracy: 0.4657\n",
      "Epoch 969/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3600 - accuracy: 0.5332 - val_loss: 1.3646 - val_accuracy: 0.5190\n",
      "Epoch 970/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3429 - accuracy: 0.5377 - val_loss: 1.4418 - val_accuracy: 0.4810\n",
      "Epoch 971/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3623 - accuracy: 0.5223 - val_loss: 1.4252 - val_accuracy: 0.4746\n",
      "Epoch 972/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3429 - accuracy: 0.5294 - val_loss: 1.3541 - val_accuracy: 0.5121\n",
      "Epoch 973/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3371 - accuracy: 0.5426 - val_loss: 1.4080 - val_accuracy: 0.4983\n",
      "Epoch 974/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.3632 - accuracy: 0.5360 - val_loss: 1.3746 - val_accuracy: 0.5116\n",
      "Epoch 975/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3420 - accuracy: 0.5375 - val_loss: 1.3952 - val_accuracy: 0.5224\n",
      "Epoch 976/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3478 - accuracy: 0.5311 - val_loss: 1.3932 - val_accuracy: 0.5619\n",
      "Epoch 977/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3656 - accuracy: 0.5269 - val_loss: 1.4164 - val_accuracy: 0.4884\n",
      "Epoch 978/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3526 - accuracy: 0.5345 - val_loss: 1.4467 - val_accuracy: 0.4790\n",
      "Epoch 979/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3391 - accuracy: 0.5369 - val_loss: 1.3775 - val_accuracy: 0.5269\n",
      "Epoch 980/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3352 - accuracy: 0.5372 - val_loss: 1.4971 - val_accuracy: 0.5022\n",
      "Epoch 981/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3562 - accuracy: 0.5348 - val_loss: 1.4070 - val_accuracy: 0.5254\n",
      "Epoch 982/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3708 - accuracy: 0.5257 - val_loss: 1.3749 - val_accuracy: 0.5121\n",
      "Epoch 983/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3572 - accuracy: 0.5368 - val_loss: 1.5377 - val_accuracy: 0.4874\n",
      "Epoch 984/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3775 - accuracy: 0.5281 - val_loss: 1.4711 - val_accuracy: 0.4751\n",
      "Epoch 985/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.3541 - accuracy: 0.5301 - val_loss: 1.4454 - val_accuracy: 0.5170\n",
      "Epoch 986/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3617 - accuracy: 0.5306 - val_loss: 1.4210 - val_accuracy: 0.4904\n",
      "Epoch 987/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.3781 - accuracy: 0.5268 - val_loss: 1.4086 - val_accuracy: 0.5249\n",
      "Epoch 988/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.3183 - accuracy: 0.5486 - val_loss: 1.3934 - val_accuracy: 0.5155\n",
      "Epoch 989/1000\n",
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.3573 - accuracy: 0.5364 - val_loss: 1.4449 - val_accuracy: 0.5170\n",
      "Epoch 990/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3526 - accuracy: 0.5331 - val_loss: 1.4235 - val_accuracy: 0.4958\n",
      "Epoch 991/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8108/8108 [==============================] - 0s 33us/step - loss: 1.3249 - accuracy: 0.5471 - val_loss: 1.3884 - val_accuracy: 0.5264\n",
      "Epoch 992/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.3419 - accuracy: 0.5343 - val_loss: 1.3560 - val_accuracy: 0.5422\n",
      "Epoch 993/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3577 - accuracy: 0.5282 - val_loss: 1.3391 - val_accuracy: 0.5590\n",
      "Epoch 994/1000\n",
      "8108/8108 [==============================] - 0s 32us/step - loss: 1.3455 - accuracy: 0.5348 - val_loss: 1.4209 - val_accuracy: 0.4953\n",
      "Epoch 995/1000\n",
      "8108/8108 [==============================] - 0s 37us/step - loss: 1.3366 - accuracy: 0.5446 - val_loss: 1.4237 - val_accuracy: 0.5451\n",
      "Epoch 996/1000\n",
      "8108/8108 [==============================] - 0s 40us/step - loss: 1.3404 - accuracy: 0.5327 - val_loss: 1.3668 - val_accuracy: 0.5234\n",
      "Epoch 997/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3281 - accuracy: 0.5419 - val_loss: 1.4932 - val_accuracy: 0.4795\n",
      "Epoch 998/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3485 - accuracy: 0.5317 - val_loss: 1.4417 - val_accuracy: 0.5022\n",
      "Epoch 999/1000\n",
      "8108/8108 [==============================] - 0s 31us/step - loss: 1.3470 - accuracy: 0.5365 - val_loss: 1.4262 - val_accuracy: 0.5091\n",
      "Epoch 1000/1000\n",
      "8108/8108 [==============================] - 0s 30us/step - loss: 1.3585 - accuracy: 0.5344 - val_loss: 1.4281 - val_accuracy: 0.4943\n"
     ]
    }
   ],
   "source": [
    "# 学習(位置)\n",
    "epochs = 1000\n",
    "batch_size = 128\n",
    "position_history = position_model.fit(position_x_train, position_y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(position_x_test, position_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rRL0MNrOy_Uq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2027/2027 [==============================] - 0s 38us/step\n",
      "Test loss: 1.4281227112286892\n",
      "Test accuracy: 0.4943265914916992\n"
     ]
    }
   ],
   "source": [
    "# モデルの評価(位置)\n",
    "position_score = position_model.evaluate(position_x_test, position_y_test, verbose=1)\n",
    "print('Test loss:', position_score[0])\n",
    "print('Test accuracy:', position_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8MU9DaNvzSH9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXiU5dX48e+ZSVg0bCIGlEhUlE0NSggopYICIiL6ulZxiWL5Uen7YmutWG0Vl1Zf97a+IspqWaw7RooLGIgKQsIuBAUMgooLSyBoSGbm/P54ZpJJZpJMlsk253NduTLzPM/M3HceyMm9nVtUFWOMMbHL1dAFMMYY07AsEBhjTIyzQGCMMTHOAoExxsQ4CwTGGBPj4hq6ANV17LHHanJyco1ee/jwYY4++ui6LVAjZ3WODVbn2FCbOufk5Pyoqp3CnWtygSA5OZns7OwavTYzM5MhQ4bUbYEaOatzbLA6x4ba1FlEdlZ0zrqGjDEmxlkgMMaYGGeBwBhjYlzUxghEpBWwHGjp/5xXVfW+ctf8HrgV8AA/ALeoaoX9WMaYulFcXMzu3bspLCxs6KLUWLt27diyZUtDF6NeRVLnVq1a0bVrV+Lj4yN+32gOFh8BzlfVAhGJBz4Skf+o6sqga9YCqar6k4j8Bvhf4JoolskYA+zevZs2bdqQnJyMiDR0cWrk0KFDtGnTpqGLUa+qqrOqsnfvXnbv3s1JJ50U8ftGrWtIHQX+p/H+Ly13zYeq+pP/6Uqga7TKY4wpVVhYSMeOHZtsEDDhiQgdO3asdksvqtNHRcQN5ADdgWdV9dNKLh8H/KeC9xkPjAdITEwkMzOz2mVpm59L4vc5rMnP5WC7ntV+fVNVUFBQo59XU2Z1rlq7du0oKCio+sJGzOv1cujQoYYuRr2KtM6FhYXV+vcg9ZGGWkTaA28A/62qm8Kcvx74LXCeqh6p7L1SU1O12usIdq2C2ZegnkKcv3/cIArigriW0CUFhk2BpLTqvW8TYHOtY0N167xlyxZ69eoVvQLVA+saqli4+ysiOaqaGu76ellQpqoHRORDYCRQJhCIyDDgHiIIAjWWlxUUBEDV6++k8oHPg+z8BKYPB3cL6NQDuvaHlGubZWAwxpjyojZGICKd/C0BRKQ1MBzILXfNWcDzwBhV/T5aZcltlYIqBBo/IkFfQdeppwjdsxHNngHTL3RaEsaYRmvq1KnMmTMHgFmzZvHNN9+UnLv11lvZvHlznX3W/fffz+OPP15n79eYRHMdQRfgQxHZAKwG3lfVDBF5QETG+K95DEgAXhGRdSKyMBoFWVKQzBveQQAlASH4KyAQGARQ9VE8YxRkz4pGkYxpcnJ27ufZD7eRs3N/QxelxIQJE7jxxhuB0EDw4osv0rt374YqWpMSta4hVd0AnBXm+F+CHg+L1ucHG3hyR65+byLfaQeudS/lKI7gwgdAnGhIMAh8j9diNGMShcueovXVL1hXkWmWprz9GZu/OVjpNYcKi8ndcwifgkugZ+c2tGlV8Tz13se35b5L+lT6nnl5eYwcOZJ+/fqxZs0a+vTpw5w5c1ixYgV/+MMf8Hg89O/fn+eee46WLVsyefJkFi5cSFxcHCNGjOC+++7j/vvvJyEhoSQH2dixY2ndujUrVqzgoosu4vHHHyc1NZX58+fz17/+FVXl4osv5tFHHwUgISGBSZMmkZGRQevWrXnrrbdITEys8me2bt06JkyYwE8//cQpp5zCjBkz6NChA3//+9+ZOnUqcXFx9O7dmwULFrBs2TImTZoEOLN6li9f3ujGNmJiZXG/bh3494RzebPNWAbpDHp7XuLUormcWjSXu4vHscfXDo8/GJRvJaDQ6mAevunDrXVgYtbBQg8+//8LnzrP68LWrVu57bbb2LJlC23btuXJJ58kPT2dl19+mY0bN+LxeHjuuefYu3cvb7zxBp999hkbNmzg3nvvLfM+V155JampqcydO5d169bRunXrknPffPMNd911F0uXLmXdunWsXr2aN998E3CyeQ4cOJD169fzy1/+khdeeCGict944408+uijbNiwgTPOOIMpU6YA8Mgjj7B27Vo2bNjA1KlTAXj88cd59tlnWbduHVlZWWXK1lg0ueyjNdWvWwf+NPCoMjMrHlm0hbmfunml+AJ8PrjGtYTJ7rm0cxWiWjqOAICCN2MS7sTe1jIwzUpVf7mD0y009sWVFHt8xMe5eOZXZ9GvW4daf3ZSUhKDBjndttdffz0PPvggJ510EqeddhoAN910E88++yy//e1vadWqFePGjWP06NGMHj2aI0cim1uyevVqhgwZQqdOTgbmsWPHsnz5ci677DJatGjB6NGjAejXrx/vv/9+le+Xn5/PgQMHOO+880rKeNVVVwFw5plnMnbsWC677DIuu+wyAAYNGsTvf/97xo4dy+WXX07Xro1vuVRMtAgqMnlULzZOGcn2v17Ml49czFX/789c2/EVXvcOQiFkgNmlsHfG1TaIbGJOv24dmHvrQH4/ogdzbx1YJ0EACFnQ1r59+7DXxcXFsWrVKq688koyMjIYOXJknXx+fHx8SRncbjceT+1aOu+88w4TJ05kzZo19O/fH4/Hw+TJk3nxxRf5+eefGTRoELm5uVW/UT2L6UBQXr9uHfjP7b/kiocW8VDi0+zzJZQ5LwLH+PbjtW4iE4P6devAxKHd6ywIAHz11VesWLECgHnz5pGamkpeXh7btm0D4KWXXuK8886joKCA/Px8Ro0axVNPPcX69etD3qtNmzZhF1ulpaWxbNkyfvzxR7xeL/Pnzy/5a74m2rVrR4cOHcjKyipTRp/Px65duxg6dCiPPvoo+fn5FBQUsH37ds444wzuuusu+vfv3ygDQcx0DVXXX267mfcWd+T8FTfi9jcLAl1FLgVfxu24rJvImFrp0aMHzz77LLfccgu9e/fm73//OwMHDuSqq64qGSyeMGEC+/bt49JLL6WwsBBV5cknnwx5r/T0dCZMmFAyWBzQpUsXHnnkEYYOHVoyWHzppZfWqtyzZ88uGSw++eSTmTlzJl6vl+uvv578/HxUlf/5n/+hffv2/PnPf+bDDz/E5XLRp08fLrroolp9djTUy8riulSjlcV+NVpxumsVe2dczTG+/QS3YlVhQ5tfkPKHd2pUlvpiq2xjQ1NcWZyXl8fo0aPZtCkk2UBEbGVxxaq7sti6hqqSlEbHW/6NVyRkRtGZhz5i/d/Ob7iyGWNMHbBAEImkNOLGvcdBKd00OtA6OLMwh4/+978aqGDGNF3Jyck1bg1E08MPP0zfvn3LfD388MMNXayosjGCSCWlsf/ce2j78Z/KTC1VhXMPL+W9xQsZMXJM1e9jjGnU7rnnHu65556GLka9shZBNSSPmMjmk28umVoKQfmKPn6mUS29N8aYSFkgqKY+Nz3N56Nf45C2KnN8mCubT6f91oKBMabJsUBQAz37D6OoQ/eQVsFv4jJY+q9HG7RsxhhTXRYIaujYwb8GKdtFBHB14SvcvmBtwxXMGGOqyQJBTaWmI2dcXSYYAJzo+pFbP7uJ9xZHJaO2MSZIfe5HUF1V7V+Qnp7Oq6++Wo8lqpjNGqqNK15A2h6P7+OnnX0M/K2CPq6dnLYinfeYZTOJTPOxaxXkZUHy4Eazon7ChAklj2fNmsXpp5/O8ccfDzj7EZjIWCCoreFTKFr/Ki0P7S63l4GX9R9l0LHX4DrNzWJMnfvPZNizsfJrjhyE7zaB+py9vhNPh5ZtK76+8xlw0SOVvmVT2o8gPz+fM888ky+//BKXy8Xhw4fp2bMnO3bsYNasWUybNo2ioiK6d+/OSy+9xFFHHVXljz3YkiVLIq7zK6+8wpQpU3C73bRr147ly5dX67PCsa6hOtBqyJ1luogC3/f6Enjg7c9sJpFp+grznSAAzvfC/Dp526ayH0G7du3o27cvy5YtAyAjI4MLL7yQ+Ph4Lr/8clavXs369evp1asX06dPr9bPoLCwsFp1fuCBB3j33XdZv349CxfWTRe0tQjqQmo6sv9LfB8/DVq60Ox292vc9nUSj76Qw1MDDnFC3xGNpkltTIkq/nIHnG6h2WPAWwTuFnDFi3Xyb7kp7UdwzTXX8PLLLzN06FAWLFjAbbfdBsCmTZu49957OXDgAAUFBVx44YXV+hls3bq1WnUeNGgQ6enpXH311Vx++eXV+qyKWIugrgyfgqvnaP/qMicYJLoO8O8W9zPXPYUuOU84/5FsLwPTFCWlwU0L4fx7nO919AdNU9qPYMyYMSxevJh9+/aRk5PD+ec7ecbS09P55z//ycaNG7nvvvsoLCysk7JVVOepU6fy0EMPsWvXLvr168fevXtr/VkWCOrSoEkhq47dQLx4ceFDvUXOYJsxTVFSGgy+o05btU1pP4KEhAT69+/PpEmTGD16NG63G3Aygnbp0oXi4mLmzp1b7fft0aNHteq8fft2BgwYwAMPPECnTp3YtWtXtT+zPOsaqktJabjOuBrd+O+QU6pQqG52tkqhZwMUzZjGqKntR3DNNddw1VVXkZmZWXLswQcfZMCAAXTq1IkBAwaEDUaVadWqFTNnzoy4znfeeSdffPEFqsoFF1xASkpKjeoSzPYjiIZnzkL37yC40asKz3lGs7bH73jhxrApwaPCcvPHBtuPIDY0uf0IRKSViKwSkfUi8pmITAlzzS9FZI2IeETkymiVpd5d/jyCUD7E/pcri/c3f8e8T79qkGIZY0w40RwjOAKcr6opQF9gpIgMLHfNV0A6MC+K5ah/SWkw2llkFhwMOrvyyYi/m1fffM2CgYl5sbIfwcSJE0Peb+bMmXVY4tqL2hiBOn1OBf6n8f4vLXdNHoCI+KJVjgaTmg6AZkwqM6W0j2snr7S4n+cXZjOPv3HdgBMbtpwmZqlqyKwdU/f7ETz77LN19l6RqEl3f1THCETEDeQA3YFnVfWuCq6bBWSoatjEGyIyHhgPkJiY2G/BggU1Kk9BQQEJCQk1em1N9dj8JJ2/XxYyXgDwJ884Tkm9mO4d3FH7/Iaoc0OzOlctISGBxMRE2rVr12SDgdfrLZm5EyuqqrOqkp+fz3fffUdBQUGZc0OHDq1wjKBeBotFpD3wBvDfqhrSFqwqEARrEoPF5f39LHRf6ODx577j+eD8t5k4tHvUPtoGTmNDdetcXFzM7t2762zOe0MoLCykVatWVV/YjERS51atWtG1a1fi4+PLHK9ssLhepo+q6gER+RAYCTS+TsFoO3kI7NsRcvg01zfs3fo0DP1nvRfJxLb4+HhOOumkhi5GrWRmZnLWWWc1dDHqVbTqHM1ZQ538LQFEpDUwHMiN1uc1ainXIq74kMVmAAO+/Re5qz9osKIZY0w0Zw11AT4UkQ3AauB9Vc0QkQdEZAyAiPQXkd3AVcDzIvJZFMvTcJLS4OZFSM+L8QX1Dzk7myl5b/3NZhEZYxpM1AKBqm5Q1bNU9UxVPV1VH/Af/4uqLvQ/Xq2qXVX1aFXtqKp9olWeBpeUBr+ax8/HppTZyEaAC93ZtHx7gmUpNcY0CMs1VM8SBt4SssWlCFzu/pisBY81bOGMMTHJAkF9C9risrwxh1+1LS6NMfXOAkFDuOIFpOfokBQUyfIdg1eOs1TVxph6ZYGgoQyahLjiSoKBCLgE4rWIaXNm23iBMabeWCBoKElpMOqJkFaBG0gtXMFfn59lwcAYUy8sEDSk1HRc7UNzDZ3t3s7L8Q/w+luvN0ChjDGxxgJBQ+t8ZpmngYVmbnxc8v00axUYY6LOAkFDGzQJxF1m1TE4ASHNncs7M/9aGgx2rYKsJ2ww2RhTp2yryoaWlAa3LEYW/hb9YWuZUwLcoy9w1dTjeeyizpyydAKIC9wt63QDcWNMbLMWQWOQlAZj/hk2H5ELZbw7gz3LZzkH1QfeIsjLaqjSGmOaGQsEjUUgH1G3c0MWm13ozqbzkTz/MwF3C0geXN8lNMY0UxYIGpOkNLj5P0innmXWFwCc7NoDwMGjTrRuIWNMnbJA0BgN+E2Z/Y4D+YgAvD/tJXfPwYYqmTGmGbJA0BilpsOg24GyM4kAOlDAyRlX2x4Gxpg6Y4GgsRo+BUk8I2xyuni8/Lzoz/VfJmNMs2SBoDEb/SQirpA0FAApvs28++AlfP32Q7auwBhTKxYIGrOkNLj4qZBA4OxsBiM8y+mS/Ri+WZdYMDDG1JgFgsYuNR1XUMrq8hvauARbV2CMqRULBE3BoEmIu6UTDCR0ANmrQm6rFEtBYYypEUsx0RQkpUF6BpKXxY9fbuCY7W+WGUNe6B3ImhU7eTh/stM6iGsFN71taw2MMRGxFkFTkZQGg+/g2Btns7LLDWVOXe7+mEt+mIZ6i5wD1lVkjKkGCwRN0LlHfx0ygJzmyi3tMnLFWQoKY0zEohYIRKSViKwSkfUi8pmITAlzTUsReVlEtonIpyKSHK3yNCu9LgXKDRxTuuTgzWPGWbeQMSZi0WwRHAHOV9UUoC8wUkQGlrtmHLBfVbsDTwGPRrE8zUdqOtJzdJnFZhL0+LNv8pn36Vf1Xy5jTJMUtUCgjgL/03j/V/kejUuB2f7HrwIXiEiYtbQmxKBJiH9Dm4DAT25y3HxWLFvUIMUyxjQ9ouXnItblm4u4gRygO/Csqt5V7vwmYKSq7vY/3w4MUNUfy103HhgPkJiY2G/BggU1Kk9BQQEJCQk1em1j1OWbdzn18/8r0y0ETpfR574TONi+D0dOOBdP57Mifs+2+bm0P7CJA+1P52C7nnVe5vrQ3O5zJKzOsaE2dR46dGiOqqaGOxfVQFDyISLtgTeA/1bVTUHHIwoEwVJTUzU7O7tG5cjMzGTIkCE1em2jlT0LzZgUkpIocFt9rnjctyyKbMxg1yqYPQa8R5r0LmjN8j5XweocG2pTZxGpMBDUy6whVT0AfAiMLHfqayAJQETigHbA3vooU7ORmo6k3hI+DYWAy1cM6+dF9l55WeAp9O+CdsSmoBoTI6I5a6iTvyWAiLQGhgO55S5bCNzkf3wlsFTro4nS3KRci7jiwianA/Bkz4lstXHyYGdPZABx2xRUY2JENFsEXYAPRWQDsBp4X1UzROQBERnjv2Y60FFEtgG/ByZHsTzNV1IajHoCQcK2DNzqZduc31YdDJLS4NQRzuNzbmuS3ULGmOqLWooJVd0AhIxSqupfgh4XAldFqwwxJTUdAMn4HYoPtOyU0lOKtuKdMarq8YKE45zvHU6KXlmNMY2KrSxuTlLTYdy7SM+LUQmTqVSL+Xrdew1aRGNM42OBoLlJSoNfzcM16PaQ3c1U4ftVr/PpK080TNmMMY2SBYLmqlXbkEMC9HVtJ23TAxYMjDElLBA0V8mDUYkrs3dBoIsI4OSNT5G7+oOGKZsxplGxQNBcJaXhuvgJfP6xgvKTco+VQ5z6zpWQPatBimeMaTwsEDRnqemsP+tRio7uXGZns9LBY8Wb8Xvb0cyYGGeBoJk72K4nLf+4lUOJoVNGRUDUS+a7rzdAyYwxjYUFghjRdvTDqMsddvXx4h1F5OzcX+9lMsY0DhYIYkVSGq6Ln0QpO14gwEPxM/hxwW3WRWRMjLJAEEtS0/nq3L+G7GHgRhnx0yI800fCVyucE/t2NEgRjTH1zwJBjEkeMZEDJ44ICQaBnET8+LlzcOVz1kIwJkZYIIhBx4y4E8UdMqU0ODeRz+exdBTGxAgLBLEoKQ3XuMUUSsuQYBCgKtyxqo0NIhsTAywQxKqkNL479z4gdLGZw8doXUbGO29aMDCmmbNAEMOSR0xk7ymXhSSnA+cfxlj3Ev743R957MU5FgyMacYsEMS4Y2+cjQy6HV+544EB5JYUka4LWbnDdhA1prmyQGBg+BRnJlGYLiKXwIXubFJ/fMuZRZT1hM0mMqaZidoOZaZpOWb4nXimL3GmkFJ2BhFAr42P4v3sYVwoEtcSblronMjLcvY2tm0tjWmyrEVgHElpxI1bzHfH9CuToA6coNBGjuDGi+DD5ymC9fNg1sWw5EGYPcZaCcY0YRYITKmkNDpPWoqccXXYYBDgVeXgrs/AWwSo8z0vyzlp3UfGNDnWNWRCXfECeziGxA1TQUO7ieLw0ea7cr/okwc7v/xnjwZvMbj93UfWZWRMo2ctAhNWlyseZfXpf8FH+HUGZWKD+ucc5WWB54jzPLiVYIxp1KIWCEQkSUQ+FJHNIvKZiEwKc00HEXlDRDaIyCoROT1a5THVN+CqOzjYbUTIOoPyLQSF0kHjAHeLss+NMY1WNFsEHuAOVe0NDAQmikjvctf8CVinqmcCNwLPRLE8pgY6DL8TccWHpK8O5lP45LMvy7YArFvImCYjaoFAVb9V1TX+x4eALcAJ5S7rDSz1X5MLJItIYrTKZGogKQ1uXoSc0C/sCmQAF8o5376ELnmg7Ot2fgLLbeDYmMZOtKI/8+ryQ0SSgeXA6ap6MOj4X4HWqvo7EUkDPgEGqGpOudePB8YDJCYm9luwYEGNylFQUEBCQkKNXttU1VWd2+bnkrLuHlzqqSgelLG/bS86HNyCAj5XC9anPMjBdj1rXY5I2H2ODVbn6hk6dGiOqqaGOxf1QCAiCcAy4GFVfb3cubY43UFnARuBnsCvVXVdRe+Xmpqq2dnZNSpLZmYmQ4YMqdFrm6o6rfOuVbDoj+i3axGcrqLy4wXhueCCe2HwHXVTjirYfY4NVufqEZEKA0FEXUMiMklE2opjuoisEZEREbwuHngNmFs+CACo6kFVvVlV++KMEXQCbGusxiopDUb9LxLXGsUVstagYj5o3THapTPG1FCkYwS3+Lt0RgAdgBuARyp7gYgIMB3YoqpPVnBNexFp4X96K7A8uOvINEJJaXDTQuSCe9l78mVAJMFAYM86W2hmTCMV6YKyQAfAKOAlVf3M/4u+MoNwAsZGEQl09fwJOBFAVacCvYDZIqLAZ8C46hTeNJCkNEhK49jBsH/GVbT/qvKdzHworjUvOesLbKGZMY1OpIEgR0TeA04C7haRNhCSubgMVf2ICueZlFyzAjgtwjKYRqjD8Dth5lLU5wm7ChlAFPB5nCeBhWYWCIxpNCLtGhoHTAb6q+pPQDxwc9RKZZqOpDS4+T9Ipx4Vhv2Q4PD1Gsj4nXUTGdNIRBoIzgG2quoBEbkeuBfIj16xTJOSlAZj/om4W1S68AxA1Qu5GZA9A2aNtmBgTCMQaSB4DvhJRFKAO4DtwJyolco0PUlpkP4OP/a4ju+1fYXBoEzjwPIRGdMoRBoIPOosOLgU+KeqPgu0iV6xTJOUlEana59j/yXT8UoclU0mUnUGkdn2QWStAktvbUzURBoIDonI3TizgN4RERfOOIExIXr2H0Zc6o0lf/0HWgfl9zcQBd35Cb7pIyB7VsVvuGsVzL4Elj5km+AYEwWRBoJrgCM46wn2AF2Bx6JWKtP0pVwLca2dx1JJMABEFV/G7fD+feH/6s/LAk+hpbc2Jkoimj6qqntEZC7QX0RGA6tU1cYITMX8C8/Iy0IKD/LN1lW8+e0xjI/LCPlHJ/58Ffrx0wguiCu31sDSWxsTVREFAhG5GqcFkInzR9w/ROROVX01imUzTZ1/4RnA8cNhwM797J69nm7eXSFTSkuf+0LXGgSvObh2ga1BMKaORbqg7B6cNQTfA4hIJ+ADwAKBiVi/bh1g1B/QjEklXUSBABCcwM6nXvZ9uYFj82+Hgh8g4bjSN+l8Rv0W2pgYEGkgcAWCgN9ebJtLUxOp6QhQsHIGh7/fyXEccMYKgloIotBx+5uoP/1gmcaDp7AeC2tMbIj0l/liEXlXRNJFJB14B1gUvWKZZi01nYTfLufdPo/hRULWHAQCgxBmsbIFAmPqXKSDxXeKyBU4ieQApqnqG9ErlokFN15zNS9PzeWKb5+IuGnK7mxY8Y/SLqOUa23MwJhaivj/n6q+hrO3gDF15poJf+H7+Xs4duvcyJqnb4wv+3ztXEjPsGBgTC1U+n9PRA6JyMEwX4dExPYNMHXiuF+k44prjY9IN7oJYusKjKm1SgOBqrZR1bZhvtqoatv6KqRp5vxrDvb2uK7MmEFkQUEgf7etNjamFmzmj2kc/HmKdg96GJ+4Sja7qCoYKD40e0Zo6gnLTWRMxCIeIzCmPiSPmAi9+kNeFj9+uYGOO94MWXMQrCSfkednZP08SEoj8dslkPl3EJftiGZMBCwQmMYnaCtMsmfx9dLnSTy8GXcFO6AF+LLn4ELounupc0DDrFI2xoSwriHTuKWmc8IfV7Cv59hKNz51ktd50ewZHH04r/RoIDeRdRUZUyFrEZgm4bhfpMP21/F5ChFVRMqmpYDSx2XixYD/B+vnwZp/ga8Y4lrBTW9bC8GYINYiME2Df2aRKzUddbfA4z+sWvGAsqLw8TOQPdMJAmDTTY0Jw1oEpunwjx24Uq7DlZfFom1FdN/xEqe6vg5/veIkLipDoHVHp5soebC1DIwhioFARJJw9jVOxPkvOU1Vnyl3TTvgX8CJ/rI8rqozo1Um00z4A8KowfDe4j6csvJGXGG6i8INLKt6kXd+D+oFcUO/myxNhYl50ewa8gB3qGpvYCAwUUR6l7tmIrBZVVOAIcATItIiimUyzcyIkWNwD5pU4S5oYam39Hv2DJh1MWT8ztYhmJgVtRaBqn4LfOt/fEhEtgAnAJuDLwPaiIgACcA+KOn+NSYyw6cgHU7im5Uvs+jHTozwfkyS68dKp5qW4S1yAsK6+c6aA3D2SPYW2ToEExPqZYxARJKBs4BPy536J7AQ+AZoA1yjqj6Mqa7UdI5PTeesnfv53dRZzG/xAC0I/adUaWzwHCkdSA6ku65sHcKuVc65wNaZgccWNEwTE/VAICIJOFlLb1fV8onqLgTWAecDpwDvi0hW+etEZDwwHiAxMZHMzMwalaWgoKDGr22qYrHO551xKu98MZTLfEvC7oBWEUVZu+9oAM72H/OKm/X7juZguZ9h2/xcUtbdi0u9+ERwqxdF8LniWZ/yIAfb9azbSlUhFu+z1bnuRDUQiEg8ThCYq6qvh7nkZuARVVVgm4h8CfQEynTMquo0YBpAamqqDhkypEblyczMpKavbapisc5kZjJk8G5JwlIAABqNSURBVGQ8M7JwaxGo0wdJFcGg0J3AMa29JLcu3fzGfeV0zu49JvTirBxQZ0qqO5ACA8XtK+Zsdy4MmVB39YlALN5nq3Pdidpgsb/ffzqwRVWfrOCyr4AL/NcnAj2AHdEqk4khSWnE3fIOP/a4jgU6jKme0SWnKhpMbuU5RLeP/4QueaD04OeLww8an3hu6WNxB51QWDvPBplNkxLNFsEg4AZgo4is8x/7E85UUVR1KvAgMEtENuJ0396lqj9GsUwmliSl0enaNE7buZ/X1uzmvTV7GOHKDrsqGSpoLayb63yPa106aLxrFezILL1mwARY+Wzpc5/H8huZJiWas4Y+ooqxOVX9BhgRrTIYA9CvWwf6detAbte7KV50HW4twiVaEgwqy26q+P8RewpLB5JnXgQ+b+lFHbqVfVEgv5ExTYStLDYxo2f/YdA5w/mF3rojPyx/gWPzN5UEg7CtBP93Rfl85X/otmoOrXzlZjhLuR5Wm25qmhgLBCa2+FclA3RK7I1v1iV4PUUo4MZXcRNW4bSC1c7j8hdtejX0M4xpQizpnIldSWm40t9mU4//5jrPfbznTa1wIFmk9CvEVyvLPreBYtPEWCAwsS0pjb7XPcDk8TdRkDoRj7hLuoki2zM5jPLbZhrTyFnXkDEEBpQvJ/eEtuQs/D86aj7D3TklyewCIlmYFnY1sq1CNo2YBQJjgvTsP4zDx/XjtTW7ydvxb249+A/cQU2DSPIX+RBcrTuWHti1CmaOcpLcueIAAW8xxFkeI9M4WCAwppzAdFM4g9zV5xG/8h90PLCBtp79qCquKqacinpg0R3Ok8Te8OFfgzbGKca/zhm8R2y9gWkULBAYU4me/YdB/2EAvLd4IR0+/V9SfRsrbRkIoD4PmjEpdBBOXDg5L3xO6yDQVRTcdWSBwdQzCwTGRGjEyDHQpzNFM0YT5zuCUHFXkUDQarQg6oVjToZ9O+C8u0pXKs+62Fmk5m5h3UWm3tmsIWOqIymNFrdk8EWHX1a5GU5FK5X5aZ/z5NjTnO+57zgDzOoNv6eybZJjoswCgTHVlZRGj9vfRgbdDuIqs+tB1bujgRYecB7/+Lnz3RWUtK58eoovs2D6cFjyoE1LNVFjXUPG1NTwKUjPi5H18/DmvISoBwVclUwxLXN86UOQ9zF8uaz02MhHynYLffG+/4FWvkmOMbVggcCY2vCnrHCnXAd5WXy6B/ptegi3+iJIaKewY6lzPnBwy1vOTKPAL/uu/UpfEC6ZnX+QuW3+0TjbfhtTfRYIjKkL/oAwAMhr14qkT+4pWYxWVUK7MrYvhZ0rSgeMj+3hHA+35mDXqpJMqCniBvdWSLnWWgym2myMwJg6ljxiIu7RT+MTNx4ViohjnffkyN/A8zN8/DSbPn2Pta8/5hzzhdnKOy/L2fsAxaUeyJ5h4wimRqxFYEw0pKbjTuzNuqwM5n2XxEDXZlL27yj5y6uyVBUKkPsOvbYsQlCn6eArdgaNu50Lw6Y4f/UHdROVvJWNI5gasEBgTLQkpdH3ujT6AuxahXfGHNTnqTiLqZ/gBAq3hJmCtPMTmHEhXPwUpKaHnrdNcUwNWNeQMfUhKQ33xU+g4kZx/uoPXoNQftpppTmN1AcZt0P2rNBzthjN1IC1CIypL6npuBJ7w/p5UPADvq2L8QWmnFLFvq4h1AkG5X232VJVmGqzQGBMfQraIc3ln/r53uFT2bP6NW7wvFkyyyjQIqh8LEFDg0fGJECcRWqjnnCmolpgMFWwQGBMQ/EHhREAR3+Bb8lbzuAwZbuKKgwG4XIZBU74PPDO752A4POAu9z0U0tyZ4JYIDCmMUgejCuuFT5PER4RtnEC7X2H2Oo7gW6u70nmO1zl1yFU0Zek6kW8XueJp9DpkipJcjfaHyAsyZ2xQGBM45CUBjctxJWXRYvkwfzsO5VLp62g2KucLZ8zv8VDtFBPRBvjlCjTYlDImQMt28E3a5y9EMCmmxogioFARJKAOUAizj/Jaar6TLlr7gTGBpWlF9BJVfdFq1zGNFpB4wf9gAXjz2Hljr0MPPlclm05hcRP7udMtocEg4i2zwQnu+nHT5c9ZtNNDdFtEXiAO1R1jYi0AXJE5H1V3Ry4QFUfAx4DEJFLgN9ZEDDGUbpTGtBtDLkdj6Iw41paaJEzy6iKvZSrDA6ueOh+Aayf7zy3VkHMilogUNVvgW/9jw+JyBbgBGBzBS+5FpgfrfIY09T17D+MXOZzYMUcUve9jRufk5QUcFN5gruwfMWQm+E8zp4FXVKgX3r4hWrBg8tgA83NjGiVCdTr4ENEkoHlwOmqejDM+aOA3UD3cC0CERkPjAdITEzst2DBghqVo6CggISEhBq9tqmyOjdPbfNzSdzzIflHlL/nn0P7n3fxG/dbnOj6EahGMPALDCco8Plpt3H46G50+eZdVNwcansqp37xAqJefOLCpT5A8bniWZ/yIAfb9azj2kUmFu5zebWp89ChQ3NUNTXcuagHAhFJAJYBD6vq6xVccw1wvapeUtX7paamanZ2do3KkpmZyZAhQ2r02qbK6hwb7p/zPh/9EM+1h2aQrgsR/xqD6gYEwMl4uv9LZyAZnH2WNZD0LhAuAHHD+ffA4DtqX4EaTGeNxftcmzqLSIWBIKqzhkQkHngNmFtREPD7FdYtZEyNDTkxnvtvHAIM4b3FC/n+o1n8yr0Ut/8PvWoFhL1fBP3ip+xjyv3h2LpjDUscZNcqmH0JeI5AXCubztoAopZrSEQEmA5sUdUnK7muHXAe8Fa0ymJMLBkxcgy9fj2dx054hnWuXlXmNSpPNUzKa4CExHIXemHx5Nqnvc7LctY5BO/CZupVNJPODQJuAM4XkXX+r1EiMkFEJgRd91/Ae6p6OIplMSam9OvWgbvH38RZ961k9el/wYMbj4IXwUdpQAgXFMo3Hkou0TDNCs8RyPxbaTDYtQqynqhecAievuqOt+msDSCas4Y+IoI8Wqo6C5gVrXIYE+sGXHUHuckpbP5kEf/akwTAeHcGA1ybaS8/lVxX0XqEkkOH94R5d5+zq1reR3DRY05aC/VVr4snKY2SsYdfzbVuoQZgK4uNiQE9+w+jZ/9hdNu5n6nLtvP4D2cx7sA/+JV8UDcf4C2CtXOc7qLA82qtWPa3OzqfWTflMdVigcCYGNKvWwdeuNGZOPLe4oN4ViwlTn01X60cLK5V2eetOzrrE7a8Bb0uDb8+oTxvceXny69nMHXCAoExMWrEyDF88fUVnLLrFWc3TECUkOR2EGFg2Plx0Au8/m4ifwth+1JnSmqrtpVPEQ1MWQ0nMLvIWwTulrQ9435gSBWFMpGwQGBMDDt1xHiYnQHeIsTlxutTVD24qpMOuyKBIBDw8TPOG7ji4KzrIeXa0IDg81T8fiWziwBvEe0PbKpGYUxlLBAYE8v8WU/Jy8KVPBgX8MNHM+nw+auIFqMIH3jPZod25tdx/0HUi5sIUmBTdqaI89w/TclbBNkzYO1cSM8oGwwqaxEkD6ZkUNkdx4H2p9ew0qY8CwTGxLqgrKcAna5Ng103l/TF7/umM3M//IIP8lMZ6NrCKNdK+rh2Vr6LmjqzTYOzYCPlAoT3iNNK6D689HWZj8C5/x2+6ygpzVnLULAH/ut5Dv7QoS5qb7BAYIwJJyg4XJcE1w04kUcWHc//LT+Nlb5eLGjxIPFBXT/lE94FttxEyh4PkZtRmvgOYMtC+Pzd0JZCYJA4IPEM+GF37epoSlggMMZEZPKoXgzv05nX1pzIXduPZsDBd/H4lIPamqvcyzhWDpW5vtI1CZXxHnH2TUg4znlF5xRY9AfweSmZZvp1DifuzIJdR9m6gzpggcAYE7HSPRLOAMaT41+XsPzzNP7lvh+3fypqjaafBst9p/RxmaR3fm/8P05CYParlpuoDkQzxYQxppkLrEtY8NAkXuvyu5JUFgEVpbGIJOdR6cXhch+pkyyjotxE2zNh+eO1z4MUI6xFYIypE9dM+Au5q89l8yeLSNr/Cam6pXSsoJwjGkdLqWSqaAQUEHcLZ+Fa1hOl6xOyZ0HGJOeiuNbWYoiABQJjTJ0JpLLIXf0BhRnXEq/OL/s4yv5V7xLFi6ukK6kmFJBel5QuXBM3nDMRVvyz9CJPYTVTXcQm6xoyxtS5nv2HsXP0fJZ0+TXzOk3iZ43HG9Qd5EL5wHs2Htx4a7g3lgBs/HfpwjX1wif/CN0/oaZ7JtQkk2oTZS0CY0xUBFoHALmrf8Ge5TM55+Bi3OqjmDimeUczzTuaSXGvMdi1EVc1B5nDX1Y+qgj8vLf6O6DtWgWzLnZWOle2ErqZsEBgjIm64C6jnTnvsdbVh59/Ooktew7xjOcK0lpsJV6LnC6KWsw4Kr+iGXHBtiWw9CHnpNv/S71zihMgKgoMeVmlq5wDK6HXzW+24w0WCIwx9SYQEC4EJoN/+mkiY7f8iYGuLezTBO6Lf4kW/qAQHBAqai2UOR6S28JbNhle4Jd6QPBgcnCrIVx3UrVTazcdFgiMMQ0mMP00Z+cpvLZmN+t37mfsd0lc7s4K2XM5kvUJ1W5JeH6GD+6DTj2c3EeBrqBw3C2abfprCwTGmAZXulAN5n2azMur+/PJoeFcXvgqQ8gpCQgQms4icKzGC9h2fuJ8BXiLCRlrSEiEa/7VLFsDYIHAGNPIXDfgRK4bcCLwC+A35K7+gG3vv8iBn4rY5EtmiGs9w93ZuPy/q70IcVLDqUfhuONDs6C2OBrWz4OPnoaETtB3bLMKChYIjDGNWmBcYd6nX7Fl9Ves+OkSpu1fx+VuZ0VxH8mjr2t7SDbUSFoJIYPLAL0vc6alBtu3w/kKWDcP0t9pNsHAAoExpkkobSlAzs6+3D2/B58fUH7lWkJf1/aQTXQiETZOlA8C4XiLnLGF7sOg8CDs2RD5dpyNkAUCY0yT069bB/408CjanJTCyh09+E9eJ7p99Sq7Pe350JvCRe5V/MK1EXfQa2qdCK+88mMLFW3HWd01DA0gaoFARJKAOUAiTgtsmqo+E+a6IcDTQDzwo6qeF60yGWOal9JB5ruBu+kD7P30K9755F0GHpiMGyfFRaCFUH6guc6Dw8dPAwJxrZxpqQAzR4Gv2Jl1VL47qZEEiWi2CDzAHaq6RkTaADki8r6qbg5cICLtgf8DRqrqVyJyXBTLY4yJAU4X0q/5fv5aOm2diwA+hPe9/QAY5q54FlLdBAZ1chxl/g3ij3KCADjdSevnl20pzB7tzFJyt2zQxWpRCwSq+i3wrf/xIRHZApwAbA667DrgdVX9yn/d99EqjzEmthz3i3TY/jrqLaIYN9O8o1mjp3G29/OSgeZNvmROd+VxgWTTxZ0P1GEw2L6UkFGIH3Lhpf9yxhN+3gueI87x4MVqDdBKEI04KXgtPkQkGVgOnK6qB4OOB7qE+gBtgGdUdU6Y148HxgMkJib2W7BgQY3KUVBQQEJCQo1e21RZnWOD1Tm8tvm5tD+wiQPtT2eN71QW7Shiz2Hlu5+1TLK7u+Lm8Zu4DHxa+qs7uIVQneAQeFuh7Kwkn/9x4Hixuw0tvM6ubl5XC9anPMjRh7Zz2rYXEBSfxLOu70McbNezWnWuyNChQ3NUNTXcuagPFotIAvAacHtwEAj6/H7ABUBrYIWIrFTVz4MvUtVpwDSA1NRUHTJkSI3KkpmZSU1f21RZnWOD1bkipefPBm71P87ZuZ+VO/bS4agW7P+piHar2+E7DC4Bj4ILQVURnOduygaDygKDVPDYVe54IAgAuPvfytlFm2DbS6XXazFnu7fCkAnVrHP1RTUQiEg8ThCYq6qvh7lkN7BXVQ8Dh0VkOZACfB7mWmOMqRPBK5kB6J6OZ+Zr+HxFFBPHlOIbOEYK2KcJHCMFJHCY8XHvlBlbqK6waxYCPv2/Sl7lt2sVJ+58NSr7NEdz1pAA04EtqvpkBZe9BfxTROKAFsAA4KlolckYY8JKSiPu5rchL4ttrVJw7U5k6qqv8AX9Hv7Al8rl7iy68zUD3LnV/4xKI0EY4oLOfZ3Hu1bBjAs5STUq+zRHs0UwCLgB2Cgi6/zH/gScCKCqU1V1i4gsBjbgdKG9qKqbolgmY4wJLykNktLoCfy1P1xxdlemLtvOlz8UsHPfT6z1nsYaz2kATOVJLnRnV50NNUi1B6DVB4vugLVzoE1nUJ8TR6KQBTWas4Y+IoL4p6qPAY9FqxzGGFMTgcyoUDqmMPBkJz3162/t4YK9a4lTb8i+zD4EUS3ZaAdqMQvJ54Gvc0qeluzTXMdZUG1lsTHGVKH8mEK//xnHopnfMzzvMUS9CLDF14112p1NvmQejJ/lHBfwKrgiHGiuSKBXSRFk5CNNZ4zAGGOas1E3303u6v7s37yUDr3PZ4PvNO5/axNen0Ix/mDgo5h48vUoEjlQJhhA9bflFNRZf1DHLBAYY0wN9ew/DPz7MvcEenRu45+WegY3ZHTjbN9nrPT14jTZxd/ip5cEgE+9PSmgFcPi1pW8VyQtBS8u4qKwOY4FAmOMqSPBXUg9Ot/o7Lq2+ivW+E6DYrjIvYp3fWnM816AGy/b424o8/qqWgqqkLvnID2T6rbcFgiMMSYKAkHhirO78tqa3Qg3k3D2n7kCeP3FlfT2lC6XUoVi3Kzxnkov107ayc9h3zMOH3uWz3RaInXIAoExxkRRyOI1YO6tAynKzEK/pCQp3r+9Q7jXM46H4qYzVpZU2Cr4ev/P5OzcH/KeteGq+hJjjDF1qV+3Dpxz/mVIXGsQNxLXkl0nXkr3Tkez5biL8Ygb1fAb7Gz0JbNyR90OGFuLwBhjGkJSmrNCOC8LV/Jg7k5K424AhpC7uhtr336OnrqDFNcOXP7WgQ841l1Qsp6hrlggMMaYhuJfzVxez/7DOHxcP7av/ZCUDf8P9RUB4JU4Ro+5mp512C0EFgiMMaZRcsYWLod+XWH9PEDY5O3B2XU8UAwWCIwxpnELajUczMyMykfYYLExxsQ4CwTGGBPjLBAYY0yMs0BgjDExzgKBMcbEOAsExhgT40RrsRlzQxCRH4CdNXz5scCPdVicpsDqHBuszrGhNnXupqqdwp1ocoGgNkQkW1VTG7oc9cnqHBuszrEhWnW2riFjjIlxFgiMMSbGxVogmNbQBWgAVufYYHWODVGpc0yNERhjjAkVay0CY4wx5VggMMaYGBczgUBERorIVhHZJiKTG7o8dUVEkkTkQxHZLCKficgk//FjROR9EfnC/72D/7iIyN/9P4cNInJ2w9agZkTELSJrRSTD//wkEfnUX6+XRaSF/3hL//Nt/vPJDVnu2hCR9iLyqojkisgWETmnOd9nEfmd/9/0JhGZLyKtmuN9FpEZIvK9iGwKOlbt+yoiN/mv/0JEbqpOGWIiEIiIG3gWuAjoDVwrIr0btlR1xgPcoaq9gYHARH/dJgNLVPVUYIn/OTg/g1P9X+OB5+q/yHViErAl6PmjwFOq2h3YD4zzHx8H7Pcff8p/XVP1DLBYVXsCKTj1b5b3WUROAP4HSFXV0wE38Cua532eBYwsd6xa91VEjgHuAwYAacB9geAREVVt9l/AOcC7Qc/vBu5u6HJFqa5vAcOBrUAX/7EuwFb/4+eBa4OuL7muqXwBXf3/Oc4HMgDBWW0ZV/5+A+8C5/gfx/mvk4auQw3q3A74snzZm+t9Bk4AdgHH+O9bBnBhc73PQDKwqab3FbgWeD7oeJnrqvqKiRYBpf+oAnb7jzUr/ubwWcCnQKKqfus/tQdI9D9uDj+Lp4E/4uzlDdAROKCqHv/z4DqV1Nd/Pt9/fVNzEvADMNPfJfaiiBxNM73Pqvo18DjwFfAtzn3Lofnf54Dq3tda3e9YCQTNnogkAK8Bt6vqweBz6vyJ0CzmCYvIaOB7Vc1p6LLUszjgbOA5VT0LOExpdwHQ7O5zB+BSnAB4PHA0od0nMaE+7musBIKvgaSg5139x5oFEYnHCQJzVfV1/+HvRKSL/3wX4Hv/8ab+sxgEjBGRPGABTvfQM0B7EQnswR1cp5L6+s+3A/bWZ4HryG5gt6p+6n/+Kk5gaK73eRjwpar+oKrFwOs497653+eA6t7XWt3vWAkEq4FT/TMOWuAMOi1s4DLVCRERYDqwRVWfDDq1EAjMHLgJZ+wgcPxG/+yDgUB+UBO00VPVu1W1q6om49zHpao6FvgQuNJ/Wfn6Bn4OV/qvb3J/NavqHmCXiPTwH7oA2Ewzvc84XUIDReQo/7/xQH2b9X0OUt37+i4wQkQ6+FtTI/zHItPQgyT1OBgzCvgc2A7c09DlqcN6/QKn2bgBWOf/GoXTP7oE+AL4ADjGf73gzKDaDmzEmZXR4PWoYd2HABn+xycDq4BtwCtAS//xVv7n2/znT27octeivn2BbP+9fhPo0JzvMzAFyAU2AS8BLZvjfQbm44yDFOO0/MbV5L4Ct/jrvw24uTplsBQTxhgT42Kla8gYY0wFLBAYY0yMs0BgjDExzgKBMcbEOAsExhgT4ywQGFOPRGRIIGOqMY2FBQJjjIlxFgiMCUNErheRVSKyTkSe9+9/UCAiT/lz5C8RkU7+a/uKyEp/fvg3gnLHdxeRD0RkvYisEZFT/G+fELSvwFz/ylljGowFAmPKEZFewDXAIFXtC3iBsTiJz7JVtQ+wDCf/O8Ac4C5VPRNntWfg+FzgWVVNAc7FWT0KTobY23H2xjgZJ4eOMQ0mrupLjIk5FwD9gNX+P9Zb4yT98gEv+6/5F/C6iLQD2qvqMv/x2cArItIGOEFV3wBQ1UIA//utUtXd/ufrcHLRfxT9ahkTngUCY0IJMFtV7y5zUOTP5a6raX6WI0GPvdj/Q9PArGvImFBLgCtF5Dgo2T+2G87/l0Dmy+uAj1Q1H9gvIoP9x28AlqnqIWC3iFzmf4+WInJUvdbCmAjZXyLGlKOqm0XkXuA9EXHhZIWciLMZTJr/3Pc44wjgpAme6v9FvwO42X/8BuB5EXnA/x5X1WM1jImYZR81JkIiUqCqCQ1dDmPqmnUNGWNMjLMWgTHGxDhrERhjTIyzQGCMMTHOAoExxsQ4CwTGGBPjLBAYY0yM+/8WRFnz2LTonwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 学習経過の可視化(位置)\n",
    "position_loss     = position_history.history['loss']\n",
    "position_val_loss = position_history.history['val_loss']\n",
    "\n",
    "nb_epoch = len(position_loss)\n",
    "plt.plot(range(nb_epoch), position_loss,     marker='.', label='position_loss')\n",
    "plt.plot(range(nb_epoch), position_val_loss, marker='.', label='position_val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "cnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
