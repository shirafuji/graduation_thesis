{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 必要なライブラリのimport\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## データについて\n",
    "\n",
    "### データファイルのpath\n",
    "no_hole_path = './../vibration_simulation/vibration_data/no_hole_data.csv'\n",
    "one_hole_path = './../vibration_simulation/vibration_data/one_hole_data.csv'\n",
    "four_holes_path = './../vibration_simulation/vibration_data/four_holes_data.csv'\n",
    "nine_holes_path = './../vibration_simulation/vibration_data/nine_holes_data.csv'\n",
    "sixteen_holes_path = './../vibration_simulation/vibration_data/sixteen_holes_data.csv'\n",
    "twentyfive_holes_path = './../vibration_simulation/vibration_data/twentyfive_holes_data.csv'\n",
    "\n",
    "### 入力データと正解データ\n",
    "no_hole_data1 = []\n",
    "no_hole_data2 = []\n",
    "no_hole_data3 = []\n",
    "size_x_data = []\n",
    "size_x_data1 = []\n",
    "size_x_data2 = []\n",
    "size_x_data3 = []\n",
    "size_y_data = []\n",
    "position_x_data = []\n",
    "position_x_data1 = []\n",
    "position_x_data2 = []\n",
    "position_x_data3 = []\n",
    "position_one_data1 = []\n",
    "position_one_data2 = []\n",
    "position_one_data3 = []\n",
    "position_two_data1 = []\n",
    "position_two_data2 = []\n",
    "position_two_data3 = []\n",
    "position_three_data1 = []\n",
    "position_three_data2 = []\n",
    "position_three_data3 = []\n",
    "position_four_data1 = []\n",
    "position_four_data2 = []\n",
    "position_four_data3 = []\n",
    "position_five_data1 = []\n",
    "position_five_data2 = []\n",
    "position_five_data3 = []\n",
    "position_y_data = []\n",
    "\n",
    "### ファイル読み込み\n",
    "\n",
    "#### 欠陥がない場合のデータ\n",
    "with open(no_hole_path) as f:\n",
    "    for line in f:\n",
    "        data_array = line.split(' ')\n",
    "        no_hole_data1 = data_array[0:1251]\n",
    "        no_hole_data2 = data_array[1251:2502]\n",
    "        no_hole_data3 = data_array[2502:-1]\n",
    "        \n",
    "#### 大きさに関するデータ\n",
    "with open(one_hole_path) as fs1:\n",
    "  for line in fs1:\n",
    "    data_array = line.split(' ')\n",
    "    size_x_data1.append(data_array[3:1254])\n",
    "    size_x_data2.append(data_array[1254:2505])\n",
    "    size_x_data3.append(data_array[2505:-1])\n",
    "    size_y_data.append(data_array[0])\n",
    "with open(four_holes_path) as fs2:\n",
    "  for line in fs2:\n",
    "    data_array = line.split(' ')\n",
    "    size_x_data1.append(data_array[3:1254])\n",
    "    size_x_data2.append(data_array[1254:2505])\n",
    "    size_x_data3.append(data_array[2505:-1])\n",
    "    size_y_data.append(data_array[0])\n",
    "with open(nine_holes_path) as fs3:\n",
    "  for line in fs3:\n",
    "    data_array = line.split(' ')\n",
    "    size_x_data1.append(data_array[3:1254])\n",
    "    size_x_data2.append(data_array[1254:2505])\n",
    "    size_x_data3.append(data_array[2505:-1])\n",
    "    size_y_data.append(data_array[0])\n",
    "with open(sixteen_holes_path) as fs4:\n",
    "  for line in fs4:\n",
    "    data_array = line.split(' ')\n",
    "    size_x_data1.append(data_array[3:1254])\n",
    "    size_x_data2.append(data_array[1254:2505])\n",
    "    size_x_data3.append(data_array[2505:-1])\n",
    "    size_y_data.append(data_array[0])\n",
    "with open(twentyfive_holes_path) as fs5:\n",
    "  for line in fs5:\n",
    "    data_array = line.split(' ')\n",
    "    size_x_data1.append(data_array[3:1254])\n",
    "    size_x_data2.append(data_array[1254:2505])\n",
    "    size_x_data3.append(data_array[2505:-1])\n",
    "    size_y_data.append(data_array[0])\n",
    "\n",
    "#### 位置に関するデータ\n",
    "with open(one_hole_path) as fp1:\n",
    "  for line in fp1:\n",
    "    data_array = line.split(' ')\n",
    "    position_x_data1.append(data_array[3:1254])\n",
    "    position_x_data2.append(data_array[1254:2505])\n",
    "    position_x_data3.append(data_array[2505:-1])\n",
    "    position_one_data1.append(data_array[3:1254])\n",
    "    position_one_data2.append(data_array[1254:2505])\n",
    "    position_one_data3.append(data_array[2505:-1])\n",
    "    position_y_data.append(data_array[1:3])\n",
    "with open(four_holes_path) as fp2:\n",
    "  for line in fp2:\n",
    "    data_array = line.split(' ')\n",
    "    position_x_data1.append(data_array[3:1254])\n",
    "    position_x_data2.append(data_array[1254:2505])\n",
    "    position_x_data3.append(data_array[2505:-1])\n",
    "    position_two_data1.append(data_array[3:1254])\n",
    "    position_two_data2.append(data_array[1254:2505])\n",
    "    position_two_data3.append(data_array[2505:-1])\n",
    "    position_y_data.append(data_array[1:3])\n",
    "with open(nine_holes_path) as fp3:\n",
    "  for line in fp3:\n",
    "    data_array = line.split(' ')\n",
    "    position_x_data1.append(data_array[3:1254])\n",
    "    position_x_data2.append(data_array[1254:2505])\n",
    "    position_x_data3.append(data_array[2505:-1])\n",
    "    position_three_data1.append(data_array[3:1254])\n",
    "    position_three_data2.append(data_array[1254:2505])\n",
    "    position_three_data3.append(data_array[2505:-1])\n",
    "    position_y_data.append(data_array[1:3])\n",
    "with open(sixteen_holes_path) as fp4:\n",
    "  for line in fp4:\n",
    "    data_array = line.split(' ')\n",
    "    position_x_data1.append(data_array[3:1254])\n",
    "    position_x_data2.append(data_array[1254:2505])\n",
    "    position_x_data3.append(data_array[2505:-1])\n",
    "    position_four_data1.append(data_array[3:1254])\n",
    "    position_four_data2.append(data_array[1254:2505])\n",
    "    position_four_data3.append(data_array[2505:-1])\n",
    "    position_y_data.append(data_array[1:3])\n",
    "with open(twentyfive_holes_path) as fp5:\n",
    "  for line in fp5:\n",
    "    data_array = line.split(' ')\n",
    "    position_x_data1.append(data_array[3:1254])\n",
    "    position_x_data2.append(data_array[1254:2505])\n",
    "    position_x_data3.append(data_array[2505:-1])\n",
    "    position_five_data1.append(data_array[3:1254])\n",
    "    position_five_data2.append(data_array[1254:2505])\n",
    "    position_five_data3.append(data_array[2505:-1])\n",
    "    position_y_data.append(data_array[1:3])\n",
    "\n",
    "### 各配列をnp.array型にして各要素を型変換\n",
    "no_hole_data1 = np.array(no_hole_data1, dtype=float)\n",
    "no_hole_data2 = np.array(no_hole_data2, dtype=float)\n",
    "no_hole_data3 = np.array(no_hole_data3, dtype=float)\n",
    "size_x_data1 = np.array(size_x_data1, dtype=float)\n",
    "size_x_data2 = np.array(size_x_data2, dtype=float)\n",
    "size_x_data3 = np.array(size_x_data3, dtype=float)\n",
    "size_y_data = np.array(size_y_data, dtype=int)\n",
    "position_x_data1 = np.array(position_x_data1, dtype=float)\n",
    "position_x_data2 = np.array(position_x_data2, dtype=float)\n",
    "position_x_data3 = np.array(position_x_data3, dtype=float)\n",
    "position_one_data1 = np.array(position_one_data1, dtype=float)\n",
    "position_two_data1 = np.array(position_two_data1, dtype=float)\n",
    "position_three_data1 = np.array(position_three_data1, dtype=float)\n",
    "position_four_data1 = np.array(position_four_data1, dtype=float)\n",
    "position_five_data1 = np.array(position_five_data1, dtype=float)\n",
    "position_one_data2 = np.array(position_one_data2, dtype=float)\n",
    "position_two_data2 = np.array(position_two_data2, dtype=float)\n",
    "position_three_data2 = np.array(position_three_data2, dtype=float)\n",
    "position_four_data2 = np.array(position_four_data2, dtype=float)\n",
    "position_five_data2 = np.array(position_five_data2, dtype=float)\n",
    "position_one_data3 = np.array(position_one_data3, dtype=float)\n",
    "position_two_data3 = np.array(position_two_data3, dtype=float)\n",
    "position_three_data3 = np.array(position_three_data3, dtype=float)\n",
    "position_four_data3 = np.array(position_four_data3, dtype=float)\n",
    "position_five_data3 = np.array(position_five_data3, dtype=float)\n",
    "position_y_data = np.array(position_y_data, dtype=float)\n",
    "\n",
    "### データの加工\n",
    "# 最大値で割る\n",
    "max_displacement = size_x_data2.max()\n",
    "size_x_data1 = size_x_data1/max_displacement\n",
    "size_x_data2 = size_x_data2/max_displacement\n",
    "size_x_data3 = size_x_data3/max_displacement\n",
    "position_x_data1 = position_x_data1/max_displacement\n",
    "position_x_data2 = position_x_data2/max_displacement\n",
    "position_x_data3 = position_x_data3/max_displacement\n",
    "position_one_data1 = position_one_data1/max_displacement\n",
    "position_one_data2 = position_one_data2/max_displacement\n",
    "position_one_data3 = position_one_data3/max_displacement\n",
    "position_two_data1 = position_two_data1/max_displacement\n",
    "position_two_data2 = position_two_data2/max_displacement\n",
    "position_two_data3 = position_two_data3/max_displacement\n",
    "position_three_data1 = position_three_data1/max_displacement\n",
    "position_three_data2 = position_three_data2/max_displacement\n",
    "position_three_data3 = position_three_data3/max_displacement\n",
    "position_four_data1 = position_four_data1/max_displacement\n",
    "position_four_data2 = position_four_data2/max_displacement\n",
    "position_four_data3 = position_four_data3/max_displacement\n",
    "position_five_data1 = position_five_data1/max_displacement\n",
    "position_five_data2 = position_five_data2/max_displacement\n",
    "position_five_data3 = position_five_data3/max_displacement\n",
    "\n",
    "# 実験2:差をとると精度が向上するか\n",
    "# size_x_data = (size_x_data-no_hole_data)\n",
    "# position_x_data = (position_x_data-no_hole_data)\n",
    "\n",
    "# position_one_data = (position_one_data-no_hole_data)\n",
    "# position_two_data = (position_two_data-no_hole_data)\n",
    "# position_three_data = (position_three_data-no_hole_data)\n",
    "# position_four_data = (position_four_data-no_hole_data)\n",
    "# position_five_data = (position_five_data-no_hole_data)\n",
    "position_y_data = position_y_data/50\n",
    "\n",
    "### train用とtest用に分割(9:1)\n",
    "size_x_train1, size_x_test1, size_x_train2, size_x_test2, size_x_train3, size_x_test3, size_y_train, size_y_test = train_test_split(size_x_data1, size_x_data2, size_x_data3, size_y_data, test_size=0.10)\n",
    "position_x_train1, position_x_test1, position_x_train2, position_x_test2, position_x_train3, position_x_test3, position_y_train, position_y_test = train_test_split(position_x_data1, position_x_data2, position_x_data3, position_y_data, test_size=0.10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2424, 1251)\n",
      "(270, 1251)\n",
      "(484, 1251)\n",
      "(529, 1251)\n",
      "(529, 1251)\n",
      "(576, 1251)\n",
      "(576, 1251)\n",
      "2694\n"
     ]
    }
   ],
   "source": [
    "print(size_x_train1.shape)\n",
    "print(size_x_test1.shape)\n",
    "print(position_five_data1.shape)\n",
    "print(position_four_data1.shape)\n",
    "print(position_three_data1.shape)\n",
    "print(position_two_data1.shape)\n",
    "print(position_one_data1.shape)\n",
    "print(484+529+529+576+576)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1251)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1251)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 1251)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            1252        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            1252        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            1252        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 3)            0           dense[0][0]                      \n",
      "                                                                 dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           128         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            33          dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,917\n",
      "Trainable params: 3,917\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#単純モデル\n",
    "# import\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, concatenate, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
    "\n",
    "# 入力を定義\n",
    "input1 = Input(shape=(1251,))\n",
    "input2 = Input(shape=(1251,))\n",
    "input3 = Input(shape=(1251,))\n",
    "\n",
    "# 入力1から結合前まで\n",
    "x = Dense(1, activation=\"linear\")(input1)\n",
    "x = Model(inputs=input1, outputs=x)\n",
    "# 入力2から結合前まで\n",
    "y = Dense(1, activation=\"linear\")(input2)\n",
    "y = Model(inputs=input2, outputs=y)\n",
    "# 入力3から結合前まで\n",
    "z = Dense(1, activation=\"linear\")(input3)\n",
    "z = Model(inputs=input3, outputs=z)\n",
    "\n",
    "# 結合\n",
    "combined = concatenate([x.output, y.output, z.output])\n",
    "\n",
    "# 密結合\n",
    "w = Dense(32, activation=\"tanh\")(combined)\n",
    "w = Dense(1, activation=\"linear\")(w)\n",
    "\n",
    "# モデル定義とコンパイル\n",
    "model = Model(inputs=[x.input, y.input, z.input], outputs=w)\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['acc'])\n",
    "model.summary()\n",
    "plot_model(model, show_shapes=True, show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1251, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1251, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 1251, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 1251, 32)     128         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 1251, 32)     128         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1251, 32)     128         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 626, 32)      0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 626, 32)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 626, 32)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 626, 96)      0           max_pooling1d[0][0]              \n",
      "                                                                 max_pooling1d_1[0][0]            \n",
      "                                                                 max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 60096)        0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            60097       flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 60,481\n",
      "Trainable params: 60,481\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNNモデルで大きさ推定\n",
    "# import\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, concatenate, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
    "\n",
    "# 入力を定義\n",
    "input1 = Input(shape=(1251,1))\n",
    "input2 = Input(shape=(1251,1))\n",
    "input3 = Input(shape=(1251,1))\n",
    "\n",
    "# 入力1から結合前まで\n",
    "x = Conv1D(32, 3, padding='same', activation='tanh')(input1)\n",
    "x = MaxPooling1D(2, padding='same')(x)\n",
    "x = Model(inputs=input1, outputs=x)\n",
    "# 入力2から結合前まで\n",
    "y = Conv1D(32, 3, padding='same', activation='tanh')(input2)\n",
    "y = MaxPooling1D(2, padding='same')(y)\n",
    "y = Model(inputs=input2, outputs=y)\n",
    "# 入力3から結合前まで\n",
    "z = Conv1D(32, 3, padding='same', activation='tanh')(input3)\n",
    "z = MaxPooling1D(2, padding='same')(z)\n",
    "z = Model(inputs=input3, outputs=z)\n",
    "\n",
    "# 結合\n",
    "combined = concatenate([x.output, y.output, z.output])\n",
    "\n",
    "# 密結合\n",
    "cnn = Flatten()(combined)\n",
    "cnn = Dense(1, activation=\"linear\")(cnn)\n",
    "\n",
    "# モデル定義とコンパイル\n",
    "cnn_size_model = Model(inputs=[x.input, y.input, z.input], outputs=cnn)\n",
    "cnn_size_model.compile(loss='mse', optimizer='adam', metrics=['acc'])\n",
    "cnn_size_model.summary()\n",
    "plot_model(cnn_size_model, show_shapes=True, show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 2.5322 - acc: 0.2075 - val_loss: 2.0579 - val_acc: 0.2074\n",
      "Epoch 2/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 1.9593 - acc: 0.2145 - val_loss: 1.9222 - val_acc: 0.2074\n",
      "Epoch 3/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.9327 - acc: 0.2145 - val_loss: 2.0496 - val_acc: 0.2074\n",
      "Epoch 4/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.8831 - acc: 0.2145 - val_loss: 1.8302 - val_acc: 0.2074\n",
      "Epoch 5/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 1.8443 - acc: 0.2145 - val_loss: 1.7964 - val_acc: 0.2074\n",
      "Epoch 6/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.8365 - acc: 0.2145 - val_loss: 1.8286 - val_acc: 0.2074\n",
      "Epoch 7/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 1.7587 - acc: 0.2145 - val_loss: 1.7297 - val_acc: 0.2074\n",
      "Epoch 8/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.7675 - acc: 0.2145 - val_loss: 1.6787 - val_acc: 0.2074\n",
      "Epoch 9/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.7214 - acc: 0.2145 - val_loss: 1.6524 - val_acc: 0.2074\n",
      "Epoch 10/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.6897 - acc: 0.2145 - val_loss: 1.6539 - val_acc: 0.2074\n",
      "Epoch 11/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 1.7169 - acc: 0.2145 - val_loss: 1.6119 - val_acc: 0.2074\n",
      "Epoch 12/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.6219 - acc: 0.2145 - val_loss: 1.6032 - val_acc: 0.2074\n",
      "Epoch 13/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.5770 - acc: 0.2145 - val_loss: 1.5654 - val_acc: 0.2074\n",
      "Epoch 14/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.5384 - acc: 0.2145 - val_loss: 1.5430 - val_acc: 0.2074\n",
      "Epoch 15/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 1.5350 - acc: 0.2145 - val_loss: 1.6474 - val_acc: 0.2074\n",
      "Epoch 16/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.5589 - acc: 0.2145 - val_loss: 1.5124 - val_acc: 0.2074\n",
      "Epoch 17/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 1.5124 - acc: 0.2145 - val_loss: 1.5203 - val_acc: 0.2074\n",
      "Epoch 18/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 1.4425 - acc: 0.2145 - val_loss: 1.4577 - val_acc: 0.2074\n",
      "Epoch 19/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 1.6254 - acc: 0.2145 - val_loss: 1.4847 - val_acc: 0.2074\n",
      "Epoch 20/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 1.4446 - acc: 0.2145 - val_loss: 1.5803 - val_acc: 0.2074\n",
      "Epoch 21/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 1.4018 - acc: 0.2145 - val_loss: 1.4126 - val_acc: 0.2074\n",
      "Epoch 22/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 1.3626 - acc: 0.2145 - val_loss: 1.3875 - val_acc: 0.2074\n",
      "Epoch 23/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 1.3418 - acc: 0.2145 - val_loss: 1.3641 - val_acc: 0.2074\n",
      "Epoch 24/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.3253 - acc: 0.2145 - val_loss: 1.4428 - val_acc: 0.2074\n",
      "Epoch 25/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.3201 - acc: 0.2145 - val_loss: 1.4682 - val_acc: 0.2074\n",
      "Epoch 26/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 1.3553 - acc: 0.2145 - val_loss: 1.3408 - val_acc: 0.2074\n",
      "Epoch 27/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.3058 - acc: 0.2145 - val_loss: 1.4111 - val_acc: 0.2074\n",
      "Epoch 28/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.3566 - acc: 0.2145 - val_loss: 1.3270 - val_acc: 0.2074\n",
      "Epoch 29/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.4645 - acc: 0.2145 - val_loss: 1.3514 - val_acc: 0.2074\n",
      "Epoch 30/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 1.3004 - acc: 0.2145 - val_loss: 1.3017 - val_acc: 0.2074\n",
      "Epoch 31/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.2354 - acc: 0.2145 - val_loss: 1.2764 - val_acc: 0.2074\n",
      "Epoch 32/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.2026 - acc: 0.2145 - val_loss: 1.3017 - val_acc: 0.2074\n",
      "Epoch 33/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.1982 - acc: 0.2145 - val_loss: 1.2671 - val_acc: 0.2074\n",
      "Epoch 34/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.1819 - acc: 0.2145 - val_loss: 1.2267 - val_acc: 0.2074\n",
      "Epoch 35/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.1748 - acc: 0.2145 - val_loss: 1.2754 - val_acc: 0.2074\n",
      "Epoch 36/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.1602 - acc: 0.2145 - val_loss: 1.1952 - val_acc: 0.2074\n",
      "Epoch 37/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 1.1860 - acc: 0.2145 - val_loss: 1.2271 - val_acc: 0.2074\n",
      "Epoch 38/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 1.1339 - acc: 0.2145 - val_loss: 1.2148 - val_acc: 0.2074\n",
      "Epoch 39/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.1136 - acc: 0.2145 - val_loss: 1.2077 - val_acc: 0.2074\n",
      "Epoch 40/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.1298 - acc: 0.2145 - val_loss: 1.1814 - val_acc: 0.2074\n",
      "Epoch 41/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.1715 - acc: 0.2145 - val_loss: 1.1808 - val_acc: 0.2074\n",
      "Epoch 42/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.1568 - acc: 0.2145 - val_loss: 1.2020 - val_acc: 0.2074\n",
      "Epoch 43/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 1.0756 - acc: 0.2145 - val_loss: 1.1316 - val_acc: 0.2074\n",
      "Epoch 44/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.0706 - acc: 0.2145 - val_loss: 1.1550 - val_acc: 0.2074\n",
      "Epoch 45/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 1.0725 - acc: 0.2145 - val_loss: 1.1127 - val_acc: 0.2074\n",
      "Epoch 46/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 1.0962 - acc: 0.2145 - val_loss: 1.1732 - val_acc: 0.2074\n",
      "Epoch 47/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 1.1091 - acc: 0.2145 - val_loss: 1.1510 - val_acc: 0.2074\n",
      "Epoch 48/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.1515 - acc: 0.2145 - val_loss: 1.2015 - val_acc: 0.2074\n",
      "Epoch 49/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 1.2397 - acc: 0.2145 - val_loss: 1.1319 - val_acc: 0.2074\n",
      "Epoch 50/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.3690 - acc: 0.2145 - val_loss: 1.1190 - val_acc: 0.2074\n",
      "Epoch 51/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 1.0627 - acc: 0.2145 - val_loss: 1.0954 - val_acc: 0.2074\n",
      "Epoch 52/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.0719 - acc: 0.2145 - val_loss: 1.2109 - val_acc: 0.2074\n",
      "Epoch 53/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 1.0286 - acc: 0.2145 - val_loss: 1.1822 - val_acc: 0.2074\n",
      "Epoch 54/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.0220 - acc: 0.2145 - val_loss: 1.1575 - val_acc: 0.2074\n",
      "Epoch 55/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 1.0070 - acc: 0.2145 - val_loss: 1.0766 - val_acc: 0.2074\n",
      "Epoch 56/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.9954 - acc: 0.2145 - val_loss: 1.0528 - val_acc: 0.2074\n",
      "Epoch 57/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.0281 - acc: 0.2145 - val_loss: 1.0656 - val_acc: 0.2074\n",
      "Epoch 58/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.9963 - acc: 0.2145 - val_loss: 1.0486 - val_acc: 0.2074\n",
      "Epoch 59/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.9881 - acc: 0.2145 - val_loss: 1.0946 - val_acc: 0.2074\n",
      "Epoch 60/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.9581 - acc: 0.2145 - val_loss: 1.0753 - val_acc: 0.2074\n",
      "Epoch 61/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.9765 - acc: 0.2145 - val_loss: 1.0589 - val_acc: 0.2074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.9692 - acc: 0.2145 - val_loss: 1.0354 - val_acc: 0.2074\n",
      "Epoch 63/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.9814 - acc: 0.2145 - val_loss: 1.0217 - val_acc: 0.2074\n",
      "Epoch 64/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.9611 - acc: 0.2145 - val_loss: 1.0127 - val_acc: 0.2074\n",
      "Epoch 65/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.9400 - acc: 0.2145 - val_loss: 1.0043 - val_acc: 0.2074\n",
      "Epoch 66/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.9479 - acc: 0.2145 - val_loss: 1.0168 - val_acc: 0.2074\n",
      "Epoch 67/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 1.2934 - acc: 0.2145 - val_loss: 2.2919 - val_acc: 0.2074\n",
      "Epoch 68/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.0631 - acc: 0.2145 - val_loss: 1.0541 - val_acc: 0.2074\n",
      "Epoch 69/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.9305 - acc: 0.2145 - val_loss: 1.0086 - val_acc: 0.2074\n",
      "Epoch 70/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.9195 - acc: 0.2145 - val_loss: 1.0040 - val_acc: 0.2074\n",
      "Epoch 71/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.9157 - acc: 0.2145 - val_loss: 1.0233 - val_acc: 0.2074\n",
      "Epoch 72/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.9973 - acc: 0.2145 - val_loss: 0.9888 - val_acc: 0.2074\n",
      "Epoch 73/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.9495 - acc: 0.2145 - val_loss: 0.9953 - val_acc: 0.2074\n",
      "Epoch 74/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.9384 - acc: 0.2145 - val_loss: 0.9858 - val_acc: 0.2074\n",
      "Epoch 75/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.9175 - acc: 0.2145 - val_loss: 1.0062 - val_acc: 0.2074\n",
      "Epoch 76/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.9081 - acc: 0.2145 - val_loss: 0.9730 - val_acc: 0.2074\n",
      "Epoch 77/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.8775 - acc: 0.2145 - val_loss: 0.9704 - val_acc: 0.2074\n",
      "Epoch 78/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.8772 - acc: 0.2145 - val_loss: 0.9851 - val_acc: 0.2074\n",
      "Epoch 79/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.8808 - acc: 0.2145 - val_loss: 1.0038 - val_acc: 0.2074\n",
      "Epoch 80/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.9711 - acc: 0.2145 - val_loss: 1.3566 - val_acc: 0.2037\n",
      "Epoch 81/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.9250 - acc: 0.2145 - val_loss: 0.9665 - val_acc: 0.2074\n",
      "Epoch 82/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.9493 - acc: 0.2145 - val_loss: 1.0720 - val_acc: 0.2074\n",
      "Epoch 83/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.8699 - acc: 0.2145 - val_loss: 0.9762 - val_acc: 0.2074\n",
      "Epoch 84/10000\n",
      "76/76 [==============================] - 6s 74ms/step - loss: 0.8914 - acc: 0.2145 - val_loss: 0.9727 - val_acc: 0.2074\n",
      "Epoch 85/10000\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 0.8726 - acc: 0.2145 - val_loss: 0.9575 - val_acc: 0.2074\n",
      "Epoch 86/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.8473 - acc: 0.2145 - val_loss: 0.9546 - val_acc: 0.2074\n",
      "Epoch 87/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.9449 - acc: 0.2145 - val_loss: 0.9617 - val_acc: 0.2074\n",
      "Epoch 88/10000\n",
      "76/76 [==============================] - 4s 46ms/step - loss: 0.8383 - acc: 0.2145 - val_loss: 1.0390 - val_acc: 0.2074\n",
      "Epoch 89/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.8643 - acc: 0.2145 - val_loss: 1.1457 - val_acc: 0.2037\n",
      "Epoch 90/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.8519 - acc: 0.2145 - val_loss: 1.0643 - val_acc: 0.2074\n",
      "Epoch 91/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.8752 - acc: 0.2145 - val_loss: 0.9526 - val_acc: 0.2074\n",
      "Epoch 92/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.8088 - acc: 0.2145 - val_loss: 0.9852 - val_acc: 0.2074\n",
      "Epoch 93/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.8049 - acc: 0.2145 - val_loss: 1.0569 - val_acc: 0.2037\n",
      "Epoch 94/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.8779 - acc: 0.2145 - val_loss: 0.9483 - val_acc: 0.2074\n",
      "Epoch 95/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 1.0287 - acc: 0.2145 - val_loss: 0.9584 - val_acc: 0.2074\n",
      "Epoch 96/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.9410 - acc: 0.2145 - val_loss: 0.9268 - val_acc: 0.2074\n",
      "Epoch 97/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.9108 - acc: 0.2145 - val_loss: 0.9398 - val_acc: 0.2074\n",
      "Epoch 98/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.9353 - acc: 0.2145 - val_loss: 0.9187 - val_acc: 0.2074\n",
      "Epoch 99/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.8724 - acc: 0.2145 - val_loss: 0.9229 - val_acc: 0.2074\n",
      "Epoch 100/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.8248 - acc: 0.2145 - val_loss: 0.9601 - val_acc: 0.2074\n",
      "Epoch 101/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.8165 - acc: 0.2145 - val_loss: 0.9933 - val_acc: 0.2074\n",
      "Epoch 102/10000\n",
      "76/76 [==============================] - 3s 46ms/step - loss: 0.8283 - acc: 0.2145 - val_loss: 0.9115 - val_acc: 0.2074\n",
      "Epoch 103/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.8311 - acc: 0.2145 - val_loss: 1.0593 - val_acc: 0.2074\n",
      "Epoch 104/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 1.5199 - acc: 0.2145 - val_loss: 1.0504 - val_acc: 0.2037\n",
      "Epoch 105/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.8347 - acc: 0.2145 - val_loss: 1.0136 - val_acc: 0.2074\n",
      "Epoch 106/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.8201 - acc: 0.2145 - val_loss: 0.9010 - val_acc: 0.2074\n",
      "Epoch 107/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.7922 - acc: 0.2145 - val_loss: 0.9105 - val_acc: 0.2074\n",
      "Epoch 108/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.7802 - acc: 0.2145 - val_loss: 0.9986 - val_acc: 0.2074\n",
      "Epoch 109/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.8153 - acc: 0.2145 - val_loss: 0.8902 - val_acc: 0.2074\n",
      "Epoch 110/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.8475 - acc: 0.2145 - val_loss: 1.0106 - val_acc: 0.2037\n",
      "Epoch 111/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.7813 - acc: 0.2145 - val_loss: 0.8809 - val_acc: 0.2074\n",
      "Epoch 112/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.8029 - acc: 0.2145 - val_loss: 0.9552 - val_acc: 0.2074\n",
      "Epoch 113/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.8407 - acc: 0.2145 - val_loss: 0.9566 - val_acc: 0.2037\n",
      "Epoch 114/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.8263 - acc: 0.2145 - val_loss: 0.8965 - val_acc: 0.2074\n",
      "Epoch 115/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.8123 - acc: 0.2145 - val_loss: 0.9449 - val_acc: 0.2074\n",
      "Epoch 116/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.7505 - acc: 0.2145 - val_loss: 0.9026 - val_acc: 0.2074\n",
      "Epoch 117/10000\n",
      "76/76 [==============================] - 5s 61ms/step - loss: 0.7896 - acc: 0.2141 - val_loss: 0.8943 - val_acc: 0.2037\n",
      "Epoch 118/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.7896 - acc: 0.2145 - val_loss: 1.1546 - val_acc: 0.2037\n",
      "Epoch 119/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.7630 - acc: 0.2145 - val_loss: 0.9130 - val_acc: 0.2074\n",
      "Epoch 120/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.7829 - acc: 0.2145 - val_loss: 0.9615 - val_acc: 0.2074\n",
      "Epoch 121/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.8855 - acc: 0.2145 - val_loss: 0.8997 - val_acc: 0.2037\n",
      "Epoch 122/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 4s 47ms/step - loss: 0.8161 - acc: 0.2145 - val_loss: 0.8816 - val_acc: 0.2074\n",
      "Epoch 123/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.7833 - acc: 0.2141 - val_loss: 0.8832 - val_acc: 0.2037\n",
      "Epoch 124/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.7744 - acc: 0.2145 - val_loss: 0.8933 - val_acc: 0.2037\n",
      "Epoch 125/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.7475 - acc: 0.2145 - val_loss: 1.0848 - val_acc: 0.2037\n",
      "Epoch 126/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.7474 - acc: 0.2145 - val_loss: 0.8968 - val_acc: 0.2074\n",
      "Epoch 127/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.7441 - acc: 0.2145 - val_loss: 0.8938 - val_acc: 0.2037\n",
      "Epoch 128/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.7723 - acc: 0.2145 - val_loss: 0.8718 - val_acc: 0.2037\n",
      "Epoch 129/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.7624 - acc: 0.2145 - val_loss: 0.9512 - val_acc: 0.2074\n",
      "Epoch 130/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.7396 - acc: 0.2145 - val_loss: 0.8611 - val_acc: 0.2037\n",
      "Epoch 131/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.7268 - acc: 0.2145 - val_loss: 0.8770 - val_acc: 0.2037\n",
      "Epoch 132/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.7598 - acc: 0.2145 - val_loss: 0.8628 - val_acc: 0.2037\n",
      "Epoch 133/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 1.1352 - acc: 0.2141 - val_loss: 1.0140 - val_acc: 0.2037\n",
      "Epoch 134/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 1.6860 - acc: 0.2141 - val_loss: 1.0309 - val_acc: 0.2074\n",
      "Epoch 135/10000\n",
      "76/76 [==============================] - 5s 60ms/step - loss: 1.2044 - acc: 0.2141 - val_loss: 0.9402 - val_acc: 0.2074\n",
      "Epoch 136/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.7764 - acc: 0.2145 - val_loss: 0.9709 - val_acc: 0.2037\n",
      "Epoch 137/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.7510 - acc: 0.2145 - val_loss: 0.9674 - val_acc: 0.2037\n",
      "Epoch 138/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.7333 - acc: 0.2145 - val_loss: 0.8740 - val_acc: 0.2037\n",
      "Epoch 139/10000\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 0.7177 - acc: 0.2145 - val_loss: 0.9064 - val_acc: 0.2074\n",
      "Epoch 140/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.7129 - acc: 0.2145 - val_loss: 0.8635 - val_acc: 0.2074\n",
      "Epoch 141/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.7223 - acc: 0.2145 - val_loss: 0.8586 - val_acc: 0.2037\n",
      "Epoch 142/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.7895 - acc: 0.2145 - val_loss: 1.0744 - val_acc: 0.2037\n",
      "Epoch 143/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.7318 - acc: 0.2145 - val_loss: 0.8553 - val_acc: 0.2037\n",
      "Epoch 144/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.7352 - acc: 0.2141 - val_loss: 0.9498 - val_acc: 0.2074\n",
      "Epoch 145/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.7265 - acc: 0.2141 - val_loss: 0.8548 - val_acc: 0.2037\n",
      "Epoch 146/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.7122 - acc: 0.2145 - val_loss: 0.8505 - val_acc: 0.2037\n",
      "Epoch 147/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.6988 - acc: 0.2141 - val_loss: 0.8671 - val_acc: 0.2037\n",
      "Epoch 148/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.7047 - acc: 0.2145 - val_loss: 0.8827 - val_acc: 0.2037\n",
      "Epoch 149/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.7174 - acc: 0.2141 - val_loss: 0.8523 - val_acc: 0.2037\n",
      "Epoch 150/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.6991 - acc: 0.2141 - val_loss: 0.8510 - val_acc: 0.2037\n",
      "Epoch 151/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.7050 - acc: 0.2145 - val_loss: 0.9514 - val_acc: 0.2037\n",
      "Epoch 152/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.7300 - acc: 0.2141 - val_loss: 0.8484 - val_acc: 0.2037\n",
      "Epoch 153/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.7094 - acc: 0.2145 - val_loss: 0.8594 - val_acc: 0.2037\n",
      "Epoch 154/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.7359 - acc: 0.2141 - val_loss: 0.9595 - val_acc: 0.2037\n",
      "Epoch 155/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.7020 - acc: 0.2141 - val_loss: 1.1325 - val_acc: 0.2037\n",
      "Epoch 156/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.8139 - acc: 0.2145 - val_loss: 0.8574 - val_acc: 0.2037\n",
      "Epoch 157/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.7563 - acc: 0.2141 - val_loss: 0.8386 - val_acc: 0.2037\n",
      "Epoch 158/10000\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.7535 - acc: 0.214 - 4s 55ms/step - loss: 0.7535 - acc: 0.2141 - val_loss: 0.8742 - val_acc: 0.2037\n",
      "Epoch 159/10000\n",
      "76/76 [==============================] - 5s 72ms/step - loss: 0.8841 - acc: 0.2137 - val_loss: 0.8730 - val_acc: 0.2037\n",
      "Epoch 160/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 1.1726 - acc: 0.2137 - val_loss: 1.5126 - val_acc: 0.2074\n",
      "Epoch 161/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.9105 - acc: 0.2137 - val_loss: 0.8929 - val_acc: 0.2074\n",
      "Epoch 162/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.7574 - acc: 0.2141 - val_loss: 0.8299 - val_acc: 0.2037\n",
      "Epoch 163/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.6803 - acc: 0.2141 - val_loss: 1.0125 - val_acc: 0.2037\n",
      "Epoch 164/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.6942 - acc: 0.2141 - val_loss: 0.8593 - val_acc: 0.2037\n",
      "Epoch 165/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.6990 - acc: 0.2141 - val_loss: 0.8334 - val_acc: 0.2037\n",
      "Epoch 166/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.6777 - acc: 0.2145 - val_loss: 0.8663 - val_acc: 0.2037\n",
      "Epoch 167/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.7065 - acc: 0.2141 - val_loss: 0.8579 - val_acc: 0.2037\n",
      "Epoch 168/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.7400 - acc: 0.2145 - val_loss: 0.8589 - val_acc: 0.2037\n",
      "Epoch 169/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.7356 - acc: 0.2137 - val_loss: 0.8308 - val_acc: 0.2037\n",
      "Epoch 170/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.7533 - acc: 0.2137 - val_loss: 0.8492 - val_acc: 0.2037\n",
      "Epoch 171/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.7127 - acc: 0.2141 - val_loss: 0.8511 - val_acc: 0.2037\n",
      "Epoch 172/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.6876 - acc: 0.2141 - val_loss: 0.9298 - val_acc: 0.2037\n",
      "Epoch 173/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.7081 - acc: 0.2141 - val_loss: 0.9156 - val_acc: 0.2037\n",
      "Epoch 174/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.6786 - acc: 0.2145 - val_loss: 0.8731 - val_acc: 0.2037\n",
      "Epoch 175/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.6817 - acc: 0.2141 - val_loss: 0.8339 - val_acc: 0.2037\n",
      "Epoch 176/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.6866 - acc: 0.2141 - val_loss: 0.8317 - val_acc: 0.2037\n",
      "Epoch 177/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.6907 - acc: 0.2141 - val_loss: 0.9499 - val_acc: 0.2037\n",
      "Epoch 178/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.7049 - acc: 0.2141 - val_loss: 0.8348 - val_acc: 0.2037\n",
      "Epoch 179/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.7326 - acc: 0.2141 - val_loss: 1.0029 - val_acc: 0.2074\n",
      "Epoch 180/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.7086 - acc: 0.2141 - val_loss: 0.8319 - val_acc: 0.2037\n",
      "Epoch 181/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.7159 - acc: 0.2141 - val_loss: 0.8761 - val_acc: 0.2037\n",
      "Epoch 182/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 3s 46ms/step - loss: 0.7072 - acc: 0.2141 - val_loss: 0.8509 - val_acc: 0.2037\n",
      "Epoch 183/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.8049 - acc: 0.2137 - val_loss: 0.9559 - val_acc: 0.2037\n",
      "Epoch 184/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.9091 - acc: 0.2145 - val_loss: 1.0044 - val_acc: 0.2037\n",
      "Epoch 185/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.7508 - acc: 0.2137 - val_loss: 0.8116 - val_acc: 0.2037\n",
      "Epoch 186/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.7464 - acc: 0.2141 - val_loss: 0.8544 - val_acc: 0.2037\n",
      "Epoch 187/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.6888 - acc: 0.2145 - val_loss: 0.8403 - val_acc: 0.2037\n",
      "Epoch 188/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.7807 - acc: 0.2137 - val_loss: 0.8474 - val_acc: 0.2037\n",
      "Epoch 189/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.6634 - acc: 0.2141 - val_loss: 0.8075 - val_acc: 0.2037\n",
      "Epoch 190/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.6623 - acc: 0.2141 - val_loss: 0.9099 - val_acc: 0.2037\n",
      "Epoch 191/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.6875 - acc: 0.2141 - val_loss: 0.8140 - val_acc: 0.2037\n",
      "Epoch 192/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.6831 - acc: 0.2141 - val_loss: 1.0041 - val_acc: 0.2037\n",
      "Epoch 193/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.7022 - acc: 0.2145 - val_loss: 0.8225 - val_acc: 0.2037\n",
      "Epoch 194/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.7019 - acc: 0.2137 - val_loss: 1.0294 - val_acc: 0.2037\n",
      "Epoch 195/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.7386 - acc: 0.2145 - val_loss: 0.8616 - val_acc: 0.2037\n",
      "Epoch 196/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.7158 - acc: 0.2141 - val_loss: 0.8347 - val_acc: 0.2037\n",
      "Epoch 197/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.6709 - acc: 0.2137 - val_loss: 0.9281 - val_acc: 0.2037\n",
      "Epoch 198/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.6651 - acc: 0.2141 - val_loss: 0.8185 - val_acc: 0.2037\n",
      "Epoch 199/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.6326 - acc: 0.2141 - val_loss: 0.8197 - val_acc: 0.2037\n",
      "Epoch 200/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.7627 - acc: 0.2137 - val_loss: 1.0747 - val_acc: 0.2037\n",
      "Epoch 201/10000\n",
      "76/76 [==============================] - 6s 77ms/step - loss: 0.6796 - acc: 0.2141 - val_loss: 0.7929 - val_acc: 0.2037\n",
      "Epoch 202/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.6540 - acc: 0.2141 - val_loss: 0.8348 - val_acc: 0.2037\n",
      "Epoch 203/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.6642 - acc: 0.2141 - val_loss: 0.8500 - val_acc: 0.2037\n",
      "Epoch 204/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.7345 - acc: 0.2141 - val_loss: 0.8253 - val_acc: 0.2037\n",
      "Epoch 205/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.7147 - acc: 0.2133 - val_loss: 0.8142 - val_acc: 0.2037\n",
      "Epoch 206/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.7523 - acc: 0.2141 - val_loss: 0.9839 - val_acc: 0.2037\n",
      "Epoch 207/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.7232 - acc: 0.2141 - val_loss: 1.1376 - val_acc: 0.2037\n",
      "Epoch 208/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.7289 - acc: 0.2137 - val_loss: 0.8050 - val_acc: 0.2037\n",
      "Epoch 209/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.7251 - acc: 0.2141 - val_loss: 0.8616 - val_acc: 0.2037\n",
      "Epoch 210/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.9108 - acc: 0.2137 - val_loss: 0.7686 - val_acc: 0.2037\n",
      "Epoch 211/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.7626 - acc: 0.2141 - val_loss: 0.8178 - val_acc: 0.2037\n",
      "Epoch 212/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.7321 - acc: 0.2137 - val_loss: 0.9874 - val_acc: 0.2037\n",
      "Epoch 213/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.6425 - acc: 0.2141 - val_loss: 0.8039 - val_acc: 0.2037\n",
      "Epoch 214/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.6309 - acc: 0.2141 - val_loss: 0.9454 - val_acc: 0.2037\n",
      "Epoch 215/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.6380 - acc: 0.2141 - val_loss: 0.8673 - val_acc: 0.2037\n",
      "Epoch 216/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.6639 - acc: 0.2141 - val_loss: 0.7851 - val_acc: 0.2037\n",
      "Epoch 217/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.6404 - acc: 0.2141 - val_loss: 0.9189 - val_acc: 0.2037\n",
      "Epoch 218/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.6282 - acc: 0.2141 - val_loss: 0.7857 - val_acc: 0.2037\n",
      "Epoch 219/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.6264 - acc: 0.2137 - val_loss: 0.9058 - val_acc: 0.2037\n",
      "Epoch 220/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.6980 - acc: 0.2137 - val_loss: 0.7952 - val_acc: 0.2037\n",
      "Epoch 221/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 1.3427 - acc: 0.2137 - val_loss: 0.9179 - val_acc: 0.2037\n",
      "Epoch 222/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.7362 - acc: 0.2141 - val_loss: 0.8509 - val_acc: 0.2037\n",
      "Epoch 223/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.6808 - acc: 0.2141 - val_loss: 0.8212 - val_acc: 0.2037\n",
      "Epoch 224/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.6781 - acc: 0.2141 - val_loss: 1.0536 - val_acc: 0.2037\n",
      "Epoch 225/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.6450 - acc: 0.2141 - val_loss: 0.7938 - val_acc: 0.2037\n",
      "Epoch 226/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.6351 - acc: 0.2145 - val_loss: 0.7829 - val_acc: 0.2037\n",
      "Epoch 227/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.6519 - acc: 0.2137 - val_loss: 0.8188 - val_acc: 0.2037\n",
      "Epoch 228/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.6530 - acc: 0.2141 - val_loss: 0.8893 - val_acc: 0.2037\n",
      "Epoch 229/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.6475 - acc: 0.2141 - val_loss: 0.7767 - val_acc: 0.2037\n",
      "Epoch 230/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.6913 - acc: 0.2129 - val_loss: 0.7800 - val_acc: 0.2037\n",
      "Epoch 231/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.6514 - acc: 0.2141 - val_loss: 0.7824 - val_acc: 0.2037\n",
      "Epoch 232/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.6283 - acc: 0.2145 - val_loss: 0.7728 - val_acc: 0.2037\n",
      "Epoch 233/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.6656 - acc: 0.2133 - val_loss: 0.7805 - val_acc: 0.2037\n",
      "Epoch 234/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.6763 - acc: 0.2145 - val_loss: 0.7806 - val_acc: 0.2037\n",
      "Epoch 235/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.6185 - acc: 0.2141 - val_loss: 0.7974 - val_acc: 0.2037\n",
      "Epoch 236/10000\n",
      "76/76 [==============================] - 5s 64ms/step - loss: 0.6468 - acc: 0.2141 - val_loss: 0.7861 - val_acc: 0.2037\n",
      "Epoch 237/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.6168 - acc: 0.2137 - val_loss: 0.8389 - val_acc: 0.2037\n",
      "Epoch 238/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.6648 - acc: 0.2133 - val_loss: 1.0106 - val_acc: 0.2037\n",
      "Epoch 239/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.9876 - acc: 0.2133 - val_loss: 0.7856 - val_acc: 0.2037\n",
      "Epoch 240/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.9656 - acc: 0.2125 - val_loss: 0.9854 - val_acc: 0.2037\n",
      "Epoch 241/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.8704 - acc: 0.2137 - val_loss: 0.7871 - val_acc: 0.2037\n",
      "Epoch 242/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 3s 39ms/step - loss: 0.6205 - acc: 0.2141 - val_loss: 0.8032 - val_acc: 0.2037\n",
      "Epoch 243/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.6482 - acc: 0.2137 - val_loss: 0.8778 - val_acc: 0.2037\n",
      "Epoch 244/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.6296 - acc: 0.2141 - val_loss: 0.7665 - val_acc: 0.2037\n",
      "Epoch 245/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.6358 - acc: 0.2141 - val_loss: 0.9540 - val_acc: 0.2037\n",
      "Epoch 246/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.6228 - acc: 0.2141 - val_loss: 0.8793 - val_acc: 0.2037\n",
      "Epoch 247/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.6061 - acc: 0.2137 - val_loss: 0.8033 - val_acc: 0.2037\n",
      "Epoch 248/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.6567 - acc: 0.2141 - val_loss: 0.7915 - val_acc: 0.2037\n",
      "Epoch 249/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.6846 - acc: 0.2129 - val_loss: 0.7528 - val_acc: 0.2037\n",
      "Epoch 250/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.6186 - acc: 0.2137 - val_loss: 0.7571 - val_acc: 0.2037\n",
      "Epoch 251/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.6082 - acc: 0.2141 - val_loss: 0.8404 - val_acc: 0.2037\n",
      "Epoch 252/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.6793 - acc: 0.2137 - val_loss: 0.7795 - val_acc: 0.2037\n",
      "Epoch 253/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.6620 - acc: 0.2137 - val_loss: 0.8804 - val_acc: 0.2037\n",
      "Epoch 254/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.6739 - acc: 0.2137 - val_loss: 0.7677 - val_acc: 0.2037\n",
      "Epoch 255/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.9698 - acc: 0.2133 - val_loss: 0.9147 - val_acc: 0.2037\n",
      "Epoch 256/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.6718 - acc: 0.2137 - val_loss: 0.8955 - val_acc: 0.2037\n",
      "Epoch 257/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.6390 - acc: 0.2145 - val_loss: 0.7583 - val_acc: 0.2037\n",
      "Epoch 258/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.6734 - acc: 0.2137 - val_loss: 0.7469 - val_acc: 0.2037\n",
      "Epoch 259/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.6067 - acc: 0.2141 - val_loss: 0.7597 - val_acc: 0.2037\n",
      "Epoch 260/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.6009 - acc: 0.2137 - val_loss: 0.8259 - val_acc: 0.2037\n",
      "Epoch 261/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.6390 - acc: 0.2133 - val_loss: 0.7526 - val_acc: 0.2037\n",
      "Epoch 262/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.6026 - acc: 0.2137 - val_loss: 0.7752 - val_acc: 0.2037\n",
      "Epoch 263/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.6547 - acc: 0.2141 - val_loss: 0.8093 - val_acc: 0.2037\n",
      "Epoch 264/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.6592 - acc: 0.2141 - val_loss: 0.7776 - val_acc: 0.2037\n",
      "Epoch 265/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.6064 - acc: 0.2141 - val_loss: 0.7919 - val_acc: 0.2037\n",
      "Epoch 266/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.6600 - acc: 0.2137 - val_loss: 0.7435 - val_acc: 0.2037\n",
      "Epoch 267/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.6187 - acc: 0.2141 - val_loss: 0.7485 - val_acc: 0.2037\n",
      "Epoch 268/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.6060 - acc: 0.2141 - val_loss: 0.7702 - val_acc: 0.2037\n",
      "Epoch 269/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.6213 - acc: 0.2137 - val_loss: 0.7764 - val_acc: 0.2037\n",
      "Epoch 270/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.7298 - acc: 0.2133 - val_loss: 0.8352 - val_acc: 0.2037\n",
      "Epoch 271/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.6902 - acc: 0.2141 - val_loss: 0.8212 - val_acc: 0.2037\n",
      "Epoch 272/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.6494 - acc: 0.2137 - val_loss: 0.7637 - val_acc: 0.2037\n",
      "Epoch 273/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.6186 - acc: 0.2137 - val_loss: 0.9225 - val_acc: 0.2037\n",
      "Epoch 274/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5916 - acc: 0.2137 - val_loss: 0.7642 - val_acc: 0.2037\n",
      "Epoch 275/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.6129 - acc: 0.2141 - val_loss: 0.7338 - val_acc: 0.2037\n",
      "Epoch 276/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5943 - acc: 0.2137 - val_loss: 0.7488 - val_acc: 0.2037\n",
      "Epoch 277/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.6129 - acc: 0.2141 - val_loss: 0.7427 - val_acc: 0.2037\n",
      "Epoch 278/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.8138 - acc: 0.2141 - val_loss: 0.7927 - val_acc: 0.2037\n",
      "Epoch 279/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5996 - acc: 0.2141 - val_loss: 0.8225 - val_acc: 0.2037\n",
      "Epoch 280/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.6267 - acc: 0.2141 - val_loss: 0.8527 - val_acc: 0.2037\n",
      "Epoch 281/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.6947 - acc: 0.2137 - val_loss: 0.7377 - val_acc: 0.2037\n",
      "Epoch 282/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5859 - acc: 0.2137 - val_loss: 0.7446 - val_acc: 0.2037\n",
      "Epoch 283/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5961 - acc: 0.2133 - val_loss: 0.7320 - val_acc: 0.2037\n",
      "Epoch 284/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.6110 - acc: 0.2141 - val_loss: 0.8473 - val_acc: 0.2037\n",
      "Epoch 285/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.6392 - acc: 0.2137 - val_loss: 0.7853 - val_acc: 0.2037\n",
      "Epoch 286/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.6712 - acc: 0.2141 - val_loss: 0.7739 - val_acc: 0.2037\n",
      "Epoch 287/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.9556 - acc: 0.2133 - val_loss: 1.2040 - val_acc: 0.2037\n",
      "Epoch 288/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.7793 - acc: 0.2137 - val_loss: 0.7207 - val_acc: 0.2037\n",
      "Epoch 289/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.9897 - acc: 0.2133 - val_loss: 0.7548 - val_acc: 0.2037\n",
      "Epoch 290/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5976 - acc: 0.2141 - val_loss: 0.7899 - val_acc: 0.2037\n",
      "Epoch 291/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5953 - acc: 0.2137 - val_loss: 0.8877 - val_acc: 0.2037\n",
      "Epoch 292/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5917 - acc: 0.2137 - val_loss: 0.7462 - val_acc: 0.2037\n",
      "Epoch 293/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.5817 - acc: 0.2133 - val_loss: 0.7666 - val_acc: 0.2037\n",
      "Epoch 294/10000\n",
      "76/76 [==============================] - 4s 56ms/step - loss: 0.5990 - acc: 0.2137 - val_loss: 0.7156 - val_acc: 0.2037\n",
      "Epoch 295/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.5918 - acc: 0.2133 - val_loss: 0.7843 - val_acc: 0.2037\n",
      "Epoch 296/10000\n",
      "76/76 [==============================] - 5s 59ms/step - loss: 0.6215 - acc: 0.2137 - val_loss: 0.7836 - val_acc: 0.2037\n",
      "Epoch 297/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.5658 - acc: 0.2141 - val_loss: 0.7244 - val_acc: 0.2037\n",
      "Epoch 298/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.5822 - acc: 0.2133 - val_loss: 0.7233 - val_acc: 0.2037\n",
      "Epoch 299/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.5835 - acc: 0.2141 - val_loss: 0.7364 - val_acc: 0.2037\n",
      "Epoch 300/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.6249 - acc: 0.2141 - val_loss: 0.7957 - val_acc: 0.2037\n",
      "Epoch 301/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.6453 - acc: 0.2137 - val_loss: 0.8038 - val_acc: 0.2037\n",
      "Epoch 302/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 3s 40ms/step - loss: 0.5902 - acc: 0.2137 - val_loss: 0.7675 - val_acc: 0.2037\n",
      "Epoch 303/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5986 - acc: 0.2133 - val_loss: 0.9117 - val_acc: 0.2037\n",
      "Epoch 304/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.6442 - acc: 0.2129 - val_loss: 0.7433 - val_acc: 0.2037\n",
      "Epoch 305/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.6124 - acc: 0.2141 - val_loss: 0.7748 - val_acc: 0.2037\n",
      "Epoch 306/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.6285 - acc: 0.2137 - val_loss: 0.7511 - val_acc: 0.2037\n",
      "Epoch 307/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.6087 - acc: 0.2141 - val_loss: 0.7525 - val_acc: 0.2037\n",
      "Epoch 308/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.6306 - acc: 0.2141 - val_loss: 0.7166 - val_acc: 0.2037\n",
      "Epoch 309/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.5780 - acc: 0.2133 - val_loss: 0.7278 - val_acc: 0.2037\n",
      "Epoch 310/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5906 - acc: 0.2137 - val_loss: 0.7107 - val_acc: 0.2037\n",
      "Epoch 311/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.6095 - acc: 0.2141 - val_loss: 0.7467 - val_acc: 0.2037\n",
      "Epoch 312/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.6113 - acc: 0.2141 - val_loss: 0.7301 - val_acc: 0.2037\n",
      "Epoch 313/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.6261 - acc: 0.2133 - val_loss: 0.7859 - val_acc: 0.2037\n",
      "Epoch 314/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5909 - acc: 0.2141 - val_loss: 0.7147 - val_acc: 0.2037\n",
      "Epoch 315/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5987 - acc: 0.2137 - val_loss: 0.8090 - val_acc: 0.2037\n",
      "Epoch 316/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5832 - acc: 0.2137 - val_loss: 0.7505 - val_acc: 0.2037\n",
      "Epoch 317/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.6363 - acc: 0.2141 - val_loss: 0.9496 - val_acc: 0.2037\n",
      "Epoch 318/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.6470 - acc: 0.2129 - val_loss: 0.7732 - val_acc: 0.2037\n",
      "Epoch 319/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.5803 - acc: 0.2137 - val_loss: 0.7702 - val_acc: 0.2037\n",
      "Epoch 320/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 1.0145 - acc: 0.2129 - val_loss: 0.7558 - val_acc: 0.2037\n",
      "Epoch 321/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.8024 - acc: 0.2125 - val_loss: 0.8179 - val_acc: 0.2037\n",
      "Epoch 322/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.8801 - acc: 0.2125 - val_loss: 0.7605 - val_acc: 0.2037\n",
      "Epoch 323/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 1.1866 - acc: 0.2125 - val_loss: 0.7308 - val_acc: 0.2037\n",
      "Epoch 324/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5923 - acc: 0.2133 - val_loss: 0.7343 - val_acc: 0.2037\n",
      "Epoch 325/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.6074 - acc: 0.2141 - val_loss: 0.7172 - val_acc: 0.2037\n",
      "Epoch 326/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5774 - acc: 0.2141 - val_loss: 0.7211 - val_acc: 0.2037\n",
      "Epoch 327/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5756 - acc: 0.2137 - val_loss: 0.7797 - val_acc: 0.2037\n",
      "Epoch 328/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.6103 - acc: 0.2133 - val_loss: 0.7060 - val_acc: 0.2037\n",
      "Epoch 329/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.6040 - acc: 0.2133 - val_loss: 0.7482 - val_acc: 0.2037\n",
      "Epoch 330/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.6565 - acc: 0.2137 - val_loss: 0.7849 - val_acc: 0.2037\n",
      "Epoch 331/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.6177 - acc: 0.2137 - val_loss: 0.7244 - val_acc: 0.2037\n",
      "Epoch 332/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.6018 - acc: 0.2137 - val_loss: 0.7221 - val_acc: 0.2037\n",
      "Epoch 333/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.6022 - acc: 0.2133 - val_loss: 0.7171 - val_acc: 0.2037\n",
      "Epoch 334/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.6127 - acc: 0.2133 - val_loss: 0.7015 - val_acc: 0.2037\n",
      "Epoch 335/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5683 - acc: 0.2141 - val_loss: 0.7204 - val_acc: 0.2037\n",
      "Epoch 336/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5721 - acc: 0.2137 - val_loss: 0.7575 - val_acc: 0.2037\n",
      "Epoch 337/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5542 - acc: 0.2137 - val_loss: 0.8414 - val_acc: 0.2037\n",
      "Epoch 338/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5927 - acc: 0.2133 - val_loss: 0.7155 - val_acc: 0.2037\n",
      "Epoch 339/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.6047 - acc: 0.2133 - val_loss: 0.7627 - val_acc: 0.2037\n",
      "Epoch 340/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.6409 - acc: 0.2137 - val_loss: 0.7115 - val_acc: 0.2037\n",
      "Epoch 341/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5729 - acc: 0.2137 - val_loss: 0.7470 - val_acc: 0.2037\n",
      "Epoch 342/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5726 - acc: 0.2141 - val_loss: 0.7677 - val_acc: 0.2037\n",
      "Epoch 343/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.8154 - acc: 0.2133 - val_loss: 0.7340 - val_acc: 0.2037\n",
      "Epoch 344/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.6525 - acc: 0.2141 - val_loss: 0.8283 - val_acc: 0.2037\n",
      "Epoch 345/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.8103 - acc: 0.2133 - val_loss: 1.0614 - val_acc: 0.2037\n",
      "Epoch 346/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.6851 - acc: 0.2141 - val_loss: 0.7624 - val_acc: 0.2037\n",
      "Epoch 347/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.6359 - acc: 0.2141 - val_loss: 0.7302 - val_acc: 0.2037\n",
      "Epoch 348/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.6327 - acc: 0.2141 - val_loss: 0.6875 - val_acc: 0.2037\n",
      "Epoch 349/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.6633 - acc: 0.2137 - val_loss: 0.9219 - val_acc: 0.2037\n",
      "Epoch 350/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.6020 - acc: 0.2133 - val_loss: 0.6933 - val_acc: 0.2037\n",
      "Epoch 351/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5735 - acc: 0.2133 - val_loss: 0.7147 - val_acc: 0.2037\n",
      "Epoch 352/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5607 - acc: 0.2141 - val_loss: 0.6972 - val_acc: 0.2037\n",
      "Epoch 353/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5466 - acc: 0.2133 - val_loss: 0.7118 - val_acc: 0.2037\n",
      "Epoch 354/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5793 - acc: 0.2129 - val_loss: 0.7039 - val_acc: 0.2037\n",
      "Epoch 355/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.6166 - acc: 0.2137 - val_loss: 0.7150 - val_acc: 0.2037\n",
      "Epoch 356/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.6021 - acc: 0.2133 - val_loss: 0.7067 - val_acc: 0.2037\n",
      "Epoch 357/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5583 - acc: 0.2137 - val_loss: 0.7650 - val_acc: 0.2037\n",
      "Epoch 358/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.6071 - acc: 0.2137 - val_loss: 0.7369 - val_acc: 0.2037\n",
      "Epoch 359/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.6410 - acc: 0.2137 - val_loss: 0.8252 - val_acc: 0.2037\n",
      "Epoch 360/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5897 - acc: 0.2133 - val_loss: 0.7029 - val_acc: 0.2037\n",
      "Epoch 361/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.7964 - acc: 0.2133 - val_loss: 0.7500 - val_acc: 0.2037\n",
      "Epoch 362/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 3s 35ms/step - loss: 0.6592 - acc: 0.2137 - val_loss: 0.7147 - val_acc: 0.2037\n",
      "Epoch 363/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.7094 - acc: 0.2137 - val_loss: 0.8872 - val_acc: 0.2037\n",
      "Epoch 364/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.6179 - acc: 0.2129 - val_loss: 0.6900 - val_acc: 0.2037\n",
      "Epoch 365/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.6181 - acc: 0.2137 - val_loss: 0.7133 - val_acc: 0.2037\n",
      "Epoch 366/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5491 - acc: 0.2141 - val_loss: 0.7226 - val_acc: 0.2037\n",
      "Epoch 367/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.5805 - acc: 0.2133 - val_loss: 0.7194 - val_acc: 0.2037\n",
      "Epoch 368/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.5715 - acc: 0.2129 - val_loss: 0.6964 - val_acc: 0.2037\n",
      "Epoch 369/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5628 - acc: 0.2129 - val_loss: 0.6951 - val_acc: 0.2037\n",
      "Epoch 370/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5572 - acc: 0.2137 - val_loss: 0.7000 - val_acc: 0.2037\n",
      "Epoch 371/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5967 - acc: 0.2120 - val_loss: 0.8433 - val_acc: 0.2037\n",
      "Epoch 372/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5681 - acc: 0.2137 - val_loss: 0.7687 - val_acc: 0.2037\n",
      "Epoch 373/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5910 - acc: 0.2137 - val_loss: 0.7355 - val_acc: 0.2037\n",
      "Epoch 374/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.6167 - acc: 0.2129 - val_loss: 0.8566 - val_acc: 0.2037\n",
      "Epoch 375/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.7717 - acc: 0.2129 - val_loss: 0.7295 - val_acc: 0.2037\n",
      "Epoch 376/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.6223 - acc: 0.2137 - val_loss: 0.7706 - val_acc: 0.2037\n",
      "Epoch 377/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.6343 - acc: 0.2116 - val_loss: 0.6955 - val_acc: 0.2037\n",
      "Epoch 378/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.5802 - acc: 0.2137 - val_loss: 0.8555 - val_acc: 0.2037\n",
      "Epoch 379/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.6611 - acc: 0.2129 - val_loss: 0.8582 - val_acc: 0.2037\n",
      "Epoch 380/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.6426 - acc: 0.2133 - val_loss: 0.6946 - val_acc: 0.2037\n",
      "Epoch 381/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.5794 - acc: 0.2129 - val_loss: 0.7025 - val_acc: 0.2037\n",
      "Epoch 382/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5872 - acc: 0.2137 - val_loss: 0.7456 - val_acc: 0.2037\n",
      "Epoch 383/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.5640 - acc: 0.2137 - val_loss: 0.7105 - val_acc: 0.2037\n",
      "Epoch 384/10000\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 0.6853 - acc: 0.2137 - val_loss: 0.6732 - val_acc: 0.2037\n",
      "Epoch 385/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.6893 - acc: 0.2133 - val_loss: 0.9108 - val_acc: 0.2037\n",
      "Epoch 386/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.6387 - acc: 0.2133 - val_loss: 0.7148 - val_acc: 0.2037\n",
      "Epoch 387/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.5490 - acc: 0.2141 - val_loss: 0.7691 - val_acc: 0.2037\n",
      "Epoch 388/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5443 - acc: 0.2141 - val_loss: 0.6766 - val_acc: 0.2037\n",
      "Epoch 389/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.5795 - acc: 0.2125 - val_loss: 0.7205 - val_acc: 0.2037\n",
      "Epoch 390/10000\n",
      "76/76 [==============================] - 3s 46ms/step - loss: 0.5603 - acc: 0.2141 - val_loss: 0.7584 - val_acc: 0.2037\n",
      "Epoch 391/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.5705 - acc: 0.2129 - val_loss: 0.6827 - val_acc: 0.2037\n",
      "Epoch 392/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.5570 - acc: 0.2133 - val_loss: 0.7142 - val_acc: 0.2037\n",
      "Epoch 393/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5866 - acc: 0.2137 - val_loss: 0.7044 - val_acc: 0.2037\n",
      "Epoch 394/10000\n",
      "76/76 [==============================] - 4s 56ms/step - loss: 0.6097 - acc: 0.2137 - val_loss: 0.7085 - val_acc: 0.2037\n",
      "Epoch 395/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.6020 - acc: 0.2129 - val_loss: 0.6514 - val_acc: 0.2037\n",
      "Epoch 396/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.7105 - acc: 0.2133 - val_loss: 1.0189 - val_acc: 0.2037\n",
      "Epoch 397/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.6992 - acc: 0.2137 - val_loss: 0.7827 - val_acc: 0.2037\n",
      "Epoch 398/10000\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 0.7460 - acc: 0.2137 - val_loss: 0.7522 - val_acc: 0.2037\n",
      "Epoch 399/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.5939 - acc: 0.2133 - val_loss: 0.8112 - val_acc: 0.2037\n",
      "Epoch 400/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.5739 - acc: 0.2133 - val_loss: 0.6862 - val_acc: 0.2037\n",
      "Epoch 401/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5429 - acc: 0.2141 - val_loss: 0.6630 - val_acc: 0.2037\n",
      "Epoch 402/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5432 - acc: 0.2133 - val_loss: 0.7127 - val_acc: 0.2037\n",
      "Epoch 403/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.5573 - acc: 0.2133 - val_loss: 0.7131 - val_acc: 0.2037\n",
      "Epoch 404/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5249 - acc: 0.2137 - val_loss: 0.6705 - val_acc: 0.2037\n",
      "Epoch 405/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5439 - acc: 0.2141 - val_loss: 0.6702 - val_acc: 0.2037\n",
      "Epoch 406/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.5471 - acc: 0.2137 - val_loss: 0.6901 - val_acc: 0.2037\n",
      "Epoch 407/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.5633 - acc: 0.2137 - val_loss: 0.7312 - val_acc: 0.2037\n",
      "Epoch 408/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.6036 - acc: 0.2137 - val_loss: 0.7106 - val_acc: 0.2037\n",
      "Epoch 409/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.6170 - acc: 0.2133 - val_loss: 0.6796 - val_acc: 0.2037\n",
      "Epoch 410/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5587 - acc: 0.2133 - val_loss: 0.6967 - val_acc: 0.2037\n",
      "Epoch 411/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.6004 - acc: 0.2137 - val_loss: 0.8315 - val_acc: 0.2037\n",
      "Epoch 412/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5635 - acc: 0.2133 - val_loss: 0.6717 - val_acc: 0.2037\n",
      "Epoch 413/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.6591 - acc: 0.2137 - val_loss: 0.7178 - val_acc: 0.2037\n",
      "Epoch 414/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.6320 - acc: 0.2137 - val_loss: 1.0808 - val_acc: 0.2037\n",
      "Epoch 415/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.6089 - acc: 0.2133 - val_loss: 0.6944 - val_acc: 0.2037\n",
      "Epoch 416/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.6515 - acc: 0.2141 - val_loss: 0.6587 - val_acc: 0.2037\n",
      "Epoch 417/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.5365 - acc: 0.2141 - val_loss: 0.6857 - val_acc: 0.2037\n",
      "Epoch 418/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.6207 - acc: 0.2137 - val_loss: 0.7080 - val_acc: 0.2037\n",
      "Epoch 419/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.5626 - acc: 0.2133 - val_loss: 0.6940 - val_acc: 0.2037\n",
      "Epoch 420/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5323 - acc: 0.2133 - val_loss: 0.7278 - val_acc: 0.2037\n",
      "Epoch 421/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5481 - acc: 0.2137 - val_loss: 0.6668 - val_acc: 0.2037\n",
      "Epoch 422/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5509 - acc: 0.2137 - val_loss: 0.6728 - val_acc: 0.2037\n",
      "Epoch 423/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5205 - acc: 0.2137 - val_loss: 0.7185 - val_acc: 0.2037\n",
      "Epoch 424/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5522 - acc: 0.2133 - val_loss: 0.7017 - val_acc: 0.2037\n",
      "Epoch 425/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.6163 - acc: 0.2129 - val_loss: 0.6610 - val_acc: 0.2037\n",
      "Epoch 426/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5633 - acc: 0.2137 - val_loss: 0.7273 - val_acc: 0.2037\n",
      "Epoch 427/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5619 - acc: 0.2133 - val_loss: 0.7354 - val_acc: 0.2037\n",
      "Epoch 428/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5834 - acc: 0.2137 - val_loss: 0.7718 - val_acc: 0.2037\n",
      "Epoch 429/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 1.1265 - acc: 0.2133 - val_loss: 0.6960 - val_acc: 0.2037\n",
      "Epoch 430/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.7734 - acc: 0.2120 - val_loss: 0.6892 - val_acc: 0.2037\n",
      "Epoch 431/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5813 - acc: 0.2137 - val_loss: 0.6944 - val_acc: 0.2037\n",
      "Epoch 432/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.6542 - acc: 0.2129 - val_loss: 0.8318 - val_acc: 0.2037\n",
      "Epoch 433/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5760 - acc: 0.2133 - val_loss: 0.6950 - val_acc: 0.2037\n",
      "Epoch 434/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5564 - acc: 0.2125 - val_loss: 0.7226 - val_acc: 0.2037\n",
      "Epoch 435/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5507 - acc: 0.2133 - val_loss: 0.7027 - val_acc: 0.2037\n",
      "Epoch 436/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5463 - acc: 0.2141 - val_loss: 1.0930 - val_acc: 0.2000\n",
      "Epoch 437/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5686 - acc: 0.2133 - val_loss: 0.8327 - val_acc: 0.2037\n",
      "Epoch 438/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5420 - acc: 0.2133 - val_loss: 0.7152 - val_acc: 0.2037\n",
      "Epoch 439/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.7310 - acc: 0.2141 - val_loss: 0.7676 - val_acc: 0.2037\n",
      "Epoch 440/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5820 - acc: 0.2141 - val_loss: 0.8068 - val_acc: 0.2037\n",
      "Epoch 441/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5369 - acc: 0.2129 - val_loss: 0.6766 - val_acc: 0.2037\n",
      "Epoch 442/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5686 - acc: 0.2137 - val_loss: 0.8075 - val_acc: 0.2037\n",
      "Epoch 443/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5643 - acc: 0.2129 - val_loss: 0.6612 - val_acc: 0.2037\n",
      "Epoch 444/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5895 - acc: 0.2137 - val_loss: 0.7013 - val_acc: 0.2037\n",
      "Epoch 445/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5995 - acc: 0.2129 - val_loss: 0.6739 - val_acc: 0.2037\n",
      "Epoch 446/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.5777 - acc: 0.2129 - val_loss: 0.6839 - val_acc: 0.2037\n",
      "Epoch 447/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.6348 - acc: 0.2133 - val_loss: 0.7046 - val_acc: 0.2037\n",
      "Epoch 448/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5901 - acc: 0.2129 - val_loss: 0.6528 - val_acc: 0.2037\n",
      "Epoch 449/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5409 - acc: 0.2129 - val_loss: 0.6585 - val_acc: 0.2037\n",
      "Epoch 450/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5705 - acc: 0.2133 - val_loss: 0.6637 - val_acc: 0.2037\n",
      "Epoch 451/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5326 - acc: 0.2133 - val_loss: 0.6708 - val_acc: 0.2037\n",
      "Epoch 452/10000\n",
      "76/76 [==============================] - 4s 46ms/step - loss: 0.5436 - acc: 0.2129 - val_loss: 0.6909 - val_acc: 0.2037\n",
      "Epoch 453/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.5240 - acc: 0.2120 - val_loss: 0.6912 - val_acc: 0.2037\n",
      "Epoch 454/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5362 - acc: 0.2133 - val_loss: 0.7460 - val_acc: 0.2037\n",
      "Epoch 455/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5612 - acc: 0.2133 - val_loss: 0.6660 - val_acc: 0.2037\n",
      "Epoch 456/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5200 - acc: 0.2120 - val_loss: 0.8192 - val_acc: 0.2037\n",
      "Epoch 457/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5205 - acc: 0.2125 - val_loss: 0.7249 - val_acc: 0.2037\n",
      "Epoch 458/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5278 - acc: 0.2137 - val_loss: 0.7335 - val_acc: 0.2037\n",
      "Epoch 459/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.6582 - acc: 0.2129 - val_loss: 0.7250 - val_acc: 0.2037\n",
      "Epoch 460/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.6108 - acc: 0.2137 - val_loss: 0.9809 - val_acc: 0.2037\n",
      "Epoch 461/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.6492 - acc: 0.2125 - val_loss: 0.7502 - val_acc: 0.2037\n",
      "Epoch 462/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5421 - acc: 0.2133 - val_loss: 0.7203 - val_acc: 0.2037\n",
      "Epoch 463/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5238 - acc: 0.2137 - val_loss: 0.6991 - val_acc: 0.2037\n",
      "Epoch 464/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5328 - acc: 0.2133 - val_loss: 0.6870 - val_acc: 0.2037\n",
      "Epoch 465/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5311 - acc: 0.2133 - val_loss: 0.6640 - val_acc: 0.2037\n",
      "Epoch 466/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5401 - acc: 0.2137 - val_loss: 0.6520 - val_acc: 0.2037\n",
      "Epoch 467/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5648 - acc: 0.2137 - val_loss: 0.6855 - val_acc: 0.2037\n",
      "Epoch 468/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5195 - acc: 0.2129 - val_loss: 0.6702 - val_acc: 0.2037\n",
      "Epoch 469/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5270 - acc: 0.2133 - val_loss: 0.6738 - val_acc: 0.2037\n",
      "Epoch 470/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.6673 - acc: 0.2133 - val_loss: 0.6820 - val_acc: 0.2037\n",
      "Epoch 471/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5508 - acc: 0.2133 - val_loss: 0.6519 - val_acc: 0.2037\n",
      "Epoch 472/10000\n",
      "76/76 [==============================] - 5s 66ms/step - loss: 0.7041 - acc: 0.2129 - val_loss: 0.7138 - val_acc: 0.2037\n",
      "Epoch 473/10000\n",
      "76/76 [==============================] - 5s 67ms/step - loss: 0.6561 - acc: 0.2133 - val_loss: 0.6639 - val_acc: 0.2037\n",
      "Epoch 474/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 1.0114 - acc: 0.2133 - val_loss: 0.9400 - val_acc: 0.2037\n",
      "Epoch 475/10000\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 1.1801 - acc: 0.2125 - val_loss: 0.7002 - val_acc: 0.2037\n",
      "Epoch 476/10000\n",
      "76/76 [==============================] - 5s 64ms/step - loss: 1.0000 - acc: 0.2137 - val_loss: 0.6633 - val_acc: 0.2037\n",
      "Epoch 477/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.5247 - acc: 0.2133 - val_loss: 0.6543 - val_acc: 0.2037\n",
      "Epoch 478/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.6304 - acc: 0.2120 - val_loss: 0.6502 - val_acc: 0.2037\n",
      "Epoch 479/10000\n",
      "76/76 [==============================] - 5s 65ms/step - loss: 0.5270 - acc: 0.2133 - val_loss: 0.6663 - val_acc: 0.2037\n",
      "Epoch 480/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.5507 - acc: 0.2137 - val_loss: 0.6818 - val_acc: 0.2037\n",
      "Epoch 481/10000\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 0.5089 - acc: 0.2133 - val_loss: 0.6401 - val_acc: 0.2037\n",
      "Epoch 482/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 4s 53ms/step - loss: 0.5391 - acc: 0.2137 - val_loss: 0.6649 - val_acc: 0.2037\n",
      "Epoch 483/10000\n",
      "76/76 [==============================] - 5s 62ms/step - loss: 0.5053 - acc: 0.2133 - val_loss: 0.6499 - val_acc: 0.2037\n",
      "Epoch 484/10000\n",
      "76/76 [==============================] - 4s 58ms/step - loss: 0.5246 - acc: 0.2129 - val_loss: 0.7498 - val_acc: 0.2037\n",
      "Epoch 485/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.5073 - acc: 0.2137 - val_loss: 0.6692 - val_acc: 0.2037\n",
      "Epoch 486/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5161 - acc: 0.2129 - val_loss: 0.6479 - val_acc: 0.2037\n",
      "Epoch 487/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.5118 - acc: 0.2137 - val_loss: 0.6472 - val_acc: 0.2037\n",
      "Epoch 488/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.5334 - acc: 0.2133 - val_loss: 0.6663 - val_acc: 0.2037\n",
      "Epoch 489/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.5105 - acc: 0.2129 - val_loss: 0.6606 - val_acc: 0.2037\n",
      "Epoch 490/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.5028 - acc: 0.2137 - val_loss: 0.6503 - val_acc: 0.2037\n",
      "Epoch 491/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5361 - acc: 0.2129 - val_loss: 0.7507 - val_acc: 0.2037\n",
      "Epoch 492/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.5446 - acc: 0.2129 - val_loss: 0.6646 - val_acc: 0.2037\n",
      "Epoch 493/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.5177 - acc: 0.2133 - val_loss: 0.6703 - val_acc: 0.2037\n",
      "Epoch 494/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.5297 - acc: 0.2129 - val_loss: 0.6972 - val_acc: 0.2037\n",
      "Epoch 495/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5281 - acc: 0.2129 - val_loss: 0.7660 - val_acc: 0.2037\n",
      "Epoch 496/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.6499 - acc: 0.2133 - val_loss: 0.6846 - val_acc: 0.2037\n",
      "Epoch 497/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5484 - acc: 0.2129 - val_loss: 0.6625 - val_acc: 0.2037\n",
      "Epoch 498/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5536 - acc: 0.2133 - val_loss: 0.7401 - val_acc: 0.2037\n",
      "Epoch 499/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.6142 - acc: 0.2125 - val_loss: 0.7788 - val_acc: 0.2037\n",
      "Epoch 500/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.5169 - acc: 0.2133 - val_loss: 0.7556 - val_acc: 0.2037\n",
      "Epoch 501/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.5259 - acc: 0.2133 - val_loss: 0.6530 - val_acc: 0.2037\n",
      "Epoch 502/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5328 - acc: 0.2133 - val_loss: 0.7238 - val_acc: 0.2037\n",
      "Epoch 503/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4983 - acc: 0.2133 - val_loss: 0.8380 - val_acc: 0.2037\n",
      "Epoch 504/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.5356 - acc: 0.2129 - val_loss: 0.8374 - val_acc: 0.2037\n",
      "Epoch 505/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5876 - acc: 0.2120 - val_loss: 0.7649 - val_acc: 0.2037\n",
      "Epoch 506/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5489 - acc: 0.2129 - val_loss: 0.6708 - val_acc: 0.2037\n",
      "Epoch 507/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.7869 - acc: 0.2129 - val_loss: 1.1072 - val_acc: 0.2037\n",
      "Epoch 508/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.7076 - acc: 0.2129 - val_loss: 0.8990 - val_acc: 0.2037\n",
      "Epoch 509/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.6083 - acc: 0.2133 - val_loss: 0.7483 - val_acc: 0.2037\n",
      "Epoch 510/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.6329 - acc: 0.2137 - val_loss: 0.6782 - val_acc: 0.2037\n",
      "Epoch 511/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5509 - acc: 0.2133 - val_loss: 0.6985 - val_acc: 0.2037\n",
      "Epoch 512/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5934 - acc: 0.2137 - val_loss: 0.6839 - val_acc: 0.2037\n",
      "Epoch 513/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5924 - acc: 0.2129 - val_loss: 0.6976 - val_acc: 0.2037\n",
      "Epoch 514/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5613 - acc: 0.2133 - val_loss: 0.7611 - val_acc: 0.2037\n",
      "Epoch 515/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.5363 - acc: 0.2125 - val_loss: 0.6591 - val_acc: 0.2037\n",
      "Epoch 516/10000\n",
      "76/76 [==============================] - 5s 70ms/step - loss: 0.5005 - acc: 0.2141 - val_loss: 0.6495 - val_acc: 0.2037\n",
      "Epoch 517/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.5260 - acc: 0.2133 - val_loss: 0.6458 - val_acc: 0.2037\n",
      "Epoch 518/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.5507 - acc: 0.2133 - val_loss: 0.6553 - val_acc: 0.2037\n",
      "Epoch 519/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5319 - acc: 0.2120 - val_loss: 1.0418 - val_acc: 0.2037\n",
      "Epoch 520/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5632 - acc: 0.2129 - val_loss: 0.8204 - val_acc: 0.2037\n",
      "Epoch 521/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5247 - acc: 0.2133 - val_loss: 0.6990 - val_acc: 0.2037\n",
      "Epoch 522/10000\n",
      "76/76 [==============================] - 4s 57ms/step - loss: 0.5483 - acc: 0.2137 - val_loss: 0.6609 - val_acc: 0.2037\n",
      "Epoch 523/10000\n",
      "76/76 [==============================] - 5s 62ms/step - loss: 0.5798 - acc: 0.2137 - val_loss: 0.7443 - val_acc: 0.2037\n",
      "Epoch 524/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5695 - acc: 0.2120 - val_loss: 0.6737 - val_acc: 0.2037\n",
      "Epoch 525/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5259 - acc: 0.2133 - val_loss: 0.6910 - val_acc: 0.2037\n",
      "Epoch 526/10000\n",
      "76/76 [==============================] - 4s 46ms/step - loss: 0.5269 - acc: 0.2129 - val_loss: 0.6669 - val_acc: 0.2037\n",
      "Epoch 527/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.5725 - acc: 0.2125 - val_loss: 0.6241 - val_acc: 0.2037\n",
      "Epoch 528/10000\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 0.5385 - acc: 0.2133 - val_loss: 0.6319 - val_acc: 0.2037\n",
      "Epoch 529/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5617 - acc: 0.2137 - val_loss: 0.6866 - val_acc: 0.2037\n",
      "Epoch 530/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5628 - acc: 0.2137 - val_loss: 0.6748 - val_acc: 0.2037\n",
      "Epoch 531/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5307 - acc: 0.2129 - val_loss: 0.6385 - val_acc: 0.2037\n",
      "Epoch 532/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5152 - acc: 0.2125 - val_loss: 0.7013 - val_acc: 0.2037\n",
      "Epoch 533/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5417 - acc: 0.2116 - val_loss: 0.6709 - val_acc: 0.2037\n",
      "Epoch 534/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.5086 - acc: 0.2133 - val_loss: 0.6356 - val_acc: 0.2037\n",
      "Epoch 535/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.5130 - acc: 0.2129 - val_loss: 0.6477 - val_acc: 0.2037\n",
      "Epoch 536/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.5503 - acc: 0.2125 - val_loss: 0.8383 - val_acc: 0.2037\n",
      "Epoch 537/10000\n",
      "76/76 [==============================] - 4s 57ms/step - loss: 0.5484 - acc: 0.2129 - val_loss: 0.6348 - val_acc: 0.2037\n",
      "Epoch 538/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.5431 - acc: 0.2129 - val_loss: 0.7819 - val_acc: 0.2037\n",
      "Epoch 539/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.6015 - acc: 0.2133 - val_loss: 0.6254 - val_acc: 0.2037\n",
      "Epoch 540/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5940 - acc: 0.2129 - val_loss: 0.7293 - val_acc: 0.2037\n",
      "Epoch 541/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.7034 - acc: 0.2129 - val_loss: 1.2535 - val_acc: 0.2037\n",
      "Epoch 542/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 3s 34ms/step - loss: 0.8368 - acc: 0.2129 - val_loss: 0.9184 - val_acc: 0.2037\n",
      "Epoch 543/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.7150 - acc: 0.2133 - val_loss: 1.1505 - val_acc: 0.2000\n",
      "Epoch 544/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.6280 - acc: 0.2125 - val_loss: 0.7256 - val_acc: 0.2037\n",
      "Epoch 545/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.5364 - acc: 0.2129 - val_loss: 0.8395 - val_acc: 0.2037\n",
      "Epoch 546/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5211 - acc: 0.2133 - val_loss: 0.7539 - val_acc: 0.2037\n",
      "Epoch 547/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5362 - acc: 0.2125 - val_loss: 0.6717 - val_acc: 0.2037\n",
      "Epoch 548/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5449 - acc: 0.2133 - val_loss: 0.7540 - val_acc: 0.2037\n",
      "Epoch 549/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5016 - acc: 0.2133 - val_loss: 0.6349 - val_acc: 0.2037\n",
      "Epoch 550/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5057 - acc: 0.2133 - val_loss: 0.6441 - val_acc: 0.2037\n",
      "Epoch 551/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5225 - acc: 0.2133 - val_loss: 0.6562 - val_acc: 0.2037\n",
      "Epoch 552/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5265 - acc: 0.2133 - val_loss: 0.7295 - val_acc: 0.2037\n",
      "Epoch 553/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5334 - acc: 0.2133 - val_loss: 0.6570 - val_acc: 0.2037\n",
      "Epoch 554/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5372 - acc: 0.2125 - val_loss: 0.6405 - val_acc: 0.2037\n",
      "Epoch 555/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5305 - acc: 0.2129 - val_loss: 0.6904 - val_acc: 0.2037\n",
      "Epoch 556/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.6074 - acc: 0.2137 - val_loss: 0.6478 - val_acc: 0.2037\n",
      "Epoch 557/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5408 - acc: 0.2141 - val_loss: 0.6919 - val_acc: 0.2037\n",
      "Epoch 558/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5958 - acc: 0.2129 - val_loss: 0.6673 - val_acc: 0.2037\n",
      "Epoch 559/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.8281 - acc: 0.2120 - val_loss: 1.5146 - val_acc: 0.2000\n",
      "Epoch 560/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5686 - acc: 0.2137 - val_loss: 0.6838 - val_acc: 0.2037\n",
      "Epoch 561/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.7434 - acc: 0.2116 - val_loss: 0.6469 - val_acc: 0.2037\n",
      "Epoch 562/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.5741 - acc: 0.2120 - val_loss: 0.6475 - val_acc: 0.2037\n",
      "Epoch 563/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.6162 - acc: 0.2125 - val_loss: 0.6362 - val_acc: 0.2037\n",
      "Epoch 564/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4989 - acc: 0.2137 - val_loss: 0.6524 - val_acc: 0.2037\n",
      "Epoch 565/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5131 - acc: 0.2125 - val_loss: 0.7042 - val_acc: 0.2037\n",
      "Epoch 566/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5237 - acc: 0.2133 - val_loss: 0.6280 - val_acc: 0.2037\n",
      "Epoch 567/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5272 - acc: 0.2125 - val_loss: 0.7883 - val_acc: 0.2037\n",
      "Epoch 568/10000\n",
      "76/76 [==============================] - 4s 46ms/step - loss: 0.4934 - acc: 0.2129 - val_loss: 0.7547 - val_acc: 0.2037\n",
      "Epoch 569/10000\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 0.5464 - acc: 0.2129 - val_loss: 0.6244 - val_acc: 0.2037\n",
      "Epoch 570/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5308 - acc: 0.2133 - val_loss: 0.6299 - val_acc: 0.2037\n",
      "Epoch 571/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5322 - acc: 0.2133 - val_loss: 0.6509 - val_acc: 0.2037\n",
      "Epoch 572/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.5639 - acc: 0.2129 - val_loss: 0.6678 - val_acc: 0.2037\n",
      "Epoch 573/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.5520 - acc: 0.2133 - val_loss: 0.6492 - val_acc: 0.2037\n",
      "Epoch 574/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5098 - acc: 0.2125 - val_loss: 0.6864 - val_acc: 0.2037\n",
      "Epoch 575/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5274 - acc: 0.2129 - val_loss: 0.6409 - val_acc: 0.2037\n",
      "Epoch 576/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.5412 - acc: 0.2125 - val_loss: 0.6711 - val_acc: 0.2037\n",
      "Epoch 577/10000\n",
      "76/76 [==============================] - 5s 67ms/step - loss: 0.5452 - acc: 0.2125 - val_loss: 0.6445 - val_acc: 0.2037\n",
      "Epoch 578/10000\n",
      "76/76 [==============================] - 3s 46ms/step - loss: 0.5456 - acc: 0.2133 - val_loss: 0.6981 - val_acc: 0.2037\n",
      "Epoch 579/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5403 - acc: 0.2137 - val_loss: 0.6265 - val_acc: 0.2037\n",
      "Epoch 580/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5337 - acc: 0.2137 - val_loss: 0.6439 - val_acc: 0.2037\n",
      "Epoch 581/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5027 - acc: 0.2133 - val_loss: 0.6732 - val_acc: 0.2037\n",
      "Epoch 582/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5514 - acc: 0.2133 - val_loss: 0.7315 - val_acc: 0.2037\n",
      "Epoch 583/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5877 - acc: 0.2129 - val_loss: 0.7917 - val_acc: 0.2037\n",
      "Epoch 584/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5102 - acc: 0.2129 - val_loss: 0.6376 - val_acc: 0.2037\n",
      "Epoch 585/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5261 - acc: 0.2120 - val_loss: 0.6561 - val_acc: 0.2037\n",
      "Epoch 586/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5179 - acc: 0.2129 - val_loss: 0.7967 - val_acc: 0.2037\n",
      "Epoch 587/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5341 - acc: 0.2125 - val_loss: 0.6602 - val_acc: 0.2037\n",
      "Epoch 588/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.6536 - acc: 0.2129 - val_loss: 0.7521 - val_acc: 0.2037\n",
      "Epoch 589/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5409 - acc: 0.2133 - val_loss: 0.6685 - val_acc: 0.2037\n",
      "Epoch 590/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5954 - acc: 0.2125 - val_loss: 0.7456 - val_acc: 0.2037\n",
      "Epoch 591/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5203 - acc: 0.2120 - val_loss: 0.6411 - val_acc: 0.2037\n",
      "Epoch 592/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5580 - acc: 0.2129 - val_loss: 0.6350 - val_acc: 0.2037\n",
      "Epoch 593/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5296 - acc: 0.2133 - val_loss: 0.6609 - val_acc: 0.2037\n",
      "Epoch 594/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5774 - acc: 0.2133 - val_loss: 0.6182 - val_acc: 0.2037\n",
      "Epoch 595/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.6912 - acc: 0.2133 - val_loss: 0.8329 - val_acc: 0.2037\n",
      "Epoch 596/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5988 - acc: 0.2125 - val_loss: 0.7041 - val_acc: 0.2037\n",
      "Epoch 597/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.9874 - acc: 0.2129 - val_loss: 0.7687 - val_acc: 0.2037\n",
      "Epoch 598/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.9683 - acc: 0.2125 - val_loss: 0.6785 - val_acc: 0.2037\n",
      "Epoch 599/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.6080 - acc: 0.2129 - val_loss: 0.6974 - val_acc: 0.2037\n",
      "Epoch 600/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5052 - acc: 0.2133 - val_loss: 0.6731 - val_acc: 0.2037\n",
      "Epoch 601/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5034 - acc: 0.2137 - val_loss: 0.6494 - val_acc: 0.2037\n",
      "Epoch 602/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5021 - acc: 0.2137 - val_loss: 0.6602 - val_acc: 0.2037\n",
      "Epoch 603/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5017 - acc: 0.2133 - val_loss: 0.7089 - val_acc: 0.2037\n",
      "Epoch 604/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5098 - acc: 0.2129 - val_loss: 0.6233 - val_acc: 0.2037\n",
      "Epoch 605/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5000 - acc: 0.2129 - val_loss: 0.6253 - val_acc: 0.2037\n",
      "Epoch 606/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5246 - acc: 0.2137 - val_loss: 0.6312 - val_acc: 0.2037\n",
      "Epoch 607/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4987 - acc: 0.2129 - val_loss: 0.6167 - val_acc: 0.2037\n",
      "Epoch 608/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5176 - acc: 0.2133 - val_loss: 0.6430 - val_acc: 0.2037\n",
      "Epoch 609/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5311 - acc: 0.2137 - val_loss: 0.7273 - val_acc: 0.2037\n",
      "Epoch 610/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5102 - acc: 0.2133 - val_loss: 0.6829 - val_acc: 0.2037\n",
      "Epoch 611/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5451 - acc: 0.2125 - val_loss: 0.6194 - val_acc: 0.2037\n",
      "Epoch 612/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5983 - acc: 0.2125 - val_loss: 0.6425 - val_acc: 0.2037\n",
      "Epoch 613/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4957 - acc: 0.2129 - val_loss: 0.6174 - val_acc: 0.2037\n",
      "Epoch 614/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4870 - acc: 0.2133 - val_loss: 0.6858 - val_acc: 0.2037\n",
      "Epoch 615/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5324 - acc: 0.2120 - val_loss: 0.6132 - val_acc: 0.2037\n",
      "Epoch 616/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5261 - acc: 0.2129 - val_loss: 0.6279 - val_acc: 0.2037\n",
      "Epoch 617/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5520 - acc: 0.2125 - val_loss: 0.8141 - val_acc: 0.2037\n",
      "Epoch 618/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5138 - acc: 0.2116 - val_loss: 0.6250 - val_acc: 0.2037\n",
      "Epoch 619/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4809 - acc: 0.2133 - val_loss: 0.7129 - val_acc: 0.2037\n",
      "Epoch 620/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5217 - acc: 0.2125 - val_loss: 0.6727 - val_acc: 0.2037\n",
      "Epoch 621/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5262 - acc: 0.2129 - val_loss: 0.6967 - val_acc: 0.2037\n",
      "Epoch 622/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4910 - acc: 0.2133 - val_loss: 0.7872 - val_acc: 0.2037\n",
      "Epoch 623/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5589 - acc: 0.2133 - val_loss: 0.9398 - val_acc: 0.2037\n",
      "Epoch 624/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5225 - acc: 0.2137 - val_loss: 0.7497 - val_acc: 0.2037\n",
      "Epoch 625/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5403 - acc: 0.2125 - val_loss: 0.6339 - val_acc: 0.2037\n",
      "Epoch 626/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5368 - acc: 0.2133 - val_loss: 0.6476 - val_acc: 0.2037\n",
      "Epoch 627/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4824 - acc: 0.2125 - val_loss: 0.6493 - val_acc: 0.2037\n",
      "Epoch 628/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4996 - acc: 0.2129 - val_loss: 0.6173 - val_acc: 0.2037\n",
      "Epoch 629/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5432 - acc: 0.2133 - val_loss: 0.6792 - val_acc: 0.2037\n",
      "Epoch 630/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.6109 - acc: 0.2125 - val_loss: 0.8458 - val_acc: 0.2037\n",
      "Epoch 631/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5509 - acc: 0.2125 - val_loss: 0.6300 - val_acc: 0.2037\n",
      "Epoch 632/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5270 - acc: 0.2120 - val_loss: 0.6246 - val_acc: 0.2037\n",
      "Epoch 633/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5503 - acc: 0.2129 - val_loss: 0.6210 - val_acc: 0.2037\n",
      "Epoch 634/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5097 - acc: 0.2129 - val_loss: 0.6381 - val_acc: 0.2037\n",
      "Epoch 635/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.7173 - acc: 0.2129 - val_loss: 0.6283 - val_acc: 0.2037\n",
      "Epoch 636/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.6684 - acc: 0.2129 - val_loss: 0.6539 - val_acc: 0.2037\n",
      "Epoch 637/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5400 - acc: 0.2133 - val_loss: 0.6930 - val_acc: 0.2037\n",
      "Epoch 638/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5771 - acc: 0.2129 - val_loss: 0.6339 - val_acc: 0.2037\n",
      "Epoch 639/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5974 - acc: 0.2137 - val_loss: 0.9655 - val_acc: 0.2037\n",
      "Epoch 640/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5477 - acc: 0.2125 - val_loss: 0.6842 - val_acc: 0.2037\n",
      "Epoch 641/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4982 - acc: 0.2129 - val_loss: 0.6763 - val_acc: 0.2037\n",
      "Epoch 642/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5060 - acc: 0.2125 - val_loss: 0.6779 - val_acc: 0.2037\n",
      "Epoch 643/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5027 - acc: 0.2133 - val_loss: 0.6197 - val_acc: 0.2037\n",
      "Epoch 644/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4718 - acc: 0.2125 - val_loss: 0.6266 - val_acc: 0.2037\n",
      "Epoch 645/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5009 - acc: 0.2137 - val_loss: 0.6189 - val_acc: 0.2037\n",
      "Epoch 646/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5150 - acc: 0.2133 - val_loss: 0.6294 - val_acc: 0.2037\n",
      "Epoch 647/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.6881 - acc: 0.2129 - val_loss: 0.7947 - val_acc: 0.2037\n",
      "Epoch 648/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5205 - acc: 0.2125 - val_loss: 0.6405 - val_acc: 0.2037\n",
      "Epoch 649/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5356 - acc: 0.2129 - val_loss: 0.6224 - val_acc: 0.2037\n",
      "Epoch 650/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4999 - acc: 0.2129 - val_loss: 0.6181 - val_acc: 0.2037\n",
      "Epoch 651/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5810 - acc: 0.2133 - val_loss: 0.6875 - val_acc: 0.2037\n",
      "Epoch 652/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.6065 - acc: 0.2125 - val_loss: 0.6699 - val_acc: 0.2037\n",
      "Epoch 653/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5326 - acc: 0.2133 - val_loss: 0.6838 - val_acc: 0.2037\n",
      "Epoch 654/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5146 - acc: 0.2125 - val_loss: 0.6240 - val_acc: 0.2037\n",
      "Epoch 655/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5121 - acc: 0.2129 - val_loss: 0.6259 - val_acc: 0.2037\n",
      "Epoch 656/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5516 - acc: 0.2133 - val_loss: 0.6258 - val_acc: 0.2037\n",
      "Epoch 657/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5317 - acc: 0.2133 - val_loss: 0.6781 - val_acc: 0.2037\n",
      "Epoch 658/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5182 - acc: 0.2120 - val_loss: 0.6042 - val_acc: 0.2037\n",
      "Epoch 659/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.5276 - acc: 0.2125 - val_loss: 0.6086 - val_acc: 0.2037\n",
      "Epoch 660/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.5474 - acc: 0.2129 - val_loss: 0.7834 - val_acc: 0.2037\n",
      "Epoch 661/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5045 - acc: 0.2133 - val_loss: 0.6272 - val_acc: 0.2037\n",
      "Epoch 662/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4917 - acc: 0.2125 - val_loss: 0.6486 - val_acc: 0.2037\n",
      "Epoch 663/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5194 - acc: 0.2129 - val_loss: 0.6484 - val_acc: 0.2037\n",
      "Epoch 664/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5772 - acc: 0.2133 - val_loss: 0.7351 - val_acc: 0.2037\n",
      "Epoch 665/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.6208 - acc: 0.2137 - val_loss: 0.6508 - val_acc: 0.2037\n",
      "Epoch 666/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5287 - acc: 0.2125 - val_loss: 0.6261 - val_acc: 0.2037\n",
      "Epoch 667/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.6253 - acc: 0.2125 - val_loss: 0.6392 - val_acc: 0.2037\n",
      "Epoch 668/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.6018 - acc: 0.2129 - val_loss: 0.6978 - val_acc: 0.2037\n",
      "Epoch 669/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5811 - acc: 0.2137 - val_loss: 1.5576 - val_acc: 0.1963\n",
      "Epoch 670/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.6244 - acc: 0.2116 - val_loss: 0.6311 - val_acc: 0.2037\n",
      "Epoch 671/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4717 - acc: 0.2129 - val_loss: 0.7105 - val_acc: 0.2037\n",
      "Epoch 672/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5095 - acc: 0.2133 - val_loss: 0.8326 - val_acc: 0.2000\n",
      "Epoch 673/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4689 - acc: 0.2125 - val_loss: 0.6152 - val_acc: 0.2037\n",
      "Epoch 674/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4992 - acc: 0.2125 - val_loss: 0.6121 - val_acc: 0.2037\n",
      "Epoch 675/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5339 - acc: 0.2133 - val_loss: 0.6907 - val_acc: 0.2037\n",
      "Epoch 676/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5834 - acc: 0.2129 - val_loss: 0.6536 - val_acc: 0.2037\n",
      "Epoch 677/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5308 - acc: 0.2145 - val_loss: 0.5975 - val_acc: 0.2037\n",
      "Epoch 678/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.5276 - acc: 0.2125 - val_loss: 0.7733 - val_acc: 0.2037\n",
      "Epoch 679/10000\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 0.5150 - acc: 0.2120 - val_loss: 0.6477 - val_acc: 0.2037\n",
      "Epoch 680/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.4840 - acc: 0.2120 - val_loss: 0.6219 - val_acc: 0.2037\n",
      "Epoch 681/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.4973 - acc: 0.2133 - val_loss: 0.6252 - val_acc: 0.2037\n",
      "Epoch 682/10000\n",
      "76/76 [==============================] - 3s 46ms/step - loss: 0.5921 - acc: 0.2129 - val_loss: 0.7094 - val_acc: 0.2037\n",
      "Epoch 683/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.5715 - acc: 0.2129 - val_loss: 0.6046 - val_acc: 0.2037\n",
      "Epoch 684/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5954 - acc: 0.2137 - val_loss: 0.7167 - val_acc: 0.2037\n",
      "Epoch 685/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.8068 - acc: 0.2129 - val_loss: 0.6577 - val_acc: 0.2037\n",
      "Epoch 686/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5476 - acc: 0.2133 - val_loss: 0.6330 - val_acc: 0.2037\n",
      "Epoch 687/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5140 - acc: 0.2129 - val_loss: 0.6746 - val_acc: 0.2037\n",
      "Epoch 688/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5429 - acc: 0.2129 - val_loss: 0.6057 - val_acc: 0.2037\n",
      "Epoch 689/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.5458 - acc: 0.2120 - val_loss: 0.6199 - val_acc: 0.2037\n",
      "Epoch 690/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4925 - acc: 0.2125 - val_loss: 0.6298 - val_acc: 0.2037\n",
      "Epoch 691/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.4717 - acc: 0.2129 - val_loss: 0.6865 - val_acc: 0.2037\n",
      "Epoch 692/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.5355 - acc: 0.2120 - val_loss: 0.6793 - val_acc: 0.2037\n",
      "Epoch 693/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.5169 - acc: 0.2120 - val_loss: 0.6580 - val_acc: 0.2037\n",
      "Epoch 694/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.5109 - acc: 0.2133 - val_loss: 0.7832 - val_acc: 0.2037\n",
      "Epoch 695/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.5622 - acc: 0.2133 - val_loss: 0.6502 - val_acc: 0.2037\n",
      "Epoch 696/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5146 - acc: 0.2125 - val_loss: 0.6917 - val_acc: 0.2037\n",
      "Epoch 697/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.5011 - acc: 0.2120 - val_loss: 0.6586 - val_acc: 0.2037\n",
      "Epoch 698/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4845 - acc: 0.2133 - val_loss: 0.6246 - val_acc: 0.2037\n",
      "Epoch 699/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4787 - acc: 0.2133 - val_loss: 0.6054 - val_acc: 0.2037\n",
      "Epoch 700/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.5246 - acc: 0.2133 - val_loss: 0.6804 - val_acc: 0.2037\n",
      "Epoch 701/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5538 - acc: 0.2129 - val_loss: 0.6567 - val_acc: 0.2037\n",
      "Epoch 702/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5117 - acc: 0.2125 - val_loss: 0.6198 - val_acc: 0.2037\n",
      "Epoch 703/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5176 - acc: 0.2125 - val_loss: 0.6614 - val_acc: 0.2037\n",
      "Epoch 704/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5182 - acc: 0.2125 - val_loss: 0.5927 - val_acc: 0.2037\n",
      "Epoch 705/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.5535 - acc: 0.2129 - val_loss: 0.7418 - val_acc: 0.2037\n",
      "Epoch 706/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.4991 - acc: 0.2129 - val_loss: 0.6459 - val_acc: 0.2037\n",
      "Epoch 707/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.5366 - acc: 0.2120 - val_loss: 0.6091 - val_acc: 0.2037\n",
      "Epoch 708/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4984 - acc: 0.2125 - val_loss: 0.7247 - val_acc: 0.2037\n",
      "Epoch 709/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.5085 - acc: 0.2133 - val_loss: 0.6398 - val_acc: 0.2037\n",
      "Epoch 710/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5504 - acc: 0.2120 - val_loss: 0.6274 - val_acc: 0.2037\n",
      "Epoch 711/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.5491 - acc: 0.2129 - val_loss: 0.6528 - val_acc: 0.2037\n",
      "Epoch 712/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.6158 - acc: 0.2120 - val_loss: 0.8597 - val_acc: 0.2037\n",
      "Epoch 713/10000\n",
      "76/76 [==============================] - 3s 46ms/step - loss: 0.5460 - acc: 0.2120 - val_loss: 0.6600 - val_acc: 0.2037\n",
      "Epoch 714/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4847 - acc: 0.2125 - val_loss: 0.6682 - val_acc: 0.2037\n",
      "Epoch 715/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4994 - acc: 0.2125 - val_loss: 0.6896 - val_acc: 0.2037\n",
      "Epoch 716/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4982 - acc: 0.2129 - val_loss: 0.6462 - val_acc: 0.2037\n",
      "Epoch 717/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5315 - acc: 0.2129 - val_loss: 0.6268 - val_acc: 0.2037\n",
      "Epoch 718/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.9130 - acc: 0.2108 - val_loss: 0.7396 - val_acc: 0.2037\n",
      "Epoch 719/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.6686 - acc: 0.2120 - val_loss: 0.6942 - val_acc: 0.2037\n",
      "Epoch 720/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.5502 - acc: 0.2120 - val_loss: 0.7515 - val_acc: 0.2037\n",
      "Epoch 721/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.4895 - acc: 0.2129 - val_loss: 0.6068 - val_acc: 0.2037\n",
      "Epoch 722/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 4s 46ms/step - loss: 0.4862 - acc: 0.2133 - val_loss: 0.6082 - val_acc: 0.2037\n",
      "Epoch 723/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4814 - acc: 0.2129 - val_loss: 0.5990 - val_acc: 0.2037\n",
      "Epoch 724/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4746 - acc: 0.2129 - val_loss: 0.5981 - val_acc: 0.2037\n",
      "Epoch 725/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4787 - acc: 0.2129 - val_loss: 0.6181 - val_acc: 0.2037\n",
      "Epoch 726/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5480 - acc: 0.2125 - val_loss: 0.6036 - val_acc: 0.2037\n",
      "Epoch 727/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4964 - acc: 0.2133 - val_loss: 0.6043 - val_acc: 0.2037\n",
      "Epoch 728/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4710 - acc: 0.2129 - val_loss: 0.6976 - val_acc: 0.2037\n",
      "Epoch 729/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4857 - acc: 0.2133 - val_loss: 0.6073 - val_acc: 0.2037\n",
      "Epoch 730/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4764 - acc: 0.2133 - val_loss: 0.6142 - val_acc: 0.2037\n",
      "Epoch 731/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4755 - acc: 0.2125 - val_loss: 1.0466 - val_acc: 0.2037\n",
      "Epoch 732/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5151 - acc: 0.2137 - val_loss: 0.6634 - val_acc: 0.2037\n",
      "Epoch 733/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4759 - acc: 0.2129 - val_loss: 0.6046 - val_acc: 0.2037\n",
      "Epoch 734/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5395 - acc: 0.2120 - val_loss: 0.8896 - val_acc: 0.2000\n",
      "Epoch 735/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5697 - acc: 0.2125 - val_loss: 0.5896 - val_acc: 0.2037\n",
      "Epoch 736/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.6764 - acc: 0.2116 - val_loss: 1.0434 - val_acc: 0.2037\n",
      "Epoch 737/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.6524 - acc: 0.2125 - val_loss: 0.7843 - val_acc: 0.2000\n",
      "Epoch 738/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5894 - acc: 0.2116 - val_loss: 0.6221 - val_acc: 0.2037\n",
      "Epoch 739/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4882 - acc: 0.2129 - val_loss: 0.7533 - val_acc: 0.2037\n",
      "Epoch 740/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5260 - acc: 0.2120 - val_loss: 0.6879 - val_acc: 0.2037\n",
      "Epoch 741/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5622 - acc: 0.2120 - val_loss: 0.5895 - val_acc: 0.2037\n",
      "Epoch 742/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4804 - acc: 0.2133 - val_loss: 0.6413 - val_acc: 0.2037\n",
      "Epoch 743/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.6165 - acc: 0.2129 - val_loss: 0.7981 - val_acc: 0.2037\n",
      "Epoch 744/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.8960 - acc: 0.2125 - val_loss: 0.6728 - val_acc: 0.2037\n",
      "Epoch 745/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.8656 - acc: 0.2125 - val_loss: 0.8357 - val_acc: 0.2037\n",
      "Epoch 746/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.7495 - acc: 0.2096 - val_loss: 0.5965 - val_acc: 0.2037\n",
      "Epoch 747/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5207 - acc: 0.2129 - val_loss: 0.6707 - val_acc: 0.2037\n",
      "Epoch 748/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5228 - acc: 0.2120 - val_loss: 0.6110 - val_acc: 0.2037\n",
      "Epoch 749/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.5117 - acc: 0.2137 - val_loss: 0.5984 - val_acc: 0.2037\n",
      "Epoch 750/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5061 - acc: 0.2125 - val_loss: 0.5918 - val_acc: 0.2037\n",
      "Epoch 751/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4644 - acc: 0.2129 - val_loss: 0.5996 - val_acc: 0.2037\n",
      "Epoch 752/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4858 - acc: 0.2125 - val_loss: 0.5957 - val_acc: 0.2037\n",
      "Epoch 753/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.5393 - acc: 0.2133 - val_loss: 0.6126 - val_acc: 0.2037\n",
      "Epoch 754/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4978 - acc: 0.2125 - val_loss: 0.6104 - val_acc: 0.2037\n",
      "Epoch 755/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4797 - acc: 0.2120 - val_loss: 0.6290 - val_acc: 0.2037\n",
      "Epoch 756/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4595 - acc: 0.2129 - val_loss: 0.6332 - val_acc: 0.2037\n",
      "Epoch 757/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4564 - acc: 0.2129 - val_loss: 0.6223 - val_acc: 0.2037\n",
      "Epoch 758/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5005 - acc: 0.2129 - val_loss: 0.6098 - val_acc: 0.2037\n",
      "Epoch 759/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4769 - acc: 0.2129 - val_loss: 0.6664 - val_acc: 0.2037\n",
      "Epoch 760/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.4668 - acc: 0.2125 - val_loss: 0.6391 - val_acc: 0.2037\n",
      "Epoch 761/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4773 - acc: 0.2125 - val_loss: 0.7325 - val_acc: 0.2037\n",
      "Epoch 762/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4906 - acc: 0.2133 - val_loss: 0.6011 - val_acc: 0.2037\n",
      "Epoch 763/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5098 - acc: 0.2125 - val_loss: 0.6073 - val_acc: 0.2037\n",
      "Epoch 764/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4743 - acc: 0.2120 - val_loss: 0.7034 - val_acc: 0.2037\n",
      "Epoch 765/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.5223 - acc: 0.2125 - val_loss: 0.6135 - val_acc: 0.2037\n",
      "Epoch 766/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4721 - acc: 0.2129 - val_loss: 0.6105 - val_acc: 0.2037\n",
      "Epoch 767/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.8893 - acc: 0.2116 - val_loss: 0.7389 - val_acc: 0.2037\n",
      "Epoch 768/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4889 - acc: 0.2125 - val_loss: 0.6853 - val_acc: 0.2037\n",
      "Epoch 769/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5339 - acc: 0.2133 - val_loss: 0.6254 - val_acc: 0.2037\n",
      "Epoch 770/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4807 - acc: 0.2133 - val_loss: 0.6711 - val_acc: 0.2037\n",
      "Epoch 771/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4853 - acc: 0.2129 - val_loss: 0.6625 - val_acc: 0.2037\n",
      "Epoch 772/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.5813 - acc: 0.2133 - val_loss: 0.6208 - val_acc: 0.2037\n",
      "Epoch 773/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4738 - acc: 0.2129 - val_loss: 0.5963 - val_acc: 0.2037\n",
      "Epoch 774/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5137 - acc: 0.2125 - val_loss: 0.6194 - val_acc: 0.2037\n",
      "Epoch 775/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5136 - acc: 0.2120 - val_loss: 0.5865 - val_acc: 0.2037\n",
      "Epoch 776/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.4888 - acc: 0.2116 - val_loss: 0.5964 - val_acc: 0.2037\n",
      "Epoch 777/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4651 - acc: 0.2125 - val_loss: 0.6047 - val_acc: 0.2037\n",
      "Epoch 778/10000\n",
      "76/76 [==============================] - 4s 46ms/step - loss: 0.4861 - acc: 0.2125 - val_loss: 0.5967 - val_acc: 0.2037\n",
      "Epoch 779/10000\n",
      "76/76 [==============================] - 4s 46ms/step - loss: 0.5043 - acc: 0.2125 - val_loss: 0.6193 - val_acc: 0.2037\n",
      "Epoch 780/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5667 - acc: 0.2120 - val_loss: 0.6404 - val_acc: 0.2037\n",
      "Epoch 781/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5727 - acc: 0.2129 - val_loss: 0.6057 - val_acc: 0.2037\n",
      "Epoch 782/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 3s 37ms/step - loss: 0.7322 - acc: 0.2125 - val_loss: 0.5731 - val_acc: 0.2037\n",
      "Epoch 783/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4730 - acc: 0.2129 - val_loss: 0.6035 - val_acc: 0.2037\n",
      "Epoch 784/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5117 - acc: 0.2120 - val_loss: 0.5991 - val_acc: 0.2037\n",
      "Epoch 785/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4576 - acc: 0.2125 - val_loss: 0.6435 - val_acc: 0.2037\n",
      "Epoch 786/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5113 - acc: 0.2129 - val_loss: 0.6384 - val_acc: 0.2037\n",
      "Epoch 787/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.4952 - acc: 0.2120 - val_loss: 0.6604 - val_acc: 0.2037\n",
      "Epoch 788/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5591 - acc: 0.2120 - val_loss: 0.6574 - val_acc: 0.2037\n",
      "Epoch 789/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.5304 - acc: 0.2129 - val_loss: 0.8604 - val_acc: 0.2000\n",
      "Epoch 790/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.6236 - acc: 0.2129 - val_loss: 0.7859 - val_acc: 0.2000\n",
      "Epoch 791/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.5475 - acc: 0.2125 - val_loss: 0.6620 - val_acc: 0.2037\n",
      "Epoch 792/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.5171 - acc: 0.2129 - val_loss: 0.5996 - val_acc: 0.2037\n",
      "Epoch 793/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4952 - acc: 0.2133 - val_loss: 0.6561 - val_acc: 0.2037\n",
      "Epoch 794/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4646 - acc: 0.2120 - val_loss: 0.6366 - val_acc: 0.2037\n",
      "Epoch 795/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4577 - acc: 0.2125 - val_loss: 0.5892 - val_acc: 0.2037\n",
      "Epoch 796/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4685 - acc: 0.2133 - val_loss: 0.5947 - val_acc: 0.2037\n",
      "Epoch 797/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.4912 - acc: 0.2125 - val_loss: 0.6231 - val_acc: 0.2037\n",
      "Epoch 798/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4881 - acc: 0.2125 - val_loss: 0.6474 - val_acc: 0.2037\n",
      "Epoch 799/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.5008 - acc: 0.2125 - val_loss: 0.5960 - val_acc: 0.2037\n",
      "Epoch 800/10000\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 0.4825 - acc: 0.2129 - val_loss: 0.5915 - val_acc: 0.2037\n",
      "Epoch 801/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4883 - acc: 0.2116 - val_loss: 0.6243 - val_acc: 0.2037\n",
      "Epoch 802/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.4978 - acc: 0.2129 - val_loss: 0.6155 - val_acc: 0.2037\n",
      "Epoch 803/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.4613 - acc: 0.2125 - val_loss: 0.6271 - val_acc: 0.2037\n",
      "Epoch 804/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4854 - acc: 0.2125 - val_loss: 0.5987 - val_acc: 0.2037\n",
      "Epoch 805/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4821 - acc: 0.2120 - val_loss: 0.6003 - val_acc: 0.2037\n",
      "Epoch 806/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5649 - acc: 0.2129 - val_loss: 0.8614 - val_acc: 0.2000\n",
      "Epoch 807/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.6085 - acc: 0.2129 - val_loss: 0.6653 - val_acc: 0.2037\n",
      "Epoch 808/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.7667 - acc: 0.2125 - val_loss: 0.6487 - val_acc: 0.2037\n",
      "Epoch 809/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4998 - acc: 0.2120 - val_loss: 0.5881 - val_acc: 0.2037\n",
      "Epoch 810/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5409 - acc: 0.2125 - val_loss: 0.6291 - val_acc: 0.2037\n",
      "Epoch 811/10000\n",
      "76/76 [==============================] - 4s 46ms/step - loss: 0.4604 - acc: 0.2125 - val_loss: 0.6015 - val_acc: 0.2037\n",
      "Epoch 812/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4636 - acc: 0.2129 - val_loss: 0.5880 - val_acc: 0.2037\n",
      "Epoch 813/10000\n",
      "76/76 [==============================] - 5s 64ms/step - loss: 0.4587 - acc: 0.2133 - val_loss: 0.6412 - val_acc: 0.2037\n",
      "Epoch 814/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.4973 - acc: 0.2120 - val_loss: 0.6178 - val_acc: 0.2037\n",
      "Epoch 815/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.4832 - acc: 0.2125 - val_loss: 0.5894 - val_acc: 0.2037\n",
      "Epoch 816/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4779 - acc: 0.2125 - val_loss: 0.5911 - val_acc: 0.2037\n",
      "Epoch 817/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4869 - acc: 0.2125 - val_loss: 0.7356 - val_acc: 0.2000\n",
      "Epoch 818/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4900 - acc: 0.2112 - val_loss: 0.5913 - val_acc: 0.2037\n",
      "Epoch 819/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4816 - acc: 0.2125 - val_loss: 0.6048 - val_acc: 0.2037\n",
      "Epoch 820/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.5196 - acc: 0.2125 - val_loss: 0.6526 - val_acc: 0.2037\n",
      "Epoch 821/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4945 - acc: 0.2125 - val_loss: 0.6626 - val_acc: 0.2037\n",
      "Epoch 822/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.8295 - acc: 0.2120 - val_loss: 0.6017 - val_acc: 0.2037\n",
      "Epoch 823/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4959 - acc: 0.2125 - val_loss: 0.6300 - val_acc: 0.2037\n",
      "Epoch 824/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5758 - acc: 0.2129 - val_loss: 0.5908 - val_acc: 0.2037\n",
      "Epoch 825/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4749 - acc: 0.2133 - val_loss: 0.7144 - val_acc: 0.2037\n",
      "Epoch 826/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.5126 - acc: 0.2116 - val_loss: 0.6294 - val_acc: 0.2037\n",
      "Epoch 827/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5189 - acc: 0.2120 - val_loss: 0.8132 - val_acc: 0.2000\n",
      "Epoch 828/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4839 - acc: 0.2129 - val_loss: 0.6151 - val_acc: 0.2037\n",
      "Epoch 829/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4981 - acc: 0.2125 - val_loss: 0.5880 - val_acc: 0.2037\n",
      "Epoch 830/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4798 - acc: 0.2125 - val_loss: 0.5905 - val_acc: 0.2037\n",
      "Epoch 831/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.4589 - acc: 0.2125 - val_loss: 0.5938 - val_acc: 0.2037\n",
      "Epoch 832/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4988 - acc: 0.2125 - val_loss: 0.7300 - val_acc: 0.2037\n",
      "Epoch 833/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4628 - acc: 0.2125 - val_loss: 0.6080 - val_acc: 0.2037\n",
      "Epoch 834/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4802 - acc: 0.2125 - val_loss: 0.7750 - val_acc: 0.2000\n",
      "Epoch 835/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.4786 - acc: 0.2120 - val_loss: 0.6839 - val_acc: 0.2037\n",
      "Epoch 836/10000\n",
      "76/76 [==============================] - 3s 46ms/step - loss: 0.5774 - acc: 0.2129 - val_loss: 0.6079 - val_acc: 0.2037\n",
      "Epoch 837/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4788 - acc: 0.2125 - val_loss: 0.6241 - val_acc: 0.2037\n",
      "Epoch 838/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4556 - acc: 0.2120 - val_loss: 0.5821 - val_acc: 0.2037\n",
      "Epoch 839/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4553 - acc: 0.2120 - val_loss: 0.5978 - val_acc: 0.2037\n",
      "Epoch 840/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4807 - acc: 0.2129 - val_loss: 0.5869 - val_acc: 0.2037\n",
      "Epoch 841/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4951 - acc: 0.2120 - val_loss: 0.5983 - val_acc: 0.2037\n",
      "Epoch 842/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 3s 36ms/step - loss: 0.6021 - acc: 0.2129 - val_loss: 0.6173 - val_acc: 0.2037\n",
      "Epoch 843/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.7265 - acc: 0.2133 - val_loss: 0.7423 - val_acc: 0.2037\n",
      "Epoch 844/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.6014 - acc: 0.2125 - val_loss: 0.7635 - val_acc: 0.2037\n",
      "Epoch 845/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 1.1641 - acc: 0.2120 - val_loss: 0.6575 - val_acc: 0.2037\n",
      "Epoch 846/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.5081 - acc: 0.2129 - val_loss: 0.5807 - val_acc: 0.2037\n",
      "Epoch 847/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.5327 - acc: 0.2125 - val_loss: 0.6292 - val_acc: 0.2037\n",
      "Epoch 848/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4554 - acc: 0.2120 - val_loss: 0.5836 - val_acc: 0.2037\n",
      "Epoch 849/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4638 - acc: 0.2125 - val_loss: 0.5815 - val_acc: 0.2037\n",
      "Epoch 850/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4702 - acc: 0.2120 - val_loss: 0.5767 - val_acc: 0.2037\n",
      "Epoch 851/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4946 - acc: 0.2125 - val_loss: 0.5865 - val_acc: 0.2037\n",
      "Epoch 852/10000\n",
      "76/76 [==============================] - 4s 46ms/step - loss: 0.4516 - acc: 0.2125 - val_loss: 0.5943 - val_acc: 0.2037\n",
      "Epoch 853/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4687 - acc: 0.2129 - val_loss: 0.6890 - val_acc: 0.2037\n",
      "Epoch 854/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4685 - acc: 0.2125 - val_loss: 0.6402 - val_acc: 0.2037\n",
      "Epoch 855/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4782 - acc: 0.2129 - val_loss: 0.5803 - val_acc: 0.2037\n",
      "Epoch 856/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4775 - acc: 0.2125 - val_loss: 0.5885 - val_acc: 0.2037\n",
      "Epoch 857/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4671 - acc: 0.2125 - val_loss: 0.6568 - val_acc: 0.2037\n",
      "Epoch 858/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5589 - acc: 0.2116 - val_loss: 0.6033 - val_acc: 0.2037\n",
      "Epoch 859/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.5217 - acc: 0.2120 - val_loss: 0.5866 - val_acc: 0.2037\n",
      "Epoch 860/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.5562 - acc: 0.2129 - val_loss: 0.6405 - val_acc: 0.2037\n",
      "Epoch 861/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.5352 - acc: 0.2125 - val_loss: 0.8445 - val_acc: 0.2000\n",
      "Epoch 862/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.4723 - acc: 0.2125 - val_loss: 0.6168 - val_acc: 0.2037\n",
      "Epoch 863/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.5202 - acc: 0.2116 - val_loss: 0.8513 - val_acc: 0.2037\n",
      "Epoch 864/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4707 - acc: 0.2125 - val_loss: 0.8083 - val_acc: 0.2000\n",
      "Epoch 865/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4764 - acc: 0.2116 - val_loss: 0.5975 - val_acc: 0.2037\n",
      "Epoch 866/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4789 - acc: 0.2129 - val_loss: 0.6319 - val_acc: 0.2037\n",
      "Epoch 867/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4956 - acc: 0.2120 - val_loss: 0.7597 - val_acc: 0.2000\n",
      "Epoch 868/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4803 - acc: 0.2125 - val_loss: 0.6298 - val_acc: 0.2037\n",
      "Epoch 869/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.5980 - acc: 0.2129 - val_loss: 0.6225 - val_acc: 0.2037\n",
      "Epoch 870/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4980 - acc: 0.2125 - val_loss: 0.5865 - val_acc: 0.2037\n",
      "Epoch 871/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4864 - acc: 0.2129 - val_loss: 0.6316 - val_acc: 0.2037\n",
      "Epoch 872/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5425 - acc: 0.2125 - val_loss: 0.5607 - val_acc: 0.2037\n",
      "Epoch 873/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5279 - acc: 0.2129 - val_loss: 0.6329 - val_acc: 0.2037\n",
      "Epoch 874/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4927 - acc: 0.2129 - val_loss: 0.6870 - val_acc: 0.2037\n",
      "Epoch 875/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.5062 - acc: 0.2125 - val_loss: 0.6052 - val_acc: 0.2037\n",
      "Epoch 876/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.7458 - acc: 0.2125 - val_loss: 0.7314 - val_acc: 0.2037\n",
      "Epoch 877/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.6147 - acc: 0.2125 - val_loss: 0.6521 - val_acc: 0.2037\n",
      "Epoch 878/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.5321 - acc: 0.2120 - val_loss: 0.7505 - val_acc: 0.2037\n",
      "Epoch 879/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.4785 - acc: 0.2120 - val_loss: 0.5866 - val_acc: 0.2037\n",
      "Epoch 880/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4932 - acc: 0.2125 - val_loss: 0.6567 - val_acc: 0.2037\n",
      "Epoch 881/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.4738 - acc: 0.2129 - val_loss: 0.5853 - val_acc: 0.2037\n",
      "Epoch 882/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4711 - acc: 0.2125 - val_loss: 0.5868 - val_acc: 0.2037\n",
      "Epoch 883/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4691 - acc: 0.2133 - val_loss: 0.5784 - val_acc: 0.2037\n",
      "Epoch 884/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5235 - acc: 0.2120 - val_loss: 0.6122 - val_acc: 0.2037\n",
      "Epoch 885/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.4708 - acc: 0.2120 - val_loss: 0.6552 - val_acc: 0.2037\n",
      "Epoch 886/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.4742 - acc: 0.2125 - val_loss: 0.6501 - val_acc: 0.2037\n",
      "Epoch 887/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.5025 - acc: 0.2120 - val_loss: 0.5837 - val_acc: 0.2037\n",
      "Epoch 888/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.4912 - acc: 0.2125 - val_loss: 0.6021 - val_acc: 0.2037\n",
      "Epoch 889/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.5529 - acc: 0.2120 - val_loss: 0.6729 - val_acc: 0.2037\n",
      "Epoch 890/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4793 - acc: 0.2125 - val_loss: 0.6312 - val_acc: 0.2037\n",
      "Epoch 891/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4974 - acc: 0.2137 - val_loss: 0.6399 - val_acc: 0.2037\n",
      "Epoch 892/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4741 - acc: 0.2125 - val_loss: 0.5989 - val_acc: 0.2037\n",
      "Epoch 893/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4776 - acc: 0.2129 - val_loss: 0.6404 - val_acc: 0.2037\n",
      "Epoch 894/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4500 - acc: 0.2125 - val_loss: 0.7555 - val_acc: 0.2000\n",
      "Epoch 895/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.4694 - acc: 0.2133 - val_loss: 0.6878 - val_acc: 0.2037\n",
      "Epoch 896/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.4816 - acc: 0.2125 - val_loss: 0.8524 - val_acc: 0.2000\n",
      "Epoch 897/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.6235 - acc: 0.2120 - val_loss: 0.9870 - val_acc: 0.2000\n",
      "Epoch 898/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.7141 - acc: 0.2116 - val_loss: 0.6485 - val_acc: 0.2037\n",
      "Epoch 899/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5254 - acc: 0.2125 - val_loss: 0.6085 - val_acc: 0.2037\n",
      "Epoch 900/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.4922 - acc: 0.2129 - val_loss: 0.5778 - val_acc: 0.2037\n",
      "Epoch 901/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.4472 - acc: 0.2120 - val_loss: 0.6113 - val_acc: 0.2037\n",
      "Epoch 902/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 3s 42ms/step - loss: 0.5627 - acc: 0.2125 - val_loss: 0.6073 - val_acc: 0.2037\n",
      "Epoch 903/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.6574 - acc: 0.2137 - val_loss: 0.6089 - val_acc: 0.2037\n",
      "Epoch 904/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.5737 - acc: 0.2120 - val_loss: 0.6584 - val_acc: 0.2037\n",
      "Epoch 905/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5738 - acc: 0.2120 - val_loss: 0.6100 - val_acc: 0.2037\n",
      "Epoch 906/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4746 - acc: 0.2129 - val_loss: 0.7333 - val_acc: 0.2000\n",
      "Epoch 907/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4792 - acc: 0.2116 - val_loss: 0.5668 - val_acc: 0.2037\n",
      "Epoch 908/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4777 - acc: 0.2125 - val_loss: 0.5917 - val_acc: 0.2037\n",
      "Epoch 909/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4860 - acc: 0.2133 - val_loss: 0.6089 - val_acc: 0.2037\n",
      "Epoch 910/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4480 - acc: 0.2125 - val_loss: 0.6071 - val_acc: 0.2037\n",
      "Epoch 911/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4711 - acc: 0.2120 - val_loss: 0.6410 - val_acc: 0.2037\n",
      "Epoch 912/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4716 - acc: 0.2125 - val_loss: 0.5757 - val_acc: 0.2037\n",
      "Epoch 913/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4461 - acc: 0.2125 - val_loss: 0.6631 - val_acc: 0.2037\n",
      "Epoch 914/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4941 - acc: 0.2125 - val_loss: 0.5900 - val_acc: 0.2037\n",
      "Epoch 915/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.5103 - acc: 0.2129 - val_loss: 0.5888 - val_acc: 0.2037\n",
      "Epoch 916/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.5716 - acc: 0.2112 - val_loss: 0.6776 - val_acc: 0.2037\n",
      "Epoch 917/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5136 - acc: 0.2125 - val_loss: 0.5927 - val_acc: 0.2037\n",
      "Epoch 918/10000\n",
      "76/76 [==============================] - 3s 46ms/step - loss: 0.5142 - acc: 0.2125 - val_loss: 0.5695 - val_acc: 0.2037\n",
      "Epoch 919/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.5043 - acc: 0.2120 - val_loss: 0.7900 - val_acc: 0.2000\n",
      "Epoch 920/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.5009 - acc: 0.2133 - val_loss: 0.5757 - val_acc: 0.2037\n",
      "Epoch 921/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.5106 - acc: 0.2120 - val_loss: 1.1401 - val_acc: 0.2000\n",
      "Epoch 922/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.5334 - acc: 0.2120 - val_loss: 0.5811 - val_acc: 0.2037\n",
      "Epoch 923/10000\n",
      "76/76 [==============================] - 5s 60ms/step - loss: 0.4783 - acc: 0.2133 - val_loss: 0.6834 - val_acc: 0.2037\n",
      "Epoch 924/10000\n",
      "76/76 [==============================] - 4s 46ms/step - loss: 0.4539 - acc: 0.2120 - val_loss: 0.5739 - val_acc: 0.2037\n",
      "Epoch 925/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.4738 - acc: 0.2125 - val_loss: 0.5863 - val_acc: 0.2037\n",
      "Epoch 926/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4813 - acc: 0.2125 - val_loss: 0.6262 - val_acc: 0.2037\n",
      "Epoch 927/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4802 - acc: 0.2125 - val_loss: 0.5906 - val_acc: 0.2037\n",
      "Epoch 928/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4766 - acc: 0.2125 - val_loss: 0.8120 - val_acc: 0.2000\n",
      "Epoch 929/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.6187 - acc: 0.2125 - val_loss: 0.6700 - val_acc: 0.2037\n",
      "Epoch 930/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.5205 - acc: 0.2129 - val_loss: 0.6349 - val_acc: 0.2037\n",
      "Epoch 931/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.5639 - acc: 0.2129 - val_loss: 0.6561 - val_acc: 0.2037\n",
      "Epoch 932/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4647 - acc: 0.2125 - val_loss: 0.5903 - val_acc: 0.2037\n",
      "Epoch 933/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.6092 - acc: 0.2112 - val_loss: 0.5992 - val_acc: 0.2037\n",
      "Epoch 934/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4984 - acc: 0.2125 - val_loss: 0.6851 - val_acc: 0.2037\n",
      "Epoch 935/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4699 - acc: 0.2125 - val_loss: 0.5968 - val_acc: 0.2037\n",
      "Epoch 936/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5524 - acc: 0.2137 - val_loss: 0.5765 - val_acc: 0.2037\n",
      "Epoch 937/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5197 - acc: 0.2125 - val_loss: 0.6558 - val_acc: 0.2037\n",
      "Epoch 938/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.7803 - acc: 0.2125 - val_loss: 0.6139 - val_acc: 0.2037\n",
      "Epoch 939/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4792 - acc: 0.2129 - val_loss: 0.7337 - val_acc: 0.2037\n",
      "Epoch 940/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4761 - acc: 0.2120 - val_loss: 0.5683 - val_acc: 0.2037\n",
      "Epoch 941/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4632 - acc: 0.2129 - val_loss: 0.6717 - val_acc: 0.2037\n",
      "Epoch 942/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.4547 - acc: 0.2120 - val_loss: 0.6007 - val_acc: 0.2037\n",
      "Epoch 943/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4380 - acc: 0.2120 - val_loss: 0.5827 - val_acc: 0.2037\n",
      "Epoch 944/10000\n",
      "76/76 [==============================] - 5s 66ms/step - loss: 0.4685 - acc: 0.2120 - val_loss: 0.5829 - val_acc: 0.2037\n",
      "Epoch 945/10000\n",
      "76/76 [==============================] - 5s 63ms/step - loss: 0.4642 - acc: 0.2125 - val_loss: 0.5937 - val_acc: 0.2037\n",
      "Epoch 946/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.5035 - acc: 0.2129 - val_loss: 0.6235 - val_acc: 0.2037\n",
      "Epoch 947/10000\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 0.4981 - acc: 0.2129 - val_loss: 0.6254 - val_acc: 0.2037\n",
      "Epoch 948/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4771 - acc: 0.2129 - val_loss: 0.6144 - val_acc: 0.2037\n",
      "Epoch 949/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4849 - acc: 0.2125 - val_loss: 0.5812 - val_acc: 0.2037\n",
      "Epoch 950/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4759 - acc: 0.2120 - val_loss: 0.7856 - val_acc: 0.2037\n",
      "Epoch 951/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4818 - acc: 0.2120 - val_loss: 0.6256 - val_acc: 0.2037\n",
      "Epoch 952/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4982 - acc: 0.2129 - val_loss: 0.6193 - val_acc: 0.2037\n",
      "Epoch 953/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5102 - acc: 0.2120 - val_loss: 0.5951 - val_acc: 0.2037\n",
      "Epoch 954/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4580 - acc: 0.2120 - val_loss: 0.5836 - val_acc: 0.2037\n",
      "Epoch 955/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.6581 - acc: 0.2125 - val_loss: 0.8797 - val_acc: 0.2000\n",
      "Epoch 956/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.6617 - acc: 0.2116 - val_loss: 0.6211 - val_acc: 0.2037\n",
      "Epoch 957/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 1.0697 - acc: 0.2129 - val_loss: 0.6098 - val_acc: 0.2037\n",
      "Epoch 958/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5303 - acc: 0.2133 - val_loss: 0.6902 - val_acc: 0.2037\n",
      "Epoch 959/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4701 - acc: 0.2125 - val_loss: 0.6486 - val_acc: 0.2037\n",
      "Epoch 960/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4876 - acc: 0.2125 - val_loss: 0.6477 - val_acc: 0.2037\n",
      "Epoch 961/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4760 - acc: 0.2125 - val_loss: 0.5769 - val_acc: 0.2037\n",
      "Epoch 962/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4373 - acc: 0.2120 - val_loss: 0.6467 - val_acc: 0.2037\n",
      "Epoch 963/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4455 - acc: 0.2125 - val_loss: 0.5680 - val_acc: 0.2037\n",
      "Epoch 964/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4809 - acc: 0.2120 - val_loss: 0.9336 - val_acc: 0.2037\n",
      "Epoch 965/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4602 - acc: 0.2133 - val_loss: 0.6011 - val_acc: 0.2037\n",
      "Epoch 966/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4462 - acc: 0.2125 - val_loss: 0.5816 - val_acc: 0.2037\n",
      "Epoch 967/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4458 - acc: 0.2133 - val_loss: 0.5715 - val_acc: 0.2037\n",
      "Epoch 968/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4461 - acc: 0.2120 - val_loss: 0.5714 - val_acc: 0.2037\n",
      "Epoch 969/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5263 - acc: 0.2125 - val_loss: 0.6004 - val_acc: 0.2037\n",
      "Epoch 970/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4573 - acc: 0.2125 - val_loss: 0.5832 - val_acc: 0.2037\n",
      "Epoch 971/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4383 - acc: 0.2125 - val_loss: 0.5929 - val_acc: 0.2037\n",
      "Epoch 972/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4402 - acc: 0.2120 - val_loss: 0.7782 - val_acc: 0.2000\n",
      "Epoch 973/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4544 - acc: 0.2129 - val_loss: 0.6295 - val_acc: 0.2037\n",
      "Epoch 974/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4735 - acc: 0.2116 - val_loss: 0.5801 - val_acc: 0.2037\n",
      "Epoch 975/10000\n",
      "76/76 [==============================] - 5s 61ms/step - loss: 0.4482 - acc: 0.2120 - val_loss: 0.5858 - val_acc: 0.2037\n",
      "Epoch 976/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.4398 - acc: 0.2120 - val_loss: 0.6125 - val_acc: 0.2037\n",
      "Epoch 977/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4687 - acc: 0.2120 - val_loss: 0.6104 - val_acc: 0.2037\n",
      "Epoch 978/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4447 - acc: 0.2120 - val_loss: 0.5992 - val_acc: 0.2037\n",
      "Epoch 979/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.5753 - acc: 0.2116 - val_loss: 0.6927 - val_acc: 0.2037\n",
      "Epoch 980/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.5211 - acc: 0.2133 - val_loss: 0.5877 - val_acc: 0.2037\n",
      "Epoch 981/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.4808 - acc: 0.2116 - val_loss: 0.6696 - val_acc: 0.2037\n",
      "Epoch 982/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4663 - acc: 0.2125 - val_loss: 0.8541 - val_acc: 0.2000\n",
      "Epoch 983/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5648 - acc: 0.2125 - val_loss: 0.7239 - val_acc: 0.2037\n",
      "Epoch 984/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4608 - acc: 0.2120 - val_loss: 0.5735 - val_acc: 0.2037\n",
      "Epoch 985/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4529 - acc: 0.2120 - val_loss: 0.6510 - val_acc: 0.2037\n",
      "Epoch 986/10000\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 0.5028 - acc: 0.2120 - val_loss: 0.6100 - val_acc: 0.2037\n",
      "Epoch 987/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4811 - acc: 0.2133 - val_loss: 0.9229 - val_acc: 0.2000\n",
      "Epoch 988/10000\n",
      "76/76 [==============================] - 4s 57ms/step - loss: 0.4895 - acc: 0.2116 - val_loss: 0.5814 - val_acc: 0.2037\n",
      "Epoch 989/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4566 - acc: 0.2120 - val_loss: 0.6978 - val_acc: 0.2037\n",
      "Epoch 990/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.5357 - acc: 0.2120 - val_loss: 0.6458 - val_acc: 0.2037\n",
      "Epoch 991/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 1.1462 - acc: 0.2083 - val_loss: 0.6174 - val_acc: 0.2037\n",
      "Epoch 992/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4830 - acc: 0.2125 - val_loss: 0.5751 - val_acc: 0.2037\n",
      "Epoch 993/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.5424 - acc: 0.2120 - val_loss: 0.5873 - val_acc: 0.2037\n",
      "Epoch 994/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5026 - acc: 0.2129 - val_loss: 0.5882 - val_acc: 0.2037\n",
      "Epoch 995/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4561 - acc: 0.2120 - val_loss: 0.5657 - val_acc: 0.2037\n",
      "Epoch 996/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4467 - acc: 0.2120 - val_loss: 0.5683 - val_acc: 0.2037\n",
      "Epoch 997/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4683 - acc: 0.2129 - val_loss: 0.9384 - val_acc: 0.2000\n",
      "Epoch 998/10000\n",
      "76/76 [==============================] - 3s 46ms/step - loss: 0.4603 - acc: 0.2120 - val_loss: 0.5629 - val_acc: 0.2037\n",
      "Epoch 999/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4464 - acc: 0.2125 - val_loss: 0.5850 - val_acc: 0.2037\n",
      "Epoch 1000/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4621 - acc: 0.2125 - val_loss: 0.5914 - val_acc: 0.2037\n",
      "Epoch 1001/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4493 - acc: 0.2129 - val_loss: 0.5840 - val_acc: 0.2037\n",
      "Epoch 1002/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4716 - acc: 0.2120 - val_loss: 0.5694 - val_acc: 0.2037\n",
      "Epoch 1003/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4708 - acc: 0.2120 - val_loss: 0.7184 - val_acc: 0.2000\n",
      "Epoch 1004/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4633 - acc: 0.2116 - val_loss: 0.7252 - val_acc: 0.2000\n",
      "Epoch 1005/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4751 - acc: 0.2125 - val_loss: 0.6860 - val_acc: 0.2037\n",
      "Epoch 1006/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4564 - acc: 0.2116 - val_loss: 0.5657 - val_acc: 0.2037\n",
      "Epoch 1007/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4454 - acc: 0.2120 - val_loss: 0.5697 - val_acc: 0.2037\n",
      "Epoch 1008/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.4528 - acc: 0.2125 - val_loss: 0.6641 - val_acc: 0.2037\n",
      "Epoch 1009/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4799 - acc: 0.2129 - val_loss: 0.6209 - val_acc: 0.2037\n",
      "Epoch 1010/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4730 - acc: 0.2125 - val_loss: 0.5930 - val_acc: 0.2037\n",
      "Epoch 1011/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4564 - acc: 0.2125 - val_loss: 0.5572 - val_acc: 0.2037\n",
      "Epoch 1012/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5024 - acc: 0.2129 - val_loss: 0.7325 - val_acc: 0.2000\n",
      "Epoch 1013/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.4770 - acc: 0.2120 - val_loss: 0.5662 - val_acc: 0.2037\n",
      "Epoch 1014/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.4801 - acc: 0.2125 - val_loss: 0.6149 - val_acc: 0.2037\n",
      "Epoch 1015/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.6571 - acc: 0.2133 - val_loss: 0.7038 - val_acc: 0.2037\n",
      "Epoch 1016/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.5298 - acc: 0.2129 - val_loss: 0.7073 - val_acc: 0.2037\n",
      "Epoch 1017/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.5264 - acc: 0.2120 - val_loss: 0.6420 - val_acc: 0.2037\n",
      "Epoch 1018/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.5739 - acc: 0.2125 - val_loss: 0.6475 - val_acc: 0.2037\n",
      "Epoch 1019/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.9814 - acc: 0.2129 - val_loss: 0.5827 - val_acc: 0.2037\n",
      "Epoch 1020/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.5181 - acc: 0.2129 - val_loss: 0.6543 - val_acc: 0.2037\n",
      "Epoch 1021/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.4943 - acc: 0.2120 - val_loss: 0.5503 - val_acc: 0.2037\n",
      "Epoch 1022/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 3s 45ms/step - loss: 0.4625 - acc: 0.2129 - val_loss: 0.5889 - val_acc: 0.2037\n",
      "Epoch 1023/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.5071 - acc: 0.2137 - val_loss: 0.5642 - val_acc: 0.2037\n",
      "Epoch 1024/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4593 - acc: 0.2129 - val_loss: 0.5610 - val_acc: 0.2037\n",
      "Epoch 1025/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.4415 - acc: 0.2129 - val_loss: 0.5589 - val_acc: 0.2037\n",
      "Epoch 1026/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4651 - acc: 0.2120 - val_loss: 0.7049 - val_acc: 0.2000\n",
      "Epoch 1027/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4316 - acc: 0.2125 - val_loss: 0.5883 - val_acc: 0.2037\n",
      "Epoch 1028/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4453 - acc: 0.2125 - val_loss: 0.5594 - val_acc: 0.2037\n",
      "Epoch 1029/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4688 - acc: 0.2125 - val_loss: 0.5866 - val_acc: 0.2037\n",
      "Epoch 1030/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4465 - acc: 0.2125 - val_loss: 0.6150 - val_acc: 0.2037\n",
      "Epoch 1031/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4873 - acc: 0.2129 - val_loss: 0.6027 - val_acc: 0.2037\n",
      "Epoch 1032/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.4637 - acc: 0.2125 - val_loss: 0.6622 - val_acc: 0.2037\n",
      "Epoch 1033/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.5319 - acc: 0.2129 - val_loss: 0.7327 - val_acc: 0.2000\n",
      "Epoch 1034/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.4561 - acc: 0.2120 - val_loss: 0.6228 - val_acc: 0.2037\n",
      "Epoch 1035/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4915 - acc: 0.2120 - val_loss: 0.6487 - val_acc: 0.2000\n",
      "Epoch 1036/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.4492 - acc: 0.2133 - val_loss: 0.7695 - val_acc: 0.2037\n",
      "Epoch 1037/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4678 - acc: 0.2125 - val_loss: 0.6014 - val_acc: 0.2037\n",
      "Epoch 1038/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4989 - acc: 0.2129 - val_loss: 0.5733 - val_acc: 0.2037\n",
      "Epoch 1039/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.5007 - acc: 0.2120 - val_loss: 0.5968 - val_acc: 0.2037\n",
      "Epoch 1040/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.7843 - acc: 0.2129 - val_loss: 0.7901 - val_acc: 0.2000\n",
      "Epoch 1041/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.6765 - acc: 0.2120 - val_loss: 0.6034 - val_acc: 0.2037\n",
      "Epoch 1042/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.5851 - acc: 0.2120 - val_loss: 0.6032 - val_acc: 0.2037\n",
      "Epoch 1043/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.7280 - acc: 0.2125 - val_loss: 0.6076 - val_acc: 0.2037\n",
      "Epoch 1044/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4890 - acc: 0.2125 - val_loss: 0.5708 - val_acc: 0.2037\n",
      "Epoch 1045/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4281 - acc: 0.2125 - val_loss: 0.5728 - val_acc: 0.2037\n",
      "Epoch 1046/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4590 - acc: 0.2129 - val_loss: 0.6219 - val_acc: 0.2037\n",
      "Epoch 1047/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4384 - acc: 0.2120 - val_loss: 0.5730 - val_acc: 0.2037\n",
      "Epoch 1048/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4413 - acc: 0.2125 - val_loss: 0.5692 - val_acc: 0.2037\n",
      "Epoch 1049/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4588 - acc: 0.2125 - val_loss: 0.5657 - val_acc: 0.2037\n",
      "Epoch 1050/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4784 - acc: 0.2129 - val_loss: 0.5669 - val_acc: 0.2037\n",
      "Epoch 1051/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4598 - acc: 0.2125 - val_loss: 0.6244 - val_acc: 0.2037\n",
      "Epoch 1052/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4472 - acc: 0.2120 - val_loss: 0.5565 - val_acc: 0.2037\n",
      "Epoch 1053/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4463 - acc: 0.2120 - val_loss: 0.5642 - val_acc: 0.2037\n",
      "Epoch 1054/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4489 - acc: 0.2125 - val_loss: 0.5775 - val_acc: 0.2037\n",
      "Epoch 1055/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4699 - acc: 0.2125 - val_loss: 0.5829 - val_acc: 0.2037\n",
      "Epoch 1056/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4406 - acc: 0.2125 - val_loss: 0.5652 - val_acc: 0.2037\n",
      "Epoch 1057/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4432 - acc: 0.2120 - val_loss: 0.5718 - val_acc: 0.2037\n",
      "Epoch 1058/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4565 - acc: 0.2116 - val_loss: 0.5817 - val_acc: 0.2037\n",
      "Epoch 1059/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4921 - acc: 0.2112 - val_loss: 0.7780 - val_acc: 0.2037\n",
      "Epoch 1060/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5132 - acc: 0.2120 - val_loss: 0.5739 - val_acc: 0.2037\n",
      "Epoch 1061/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4594 - acc: 0.2116 - val_loss: 0.5910 - val_acc: 0.2037\n",
      "Epoch 1062/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5108 - acc: 0.2120 - val_loss: 0.6326 - val_acc: 0.2037\n",
      "Epoch 1063/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5307 - acc: 0.2116 - val_loss: 0.5596 - val_acc: 0.2037\n",
      "Epoch 1064/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4803 - acc: 0.2129 - val_loss: 0.7008 - val_acc: 0.2000\n",
      "Epoch 1065/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4610 - acc: 0.2125 - val_loss: 0.5679 - val_acc: 0.2037\n",
      "Epoch 1066/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4854 - acc: 0.2125 - val_loss: 0.8919 - val_acc: 0.2000\n",
      "Epoch 1067/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.6565 - acc: 0.2133 - val_loss: 0.7296 - val_acc: 0.2000\n",
      "Epoch 1068/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5451 - acc: 0.2129 - val_loss: 0.6345 - val_acc: 0.2037\n",
      "Epoch 1069/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4840 - acc: 0.2133 - val_loss: 0.9390 - val_acc: 0.2000\n",
      "Epoch 1070/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4775 - acc: 0.2125 - val_loss: 0.5748 - val_acc: 0.2037\n",
      "Epoch 1071/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4665 - acc: 0.2125 - val_loss: 0.6362 - val_acc: 0.2037\n",
      "Epoch 1072/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4614 - acc: 0.2129 - val_loss: 0.5748 - val_acc: 0.2037\n",
      "Epoch 1073/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4575 - acc: 0.2120 - val_loss: 0.6499 - val_acc: 0.2037\n",
      "Epoch 1074/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4670 - acc: 0.2116 - val_loss: 0.5748 - val_acc: 0.2037\n",
      "Epoch 1075/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.4736 - acc: 0.2120 - val_loss: 0.7264 - val_acc: 0.2000\n",
      "Epoch 1076/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.5683 - acc: 0.2129 - val_loss: 0.6351 - val_acc: 0.2037\n",
      "Epoch 1077/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.6012 - acc: 0.2116 - val_loss: 0.6819 - val_acc: 0.2037\n",
      "Epoch 1078/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5894 - acc: 0.2120 - val_loss: 0.6166 - val_acc: 0.2037\n",
      "Epoch 1079/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.8212 - acc: 0.2133 - val_loss: 0.6157 - val_acc: 0.2037\n",
      "Epoch 1080/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5088 - acc: 0.2137 - val_loss: 0.5744 - val_acc: 0.2037\n",
      "Epoch 1081/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4727 - acc: 0.2125 - val_loss: 0.6336 - val_acc: 0.2037\n",
      "Epoch 1082/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4837 - acc: 0.2125 - val_loss: 0.5759 - val_acc: 0.2037\n",
      "Epoch 1083/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4420 - acc: 0.2116 - val_loss: 0.5549 - val_acc: 0.2037\n",
      "Epoch 1084/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4680 - acc: 0.2125 - val_loss: 0.5652 - val_acc: 0.2037\n",
      "Epoch 1085/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.4652 - acc: 0.2129 - val_loss: 0.5648 - val_acc: 0.2037\n",
      "Epoch 1086/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4350 - acc: 0.2120 - val_loss: 0.5657 - val_acc: 0.2037\n",
      "Epoch 1087/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4380 - acc: 0.2120 - val_loss: 0.7647 - val_acc: 0.2000\n",
      "Epoch 1088/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4754 - acc: 0.2120 - val_loss: 0.5623 - val_acc: 0.2037\n",
      "Epoch 1089/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4405 - acc: 0.2125 - val_loss: 0.5674 - val_acc: 0.2037\n",
      "Epoch 1090/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4420 - acc: 0.2120 - val_loss: 0.5931 - val_acc: 0.2037\n",
      "Epoch 1091/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5000 - acc: 0.2116 - val_loss: 0.5734 - val_acc: 0.2037\n",
      "Epoch 1092/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4550 - acc: 0.2125 - val_loss: 0.6021 - val_acc: 0.2037\n",
      "Epoch 1093/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4535 - acc: 0.2125 - val_loss: 0.6465 - val_acc: 0.2037\n",
      "Epoch 1094/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4504 - acc: 0.2125 - val_loss: 0.5986 - val_acc: 0.2037\n",
      "Epoch 1095/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4339 - acc: 0.2120 - val_loss: 0.6043 - val_acc: 0.2037\n",
      "Epoch 1096/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4579 - acc: 0.2125 - val_loss: 0.6264 - val_acc: 0.2037\n",
      "Epoch 1097/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4701 - acc: 0.2129 - val_loss: 0.6075 - val_acc: 0.2037\n",
      "Epoch 1098/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4534 - acc: 0.2120 - val_loss: 0.5563 - val_acc: 0.2037\n",
      "Epoch 1099/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4499 - acc: 0.2133 - val_loss: 0.6357 - val_acc: 0.2037\n",
      "Epoch 1100/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5263 - acc: 0.2108 - val_loss: 0.6216 - val_acc: 0.2037\n",
      "Epoch 1101/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5531 - acc: 0.2120 - val_loss: 0.5795 - val_acc: 0.2037\n",
      "Epoch 1102/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.5164 - acc: 0.2129 - val_loss: 0.7103 - val_acc: 0.2037\n",
      "Epoch 1103/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.6231 - acc: 0.2125 - val_loss: 0.6273 - val_acc: 0.2037\n",
      "Epoch 1104/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4854 - acc: 0.2125 - val_loss: 0.5729 - val_acc: 0.2037\n",
      "Epoch 1105/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4589 - acc: 0.2125 - val_loss: 0.6141 - val_acc: 0.2037\n",
      "Epoch 1106/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4958 - acc: 0.2116 - val_loss: 0.6226 - val_acc: 0.2037\n",
      "Epoch 1107/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.4733 - acc: 0.2120 - val_loss: 0.6591 - val_acc: 0.2000\n",
      "Epoch 1108/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.4716 - acc: 0.2129 - val_loss: 0.7079 - val_acc: 0.2000\n",
      "Epoch 1109/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4584 - acc: 0.2125 - val_loss: 0.5683 - val_acc: 0.2037\n",
      "Epoch 1110/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4429 - acc: 0.2125 - val_loss: 0.9182 - val_acc: 0.2037\n",
      "Epoch 1111/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4741 - acc: 0.2116 - val_loss: 0.5639 - val_acc: 0.2037\n",
      "Epoch 1112/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4439 - acc: 0.2129 - val_loss: 0.7163 - val_acc: 0.2000\n",
      "Epoch 1113/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4392 - acc: 0.2125 - val_loss: 0.5572 - val_acc: 0.2037\n",
      "Epoch 1114/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4392 - acc: 0.2129 - val_loss: 0.6546 - val_acc: 0.2037\n",
      "Epoch 1115/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4693 - acc: 0.2116 - val_loss: 0.5625 - val_acc: 0.2037\n",
      "Epoch 1116/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4802 - acc: 0.2120 - val_loss: 0.5688 - val_acc: 0.2037\n",
      "Epoch 1117/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5222 - acc: 0.2133 - val_loss: 0.5825 - val_acc: 0.2037\n",
      "Epoch 1118/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4783 - acc: 0.2120 - val_loss: 0.5933 - val_acc: 0.2037\n",
      "Epoch 1119/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.6076 - acc: 0.2108 - val_loss: 0.6137 - val_acc: 0.2037\n",
      "Epoch 1120/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5078 - acc: 0.2120 - val_loss: 0.5838 - val_acc: 0.2037\n",
      "Epoch 1121/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4972 - acc: 0.2120 - val_loss: 0.5731 - val_acc: 0.2037\n",
      "Epoch 1122/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.4434 - acc: 0.2129 - val_loss: 0.5843 - val_acc: 0.2037\n",
      "Epoch 1123/10000\n",
      "76/76 [==============================] - 5s 71ms/step - loss: 0.4669 - acc: 0.2125 - val_loss: 0.5856 - val_acc: 0.2037\n",
      "Epoch 1124/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.4716 - acc: 0.2120 - val_loss: 0.7569 - val_acc: 0.2037\n",
      "Epoch 1125/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.5670 - acc: 0.2120 - val_loss: 0.5850 - val_acc: 0.2037\n",
      "Epoch 1126/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.4999 - acc: 0.2120 - val_loss: 0.6086 - val_acc: 0.2000\n",
      "Epoch 1127/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.5021 - acc: 0.2129 - val_loss: 0.6229 - val_acc: 0.2037\n",
      "Epoch 1128/10000\n",
      "76/76 [==============================] - 4s 46ms/step - loss: 0.6795 - acc: 0.2116 - val_loss: 0.6540 - val_acc: 0.2037\n",
      "Epoch 1129/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.6012 - acc: 0.2125 - val_loss: 0.8309 - val_acc: 0.2037\n",
      "Epoch 1130/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.7911 - acc: 0.2125 - val_loss: 0.7822 - val_acc: 0.2000\n",
      "Epoch 1131/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.5333 - acc: 0.2120 - val_loss: 0.5996 - val_acc: 0.2037\n",
      "Epoch 1132/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.5675 - acc: 0.2125 - val_loss: 0.5791 - val_acc: 0.2037\n",
      "Epoch 1133/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4634 - acc: 0.2125 - val_loss: 0.5805 - val_acc: 0.2037\n",
      "Epoch 1134/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.4488 - acc: 0.2125 - val_loss: 0.6633 - val_acc: 0.2037\n",
      "Epoch 1135/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.4901 - acc: 0.2129 - val_loss: 0.5557 - val_acc: 0.2037\n",
      "Epoch 1136/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.4661 - acc: 0.2120 - val_loss: 0.5614 - val_acc: 0.2037\n",
      "Epoch 1137/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4281 - acc: 0.2125 - val_loss: 0.5557 - val_acc: 0.2037\n",
      "Epoch 1138/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.4805 - acc: 0.2129 - val_loss: 0.5637 - val_acc: 0.2037\n",
      "Epoch 1139/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.4676 - acc: 0.2125 - val_loss: 0.5973 - val_acc: 0.2037\n",
      "Epoch 1140/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4346 - acc: 0.2125 - val_loss: 0.5709 - val_acc: 0.2037\n",
      "Epoch 1141/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4999 - acc: 0.2120 - val_loss: 0.5583 - val_acc: 0.2037\n",
      "Epoch 1142/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.4329 - acc: 0.2120 - val_loss: 0.5873 - val_acc: 0.2037\n",
      "Epoch 1143/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.4455 - acc: 0.2120 - val_loss: 0.6420 - val_acc: 0.2037\n",
      "Epoch 1144/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4645 - acc: 0.2125 - val_loss: 0.5714 - val_acc: 0.2037\n",
      "Epoch 1145/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4841 - acc: 0.2108 - val_loss: 0.5937 - val_acc: 0.2037\n",
      "Epoch 1146/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4362 - acc: 0.2125 - val_loss: 0.5661 - val_acc: 0.2037\n",
      "Epoch 1147/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5149 - acc: 0.2125 - val_loss: 0.5858 - val_acc: 0.2037\n",
      "Epoch 1148/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4572 - acc: 0.2125 - val_loss: 0.5927 - val_acc: 0.2037\n",
      "Epoch 1149/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.5031 - acc: 0.2116 - val_loss: 0.5707 - val_acc: 0.2037\n",
      "Epoch 1150/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.4398 - acc: 0.2116 - val_loss: 0.5647 - val_acc: 0.2037\n",
      "Epoch 1151/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.5057 - acc: 0.2120 - val_loss: 0.5635 - val_acc: 0.2037\n",
      "Epoch 1152/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4675 - acc: 0.2129 - val_loss: 0.6035 - val_acc: 0.2037\n",
      "Epoch 1153/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4486 - acc: 0.2125 - val_loss: 0.5617 - val_acc: 0.2037\n",
      "Epoch 1154/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4548 - acc: 0.2125 - val_loss: 0.5763 - val_acc: 0.2037\n",
      "Epoch 1155/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4390 - acc: 0.2120 - val_loss: 0.5716 - val_acc: 0.2037\n",
      "Epoch 1156/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4389 - acc: 0.2120 - val_loss: 0.6098 - val_acc: 0.2037\n",
      "Epoch 1157/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4400 - acc: 0.2125 - val_loss: 0.8530 - val_acc: 0.2000\n",
      "Epoch 1158/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5142 - acc: 0.2116 - val_loss: 0.5653 - val_acc: 0.2037\n",
      "Epoch 1159/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4869 - acc: 0.2125 - val_loss: 0.7770 - val_acc: 0.2000\n",
      "Epoch 1160/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5750 - acc: 0.2112 - val_loss: 0.5551 - val_acc: 0.2037\n",
      "Epoch 1161/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.5362 - acc: 0.2120 - val_loss: 0.7348 - val_acc: 0.2000\n",
      "Epoch 1162/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.4432 - acc: 0.2116 - val_loss: 0.5565 - val_acc: 0.2037\n",
      "Epoch 1163/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4621 - acc: 0.2120 - val_loss: 0.5581 - val_acc: 0.2037\n",
      "Epoch 1164/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4321 - acc: 0.2125 - val_loss: 0.5574 - val_acc: 0.2037\n",
      "Epoch 1165/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4521 - acc: 0.2129 - val_loss: 0.6137 - val_acc: 0.2037\n",
      "Epoch 1166/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4459 - acc: 0.2116 - val_loss: 0.5615 - val_acc: 0.2037\n",
      "Epoch 1167/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4309 - acc: 0.2125 - val_loss: 0.5528 - val_acc: 0.2037\n",
      "Epoch 1168/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4520 - acc: 0.2133 - val_loss: 1.0115 - val_acc: 0.2000\n",
      "Epoch 1169/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4875 - acc: 0.2116 - val_loss: 0.6128 - val_acc: 0.2000\n",
      "Epoch 1170/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4253 - acc: 0.2116 - val_loss: 0.7092 - val_acc: 0.2037\n",
      "Epoch 1171/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4760 - acc: 0.2125 - val_loss: 0.6686 - val_acc: 0.2000\n",
      "Epoch 1172/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4804 - acc: 0.2120 - val_loss: 0.5648 - val_acc: 0.2037\n",
      "Epoch 1173/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4672 - acc: 0.2120 - val_loss: 0.6947 - val_acc: 0.2000\n",
      "Epoch 1174/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4342 - acc: 0.2120 - val_loss: 0.5637 - val_acc: 0.2037\n",
      "Epoch 1175/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4598 - acc: 0.2116 - val_loss: 0.6476 - val_acc: 0.2037\n",
      "Epoch 1176/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.6063 - acc: 0.2116 - val_loss: 0.6290 - val_acc: 0.2037\n",
      "Epoch 1177/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 1.4393 - acc: 0.2104 - val_loss: 0.7098 - val_acc: 0.2037\n",
      "Epoch 1178/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5164 - acc: 0.2125 - val_loss: 0.5688 - val_acc: 0.2037\n",
      "Epoch 1179/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5305 - acc: 0.2125 - val_loss: 0.5454 - val_acc: 0.2037\n",
      "Epoch 1180/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5039 - acc: 0.2116 - val_loss: 0.5355 - val_acc: 0.2037\n",
      "Epoch 1181/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4458 - acc: 0.2120 - val_loss: 0.5405 - val_acc: 0.2037\n",
      "Epoch 1182/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4322 - acc: 0.2125 - val_loss: 0.5457 - val_acc: 0.2037\n",
      "Epoch 1183/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4412 - acc: 0.2125 - val_loss: 0.5989 - val_acc: 0.2037\n",
      "Epoch 1184/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4347 - acc: 0.2129 - val_loss: 0.5421 - val_acc: 0.2037\n",
      "Epoch 1185/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4605 - acc: 0.2125 - val_loss: 0.7005 - val_acc: 0.2000\n",
      "Epoch 1186/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4358 - acc: 0.2129 - val_loss: 0.5687 - val_acc: 0.2037\n",
      "Epoch 1187/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4614 - acc: 0.2120 - val_loss: 0.5750 - val_acc: 0.2037\n",
      "Epoch 1188/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4617 - acc: 0.2116 - val_loss: 0.7476 - val_acc: 0.2037\n",
      "Epoch 1189/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4421 - acc: 0.2125 - val_loss: 0.5561 - val_acc: 0.2037\n",
      "Epoch 1190/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4944 - acc: 0.2129 - val_loss: 0.5647 - val_acc: 0.2037\n",
      "Epoch 1191/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5910 - acc: 0.2129 - val_loss: 0.6378 - val_acc: 0.2037\n",
      "Epoch 1192/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4591 - acc: 0.2120 - val_loss: 0.5681 - val_acc: 0.2037\n",
      "Epoch 1193/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4270 - acc: 0.2125 - val_loss: 0.5537 - val_acc: 0.2037\n",
      "Epoch 1194/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.4298 - acc: 0.2129 - val_loss: 0.6178 - val_acc: 0.2000\n",
      "Epoch 1195/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.4310 - acc: 0.2125 - val_loss: 0.5468 - val_acc: 0.2037\n",
      "Epoch 1196/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.4689 - acc: 0.2120 - val_loss: 0.5594 - val_acc: 0.2037\n",
      "Epoch 1197/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4423 - acc: 0.2120 - val_loss: 0.5831 - val_acc: 0.2037\n",
      "Epoch 1198/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4667 - acc: 0.2129 - val_loss: 0.6857 - val_acc: 0.2000\n",
      "Epoch 1199/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4528 - acc: 0.2120 - val_loss: 0.5688 - val_acc: 0.2037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1200/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.4644 - acc: 0.2120 - val_loss: 0.6479 - val_acc: 0.2000\n",
      "Epoch 1201/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4781 - acc: 0.2125 - val_loss: 0.5608 - val_acc: 0.2037\n",
      "Epoch 1202/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4483 - acc: 0.2129 - val_loss: 0.5621 - val_acc: 0.2037\n",
      "Epoch 1203/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4874 - acc: 0.2129 - val_loss: 0.5942 - val_acc: 0.2037\n",
      "Epoch 1204/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.9143 - acc: 0.2116 - val_loss: 0.7643 - val_acc: 0.2037\n",
      "Epoch 1205/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.6052 - acc: 0.2125 - val_loss: 1.0410 - val_acc: 0.2000\n",
      "Epoch 1206/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.6821 - acc: 0.2112 - val_loss: 0.5521 - val_acc: 0.2037\n",
      "Epoch 1207/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4908 - acc: 0.2125 - val_loss: 0.6145 - val_acc: 0.2037\n",
      "Epoch 1208/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4573 - acc: 0.2125 - val_loss: 0.5675 - val_acc: 0.2037\n",
      "Epoch 1209/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4382 - acc: 0.2125 - val_loss: 0.5898 - val_acc: 0.2037\n",
      "Epoch 1210/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4254 - acc: 0.2133 - val_loss: 0.5654 - val_acc: 0.2037\n",
      "Epoch 1211/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.4679 - acc: 0.2129 - val_loss: 0.5788 - val_acc: 0.2037\n",
      "Epoch 1212/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.4681 - acc: 0.2116 - val_loss: 0.5934 - val_acc: 0.2037\n",
      "Epoch 1213/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.4453 - acc: 0.2129 - val_loss: 0.5612 - val_acc: 0.2037\n",
      "Epoch 1214/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.4627 - acc: 0.2125 - val_loss: 0.5568 - val_acc: 0.2037\n",
      "Epoch 1215/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.4449 - acc: 0.2125 - val_loss: 0.5440 - val_acc: 0.2037\n",
      "Epoch 1216/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4156 - acc: 0.2120 - val_loss: 0.5482 - val_acc: 0.2037\n",
      "Epoch 1217/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4575 - acc: 0.2120 - val_loss: 0.5706 - val_acc: 0.2037\n",
      "Epoch 1218/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4509 - acc: 0.2125 - val_loss: 0.6063 - val_acc: 0.2037\n",
      "Epoch 1219/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4472 - acc: 0.2125 - val_loss: 0.6466 - val_acc: 0.2037\n",
      "Epoch 1220/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4597 - acc: 0.2133 - val_loss: 0.5746 - val_acc: 0.2037\n",
      "Epoch 1221/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4241 - acc: 0.2125 - val_loss: 0.5645 - val_acc: 0.2037\n",
      "Epoch 1222/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4547 - acc: 0.2116 - val_loss: 0.6119 - val_acc: 0.2000\n",
      "Epoch 1223/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4467 - acc: 0.2129 - val_loss: 0.6106 - val_acc: 0.2000\n",
      "Epoch 1224/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4651 - acc: 0.2125 - val_loss: 0.6484 - val_acc: 0.2037\n",
      "Epoch 1225/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4326 - acc: 0.2125 - val_loss: 0.6034 - val_acc: 0.2037\n",
      "Epoch 1226/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4301 - acc: 0.2125 - val_loss: 0.7288 - val_acc: 0.2000\n",
      "Epoch 1227/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4780 - acc: 0.2129 - val_loss: 0.7162 - val_acc: 0.2000\n",
      "Epoch 1228/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5114 - acc: 0.2120 - val_loss: 0.6616 - val_acc: 0.2000\n",
      "Epoch 1229/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5459 - acc: 0.2108 - val_loss: 0.6058 - val_acc: 0.2037\n",
      "Epoch 1230/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.6194 - acc: 0.2125 - val_loss: 0.6180 - val_acc: 0.2037\n",
      "Epoch 1231/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4952 - acc: 0.2133 - val_loss: 0.6261 - val_acc: 0.2000\n",
      "Epoch 1232/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5818 - acc: 0.2125 - val_loss: 0.8812 - val_acc: 0.2000\n",
      "Epoch 1233/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4515 - acc: 0.2120 - val_loss: 0.5638 - val_acc: 0.2037\n",
      "Epoch 1234/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4568 - acc: 0.2120 - val_loss: 0.5626 - val_acc: 0.2037\n",
      "Epoch 1235/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4146 - acc: 0.2125 - val_loss: 0.5874 - val_acc: 0.2037\n",
      "Epoch 1236/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4423 - acc: 0.2120 - val_loss: 0.6371 - val_acc: 0.2037\n",
      "Epoch 1237/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4462 - acc: 0.2125 - val_loss: 0.6252 - val_acc: 0.2037\n",
      "Epoch 1238/10000\n",
      "76/76 [==============================] - 3s 46ms/step - loss: 0.4489 - acc: 0.2116 - val_loss: 0.5627 - val_acc: 0.2037\n",
      "Epoch 1239/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4245 - acc: 0.2120 - val_loss: 0.5777 - val_acc: 0.2037\n",
      "Epoch 1240/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4446 - acc: 0.2125 - val_loss: 0.5514 - val_acc: 0.2037\n",
      "Epoch 1241/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4482 - acc: 0.2125 - val_loss: 0.5856 - val_acc: 0.2037\n",
      "Epoch 1242/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4355 - acc: 0.2120 - val_loss: 0.6099 - val_acc: 0.2037\n",
      "Epoch 1243/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4421 - acc: 0.2120 - val_loss: 0.6113 - val_acc: 0.2037\n",
      "Epoch 1244/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.4718 - acc: 0.2120 - val_loss: 0.5967 - val_acc: 0.2037\n",
      "Epoch 1245/10000\n",
      "76/76 [==============================] - 4s 46ms/step - loss: 0.5370 - acc: 0.2116 - val_loss: 0.6336 - val_acc: 0.2037\n",
      "Epoch 1246/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.7785 - acc: 0.2112 - val_loss: 0.6445 - val_acc: 0.2037\n",
      "Epoch 1247/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.6925 - acc: 0.2108 - val_loss: 0.6280 - val_acc: 0.2037\n",
      "Epoch 1248/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4918 - acc: 0.2125 - val_loss: 0.5936 - val_acc: 0.2037\n",
      "Epoch 1249/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.5017 - acc: 0.2125 - val_loss: 0.5415 - val_acc: 0.2037\n",
      "Epoch 1250/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4892 - acc: 0.2129 - val_loss: 0.5740 - val_acc: 0.2037\n",
      "Epoch 1251/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4566 - acc: 0.2125 - val_loss: 0.5640 - val_acc: 0.2037\n",
      "Epoch 1252/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4476 - acc: 0.2116 - val_loss: 0.5610 - val_acc: 0.2037\n",
      "Epoch 1253/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4281 - acc: 0.2116 - val_loss: 0.5607 - val_acc: 0.2037\n",
      "Epoch 1254/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4285 - acc: 0.2125 - val_loss: 0.5409 - val_acc: 0.2037\n",
      "Epoch 1255/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4298 - acc: 0.2120 - val_loss: 0.5731 - val_acc: 0.2037\n",
      "Epoch 1256/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4431 - acc: 0.2120 - val_loss: 0.5443 - val_acc: 0.2037\n",
      "Epoch 1257/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4417 - acc: 0.2125 - val_loss: 0.5518 - val_acc: 0.2037\n",
      "Epoch 1258/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4630 - acc: 0.2116 - val_loss: 0.6129 - val_acc: 0.2000\n",
      "Epoch 1259/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.4721 - acc: 0.2120 - val_loss: 0.6538 - val_acc: 0.2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1260/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4328 - acc: 0.2120 - val_loss: 0.6779 - val_acc: 0.2000\n",
      "Epoch 1261/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4655 - acc: 0.2120 - val_loss: 0.5914 - val_acc: 0.2037\n",
      "Epoch 1262/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4699 - acc: 0.2120 - val_loss: 0.6904 - val_acc: 0.2037\n",
      "Epoch 1263/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4438 - acc: 0.2120 - val_loss: 0.6835 - val_acc: 0.2000\n",
      "Epoch 1264/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4484 - acc: 0.2125 - val_loss: 0.5822 - val_acc: 0.2037\n",
      "Epoch 1265/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4575 - acc: 0.2112 - val_loss: 0.5650 - val_acc: 0.2037\n",
      "Epoch 1266/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4586 - acc: 0.2129 - val_loss: 0.5642 - val_acc: 0.2037\n",
      "Epoch 1267/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4323 - acc: 0.2120 - val_loss: 0.5600 - val_acc: 0.2037\n",
      "Epoch 1268/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4467 - acc: 0.2125 - val_loss: 0.7686 - val_acc: 0.2037\n",
      "Epoch 1269/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4348 - acc: 0.2129 - val_loss: 0.5501 - val_acc: 0.2037\n",
      "Epoch 1270/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4798 - acc: 0.2112 - val_loss: 0.6513 - val_acc: 0.2037\n",
      "Epoch 1271/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4663 - acc: 0.2125 - val_loss: 0.5639 - val_acc: 0.2037\n",
      "Epoch 1272/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.4746 - acc: 0.2120 - val_loss: 0.5963 - val_acc: 0.2037\n",
      "Epoch 1273/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.7225 - acc: 0.2120 - val_loss: 0.6839 - val_acc: 0.2037\n",
      "Epoch 1274/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5207 - acc: 0.2112 - val_loss: 0.6124 - val_acc: 0.2037\n",
      "Epoch 1275/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4650 - acc: 0.2125 - val_loss: 0.5675 - val_acc: 0.2037\n",
      "Epoch 1276/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4938 - acc: 0.2120 - val_loss: 0.7153 - val_acc: 0.2000\n",
      "Epoch 1277/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4686 - acc: 0.2116 - val_loss: 0.5574 - val_acc: 0.2037\n",
      "Epoch 1278/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4458 - acc: 0.2120 - val_loss: 0.5569 - val_acc: 0.2037\n",
      "Epoch 1279/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.4290 - acc: 0.2120 - val_loss: 0.5527 - val_acc: 0.2037\n",
      "Epoch 1280/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4284 - acc: 0.2129 - val_loss: 0.6044 - val_acc: 0.2037\n",
      "Epoch 1281/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4582 - acc: 0.2116 - val_loss: 0.8654 - val_acc: 0.2037\n",
      "Epoch 1282/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4398 - acc: 0.2129 - val_loss: 0.5591 - val_acc: 0.2037\n",
      "Epoch 1283/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4284 - acc: 0.2125 - val_loss: 0.5931 - val_acc: 0.2037\n",
      "Epoch 1284/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4464 - acc: 0.2116 - val_loss: 0.5513 - val_acc: 0.2037\n",
      "Epoch 1285/10000\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 0.4322 - acc: 0.2125 - val_loss: 0.5473 - val_acc: 0.2037\n",
      "Epoch 1286/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.4331 - acc: 0.2120 - val_loss: 0.5477 - val_acc: 0.2037\n",
      "Epoch 1287/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.4415 - acc: 0.2116 - val_loss: 0.6190 - val_acc: 0.2000\n",
      "Epoch 1288/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4399 - acc: 0.2125 - val_loss: 0.9120 - val_acc: 0.2000\n",
      "Epoch 1289/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.4737 - acc: 0.2120 - val_loss: 0.7057 - val_acc: 0.2037\n",
      "Epoch 1290/10000\n",
      "76/76 [==============================] - 3s 46ms/step - loss: 0.4951 - acc: 0.2125 - val_loss: 0.6911 - val_acc: 0.2037\n",
      "Epoch 1291/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4676 - acc: 0.2116 - val_loss: 0.5557 - val_acc: 0.2037\n",
      "Epoch 1292/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4309 - acc: 0.2120 - val_loss: 0.5718 - val_acc: 0.2037\n",
      "Epoch 1293/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.5535 - acc: 0.2125 - val_loss: 0.5626 - val_acc: 0.2037\n",
      "Epoch 1294/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4447 - acc: 0.2120 - val_loss: 0.5831 - val_acc: 0.2037\n",
      "Epoch 1295/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4496 - acc: 0.2120 - val_loss: 0.5582 - val_acc: 0.2037\n",
      "Epoch 1296/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4803 - acc: 0.2120 - val_loss: 0.5659 - val_acc: 0.2037\n",
      "Epoch 1297/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.7444 - acc: 0.2116 - val_loss: 0.7016 - val_acc: 0.2037\n",
      "Epoch 1298/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.5412 - acc: 0.2129 - val_loss: 0.6463 - val_acc: 0.2037\n",
      "Epoch 1299/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.5443 - acc: 0.2112 - val_loss: 0.7236 - val_acc: 0.2000\n",
      "Epoch 1300/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4489 - acc: 0.2125 - val_loss: 0.5541 - val_acc: 0.2037\n",
      "Epoch 1301/10000\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 0.4737 - acc: 0.2129 - val_loss: 0.5837 - val_acc: 0.2037\n",
      "Epoch 1302/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.4480 - acc: 0.2125 - val_loss: 0.6345 - val_acc: 0.2000\n",
      "Epoch 1303/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4312 - acc: 0.2125 - val_loss: 0.5807 - val_acc: 0.2037\n",
      "Epoch 1304/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4370 - acc: 0.2116 - val_loss: 0.5544 - val_acc: 0.2037\n",
      "Epoch 1305/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.4309 - acc: 0.2125 - val_loss: 0.5448 - val_acc: 0.2037\n",
      "Epoch 1306/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.4676 - acc: 0.2120 - val_loss: 0.5428 - val_acc: 0.2037\n",
      "Epoch 1307/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.5045 - acc: 0.2120 - val_loss: 0.5740 - val_acc: 0.2037\n",
      "Epoch 1308/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.7532 - acc: 0.2112 - val_loss: 0.5440 - val_acc: 0.2037\n",
      "Epoch 1309/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5131 - acc: 0.2120 - val_loss: 0.6045 - val_acc: 0.2037\n",
      "Epoch 1310/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5305 - acc: 0.2108 - val_loss: 0.5820 - val_acc: 0.2037\n",
      "Epoch 1311/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4386 - acc: 0.2120 - val_loss: 0.6808 - val_acc: 0.2000\n",
      "Epoch 1312/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4184 - acc: 0.2125 - val_loss: 0.6091 - val_acc: 0.2037\n",
      "Epoch 1313/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.4338 - acc: 0.2120 - val_loss: 0.5469 - val_acc: 0.2037\n",
      "Epoch 1314/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.4638 - acc: 0.2120 - val_loss: 0.5395 - val_acc: 0.2037\n",
      "Epoch 1315/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4490 - acc: 0.2125 - val_loss: 0.5894 - val_acc: 0.2037\n",
      "Epoch 1316/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4268 - acc: 0.2120 - val_loss: 0.5472 - val_acc: 0.2037\n",
      "Epoch 1317/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.4453 - acc: 0.2125 - val_loss: 0.5491 - val_acc: 0.2037\n",
      "Epoch 1318/10000\n",
      "76/76 [==============================] - 4s 46ms/step - loss: 0.4332 - acc: 0.2120 - val_loss: 0.5888 - val_acc: 0.2037\n",
      "Epoch 1319/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4281 - acc: 0.2125 - val_loss: 0.7800 - val_acc: 0.2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1320/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4433 - acc: 0.2125 - val_loss: 0.5533 - val_acc: 0.2037\n",
      "Epoch 1321/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.4659 - acc: 0.2125 - val_loss: 0.6402 - val_acc: 0.2037\n",
      "Epoch 1322/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.4391 - acc: 0.2129 - val_loss: 0.5925 - val_acc: 0.2037\n",
      "Epoch 1323/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4630 - acc: 0.2120 - val_loss: 0.5647 - val_acc: 0.2037\n",
      "Epoch 1324/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4593 - acc: 0.2129 - val_loss: 0.5829 - val_acc: 0.2037\n",
      "Epoch 1325/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.5084 - acc: 0.2129 - val_loss: 0.5773 - val_acc: 0.2037\n",
      "Epoch 1326/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4670 - acc: 0.2125 - val_loss: 0.5316 - val_acc: 0.2037\n",
      "Epoch 1327/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5108 - acc: 0.2120 - val_loss: 0.7810 - val_acc: 0.2000\n",
      "Epoch 1328/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4725 - acc: 0.2120 - val_loss: 0.5698 - val_acc: 0.2037\n",
      "Epoch 1329/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5026 - acc: 0.2125 - val_loss: 0.5850 - val_acc: 0.2037\n",
      "Epoch 1330/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4810 - acc: 0.2125 - val_loss: 0.5888 - val_acc: 0.2037\n",
      "Epoch 1331/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5010 - acc: 0.2120 - val_loss: 0.6371 - val_acc: 0.2037\n",
      "Epoch 1332/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.8545 - acc: 0.2120 - val_loss: 1.0680 - val_acc: 0.2000\n",
      "Epoch 1333/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.5607 - acc: 0.2129 - val_loss: 0.6321 - val_acc: 0.2000\n",
      "Epoch 1334/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5304 - acc: 0.2120 - val_loss: 0.6534 - val_acc: 0.2000\n",
      "Epoch 1335/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5403 - acc: 0.2125 - val_loss: 0.5526 - val_acc: 0.2037\n",
      "Epoch 1336/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5128 - acc: 0.2125 - val_loss: 0.5904 - val_acc: 0.2037\n",
      "Epoch 1337/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4534 - acc: 0.2129 - val_loss: 0.6148 - val_acc: 0.2037\n",
      "Epoch 1338/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4372 - acc: 0.2125 - val_loss: 0.5954 - val_acc: 0.2000\n",
      "Epoch 1339/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4311 - acc: 0.2120 - val_loss: 0.5965 - val_acc: 0.2037\n",
      "Epoch 1340/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4482 - acc: 0.2125 - val_loss: 0.6103 - val_acc: 0.2037\n",
      "Epoch 1341/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4958 - acc: 0.2133 - val_loss: 0.5983 - val_acc: 0.2037\n",
      "Epoch 1342/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4437 - acc: 0.2129 - val_loss: 0.5919 - val_acc: 0.2037\n",
      "Epoch 1343/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4387 - acc: 0.2120 - val_loss: 0.5703 - val_acc: 0.2037\n",
      "Epoch 1344/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4656 - acc: 0.2120 - val_loss: 0.5788 - val_acc: 0.2037\n",
      "Epoch 1345/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.4300 - acc: 0.2125 - val_loss: 0.5727 - val_acc: 0.2037\n",
      "Epoch 1346/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4631 - acc: 0.2129 - val_loss: 0.5749 - val_acc: 0.2037\n",
      "Epoch 1347/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4445 - acc: 0.2125 - val_loss: 0.5552 - val_acc: 0.2037\n",
      "Epoch 1348/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4447 - acc: 0.2116 - val_loss: 0.5929 - val_acc: 0.2037\n",
      "Epoch 1349/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4548 - acc: 0.2120 - val_loss: 0.5448 - val_acc: 0.2037\n",
      "Epoch 1350/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4572 - acc: 0.2129 - val_loss: 0.5419 - val_acc: 0.2037\n",
      "Epoch 1351/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4553 - acc: 0.2116 - val_loss: 0.5700 - val_acc: 0.2037\n",
      "Epoch 1352/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4641 - acc: 0.2120 - val_loss: 0.6609 - val_acc: 0.2037\n",
      "Epoch 1353/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4325 - acc: 0.2120 - val_loss: 0.5639 - val_acc: 0.2037\n",
      "Epoch 1354/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.5981 - acc: 0.2125 - val_loss: 0.6041 - val_acc: 0.2037\n",
      "Epoch 1355/10000\n",
      "76/76 [==============================] - 5s 61ms/step - loss: 0.4538 - acc: 0.2112 - val_loss: 0.5961 - val_acc: 0.2037\n",
      "Epoch 1356/10000\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 0.4391 - acc: 0.2129 - val_loss: 0.5399 - val_acc: 0.2037\n",
      "Epoch 1357/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.4605 - acc: 0.2129 - val_loss: 0.6771 - val_acc: 0.2037\n",
      "Epoch 1358/10000\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 0.5031 - acc: 0.2133 - val_loss: 0.5394 - val_acc: 0.2037\n",
      "Epoch 1359/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.4434 - acc: 0.2125 - val_loss: 0.5513 - val_acc: 0.2037\n",
      "Epoch 1360/10000\n",
      "76/76 [==============================] - 4s 56ms/step - loss: 0.4118 - acc: 0.2125 - val_loss: 0.5473 - val_acc: 0.2037\n",
      "Epoch 1361/10000\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 0.4291 - acc: 0.2125 - val_loss: 0.5593 - val_acc: 0.2037\n",
      "Epoch 1362/10000\n",
      "76/76 [==============================] - 4s 46ms/step - loss: 0.4134 - acc: 0.2120 - val_loss: 0.5801 - val_acc: 0.2037\n",
      "Epoch 1363/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.4230 - acc: 0.2116 - val_loss: 0.6295 - val_acc: 0.2037\n",
      "Epoch 1364/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4856 - acc: 0.2129 - val_loss: 0.6762 - val_acc: 0.2000\n",
      "Epoch 1365/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4480 - acc: 0.2120 - val_loss: 0.6147 - val_acc: 0.2000\n",
      "Epoch 1366/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4212 - acc: 0.2125 - val_loss: 0.5378 - val_acc: 0.2037\n",
      "Epoch 1367/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4366 - acc: 0.2116 - val_loss: 0.6257 - val_acc: 0.2037\n",
      "Epoch 1368/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.5647 - acc: 0.2112 - val_loss: 0.6082 - val_acc: 0.2037\n",
      "Epoch 1369/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.4516 - acc: 0.2116 - val_loss: 0.5952 - val_acc: 0.2037\n",
      "Epoch 1370/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.5101 - acc: 0.2120 - val_loss: 0.6128 - val_acc: 0.2000\n",
      "Epoch 1371/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.4565 - acc: 0.2120 - val_loss: 0.5623 - val_acc: 0.2037\n",
      "Epoch 1372/10000\n",
      "76/76 [==============================] - 5s 69ms/step - loss: 0.4217 - acc: 0.2120 - val_loss: 0.5441 - val_acc: 0.2037\n",
      "Epoch 1373/10000\n",
      "76/76 [==============================] - 5s 61ms/step - loss: 0.4377 - acc: 0.2125 - val_loss: 0.6441 - val_acc: 0.2000\n",
      "Epoch 1374/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5374 - acc: 0.2116 - val_loss: 0.7074 - val_acc: 0.2000\n",
      "Epoch 1375/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4636 - acc: 0.2125 - val_loss: 0.5478 - val_acc: 0.2037\n",
      "Epoch 1376/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4569 - acc: 0.2125 - val_loss: 0.5474 - val_acc: 0.2037\n",
      "Epoch 1377/10000\n",
      "76/76 [==============================] - 4s 57ms/step - loss: 0.4399 - acc: 0.2112 - val_loss: 0.5640 - val_acc: 0.2037\n",
      "Epoch 1378/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.4457 - acc: 0.2116 - val_loss: 0.6085 - val_acc: 0.2037\n",
      "Epoch 1379/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.4833 - acc: 0.2120 - val_loss: 0.6303 - val_acc: 0.2037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1380/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.5454 - acc: 0.2120 - val_loss: 0.5296 - val_acc: 0.2037\n",
      "Epoch 1381/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4437 - acc: 0.2120 - val_loss: 0.5730 - val_acc: 0.2037\n",
      "Epoch 1382/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.6126 - acc: 0.2125 - val_loss: 0.7178 - val_acc: 0.2000\n",
      "Epoch 1383/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.4604 - acc: 0.2129 - val_loss: 0.5562 - val_acc: 0.2037\n",
      "Epoch 1384/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.4311 - acc: 0.2125 - val_loss: 0.5866 - val_acc: 0.2037\n",
      "Epoch 1385/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.5347 - acc: 0.2120 - val_loss: 0.8657 - val_acc: 0.2037\n",
      "Epoch 1386/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5711 - acc: 0.2129 - val_loss: 0.5493 - val_acc: 0.2037\n",
      "Epoch 1387/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.5451 - acc: 0.2120 - val_loss: 0.5681 - val_acc: 0.2037\n",
      "Epoch 1388/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4965 - acc: 0.2133 - val_loss: 0.5318 - val_acc: 0.2037\n",
      "Epoch 1389/10000\n",
      "76/76 [==============================] - 5s 65ms/step - loss: 0.4425 - acc: 0.2125 - val_loss: 0.6525 - val_acc: 0.2000\n",
      "Epoch 1390/10000\n",
      "76/76 [==============================] - 5s 67ms/step - loss: 0.4530 - acc: 0.2125 - val_loss: 0.5315 - val_acc: 0.2037\n",
      "Epoch 1391/10000\n",
      "76/76 [==============================] - 5s 64ms/step - loss: 0.4293 - acc: 0.2125 - val_loss: 0.5782 - val_acc: 0.2037\n",
      "Epoch 1392/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4549 - acc: 0.2120 - val_loss: 0.5349 - val_acc: 0.2037\n",
      "Epoch 1393/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4564 - acc: 0.2125 - val_loss: 0.5474 - val_acc: 0.2037\n",
      "Epoch 1394/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4346 - acc: 0.2120 - val_loss: 0.5681 - val_acc: 0.2037\n",
      "Epoch 1395/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4566 - acc: 0.2125 - val_loss: 0.6569 - val_acc: 0.2000\n",
      "Epoch 1396/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4930 - acc: 0.2120 - val_loss: 0.5759 - val_acc: 0.2037\n",
      "Epoch 1397/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4895 - acc: 0.2125 - val_loss: 0.5845 - val_acc: 0.2037\n",
      "Epoch 1398/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4272 - acc: 0.2137 - val_loss: 0.5470 - val_acc: 0.2037\n",
      "Epoch 1399/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4115 - acc: 0.2125 - val_loss: 0.5514 - val_acc: 0.2037\n",
      "Epoch 1400/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4138 - acc: 0.2125 - val_loss: 0.5443 - val_acc: 0.2037\n",
      "Epoch 1401/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4083 - acc: 0.2120 - val_loss: 0.5619 - val_acc: 0.2037\n",
      "Epoch 1402/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4382 - acc: 0.2116 - val_loss: 0.5692 - val_acc: 0.2037\n",
      "Epoch 1403/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4888 - acc: 0.2120 - val_loss: 0.6537 - val_acc: 0.2000\n",
      "Epoch 1404/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4275 - acc: 0.2125 - val_loss: 0.5621 - val_acc: 0.2037\n",
      "Epoch 1405/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4644 - acc: 0.2125 - val_loss: 0.5995 - val_acc: 0.2037\n",
      "Epoch 1406/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4456 - acc: 0.2125 - val_loss: 0.5788 - val_acc: 0.2037\n",
      "Epoch 1407/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4367 - acc: 0.2125 - val_loss: 0.6156 - val_acc: 0.2000\n",
      "Epoch 1408/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4387 - acc: 0.2120 - val_loss: 0.5843 - val_acc: 0.2037\n",
      "Epoch 1409/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4461 - acc: 0.2125 - val_loss: 0.5395 - val_acc: 0.2037\n",
      "Epoch 1410/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4652 - acc: 0.2129 - val_loss: 0.6430 - val_acc: 0.2037\n",
      "Epoch 1411/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4793 - acc: 0.2120 - val_loss: 0.5886 - val_acc: 0.2037\n",
      "Epoch 1412/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5676 - acc: 0.2129 - val_loss: 0.5681 - val_acc: 0.2037\n",
      "Epoch 1413/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4590 - acc: 0.2120 - val_loss: 0.6612 - val_acc: 0.2037\n",
      "Epoch 1414/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4506 - acc: 0.2116 - val_loss: 0.5655 - val_acc: 0.2037\n",
      "Epoch 1415/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4277 - acc: 0.2129 - val_loss: 0.5416 - val_acc: 0.2037\n",
      "Epoch 1416/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5531 - acc: 0.2112 - val_loss: 0.6138 - val_acc: 0.2037\n",
      "Epoch 1417/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5377 - acc: 0.2108 - val_loss: 0.6966 - val_acc: 0.2000\n",
      "Epoch 1418/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.6694 - acc: 0.2112 - val_loss: 0.5929 - val_acc: 0.2037\n",
      "Epoch 1419/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5184 - acc: 0.2120 - val_loss: 0.5279 - val_acc: 0.2037\n",
      "Epoch 1420/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5126 - acc: 0.2116 - val_loss: 0.5560 - val_acc: 0.2037\n",
      "Epoch 1421/10000\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 0.4318 - acc: 0.2125 - val_loss: 0.5544 - val_acc: 0.2037\n",
      "Epoch 1422/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.4413 - acc: 0.2125 - val_loss: 0.5396 - val_acc: 0.2037\n",
      "Epoch 1423/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4201 - acc: 0.2116 - val_loss: 0.5482 - val_acc: 0.2037\n",
      "Epoch 1424/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.4170 - acc: 0.2120 - val_loss: 0.5458 - val_acc: 0.2037\n",
      "Epoch 1425/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.4247 - acc: 0.2129 - val_loss: 0.6271 - val_acc: 0.2000\n",
      "Epoch 1426/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4370 - acc: 0.2125 - val_loss: 0.5434 - val_acc: 0.2037\n",
      "Epoch 1427/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4333 - acc: 0.2125 - val_loss: 0.5496 - val_acc: 0.2037\n",
      "Epoch 1428/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4561 - acc: 0.2116 - val_loss: 0.5975 - val_acc: 0.2000\n",
      "Epoch 1429/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4451 - acc: 0.2120 - val_loss: 0.5770 - val_acc: 0.2037\n",
      "Epoch 1430/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4692 - acc: 0.2112 - val_loss: 0.5882 - val_acc: 0.2037\n",
      "Epoch 1431/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4774 - acc: 0.2125 - val_loss: 0.6709 - val_acc: 0.2000\n",
      "Epoch 1432/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4687 - acc: 0.2120 - val_loss: 0.5580 - val_acc: 0.2037\n",
      "Epoch 1433/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5387 - acc: 0.2112 - val_loss: 0.5985 - val_acc: 0.2000\n",
      "Epoch 1434/10000\n",
      "76/76 [==============================] - 5s 64ms/step - loss: 0.4576 - acc: 0.2125 - val_loss: 0.5405 - val_acc: 0.2037\n",
      "Epoch 1435/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.4229 - acc: 0.2129 - val_loss: 0.5664 - val_acc: 0.2037\n",
      "Epoch 1436/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4369 - acc: 0.2116 - val_loss: 0.5643 - val_acc: 0.2037\n",
      "Epoch 1437/10000\n",
      "76/76 [==============================] - 4s 57ms/step - loss: 0.4216 - acc: 0.2116 - val_loss: 0.5482 - val_acc: 0.2037\n",
      "Epoch 1438/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4213 - acc: 0.2125 - val_loss: 0.6670 - val_acc: 0.2000\n",
      "Epoch 1439/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.4355 - acc: 0.2125 - val_loss: 0.5956 - val_acc: 0.2037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1440/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.4426 - acc: 0.2129 - val_loss: 0.5783 - val_acc: 0.2037\n",
      "Epoch 1441/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.4401 - acc: 0.2116 - val_loss: 0.5800 - val_acc: 0.2037\n",
      "Epoch 1442/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4142 - acc: 0.2125 - val_loss: 0.5650 - val_acc: 0.2037\n",
      "Epoch 1443/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4582 - acc: 0.2129 - val_loss: 1.1713 - val_acc: 0.1963\n",
      "Epoch 1444/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.5060 - acc: 0.2112 - val_loss: 0.5578 - val_acc: 0.2037\n",
      "Epoch 1445/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4549 - acc: 0.2125 - val_loss: 0.6421 - val_acc: 0.2000\n",
      "Epoch 1446/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.6886 - acc: 0.2100 - val_loss: 0.5517 - val_acc: 0.2037\n",
      "Epoch 1447/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5552 - acc: 0.2112 - val_loss: 0.5900 - val_acc: 0.2037\n",
      "Epoch 1448/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4553 - acc: 0.2120 - val_loss: 0.5583 - val_acc: 0.2037\n",
      "Epoch 1449/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4167 - acc: 0.2120 - val_loss: 0.5715 - val_acc: 0.2037\n",
      "Epoch 1450/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4246 - acc: 0.2125 - val_loss: 0.5732 - val_acc: 0.2037\n",
      "Epoch 1451/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4665 - acc: 0.2129 - val_loss: 0.5541 - val_acc: 0.2037\n",
      "Epoch 1452/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4124 - acc: 0.2125 - val_loss: 0.5461 - val_acc: 0.2037\n",
      "Epoch 1453/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4585 - acc: 0.2112 - val_loss: 0.5649 - val_acc: 0.2037\n",
      "Epoch 1454/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4253 - acc: 0.2125 - val_loss: 0.5917 - val_acc: 0.2037\n",
      "Epoch 1455/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4535 - acc: 0.2125 - val_loss: 0.6062 - val_acc: 0.2037\n",
      "Epoch 1456/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4584 - acc: 0.2120 - val_loss: 0.7345 - val_acc: 0.2037\n",
      "Epoch 1457/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4870 - acc: 0.2120 - val_loss: 0.6461 - val_acc: 0.2037\n",
      "Epoch 1458/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4826 - acc: 0.2120 - val_loss: 0.5486 - val_acc: 0.2037\n",
      "Epoch 1459/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4498 - acc: 0.2120 - val_loss: 0.5487 - val_acc: 0.2037\n",
      "Epoch 1460/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5393 - acc: 0.2129 - val_loss: 0.5628 - val_acc: 0.2037\n",
      "Epoch 1461/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5484 - acc: 0.2125 - val_loss: 0.5629 - val_acc: 0.2037\n",
      "Epoch 1462/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.5661 - acc: 0.2112 - val_loss: 0.5945 - val_acc: 0.2037\n",
      "Epoch 1463/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.5324 - acc: 0.2125 - val_loss: 0.5582 - val_acc: 0.2037\n",
      "Epoch 1464/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.6239 - acc: 0.2133 - val_loss: 0.5897 - val_acc: 0.2000\n",
      "Epoch 1465/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4226 - acc: 0.2120 - val_loss: 0.5335 - val_acc: 0.2037\n",
      "Epoch 1466/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4230 - acc: 0.2129 - val_loss: 0.6117 - val_acc: 0.2037\n",
      "Epoch 1467/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4402 - acc: 0.2129 - val_loss: 0.9619 - val_acc: 0.2037\n",
      "Epoch 1468/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4457 - acc: 0.2125 - val_loss: 0.5493 - val_acc: 0.2037\n",
      "Epoch 1469/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4282 - acc: 0.2129 - val_loss: 0.5449 - val_acc: 0.2037\n",
      "Epoch 1470/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4320 - acc: 0.2129 - val_loss: 0.6507 - val_acc: 0.2000\n",
      "Epoch 1471/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4133 - acc: 0.2129 - val_loss: 0.5771 - val_acc: 0.2037\n",
      "Epoch 1472/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4401 - acc: 0.2133 - val_loss: 0.6341 - val_acc: 0.2000\n",
      "Epoch 1473/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.4206 - acc: 0.2133 - val_loss: 0.7126 - val_acc: 0.2037\n",
      "Epoch 1474/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4368 - acc: 0.2125 - val_loss: 0.5433 - val_acc: 0.2037\n",
      "Epoch 1475/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4383 - acc: 0.2116 - val_loss: 0.6330 - val_acc: 0.2000\n",
      "Epoch 1476/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4837 - acc: 0.2129 - val_loss: 0.6248 - val_acc: 0.2037\n",
      "Epoch 1477/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4853 - acc: 0.2133 - val_loss: 0.5651 - val_acc: 0.2037\n",
      "Epoch 1478/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.5514 - acc: 0.2120 - val_loss: 0.6261 - val_acc: 0.2037\n",
      "Epoch 1479/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.5013 - acc: 0.2120 - val_loss: 0.5857 - val_acc: 0.2037\n",
      "Epoch 1480/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.4782 - acc: 0.2120 - val_loss: 0.6622 - val_acc: 0.2037\n",
      "Epoch 1481/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.4927 - acc: 0.2125 - val_loss: 0.5676 - val_acc: 0.2037\n",
      "Epoch 1482/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4565 - acc: 0.2116 - val_loss: 0.6056 - val_acc: 0.2037\n",
      "Epoch 1483/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4378 - acc: 0.2120 - val_loss: 0.6543 - val_acc: 0.2037\n",
      "Epoch 1484/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4258 - acc: 0.2125 - val_loss: 0.5400 - val_acc: 0.2037\n",
      "Epoch 1485/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4414 - acc: 0.2112 - val_loss: 0.6177 - val_acc: 0.2000\n",
      "Epoch 1486/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4969 - acc: 0.2125 - val_loss: 0.5378 - val_acc: 0.2037\n",
      "Epoch 1487/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4155 - acc: 0.2116 - val_loss: 0.5725 - val_acc: 0.2037\n",
      "Epoch 1488/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4257 - acc: 0.2120 - val_loss: 0.6935 - val_acc: 0.2000\n",
      "Epoch 1489/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.6261 - acc: 0.2120 - val_loss: 0.6055 - val_acc: 0.2037\n",
      "Epoch 1490/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4276 - acc: 0.2125 - val_loss: 0.5904 - val_acc: 0.2000\n",
      "Epoch 1491/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4500 - acc: 0.2120 - val_loss: 0.5357 - val_acc: 0.2037\n",
      "Epoch 1492/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4554 - acc: 0.2120 - val_loss: 0.6094 - val_acc: 0.2037\n",
      "Epoch 1493/10000\n",
      "76/76 [==============================] - 247s 3s/step - loss: 0.4317 - acc: 0.2125 - val_loss: 0.7202 - val_acc: 0.2000\n",
      "Epoch 1494/10000\n",
      "52/76 [===================>..........] - ETA: 1s - loss: 0.4552 - acc: 0.2175"
     ]
    }
   ],
   "source": [
    "size_history = cnn_size_model.fit([size_x_train1, size_x_train2, size_x_train3], size_y_train, epochs=10000, validation_data=([size_x_test1,size_x_test2,size_x_test3], size_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの評価(大きさ)\n",
    "score = cnn_size_model.evaluate([size_x_test1, size_x_test2, size_x_test3], size_y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習経過の可視化(大きさ)\n",
    "loss     = size_history.history['loss']\n",
    "val_loss = size_history.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss,     marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 散布図表示\n",
    "size_predict = cnn_size_model.predict([size_x_test1,size_x_test2,size_x_test3])\n",
    "size_answer = size_y_test\n",
    "\n",
    "plt.scatter(size_answer, size_predict)\n",
    "plt.xlabel(\"欠陥の大きさ\")\n",
    "plt.ylabel(\"推定した欠陥の大きさ\")\n",
    "plt.grid(True)\n",
    "## y=xの直線をひく\n",
    "x = []\n",
    "for i in range(60):\n",
    "    x.append(i*0.1)\n",
    "y = []\n",
    "for i in range(60):\n",
    "    y.append(i*60)\n",
    "plt.plot(x, y, color='black')\n",
    "## 誤差-20%の直線を引く\n",
    "y = []\n",
    "for i in range(60):\n",
    "    y.append(i*0.1*0.8)\n",
    "plt.plot(x, y, color='red')\n",
    "## 誤差+20%の直線を引く\n",
    "y = []\n",
    "for i in range(60):\n",
    "    y.append(i*0.1*1.2)\n",
    "plt.plot(x, y, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大きさ1の正答率：0.058333333333333334\n",
      "大きさ2の正答率：0.45614035087719296\n",
      "大きさ3の正答率：0.6568627450980392\n",
      "大きさ4の正答率：0.9230769230769231\n",
      "大きさ5の正答率：0.6868686868686869\n"
     ]
    }
   ],
   "source": [
    "#大きさごとの推定精度の確認：20%以下\n",
    "size_predict = cnn_size_model.predict([size_x_test1,size_x_test2,size_x_test3])\n",
    "size_answer = size_y_test\n",
    "one_total = 0\n",
    "one_ok = 0\n",
    "two_total = 0\n",
    "two_ok = 0\n",
    "three_total = 0\n",
    "three_ok = 0\n",
    "four_total = 0\n",
    "four_ok = 0\n",
    "five_total = 0\n",
    "five_ok = 0\n",
    "for i in range(len(size_predict)):\n",
    "    if size_answer[i] == 1:\n",
    "        one_total = one_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.2):\n",
    "            one_ok = one_ok + 1\n",
    "    if size_answer[i] == 2:\n",
    "        two_total = two_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.4):\n",
    "            two_ok = two_ok + 1\n",
    "    if size_answer[i] == 3:\n",
    "        three_total = three_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.6):\n",
    "            three_ok = three_ok + 1\n",
    "    if size_answer[i] == 4:\n",
    "        four_total = four_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.8):\n",
    "            four_ok = four_ok + 1\n",
    "    if size_answer[i] == 5:\n",
    "        five_total = five_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 1):\n",
    "            five_ok = five_ok + 1\n",
    "print(\"大きさ1の正答率：\"+str(one_ok/one_total))\n",
    "print(\"大きさ2の正答率：\"+str(two_ok/two_total))\n",
    "print(\"大きさ3の正答率：\"+str(three_ok/three_total))\n",
    "print(\"大きさ4の正答率：\"+str(four_ok/four_total))\n",
    "print(\"大きさ5の正答率：\"+str(five_ok/five_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "left = np.array([1,2,3,4,5])\n",
    "height = np.array([one_ok/one_total,two_ok/two_total,three_ok/three_total,four_ok/four_total,five_ok/five_total])\n",
    "plt.bar(left, height)\n",
    "plt.xlabel(\"size\")\n",
    "plt.ylabel(\"size acc\")\n",
    "plt.ylim(top=1, bottom=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大きさ1の正答率：0.8083333333333333\n",
      "大きさ2の正答率：0.7017543859649122\n",
      "大きさ3の正答率：0.5098039215686274\n",
      "大きさ4の正答率：0.75\n",
      "大きさ5の正答率：0.37373737373737376\n"
     ]
    }
   ],
   "source": [
    "#大きさごとの推定精度の確認：最も近く予測\n",
    "size_predict = cnn_size_model.predict([size_x_test1,size_x_test2,size_x_test3])\n",
    "size_answer = size_y_test\n",
    "one_total = 0\n",
    "one_ok = 0\n",
    "two_total = 0\n",
    "two_ok = 0\n",
    "three_total = 0\n",
    "three_ok = 0\n",
    "four_total = 0\n",
    "four_ok = 0\n",
    "five_total = 0\n",
    "five_ok = 0\n",
    "for i in range(len(size_predict)):\n",
    "    if size_answer[i] == 1:\n",
    "        one_total = one_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.5):\n",
    "            one_ok = one_ok + 1\n",
    "    if size_answer[i] == 2:\n",
    "        two_total = two_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.5):\n",
    "            two_ok = two_ok + 1\n",
    "    if size_answer[i] == 3:\n",
    "        three_total = three_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.5):\n",
    "            three_ok = three_ok + 1\n",
    "    if size_answer[i] == 4:\n",
    "        four_total = four_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.5):\n",
    "            four_ok = four_ok + 1\n",
    "    if size_answer[i] == 5:\n",
    "        five_total = five_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.5):\n",
    "            five_ok = five_ok + 1\n",
    "print(\"大きさ1の正答率：\"+str(one_ok/one_total))\n",
    "print(\"大きさ2の正答率：\"+str(two_ok/two_total))\n",
    "print(\"大きさ3の正答率：\"+str(three_ok/three_total))\n",
    "print(\"大きさ4の正答率：\"+str(four_ok/four_total))\n",
    "print(\"大きさ5の正答率：\"+str(five_ok/five_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQNUlEQVR4nO3dfayedX3H8ffHFnRBxE3ODLaVEldl1W2KJwyDm0+oBUzrMlBIdLqhTRYxOoymRoeTuURFmdE0aifM+TArU2dOoFqZ4mNEe6qAtFhXsRstJC0+MBUnRb7741x1Z6en7Q07131zzu/9Sk7OfV3X777P5/6j+fR6+l2pKiRJ7XrQqANIkkbLIpCkxlkEktQ4i0CSGmcRSFLjLAJJalxvRZDkiiR7k9x0iO1J8u4kO5PcmOSUvrJIkg6tzz2CDwKrDrP9TGBF97MWeG+PWSRJh9BbEVTVl4EfHWbIGuBDNeU64OFJTugrjyRpdotH+LeXALdOW97drbt95sAka5naa+CYY4558sknnzyUgJK0UGzduvWOqhqbbdsoi2BgVbUB2AAwPj5ek5OTI04kSfNLkv841LZRXjW0B1g2bXlpt06SNESjLIIJ4M+6q4dOA+6sqoMOC0mS+tXboaEkHwOeDhyfZDfwJuAogKp6H7AJOAvYCdwF/HlfWSRJh9ZbEVTV+UfYXsAr+vr7kqTBeGexJDXOIpCkxlkEktQ4i0CSGmcRSFLjLAJJapxFIEmNswgkqXEWgSQ1ziKQpMZZBJLUOItAkhpnEUhS4ywCSWqcRSBJjbMIJKlxFoEkNc4ikKTGWQSS1DiLQJIaZxFIUuMsAklqnEUgSY2zCCSpcRaBJDXOIpCkxlkEktQ4i0CSGmcRSFLjLAJJapxFIEmNswgkqXEWgSQ1ziKQpMZZBJLUuF6LIMmqJDuS7Eyybpbtj05ybZJvJ7kxyVl95pEkHWxxXx+cZBGwHng2sBvYkmSiqrZPG/ZG4Mqqem+SlcAmYHlfmZavu7qvjx66XW89e9QRJC0Qfe4RnArsrKpbqupuYCOwZsaYAh7WvT4OuK3HPJKkWfRZBEuAW6ct7+7WTfc3wIuS7GZqb+CVs31QkrVJJpNM7tu3r4+sktSsUZ8sPh/4YFUtBc4CPpzkoExVtaGqxqtqfGxsbOghJWkh67MI9gDLpi0v7dZNdwFwJUBVfR14CHB8j5kkSTP0WQRbgBVJTkpyNHAeMDFjzH8CzwJI8rtMFYHHfiRpiHorgqq6B7gQ2AzczNTVQduSXJJkdTfsNcDLk9wAfAx4aVVVX5kkSQfr7fJRgKraxNRJ4OnrLp72ejtwep8ZJEmHN+qTxZKkEbMIJKlxFoEkNc4ikKTGWQSS1LherxqS9MCwUCZcdLLFfrhHIEmNswgkqXEWgSQ1ziKQpMZZBJLUOItAkhpnEUhS4ywCSWqcRSBJjfPO4oZ4d6mk2bhHIEmNswgkqXEWgSQ1ziKQpMZZBJLUOItAkhpnEUhS4ywCSWqcRSBJjbMIJKlxFoEkNc4ikKTGWQSS1DiLQJIaZxFIUuMsAklqnEUgSY2zCCSpcb0WQZJVSXYk2Zlk3SHGvCDJ9iTbkvxzn3kkSQfr7ZnFSRYB64FnA7uBLUkmqmr7tDErgNcDp1fVj5P8dl95JEmz63OP4FRgZ1XdUlV3AxuBNTPGvBxYX1U/BqiqvT3mkSTNos8iWALcOm15d7duuscCj03ytSTXJVk12wclWZtkMsnkvn37eoorSW0a9cnixcAK4OnA+cA/JHn4zEFVtaGqxqtqfGxsbLgJJWmB67MI9gDLpi0v7dZNtxuYqKr9VfUD4HtMFYMkaUj6LIItwIokJyU5GjgPmJgx5tNM7Q2Q5HimDhXd0mMmSdIMvRVBVd0DXAhsBm4GrqyqbUkuSbK6G7YZ+GGS7cC1wGur6od9ZZIkHeyIl48muQY4t6p+0i3/JrCxqp57pPdW1SZg04x1F097XcBF3Y8kaQQG2SM4/kAJAHSXenq9vyQtEIMUwb1JHn1gIcmJQPUXSZI0TIPcWfwG4KtJvgQE+CNgba+pJElDc8QiqKrPJjkFOK1b9eqquqPfWJKkYTnioaEkfwLsr6qrquoq4J4kz+89mSRpKAY5R/CmqrrzwEJ34vhNvSWSJA3VIEUw25jeZi2VJA3XIEUwmeSyJI/pfi4DtvYdTJI0HIMUwSuBu4GPdz+/BF7RZyhJ0vAMctXQz4FZny4mSZr/BpliYgx4HfB44CEH1lfVM3vMJUkakkEODX0U+C5wEvBmYBdTM4tKkhaAQYrgEVV1OVP3Enypqv4CcG9AkhaIQS4D3d/9vj3J2cBtwG/1F0mSNEyDFMFbkhwHvAZ4D/Aw4K96TSXNseXrrh51hDmz661njzqCFphBrhq6qnt5J/CMfuNIkoZt1A+vlySNmEUgSY2zCCSpcYNMQ/3IJJcn+Uy3vDLJBf1HkyQNwyB7BB8ENgOP6pa/B7y6pzySpCEb9OH1VwL3AlTVPcCvek0lSRqaQYrg50keQffA+iSnMXUpqSRpARjkhrLXABPAY5J8DRgDzu01lSRpaAa5oWxrkqcBjwMC7Kiq/Ud4myRpnhjkqqHvAy+rqm1VdVNV7U9y1ZHeJ0maHwY5R7AfeEaSf0xydLduSY+ZJElDNEgR3FVVLwRuBr6S5NF0J44lSfPfICeLA1BVb0/yLeBzOA21JC0YgxTBxQdeVNW/JXku8JL+IkmShumQRZDk5Kr6LrAnySkzNnuyWJIWiMPtEVwErAXeOcu2wsdVStKCcMgiqKq13W8fRiNJC9gg9xGcm+TY7vUbk3wqyZP6jyZJGoZBLh/966r6aZKnAmcAlwPv6zeWJGlYBimCAzONng1sqKqrgaMPM/7XkqxKsiPJziTrDjPuT5NUkvFBPleSNHcGKYI9Sd4PvBDYlOTBg7wvySJgPXAmsBI4P8nKWcYdC7wK+MZ9CS5JmhuDFMELmHowzXOr6idM3Uz22gHedyqws6puqaq7gY3AmlnG/S3wNuC/B0osSZpTRyyCqrqrqj5VVf/eLd9eVZ8b4LOXALdOW97NjDmKuvsTlnWHmw4pydokk0km9+3bN8CfliQNamQPr0/yIOAypp53cFhVtaGqxqtqfGxsrP9wktSQPotgD7Bs2vLSbt0BxwJPAL6YZBdwGjDhCWNJGq4+i2ALsCLJSd301ecx9aQzAKrqzqo6vqqWV9Vy4DpgdVVN9phJkjRDb0XQPeT+QqZONN8MXFlV25JckmR1X39XknTfDDL76P1WVZuATTPWXXyIsU/vM4skaXa9FoEkjdrydYe9KHFe2fXWs3v53JFdNSRJemCwCCSpcRaBJDXOIpCkxlkEktQ4i0CSGmcRSFLjLAJJapxFIEmNswgkqXEWgSQ1ziKQpMZZBJLUOItAkhpnEUhS4ywCSWqcRSBJjbMIJKlxFoEkNc4ikKTGWQSS1DiLQJIaZxFIUuMsAklqnEUgSY2zCCSpcRaBJDXOIpCkxlkEktQ4i0CSGmcRSFLjLAJJapxFIEmN67UIkqxKsiPJziTrZtl+UZLtSW5M8vkkJ/aZR5J0sN6KIMkiYD1wJrASOD/JyhnDvg2MV9XvA58A3t5XHknS7PrcIzgV2FlVt1TV3cBGYM30AVV1bVXd1S1eByztMY8kaRZ9FsES4NZpy7u7dYdyAfCZ2TYkWZtkMsnkvn375jCiJOkBcbI4yYuAceDS2bZX1YaqGq+q8bGxseGGk6QFbnGPn70HWDZteWm37v9IcgbwBuBpVfXLHvNIkmbR5x7BFmBFkpOSHA2cB0xMH5DkScD7gdVVtbfHLJKkQ+itCKrqHuBCYDNwM3BlVW1LckmS1d2wS4GHAv+S5PokE4f4OElST/o8NERVbQI2zVh38bTXZ/T59yVJR/aAOFksSRodi0CSGmcRSFLjLAJJapxFIEmNswgkqXEWgSQ1ziKQpMZZBJLUOItAkhpnEUhS4ywCSWqcRSBJjbMIJKlxFoEkNc4ikKTGWQSS1DiLQJIaZxFIUuMsAklqnEUgSY2zCCSpcRaBJDXOIpCkxlkEktQ4i0CSGmcRSFLjLAJJapxFIEmNswgkqXEWgSQ1ziKQpMZZBJLUOItAkhpnEUhS43otgiSrkuxIsjPJulm2PzjJx7vt30iyvM88kqSD9VYESRYB64EzgZXA+UlWzhh2AfDjqvod4O+Bt/WVR5I0uz73CE4FdlbVLVV1N7ARWDNjzBrgn7rXnwCelSQ9ZpIkzZCq6ueDk3OAVVX1sm75xcAfVtWF08bc1I3Z3S1/vxtzx4zPWgus7RYfB+zoJfTcOR6444ijFia/e7ta/v7z4bufWFVjs21YPOwk90dVbQA2jDrHoJJMVtX4qHOMgt+9ze8ObX//+f7d+zw0tAdYNm15abdu1jFJFgPHAT/sMZMkaYY+i2ALsCLJSUmOBs4DJmaMmQBe0r0+B/hC9XWsSpI0q94ODVXVPUkuBDYDi4ArqmpbkkuAyaqaAC4HPpxkJ/AjpspiIZg3h7F64HdvV8vff15/995OFkuS5gfvLJakxlkEktQ4i2AOJbkiyd7u/oimJFmW5Nok25NsS/KqUWcaliQPSfLNJDd03/3No840bEkWJfl2kqtGnWXYkuxK8p0k1yeZHHWe+8NzBHMoyR8DPwM+VFVPGHWeYUpyAnBCVX0rybHAVuD5VbV9xNF6190Nf0xV/SzJUcBXgVdV1XUjjjY0SS4CxoGHVdXzRp1nmJLsAsZn3gg7n7hHMIeq6stMXf3UnKq6vaq+1b3+KXAzsGS0qYajpvysWzyq+2nmf1hJlgJnAx8YdRbdPxaB5lw3i+yTgG+MOMrQdIdGrgf2AtdUVTPfHXgX8Drg3hHnGJUCPpdkazcdzrxjEWhOJXko8Eng1VX1X6POMyxV9auqeiJTd9CfmqSJQ4NJngfsraqto84yQk+tqlOYmmn5Fd0h4nnFItCc6Y6PfxL4aFV9atR5RqGqfgJcC6wacZRhOR1Y3R0n3wg8M8lHRhtpuKpqT/d7L/CvTM28PK9YBJoT3QnTy4Gbq+qyUecZpiRjSR7evf4N4NnAd0caakiq6vVVtbSqljM1M8AXqupFI441NEmO6S6OIMkxwHOAeXfVoEUwh5J8DPg68Lgku5NcMOpMQ3Q68GKm/kd4ffdz1qhDDckJwLVJbmRqjq1rqqq5yygb9Ujgq0luAL4JXF1Vnx1xpvvMy0clqXHuEUhS4ywCSWqcRSBJjbMIJKlxFoEkNc4ikO6nJB9IsnLUOaT/Ly8flaTGuUcgDaC7g/Tq7pkDNyV5YZIvJhlPsnraTXQ7kvyge8+Tk3ypm4xsczdVt/SAYxFIg1kF3FZVf9A9a+LXd49W1URVPbGbdO4G4B3dvEvvAc6pqicDVwB/N4Lc0hEtHnUAaZ74DvDOJG8Drqqqr0xNr/S/krwO+EVVre9mH30CcE03bhFw+5AzSwOxCKQBVNX3kpwCnAW8Jcnnp29PcgZwLnBgCuIA26rqKcNNKt13HhqSBpDkUcBdVfUR4FLglGnbTgTWA+dW1S+61TuAsSRP6cYcleTxQ44tDcQ9AmkwvwdcmuReYD/wl8A7um0vBR4BfLo7DHRbVZ2V5Bzg3UmOY+rf2ruAbUPOLR2Rl49KUuM8NCRJjbMIJKlxFoEkNc4ikKTGWQSS1DiLQJIaZxFIUuP+B0zYHhQZCwq5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "left = np.array([1,2,3,4,5])\n",
    "height = np.array([one_ok/one_total,two_ok/two_total,three_ok/three_total,four_ok/four_total,five_ok/five_total])\n",
    "plt.bar(left, height)\n",
    "plt.xlabel(\"size\")\n",
    "plt.ylabel(\"size acc\")\n",
    "plt.ylim(top=1, bottom=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.44252, 1.1473302, 1.4547509, 1.1462659, 1.279724, 1.4187611, 2.2494783, 1.4151858, 1.5425566, 1.3619479, 1.5114468, 1.3730124, 1.5752915, 1.4545077, 1.3821934, 1.5695113, 1.2814149, 1.4333647, 1.567007, 0.73064697, 1.4592646, 1.4466609, 1.4385337, 1.4378985, 1.4328555, 1.4320906, 0.7976588, 1.4148434, 1.4687041, 1.396653, 1.4211091, 1.3610276, 1.4213666, 1.3046511, 1.4013566, 1.1810225, 1.3877333, 1.4635714, 1.4398497, 1.4356498, 1.4115142, 1.435707, 1.3438138, 1.2059973, 1.4960641, 1.4183291, 1.4417571, 1.4593323, 1.3119601, 1.3960971, 1.4772471, 1.5889014, 1.4211463, 1.4654015, 1.5327939, 1.4758557, 1.3323001, 1.4968585, 1.5920066, 1.5640067, 1.3928717, 1.4473618, 1.6459101, 1.461213, 1.4432524, 0.48839843, 1.4031609, 1.4343623, 1.4961585, 1.5364636, 1.4618129, 1.2368821, 1.4010838, 1.2895831, 1.4371518, 1.4584311, 1.4902104, 1.60155, 1.2386817, 1.3893145, 1.4438361, 1.4162654, 1.4688128, 1.4389266, 1.501458, 1.0119036, 1.5519599, 1.4248704, 1.4687833, 1.4215535, 1.7420453, 1.4437693, 1.4343117, 1.5139579, 0.9973773, 1.4538172, 1.5159482, -0.11382401, 1.4308633, 1.4684209, 0.8307208, 1.4089888, 1.4299, 1.4102553, 1.4873255, 1.2943581, 1.3691577, 1.4503945, 1.392393, 1.3947467, 1.502941, 1.4222916, 1.49028, 1.4303769, 0.86862934, 1.3616542, 1.9995621, 1.4444684, 1.4969891, 1.5039643]\n"
     ]
    }
   ],
   "source": [
    "one_predict = []\n",
    "size_predict = cnn_size_model.predict([size_x_test1,size_x_test2,size_x_test3])\n",
    "size_answer = size_y_test\n",
    "for i in range(len(size_y_test)):\n",
    "    if size_answer[i] == 1:\n",
    "        one_predict.append(size_predict[i][0])\n",
    "print(one_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1251, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1251, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 1251, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 1251, 32)     128         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1251, 32)     128         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1251, 32)     128         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 626, 32)      0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 626, 32)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 626, 32)      0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 626, 32)      3104        max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 626, 32)      3104        max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 626, 32)      3104        max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 313, 32)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 313, 32)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 313, 32)      0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 313, 96)      0           max_pooling1d_1[0][0]            \n",
      "                                                                 max_pooling1d_3[0][0]            \n",
      "                                                                 max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 30048)        0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            30049       flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 39,745\n",
      "Trainable params: 39,745\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNNモデルで大きさ推定(層を増やす)\n",
    "# import\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, concatenate, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
    "\n",
    "# 入力を定義\n",
    "input1 = Input(shape=(1251,1))\n",
    "input2 = Input(shape=(1251,1))\n",
    "input3 = Input(shape=(1251,1))\n",
    "\n",
    "# 入力1から結合前まで\n",
    "x = Conv1D(32, 3, padding='same', activation='tanh')(input1)\n",
    "x = MaxPooling1D(2, padding='same')(x)\n",
    "x = Conv1D(32, 3, padding='same', activation='tanh')(x)\n",
    "x = MaxPooling1D(2, padding='same')(x)\n",
    "x = Model(inputs=input1, outputs=x)\n",
    "# 入力2から結合前まで\n",
    "y = Conv1D(32, 3, padding='same', activation='tanh')(input2)\n",
    "y = MaxPooling1D(2, padding='same')(y)\n",
    "y = Conv1D(32, 3, padding='same', activation='tanh')(y)\n",
    "y = MaxPooling1D(2, padding='same')(y)\n",
    "y = Model(inputs=input2, outputs=y)\n",
    "# 入力3から結合前まで\n",
    "z = Conv1D(32, 3, padding='same', activation='tanh')(input3)\n",
    "z = MaxPooling1D(2, padding='same')(z)\n",
    "z = Conv1D(32, 3, padding='same', activation='tanh')(z)\n",
    "z = MaxPooling1D(2, padding='same')(z)\n",
    "z = Model(inputs=input3, outputs=z)\n",
    "\n",
    "# 結合\n",
    "combined = concatenate([x.output, y.output, z.output])\n",
    "\n",
    "# 密結合\n",
    "cnn = Flatten()(combined)\n",
    "cnn = Dense(1, activation=\"linear\")(cnn)\n",
    "\n",
    "# モデル定義とコンパイル\n",
    "cnn_size_model = Model(inputs=[x.input, y.input, z.input], outputs=cnn)\n",
    "cnn_size_model.compile(loss='mse', optimizer='adam', metrics=['acc'])\n",
    "cnn_size_model.summary()\n",
    "plot_model(cnn_size_model, show_shapes=True, show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 1.9712 - acc: 0.2172 - val_loss: 1.9494 - val_acc: 0.2004\n",
      "Epoch 2/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 1.9611 - acc: 0.2172 - val_loss: 1.9221 - val_acc: 0.2004\n",
      "Epoch 3/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 1.9368 - acc: 0.2172 - val_loss: 1.8511 - val_acc: 0.2004\n",
      "Epoch 4/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 1.8238 - acc: 0.2172 - val_loss: 1.7745 - val_acc: 0.2004\n",
      "Epoch 5/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 1.7258 - acc: 0.2172 - val_loss: 1.7579 - val_acc: 0.2004\n",
      "Epoch 6/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 1.7605 - acc: 0.2172 - val_loss: 1.9649 - val_acc: 0.2004\n",
      "Epoch 7/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 1.7141 - acc: 0.2172 - val_loss: 1.7147 - val_acc: 0.2004\n",
      "Epoch 8/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 1.5905 - acc: 0.2172 - val_loss: 1.7092 - val_acc: 0.2004\n",
      "Epoch 9/4000\n",
      "68/68 [==============================] - 5s 77ms/step - loss: 1.5608 - acc: 0.2172 - val_loss: 1.8368 - val_acc: 0.2004\n",
      "Epoch 10/4000\n",
      "68/68 [==============================] - 5s 78ms/step - loss: 1.5561 - acc: 0.2172 - val_loss: 1.6648 - val_acc: 0.2004\n",
      "Epoch 11/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 1.4753 - acc: 0.2172 - val_loss: 1.6022 - val_acc: 0.2004\n",
      "Epoch 12/4000\n",
      "68/68 [==============================] - 5s 71ms/step - loss: 1.4900 - acc: 0.2172 - val_loss: 1.4933 - val_acc: 0.2004\n",
      "Epoch 13/4000\n",
      "68/68 [==============================] - 5s 69ms/step - loss: 1.4808 - acc: 0.2172 - val_loss: 1.5167 - val_acc: 0.2004\n",
      "Epoch 14/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 1.4853 - acc: 0.2172 - val_loss: 1.5366 - val_acc: 0.2004\n",
      "Epoch 15/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 1.4260 - acc: 0.2172 - val_loss: 1.4179 - val_acc: 0.2004\n",
      "Epoch 16/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 1.3228 - acc: 0.2172 - val_loss: 1.3881 - val_acc: 0.2004\n",
      "Epoch 17/4000\n",
      "68/68 [==============================] - 5s 70ms/step - loss: 1.3273 - acc: 0.2172 - val_loss: 1.3492 - val_acc: 0.2004\n",
      "Epoch 18/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 1.3382 - acc: 0.2172 - val_loss: 1.4073 - val_acc: 0.2004\n",
      "Epoch 19/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 1.2649 - acc: 0.2172 - val_loss: 1.3512 - val_acc: 0.2004\n",
      "Epoch 20/4000\n",
      "68/68 [==============================] - 5s 69ms/step - loss: 1.3223 - acc: 0.2172 - val_loss: 1.3309 - val_acc: 0.2004\n",
      "Epoch 21/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 1.2582 - acc: 0.2172 - val_loss: 1.2883 - val_acc: 0.2004\n",
      "Epoch 22/4000\n",
      "68/68 [==============================] - 5s 70ms/step - loss: 1.1972 - acc: 0.2172 - val_loss: 1.3119 - val_acc: 0.2004\n",
      "Epoch 23/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 1.2029 - acc: 0.2172 - val_loss: 1.2765 - val_acc: 0.2004\n",
      "Epoch 24/4000\n",
      "68/68 [==============================] - 5s 71ms/step - loss: 1.1924 - acc: 0.2172 - val_loss: 1.3055 - val_acc: 0.2004\n",
      "Epoch 25/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 1.1981 - acc: 0.2172 - val_loss: 1.2328 - val_acc: 0.2004\n",
      "Epoch 26/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 1.1524 - acc: 0.2172 - val_loss: 1.2684 - val_acc: 0.2004\n",
      "Epoch 27/4000\n",
      "68/68 [==============================] - 5s 72ms/step - loss: 1.1580 - acc: 0.2172 - val_loss: 1.2389 - val_acc: 0.2004\n",
      "Epoch 28/4000\n",
      "68/68 [==============================] - 5s 74ms/step - loss: 1.2464 - acc: 0.2172 - val_loss: 1.3214 - val_acc: 0.2004\n",
      "Epoch 29/4000\n",
      "68/68 [==============================] - 5s 76ms/step - loss: 1.1837 - acc: 0.2172 - val_loss: 1.2955 - val_acc: 0.2004\n",
      "Epoch 30/4000\n",
      "68/68 [==============================] - 5s 72ms/step - loss: 1.1226 - acc: 0.2172 - val_loss: 1.1708 - val_acc: 0.2004\n",
      "Epoch 31/4000\n",
      "68/68 [==============================] - 5s 71ms/step - loss: 1.1583 - acc: 0.2172 - val_loss: 1.3401 - val_acc: 0.2004\n",
      "Epoch 32/4000\n",
      "68/68 [==============================] - 5s 70ms/step - loss: 1.1018 - acc: 0.2172 - val_loss: 1.1687 - val_acc: 0.2004\n",
      "Epoch 33/4000\n",
      "68/68 [==============================] - 5s 70ms/step - loss: 1.0694 - acc: 0.2172 - val_loss: 1.1291 - val_acc: 0.2004\n",
      "Epoch 34/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 1.0464 - acc: 0.2172 - val_loss: 1.1685 - val_acc: 0.2004\n",
      "Epoch 35/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 1.0659 - acc: 0.2172 - val_loss: 1.1199 - val_acc: 0.2004\n",
      "Epoch 36/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 1.0448 - acc: 0.2172 - val_loss: 1.1119 - val_acc: 0.2004\n",
      "Epoch 37/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 1.0429 - acc: 0.2172 - val_loss: 1.0936 - val_acc: 0.2004\n",
      "Epoch 38/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 1.0455 - acc: 0.2172 - val_loss: 1.2553 - val_acc: 0.2004\n",
      "Epoch 39/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.9913 - acc: 0.2172 - val_loss: 1.0885 - val_acc: 0.2004\n",
      "Epoch 40/4000\n",
      "68/68 [==============================] - 5s 70ms/step - loss: 1.0083 - acc: 0.2172 - val_loss: 1.1777 - val_acc: 0.2004\n",
      "Epoch 41/4000\n",
      "68/68 [==============================] - 5s 66ms/step - loss: 1.0252 - acc: 0.2172 - val_loss: 1.0614 - val_acc: 0.2004\n",
      "Epoch 42/4000\n",
      "68/68 [==============================] - 5s 77ms/step - loss: 1.0005 - acc: 0.2172 - val_loss: 1.0543 - val_acc: 0.2004\n",
      "Epoch 43/4000\n",
      "68/68 [==============================] - 5s 71ms/step - loss: 0.9657 - acc: 0.2172 - val_loss: 1.0521 - val_acc: 0.2004\n",
      "Epoch 44/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 0.9828 - acc: 0.2172 - val_loss: 1.1759 - val_acc: 0.2004\n",
      "Epoch 45/4000\n",
      "68/68 [==============================] - 5s 66ms/step - loss: 1.0702 - acc: 0.2172 - val_loss: 1.0335 - val_acc: 0.2004\n",
      "Epoch 46/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 1.1234 - acc: 0.2172 - val_loss: 1.2539 - val_acc: 0.2004\n",
      "Epoch 47/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 1.0371 - acc: 0.2172 - val_loss: 1.0621 - val_acc: 0.2004\n",
      "Epoch 48/4000\n",
      "68/68 [==============================] - 5s 78ms/step - loss: 0.9600 - acc: 0.2172 - val_loss: 1.0419 - val_acc: 0.2004\n",
      "Epoch 49/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.9398 - acc: 0.2172 - val_loss: 1.0454 - val_acc: 0.2004\n",
      "Epoch 50/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.9510 - acc: 0.2172 - val_loss: 0.9947 - val_acc: 0.2004\n",
      "Epoch 51/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.9448 - acc: 0.2172 - val_loss: 0.9888 - val_acc: 0.2004\n",
      "Epoch 52/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.9132 - acc: 0.2172 - val_loss: 1.3331 - val_acc: 0.2004\n",
      "Epoch 53/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 0.9122 - acc: 0.2167 - val_loss: 1.0442 - val_acc: 0.2004\n",
      "Epoch 54/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.9069 - acc: 0.2167 - val_loss: 1.1170 - val_acc: 0.2004\n",
      "Epoch 55/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.9790 - acc: 0.2172 - val_loss: 1.2856 - val_acc: 0.2004\n",
      "Epoch 56/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.9325 - acc: 0.2172 - val_loss: 1.1629 - val_acc: 0.2004\n",
      "Epoch 57/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.9188 - acc: 0.2172 - val_loss: 1.0862 - val_acc: 0.2004\n",
      "Epoch 58/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.8881 - acc: 0.2172 - val_loss: 0.9607 - val_acc: 0.2004\n",
      "Epoch 59/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.8392 - acc: 0.2172 - val_loss: 0.9899 - val_acc: 0.2004\n",
      "Epoch 60/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.8762 - acc: 0.2172 - val_loss: 0.9635 - val_acc: 0.2004\n",
      "Epoch 61/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 1.2175 - acc: 0.2162 - val_loss: 0.9649 - val_acc: 0.2004\n",
      "Epoch 62/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.9783 - acc: 0.2167 - val_loss: 0.9632 - val_acc: 0.2004\n",
      "Epoch 63/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.9294 - acc: 0.2167 - val_loss: 1.0599 - val_acc: 0.2004\n",
      "Epoch 64/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.8540 - acc: 0.2172 - val_loss: 0.9815 - val_acc: 0.2004\n",
      "Epoch 65/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.9309 - acc: 0.2167 - val_loss: 0.9586 - val_acc: 0.2004\n",
      "Epoch 66/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.9202 - acc: 0.2172 - val_loss: 0.9457 - val_acc: 0.2004\n",
      "Epoch 67/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.8350 - acc: 0.2172 - val_loss: 0.9333 - val_acc: 0.2004\n",
      "Epoch 68/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.8135 - acc: 0.2167 - val_loss: 0.9235 - val_acc: 0.2004\n",
      "Epoch 69/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.8740 - acc: 0.2172 - val_loss: 0.9598 - val_acc: 0.2004\n",
      "Epoch 70/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.8399 - acc: 0.2167 - val_loss: 1.0878 - val_acc: 0.2004\n",
      "Epoch 71/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.8498 - acc: 0.2167 - val_loss: 0.9357 - val_acc: 0.2004\n",
      "Epoch 72/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.8592 - acc: 0.2167 - val_loss: 0.9295 - val_acc: 0.2004\n",
      "Epoch 73/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.8245 - acc: 0.2167 - val_loss: 1.0579 - val_acc: 0.2004\n",
      "Epoch 74/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.8461 - acc: 0.2167 - val_loss: 0.9380 - val_acc: 0.2004\n",
      "Epoch 75/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.7934 - acc: 0.2162 - val_loss: 0.9033 - val_acc: 0.2004\n",
      "Epoch 76/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.8511 - acc: 0.2158 - val_loss: 0.9031 - val_acc: 0.2004\n",
      "Epoch 77/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.8537 - acc: 0.2162 - val_loss: 0.9195 - val_acc: 0.2004\n",
      "Epoch 78/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 1.1414 - acc: 0.2167 - val_loss: 0.9366 - val_acc: 0.2004\n",
      "Epoch 79/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 1.0126 - acc: 0.2172 - val_loss: 0.9733 - val_acc: 0.2004\n",
      "Epoch 80/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.8238 - acc: 0.2167 - val_loss: 0.9339 - val_acc: 0.2004\n",
      "Epoch 81/4000\n",
      "68/68 [==============================] - 5s 78ms/step - loss: 0.8228 - acc: 0.2167 - val_loss: 0.9277 - val_acc: 0.2004\n",
      "Epoch 82/4000\n",
      "68/68 [==============================] - 5s 66ms/step - loss: 0.7927 - acc: 0.2167 - val_loss: 0.9023 - val_acc: 0.2004\n",
      "Epoch 83/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.7820 - acc: 0.2167 - val_loss: 0.9136 - val_acc: 0.2004\n",
      "Epoch 84/4000\n",
      "68/68 [==============================] - 5s 66ms/step - loss: 0.8068 - acc: 0.2167 - val_loss: 1.0332 - val_acc: 0.2004\n",
      "Epoch 85/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.8219 - acc: 0.2167 - val_loss: 0.9544 - val_acc: 0.2004\n",
      "Epoch 86/4000\n",
      "68/68 [==============================] - 5s 66ms/step - loss: 0.7828 - acc: 0.2167 - val_loss: 0.9921 - val_acc: 0.2004\n",
      "Epoch 87/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.7894 - acc: 0.2167 - val_loss: 0.8896 - val_acc: 0.2004\n",
      "Epoch 88/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.7711 - acc: 0.2162 - val_loss: 0.8916 - val_acc: 0.2004\n",
      "Epoch 89/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.8046 - acc: 0.2162 - val_loss: 0.8643 - val_acc: 0.2004\n",
      "Epoch 90/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.7685 - acc: 0.2167 - val_loss: 0.8937 - val_acc: 0.2004\n",
      "Epoch 91/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.7562 - acc: 0.2162 - val_loss: 0.8883 - val_acc: 0.2004\n",
      "Epoch 92/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.7343 - acc: 0.2162 - val_loss: 0.9603 - val_acc: 0.2004\n",
      "Epoch 93/4000\n",
      "68/68 [==============================] - 5s 66ms/step - loss: 0.7459 - acc: 0.2162 - val_loss: 0.9039 - val_acc: 0.2004\n",
      "Epoch 94/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.7342 - acc: 0.2162 - val_loss: 0.9116 - val_acc: 0.2004\n",
      "Epoch 95/4000\n",
      "68/68 [==============================] - 5s 66ms/step - loss: 0.7482 - acc: 0.2162 - val_loss: 0.9391 - val_acc: 0.2004\n",
      "Epoch 96/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.7745 - acc: 0.2158 - val_loss: 1.1234 - val_acc: 0.2004\n",
      "Epoch 97/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.7776 - acc: 0.2162 - val_loss: 1.2125 - val_acc: 0.2004\n",
      "Epoch 98/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.7682 - acc: 0.2162 - val_loss: 0.8884 - val_acc: 0.2004\n",
      "Epoch 99/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.7744 - acc: 0.2153 - val_loss: 0.9976 - val_acc: 0.2004\n",
      "Epoch 100/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 0.7314 - acc: 0.2162 - val_loss: 0.8552 - val_acc: 0.2004\n",
      "Epoch 101/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.7044 - acc: 0.2167 - val_loss: 1.2564 - val_acc: 0.2004\n",
      "Epoch 102/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.7444 - acc: 0.2162 - val_loss: 0.8620 - val_acc: 0.2004\n",
      "Epoch 103/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.7429 - acc: 0.2162 - val_loss: 1.0057 - val_acc: 0.2004\n",
      "Epoch 104/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.7743 - acc: 0.2158 - val_loss: 0.8712 - val_acc: 0.2004\n",
      "Epoch 105/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.7588 - acc: 0.2162 - val_loss: 0.9959 - val_acc: 0.2004\n",
      "Epoch 106/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.7795 - acc: 0.2158 - val_loss: 0.8945 - val_acc: 0.2004\n",
      "Epoch 107/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.7249 - acc: 0.2162 - val_loss: 0.8443 - val_acc: 0.2004\n",
      "Epoch 108/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.6906 - acc: 0.2167 - val_loss: 0.8183 - val_acc: 0.2004\n",
      "Epoch 109/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.6860 - acc: 0.2162 - val_loss: 0.9264 - val_acc: 0.2004\n",
      "Epoch 110/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.7000 - acc: 0.2162 - val_loss: 0.8489 - val_acc: 0.2004\n",
      "Epoch 111/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.7156 - acc: 0.2162 - val_loss: 0.8118 - val_acc: 0.2004\n",
      "Epoch 112/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.6759 - acc: 0.2162 - val_loss: 0.8580 - val_acc: 0.2004\n",
      "Epoch 113/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.7291 - acc: 0.2158 - val_loss: 0.7962 - val_acc: 0.2004\n",
      "Epoch 114/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.7036 - acc: 0.2167 - val_loss: 0.8123 - val_acc: 0.2004\n",
      "Epoch 115/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.7299 - acc: 0.2148 - val_loss: 0.9262 - val_acc: 0.2004\n",
      "Epoch 116/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.6941 - acc: 0.2162 - val_loss: 0.9152 - val_acc: 0.2004\n",
      "Epoch 117/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.7159 - acc: 0.2158 - val_loss: 0.8224 - val_acc: 0.2004\n",
      "Epoch 118/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.6474 - acc: 0.2162 - val_loss: 0.7896 - val_acc: 0.2004\n",
      "Epoch 119/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.6703 - acc: 0.2158 - val_loss: 0.9250 - val_acc: 0.2004\n",
      "Epoch 120/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.7002 - acc: 0.2162 - val_loss: 0.9457 - val_acc: 0.2004\n",
      "Epoch 121/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 0.7157 - acc: 0.2162 - val_loss: 1.1106 - val_acc: 0.2004\n",
      "Epoch 122/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.7901 - acc: 0.2158 - val_loss: 0.9104 - val_acc: 0.2004\n",
      "Epoch 123/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 63ms/step - loss: 0.9350 - acc: 0.2162 - val_loss: 0.9978 - val_acc: 0.2004\n",
      "Epoch 124/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.8806 - acc: 0.2162 - val_loss: 0.8940 - val_acc: 0.2004\n",
      "Epoch 125/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 1.1510 - acc: 0.2167 - val_loss: 0.8955 - val_acc: 0.2004\n",
      "Epoch 126/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.7568 - acc: 0.2167 - val_loss: 0.9166 - val_acc: 0.2004\n",
      "Epoch 127/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.7135 - acc: 0.2167 - val_loss: 0.8179 - val_acc: 0.2004\n",
      "Epoch 128/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.6569 - acc: 0.2162 - val_loss: 0.9375 - val_acc: 0.2004\n",
      "Epoch 129/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.6703 - acc: 0.2162 - val_loss: 0.8611 - val_acc: 0.2004\n",
      "Epoch 130/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.6437 - acc: 0.2162 - val_loss: 0.8667 - val_acc: 0.2004\n",
      "Epoch 131/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.6766 - acc: 0.2162 - val_loss: 0.8408 - val_acc: 0.2004\n",
      "Epoch 132/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.6376 - acc: 0.2162 - val_loss: 0.8030 - val_acc: 0.2004\n",
      "Epoch 133/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.6502 - acc: 0.2158 - val_loss: 0.8582 - val_acc: 0.2004\n",
      "Epoch 134/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.7253 - acc: 0.2158 - val_loss: 0.7874 - val_acc: 0.2004\n",
      "Epoch 135/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.7112 - acc: 0.2158 - val_loss: 0.7948 - val_acc: 0.2004\n",
      "Epoch 136/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.7485 - acc: 0.2158 - val_loss: 0.8355 - val_acc: 0.2004\n",
      "Epoch 137/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.6394 - acc: 0.2158 - val_loss: 0.9959 - val_acc: 0.2004\n",
      "Epoch 138/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.7029 - acc: 0.2162 - val_loss: 0.8160 - val_acc: 0.2004\n",
      "Epoch 139/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.6086 - acc: 0.2162 - val_loss: 0.8284 - val_acc: 0.2004\n",
      "Epoch 140/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.6146 - acc: 0.2162 - val_loss: 0.8652 - val_acc: 0.2004\n",
      "Epoch 141/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.6425 - acc: 0.2158 - val_loss: 1.0283 - val_acc: 0.2004\n",
      "Epoch 142/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.6990 - acc: 0.2162 - val_loss: 1.0548 - val_acc: 0.2004\n",
      "Epoch 143/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.6651 - acc: 0.2162 - val_loss: 0.7560 - val_acc: 0.2004\n",
      "Epoch 144/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.6382 - acc: 0.2162 - val_loss: 1.0780 - val_acc: 0.1985\n",
      "Epoch 145/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.6084 - acc: 0.2148 - val_loss: 0.7800 - val_acc: 0.2004\n",
      "Epoch 146/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5898 - acc: 0.2162 - val_loss: 0.7935 - val_acc: 0.2004\n",
      "Epoch 147/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.6389 - acc: 0.2153 - val_loss: 0.8685 - val_acc: 0.2004\n",
      "Epoch 148/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.6278 - acc: 0.2158 - val_loss: 0.8409 - val_acc: 0.2004\n",
      "Epoch 149/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.6245 - acc: 0.2153 - val_loss: 0.7799 - val_acc: 0.2004\n",
      "Epoch 150/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.6151 - acc: 0.2153 - val_loss: 0.8246 - val_acc: 0.2004\n",
      "Epoch 151/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5858 - acc: 0.2148 - val_loss: 0.8103 - val_acc: 0.2004\n",
      "Epoch 152/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5939 - acc: 0.2158 - val_loss: 0.7955 - val_acc: 0.2004\n",
      "Epoch 153/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.5895 - acc: 0.2158 - val_loss: 0.8092 - val_acc: 0.2004\n",
      "Epoch 154/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.6454 - acc: 0.2144 - val_loss: 0.7853 - val_acc: 0.2004\n",
      "Epoch 155/4000\n",
      "68/68 [==============================] - 5s 77ms/step - loss: 0.6172 - acc: 0.2158 - val_loss: 1.2081 - val_acc: 0.2004\n",
      "Epoch 156/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.6462 - acc: 0.2158 - val_loss: 0.7554 - val_acc: 0.2004\n",
      "Epoch 157/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.6211 - acc: 0.2158 - val_loss: 0.8813 - val_acc: 0.2004\n",
      "Epoch 158/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5996 - acc: 0.2162 - val_loss: 0.7742 - val_acc: 0.2004\n",
      "Epoch 159/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5680 - acc: 0.2162 - val_loss: 0.7701 - val_acc: 0.2004\n",
      "Epoch 160/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5912 - acc: 0.2153 - val_loss: 0.7667 - val_acc: 0.2004\n",
      "Epoch 161/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5844 - acc: 0.2153 - val_loss: 0.7643 - val_acc: 0.2004\n",
      "Epoch 162/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.6007 - acc: 0.2158 - val_loss: 0.7736 - val_acc: 0.2004\n",
      "Epoch 163/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.6316 - acc: 0.2153 - val_loss: 0.8166 - val_acc: 0.2004\n",
      "Epoch 164/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.6220 - acc: 0.2158 - val_loss: 0.9451 - val_acc: 0.2004\n",
      "Epoch 165/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.6478 - acc: 0.2144 - val_loss: 0.7710 - val_acc: 0.2004\n",
      "Epoch 166/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.5850 - acc: 0.2162 - val_loss: 0.8106 - val_acc: 0.2004\n",
      "Epoch 167/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.6770 - acc: 0.2148 - val_loss: 0.8027 - val_acc: 0.2004\n",
      "Epoch 168/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.5632 - acc: 0.2158 - val_loss: 0.8354 - val_acc: 0.2004\n",
      "Epoch 169/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5741 - acc: 0.2158 - val_loss: 0.7589 - val_acc: 0.2004\n",
      "Epoch 170/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.6202 - acc: 0.2153 - val_loss: 1.0920 - val_acc: 0.2004\n",
      "Epoch 171/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.6166 - acc: 0.2153 - val_loss: 1.0254 - val_acc: 0.1985\n",
      "Epoch 172/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5990 - acc: 0.2158 - val_loss: 0.9630 - val_acc: 0.2004\n",
      "Epoch 173/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.5975 - acc: 0.2148 - val_loss: 0.7465 - val_acc: 0.2004\n",
      "Epoch 174/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5505 - acc: 0.2158 - val_loss: 0.7236 - val_acc: 0.2004\n",
      "Epoch 175/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.5779 - acc: 0.2153 - val_loss: 0.7736 - val_acc: 0.2004\n",
      "Epoch 176/4000\n",
      "68/68 [==============================] - 5s 66ms/step - loss: 0.5934 - acc: 0.2148 - val_loss: 0.9123 - val_acc: 0.2004\n",
      "Epoch 177/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.6224 - acc: 0.2148 - val_loss: 1.1728 - val_acc: 0.2004\n",
      "Epoch 178/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5681 - acc: 0.2158 - val_loss: 0.8319 - val_acc: 0.2004\n",
      "Epoch 179/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5770 - acc: 0.2148 - val_loss: 0.7463 - val_acc: 0.2004\n",
      "Epoch 180/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.5371 - acc: 0.2139 - val_loss: 0.9101 - val_acc: 0.2004\n",
      "Epoch 181/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.5767 - acc: 0.2153 - val_loss: 0.7688 - val_acc: 0.2004\n",
      "Epoch 182/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5643 - acc: 0.2144 - val_loss: 0.8088 - val_acc: 0.2004\n",
      "Epoch 183/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5708 - acc: 0.2153 - val_loss: 0.8710 - val_acc: 0.2004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5378 - acc: 0.2148 - val_loss: 0.8351 - val_acc: 0.2004\n",
      "Epoch 185/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.5264 - acc: 0.2153 - val_loss: 0.7978 - val_acc: 0.2004\n",
      "Epoch 186/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5612 - acc: 0.2153 - val_loss: 0.7622 - val_acc: 0.2004\n",
      "Epoch 187/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5767 - acc: 0.2153 - val_loss: 1.0635 - val_acc: 0.1985\n",
      "Epoch 188/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5889 - acc: 0.2144 - val_loss: 0.7787 - val_acc: 0.2004\n",
      "Epoch 189/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.5276 - acc: 0.2158 - val_loss: 0.7650 - val_acc: 0.2004\n",
      "Epoch 190/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5279 - acc: 0.2148 - val_loss: 0.8949 - val_acc: 0.2004\n",
      "Epoch 191/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.6038 - acc: 0.2153 - val_loss: 0.9055 - val_acc: 0.2004\n",
      "Epoch 192/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5951 - acc: 0.2153 - val_loss: 0.7630 - val_acc: 0.2004\n",
      "Epoch 193/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5460 - acc: 0.2153 - val_loss: 0.8811 - val_acc: 0.2004\n",
      "Epoch 194/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.5548 - acc: 0.2153 - val_loss: 0.7865 - val_acc: 0.2004\n",
      "Epoch 195/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5577 - acc: 0.2139 - val_loss: 0.9052 - val_acc: 0.2004\n",
      "Epoch 196/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5964 - acc: 0.2135 - val_loss: 0.7582 - val_acc: 0.2004\n",
      "Epoch 197/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5233 - acc: 0.2144 - val_loss: 0.8042 - val_acc: 0.2004\n",
      "Epoch 198/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.5431 - acc: 0.2144 - val_loss: 0.8197 - val_acc: 0.2004\n",
      "Epoch 199/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 0.5438 - acc: 0.2148 - val_loss: 0.8090 - val_acc: 0.2004\n",
      "Epoch 200/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5443 - acc: 0.2148 - val_loss: 0.8162 - val_acc: 0.2004\n",
      "Epoch 201/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5361 - acc: 0.2148 - val_loss: 0.8218 - val_acc: 0.2004\n",
      "Epoch 202/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5092 - acc: 0.2148 - val_loss: 1.1894 - val_acc: 0.2004\n",
      "Epoch 203/4000\n",
      "68/68 [==============================] - 5s 70ms/step - loss: 0.5476 - acc: 0.2148 - val_loss: 0.7924 - val_acc: 0.2004\n",
      "Epoch 204/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5397 - acc: 0.2139 - val_loss: 0.7858 - val_acc: 0.2004\n",
      "Epoch 205/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5078 - acc: 0.2148 - val_loss: 0.7508 - val_acc: 0.2004\n",
      "Epoch 206/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4982 - acc: 0.2148 - val_loss: 0.8413 - val_acc: 0.2004\n",
      "Epoch 207/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5949 - acc: 0.2144 - val_loss: 0.8995 - val_acc: 0.2004\n",
      "Epoch 208/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4982 - acc: 0.2148 - val_loss: 0.8570 - val_acc: 0.2004\n",
      "Epoch 209/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5470 - acc: 0.2148 - val_loss: 0.7476 - val_acc: 0.2004\n",
      "Epoch 210/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5551 - acc: 0.2139 - val_loss: 0.8003 - val_acc: 0.2004\n",
      "Epoch 211/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.5053 - acc: 0.2148 - val_loss: 0.8459 - val_acc: 0.2004\n",
      "Epoch 212/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.5201 - acc: 0.2148 - val_loss: 0.7509 - val_acc: 0.2004\n",
      "Epoch 213/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5237 - acc: 0.2158 - val_loss: 0.7748 - val_acc: 0.2004\n",
      "Epoch 214/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5225 - acc: 0.2148 - val_loss: 0.7684 - val_acc: 0.2004\n",
      "Epoch 215/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5022 - acc: 0.2153 - val_loss: 0.7619 - val_acc: 0.2004\n",
      "Epoch 216/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4936 - acc: 0.2148 - val_loss: 0.7886 - val_acc: 0.2004\n",
      "Epoch 217/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.5338 - acc: 0.2148 - val_loss: 0.7476 - val_acc: 0.2004\n",
      "Epoch 218/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5235 - acc: 0.2144 - val_loss: 0.8776 - val_acc: 0.2004\n",
      "Epoch 219/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.4993 - acc: 0.2148 - val_loss: 0.9372 - val_acc: 0.2004\n",
      "Epoch 220/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5261 - acc: 0.2144 - val_loss: 0.8186 - val_acc: 0.2004\n",
      "Epoch 221/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.5123 - acc: 0.2148 - val_loss: 0.8434 - val_acc: 0.2004\n",
      "Epoch 222/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4845 - acc: 0.2153 - val_loss: 0.7580 - val_acc: 0.2004\n",
      "Epoch 223/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5311 - acc: 0.2144 - val_loss: 1.2977 - val_acc: 0.1967\n",
      "Epoch 224/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5503 - acc: 0.2144 - val_loss: 0.8754 - val_acc: 0.2004\n",
      "Epoch 225/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4734 - acc: 0.2144 - val_loss: 0.7870 - val_acc: 0.2004\n",
      "Epoch 226/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4930 - acc: 0.2148 - val_loss: 0.8595 - val_acc: 0.2004\n",
      "Epoch 227/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4770 - acc: 0.2148 - val_loss: 0.8655 - val_acc: 0.2004\n",
      "Epoch 228/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.5031 - acc: 0.2148 - val_loss: 0.7729 - val_acc: 0.2004\n",
      "Epoch 229/4000\n",
      "68/68 [==============================] - 5s 79ms/step - loss: 0.4922 - acc: 0.2144 - val_loss: 0.7848 - val_acc: 0.2004\n",
      "Epoch 230/4000\n",
      "68/68 [==============================] - 5s 71ms/step - loss: 0.5023 - acc: 0.2144 - val_loss: 0.8405 - val_acc: 0.2004\n",
      "Epoch 231/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4898 - acc: 0.2153 - val_loss: 0.8451 - val_acc: 0.2004\n",
      "Epoch 232/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5346 - acc: 0.2135 - val_loss: 0.9273 - val_acc: 0.1985\n",
      "Epoch 233/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5380 - acc: 0.2148 - val_loss: 0.7039 - val_acc: 0.2004\n",
      "Epoch 234/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.7163 - acc: 0.2144 - val_loss: 0.8638 - val_acc: 0.2004\n",
      "Epoch 235/4000\n",
      "68/68 [==============================] - 5s 66ms/step - loss: 0.6956 - acc: 0.2153 - val_loss: 1.1272 - val_acc: 0.1967\n",
      "Epoch 236/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.6499 - acc: 0.2135 - val_loss: 0.9566 - val_acc: 0.2004\n",
      "Epoch 237/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4758 - acc: 0.2148 - val_loss: 0.7444 - val_acc: 0.2004\n",
      "Epoch 238/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4995 - acc: 0.2158 - val_loss: 0.7565 - val_acc: 0.2004\n",
      "Epoch 239/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4712 - acc: 0.2153 - val_loss: 0.8725 - val_acc: 0.2004\n",
      "Epoch 240/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.6083 - acc: 0.2139 - val_loss: 0.9223 - val_acc: 0.2004\n",
      "Epoch 241/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4886 - acc: 0.2144 - val_loss: 0.9002 - val_acc: 0.2004\n",
      "Epoch 242/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.5095 - acc: 0.2153 - val_loss: 0.8604 - val_acc: 0.2004\n",
      "Epoch 243/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4659 - acc: 0.2148 - val_loss: 0.7666 - val_acc: 0.2004\n",
      "Epoch 244/4000\n",
      "68/68 [==============================] - 5s 66ms/step - loss: 0.4774 - acc: 0.2144 - val_loss: 0.7664 - val_acc: 0.2004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4798 - acc: 0.2153 - val_loss: 0.7586 - val_acc: 0.2004\n",
      "Epoch 246/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4772 - acc: 0.2148 - val_loss: 0.8943 - val_acc: 0.2004\n",
      "Epoch 247/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.4892 - acc: 0.2144 - val_loss: 0.7604 - val_acc: 0.2004\n",
      "Epoch 248/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4726 - acc: 0.2148 - val_loss: 0.8495 - val_acc: 0.2004\n",
      "Epoch 249/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4654 - acc: 0.2148 - val_loss: 0.7805 - val_acc: 0.2004\n",
      "Epoch 250/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4567 - acc: 0.2148 - val_loss: 0.9075 - val_acc: 0.2004\n",
      "Epoch 251/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5014 - acc: 0.2148 - val_loss: 0.8294 - val_acc: 0.2004\n",
      "Epoch 252/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.4947 - acc: 0.2148 - val_loss: 0.7611 - val_acc: 0.2004\n",
      "Epoch 253/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.4481 - acc: 0.2148 - val_loss: 0.8223 - val_acc: 0.2004\n",
      "Epoch 254/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4539 - acc: 0.2144 - val_loss: 0.9092 - val_acc: 0.2004\n",
      "Epoch 255/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4876 - acc: 0.2153 - val_loss: 0.7588 - val_acc: 0.2004\n",
      "Epoch 256/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.4816 - acc: 0.2148 - val_loss: 0.7789 - val_acc: 0.2004\n",
      "Epoch 257/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4703 - acc: 0.2144 - val_loss: 0.7814 - val_acc: 0.2004\n",
      "Epoch 258/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.5226 - acc: 0.2144 - val_loss: 0.8256 - val_acc: 0.2004\n",
      "Epoch 259/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.4796 - acc: 0.2153 - val_loss: 0.8073 - val_acc: 0.2004\n",
      "Epoch 260/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4857 - acc: 0.2148 - val_loss: 0.7426 - val_acc: 0.2004\n",
      "Epoch 261/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4467 - acc: 0.2153 - val_loss: 0.8369 - val_acc: 0.2004\n",
      "Epoch 262/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4613 - acc: 0.2139 - val_loss: 0.7797 - val_acc: 0.2004\n",
      "Epoch 263/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.5244 - acc: 0.2153 - val_loss: 0.7984 - val_acc: 0.2004\n",
      "Epoch 264/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4549 - acc: 0.2148 - val_loss: 0.8991 - val_acc: 0.1985\n",
      "Epoch 265/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4876 - acc: 0.2144 - val_loss: 0.7707 - val_acc: 0.2004\n",
      "Epoch 266/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4590 - acc: 0.2148 - val_loss: 1.0707 - val_acc: 0.2004\n",
      "Epoch 267/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4984 - acc: 0.2139 - val_loss: 0.7819 - val_acc: 0.2004\n",
      "Epoch 268/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4752 - acc: 0.2144 - val_loss: 0.7937 - val_acc: 0.2004\n",
      "Epoch 269/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4790 - acc: 0.2144 - val_loss: 0.7987 - val_acc: 0.2004\n",
      "Epoch 270/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.4972 - acc: 0.2148 - val_loss: 0.7838 - val_acc: 0.2004\n",
      "Epoch 271/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4758 - acc: 0.2144 - val_loss: 0.8305 - val_acc: 0.2004\n",
      "Epoch 272/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4805 - acc: 0.2158 - val_loss: 0.7619 - val_acc: 0.2004\n",
      "Epoch 273/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5122 - acc: 0.2139 - val_loss: 0.8422 - val_acc: 0.2004\n",
      "Epoch 274/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4741 - acc: 0.2153 - val_loss: 0.7732 - val_acc: 0.2004\n",
      "Epoch 275/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4799 - acc: 0.2144 - val_loss: 0.8914 - val_acc: 0.2004\n",
      "Epoch 276/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.5017 - acc: 0.2148 - val_loss: 0.7717 - val_acc: 0.2004\n",
      "Epoch 277/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4633 - acc: 0.2153 - val_loss: 0.8773 - val_acc: 0.2004\n",
      "Epoch 278/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4533 - acc: 0.2148 - val_loss: 0.8559 - val_acc: 0.2004\n",
      "Epoch 279/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4293 - acc: 0.2158 - val_loss: 0.8099 - val_acc: 0.2004\n",
      "Epoch 280/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4389 - acc: 0.2148 - val_loss: 0.7808 - val_acc: 0.2004\n",
      "Epoch 281/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4284 - acc: 0.2139 - val_loss: 0.9277 - val_acc: 0.1985\n",
      "Epoch 282/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4660 - acc: 0.2148 - val_loss: 0.9714 - val_acc: 0.1985\n",
      "Epoch 283/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4516 - acc: 0.2158 - val_loss: 0.9016 - val_acc: 0.2004\n",
      "Epoch 284/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.4698 - acc: 0.2139 - val_loss: 0.9756 - val_acc: 0.1985\n",
      "Epoch 285/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4728 - acc: 0.2144 - val_loss: 0.8337 - val_acc: 0.2004\n",
      "Epoch 286/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4711 - acc: 0.2148 - val_loss: 0.8053 - val_acc: 0.2004\n",
      "Epoch 287/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4943 - acc: 0.2135 - val_loss: 1.1919 - val_acc: 0.2004\n",
      "Epoch 288/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5283 - acc: 0.2139 - val_loss: 0.7492 - val_acc: 0.2004\n",
      "Epoch 289/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4092 - acc: 0.2144 - val_loss: 0.7677 - val_acc: 0.2004\n",
      "Epoch 290/4000\n",
      "68/68 [==============================] - 5s 66ms/step - loss: 0.4588 - acc: 0.2148 - val_loss: 0.7978 - val_acc: 0.2004\n",
      "Epoch 291/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4480 - acc: 0.2144 - val_loss: 0.7882 - val_acc: 0.2004\n",
      "Epoch 292/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4167 - acc: 0.2148 - val_loss: 0.8445 - val_acc: 0.2004\n",
      "Epoch 293/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4227 - acc: 0.2144 - val_loss: 0.7708 - val_acc: 0.2004\n",
      "Epoch 294/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5127 - acc: 0.2135 - val_loss: 0.8343 - val_acc: 0.2004\n",
      "Epoch 295/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4303 - acc: 0.2148 - val_loss: 0.8291 - val_acc: 0.2004\n",
      "Epoch 296/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4390 - acc: 0.2144 - val_loss: 0.9712 - val_acc: 0.1985\n",
      "Epoch 297/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4963 - acc: 0.2139 - val_loss: 0.7996 - val_acc: 0.2004\n",
      "Epoch 298/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4394 - acc: 0.2148 - val_loss: 0.8519 - val_acc: 0.1985\n",
      "Epoch 299/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4714 - acc: 0.2144 - val_loss: 0.8488 - val_acc: 0.2004\n",
      "Epoch 300/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4288 - acc: 0.2148 - val_loss: 0.8151 - val_acc: 0.2004\n",
      "Epoch 301/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4301 - acc: 0.2144 - val_loss: 0.8735 - val_acc: 0.1985\n",
      "Epoch 302/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5030 - acc: 0.2139 - val_loss: 0.8284 - val_acc: 0.2004\n",
      "Epoch 303/4000\n",
      "68/68 [==============================] - 5s 72ms/step - loss: 0.4251 - acc: 0.2144 - val_loss: 0.9909 - val_acc: 0.2004\n",
      "Epoch 304/4000\n",
      "68/68 [==============================] - 5s 72ms/step - loss: 0.4639 - acc: 0.2153 - val_loss: 0.8435 - val_acc: 0.2004\n",
      "Epoch 305/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4484 - acc: 0.2139 - val_loss: 0.9529 - val_acc: 0.1985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 306/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4309 - acc: 0.2144 - val_loss: 0.7286 - val_acc: 0.2004\n",
      "Epoch 307/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4953 - acc: 0.2144 - val_loss: 0.8158 - val_acc: 0.2004\n",
      "Epoch 308/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4859 - acc: 0.2139 - val_loss: 0.8647 - val_acc: 0.1985\n",
      "Epoch 309/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4352 - acc: 0.2144 - val_loss: 0.8145 - val_acc: 0.2004\n",
      "Epoch 310/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4316 - acc: 0.2144 - val_loss: 0.8731 - val_acc: 0.2004\n",
      "Epoch 311/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4249 - acc: 0.2148 - val_loss: 0.8800 - val_acc: 0.2004\n",
      "Epoch 312/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4374 - acc: 0.2153 - val_loss: 0.8427 - val_acc: 0.2004\n",
      "Epoch 313/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4441 - acc: 0.2144 - val_loss: 0.9221 - val_acc: 0.2004\n",
      "Epoch 314/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4135 - acc: 0.2153 - val_loss: 1.1124 - val_acc: 0.2004\n",
      "Epoch 315/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4281 - acc: 0.2148 - val_loss: 0.8290 - val_acc: 0.2004\n",
      "Epoch 316/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4223 - acc: 0.2144 - val_loss: 0.7664 - val_acc: 0.2004\n",
      "Epoch 317/4000\n",
      "68/68 [==============================] - 6s 91ms/step - loss: 0.4017 - acc: 0.2144 - val_loss: 0.9269 - val_acc: 0.2004\n",
      "Epoch 318/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4333 - acc: 0.2139 - val_loss: 0.8864 - val_acc: 0.2004\n",
      "Epoch 319/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4478 - acc: 0.2158 - val_loss: 0.8354 - val_acc: 0.2004\n",
      "Epoch 320/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4348 - acc: 0.2135 - val_loss: 0.8528 - val_acc: 0.2004\n",
      "Epoch 321/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.5124 - acc: 0.2130 - val_loss: 0.8630 - val_acc: 0.2004\n",
      "Epoch 322/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.5416 - acc: 0.2153 - val_loss: 0.8200 - val_acc: 0.2004\n",
      "Epoch 323/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.4985 - acc: 0.2148 - val_loss: 0.8295 - val_acc: 0.2004\n",
      "Epoch 324/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4143 - acc: 0.2148 - val_loss: 0.7616 - val_acc: 0.2004\n",
      "Epoch 325/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4120 - acc: 0.2144 - val_loss: 0.8899 - val_acc: 0.2004\n",
      "Epoch 326/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.4623 - acc: 0.2139 - val_loss: 0.9085 - val_acc: 0.1985\n",
      "Epoch 327/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4068 - acc: 0.2144 - val_loss: 0.7983 - val_acc: 0.2004\n",
      "Epoch 328/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3895 - acc: 0.2144 - val_loss: 0.7477 - val_acc: 0.2004\n",
      "Epoch 329/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4162 - acc: 0.2148 - val_loss: 0.7903 - val_acc: 0.2004\n",
      "Epoch 330/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4297 - acc: 0.2144 - val_loss: 0.7589 - val_acc: 0.2004\n",
      "Epoch 331/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4181 - acc: 0.2144 - val_loss: 0.8019 - val_acc: 0.2004\n",
      "Epoch 332/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3910 - acc: 0.2153 - val_loss: 0.8004 - val_acc: 0.2004\n",
      "Epoch 333/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4062 - acc: 0.2130 - val_loss: 0.8033 - val_acc: 0.2004\n",
      "Epoch 334/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.4094 - acc: 0.2139 - val_loss: 0.8459 - val_acc: 0.1985\n",
      "Epoch 335/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4121 - acc: 0.2148 - val_loss: 0.8612 - val_acc: 0.2004\n",
      "Epoch 336/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4091 - acc: 0.2144 - val_loss: 0.7701 - val_acc: 0.2004\n",
      "Epoch 337/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.4477 - acc: 0.2148 - val_loss: 1.0159 - val_acc: 0.2004\n",
      "Epoch 338/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4340 - acc: 0.2148 - val_loss: 0.8199 - val_acc: 0.1985\n",
      "Epoch 339/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.4089 - acc: 0.2148 - val_loss: 0.8189 - val_acc: 0.2004\n",
      "Epoch 340/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4309 - acc: 0.2144 - val_loss: 0.7414 - val_acc: 0.2004\n",
      "Epoch 341/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4675 - acc: 0.2148 - val_loss: 0.9900 - val_acc: 0.2004\n",
      "Epoch 342/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.6735 - acc: 0.2144 - val_loss: 1.5813 - val_acc: 0.2004\n",
      "Epoch 343/4000\n",
      "68/68 [==============================] - 6s 86ms/step - loss: 1.7624 - acc: 0.2125 - val_loss: 1.6051 - val_acc: 0.2004\n",
      "Epoch 344/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 0.7796 - acc: 0.2148 - val_loss: 0.8392 - val_acc: 0.2004\n",
      "Epoch 345/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.6803 - acc: 0.2158 - val_loss: 0.8741 - val_acc: 0.2004\n",
      "Epoch 346/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4554 - acc: 0.2153 - val_loss: 0.9792 - val_acc: 0.1985\n",
      "Epoch 347/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4229 - acc: 0.2153 - val_loss: 0.7647 - val_acc: 0.2004\n",
      "Epoch 348/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3957 - acc: 0.2158 - val_loss: 0.8431 - val_acc: 0.1985\n",
      "Epoch 349/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4091 - acc: 0.2153 - val_loss: 0.7712 - val_acc: 0.2004\n",
      "Epoch 350/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4112 - acc: 0.2148 - val_loss: 0.7761 - val_acc: 0.2004\n",
      "Epoch 351/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3805 - acc: 0.2148 - val_loss: 0.7873 - val_acc: 0.2004\n",
      "Epoch 352/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3951 - acc: 0.2148 - val_loss: 0.7888 - val_acc: 0.2004\n",
      "Epoch 353/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3999 - acc: 0.2144 - val_loss: 0.7780 - val_acc: 0.2004\n",
      "Epoch 354/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3931 - acc: 0.2158 - val_loss: 0.7856 - val_acc: 0.2004\n",
      "Epoch 355/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3999 - acc: 0.2139 - val_loss: 0.7787 - val_acc: 0.2004\n",
      "Epoch 356/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3942 - acc: 0.2144 - val_loss: 0.7958 - val_acc: 0.2004\n",
      "Epoch 357/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3833 - acc: 0.2144 - val_loss: 0.8051 - val_acc: 0.1985\n",
      "Epoch 358/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3782 - acc: 0.2153 - val_loss: 0.7968 - val_acc: 0.2004\n",
      "Epoch 359/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4336 - acc: 0.2148 - val_loss: 1.0936 - val_acc: 0.1985\n",
      "Epoch 360/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.4604 - acc: 0.2148 - val_loss: 0.8225 - val_acc: 0.2004\n",
      "Epoch 361/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3797 - acc: 0.2144 - val_loss: 0.8291 - val_acc: 0.2004\n",
      "Epoch 362/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3990 - acc: 0.2153 - val_loss: 0.8060 - val_acc: 0.2004\n",
      "Epoch 363/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4111 - acc: 0.2148 - val_loss: 0.7983 - val_acc: 0.2004\n",
      "Epoch 364/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3907 - acc: 0.2153 - val_loss: 0.9189 - val_acc: 0.1985\n",
      "Epoch 365/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3949 - acc: 0.2144 - val_loss: 0.8338 - val_acc: 0.2004\n",
      "Epoch 366/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3838 - acc: 0.2148 - val_loss: 0.8332 - val_acc: 0.1985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4217 - acc: 0.2139 - val_loss: 0.7729 - val_acc: 0.2004\n",
      "Epoch 368/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3804 - acc: 0.2144 - val_loss: 0.7984 - val_acc: 0.2004\n",
      "Epoch 369/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.4038 - acc: 0.2148 - val_loss: 0.7856 - val_acc: 0.2004\n",
      "Epoch 370/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3857 - acc: 0.2153 - val_loss: 0.8648 - val_acc: 0.2004\n",
      "Epoch 371/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4260 - acc: 0.2148 - val_loss: 0.9972 - val_acc: 0.2004\n",
      "Epoch 372/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4525 - acc: 0.2135 - val_loss: 0.8863 - val_acc: 0.2004\n",
      "Epoch 373/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4089 - acc: 0.2144 - val_loss: 0.8392 - val_acc: 0.2004\n",
      "Epoch 374/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4267 - acc: 0.2148 - val_loss: 0.8598 - val_acc: 0.2004\n",
      "Epoch 375/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4061 - acc: 0.2144 - val_loss: 0.8288 - val_acc: 0.2004\n",
      "Epoch 376/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4347 - acc: 0.2144 - val_loss: 0.7566 - val_acc: 0.2004\n",
      "Epoch 377/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.4229 - acc: 0.2153 - val_loss: 0.8205 - val_acc: 0.2004\n",
      "Epoch 378/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4026 - acc: 0.2130 - val_loss: 0.8723 - val_acc: 0.2004\n",
      "Epoch 379/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3739 - acc: 0.2139 - val_loss: 0.8064 - val_acc: 0.2004\n",
      "Epoch 380/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3932 - acc: 0.2148 - val_loss: 1.0040 - val_acc: 0.2004\n",
      "Epoch 381/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 0.3794 - acc: 0.2144 - val_loss: 0.8528 - val_acc: 0.2004\n",
      "Epoch 382/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4088 - acc: 0.2148 - val_loss: 0.8450 - val_acc: 0.2004\n",
      "Epoch 383/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4045 - acc: 0.2148 - val_loss: 1.0113 - val_acc: 0.2004\n",
      "Epoch 384/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3798 - acc: 0.2144 - val_loss: 0.7754 - val_acc: 0.2004\n",
      "Epoch 385/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.4093 - acc: 0.2153 - val_loss: 1.0413 - val_acc: 0.1985\n",
      "Epoch 386/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.4340 - acc: 0.2139 - val_loss: 0.7782 - val_acc: 0.2004\n",
      "Epoch 387/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3817 - acc: 0.2148 - val_loss: 0.8470 - val_acc: 0.1985\n",
      "Epoch 388/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4062 - acc: 0.2148 - val_loss: 0.8696 - val_acc: 0.2004\n",
      "Epoch 389/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4113 - acc: 0.2139 - val_loss: 0.8124 - val_acc: 0.2004\n",
      "Epoch 390/4000\n",
      "68/68 [==============================] - 6s 83ms/step - loss: 0.3724 - acc: 0.2144 - val_loss: 0.7756 - val_acc: 0.2004\n",
      "Epoch 391/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.4313 - acc: 0.2148 - val_loss: 0.8731 - val_acc: 0.1985\n",
      "Epoch 392/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3887 - acc: 0.2148 - val_loss: 0.7739 - val_acc: 0.2004\n",
      "Epoch 393/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3886 - acc: 0.2139 - val_loss: 0.7930 - val_acc: 0.1985\n",
      "Epoch 394/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4394 - acc: 0.2148 - val_loss: 0.9903 - val_acc: 0.2004\n",
      "Epoch 395/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3974 - acc: 0.2148 - val_loss: 0.7674 - val_acc: 0.2004\n",
      "Epoch 396/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4182 - acc: 0.2144 - val_loss: 0.7931 - val_acc: 0.2004\n",
      "Epoch 397/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3650 - acc: 0.2144 - val_loss: 0.8054 - val_acc: 0.1985\n",
      "Epoch 398/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3988 - acc: 0.2144 - val_loss: 0.8315 - val_acc: 0.1985\n",
      "Epoch 399/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3939 - acc: 0.2144 - val_loss: 0.8025 - val_acc: 0.2004\n",
      "Epoch 400/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3668 - acc: 0.2153 - val_loss: 0.8528 - val_acc: 0.2004\n",
      "Epoch 401/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3925 - acc: 0.2153 - val_loss: 0.7793 - val_acc: 0.2004\n",
      "Epoch 402/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3728 - acc: 0.2153 - val_loss: 0.8422 - val_acc: 0.2004\n",
      "Epoch 403/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3861 - acc: 0.2148 - val_loss: 1.0959 - val_acc: 0.2004\n",
      "Epoch 404/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4831 - acc: 0.2130 - val_loss: 0.8438 - val_acc: 0.2004\n",
      "Epoch 405/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3975 - acc: 0.2148 - val_loss: 0.8123 - val_acc: 0.2004\n",
      "Epoch 406/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3707 - acc: 0.2153 - val_loss: 0.7981 - val_acc: 0.2004\n",
      "Epoch 407/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3692 - acc: 0.2139 - val_loss: 0.7964 - val_acc: 0.2004\n",
      "Epoch 408/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3775 - acc: 0.2148 - val_loss: 0.7928 - val_acc: 0.2004\n",
      "Epoch 409/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4090 - acc: 0.2139 - val_loss: 0.8246 - val_acc: 0.2004\n",
      "Epoch 410/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3706 - acc: 0.2153 - val_loss: 0.9030 - val_acc: 0.2004\n",
      "Epoch 411/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3942 - acc: 0.2148 - val_loss: 0.8335 - val_acc: 0.2004\n",
      "Epoch 412/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3728 - acc: 0.2144 - val_loss: 0.7731 - val_acc: 0.2004\n",
      "Epoch 413/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3782 - acc: 0.2144 - val_loss: 0.9492 - val_acc: 0.1985\n",
      "Epoch 414/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.4706 - acc: 0.2148 - val_loss: 0.8581 - val_acc: 0.1985\n",
      "Epoch 415/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.4142 - acc: 0.2148 - val_loss: 0.7939 - val_acc: 0.2004\n",
      "Epoch 416/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3821 - acc: 0.2148 - val_loss: 0.8276 - val_acc: 0.2004\n",
      "Epoch 417/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4259 - acc: 0.2144 - val_loss: 1.0374 - val_acc: 0.2004\n",
      "Epoch 418/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4260 - acc: 0.2144 - val_loss: 0.8409 - val_acc: 0.1985\n",
      "Epoch 419/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3990 - acc: 0.2153 - val_loss: 0.9790 - val_acc: 0.1985\n",
      "Epoch 420/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3988 - acc: 0.2139 - val_loss: 0.8577 - val_acc: 0.2004\n",
      "Epoch 421/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3703 - acc: 0.2139 - val_loss: 0.8147 - val_acc: 0.2004\n",
      "Epoch 422/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3739 - acc: 0.2153 - val_loss: 0.8014 - val_acc: 0.1985\n",
      "Epoch 423/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3775 - acc: 0.2139 - val_loss: 0.9510 - val_acc: 0.2004\n",
      "Epoch 424/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3680 - acc: 0.2144 - val_loss: 0.8259 - val_acc: 0.1985\n",
      "Epoch 425/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3717 - acc: 0.2148 - val_loss: 0.7825 - val_acc: 0.2004\n",
      "Epoch 426/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.3611 - acc: 0.2135 - val_loss: 0.8429 - val_acc: 0.2004\n",
      "Epoch 427/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3657 - acc: 0.2162 - val_loss: 0.7941 - val_acc: 0.2004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 428/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3606 - acc: 0.2139 - val_loss: 0.9401 - val_acc: 0.1985\n",
      "Epoch 429/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4619 - acc: 0.2144 - val_loss: 0.8976 - val_acc: 0.2004\n",
      "Epoch 430/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.6286 - acc: 0.2144 - val_loss: 0.8928 - val_acc: 0.1985\n",
      "Epoch 431/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.9151 - acc: 0.2139 - val_loss: 1.3437 - val_acc: 0.2004\n",
      "Epoch 432/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 1.1105 - acc: 0.2107 - val_loss: 0.8755 - val_acc: 0.2004\n",
      "Epoch 433/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.5649 - acc: 0.2162 - val_loss: 0.9790 - val_acc: 0.2004\n",
      "Epoch 434/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.6566 - acc: 0.2144 - val_loss: 1.0227 - val_acc: 0.2004\n",
      "Epoch 435/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4451 - acc: 0.2153 - val_loss: 0.6989 - val_acc: 0.2004\n",
      "Epoch 436/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3711 - acc: 0.2153 - val_loss: 0.7782 - val_acc: 0.2004\n",
      "Epoch 437/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3651 - acc: 0.2144 - val_loss: 0.9653 - val_acc: 0.2004\n",
      "Epoch 438/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3955 - acc: 0.2153 - val_loss: 0.7565 - val_acc: 0.2004\n",
      "Epoch 439/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3603 - acc: 0.2139 - val_loss: 0.7901 - val_acc: 0.2004\n",
      "Epoch 440/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3705 - acc: 0.2144 - val_loss: 0.7623 - val_acc: 0.2004\n",
      "Epoch 441/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4604 - acc: 0.2148 - val_loss: 1.0095 - val_acc: 0.1985\n",
      "Epoch 442/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3634 - acc: 0.2148 - val_loss: 0.7760 - val_acc: 0.2004\n",
      "Epoch 443/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3637 - acc: 0.2144 - val_loss: 0.8290 - val_acc: 0.2004\n",
      "Epoch 444/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3547 - acc: 0.2158 - val_loss: 0.7588 - val_acc: 0.2004\n",
      "Epoch 445/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3483 - acc: 0.2153 - val_loss: 0.7738 - val_acc: 0.2004\n",
      "Epoch 446/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3670 - acc: 0.2144 - val_loss: 0.7602 - val_acc: 0.2004\n",
      "Epoch 447/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3714 - acc: 0.2139 - val_loss: 0.8218 - val_acc: 0.1985\n",
      "Epoch 448/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3795 - acc: 0.2144 - val_loss: 0.7777 - val_acc: 0.2004\n",
      "Epoch 449/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3585 - acc: 0.2153 - val_loss: 0.7463 - val_acc: 0.2004\n",
      "Epoch 450/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4076 - acc: 0.2148 - val_loss: 0.9391 - val_acc: 0.1985\n",
      "Epoch 451/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4171 - acc: 0.2148 - val_loss: 0.8282 - val_acc: 0.2004\n",
      "Epoch 452/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3607 - acc: 0.2153 - val_loss: 0.7692 - val_acc: 0.2004\n",
      "Epoch 453/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3874 - acc: 0.2162 - val_loss: 0.7900 - val_acc: 0.2004\n",
      "Epoch 454/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3753 - acc: 0.2144 - val_loss: 0.8902 - val_acc: 0.1985\n",
      "Epoch 455/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3539 - acc: 0.2148 - val_loss: 0.7598 - val_acc: 0.2004\n",
      "Epoch 456/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3642 - acc: 0.2139 - val_loss: 0.8105 - val_acc: 0.2004\n",
      "Epoch 457/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3592 - acc: 0.2153 - val_loss: 0.7797 - val_acc: 0.2004\n",
      "Epoch 458/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3568 - acc: 0.2148 - val_loss: 0.7615 - val_acc: 0.2004\n",
      "Epoch 459/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3517 - acc: 0.2153 - val_loss: 0.7962 - val_acc: 0.2004\n",
      "Epoch 460/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3429 - acc: 0.2139 - val_loss: 0.7736 - val_acc: 0.1985\n",
      "Epoch 461/4000\n",
      "68/68 [==============================] - 5s 74ms/step - loss: 0.3506 - acc: 0.2148 - val_loss: 0.7871 - val_acc: 0.2004\n",
      "Epoch 462/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3640 - acc: 0.2148 - val_loss: 0.7809 - val_acc: 0.2004\n",
      "Epoch 463/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3629 - acc: 0.2148 - val_loss: 0.8064 - val_acc: 0.1985\n",
      "Epoch 464/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3767 - acc: 0.2144 - val_loss: 0.7857 - val_acc: 0.2004\n",
      "Epoch 465/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3431 - acc: 0.2139 - val_loss: 0.7812 - val_acc: 0.2004\n",
      "Epoch 466/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3545 - acc: 0.2148 - val_loss: 0.8374 - val_acc: 0.1985\n",
      "Epoch 467/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3741 - acc: 0.2148 - val_loss: 0.8684 - val_acc: 0.1985\n",
      "Epoch 468/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3733 - acc: 0.2148 - val_loss: 0.8263 - val_acc: 0.2004\n",
      "Epoch 469/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3987 - acc: 0.2148 - val_loss: 0.8173 - val_acc: 0.1985\n",
      "Epoch 470/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3681 - acc: 0.2139 - val_loss: 0.9278 - val_acc: 0.2004\n",
      "Epoch 471/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3651 - acc: 0.2144 - val_loss: 0.8920 - val_acc: 0.1985\n",
      "Epoch 472/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3978 - acc: 0.2162 - val_loss: 0.8120 - val_acc: 0.1985\n",
      "Epoch 473/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3396 - acc: 0.2144 - val_loss: 0.8128 - val_acc: 0.1985\n",
      "Epoch 474/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3688 - acc: 0.2153 - val_loss: 0.9304 - val_acc: 0.1985\n",
      "Epoch 475/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4054 - acc: 0.2158 - val_loss: 0.8348 - val_acc: 0.1985\n",
      "Epoch 476/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3707 - acc: 0.2148 - val_loss: 0.8082 - val_acc: 0.2004\n",
      "Epoch 477/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3743 - acc: 0.2148 - val_loss: 0.8198 - val_acc: 0.1985\n",
      "Epoch 478/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3552 - acc: 0.2135 - val_loss: 0.8108 - val_acc: 0.2004\n",
      "Epoch 479/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3467 - acc: 0.2144 - val_loss: 0.9007 - val_acc: 0.1985\n",
      "Epoch 480/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3441 - acc: 0.2153 - val_loss: 0.8877 - val_acc: 0.1985\n",
      "Epoch 481/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3646 - acc: 0.2148 - val_loss: 0.7604 - val_acc: 0.2004\n",
      "Epoch 482/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3479 - acc: 0.2148 - val_loss: 0.8299 - val_acc: 0.2004\n",
      "Epoch 483/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3870 - acc: 0.2148 - val_loss: 0.7788 - val_acc: 0.2004\n",
      "Epoch 484/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3564 - acc: 0.2148 - val_loss: 0.9076 - val_acc: 0.2004\n",
      "Epoch 485/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3440 - acc: 0.2148 - val_loss: 0.7815 - val_acc: 0.1985\n",
      "Epoch 486/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3555 - acc: 0.2148 - val_loss: 0.8075 - val_acc: 0.1985\n",
      "Epoch 487/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3346 - acc: 0.2148 - val_loss: 0.7955 - val_acc: 0.2004\n",
      "Epoch 488/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3919 - acc: 0.2135 - val_loss: 0.7970 - val_acc: 0.2004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 489/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3539 - acc: 0.2148 - val_loss: 0.7684 - val_acc: 0.1985\n",
      "Epoch 490/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3750 - acc: 0.2148 - val_loss: 0.8512 - val_acc: 0.1985\n",
      "Epoch 491/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3476 - acc: 0.2153 - val_loss: 0.7866 - val_acc: 0.1985\n",
      "Epoch 492/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4326 - acc: 0.2135 - val_loss: 0.8629 - val_acc: 0.1985\n",
      "Epoch 493/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3611 - acc: 0.2153 - val_loss: 0.7509 - val_acc: 0.2004\n",
      "Epoch 494/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3377 - acc: 0.2148 - val_loss: 0.8514 - val_acc: 0.2004\n",
      "Epoch 495/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3370 - acc: 0.2139 - val_loss: 0.8107 - val_acc: 0.1985\n",
      "Epoch 496/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3305 - acc: 0.2144 - val_loss: 0.7740 - val_acc: 0.2004\n",
      "Epoch 497/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3330 - acc: 0.2148 - val_loss: 0.7875 - val_acc: 0.2004\n",
      "Epoch 498/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3280 - acc: 0.2144 - val_loss: 1.0575 - val_acc: 0.1985\n",
      "Epoch 499/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3686 - acc: 0.2148 - val_loss: 0.8444 - val_acc: 0.2004\n",
      "Epoch 500/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3587 - acc: 0.2148 - val_loss: 0.7512 - val_acc: 0.2004\n",
      "Epoch 501/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3524 - acc: 0.2144 - val_loss: 0.7640 - val_acc: 0.2004\n",
      "Epoch 502/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3532 - acc: 0.2144 - val_loss: 0.7821 - val_acc: 0.1985\n",
      "Epoch 503/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3633 - acc: 0.2148 - val_loss: 0.7860 - val_acc: 0.1985\n",
      "Epoch 504/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3934 - acc: 0.2158 - val_loss: 0.9422 - val_acc: 0.1985\n",
      "Epoch 505/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3843 - acc: 0.2153 - val_loss: 0.7734 - val_acc: 0.1985\n",
      "Epoch 506/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3400 - acc: 0.2139 - val_loss: 0.8575 - val_acc: 0.2004\n",
      "Epoch 507/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3859 - acc: 0.2148 - val_loss: 0.7182 - val_acc: 0.2004\n",
      "Epoch 508/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3590 - acc: 0.2148 - val_loss: 0.8715 - val_acc: 0.1985\n",
      "Epoch 509/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3456 - acc: 0.2144 - val_loss: 0.7898 - val_acc: 0.2004\n",
      "Epoch 510/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3432 - acc: 0.2153 - val_loss: 0.7821 - val_acc: 0.1985\n",
      "Epoch 511/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3213 - acc: 0.2144 - val_loss: 0.8222 - val_acc: 0.1985\n",
      "Epoch 512/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3411 - acc: 0.2148 - val_loss: 0.8069 - val_acc: 0.1985\n",
      "Epoch 513/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3564 - acc: 0.2158 - val_loss: 0.7929 - val_acc: 0.2004\n",
      "Epoch 514/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3666 - acc: 0.2144 - val_loss: 0.7804 - val_acc: 0.1985\n",
      "Epoch 515/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3456 - acc: 0.2148 - val_loss: 0.7849 - val_acc: 0.2004\n",
      "Epoch 516/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3705 - acc: 0.2153 - val_loss: 0.8811 - val_acc: 0.2004\n",
      "Epoch 517/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3469 - acc: 0.2139 - val_loss: 0.8149 - val_acc: 0.2004\n",
      "Epoch 518/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3566 - acc: 0.2148 - val_loss: 1.0245 - val_acc: 0.1985\n",
      "Epoch 519/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3492 - acc: 0.2139 - val_loss: 0.7774 - val_acc: 0.2004\n",
      "Epoch 520/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.4042 - acc: 0.2148 - val_loss: 1.2033 - val_acc: 0.2004\n",
      "Epoch 521/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4402 - acc: 0.2139 - val_loss: 0.8402 - val_acc: 0.1985\n",
      "Epoch 522/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3748 - acc: 0.2144 - val_loss: 0.7586 - val_acc: 0.2004\n",
      "Epoch 523/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3926 - acc: 0.2148 - val_loss: 0.8236 - val_acc: 0.2004\n",
      "Epoch 524/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3569 - acc: 0.2144 - val_loss: 0.9119 - val_acc: 0.1985\n",
      "Epoch 525/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3591 - acc: 0.2148 - val_loss: 0.7409 - val_acc: 0.2004\n",
      "Epoch 526/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3607 - acc: 0.2153 - val_loss: 0.7877 - val_acc: 0.2004\n",
      "Epoch 527/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3343 - acc: 0.2148 - val_loss: 0.8167 - val_acc: 0.1985\n",
      "Epoch 528/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3622 - acc: 0.2148 - val_loss: 0.7375 - val_acc: 0.2004\n",
      "Epoch 529/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3468 - acc: 0.2153 - val_loss: 0.8081 - val_acc: 0.2004\n",
      "Epoch 530/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3195 - acc: 0.2148 - val_loss: 0.7697 - val_acc: 0.2004\n",
      "Epoch 531/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3745 - acc: 0.2153 - val_loss: 0.8420 - val_acc: 0.2004\n",
      "Epoch 532/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3320 - acc: 0.2153 - val_loss: 0.7919 - val_acc: 0.2004\n",
      "Epoch 533/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3336 - acc: 0.2148 - val_loss: 0.8168 - val_acc: 0.2004\n",
      "Epoch 534/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4285 - acc: 0.2144 - val_loss: 1.4562 - val_acc: 0.2004\n",
      "Epoch 535/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3754 - acc: 0.2144 - val_loss: 0.8003 - val_acc: 0.1985\n",
      "Epoch 536/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3615 - acc: 0.2153 - val_loss: 0.7932 - val_acc: 0.2004\n",
      "Epoch 537/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3785 - acc: 0.2148 - val_loss: 0.7437 - val_acc: 0.2004\n",
      "Epoch 538/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4375 - acc: 0.2130 - val_loss: 0.9007 - val_acc: 0.1985\n",
      "Epoch 539/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3423 - acc: 0.2139 - val_loss: 0.8521 - val_acc: 0.2004\n",
      "Epoch 540/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3862 - acc: 0.2148 - val_loss: 0.9743 - val_acc: 0.2004\n",
      "Epoch 541/4000\n",
      "68/68 [==============================] - 5s 69ms/step - loss: 0.3404 - acc: 0.2153 - val_loss: 0.8006 - val_acc: 0.1985\n",
      "Epoch 542/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.3439 - acc: 0.2135 - val_loss: 1.1208 - val_acc: 0.1985\n",
      "Epoch 543/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3705 - acc: 0.2135 - val_loss: 0.7401 - val_acc: 0.1985\n",
      "Epoch 544/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3292 - acc: 0.2144 - val_loss: 0.7908 - val_acc: 0.1985\n",
      "Epoch 545/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3493 - acc: 0.2144 - val_loss: 0.7711 - val_acc: 0.1985\n",
      "Epoch 546/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3216 - acc: 0.2139 - val_loss: 0.7682 - val_acc: 0.2004\n",
      "Epoch 547/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3447 - acc: 0.2158 - val_loss: 0.7487 - val_acc: 0.2004\n",
      "Epoch 548/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3309 - acc: 0.2158 - val_loss: 0.8265 - val_acc: 0.2004\n",
      "Epoch 549/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3282 - acc: 0.2158 - val_loss: 0.8484 - val_acc: 0.2004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 550/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3313 - acc: 0.2153 - val_loss: 0.7517 - val_acc: 0.2004\n",
      "Epoch 551/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3240 - acc: 0.2139 - val_loss: 0.7899 - val_acc: 0.2004\n",
      "Epoch 552/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3576 - acc: 0.2148 - val_loss: 0.9727 - val_acc: 0.1985\n",
      "Epoch 553/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3194 - acc: 0.2158 - val_loss: 0.7633 - val_acc: 0.1985\n",
      "Epoch 554/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3238 - acc: 0.2148 - val_loss: 0.7573 - val_acc: 0.2004\n",
      "Epoch 555/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3322 - acc: 0.2153 - val_loss: 0.7606 - val_acc: 0.2004\n",
      "Epoch 556/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3450 - acc: 0.2158 - val_loss: 0.9342 - val_acc: 0.1985\n",
      "Epoch 557/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3626 - acc: 0.2139 - val_loss: 0.7154 - val_acc: 0.2004\n",
      "Epoch 558/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.7276 - acc: 0.2144 - val_loss: 1.3270 - val_acc: 0.2004\n",
      "Epoch 559/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.7287 - acc: 0.2153 - val_loss: 0.8311 - val_acc: 0.1985\n",
      "Epoch 560/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.9804 - acc: 0.2097 - val_loss: 0.7930 - val_acc: 0.2004\n",
      "Epoch 561/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4815 - acc: 0.2162 - val_loss: 0.9697 - val_acc: 0.2004\n",
      "Epoch 562/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4203 - acc: 0.2148 - val_loss: 0.7198 - val_acc: 0.2004\n",
      "Epoch 563/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3474 - acc: 0.2153 - val_loss: 0.7486 - val_acc: 0.2004\n",
      "Epoch 564/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3251 - acc: 0.2144 - val_loss: 0.7211 - val_acc: 0.2004\n",
      "Epoch 565/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3340 - acc: 0.2144 - val_loss: 1.0753 - val_acc: 0.2004\n",
      "Epoch 566/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3593 - acc: 0.2153 - val_loss: 0.7883 - val_acc: 0.1985\n",
      "Epoch 567/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3317 - acc: 0.2153 - val_loss: 0.8136 - val_acc: 0.2004\n",
      "Epoch 568/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3339 - acc: 0.2148 - val_loss: 0.8497 - val_acc: 0.1985\n",
      "Epoch 569/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3646 - acc: 0.2153 - val_loss: 0.7341 - val_acc: 0.2004\n",
      "Epoch 570/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3391 - acc: 0.2153 - val_loss: 0.7447 - val_acc: 0.2004\n",
      "Epoch 571/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3477 - acc: 0.2144 - val_loss: 0.7568 - val_acc: 0.2004\n",
      "Epoch 572/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3465 - acc: 0.2153 - val_loss: 0.8763 - val_acc: 0.2004\n",
      "Epoch 573/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3378 - acc: 0.2158 - val_loss: 0.7727 - val_acc: 0.1985\n",
      "Epoch 574/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3271 - acc: 0.2158 - val_loss: 0.8405 - val_acc: 0.2004\n",
      "Epoch 575/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3224 - acc: 0.2158 - val_loss: 0.7802 - val_acc: 0.1985\n",
      "Epoch 576/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3453 - acc: 0.2144 - val_loss: 0.7818 - val_acc: 0.2004\n",
      "Epoch 577/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3828 - acc: 0.2144 - val_loss: 0.7850 - val_acc: 0.1985\n",
      "Epoch 578/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3206 - acc: 0.2153 - val_loss: 0.7643 - val_acc: 0.1985\n",
      "Epoch 579/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3689 - acc: 0.2144 - val_loss: 0.8623 - val_acc: 0.1985\n",
      "Epoch 580/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3701 - acc: 0.2144 - val_loss: 0.7828 - val_acc: 0.2004\n",
      "Epoch 581/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3334 - acc: 0.2153 - val_loss: 0.7603 - val_acc: 0.2004\n",
      "Epoch 582/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3377 - acc: 0.2139 - val_loss: 0.7657 - val_acc: 0.2004\n",
      "Epoch 583/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3256 - acc: 0.2153 - val_loss: 0.7491 - val_acc: 0.2004\n",
      "Epoch 584/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3113 - acc: 0.2158 - val_loss: 0.7308 - val_acc: 0.2004\n",
      "Epoch 585/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3148 - acc: 0.2158 - val_loss: 0.7827 - val_acc: 0.1985\n",
      "Epoch 586/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3121 - acc: 0.2148 - val_loss: 0.7487 - val_acc: 0.2004\n",
      "Epoch 587/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3215 - acc: 0.2153 - val_loss: 0.8560 - val_acc: 0.1985\n",
      "Epoch 588/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3412 - acc: 0.2158 - val_loss: 0.7527 - val_acc: 0.2004\n",
      "Epoch 589/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3256 - acc: 0.2153 - val_loss: 0.7849 - val_acc: 0.2004\n",
      "Epoch 590/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.3213 - acc: 0.2144 - val_loss: 0.7852 - val_acc: 0.2004\n",
      "Epoch 591/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3200 - acc: 0.2148 - val_loss: 0.7917 - val_acc: 0.2004\n",
      "Epoch 592/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4658 - acc: 0.2135 - val_loss: 0.9539 - val_acc: 0.2004\n",
      "Epoch 593/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3555 - acc: 0.2144 - val_loss: 0.7576 - val_acc: 0.2004\n",
      "Epoch 594/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3340 - acc: 0.2148 - val_loss: 0.9621 - val_acc: 0.1985\n",
      "Epoch 595/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3219 - acc: 0.2158 - val_loss: 0.7733 - val_acc: 0.2004\n",
      "Epoch 596/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3054 - acc: 0.2158 - val_loss: 0.8199 - val_acc: 0.1985\n",
      "Epoch 597/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3090 - acc: 0.2158 - val_loss: 0.8013 - val_acc: 0.2004\n",
      "Epoch 598/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3115 - acc: 0.2148 - val_loss: 0.7546 - val_acc: 0.2004\n",
      "Epoch 599/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3003 - acc: 0.2153 - val_loss: 0.8521 - val_acc: 0.1985\n",
      "Epoch 600/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.3614 - acc: 0.2144 - val_loss: 0.9254 - val_acc: 0.1985\n",
      "Epoch 601/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3336 - acc: 0.2144 - val_loss: 0.7808 - val_acc: 0.2004\n",
      "Epoch 602/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3136 - acc: 0.2158 - val_loss: 0.7364 - val_acc: 0.2004\n",
      "Epoch 603/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3237 - acc: 0.2148 - val_loss: 0.7407 - val_acc: 0.2004\n",
      "Epoch 604/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3415 - acc: 0.2153 - val_loss: 0.9593 - val_acc: 0.2004\n",
      "Epoch 605/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.4279 - acc: 0.2139 - val_loss: 0.7969 - val_acc: 0.2004\n",
      "Epoch 606/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3733 - acc: 0.2148 - val_loss: 0.7827 - val_acc: 0.2004\n",
      "Epoch 607/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3414 - acc: 0.2158 - val_loss: 0.7298 - val_acc: 0.2004\n",
      "Epoch 608/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3905 - acc: 0.2139 - val_loss: 0.7325 - val_acc: 0.2004\n",
      "Epoch 609/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3462 - acc: 0.2148 - val_loss: 0.7404 - val_acc: 0.2004\n",
      "Epoch 610/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3345 - acc: 0.2158 - val_loss: 0.7663 - val_acc: 0.2004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 611/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3410 - acc: 0.2158 - val_loss: 0.7547 - val_acc: 0.1985\n",
      "Epoch 612/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3092 - acc: 0.2153 - val_loss: 0.7789 - val_acc: 0.2004\n",
      "Epoch 613/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3257 - acc: 0.2148 - val_loss: 0.7028 - val_acc: 0.2004\n",
      "Epoch 614/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3228 - acc: 0.2158 - val_loss: 0.8936 - val_acc: 0.1985\n",
      "Epoch 615/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3650 - acc: 0.2153 - val_loss: 0.8534 - val_acc: 0.2004\n",
      "Epoch 616/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3546 - acc: 0.2153 - val_loss: 0.7420 - val_acc: 0.1985\n",
      "Epoch 617/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3253 - acc: 0.2153 - val_loss: 0.8569 - val_acc: 0.1985\n",
      "Epoch 618/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3129 - acc: 0.2148 - val_loss: 0.8192 - val_acc: 0.1985\n",
      "Epoch 619/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3604 - acc: 0.2139 - val_loss: 0.7768 - val_acc: 0.1985\n",
      "Epoch 620/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3362 - acc: 0.2153 - val_loss: 0.8935 - val_acc: 0.2004\n",
      "Epoch 621/4000\n",
      "68/68 [==============================] - 5s 73ms/step - loss: 0.3613 - acc: 0.2144 - val_loss: 0.7547 - val_acc: 0.2004\n",
      "Epoch 622/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.2973 - acc: 0.2153 - val_loss: 0.7669 - val_acc: 0.2004\n",
      "Epoch 623/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3286 - acc: 0.2144 - val_loss: 0.8183 - val_acc: 0.1985\n",
      "Epoch 624/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3826 - acc: 0.2144 - val_loss: 0.7598 - val_acc: 0.2004\n",
      "Epoch 625/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3079 - acc: 0.2153 - val_loss: 0.8463 - val_acc: 0.1985\n",
      "Epoch 626/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3307 - acc: 0.2153 - val_loss: 0.7764 - val_acc: 0.2004\n",
      "Epoch 627/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3309 - acc: 0.2153 - val_loss: 0.7736 - val_acc: 0.1985\n",
      "Epoch 628/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.3390 - acc: 0.2144 - val_loss: 0.7654 - val_acc: 0.2004\n",
      "Epoch 629/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.3334 - acc: 0.2158 - val_loss: 0.7945 - val_acc: 0.1985\n",
      "Epoch 630/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3117 - acc: 0.2144 - val_loss: 0.7731 - val_acc: 0.2004\n",
      "Epoch 631/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3155 - acc: 0.2144 - val_loss: 0.7818 - val_acc: 0.2004\n",
      "Epoch 632/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3298 - acc: 0.2148 - val_loss: 0.8803 - val_acc: 0.1985\n",
      "Epoch 633/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3454 - acc: 0.2162 - val_loss: 0.7266 - val_acc: 0.2004\n",
      "Epoch 634/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3146 - acc: 0.2153 - val_loss: 0.7937 - val_acc: 0.2004\n",
      "Epoch 635/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3227 - acc: 0.2158 - val_loss: 0.9742 - val_acc: 0.2004\n",
      "Epoch 636/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3730 - acc: 0.2148 - val_loss: 0.8179 - val_acc: 0.1985\n",
      "Epoch 637/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3061 - acc: 0.2153 - val_loss: 0.7445 - val_acc: 0.2004\n",
      "Epoch 638/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3138 - acc: 0.2153 - val_loss: 0.7497 - val_acc: 0.1985\n",
      "Epoch 639/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3324 - acc: 0.2153 - val_loss: 0.7445 - val_acc: 0.1985\n",
      "Epoch 640/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3065 - acc: 0.2148 - val_loss: 0.7413 - val_acc: 0.2004\n",
      "Epoch 641/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3420 - acc: 0.2144 - val_loss: 0.7804 - val_acc: 0.1985\n",
      "Epoch 642/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3469 - acc: 0.2153 - val_loss: 1.3167 - val_acc: 0.1911\n",
      "Epoch 643/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3434 - acc: 0.2158 - val_loss: 0.7515 - val_acc: 0.1985\n",
      "Epoch 644/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3340 - acc: 0.2153 - val_loss: 0.7609 - val_acc: 0.2004\n",
      "Epoch 645/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2975 - acc: 0.2153 - val_loss: 0.7740 - val_acc: 0.1985\n",
      "Epoch 646/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3314 - acc: 0.2158 - val_loss: 0.7310 - val_acc: 0.2004\n",
      "Epoch 647/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3593 - acc: 0.2144 - val_loss: 0.7297 - val_acc: 0.2004\n",
      "Epoch 648/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3067 - acc: 0.2148 - val_loss: 0.8152 - val_acc: 0.2004\n",
      "Epoch 649/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3193 - acc: 0.2153 - val_loss: 0.7532 - val_acc: 0.2004\n",
      "Epoch 650/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3216 - acc: 0.2158 - val_loss: 0.8007 - val_acc: 0.1985\n",
      "Epoch 651/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3429 - acc: 0.2158 - val_loss: 0.7889 - val_acc: 0.2004\n",
      "Epoch 652/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3073 - acc: 0.2144 - val_loss: 0.7774 - val_acc: 0.1985\n",
      "Epoch 653/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3268 - acc: 0.2144 - val_loss: 0.7958 - val_acc: 0.1985\n",
      "Epoch 654/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3438 - acc: 0.2139 - val_loss: 0.7333 - val_acc: 0.2004\n",
      "Epoch 655/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3777 - acc: 0.2135 - val_loss: 0.7510 - val_acc: 0.1985\n",
      "Epoch 656/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3932 - acc: 0.2144 - val_loss: 0.6922 - val_acc: 0.2004\n",
      "Epoch 657/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3436 - acc: 0.2167 - val_loss: 0.8601 - val_acc: 0.2004\n",
      "Epoch 658/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3208 - acc: 0.2153 - val_loss: 0.8459 - val_acc: 0.2004\n",
      "Epoch 659/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3491 - acc: 0.2158 - val_loss: 0.8983 - val_acc: 0.1985\n",
      "Epoch 660/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3230 - acc: 0.2153 - val_loss: 0.8199 - val_acc: 0.1985\n",
      "Epoch 661/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3084 - acc: 0.2162 - val_loss: 0.7666 - val_acc: 0.1985\n",
      "Epoch 662/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3480 - acc: 0.2148 - val_loss: 0.7888 - val_acc: 0.2004\n",
      "Epoch 663/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3313 - acc: 0.2153 - val_loss: 0.7729 - val_acc: 0.1985\n",
      "Epoch 664/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3036 - acc: 0.2148 - val_loss: 0.8223 - val_acc: 0.2004\n",
      "Epoch 665/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3760 - acc: 0.2153 - val_loss: 0.9035 - val_acc: 0.2004\n",
      "Epoch 666/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3350 - acc: 0.2144 - val_loss: 0.7827 - val_acc: 0.2004\n",
      "Epoch 667/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3480 - acc: 0.2158 - val_loss: 0.7346 - val_acc: 0.2004\n",
      "Epoch 668/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3466 - acc: 0.2172 - val_loss: 0.9680 - val_acc: 0.2004\n",
      "Epoch 669/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4225 - acc: 0.2158 - val_loss: 0.8665 - val_acc: 0.2004\n",
      "Epoch 670/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3758 - acc: 0.2144 - val_loss: 1.1557 - val_acc: 0.2004\n",
      "Epoch 671/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4696 - acc: 0.2158 - val_loss: 0.7043 - val_acc: 0.2004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 672/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3705 - acc: 0.2162 - val_loss: 0.6732 - val_acc: 0.2004\n",
      "Epoch 673/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3189 - acc: 0.2148 - val_loss: 0.7796 - val_acc: 0.2004\n",
      "Epoch 674/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3402 - acc: 0.2158 - val_loss: 0.7041 - val_acc: 0.2004\n",
      "Epoch 675/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3258 - acc: 0.2153 - val_loss: 0.7779 - val_acc: 0.2004\n",
      "Epoch 676/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3193 - acc: 0.2153 - val_loss: 0.7088 - val_acc: 0.1985\n",
      "Epoch 677/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3143 - acc: 0.2153 - val_loss: 0.7358 - val_acc: 0.2004\n",
      "Epoch 678/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3069 - acc: 0.2158 - val_loss: 0.7660 - val_acc: 0.1985\n",
      "Epoch 679/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3375 - acc: 0.2153 - val_loss: 1.0107 - val_acc: 0.2004\n",
      "Epoch 680/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3306 - acc: 0.2162 - val_loss: 0.7398 - val_acc: 0.2004\n",
      "Epoch 681/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3215 - acc: 0.2162 - val_loss: 0.7095 - val_acc: 0.2004\n",
      "Epoch 682/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3065 - acc: 0.2148 - val_loss: 0.7514 - val_acc: 0.1985\n",
      "Epoch 683/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3236 - acc: 0.2153 - val_loss: 0.6919 - val_acc: 0.1985\n",
      "Epoch 684/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3203 - acc: 0.2153 - val_loss: 0.7656 - val_acc: 0.1985\n",
      "Epoch 685/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2924 - acc: 0.2158 - val_loss: 0.7345 - val_acc: 0.1985\n",
      "Epoch 686/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2954 - acc: 0.2153 - val_loss: 0.7544 - val_acc: 0.2004\n",
      "Epoch 687/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3249 - acc: 0.2153 - val_loss: 0.7267 - val_acc: 0.1985\n",
      "Epoch 688/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3174 - acc: 0.2148 - val_loss: 0.7288 - val_acc: 0.1985\n",
      "Epoch 689/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3222 - acc: 0.2144 - val_loss: 0.7988 - val_acc: 0.1985\n",
      "Epoch 690/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2953 - acc: 0.2153 - val_loss: 0.7757 - val_acc: 0.2004\n",
      "Epoch 691/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3141 - acc: 0.2153 - val_loss: 0.7371 - val_acc: 0.1985\n",
      "Epoch 692/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3001 - acc: 0.2162 - val_loss: 0.7463 - val_acc: 0.2004\n",
      "Epoch 693/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.3010 - acc: 0.2153 - val_loss: 0.7527 - val_acc: 0.1985\n",
      "Epoch 694/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3600 - acc: 0.2144 - val_loss: 1.0074 - val_acc: 0.2004\n",
      "Epoch 695/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3165 - acc: 0.2162 - val_loss: 0.7061 - val_acc: 0.1985\n",
      "Epoch 696/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3163 - acc: 0.2148 - val_loss: 0.7838 - val_acc: 0.2004\n",
      "Epoch 697/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3032 - acc: 0.2148 - val_loss: 0.8167 - val_acc: 0.2004\n",
      "Epoch 698/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3764 - acc: 0.2158 - val_loss: 0.8270 - val_acc: 0.1985\n",
      "Epoch 699/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3138 - acc: 0.2158 - val_loss: 0.7273 - val_acc: 0.2004\n",
      "Epoch 700/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3062 - acc: 0.2144 - val_loss: 0.7203 - val_acc: 0.2004\n",
      "Epoch 701/4000\n",
      "68/68 [==============================] - 5s 74ms/step - loss: 0.3108 - acc: 0.2148 - val_loss: 0.8147 - val_acc: 0.2004\n",
      "Epoch 702/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3125 - acc: 0.2158 - val_loss: 0.6694 - val_acc: 0.1985\n",
      "Epoch 703/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3205 - acc: 0.2148 - val_loss: 0.8973 - val_acc: 0.2004\n",
      "Epoch 704/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3469 - acc: 0.2148 - val_loss: 0.6927 - val_acc: 0.2004\n",
      "Epoch 705/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2957 - acc: 0.2153 - val_loss: 0.7881 - val_acc: 0.2004\n",
      "Epoch 706/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2996 - acc: 0.2158 - val_loss: 0.7807 - val_acc: 0.2004\n",
      "Epoch 707/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3024 - acc: 0.2153 - val_loss: 0.7556 - val_acc: 0.2004\n",
      "Epoch 708/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2877 - acc: 0.2153 - val_loss: 0.7540 - val_acc: 0.1985\n",
      "Epoch 709/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2923 - acc: 0.2153 - val_loss: 0.7932 - val_acc: 0.1985\n",
      "Epoch 710/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3554 - acc: 0.2148 - val_loss: 0.8159 - val_acc: 0.2004\n",
      "Epoch 711/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3422 - acc: 0.2148 - val_loss: 0.7791 - val_acc: 0.1985\n",
      "Epoch 712/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3202 - acc: 0.2153 - val_loss: 0.7583 - val_acc: 0.1985\n",
      "Epoch 713/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2999 - acc: 0.2158 - val_loss: 0.7159 - val_acc: 0.2004\n",
      "Epoch 714/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2931 - acc: 0.2158 - val_loss: 0.7417 - val_acc: 0.1985\n",
      "Epoch 715/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3226 - acc: 0.2153 - val_loss: 0.8575 - val_acc: 0.1985\n",
      "Epoch 716/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3114 - acc: 0.2158 - val_loss: 0.7601 - val_acc: 0.1985\n",
      "Epoch 717/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2979 - acc: 0.2158 - val_loss: 0.7017 - val_acc: 0.2004\n",
      "Epoch 718/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3246 - acc: 0.2167 - val_loss: 0.7195 - val_acc: 0.2004\n",
      "Epoch 719/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.3318 - acc: 0.2158 - val_loss: 0.8358 - val_acc: 0.2004\n",
      "Epoch 720/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.3551 - acc: 0.2153 - val_loss: 0.9217 - val_acc: 0.2004\n",
      "Epoch 721/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.3224 - acc: 0.2153 - val_loss: 0.8005 - val_acc: 0.1985\n",
      "Epoch 722/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3071 - acc: 0.2148 - val_loss: 0.7350 - val_acc: 0.2004\n",
      "Epoch 723/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3050 - acc: 0.2153 - val_loss: 1.1556 - val_acc: 0.2004\n",
      "Epoch 724/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3361 - acc: 0.2153 - val_loss: 0.7248 - val_acc: 0.2004\n",
      "Epoch 725/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3080 - acc: 0.2162 - val_loss: 1.1836 - val_acc: 0.1948\n",
      "Epoch 726/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3879 - acc: 0.2148 - val_loss: 0.7744 - val_acc: 0.1985\n",
      "Epoch 727/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3108 - acc: 0.2153 - val_loss: 0.7061 - val_acc: 0.2004\n",
      "Epoch 728/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.3243 - acc: 0.2158 - val_loss: 0.7886 - val_acc: 0.2004\n",
      "Epoch 729/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2983 - acc: 0.2162 - val_loss: 0.6787 - val_acc: 0.2004\n",
      "Epoch 730/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3192 - acc: 0.2153 - val_loss: 0.7758 - val_acc: 0.1985\n",
      "Epoch 731/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3266 - acc: 0.2158 - val_loss: 0.6902 - val_acc: 0.2004\n",
      "Epoch 732/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3035 - acc: 0.2153 - val_loss: 0.9433 - val_acc: 0.1985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 733/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3090 - acc: 0.2158 - val_loss: 0.7644 - val_acc: 0.2004\n",
      "Epoch 734/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.3384 - acc: 0.2148 - val_loss: 1.0691 - val_acc: 0.1985\n",
      "Epoch 735/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.3348 - acc: 0.2158 - val_loss: 0.7171 - val_acc: 0.2004\n",
      "Epoch 736/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3426 - acc: 0.2153 - val_loss: 0.8987 - val_acc: 0.2004\n",
      "Epoch 737/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3562 - acc: 0.2153 - val_loss: 0.9226 - val_acc: 0.2004\n",
      "Epoch 738/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3054 - acc: 0.2148 - val_loss: 0.8766 - val_acc: 0.1985\n",
      "Epoch 739/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3021 - acc: 0.2153 - val_loss: 0.7801 - val_acc: 0.1985\n",
      "Epoch 740/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3033 - acc: 0.2158 - val_loss: 0.7210 - val_acc: 0.2004\n",
      "Epoch 741/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.3164 - acc: 0.2148 - val_loss: 0.7200 - val_acc: 0.1985\n",
      "Epoch 742/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3089 - acc: 0.2162 - val_loss: 0.7498 - val_acc: 0.2004\n",
      "Epoch 743/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3071 - acc: 0.2158 - val_loss: 0.7247 - val_acc: 0.1985\n",
      "Epoch 744/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2947 - acc: 0.2158 - val_loss: 0.7471 - val_acc: 0.2004\n",
      "Epoch 745/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2931 - acc: 0.2153 - val_loss: 0.8545 - val_acc: 0.2004\n",
      "Epoch 746/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3334 - acc: 0.2162 - val_loss: 0.7663 - val_acc: 0.2004\n",
      "Epoch 747/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4009 - acc: 0.2153 - val_loss: 0.7535 - val_acc: 0.1985\n",
      "Epoch 748/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4351 - acc: 0.2158 - val_loss: 0.6935 - val_acc: 0.2004\n",
      "Epoch 749/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.3706 - acc: 0.2148 - val_loss: 0.7531 - val_acc: 0.1985\n",
      "Epoch 750/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3670 - acc: 0.2158 - val_loss: 0.9049 - val_acc: 0.2004\n",
      "Epoch 751/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3551 - acc: 0.2144 - val_loss: 0.6875 - val_acc: 0.1985\n",
      "Epoch 752/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3465 - acc: 0.2144 - val_loss: 0.7268 - val_acc: 0.1985\n",
      "Epoch 753/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3682 - acc: 0.2153 - val_loss: 0.9034 - val_acc: 0.1985\n",
      "Epoch 754/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4206 - acc: 0.2144 - val_loss: 0.8066 - val_acc: 0.2004\n",
      "Epoch 755/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3139 - acc: 0.2162 - val_loss: 0.7098 - val_acc: 0.2004\n",
      "Epoch 756/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2792 - acc: 0.2153 - val_loss: 0.7261 - val_acc: 0.2004\n",
      "Epoch 757/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2869 - acc: 0.2153 - val_loss: 0.6917 - val_acc: 0.2004\n",
      "Epoch 758/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2971 - acc: 0.2158 - val_loss: 0.7194 - val_acc: 0.1985\n",
      "Epoch 759/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3397 - acc: 0.2153 - val_loss: 0.7554 - val_acc: 0.2004\n",
      "Epoch 760/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3146 - acc: 0.2153 - val_loss: 0.8408 - val_acc: 0.1985\n",
      "Epoch 761/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3222 - acc: 0.2153 - val_loss: 0.7190 - val_acc: 0.1985\n",
      "Epoch 762/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2875 - acc: 0.2153 - val_loss: 0.7313 - val_acc: 0.2004\n",
      "Epoch 763/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2914 - acc: 0.2162 - val_loss: 0.7320 - val_acc: 0.2004\n",
      "Epoch 764/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2844 - acc: 0.2158 - val_loss: 0.7856 - val_acc: 0.2004\n",
      "Epoch 765/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2958 - acc: 0.2162 - val_loss: 0.7257 - val_acc: 0.2004\n",
      "Epoch 766/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3003 - acc: 0.2148 - val_loss: 0.7180 - val_acc: 0.1985\n",
      "Epoch 767/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2958 - acc: 0.2167 - val_loss: 0.7635 - val_acc: 0.1985\n",
      "Epoch 768/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3136 - acc: 0.2153 - val_loss: 0.7542 - val_acc: 0.2004\n",
      "Epoch 769/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3537 - acc: 0.2148 - val_loss: 0.8276 - val_acc: 0.2004\n",
      "Epoch 770/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3009 - acc: 0.2153 - val_loss: 0.7140 - val_acc: 0.2004\n",
      "Epoch 771/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2989 - acc: 0.2144 - val_loss: 0.7256 - val_acc: 0.2004\n",
      "Epoch 772/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3295 - acc: 0.2158 - val_loss: 0.8595 - val_acc: 0.1985\n",
      "Epoch 773/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3284 - acc: 0.2158 - val_loss: 0.7428 - val_acc: 0.1985\n",
      "Epoch 774/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3159 - acc: 0.2148 - val_loss: 0.7007 - val_acc: 0.2004\n",
      "Epoch 775/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3028 - acc: 0.2158 - val_loss: 0.7911 - val_acc: 0.1985\n",
      "Epoch 776/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3406 - acc: 0.2153 - val_loss: 0.7423 - val_acc: 0.1985\n",
      "Epoch 777/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2807 - acc: 0.2148 - val_loss: 0.7515 - val_acc: 0.2004\n",
      "Epoch 778/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2984 - acc: 0.2158 - val_loss: 0.8176 - val_acc: 0.1985\n",
      "Epoch 779/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3299 - acc: 0.2153 - val_loss: 0.8581 - val_acc: 0.2004\n",
      "Epoch 780/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3461 - acc: 0.2167 - val_loss: 0.6915 - val_acc: 0.2004\n",
      "Epoch 781/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.3227 - acc: 0.2148 - val_loss: 0.7870 - val_acc: 0.2004\n",
      "Epoch 782/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 0.3073 - acc: 0.2162 - val_loss: 0.7263 - val_acc: 0.2004\n",
      "Epoch 783/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2837 - acc: 0.2148 - val_loss: 0.7232 - val_acc: 0.1985\n",
      "Epoch 784/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2821 - acc: 0.2167 - val_loss: 0.7375 - val_acc: 0.1985\n",
      "Epoch 785/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2995 - acc: 0.2158 - val_loss: 0.7176 - val_acc: 0.1985\n",
      "Epoch 786/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3032 - acc: 0.2153 - val_loss: 0.7435 - val_acc: 0.1985\n",
      "Epoch 787/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3142 - acc: 0.2158 - val_loss: 0.9583 - val_acc: 0.2004\n",
      "Epoch 788/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3599 - acc: 0.2148 - val_loss: 0.6806 - val_acc: 0.1985\n",
      "Epoch 789/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3418 - acc: 0.2144 - val_loss: 1.1429 - val_acc: 0.2004\n",
      "Epoch 790/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4063 - acc: 0.2162 - val_loss: 0.6976 - val_acc: 0.1985\n",
      "Epoch 791/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3541 - acc: 0.2158 - val_loss: 0.7494 - val_acc: 0.2004\n",
      "Epoch 792/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2912 - acc: 0.2158 - val_loss: 0.7192 - val_acc: 0.2004\n",
      "Epoch 793/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2951 - acc: 0.2158 - val_loss: 0.7243 - val_acc: 0.2004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 794/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2965 - acc: 0.2153 - val_loss: 0.7198 - val_acc: 0.2004\n",
      "Epoch 795/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2968 - acc: 0.2158 - val_loss: 0.6961 - val_acc: 0.1985\n",
      "Epoch 796/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2869 - acc: 0.2158 - val_loss: 0.7834 - val_acc: 0.1985\n",
      "Epoch 797/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3126 - acc: 0.2153 - val_loss: 0.7205 - val_acc: 0.2004\n",
      "Epoch 798/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3011 - acc: 0.2144 - val_loss: 0.7047 - val_acc: 0.2004\n",
      "Epoch 799/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2932 - acc: 0.2153 - val_loss: 0.7418 - val_acc: 0.2004\n",
      "Epoch 800/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2972 - acc: 0.2158 - val_loss: 0.7447 - val_acc: 0.1985\n",
      "Epoch 801/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3296 - acc: 0.2148 - val_loss: 0.7542 - val_acc: 0.2004\n",
      "Epoch 802/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3083 - acc: 0.2153 - val_loss: 0.8205 - val_acc: 0.2004\n",
      "Epoch 803/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3012 - acc: 0.2153 - val_loss: 0.6978 - val_acc: 0.2004\n",
      "Epoch 804/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2874 - acc: 0.2162 - val_loss: 0.8644 - val_acc: 0.2004\n",
      "Epoch 805/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3188 - acc: 0.2148 - val_loss: 0.7114 - val_acc: 0.2004\n",
      "Epoch 806/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3030 - acc: 0.2153 - val_loss: 0.7177 - val_acc: 0.2004\n",
      "Epoch 807/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3308 - acc: 0.2153 - val_loss: 0.7278 - val_acc: 0.1985\n",
      "Epoch 808/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3024 - acc: 0.2158 - val_loss: 0.7444 - val_acc: 0.2004\n",
      "Epoch 809/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2859 - acc: 0.2153 - val_loss: 0.7031 - val_acc: 0.1985\n",
      "Epoch 810/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2922 - acc: 0.2167 - val_loss: 0.8062 - val_acc: 0.2004\n",
      "Epoch 811/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3140 - acc: 0.2153 - val_loss: 0.8175 - val_acc: 0.1985\n",
      "Epoch 812/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3212 - acc: 0.2148 - val_loss: 0.7150 - val_acc: 0.2004\n",
      "Epoch 813/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3402 - acc: 0.2158 - val_loss: 0.7494 - val_acc: 0.2004\n",
      "Epoch 814/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.5025 - acc: 0.2139 - val_loss: 0.9602 - val_acc: 0.1985\n",
      "Epoch 815/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4127 - acc: 0.2158 - val_loss: 0.8708 - val_acc: 0.2004\n",
      "Epoch 816/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3523 - acc: 0.2153 - val_loss: 0.7628 - val_acc: 0.1985\n",
      "Epoch 817/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3052 - acc: 0.2162 - val_loss: 0.7549 - val_acc: 0.2004\n",
      "Epoch 818/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3055 - acc: 0.2162 - val_loss: 0.6864 - val_acc: 0.2004\n",
      "Epoch 819/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2888 - acc: 0.2148 - val_loss: 0.7159 - val_acc: 0.2004\n",
      "Epoch 820/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3059 - acc: 0.2158 - val_loss: 0.7303 - val_acc: 0.1985\n",
      "Epoch 821/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2940 - acc: 0.2167 - val_loss: 0.6933 - val_acc: 0.1985\n",
      "Epoch 822/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3278 - acc: 0.2148 - val_loss: 0.8506 - val_acc: 0.1985\n",
      "Epoch 823/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2856 - acc: 0.2153 - val_loss: 0.6831 - val_acc: 0.2004\n",
      "Epoch 824/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2778 - acc: 0.2162 - val_loss: 0.7311 - val_acc: 0.2004\n",
      "Epoch 825/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3128 - acc: 0.2144 - val_loss: 0.7259 - val_acc: 0.2004\n",
      "Epoch 826/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3190 - acc: 0.2148 - val_loss: 0.7133 - val_acc: 0.2004\n",
      "Epoch 827/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2990 - acc: 0.2158 - val_loss: 0.8948 - val_acc: 0.1985\n",
      "Epoch 828/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3079 - acc: 0.2153 - val_loss: 0.7206 - val_acc: 0.1985\n",
      "Epoch 829/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2939 - acc: 0.2153 - val_loss: 0.7359 - val_acc: 0.1985\n",
      "Epoch 830/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2920 - acc: 0.2162 - val_loss: 0.7434 - val_acc: 0.1985\n",
      "Epoch 831/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3090 - acc: 0.2158 - val_loss: 0.7323 - val_acc: 0.1985\n",
      "Epoch 832/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3049 - acc: 0.2153 - val_loss: 0.7323 - val_acc: 0.1985\n",
      "Epoch 833/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2907 - acc: 0.2153 - val_loss: 0.7906 - val_acc: 0.1985\n",
      "Epoch 834/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3661 - acc: 0.2158 - val_loss: 0.7299 - val_acc: 0.2004\n",
      "Epoch 835/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2840 - acc: 0.2153 - val_loss: 0.7174 - val_acc: 0.2004\n",
      "Epoch 836/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2734 - acc: 0.2158 - val_loss: 0.8026 - val_acc: 0.2004\n",
      "Epoch 837/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2970 - acc: 0.2148 - val_loss: 0.7067 - val_acc: 0.2004\n",
      "Epoch 838/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2748 - acc: 0.2162 - val_loss: 0.7087 - val_acc: 0.2004\n",
      "Epoch 839/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2859 - acc: 0.2162 - val_loss: 0.7241 - val_acc: 0.1985\n",
      "Epoch 840/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2918 - acc: 0.2144 - val_loss: 0.7508 - val_acc: 0.2004\n",
      "Epoch 841/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3662 - acc: 0.2148 - val_loss: 0.8905 - val_acc: 0.1985\n",
      "Epoch 842/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2999 - acc: 0.2167 - val_loss: 0.7073 - val_acc: 0.2004\n",
      "Epoch 843/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2937 - acc: 0.2153 - val_loss: 0.7738 - val_acc: 0.1985\n",
      "Epoch 844/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2860 - acc: 0.2167 - val_loss: 0.7379 - val_acc: 0.2004\n",
      "Epoch 845/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2927 - acc: 0.2158 - val_loss: 0.8099 - val_acc: 0.2004\n",
      "Epoch 846/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3003 - acc: 0.2148 - val_loss: 0.7609 - val_acc: 0.2004\n",
      "Epoch 847/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3291 - acc: 0.2167 - val_loss: 0.7745 - val_acc: 0.1985\n",
      "Epoch 848/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2808 - acc: 0.2162 - val_loss: 0.7199 - val_acc: 0.1985\n",
      "Epoch 849/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2841 - acc: 0.2158 - val_loss: 0.7026 - val_acc: 0.2004\n",
      "Epoch 850/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2819 - acc: 0.2158 - val_loss: 0.7393 - val_acc: 0.1985\n",
      "Epoch 851/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2916 - acc: 0.2158 - val_loss: 0.6891 - val_acc: 0.2004\n",
      "Epoch 852/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2970 - acc: 0.2148 - val_loss: 0.7294 - val_acc: 0.2004\n",
      "Epoch 853/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2932 - acc: 0.2153 - val_loss: 0.7353 - val_acc: 0.2004\n",
      "Epoch 854/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2854 - acc: 0.2153 - val_loss: 0.7095 - val_acc: 0.2004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 855/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2871 - acc: 0.2162 - val_loss: 0.6674 - val_acc: 0.1985\n",
      "Epoch 856/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2902 - acc: 0.2162 - val_loss: 0.7628 - val_acc: 0.2004\n",
      "Epoch 857/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3322 - acc: 0.2162 - val_loss: 0.8319 - val_acc: 0.2004\n",
      "Epoch 858/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3039 - acc: 0.2153 - val_loss: 0.7401 - val_acc: 0.2004\n",
      "Epoch 859/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3674 - acc: 0.2167 - val_loss: 0.8988 - val_acc: 0.2004\n",
      "Epoch 860/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3917 - acc: 0.2162 - val_loss: 0.8970 - val_acc: 0.1985\n",
      "Epoch 861/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3519 - acc: 0.2148 - val_loss: 0.9967 - val_acc: 0.1985\n",
      "Epoch 862/4000\n",
      "68/68 [==============================] - 5s 72ms/step - loss: 0.4674 - acc: 0.2153 - val_loss: 1.0312 - val_acc: 0.2004\n",
      "Epoch 863/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.5180 - acc: 0.2153 - val_loss: 0.7443 - val_acc: 0.2004\n",
      "Epoch 864/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3853 - acc: 0.2153 - val_loss: 0.8002 - val_acc: 0.1985\n",
      "Epoch 865/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3180 - acc: 0.2153 - val_loss: 0.6472 - val_acc: 0.2004\n",
      "Epoch 866/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3233 - acc: 0.2158 - val_loss: 0.7549 - val_acc: 0.2004\n",
      "Epoch 867/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3426 - acc: 0.2158 - val_loss: 0.6841 - val_acc: 0.1985\n",
      "Epoch 868/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3111 - acc: 0.2162 - val_loss: 0.7039 - val_acc: 0.2004\n",
      "Epoch 869/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3165 - acc: 0.2148 - val_loss: 0.6953 - val_acc: 0.1985\n",
      "Epoch 870/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3158 - acc: 0.2153 - val_loss: 0.7251 - val_acc: 0.1985\n",
      "Epoch 871/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2857 - acc: 0.2167 - val_loss: 0.6874 - val_acc: 0.2004\n",
      "Epoch 872/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2811 - acc: 0.2162 - val_loss: 0.7071 - val_acc: 0.1985\n",
      "Epoch 873/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2971 - acc: 0.2158 - val_loss: 0.6989 - val_acc: 0.2004\n",
      "Epoch 874/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3407 - acc: 0.2144 - val_loss: 0.7148 - val_acc: 0.2004\n",
      "Epoch 875/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2794 - acc: 0.2162 - val_loss: 0.7105 - val_acc: 0.1985\n",
      "Epoch 876/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2842 - acc: 0.2153 - val_loss: 0.7126 - val_acc: 0.2004\n",
      "Epoch 877/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3005 - acc: 0.2162 - val_loss: 0.7090 - val_acc: 0.2004\n",
      "Epoch 878/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2910 - acc: 0.2148 - val_loss: 0.7592 - val_acc: 0.2004\n",
      "Epoch 879/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2824 - acc: 0.2158 - val_loss: 0.7247 - val_acc: 0.1985\n",
      "Epoch 880/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2952 - acc: 0.2158 - val_loss: 0.7416 - val_acc: 0.2004\n",
      "Epoch 881/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2769 - acc: 0.2153 - val_loss: 0.7024 - val_acc: 0.1985\n",
      "Epoch 882/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2938 - acc: 0.2158 - val_loss: 0.8189 - val_acc: 0.1985\n",
      "Epoch 883/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2888 - acc: 0.2148 - val_loss: 0.7051 - val_acc: 0.2004\n",
      "Epoch 884/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2812 - acc: 0.2158 - val_loss: 0.6761 - val_acc: 0.2004\n",
      "Epoch 885/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2670 - acc: 0.2162 - val_loss: 0.6858 - val_acc: 0.1985\n",
      "Epoch 886/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3130 - acc: 0.2162 - val_loss: 0.7238 - val_acc: 0.2004\n",
      "Epoch 887/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3018 - acc: 0.2153 - val_loss: 0.9438 - val_acc: 0.2004\n",
      "Epoch 888/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3195 - acc: 0.2148 - val_loss: 0.6983 - val_acc: 0.1985\n",
      "Epoch 889/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2812 - acc: 0.2148 - val_loss: 0.7387 - val_acc: 0.2004\n",
      "Epoch 890/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2632 - acc: 0.2158 - val_loss: 0.8071 - val_acc: 0.2004\n",
      "Epoch 891/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2792 - acc: 0.2162 - val_loss: 0.6842 - val_acc: 0.1985\n",
      "Epoch 892/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3075 - acc: 0.2153 - val_loss: 0.7227 - val_acc: 0.1985\n",
      "Epoch 893/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3057 - acc: 0.2167 - val_loss: 0.7594 - val_acc: 0.1985\n",
      "Epoch 894/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2841 - acc: 0.2158 - val_loss: 0.6939 - val_acc: 0.2004\n",
      "Epoch 895/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2833 - acc: 0.2158 - val_loss: 0.6982 - val_acc: 0.2004\n",
      "Epoch 896/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2819 - acc: 0.2158 - val_loss: 0.7490 - val_acc: 0.2004\n",
      "Epoch 897/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2705 - acc: 0.2162 - val_loss: 0.6905 - val_acc: 0.2004\n",
      "Epoch 898/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2721 - acc: 0.2162 - val_loss: 0.7293 - val_acc: 0.2004\n",
      "Epoch 899/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3029 - acc: 0.2167 - val_loss: 0.6889 - val_acc: 0.2004\n",
      "Epoch 900/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2973 - acc: 0.2162 - val_loss: 0.7626 - val_acc: 0.1985\n",
      "Epoch 901/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2835 - acc: 0.2153 - val_loss: 0.7869 - val_acc: 0.2004\n",
      "Epoch 902/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3338 - acc: 0.2153 - val_loss: 0.9311 - val_acc: 0.1985\n",
      "Epoch 903/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3513 - acc: 0.2158 - val_loss: 0.7742 - val_acc: 0.2004\n",
      "Epoch 904/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3129 - acc: 0.2158 - val_loss: 0.9195 - val_acc: 0.1985\n",
      "Epoch 905/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3425 - acc: 0.2167 - val_loss: 0.7353 - val_acc: 0.1985\n",
      "Epoch 906/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3004 - acc: 0.2148 - val_loss: 0.8355 - val_acc: 0.2004\n",
      "Epoch 907/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3277 - acc: 0.2144 - val_loss: 0.6890 - val_acc: 0.1985\n",
      "Epoch 908/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2762 - acc: 0.2148 - val_loss: 0.7263 - val_acc: 0.1985\n",
      "Epoch 909/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2955 - acc: 0.2158 - val_loss: 0.7191 - val_acc: 0.1985\n",
      "Epoch 910/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2874 - acc: 0.2153 - val_loss: 0.8085 - val_acc: 0.1985\n",
      "Epoch 911/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3075 - acc: 0.2139 - val_loss: 0.7539 - val_acc: 0.2004\n",
      "Epoch 912/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2858 - acc: 0.2162 - val_loss: 0.8013 - val_acc: 0.1985\n",
      "Epoch 913/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2892 - acc: 0.2153 - val_loss: 0.7208 - val_acc: 0.2004\n",
      "Epoch 914/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2793 - acc: 0.2158 - val_loss: 0.7032 - val_acc: 0.2004\n",
      "Epoch 915/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3024 - acc: 0.2153 - val_loss: 0.6975 - val_acc: 0.1985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 916/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2926 - acc: 0.2162 - val_loss: 0.7996 - val_acc: 0.1985\n",
      "Epoch 917/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3230 - acc: 0.2158 - val_loss: 0.7123 - val_acc: 0.1985\n",
      "Epoch 918/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3300 - acc: 0.2153 - val_loss: 0.7136 - val_acc: 0.2004\n",
      "Epoch 919/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2827 - acc: 0.2172 - val_loss: 0.8212 - val_acc: 0.1985\n",
      "Epoch 920/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3247 - acc: 0.2153 - val_loss: 0.7307 - val_acc: 0.1985\n",
      "Epoch 921/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2721 - acc: 0.2162 - val_loss: 0.7241 - val_acc: 0.1985\n",
      "Epoch 922/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2758 - acc: 0.2162 - val_loss: 0.7126 - val_acc: 0.2004\n",
      "Epoch 923/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2795 - acc: 0.2158 - val_loss: 0.7004 - val_acc: 0.2004\n",
      "Epoch 924/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3043 - acc: 0.2158 - val_loss: 0.7714 - val_acc: 0.1985\n",
      "Epoch 925/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2861 - acc: 0.2162 - val_loss: 0.7665 - val_acc: 0.2004\n",
      "Epoch 926/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3458 - acc: 0.2172 - val_loss: 0.7638 - val_acc: 0.1985\n",
      "Epoch 927/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2899 - acc: 0.2172 - val_loss: 0.6093 - val_acc: 0.2004\n",
      "Epoch 928/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3651 - acc: 0.2153 - val_loss: 0.8934 - val_acc: 0.1985\n",
      "Epoch 929/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.8296 - acc: 0.2162 - val_loss: 1.0426 - val_acc: 0.2004\n",
      "Epoch 930/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.9099 - acc: 0.2148 - val_loss: 0.6316 - val_acc: 0.2004\n",
      "Epoch 931/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.8541 - acc: 0.2167 - val_loss: 0.6839 - val_acc: 0.2004\n",
      "Epoch 932/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4934 - acc: 0.2167 - val_loss: 0.8480 - val_acc: 0.2004\n",
      "Epoch 933/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3355 - acc: 0.2167 - val_loss: 0.6641 - val_acc: 0.2004\n",
      "Epoch 934/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2835 - acc: 0.2167 - val_loss: 0.6674 - val_acc: 0.2004\n",
      "Epoch 935/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2723 - acc: 0.2167 - val_loss: 0.6625 - val_acc: 0.2004\n",
      "Epoch 936/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2625 - acc: 0.2167 - val_loss: 0.6737 - val_acc: 0.2004\n",
      "Epoch 937/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2945 - acc: 0.2167 - val_loss: 0.7391 - val_acc: 0.2004\n",
      "Epoch 938/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2662 - acc: 0.2162 - val_loss: 0.6705 - val_acc: 0.2004\n",
      "Epoch 939/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2799 - acc: 0.2158 - val_loss: 0.7549 - val_acc: 0.1985\n",
      "Epoch 940/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2643 - acc: 0.2158 - val_loss: 0.6706 - val_acc: 0.2004\n",
      "Epoch 941/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2634 - acc: 0.2162 - val_loss: 0.6836 - val_acc: 0.1985\n",
      "Epoch 942/4000\n",
      "68/68 [==============================] - 5s 72ms/step - loss: 0.2677 - acc: 0.2162 - val_loss: 0.7036 - val_acc: 0.2004\n",
      "Epoch 943/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3101 - acc: 0.2167 - val_loss: 0.6978 - val_acc: 0.2004\n",
      "Epoch 944/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2911 - acc: 0.2158 - val_loss: 0.6743 - val_acc: 0.2004\n",
      "Epoch 945/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3093 - acc: 0.2162 - val_loss: 0.8027 - val_acc: 0.1985\n",
      "Epoch 946/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2693 - acc: 0.2167 - val_loss: 0.7190 - val_acc: 0.1985\n",
      "Epoch 947/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2757 - acc: 0.2158 - val_loss: 0.7412 - val_acc: 0.2004\n",
      "Epoch 948/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2722 - acc: 0.2162 - val_loss: 0.6889 - val_acc: 0.2004\n",
      "Epoch 949/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.2689 - acc: 0.2153 - val_loss: 0.6838 - val_acc: 0.1985\n",
      "Epoch 950/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2749 - acc: 0.2167 - val_loss: 0.6975 - val_acc: 0.2004\n",
      "Epoch 951/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2757 - acc: 0.2158 - val_loss: 0.6937 - val_acc: 0.1985\n",
      "Epoch 952/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2694 - acc: 0.2167 - val_loss: 0.7247 - val_acc: 0.2004\n",
      "Epoch 953/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2816 - acc: 0.2162 - val_loss: 0.7026 - val_acc: 0.2004\n",
      "Epoch 954/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3189 - acc: 0.2144 - val_loss: 0.6911 - val_acc: 0.1985\n",
      "Epoch 955/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2963 - acc: 0.2162 - val_loss: 0.7837 - val_acc: 0.1985\n",
      "Epoch 956/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3110 - acc: 0.2153 - val_loss: 0.7198 - val_acc: 0.2004\n",
      "Epoch 957/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2831 - acc: 0.2162 - val_loss: 0.6915 - val_acc: 0.2004\n",
      "Epoch 958/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2984 - acc: 0.2167 - val_loss: 0.7137 - val_acc: 0.2004\n",
      "Epoch 959/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2928 - acc: 0.2158 - val_loss: 0.7113 - val_acc: 0.2004\n",
      "Epoch 960/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3005 - acc: 0.2153 - val_loss: 0.8048 - val_acc: 0.1985\n",
      "Epoch 961/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2981 - acc: 0.2162 - val_loss: 0.6627 - val_acc: 0.1985\n",
      "Epoch 962/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3009 - acc: 0.2153 - val_loss: 0.6903 - val_acc: 0.1985\n",
      "Epoch 963/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2868 - acc: 0.2148 - val_loss: 0.6713 - val_acc: 0.2004\n",
      "Epoch 964/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2941 - acc: 0.2144 - val_loss: 0.6953 - val_acc: 0.1985\n",
      "Epoch 965/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2853 - acc: 0.2162 - val_loss: 0.7031 - val_acc: 0.1985\n",
      "Epoch 966/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3317 - acc: 0.2153 - val_loss: 0.9125 - val_acc: 0.1985\n",
      "Epoch 967/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3240 - acc: 0.2148 - val_loss: 0.8368 - val_acc: 0.2004\n",
      "Epoch 968/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2922 - acc: 0.2162 - val_loss: 0.6767 - val_acc: 0.2004\n",
      "Epoch 969/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2893 - acc: 0.2162 - val_loss: 0.7224 - val_acc: 0.2004\n",
      "Epoch 970/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2763 - acc: 0.2162 - val_loss: 0.7027 - val_acc: 0.1985\n",
      "Epoch 971/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2761 - acc: 0.2162 - val_loss: 0.8925 - val_acc: 0.2004\n",
      "Epoch 972/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2776 - acc: 0.2167 - val_loss: 0.7680 - val_acc: 0.1985\n",
      "Epoch 973/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2846 - acc: 0.2153 - val_loss: 0.7372 - val_acc: 0.1985\n",
      "Epoch 974/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2856 - acc: 0.2158 - val_loss: 0.6957 - val_acc: 0.1985\n",
      "Epoch 975/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2820 - acc: 0.2167 - val_loss: 0.7138 - val_acc: 0.1985\n",
      "Epoch 976/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2928 - acc: 0.2153 - val_loss: 0.6958 - val_acc: 0.1985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 977/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3455 - acc: 0.2153 - val_loss: 0.7059 - val_acc: 0.2004\n",
      "Epoch 978/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.2837 - acc: 0.2158 - val_loss: 0.7397 - val_acc: 0.1985\n",
      "Epoch 979/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3269 - acc: 0.2153 - val_loss: 0.9396 - val_acc: 0.1985\n",
      "Epoch 980/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3137 - acc: 0.2153 - val_loss: 0.7299 - val_acc: 0.1985\n",
      "Epoch 981/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3387 - acc: 0.2148 - val_loss: 0.7002 - val_acc: 0.2004\n",
      "Epoch 982/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2752 - acc: 0.2153 - val_loss: 0.6693 - val_acc: 0.2004\n",
      "Epoch 983/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2815 - acc: 0.2158 - val_loss: 0.7077 - val_acc: 0.2004\n",
      "Epoch 984/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2716 - acc: 0.2167 - val_loss: 0.8476 - val_acc: 0.2004\n",
      "Epoch 985/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2747 - acc: 0.2158 - val_loss: 0.6792 - val_acc: 0.2004\n",
      "Epoch 986/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2649 - acc: 0.2158 - val_loss: 0.6677 - val_acc: 0.2004\n",
      "Epoch 987/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2696 - acc: 0.2158 - val_loss: 0.7039 - val_acc: 0.2004\n",
      "Epoch 988/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2835 - acc: 0.2153 - val_loss: 0.8167 - val_acc: 0.2004\n",
      "Epoch 989/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3153 - acc: 0.2148 - val_loss: 0.7785 - val_acc: 0.1985\n",
      "Epoch 990/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3333 - acc: 0.2153 - val_loss: 0.7314 - val_acc: 0.2004\n",
      "Epoch 991/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2729 - acc: 0.2162 - val_loss: 0.7142 - val_acc: 0.2004\n",
      "Epoch 992/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3105 - acc: 0.2148 - val_loss: 0.7332 - val_acc: 0.1985\n",
      "Epoch 993/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2762 - acc: 0.2162 - val_loss: 0.6839 - val_acc: 0.1985\n",
      "Epoch 994/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3148 - acc: 0.2153 - val_loss: 0.6786 - val_acc: 0.1985\n",
      "Epoch 995/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2835 - acc: 0.2153 - val_loss: 0.8148 - val_acc: 0.2004\n",
      "Epoch 996/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2995 - acc: 0.2162 - val_loss: 0.7683 - val_acc: 0.1985\n",
      "Epoch 997/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3168 - acc: 0.2167 - val_loss: 0.7133 - val_acc: 0.2004\n",
      "Epoch 998/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3116 - acc: 0.2162 - val_loss: 0.6605 - val_acc: 0.2004\n",
      "Epoch 999/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2673 - acc: 0.2153 - val_loss: 0.7242 - val_acc: 0.2004\n",
      "Epoch 1000/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2656 - acc: 0.2162 - val_loss: 0.6533 - val_acc: 0.2004\n",
      "Epoch 1001/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2693 - acc: 0.2158 - val_loss: 0.7016 - val_acc: 0.1985\n",
      "Epoch 1002/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2740 - acc: 0.2158 - val_loss: 0.8071 - val_acc: 0.1985\n",
      "Epoch 1003/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2814 - acc: 0.2153 - val_loss: 0.7166 - val_acc: 0.1985\n",
      "Epoch 1004/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2937 - acc: 0.2148 - val_loss: 0.7587 - val_acc: 0.1985\n",
      "Epoch 1005/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2902 - acc: 0.2158 - val_loss: 0.8528 - val_acc: 0.1985\n",
      "Epoch 1006/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3152 - acc: 0.2158 - val_loss: 0.6990 - val_acc: 0.1985\n",
      "Epoch 1007/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3187 - acc: 0.2153 - val_loss: 0.7890 - val_acc: 0.2004\n",
      "Epoch 1008/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3143 - acc: 0.2162 - val_loss: 0.6911 - val_acc: 0.2004\n",
      "Epoch 1009/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3496 - acc: 0.2162 - val_loss: 0.8673 - val_acc: 0.1985\n",
      "Epoch 1010/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3390 - acc: 0.2153 - val_loss: 0.7360 - val_acc: 0.2004\n",
      "Epoch 1011/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2826 - acc: 0.2158 - val_loss: 0.7794 - val_acc: 0.2004\n",
      "Epoch 1012/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3675 - acc: 0.2167 - val_loss: 0.7442 - val_acc: 0.2004\n",
      "Epoch 1013/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3616 - acc: 0.2162 - val_loss: 0.9822 - val_acc: 0.2004\n",
      "Epoch 1014/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3563 - acc: 0.2162 - val_loss: 0.7744 - val_acc: 0.2004\n",
      "Epoch 1015/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3083 - acc: 0.2167 - val_loss: 0.6209 - val_acc: 0.2004\n",
      "Epoch 1016/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3299 - acc: 0.2162 - val_loss: 0.8256 - val_acc: 0.1985\n",
      "Epoch 1017/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3061 - acc: 0.2153 - val_loss: 0.6806 - val_acc: 0.2004\n",
      "Epoch 1018/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2773 - acc: 0.2167 - val_loss: 0.6998 - val_acc: 0.1985\n",
      "Epoch 1019/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2632 - acc: 0.2167 - val_loss: 0.6544 - val_acc: 0.2004\n",
      "Epoch 1020/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2654 - acc: 0.2162 - val_loss: 0.7060 - val_acc: 0.2004\n",
      "Epoch 1021/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.2912 - acc: 0.2158 - val_loss: 0.6623 - val_acc: 0.1985\n",
      "Epoch 1022/4000\n",
      "68/68 [==============================] - 5s 69ms/step - loss: 0.2697 - acc: 0.2162 - val_loss: 0.7060 - val_acc: 0.2004\n",
      "Epoch 1023/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2756 - acc: 0.2158 - val_loss: 0.6640 - val_acc: 0.2004\n",
      "Epoch 1024/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2685 - acc: 0.2167 - val_loss: 0.7629 - val_acc: 0.1985\n",
      "Epoch 1025/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2793 - acc: 0.2162 - val_loss: 0.8119 - val_acc: 0.1985\n",
      "Epoch 1026/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2694 - acc: 0.2162 - val_loss: 0.6790 - val_acc: 0.2004\n",
      "Epoch 1027/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2707 - acc: 0.2162 - val_loss: 0.7473 - val_acc: 0.2004\n",
      "Epoch 1028/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2822 - acc: 0.2158 - val_loss: 0.7274 - val_acc: 0.1985\n",
      "Epoch 1029/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2941 - acc: 0.2162 - val_loss: 0.7192 - val_acc: 0.1985\n",
      "Epoch 1030/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3427 - acc: 0.2162 - val_loss: 0.8073 - val_acc: 0.1985\n",
      "Epoch 1031/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3258 - acc: 0.2162 - val_loss: 0.9347 - val_acc: 0.2004\n",
      "Epoch 1032/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3190 - acc: 0.2162 - val_loss: 0.7587 - val_acc: 0.2004\n",
      "Epoch 1033/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2711 - acc: 0.2158 - val_loss: 0.6686 - val_acc: 0.2004\n",
      "Epoch 1034/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2895 - acc: 0.2167 - val_loss: 0.7070 - val_acc: 0.1985\n",
      "Epoch 1035/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2829 - acc: 0.2162 - val_loss: 0.6766 - val_acc: 0.2004\n",
      "Epoch 1036/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2888 - acc: 0.2158 - val_loss: 0.6674 - val_acc: 0.1985\n",
      "Epoch 1037/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2794 - acc: 0.2162 - val_loss: 0.7124 - val_acc: 0.1985\n",
      "Epoch 1038/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2595 - acc: 0.2162 - val_loss: 0.7295 - val_acc: 0.1985\n",
      "Epoch 1039/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3102 - acc: 0.2148 - val_loss: 0.6789 - val_acc: 0.2004\n",
      "Epoch 1040/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2726 - acc: 0.2153 - val_loss: 0.7280 - val_acc: 0.2004\n",
      "Epoch 1041/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2892 - acc: 0.2158 - val_loss: 0.6640 - val_acc: 0.2004\n",
      "Epoch 1042/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2973 - acc: 0.2158 - val_loss: 0.7394 - val_acc: 0.1985\n",
      "Epoch 1043/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2677 - acc: 0.2167 - val_loss: 0.6711 - val_acc: 0.2004\n",
      "Epoch 1044/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3054 - acc: 0.2139 - val_loss: 0.7782 - val_acc: 0.1985\n",
      "Epoch 1045/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2625 - acc: 0.2162 - val_loss: 0.6995 - val_acc: 0.1985\n",
      "Epoch 1046/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2903 - acc: 0.2167 - val_loss: 0.6664 - val_acc: 0.2004\n",
      "Epoch 1047/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2638 - acc: 0.2167 - val_loss: 0.6773 - val_acc: 0.2004\n",
      "Epoch 1048/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2701 - acc: 0.2158 - val_loss: 0.6662 - val_acc: 0.2004\n",
      "Epoch 1049/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3050 - acc: 0.2148 - val_loss: 0.6553 - val_acc: 0.1985\n",
      "Epoch 1050/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2938 - acc: 0.2148 - val_loss: 0.6317 - val_acc: 0.2004\n",
      "Epoch 1051/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2818 - acc: 0.2162 - val_loss: 0.7606 - val_acc: 0.2004\n",
      "Epoch 1052/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3247 - acc: 0.2148 - val_loss: 0.6940 - val_acc: 0.2004\n",
      "Epoch 1053/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2840 - acc: 0.2158 - val_loss: 0.6744 - val_acc: 0.1985\n",
      "Epoch 1054/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2963 - acc: 0.2153 - val_loss: 0.6556 - val_acc: 0.2004\n",
      "Epoch 1055/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2818 - acc: 0.2153 - val_loss: 0.6595 - val_acc: 0.2004\n",
      "Epoch 1056/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2604 - acc: 0.2158 - val_loss: 0.6856 - val_acc: 0.2004\n",
      "Epoch 1057/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2772 - acc: 0.2158 - val_loss: 0.7381 - val_acc: 0.1985\n",
      "Epoch 1058/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2980 - acc: 0.2153 - val_loss: 0.6632 - val_acc: 0.2004\n",
      "Epoch 1059/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2808 - acc: 0.2158 - val_loss: 0.6724 - val_acc: 0.2004\n",
      "Epoch 1060/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2724 - acc: 0.2167 - val_loss: 0.6879 - val_acc: 0.1985\n",
      "Epoch 1061/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2671 - acc: 0.2158 - val_loss: 0.7054 - val_acc: 0.1985\n",
      "Epoch 1062/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4826 - acc: 0.2153 - val_loss: 1.2520 - val_acc: 0.2004\n",
      "Epoch 1063/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 1.6580 - acc: 0.2042 - val_loss: 1.3279 - val_acc: 0.2004\n",
      "Epoch 1064/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.8072 - acc: 0.2148 - val_loss: 1.5658 - val_acc: 0.2004\n",
      "Epoch 1065/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.6862 - acc: 0.2084 - val_loss: 0.6567 - val_acc: 0.2004\n",
      "Epoch 1066/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2825 - acc: 0.2167 - val_loss: 0.6553 - val_acc: 0.2004\n",
      "Epoch 1067/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2623 - acc: 0.2172 - val_loss: 0.6327 - val_acc: 0.2004\n",
      "Epoch 1068/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2555 - acc: 0.2167 - val_loss: 0.6420 - val_acc: 0.2004\n",
      "Epoch 1069/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2504 - acc: 0.2167 - val_loss: 0.6439 - val_acc: 0.2004\n",
      "Epoch 1070/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2828 - acc: 0.2158 - val_loss: 0.7150 - val_acc: 0.1985\n",
      "Epoch 1071/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.2894 - acc: 0.2162 - val_loss: 0.8612 - val_acc: 0.2004\n",
      "Epoch 1072/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2654 - acc: 0.2167 - val_loss: 0.7536 - val_acc: 0.1985\n",
      "Epoch 1073/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2641 - acc: 0.2167 - val_loss: 0.6664 - val_acc: 0.1985\n",
      "Epoch 1074/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2657 - acc: 0.2158 - val_loss: 0.6494 - val_acc: 0.2004\n",
      "Epoch 1075/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2641 - acc: 0.2158 - val_loss: 0.6524 - val_acc: 0.2004\n",
      "Epoch 1076/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2653 - acc: 0.2162 - val_loss: 0.6570 - val_acc: 0.2004\n",
      "Epoch 1077/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2607 - acc: 0.2158 - val_loss: 0.6190 - val_acc: 0.2004\n",
      "Epoch 1078/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2680 - acc: 0.2162 - val_loss: 0.6453 - val_acc: 0.2004\n",
      "Epoch 1079/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2665 - acc: 0.2158 - val_loss: 0.7000 - val_acc: 0.2004\n",
      "Epoch 1080/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2526 - acc: 0.2167 - val_loss: 0.6478 - val_acc: 0.2004\n",
      "Epoch 1081/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2980 - acc: 0.2153 - val_loss: 0.8365 - val_acc: 0.1985\n",
      "Epoch 1082/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3096 - acc: 0.2153 - val_loss: 0.6605 - val_acc: 0.2004\n",
      "Epoch 1083/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2593 - acc: 0.2167 - val_loss: 0.6721 - val_acc: 0.1985\n",
      "Epoch 1084/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2644 - acc: 0.2167 - val_loss: 0.6482 - val_acc: 0.2004\n",
      "Epoch 1085/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.2534 - acc: 0.2172 - val_loss: 0.7953 - val_acc: 0.2004\n",
      "Epoch 1086/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.2648 - acc: 0.2162 - val_loss: 0.6985 - val_acc: 0.1985\n",
      "Epoch 1087/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2741 - acc: 0.2153 - val_loss: 0.6729 - val_acc: 0.1985\n",
      "Epoch 1088/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2959 - acc: 0.2162 - val_loss: 0.7798 - val_acc: 0.1985\n",
      "Epoch 1089/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2714 - acc: 0.2167 - val_loss: 0.8467 - val_acc: 0.1985\n",
      "Epoch 1090/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2745 - acc: 0.2158 - val_loss: 0.6871 - val_acc: 0.2004\n",
      "Epoch 1091/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2719 - acc: 0.2167 - val_loss: 0.8543 - val_acc: 0.1985\n",
      "Epoch 1092/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.2726 - acc: 0.2158 - val_loss: 0.6480 - val_acc: 0.2004\n",
      "Epoch 1093/4000\n",
      "68/68 [==============================] - 5s 66ms/step - loss: 0.2624 - acc: 0.2153 - val_loss: 0.6703 - val_acc: 0.1985\n",
      "Epoch 1094/4000\n",
      "68/68 [==============================] - 5s 69ms/step - loss: 0.2705 - acc: 0.2162 - val_loss: 0.7038 - val_acc: 0.1985\n",
      "Epoch 1095/4000\n",
      "68/68 [==============================] - 5s 69ms/step - loss: 0.2921 - acc: 0.2153 - val_loss: 0.7753 - val_acc: 0.2004\n",
      "Epoch 1096/4000\n",
      "68/68 [==============================] - 5s 71ms/step - loss: 0.2687 - acc: 0.2162 - val_loss: 0.6572 - val_acc: 0.2004\n",
      "Epoch 1097/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 5s 66ms/step - loss: 0.2621 - acc: 0.2153 - val_loss: 0.7311 - val_acc: 0.2004\n",
      "Epoch 1098/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.3012 - acc: 0.2153 - val_loss: 0.6467 - val_acc: 0.2004\n",
      "Epoch 1099/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3063 - acc: 0.2162 - val_loss: 0.6466 - val_acc: 0.1985\n",
      "Epoch 1100/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3796 - acc: 0.2135 - val_loss: 0.7256 - val_acc: 0.2004\n",
      "Epoch 1101/4000\n",
      "68/68 [==============================] - 5s 73ms/step - loss: 0.3730 - acc: 0.2162 - val_loss: 0.6778 - val_acc: 0.2004\n",
      "Epoch 1102/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2862 - acc: 0.2162 - val_loss: 0.6877 - val_acc: 0.1985\n",
      "Epoch 1103/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2916 - acc: 0.2158 - val_loss: 0.6939 - val_acc: 0.2004\n",
      "Epoch 1104/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2568 - acc: 0.2162 - val_loss: 0.6401 - val_acc: 0.2004\n",
      "Epoch 1105/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2739 - acc: 0.2162 - val_loss: 0.6898 - val_acc: 0.1985\n",
      "Epoch 1106/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2835 - acc: 0.2158 - val_loss: 0.7029 - val_acc: 0.2004\n",
      "Epoch 1107/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2738 - acc: 0.2162 - val_loss: 0.7175 - val_acc: 0.1985\n",
      "Epoch 1108/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2666 - acc: 0.2148 - val_loss: 0.6874 - val_acc: 0.1985\n",
      "Epoch 1109/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2801 - acc: 0.2167 - val_loss: 0.7286 - val_acc: 0.2004\n",
      "Epoch 1110/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2885 - acc: 0.2158 - val_loss: 0.7158 - val_acc: 0.2004\n",
      "Epoch 1111/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2784 - acc: 0.2153 - val_loss: 0.7017 - val_acc: 0.2004\n",
      "Epoch 1112/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2880 - acc: 0.2158 - val_loss: 0.8262 - val_acc: 0.1985\n",
      "Epoch 1113/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2653 - acc: 0.2162 - val_loss: 0.6540 - val_acc: 0.2004\n",
      "Epoch 1114/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2935 - acc: 0.2158 - val_loss: 0.6962 - val_acc: 0.1985\n",
      "Epoch 1115/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2625 - acc: 0.2148 - val_loss: 0.6636 - val_acc: 0.2004\n",
      "Epoch 1116/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2853 - acc: 0.2144 - val_loss: 0.7349 - val_acc: 0.2004\n",
      "Epoch 1117/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2840 - acc: 0.2162 - val_loss: 0.6925 - val_acc: 0.1985\n",
      "Epoch 1118/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2653 - acc: 0.2162 - val_loss: 0.6772 - val_acc: 0.1985\n",
      "Epoch 1119/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2684 - acc: 0.2162 - val_loss: 0.6885 - val_acc: 0.2004\n",
      "Epoch 1120/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2957 - acc: 0.2158 - val_loss: 0.6758 - val_acc: 0.1985\n",
      "Epoch 1121/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2869 - acc: 0.2162 - val_loss: 0.6754 - val_acc: 0.1985\n",
      "Epoch 1122/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2734 - acc: 0.2158 - val_loss: 0.6399 - val_acc: 0.2004\n",
      "Epoch 1123/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2824 - acc: 0.2153 - val_loss: 0.7001 - val_acc: 0.2004\n",
      "Epoch 1124/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2825 - acc: 0.2158 - val_loss: 0.7221 - val_acc: 0.1985\n",
      "Epoch 1125/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2709 - acc: 0.2158 - val_loss: 0.7177 - val_acc: 0.1985\n",
      "Epoch 1126/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2678 - acc: 0.2158 - val_loss: 0.7022 - val_acc: 0.2004\n",
      "Epoch 1127/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2781 - acc: 0.2162 - val_loss: 0.7713 - val_acc: 0.1985\n",
      "Epoch 1128/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2927 - acc: 0.2158 - val_loss: 0.6603 - val_acc: 0.2004\n",
      "Epoch 1129/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2854 - acc: 0.2162 - val_loss: 0.6836 - val_acc: 0.2004\n",
      "Epoch 1130/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2840 - acc: 0.2158 - val_loss: 0.7599 - val_acc: 0.1985\n",
      "Epoch 1131/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2793 - acc: 0.2153 - val_loss: 0.6477 - val_acc: 0.2004\n",
      "Epoch 1132/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2591 - acc: 0.2167 - val_loss: 0.6904 - val_acc: 0.2004\n",
      "Epoch 1133/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2704 - acc: 0.2158 - val_loss: 0.6640 - val_acc: 0.1985\n",
      "Epoch 1134/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2722 - acc: 0.2148 - val_loss: 0.6546 - val_acc: 0.1985\n",
      "Epoch 1135/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2716 - acc: 0.2162 - val_loss: 0.6477 - val_acc: 0.2004\n",
      "Epoch 1136/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2640 - acc: 0.2162 - val_loss: 0.6525 - val_acc: 0.2004\n",
      "Epoch 1137/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2576 - acc: 0.2153 - val_loss: 0.6955 - val_acc: 0.2004\n",
      "Epoch 1138/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2668 - acc: 0.2153 - val_loss: 0.6555 - val_acc: 0.2004\n",
      "Epoch 1139/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2640 - acc: 0.2153 - val_loss: 0.7080 - val_acc: 0.1985\n",
      "Epoch 1140/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2692 - acc: 0.2158 - val_loss: 0.6913 - val_acc: 0.1985\n",
      "Epoch 1141/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2749 - acc: 0.2148 - val_loss: 0.6467 - val_acc: 0.2004\n",
      "Epoch 1142/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2574 - acc: 0.2158 - val_loss: 0.6508 - val_acc: 0.2004\n",
      "Epoch 1143/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2624 - acc: 0.2158 - val_loss: 0.7229 - val_acc: 0.1985\n",
      "Epoch 1144/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2540 - acc: 0.2148 - val_loss: 0.6356 - val_acc: 0.2004\n",
      "Epoch 1145/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2880 - acc: 0.2162 - val_loss: 0.6765 - val_acc: 0.1985\n",
      "Epoch 1146/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2607 - acc: 0.2153 - val_loss: 0.6819 - val_acc: 0.1985\n",
      "Epoch 1147/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2627 - acc: 0.2162 - val_loss: 0.6483 - val_acc: 0.2004\n",
      "Epoch 1148/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2673 - acc: 0.2158 - val_loss: 0.7191 - val_acc: 0.1985\n",
      "Epoch 1149/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2829 - acc: 0.2153 - val_loss: 0.6585 - val_acc: 0.2004\n",
      "Epoch 1150/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2785 - acc: 0.2162 - val_loss: 0.6601 - val_acc: 0.2004\n",
      "Epoch 1151/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2521 - acc: 0.2158 - val_loss: 0.6801 - val_acc: 0.2004\n",
      "Epoch 1152/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2966 - acc: 0.2158 - val_loss: 0.8998 - val_acc: 0.1985\n",
      "Epoch 1153/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2775 - acc: 0.2148 - val_loss: 0.7374 - val_acc: 0.2004\n",
      "Epoch 1154/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2719 - acc: 0.2167 - val_loss: 0.6239 - val_acc: 0.1985\n",
      "Epoch 1155/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3072 - acc: 0.2162 - val_loss: 0.7362 - val_acc: 0.2004\n",
      "Epoch 1156/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3182 - acc: 0.2158 - val_loss: 0.6862 - val_acc: 0.2004\n",
      "Epoch 1157/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.4948 - acc: 0.2139 - val_loss: 0.9728 - val_acc: 0.2004\n",
      "Epoch 1158/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.5114 - acc: 0.2153 - val_loss: 0.8434 - val_acc: 0.2004\n",
      "Epoch 1159/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4599 - acc: 0.2148 - val_loss: 0.7633 - val_acc: 0.1985\n",
      "Epoch 1160/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3014 - acc: 0.2167 - val_loss: 0.6178 - val_acc: 0.2004\n",
      "Epoch 1161/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3413 - acc: 0.2167 - val_loss: 0.5977 - val_acc: 0.2004\n",
      "Epoch 1162/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3253 - acc: 0.2167 - val_loss: 0.8186 - val_acc: 0.1985\n",
      "Epoch 1163/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3052 - acc: 0.2167 - val_loss: 0.6283 - val_acc: 0.2004\n",
      "Epoch 1164/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2797 - acc: 0.2162 - val_loss: 0.6405 - val_acc: 0.2004\n",
      "Epoch 1165/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2555 - acc: 0.2162 - val_loss: 0.6414 - val_acc: 0.2004\n",
      "Epoch 1166/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2548 - acc: 0.2158 - val_loss: 0.6500 - val_acc: 0.2004\n",
      "Epoch 1167/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2789 - acc: 0.2153 - val_loss: 0.7487 - val_acc: 0.2004\n",
      "Epoch 1168/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2872 - acc: 0.2162 - val_loss: 0.6788 - val_acc: 0.1985\n",
      "Epoch 1169/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2664 - acc: 0.2162 - val_loss: 0.6476 - val_acc: 0.2004\n",
      "Epoch 1170/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2700 - acc: 0.2158 - val_loss: 0.7494 - val_acc: 0.1985\n",
      "Epoch 1171/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2781 - acc: 0.2162 - val_loss: 0.6489 - val_acc: 0.2004\n",
      "Epoch 1172/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2656 - acc: 0.2167 - val_loss: 0.7222 - val_acc: 0.1985\n",
      "Epoch 1173/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2577 - acc: 0.2153 - val_loss: 0.8051 - val_acc: 0.1985\n",
      "Epoch 1174/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2778 - acc: 0.2162 - val_loss: 0.7131 - val_acc: 0.1985\n",
      "Epoch 1175/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2921 - acc: 0.2162 - val_loss: 0.6455 - val_acc: 0.2004\n",
      "Epoch 1176/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2652 - acc: 0.2158 - val_loss: 0.6867 - val_acc: 0.2004\n",
      "Epoch 1177/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2522 - acc: 0.2162 - val_loss: 0.6818 - val_acc: 0.2004\n",
      "Epoch 1178/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2673 - acc: 0.2158 - val_loss: 0.6470 - val_acc: 0.1985\n",
      "Epoch 1179/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2542 - acc: 0.2158 - val_loss: 0.7371 - val_acc: 0.1985\n",
      "Epoch 1180/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2449 - acc: 0.2158 - val_loss: 0.6426 - val_acc: 0.2004\n",
      "Epoch 1181/4000\n",
      "68/68 [==============================] - 5s 71ms/step - loss: 0.2515 - acc: 0.2162 - val_loss: 0.7417 - val_acc: 0.2004\n",
      "Epoch 1182/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.2870 - acc: 0.2162 - val_loss: 0.6508 - val_acc: 0.2004\n",
      "Epoch 1183/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2884 - acc: 0.2148 - val_loss: 0.6626 - val_acc: 0.2004\n",
      "Epoch 1184/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2574 - acc: 0.2158 - val_loss: 0.6638 - val_acc: 0.1985\n",
      "Epoch 1185/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2640 - acc: 0.2153 - val_loss: 0.6464 - val_acc: 0.2004\n",
      "Epoch 1186/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2772 - acc: 0.2158 - val_loss: 0.7288 - val_acc: 0.2004\n",
      "Epoch 1187/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2709 - acc: 0.2153 - val_loss: 0.6530 - val_acc: 0.2004\n",
      "Epoch 1188/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2784 - acc: 0.2158 - val_loss: 0.6802 - val_acc: 0.1985\n",
      "Epoch 1189/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2595 - acc: 0.2153 - val_loss: 0.6783 - val_acc: 0.2004\n",
      "Epoch 1190/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2644 - acc: 0.2158 - val_loss: 0.6761 - val_acc: 0.2004\n",
      "Epoch 1191/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2566 - acc: 0.2148 - val_loss: 0.6980 - val_acc: 0.1985\n",
      "Epoch 1192/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2860 - acc: 0.2162 - val_loss: 0.6521 - val_acc: 0.2004\n",
      "Epoch 1193/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2578 - acc: 0.2158 - val_loss: 0.6471 - val_acc: 0.2004\n",
      "Epoch 1194/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2785 - acc: 0.2158 - val_loss: 0.8797 - val_acc: 0.2004\n",
      "Epoch 1195/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2796 - acc: 0.2162 - val_loss: 0.6777 - val_acc: 0.2004\n",
      "Epoch 1196/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3120 - acc: 0.2148 - val_loss: 0.7389 - val_acc: 0.2004\n",
      "Epoch 1197/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2664 - acc: 0.2158 - val_loss: 0.8353 - val_acc: 0.1985\n",
      "Epoch 1198/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2882 - acc: 0.2158 - val_loss: 0.8079 - val_acc: 0.2004\n",
      "Epoch 1199/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2725 - acc: 0.2158 - val_loss: 0.6602 - val_acc: 0.2004\n",
      "Epoch 1200/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2470 - acc: 0.2162 - val_loss: 0.6645 - val_acc: 0.2004\n",
      "Epoch 1201/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2617 - acc: 0.2167 - val_loss: 0.6556 - val_acc: 0.2004\n",
      "Epoch 1202/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2505 - acc: 0.2158 - val_loss: 0.6568 - val_acc: 0.1985\n",
      "Epoch 1203/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2424 - acc: 0.2153 - val_loss: 0.6342 - val_acc: 0.2004\n",
      "Epoch 1204/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2520 - acc: 0.2162 - val_loss: 0.7377 - val_acc: 0.1985\n",
      "Epoch 1205/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2510 - acc: 0.2162 - val_loss: 0.6294 - val_acc: 0.2004\n",
      "Epoch 1206/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2615 - acc: 0.2162 - val_loss: 0.6606 - val_acc: 0.2004\n",
      "Epoch 1207/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2891 - acc: 0.2162 - val_loss: 0.7642 - val_acc: 0.1985\n",
      "Epoch 1208/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2943 - acc: 0.2148 - val_loss: 0.7033 - val_acc: 0.2004\n",
      "Epoch 1209/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2652 - acc: 0.2158 - val_loss: 0.6667 - val_acc: 0.1985\n",
      "Epoch 1210/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2790 - acc: 0.2158 - val_loss: 0.9280 - val_acc: 0.2004\n",
      "Epoch 1211/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2737 - acc: 0.2153 - val_loss: 0.6374 - val_acc: 0.2004\n",
      "Epoch 1212/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2447 - acc: 0.2167 - val_loss: 0.7410 - val_acc: 0.2004\n",
      "Epoch 1213/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2811 - acc: 0.2158 - val_loss: 0.6595 - val_acc: 0.2004\n",
      "Epoch 1214/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2728 - acc: 0.2153 - val_loss: 0.6727 - val_acc: 0.1985\n",
      "Epoch 1215/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2640 - acc: 0.2158 - val_loss: 0.6515 - val_acc: 0.2004\n",
      "Epoch 1216/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2532 - acc: 0.2158 - val_loss: 0.6810 - val_acc: 0.2004\n",
      "Epoch 1217/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2546 - acc: 0.2158 - val_loss: 0.6244 - val_acc: 0.2004\n",
      "Epoch 1218/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2660 - acc: 0.2153 - val_loss: 0.6621 - val_acc: 0.1985\n",
      "Epoch 1219/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2654 - acc: 0.2162 - val_loss: 0.6355 - val_acc: 0.1985\n",
      "Epoch 1220/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2930 - acc: 0.2158 - val_loss: 0.7066 - val_acc: 0.2004\n",
      "Epoch 1221/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2661 - acc: 0.2158 - val_loss: 0.6343 - val_acc: 0.2004\n",
      "Epoch 1222/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2704 - acc: 0.2167 - val_loss: 0.7254 - val_acc: 0.2004\n",
      "Epoch 1223/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2711 - acc: 0.2148 - val_loss: 0.7438 - val_acc: 0.1985\n",
      "Epoch 1224/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2549 - acc: 0.2167 - val_loss: 0.6435 - val_acc: 0.2004\n",
      "Epoch 1225/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2574 - acc: 0.2162 - val_loss: 0.6447 - val_acc: 0.1985\n",
      "Epoch 1226/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2646 - acc: 0.2153 - val_loss: 0.7092 - val_acc: 0.1985\n",
      "Epoch 1227/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3033 - acc: 0.2167 - val_loss: 0.6434 - val_acc: 0.1985\n",
      "Epoch 1228/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2579 - acc: 0.2158 - val_loss: 0.7274 - val_acc: 0.1985\n",
      "Epoch 1229/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2671 - acc: 0.2167 - val_loss: 0.6893 - val_acc: 0.1985\n",
      "Epoch 1230/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3200 - acc: 0.2148 - val_loss: 0.7200 - val_acc: 0.2004\n",
      "Epoch 1231/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2884 - acc: 0.2167 - val_loss: 0.6490 - val_acc: 0.2004\n",
      "Epoch 1232/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2778 - acc: 0.2158 - val_loss: 0.6451 - val_acc: 0.2004\n",
      "Epoch 1233/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2592 - acc: 0.2158 - val_loss: 0.6714 - val_acc: 0.2004\n",
      "Epoch 1234/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2580 - acc: 0.2162 - val_loss: 0.6406 - val_acc: 0.1985\n",
      "Epoch 1235/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2511 - acc: 0.2148 - val_loss: 0.6718 - val_acc: 0.2004\n",
      "Epoch 1236/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2663 - acc: 0.2158 - val_loss: 0.6572 - val_acc: 0.1985\n",
      "Epoch 1237/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2805 - acc: 0.2158 - val_loss: 0.6277 - val_acc: 0.2004\n",
      "Epoch 1238/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2552 - acc: 0.2158 - val_loss: 0.6702 - val_acc: 0.1985\n",
      "Epoch 1239/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2462 - acc: 0.2153 - val_loss: 0.6612 - val_acc: 0.2004\n",
      "Epoch 1240/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2883 - acc: 0.2158 - val_loss: 0.6567 - val_acc: 0.2004\n",
      "Epoch 1241/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2538 - acc: 0.2148 - val_loss: 0.6608 - val_acc: 0.2004\n",
      "Epoch 1242/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2526 - acc: 0.2158 - val_loss: 0.7703 - val_acc: 0.1985\n",
      "Epoch 1243/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2642 - acc: 0.2162 - val_loss: 0.7046 - val_acc: 0.2004\n",
      "Epoch 1244/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2630 - acc: 0.2158 - val_loss: 0.7538 - val_acc: 0.1985\n",
      "Epoch 1245/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2807 - acc: 0.2153 - val_loss: 0.6309 - val_acc: 0.2004\n",
      "Epoch 1246/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2624 - acc: 0.2153 - val_loss: 0.6776 - val_acc: 0.2004\n",
      "Epoch 1247/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2390 - acc: 0.2153 - val_loss: 0.6975 - val_acc: 0.1985\n",
      "Epoch 1248/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2821 - acc: 0.2153 - val_loss: 0.6746 - val_acc: 0.2004\n",
      "Epoch 1249/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2526 - acc: 0.2153 - val_loss: 0.6733 - val_acc: 0.1985\n",
      "Epoch 1250/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2812 - acc: 0.2158 - val_loss: 0.6706 - val_acc: 0.2004\n",
      "Epoch 1251/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2761 - acc: 0.2153 - val_loss: 0.6686 - val_acc: 0.1985\n",
      "Epoch 1252/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2583 - acc: 0.2148 - val_loss: 0.6818 - val_acc: 0.2004\n",
      "Epoch 1253/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2643 - acc: 0.2148 - val_loss: 0.6825 - val_acc: 0.2004\n",
      "Epoch 1254/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2492 - acc: 0.2158 - val_loss: 0.6601 - val_acc: 0.1985\n",
      "Epoch 1255/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2451 - acc: 0.2162 - val_loss: 0.7446 - val_acc: 0.2004\n",
      "Epoch 1256/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2656 - acc: 0.2158 - val_loss: 0.6407 - val_acc: 0.2004\n",
      "Epoch 1257/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3021 - acc: 0.2153 - val_loss: 0.6919 - val_acc: 0.2004\n",
      "Epoch 1258/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2586 - acc: 0.2162 - val_loss: 0.8112 - val_acc: 0.2004\n",
      "Epoch 1259/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3162 - acc: 0.2153 - val_loss: 0.6484 - val_acc: 0.2004\n",
      "Epoch 1260/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2787 - acc: 0.2158 - val_loss: 0.7133 - val_acc: 0.1985\n",
      "Epoch 1261/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 0.2806 - acc: 0.2167 - val_loss: 0.5993 - val_acc: 0.2004\n",
      "Epoch 1262/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.2769 - acc: 0.2162 - val_loss: 0.6982 - val_acc: 0.1985\n",
      "Epoch 1263/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3444 - acc: 0.2158 - val_loss: 0.9538 - val_acc: 0.1985\n",
      "Epoch 1264/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.4488 - acc: 0.2158 - val_loss: 0.8272 - val_acc: 0.2004\n",
      "Epoch 1265/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 1.1850 - acc: 0.2153 - val_loss: 1.1456 - val_acc: 0.1985\n",
      "Epoch 1266/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3973 - acc: 0.2162 - val_loss: 0.5600 - val_acc: 0.2004\n",
      "Epoch 1267/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3989 - acc: 0.2162 - val_loss: 0.5767 - val_acc: 0.2004\n",
      "Epoch 1268/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3264 - acc: 0.2167 - val_loss: 0.7719 - val_acc: 0.2004\n",
      "Epoch 1269/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2766 - acc: 0.2167 - val_loss: 0.6077 - val_acc: 0.2004\n",
      "Epoch 1270/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2441 - acc: 0.2167 - val_loss: 0.7278 - val_acc: 0.1985\n",
      "Epoch 1271/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2549 - acc: 0.2153 - val_loss: 0.6696 - val_acc: 0.2004\n",
      "Epoch 1272/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2806 - acc: 0.2153 - val_loss: 0.6471 - val_acc: 0.2004\n",
      "Epoch 1273/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2663 - acc: 0.2162 - val_loss: 0.6540 - val_acc: 0.2004\n",
      "Epoch 1274/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2830 - acc: 0.2158 - val_loss: 0.6215 - val_acc: 0.2004\n",
      "Epoch 1275/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2601 - acc: 0.2162 - val_loss: 0.6571 - val_acc: 0.2004\n",
      "Epoch 1276/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2562 - acc: 0.2167 - val_loss: 0.6237 - val_acc: 0.2004\n",
      "Epoch 1277/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2435 - acc: 0.2153 - val_loss: 0.6253 - val_acc: 0.2004\n",
      "Epoch 1278/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2500 - acc: 0.2167 - val_loss: 0.6459 - val_acc: 0.2004\n",
      "Epoch 1279/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2521 - acc: 0.2162 - val_loss: 0.6432 - val_acc: 0.1985\n",
      "Epoch 1280/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2679 - acc: 0.2162 - val_loss: 0.6394 - val_acc: 0.2004\n",
      "Epoch 1281/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2756 - acc: 0.2158 - val_loss: 0.6284 - val_acc: 0.1985\n",
      "Epoch 1282/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2605 - acc: 0.2167 - val_loss: 0.6284 - val_acc: 0.2004\n",
      "Epoch 1283/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2526 - acc: 0.2158 - val_loss: 0.6376 - val_acc: 0.2004\n",
      "Epoch 1284/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2392 - acc: 0.2162 - val_loss: 0.6412 - val_acc: 0.2004\n",
      "Epoch 1285/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2401 - acc: 0.2162 - val_loss: 0.6319 - val_acc: 0.2004\n",
      "Epoch 1286/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2451 - acc: 0.2162 - val_loss: 0.8031 - val_acc: 0.2004\n",
      "Epoch 1287/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2632 - acc: 0.2148 - val_loss: 0.7018 - val_acc: 0.1985\n",
      "Epoch 1288/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2508 - acc: 0.2162 - val_loss: 0.6906 - val_acc: 0.2004\n",
      "Epoch 1289/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2666 - acc: 0.2162 - val_loss: 0.6179 - val_acc: 0.2004\n",
      "Epoch 1290/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2510 - acc: 0.2162 - val_loss: 0.6644 - val_acc: 0.2004\n",
      "Epoch 1291/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2672 - acc: 0.2162 - val_loss: 0.6569 - val_acc: 0.1985\n",
      "Epoch 1292/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2537 - acc: 0.2167 - val_loss: 0.6458 - val_acc: 0.1985\n",
      "Epoch 1293/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2855 - acc: 0.2158 - val_loss: 0.7207 - val_acc: 0.2004\n",
      "Epoch 1294/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2852 - acc: 0.2162 - val_loss: 0.6640 - val_acc: 0.1985\n",
      "Epoch 1295/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2656 - acc: 0.2167 - val_loss: 0.6648 - val_acc: 0.2004\n",
      "Epoch 1296/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2537 - acc: 0.2162 - val_loss: 0.6610 - val_acc: 0.2004\n",
      "Epoch 1297/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2360 - acc: 0.2162 - val_loss: 0.6582 - val_acc: 0.2004\n",
      "Epoch 1298/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.2527 - acc: 0.2167 - val_loss: 0.6646 - val_acc: 0.1985\n",
      "Epoch 1299/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2753 - acc: 0.2153 - val_loss: 0.7067 - val_acc: 0.2004\n",
      "Epoch 1300/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2600 - acc: 0.2162 - val_loss: 0.7019 - val_acc: 0.2004\n",
      "Epoch 1301/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2604 - acc: 0.2162 - val_loss: 0.7804 - val_acc: 0.2004\n",
      "Epoch 1302/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2512 - acc: 0.2167 - val_loss: 0.6295 - val_acc: 0.1985\n",
      "Epoch 1303/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2415 - acc: 0.2167 - val_loss: 0.6446 - val_acc: 0.2004\n",
      "Epoch 1304/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2526 - acc: 0.2162 - val_loss: 0.7517 - val_acc: 0.2004\n",
      "Epoch 1305/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2862 - acc: 0.2144 - val_loss: 0.7009 - val_acc: 0.2004\n",
      "Epoch 1306/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2764 - acc: 0.2158 - val_loss: 0.6702 - val_acc: 0.1985\n",
      "Epoch 1307/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2528 - acc: 0.2162 - val_loss: 0.7078 - val_acc: 0.2004\n",
      "Epoch 1308/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2606 - acc: 0.2158 - val_loss: 0.7472 - val_acc: 0.2004\n",
      "Epoch 1309/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2826 - acc: 0.2162 - val_loss: 0.6731 - val_acc: 0.1985\n",
      "Epoch 1310/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2446 - acc: 0.2167 - val_loss: 0.6277 - val_acc: 0.2004\n",
      "Epoch 1311/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2510 - acc: 0.2153 - val_loss: 0.6352 - val_acc: 0.2004\n",
      "Epoch 1312/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2764 - acc: 0.2167 - val_loss: 0.6293 - val_acc: 0.2004\n",
      "Epoch 1313/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2753 - acc: 0.2144 - val_loss: 0.7476 - val_acc: 0.1985\n",
      "Epoch 1314/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2791 - acc: 0.2158 - val_loss: 0.6075 - val_acc: 0.2004\n",
      "Epoch 1315/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3066 - acc: 0.2153 - val_loss: 0.6914 - val_acc: 0.2004\n",
      "Epoch 1316/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2579 - acc: 0.2158 - val_loss: 0.6867 - val_acc: 0.1985\n",
      "Epoch 1317/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2629 - acc: 0.2158 - val_loss: 0.6817 - val_acc: 0.2004\n",
      "Epoch 1318/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2566 - acc: 0.2153 - val_loss: 0.6327 - val_acc: 0.1985\n",
      "Epoch 1319/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2810 - acc: 0.2162 - val_loss: 0.7494 - val_acc: 0.2004\n",
      "Epoch 1320/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2740 - acc: 0.2162 - val_loss: 0.6200 - val_acc: 0.2004\n",
      "Epoch 1321/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2478 - acc: 0.2162 - val_loss: 0.6734 - val_acc: 0.2004\n",
      "Epoch 1322/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2467 - acc: 0.2158 - val_loss: 0.7896 - val_acc: 0.1985\n",
      "Epoch 1323/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2685 - acc: 0.2148 - val_loss: 0.6763 - val_acc: 0.1985\n",
      "Epoch 1324/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2713 - acc: 0.2167 - val_loss: 0.6456 - val_acc: 0.2004\n",
      "Epoch 1325/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2676 - acc: 0.2148 - val_loss: 0.6307 - val_acc: 0.2004\n",
      "Epoch 1326/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2429 - acc: 0.2162 - val_loss: 0.6869 - val_acc: 0.2004\n",
      "Epoch 1327/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.2392 - acc: 0.2162 - val_loss: 0.6207 - val_acc: 0.2004\n",
      "Epoch 1328/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2398 - acc: 0.2162 - val_loss: 0.6961 - val_acc: 0.1985\n",
      "Epoch 1329/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2524 - acc: 0.2158 - val_loss: 0.6550 - val_acc: 0.2004\n",
      "Epoch 1330/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2744 - acc: 0.2162 - val_loss: 0.6633 - val_acc: 0.2004\n",
      "Epoch 1331/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2679 - acc: 0.2162 - val_loss: 0.6615 - val_acc: 0.2004\n",
      "Epoch 1332/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2519 - acc: 0.2162 - val_loss: 0.6308 - val_acc: 0.2004\n",
      "Epoch 1333/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2399 - acc: 0.2158 - val_loss: 0.6567 - val_acc: 0.2004\n",
      "Epoch 1334/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2706 - acc: 0.2167 - val_loss: 0.6655 - val_acc: 0.2004\n",
      "Epoch 1335/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2525 - acc: 0.2158 - val_loss: 0.6452 - val_acc: 0.2004\n",
      "Epoch 1336/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2572 - acc: 0.2167 - val_loss: 0.9294 - val_acc: 0.1967\n",
      "Epoch 1337/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2889 - acc: 0.2148 - val_loss: 0.6464 - val_acc: 0.2004\n",
      "Epoch 1338/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2873 - acc: 0.2135 - val_loss: 0.6611 - val_acc: 0.2004\n",
      "Epoch 1339/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2538 - acc: 0.2162 - val_loss: 0.8750 - val_acc: 0.2004\n",
      "Epoch 1340/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2451 - acc: 0.2167 - val_loss: 0.6886 - val_acc: 0.2004\n",
      "Epoch 1341/4000\n",
      "68/68 [==============================] - 5s 69ms/step - loss: 0.2547 - acc: 0.2158 - val_loss: 0.6394 - val_acc: 0.2004\n",
      "Epoch 1342/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.2457 - acc: 0.2167 - val_loss: 0.7524 - val_acc: 0.1985\n",
      "Epoch 1343/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2464 - acc: 0.2158 - val_loss: 0.6347 - val_acc: 0.1985\n",
      "Epoch 1344/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2606 - acc: 0.2153 - val_loss: 0.6307 - val_acc: 0.1985\n",
      "Epoch 1345/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2803 - acc: 0.2158 - val_loss: 0.6218 - val_acc: 0.2004\n",
      "Epoch 1346/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3084 - acc: 0.2153 - val_loss: 0.6231 - val_acc: 0.2004\n",
      "Epoch 1347/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2521 - acc: 0.2162 - val_loss: 0.6853 - val_acc: 0.2004\n",
      "Epoch 1348/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2734 - acc: 0.2162 - val_loss: 0.6302 - val_acc: 0.2004\n",
      "Epoch 1349/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2411 - acc: 0.2162 - val_loss: 0.6383 - val_acc: 0.1985\n",
      "Epoch 1350/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2812 - acc: 0.2167 - val_loss: 0.6423 - val_acc: 0.2004\n",
      "Epoch 1351/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2362 - acc: 0.2162 - val_loss: 0.6290 - val_acc: 0.2004\n",
      "Epoch 1352/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2355 - acc: 0.2158 - val_loss: 0.6294 - val_acc: 0.2004\n",
      "Epoch 1353/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2637 - acc: 0.2158 - val_loss: 0.6210 - val_acc: 0.2004\n",
      "Epoch 1354/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2801 - acc: 0.2139 - val_loss: 0.6353 - val_acc: 0.2004\n",
      "Epoch 1355/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2357 - acc: 0.2167 - val_loss: 0.7495 - val_acc: 0.2004\n",
      "Epoch 1356/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.2458 - acc: 0.2162 - val_loss: 0.7122 - val_acc: 0.1985\n",
      "Epoch 1357/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2699 - acc: 0.2162 - val_loss: 0.7098 - val_acc: 0.2004\n",
      "Epoch 1358/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2673 - acc: 0.2153 - val_loss: 0.6731 - val_acc: 0.1985\n",
      "Epoch 1359/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2702 - acc: 0.2148 - val_loss: 0.6585 - val_acc: 0.2004\n",
      "Epoch 1360/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2592 - acc: 0.2158 - val_loss: 0.6713 - val_acc: 0.1985\n",
      "Epoch 1361/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2707 - acc: 0.2148 - val_loss: 0.7242 - val_acc: 0.2004\n",
      "Epoch 1362/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2491 - acc: 0.2162 - val_loss: 0.6580 - val_acc: 0.2004\n",
      "Epoch 1363/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2371 - acc: 0.2167 - val_loss: 0.6160 - val_acc: 0.2004\n",
      "Epoch 1364/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2646 - acc: 0.2158 - val_loss: 0.6202 - val_acc: 0.2004\n",
      "Epoch 1365/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2585 - acc: 0.2162 - val_loss: 0.6275 - val_acc: 0.2004\n",
      "Epoch 1366/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2798 - acc: 0.2153 - val_loss: 0.6782 - val_acc: 0.1985\n",
      "Epoch 1367/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2634 - acc: 0.2153 - val_loss: 0.6675 - val_acc: 0.2004\n",
      "Epoch 1368/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2387 - acc: 0.2162 - val_loss: 0.7043 - val_acc: 0.1985\n",
      "Epoch 1369/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2992 - acc: 0.2162 - val_loss: 0.6881 - val_acc: 0.1985\n",
      "Epoch 1370/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2436 - acc: 0.2158 - val_loss: 0.6488 - val_acc: 0.1985\n",
      "Epoch 1371/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2379 - acc: 0.2162 - val_loss: 0.8281 - val_acc: 0.1985\n",
      "Epoch 1372/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2887 - acc: 0.2162 - val_loss: 0.6473 - val_acc: 0.2004\n",
      "Epoch 1373/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2476 - acc: 0.2162 - val_loss: 0.6355 - val_acc: 0.2004\n",
      "Epoch 1374/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2470 - acc: 0.2167 - val_loss: 0.6522 - val_acc: 0.1985\n",
      "Epoch 1375/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2568 - acc: 0.2162 - val_loss: 0.6273 - val_acc: 0.1985\n",
      "Epoch 1376/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3072 - acc: 0.2153 - val_loss: 0.6720 - val_acc: 0.2004\n",
      "Epoch 1377/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2888 - acc: 0.2158 - val_loss: 0.7723 - val_acc: 0.1985\n",
      "Epoch 1378/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2614 - acc: 0.2153 - val_loss: 0.6629 - val_acc: 0.2004\n",
      "Epoch 1379/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2429 - acc: 0.2153 - val_loss: 0.6392 - val_acc: 0.2004\n",
      "Epoch 1380/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2912 - acc: 0.2162 - val_loss: 0.6364 - val_acc: 0.1985\n",
      "Epoch 1381/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2611 - acc: 0.2153 - val_loss: 0.7970 - val_acc: 0.2004\n",
      "Epoch 1382/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2827 - acc: 0.2158 - val_loss: 0.6545 - val_acc: 0.2004\n",
      "Epoch 1383/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2563 - acc: 0.2162 - val_loss: 0.6214 - val_acc: 0.2004\n",
      "Epoch 1384/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2539 - acc: 0.2144 - val_loss: 0.6938 - val_acc: 0.2004\n",
      "Epoch 1385/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2437 - acc: 0.2167 - val_loss: 0.6174 - val_acc: 0.2004\n",
      "Epoch 1386/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2590 - acc: 0.2158 - val_loss: 0.6146 - val_acc: 0.2004\n",
      "Epoch 1387/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2445 - acc: 0.2158 - val_loss: 0.6515 - val_acc: 0.2004\n",
      "Epoch 1388/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2456 - acc: 0.2162 - val_loss: 0.6113 - val_acc: 0.2004\n",
      "Epoch 1389/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2338 - acc: 0.2162 - val_loss: 0.7385 - val_acc: 0.1985\n",
      "Epoch 1390/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2728 - acc: 0.2158 - val_loss: 0.6369 - val_acc: 0.2004\n",
      "Epoch 1391/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2574 - acc: 0.2167 - val_loss: 0.6717 - val_acc: 0.1985\n",
      "Epoch 1392/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3119 - acc: 0.2148 - val_loss: 1.0828 - val_acc: 0.1929\n",
      "Epoch 1393/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2548 - acc: 0.2158 - val_loss: 0.6156 - val_acc: 0.2004\n",
      "Epoch 1394/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2433 - acc: 0.2162 - val_loss: 0.8537 - val_acc: 0.1985\n",
      "Epoch 1395/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2608 - acc: 0.2162 - val_loss: 0.6803 - val_acc: 0.1985\n",
      "Epoch 1396/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2387 - acc: 0.2158 - val_loss: 0.7203 - val_acc: 0.2004\n",
      "Epoch 1397/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2638 - acc: 0.2153 - val_loss: 0.6597 - val_acc: 0.1985\n",
      "Epoch 1398/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2600 - acc: 0.2158 - val_loss: 0.6843 - val_acc: 0.1985\n",
      "Epoch 1399/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2423 - acc: 0.2162 - val_loss: 0.6499 - val_acc: 0.1985\n",
      "Epoch 1400/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2454 - acc: 0.2162 - val_loss: 0.6941 - val_acc: 0.1985\n",
      "Epoch 1401/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2521 - acc: 0.2158 - val_loss: 0.7689 - val_acc: 0.2004\n",
      "Epoch 1402/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2794 - acc: 0.2158 - val_loss: 0.6285 - val_acc: 0.2004\n",
      "Epoch 1403/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2488 - acc: 0.2158 - val_loss: 0.6734 - val_acc: 0.2004\n",
      "Epoch 1404/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2359 - acc: 0.2162 - val_loss: 0.7226 - val_acc: 0.2004\n",
      "Epoch 1405/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2537 - acc: 0.2167 - val_loss: 0.6512 - val_acc: 0.2004\n",
      "Epoch 1406/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2588 - acc: 0.2158 - val_loss: 0.7021 - val_acc: 0.2004\n",
      "Epoch 1407/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2604 - acc: 0.2167 - val_loss: 0.7043 - val_acc: 0.1985\n",
      "Epoch 1408/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2441 - acc: 0.2153 - val_loss: 0.7049 - val_acc: 0.2004\n",
      "Epoch 1409/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2626 - acc: 0.2153 - val_loss: 0.7024 - val_acc: 0.2004\n",
      "Epoch 1410/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2621 - acc: 0.2153 - val_loss: 0.6754 - val_acc: 0.2004\n",
      "Epoch 1411/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3038 - acc: 0.2153 - val_loss: 0.6010 - val_acc: 0.2004\n",
      "Epoch 1412/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2428 - acc: 0.2158 - val_loss: 0.6382 - val_acc: 0.2004\n",
      "Epoch 1413/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2380 - acc: 0.2167 - val_loss: 0.8080 - val_acc: 0.2004\n",
      "Epoch 1414/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3111 - acc: 0.2162 - val_loss: 0.6746 - val_acc: 0.2004\n",
      "Epoch 1415/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3838 - acc: 0.2158 - val_loss: 0.7874 - val_acc: 0.2004\n",
      "Epoch 1416/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.6299 - acc: 0.2144 - val_loss: 0.6928 - val_acc: 0.2004\n",
      "Epoch 1417/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2936 - acc: 0.2167 - val_loss: 0.5512 - val_acc: 0.2004\n",
      "Epoch 1418/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3113 - acc: 0.2167 - val_loss: 0.6068 - val_acc: 0.2004\n",
      "Epoch 1419/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2921 - acc: 0.2153 - val_loss: 0.7176 - val_acc: 0.2004\n",
      "Epoch 1420/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.2991 - acc: 0.2158 - val_loss: 0.7441 - val_acc: 0.1985\n",
      "Epoch 1421/4000\n",
      "68/68 [==============================] - 5s 79ms/step - loss: 0.2771 - acc: 0.2158 - val_loss: 0.6458 - val_acc: 0.2004\n",
      "Epoch 1422/4000\n",
      "68/68 [==============================] - 4s 56ms/step - loss: 0.2745 - acc: 0.2167 - val_loss: 0.6355 - val_acc: 0.2004\n",
      "Epoch 1423/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.2310 - acc: 0.2167 - val_loss: 0.6409 - val_acc: 0.1985\n",
      "Epoch 1424/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2406 - acc: 0.2167 - val_loss: 0.6211 - val_acc: 0.2004\n",
      "Epoch 1425/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2409 - acc: 0.2167 - val_loss: 0.6441 - val_acc: 0.2004\n",
      "Epoch 1426/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2536 - acc: 0.2172 - val_loss: 0.9356 - val_acc: 0.2004\n",
      "Epoch 1427/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2966 - acc: 0.2139 - val_loss: 0.6957 - val_acc: 0.1985\n",
      "Epoch 1428/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2402 - acc: 0.2158 - val_loss: 0.6244 - val_acc: 0.2004\n",
      "Epoch 1429/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.2287 - acc: 0.2158 - val_loss: 0.6401 - val_acc: 0.2004\n",
      "Epoch 1430/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2317 - acc: 0.2167 - val_loss: 0.6672 - val_acc: 0.2004\n",
      "Epoch 1431/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2598 - acc: 0.2158 - val_loss: 0.8328 - val_acc: 0.1985\n",
      "Epoch 1432/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2505 - acc: 0.2153 - val_loss: 0.6328 - val_acc: 0.2004\n",
      "Epoch 1433/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2521 - acc: 0.2153 - val_loss: 0.6376 - val_acc: 0.2004\n",
      "Epoch 1434/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2561 - acc: 0.2172 - val_loss: 0.6523 - val_acc: 0.2004\n",
      "Epoch 1435/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2398 - acc: 0.2153 - val_loss: 0.6465 - val_acc: 0.2004\n",
      "Epoch 1436/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2557 - acc: 0.2158 - val_loss: 0.6061 - val_acc: 0.2004\n",
      "Epoch 1437/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2360 - acc: 0.2162 - val_loss: 0.7014 - val_acc: 0.1985\n",
      "Epoch 1438/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2388 - acc: 0.2158 - val_loss: 0.6229 - val_acc: 0.2004\n",
      "Epoch 1439/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2358 - acc: 0.2162 - val_loss: 0.6598 - val_acc: 0.1985\n",
      "Epoch 1440/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2367 - acc: 0.2162 - val_loss: 0.6841 - val_acc: 0.2004\n",
      "Epoch 1441/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2398 - acc: 0.2162 - val_loss: 0.6421 - val_acc: 0.2004\n",
      "Epoch 1442/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2555 - acc: 0.2158 - val_loss: 0.6712 - val_acc: 0.2004\n",
      "Epoch 1443/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2742 - acc: 0.2153 - val_loss: 0.6579 - val_acc: 0.1985\n",
      "Epoch 1444/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2439 - acc: 0.2167 - val_loss: 0.6568 - val_acc: 0.1985\n",
      "Epoch 1445/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2836 - acc: 0.2144 - val_loss: 0.7343 - val_acc: 0.1985\n",
      "Epoch 1446/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2679 - acc: 0.2153 - val_loss: 0.6436 - val_acc: 0.1985\n",
      "Epoch 1447/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2699 - acc: 0.2167 - val_loss: 0.6568 - val_acc: 0.2004\n",
      "Epoch 1448/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2523 - acc: 0.2158 - val_loss: 0.6699 - val_acc: 0.1985\n",
      "Epoch 1449/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2329 - acc: 0.2158 - val_loss: 0.6324 - val_acc: 0.2004\n",
      "Epoch 1450/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2427 - acc: 0.2148 - val_loss: 0.6961 - val_acc: 0.1985\n",
      "Epoch 1451/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2569 - acc: 0.2153 - val_loss: 0.6776 - val_acc: 0.2004\n",
      "Epoch 1452/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2446 - acc: 0.2167 - val_loss: 0.6419 - val_acc: 0.1985\n",
      "Epoch 1453/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2371 - acc: 0.2158 - val_loss: 0.7885 - val_acc: 0.1985\n",
      "Epoch 1454/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2455 - acc: 0.2148 - val_loss: 0.7693 - val_acc: 0.2004\n",
      "Epoch 1455/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2368 - acc: 0.2158 - val_loss: 0.6438 - val_acc: 0.2004\n",
      "Epoch 1456/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2564 - acc: 0.2162 - val_loss: 0.6920 - val_acc: 0.1985\n",
      "Epoch 1457/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2371 - acc: 0.2158 - val_loss: 0.6661 - val_acc: 0.2004\n",
      "Epoch 1458/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2319 - acc: 0.2153 - val_loss: 0.6146 - val_acc: 0.2004\n",
      "Epoch 1459/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2334 - acc: 0.2162 - val_loss: 0.6307 - val_acc: 0.2004\n",
      "Epoch 1460/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2437 - acc: 0.2162 - val_loss: 0.8556 - val_acc: 0.1985\n",
      "Epoch 1461/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2526 - acc: 0.2158 - val_loss: 0.7629 - val_acc: 0.1985\n",
      "Epoch 1462/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2520 - acc: 0.2158 - val_loss: 0.6719 - val_acc: 0.2004\n",
      "Epoch 1463/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2862 - acc: 0.2144 - val_loss: 0.6491 - val_acc: 0.2004\n",
      "Epoch 1464/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2421 - acc: 0.2162 - val_loss: 0.7552 - val_acc: 0.2004\n",
      "Epoch 1465/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2419 - acc: 0.2167 - val_loss: 0.5999 - val_acc: 0.2004\n",
      "Epoch 1466/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2590 - acc: 0.2158 - val_loss: 0.6726 - val_acc: 0.2004\n",
      "Epoch 1467/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2423 - acc: 0.2158 - val_loss: 0.6879 - val_acc: 0.2004\n",
      "Epoch 1468/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2552 - acc: 0.2167 - val_loss: 0.6876 - val_acc: 0.2004\n",
      "Epoch 1469/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2636 - acc: 0.2153 - val_loss: 0.6338 - val_acc: 0.2004\n",
      "Epoch 1470/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2542 - acc: 0.2148 - val_loss: 0.6702 - val_acc: 0.2004\n",
      "Epoch 1471/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2356 - acc: 0.2167 - val_loss: 0.6906 - val_acc: 0.2004\n",
      "Epoch 1472/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2518 - acc: 0.2158 - val_loss: 0.6471 - val_acc: 0.2004\n",
      "Epoch 1473/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2751 - acc: 0.2158 - val_loss: 0.6460 - val_acc: 0.1985\n",
      "Epoch 1474/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2589 - acc: 0.2158 - val_loss: 0.6726 - val_acc: 0.2004\n",
      "Epoch 1475/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2301 - acc: 0.2162 - val_loss: 0.6595 - val_acc: 0.2004\n",
      "Epoch 1476/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2467 - acc: 0.2148 - val_loss: 0.6706 - val_acc: 0.2004\n",
      "Epoch 1477/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2500 - acc: 0.2153 - val_loss: 0.6912 - val_acc: 0.2004\n",
      "Epoch 1478/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2425 - acc: 0.2167 - val_loss: 0.6255 - val_acc: 0.2004\n",
      "Epoch 1479/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2464 - acc: 0.2158 - val_loss: 0.6288 - val_acc: 0.2004\n",
      "Epoch 1480/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2294 - acc: 0.2162 - val_loss: 0.6313 - val_acc: 0.1985\n",
      "Epoch 1481/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2659 - acc: 0.2158 - val_loss: 0.8924 - val_acc: 0.1985\n",
      "Epoch 1482/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3077 - acc: 0.2158 - val_loss: 0.6578 - val_acc: 0.2004\n",
      "Epoch 1483/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2337 - acc: 0.2158 - val_loss: 0.6292 - val_acc: 0.2004\n",
      "Epoch 1484/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2852 - acc: 0.2158 - val_loss: 0.7179 - val_acc: 0.2004\n",
      "Epoch 1485/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2650 - acc: 0.2153 - val_loss: 0.5706 - val_acc: 0.2004\n",
      "Epoch 1486/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2616 - acc: 0.2158 - val_loss: 0.7212 - val_acc: 0.2004\n",
      "Epoch 1487/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3332 - acc: 0.2158 - val_loss: 0.6956 - val_acc: 0.2004\n",
      "Epoch 1488/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3699 - acc: 0.2162 - val_loss: 0.9549 - val_acc: 0.2004\n",
      "Epoch 1489/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3848 - acc: 0.2148 - val_loss: 0.8226 - val_acc: 0.2004\n",
      "Epoch 1490/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.5162 - acc: 0.2162 - val_loss: 0.6801 - val_acc: 0.2004\n",
      "Epoch 1491/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2822 - acc: 0.2167 - val_loss: 0.7770 - val_acc: 0.2004\n",
      "Epoch 1492/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.5244 - acc: 0.2135 - val_loss: 0.7541 - val_acc: 0.2004\n",
      "Epoch 1493/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3562 - acc: 0.2158 - val_loss: 0.6288 - val_acc: 0.2004\n",
      "Epoch 1494/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.2482 - acc: 0.2162 - val_loss: 0.6120 - val_acc: 0.2004\n",
      "Epoch 1495/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2317 - acc: 0.2167 - val_loss: 0.6518 - val_acc: 0.1985\n",
      "Epoch 1496/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2550 - acc: 0.2162 - val_loss: 0.6230 - val_acc: 0.2004\n",
      "Epoch 1497/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2399 - acc: 0.2167 - val_loss: 0.6084 - val_acc: 0.2004\n",
      "Epoch 1498/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2581 - acc: 0.2153 - val_loss: 0.6176 - val_acc: 0.1985\n",
      "Epoch 1499/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2479 - acc: 0.2153 - val_loss: 0.7581 - val_acc: 0.1985\n",
      "Epoch 1500/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2566 - acc: 0.2167 - val_loss: 0.6435 - val_acc: 0.2004\n",
      "Epoch 1501/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.2256 - acc: 0.2167 - val_loss: 0.6187 - val_acc: 0.2004\n",
      "Epoch 1502/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.2272 - acc: 0.2158 - val_loss: 0.6243 - val_acc: 0.2004\n",
      "Epoch 1503/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2312 - acc: 0.2158 - val_loss: 0.6082 - val_acc: 0.2004\n",
      "Epoch 1504/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2297 - acc: 0.2158 - val_loss: 0.6860 - val_acc: 0.2004\n",
      "Epoch 1505/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2726 - acc: 0.2158 - val_loss: 0.6084 - val_acc: 0.2004\n",
      "Epoch 1506/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2311 - acc: 0.2158 - val_loss: 0.6821 - val_acc: 0.2004\n",
      "Epoch 1507/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2305 - acc: 0.2158 - val_loss: 0.6180 - val_acc: 0.1985\n",
      "Epoch 1508/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2321 - acc: 0.2158 - val_loss: 0.6268 - val_acc: 0.2004\n",
      "Epoch 1509/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2770 - acc: 0.2158 - val_loss: 0.6517 - val_acc: 0.1985\n",
      "Epoch 1510/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2802 - acc: 0.2158 - val_loss: 0.6105 - val_acc: 0.2004\n",
      "Epoch 1511/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2410 - acc: 0.2167 - val_loss: 0.6446 - val_acc: 0.1985\n",
      "Epoch 1512/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2247 - acc: 0.2167 - val_loss: 0.6314 - val_acc: 0.1985\n",
      "Epoch 1513/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2396 - acc: 0.2162 - val_loss: 0.6040 - val_acc: 0.2004\n",
      "Epoch 1514/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2636 - acc: 0.2153 - val_loss: 0.6138 - val_acc: 0.2004\n",
      "Epoch 1515/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2459 - acc: 0.2158 - val_loss: 0.6475 - val_acc: 0.2004\n",
      "Epoch 1516/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2396 - acc: 0.2167 - val_loss: 0.7109 - val_acc: 0.2004\n",
      "Epoch 1517/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2334 - acc: 0.2162 - val_loss: 0.6379 - val_acc: 0.2004\n",
      "Epoch 1518/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2316 - acc: 0.2167 - val_loss: 0.6220 - val_acc: 0.2004\n",
      "Epoch 1519/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2324 - acc: 0.2162 - val_loss: 0.6036 - val_acc: 0.2004\n",
      "Epoch 1520/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2249 - acc: 0.2158 - val_loss: 0.6431 - val_acc: 0.1985\n",
      "Epoch 1521/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2328 - acc: 0.2162 - val_loss: 0.6504 - val_acc: 0.1985\n",
      "Epoch 1522/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2254 - acc: 0.2167 - val_loss: 0.6182 - val_acc: 0.2004\n",
      "Epoch 1523/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2410 - acc: 0.2162 - val_loss: 0.6381 - val_acc: 0.1985\n",
      "Epoch 1524/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2504 - acc: 0.2158 - val_loss: 0.6617 - val_acc: 0.2004\n",
      "Epoch 1525/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2330 - acc: 0.2153 - val_loss: 0.6769 - val_acc: 0.1985\n",
      "Epoch 1526/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2419 - acc: 0.2167 - val_loss: 0.6224 - val_acc: 0.2004\n",
      "Epoch 1527/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2332 - acc: 0.2162 - val_loss: 0.5964 - val_acc: 0.2004\n",
      "Epoch 1528/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2315 - acc: 0.2158 - val_loss: 0.6709 - val_acc: 0.2004\n",
      "Epoch 1529/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2388 - acc: 0.2158 - val_loss: 0.6151 - val_acc: 0.2004\n",
      "Epoch 1530/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2328 - acc: 0.2153 - val_loss: 0.6630 - val_acc: 0.2004\n",
      "Epoch 1531/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2544 - acc: 0.2148 - val_loss: 0.6369 - val_acc: 0.1985\n",
      "Epoch 1532/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2849 - acc: 0.2158 - val_loss: 0.8568 - val_acc: 0.1985\n",
      "Epoch 1533/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3029 - acc: 0.2153 - val_loss: 0.6301 - val_acc: 0.2004\n",
      "Epoch 1534/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2567 - acc: 0.2162 - val_loss: 0.7862 - val_acc: 0.1985\n",
      "Epoch 1535/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2698 - acc: 0.2153 - val_loss: 0.6201 - val_acc: 0.2004\n",
      "Epoch 1536/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2344 - acc: 0.2162 - val_loss: 0.6500 - val_acc: 0.2004\n",
      "Epoch 1537/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2853 - acc: 0.2153 - val_loss: 0.6226 - val_acc: 0.2004\n",
      "Epoch 1538/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2653 - acc: 0.2139 - val_loss: 0.6365 - val_acc: 0.1985\n",
      "Epoch 1539/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2590 - acc: 0.2153 - val_loss: 0.6164 - val_acc: 0.1985\n",
      "Epoch 1540/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2390 - acc: 0.2153 - val_loss: 0.6542 - val_acc: 0.2004\n",
      "Epoch 1541/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2418 - acc: 0.2153 - val_loss: 1.0066 - val_acc: 0.1948\n",
      "Epoch 1542/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2509 - acc: 0.2148 - val_loss: 0.6468 - val_acc: 0.2004\n",
      "Epoch 1543/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2530 - acc: 0.2144 - val_loss: 0.7362 - val_acc: 0.1985\n",
      "Epoch 1544/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2467 - acc: 0.2162 - val_loss: 0.6234 - val_acc: 0.2004\n",
      "Epoch 1545/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2219 - acc: 0.2158 - val_loss: 0.6518 - val_acc: 0.1985\n",
      "Epoch 1546/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2438 - acc: 0.2172 - val_loss: 0.6225 - val_acc: 0.2004\n",
      "Epoch 1547/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2578 - acc: 0.2153 - val_loss: 0.9249 - val_acc: 0.1985\n",
      "Epoch 1548/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2597 - acc: 0.2148 - val_loss: 0.6777 - val_acc: 0.1985\n",
      "Epoch 1549/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2434 - acc: 0.2162 - val_loss: 0.6301 - val_acc: 0.2004\n",
      "Epoch 1550/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2537 - acc: 0.2148 - val_loss: 0.7345 - val_acc: 0.1985\n",
      "Epoch 1551/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2673 - acc: 0.2139 - val_loss: 0.6400 - val_acc: 0.1985\n",
      "Epoch 1552/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2415 - acc: 0.2167 - val_loss: 0.6227 - val_acc: 0.2004\n",
      "Epoch 1553/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2396 - acc: 0.2153 - val_loss: 0.6724 - val_acc: 0.2004\n",
      "Epoch 1554/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2408 - acc: 0.2158 - val_loss: 0.6997 - val_acc: 0.1985\n",
      "Epoch 1555/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2270 - acc: 0.2153 - val_loss: 0.6271 - val_acc: 0.2004\n",
      "Epoch 1556/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2232 - acc: 0.2162 - val_loss: 0.6175 - val_acc: 0.2004\n",
      "Epoch 1557/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2294 - acc: 0.2148 - val_loss: 0.6144 - val_acc: 0.2004\n",
      "Epoch 1558/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2352 - acc: 0.2158 - val_loss: 0.6142 - val_acc: 0.1985\n",
      "Epoch 1559/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2407 - acc: 0.2158 - val_loss: 0.6332 - val_acc: 0.2004\n",
      "Epoch 1560/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2396 - acc: 0.2148 - val_loss: 0.6226 - val_acc: 0.1985\n",
      "Epoch 1561/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2345 - acc: 0.2158 - val_loss: 0.6432 - val_acc: 0.2004\n",
      "Epoch 1562/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2402 - acc: 0.2158 - val_loss: 0.6513 - val_acc: 0.1985\n",
      "Epoch 1563/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2675 - acc: 0.2162 - val_loss: 0.6678 - val_acc: 0.2004\n",
      "Epoch 1564/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2492 - acc: 0.2148 - val_loss: 0.6890 - val_acc: 0.1985\n",
      "Epoch 1565/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2448 - acc: 0.2158 - val_loss: 0.6425 - val_acc: 0.2004\n",
      "Epoch 1566/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2355 - acc: 0.2167 - val_loss: 0.7183 - val_acc: 0.2004\n",
      "Epoch 1567/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2375 - acc: 0.2167 - val_loss: 0.6290 - val_acc: 0.2004\n",
      "Epoch 1568/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2635 - acc: 0.2153 - val_loss: 0.7854 - val_acc: 0.2004\n",
      "Epoch 1569/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2328 - acc: 0.2167 - val_loss: 0.6837 - val_acc: 0.1985\n",
      "Epoch 1570/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2379 - acc: 0.2158 - val_loss: 0.8073 - val_acc: 0.1985\n",
      "Epoch 1571/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2564 - acc: 0.2153 - val_loss: 0.7411 - val_acc: 0.2004\n",
      "Epoch 1572/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.4372 - acc: 0.2144 - val_loss: 0.8641 - val_acc: 0.2004\n",
      "Epoch 1573/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3751 - acc: 0.2158 - val_loss: 0.6802 - val_acc: 0.2004\n",
      "Epoch 1574/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.8688 - acc: 0.2130 - val_loss: 0.6984 - val_acc: 0.2004\n",
      "Epoch 1575/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4331 - acc: 0.2144 - val_loss: 0.6458 - val_acc: 0.2004\n",
      "Epoch 1576/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3411 - acc: 0.2167 - val_loss: 0.7507 - val_acc: 0.2004\n",
      "Epoch 1577/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2836 - acc: 0.2158 - val_loss: 0.5991 - val_acc: 0.2004\n",
      "Epoch 1578/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2340 - acc: 0.2158 - val_loss: 0.6419 - val_acc: 0.2004\n",
      "Epoch 1579/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2314 - acc: 0.2158 - val_loss: 0.6564 - val_acc: 0.1985\n",
      "Epoch 1580/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2353 - acc: 0.2153 - val_loss: 0.6312 - val_acc: 0.1985\n",
      "Epoch 1581/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.2329 - acc: 0.2167 - val_loss: 0.6396 - val_acc: 0.1985\n",
      "Epoch 1582/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.2220 - acc: 0.2158 - val_loss: 0.6846 - val_acc: 0.2004\n",
      "Epoch 1583/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2416 - acc: 0.2158 - val_loss: 0.6275 - val_acc: 0.2004\n",
      "Epoch 1584/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2252 - acc: 0.2153 - val_loss: 0.6365 - val_acc: 0.1985\n",
      "Epoch 1585/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2266 - acc: 0.2162 - val_loss: 0.6819 - val_acc: 0.1985\n",
      "Epoch 1586/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2523 - acc: 0.2158 - val_loss: 0.6384 - val_acc: 0.2004\n",
      "Epoch 1587/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2352 - acc: 0.2158 - val_loss: 0.6195 - val_acc: 0.2004\n",
      "Epoch 1588/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2246 - acc: 0.2162 - val_loss: 0.6854 - val_acc: 0.1985\n",
      "Epoch 1589/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2225 - acc: 0.2162 - val_loss: 0.6213 - val_acc: 0.2004\n",
      "Epoch 1590/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2378 - acc: 0.2162 - val_loss: 0.6203 - val_acc: 0.2004\n",
      "Epoch 1591/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2436 - acc: 0.2162 - val_loss: 0.6608 - val_acc: 0.1985\n",
      "Epoch 1592/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2298 - acc: 0.2158 - val_loss: 0.7036 - val_acc: 0.2004\n",
      "Epoch 1593/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2711 - acc: 0.2162 - val_loss: 0.6817 - val_acc: 0.1985\n",
      "Epoch 1594/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2319 - acc: 0.2162 - val_loss: 0.6184 - val_acc: 0.2004\n",
      "Epoch 1595/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2172 - acc: 0.2158 - val_loss: 0.6591 - val_acc: 0.2004\n",
      "Epoch 1596/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2227 - acc: 0.2162 - val_loss: 0.6157 - val_acc: 0.2004\n",
      "Epoch 1597/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2251 - acc: 0.2167 - val_loss: 0.6464 - val_acc: 0.1985\n",
      "Epoch 1598/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2460 - acc: 0.2162 - val_loss: 0.7065 - val_acc: 0.1985\n",
      "Epoch 1599/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2390 - acc: 0.2162 - val_loss: 0.7888 - val_acc: 0.2004\n",
      "Epoch 1600/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2249 - acc: 0.2162 - val_loss: 0.6315 - val_acc: 0.2004\n",
      "Epoch 1601/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2247 - acc: 0.2172 - val_loss: 0.6544 - val_acc: 0.1985\n",
      "Epoch 1602/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2323 - acc: 0.2148 - val_loss: 0.6549 - val_acc: 0.2004\n",
      "Epoch 1603/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2544 - acc: 0.2158 - val_loss: 0.6367 - val_acc: 0.2004\n",
      "Epoch 1604/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2276 - acc: 0.2153 - val_loss: 0.6043 - val_acc: 0.2004\n",
      "Epoch 1605/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2521 - acc: 0.2153 - val_loss: 0.8246 - val_acc: 0.1985\n",
      "Epoch 1606/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2456 - acc: 0.2153 - val_loss: 0.6602 - val_acc: 0.2004\n",
      "Epoch 1607/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2280 - acc: 0.2167 - val_loss: 0.6272 - val_acc: 0.2004\n",
      "Epoch 1608/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3019 - acc: 0.2139 - val_loss: 0.6573 - val_acc: 0.1985\n",
      "Epoch 1609/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2500 - acc: 0.2148 - val_loss: 0.6121 - val_acc: 0.2004\n",
      "Epoch 1610/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2648 - acc: 0.2148 - val_loss: 0.7706 - val_acc: 0.1985\n",
      "Epoch 1611/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2430 - acc: 0.2167 - val_loss: 0.6719 - val_acc: 0.1985\n",
      "Epoch 1612/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2395 - acc: 0.2158 - val_loss: 0.6207 - val_acc: 0.2004\n",
      "Epoch 1613/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2436 - acc: 0.2162 - val_loss: 0.6214 - val_acc: 0.2004\n",
      "Epoch 1614/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2529 - acc: 0.2162 - val_loss: 0.6373 - val_acc: 0.1985\n",
      "Epoch 1615/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2330 - acc: 0.2153 - val_loss: 0.6110 - val_acc: 0.2004\n",
      "Epoch 1616/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2287 - acc: 0.2167 - val_loss: 0.5881 - val_acc: 0.2004\n",
      "Epoch 1617/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2441 - acc: 0.2153 - val_loss: 0.6697 - val_acc: 0.1985\n",
      "Epoch 1618/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2463 - acc: 0.2153 - val_loss: 0.6676 - val_acc: 0.1985\n",
      "Epoch 1619/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2426 - acc: 0.2148 - val_loss: 0.6436 - val_acc: 0.2004\n",
      "Epoch 1620/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2193 - acc: 0.2158 - val_loss: 0.6113 - val_acc: 0.2004\n",
      "Epoch 1621/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2162 - acc: 0.2158 - val_loss: 0.6471 - val_acc: 0.1985\n",
      "Epoch 1622/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2331 - acc: 0.2139 - val_loss: 0.6559 - val_acc: 0.2004\n",
      "Epoch 1623/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2306 - acc: 0.2167 - val_loss: 0.6482 - val_acc: 0.2004\n",
      "Epoch 1624/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2311 - acc: 0.2148 - val_loss: 0.6180 - val_acc: 0.2004\n",
      "Epoch 1625/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.2223 - acc: 0.2153 - val_loss: 0.6312 - val_acc: 0.1985\n",
      "Epoch 1626/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.2269 - acc: 0.2167 - val_loss: 0.6821 - val_acc: 0.1985\n",
      "Epoch 1627/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2499 - acc: 0.2158 - val_loss: 0.6216 - val_acc: 0.2004\n",
      "Epoch 1628/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2282 - acc: 0.2158 - val_loss: 0.6237 - val_acc: 0.2004\n",
      "Epoch 1629/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2305 - acc: 0.2153 - val_loss: 0.6301 - val_acc: 0.2004\n",
      "Epoch 1630/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2297 - acc: 0.2144 - val_loss: 0.6245 - val_acc: 0.2004\n",
      "Epoch 1631/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2742 - acc: 0.2139 - val_loss: 0.6829 - val_acc: 0.1985\n",
      "Epoch 1632/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2351 - acc: 0.2158 - val_loss: 0.6467 - val_acc: 0.1985\n",
      "Epoch 1633/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2402 - acc: 0.2144 - val_loss: 0.7156 - val_acc: 0.1985\n",
      "Epoch 1634/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2624 - acc: 0.2158 - val_loss: 0.6485 - val_acc: 0.1985\n",
      "Epoch 1635/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2312 - acc: 0.2148 - val_loss: 0.6760 - val_acc: 0.2004\n",
      "Epoch 1636/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2290 - acc: 0.2153 - val_loss: 0.6923 - val_acc: 0.1985\n",
      "Epoch 1637/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2424 - acc: 0.2144 - val_loss: 0.7144 - val_acc: 0.2004\n",
      "Epoch 1638/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2498 - acc: 0.2144 - val_loss: 0.6199 - val_acc: 0.2004\n",
      "Epoch 1639/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2392 - acc: 0.2162 - val_loss: 0.6236 - val_acc: 0.2004\n",
      "Epoch 1640/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2347 - acc: 0.2167 - val_loss: 0.6484 - val_acc: 0.2004\n",
      "Epoch 1641/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2378 - acc: 0.2167 - val_loss: 0.6197 - val_acc: 0.2004\n",
      "Epoch 1642/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2278 - acc: 0.2162 - val_loss: 0.6950 - val_acc: 0.2004\n",
      "Epoch 1643/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2352 - acc: 0.2148 - val_loss: 0.6304 - val_acc: 0.2004\n",
      "Epoch 1644/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2542 - acc: 0.2148 - val_loss: 0.6435 - val_acc: 0.1985\n",
      "Epoch 1645/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2269 - acc: 0.2153 - val_loss: 0.6231 - val_acc: 0.1985\n",
      "Epoch 1646/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2467 - acc: 0.2162 - val_loss: 0.5907 - val_acc: 0.2004\n",
      "Epoch 1647/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2308 - acc: 0.2158 - val_loss: 0.6488 - val_acc: 0.1985\n",
      "Epoch 1648/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2341 - acc: 0.2153 - val_loss: 0.6278 - val_acc: 0.2004\n",
      "Epoch 1649/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2263 - acc: 0.2158 - val_loss: 0.8529 - val_acc: 0.1985\n",
      "Epoch 1650/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2481 - acc: 0.2148 - val_loss: 0.7125 - val_acc: 0.2004\n",
      "Epoch 1651/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2541 - acc: 0.2153 - val_loss: 0.6273 - val_acc: 0.2004\n",
      "Epoch 1652/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2611 - acc: 0.2158 - val_loss: 0.8156 - val_acc: 0.1985\n",
      "Epoch 1653/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2569 - acc: 0.2148 - val_loss: 0.6516 - val_acc: 0.2004\n",
      "Epoch 1654/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2481 - acc: 0.2162 - val_loss: 0.6768 - val_acc: 0.1985\n",
      "Epoch 1655/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2344 - acc: 0.2162 - val_loss: 0.6405 - val_acc: 0.2004\n",
      "Epoch 1656/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2282 - acc: 0.2162 - val_loss: 0.6313 - val_acc: 0.1985\n",
      "Epoch 1657/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2295 - acc: 0.2162 - val_loss: 0.6356 - val_acc: 0.2004\n",
      "Epoch 1658/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2454 - acc: 0.2158 - val_loss: 0.6590 - val_acc: 0.2004\n",
      "Epoch 1659/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2508 - acc: 0.2158 - val_loss: 0.6274 - val_acc: 0.2004\n",
      "Epoch 1660/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2577 - acc: 0.2158 - val_loss: 0.6132 - val_acc: 0.2004\n",
      "Epoch 1661/4000\n",
      "68/68 [==============================] - 5s 72ms/step - loss: 0.2317 - acc: 0.2158 - val_loss: 0.7486 - val_acc: 0.1985\n",
      "Epoch 1662/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2880 - acc: 0.2158 - val_loss: 0.6211 - val_acc: 0.2004\n",
      "Epoch 1663/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2339 - acc: 0.2158 - val_loss: 0.6440 - val_acc: 0.2004\n",
      "Epoch 1664/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2335 - acc: 0.2167 - val_loss: 0.5805 - val_acc: 0.2004\n",
      "Epoch 1665/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.2747 - acc: 0.2167 - val_loss: 1.0310 - val_acc: 0.2004\n",
      "Epoch 1666/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4013 - acc: 0.2144 - val_loss: 0.9459 - val_acc: 0.1911\n",
      "Epoch 1667/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4028 - acc: 0.2139 - val_loss: 0.8517 - val_acc: 0.1985\n",
      "Epoch 1668/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 1.2213 - acc: 0.2079 - val_loss: 1.3772 - val_acc: 0.1800\n",
      "Epoch 1669/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 1.7662 - acc: 0.1981 - val_loss: 0.7787 - val_acc: 0.1985\n",
      "Epoch 1670/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.3553 - acc: 0.2162 - val_loss: 0.5666 - val_acc: 0.2004\n",
      "Epoch 1671/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3429 - acc: 0.2162 - val_loss: 0.6487 - val_acc: 0.2004\n",
      "Epoch 1672/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2612 - acc: 0.2162 - val_loss: 0.5896 - val_acc: 0.2004\n",
      "Epoch 1673/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2263 - acc: 0.2172 - val_loss: 0.6003 - val_acc: 0.1985\n",
      "Epoch 1674/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2223 - acc: 0.2162 - val_loss: 0.6149 - val_acc: 0.2004\n",
      "Epoch 1675/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2197 - acc: 0.2153 - val_loss: 0.6720 - val_acc: 0.2004\n",
      "Epoch 1676/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2153 - acc: 0.2162 - val_loss: 0.6546 - val_acc: 0.2004\n",
      "Epoch 1677/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2255 - acc: 0.2153 - val_loss: 0.6125 - val_acc: 0.1985\n",
      "Epoch 1678/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2355 - acc: 0.2162 - val_loss: 0.7213 - val_acc: 0.1985\n",
      "Epoch 1679/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2193 - acc: 0.2162 - val_loss: 0.6062 - val_acc: 0.2004\n",
      "Epoch 1680/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2148 - acc: 0.2158 - val_loss: 0.6082 - val_acc: 0.2004\n",
      "Epoch 1681/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2155 - acc: 0.2162 - val_loss: 0.6144 - val_acc: 0.2004\n",
      "Epoch 1682/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2115 - acc: 0.2162 - val_loss: 0.6194 - val_acc: 0.2004\n",
      "Epoch 1683/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2197 - acc: 0.2162 - val_loss: 0.6150 - val_acc: 0.2004\n",
      "Epoch 1684/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2112 - acc: 0.2162 - val_loss: 0.6690 - val_acc: 0.2004\n",
      "Epoch 1685/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2228 - acc: 0.2162 - val_loss: 0.6417 - val_acc: 0.2004\n",
      "Epoch 1686/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2402 - acc: 0.2167 - val_loss: 0.6288 - val_acc: 0.1985\n",
      "Epoch 1687/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2187 - acc: 0.2162 - val_loss: 0.6506 - val_acc: 0.1985\n",
      "Epoch 1688/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2280 - acc: 0.2148 - val_loss: 0.6027 - val_acc: 0.2004\n",
      "Epoch 1689/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2162 - acc: 0.2167 - val_loss: 0.6897 - val_acc: 0.2004\n",
      "Epoch 1690/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2255 - acc: 0.2167 - val_loss: 0.6316 - val_acc: 0.1985\n",
      "Epoch 1691/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2370 - acc: 0.2158 - val_loss: 0.6237 - val_acc: 0.2004\n",
      "Epoch 1692/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2314 - acc: 0.2148 - val_loss: 0.6314 - val_acc: 0.2004\n",
      "Epoch 1693/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2387 - acc: 0.2162 - val_loss: 0.6107 - val_acc: 0.2004\n",
      "Epoch 1694/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2367 - acc: 0.2148 - val_loss: 0.6122 - val_acc: 0.2004\n",
      "Epoch 1695/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2262 - acc: 0.2172 - val_loss: 0.6300 - val_acc: 0.1985\n",
      "Epoch 1696/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2358 - acc: 0.2158 - val_loss: 0.6130 - val_acc: 0.2004\n",
      "Epoch 1697/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2505 - acc: 0.2158 - val_loss: 0.6218 - val_acc: 0.1985\n",
      "Epoch 1698/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2229 - acc: 0.2153 - val_loss: 0.6149 - val_acc: 0.2004\n",
      "Epoch 1699/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2308 - acc: 0.2172 - val_loss: 0.6093 - val_acc: 0.2004\n",
      "Epoch 1700/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2286 - acc: 0.2167 - val_loss: 0.7240 - val_acc: 0.1985\n",
      "Epoch 1701/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2484 - acc: 0.2162 - val_loss: 0.6259 - val_acc: 0.2004\n",
      "Epoch 1702/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2308 - acc: 0.2158 - val_loss: 0.6762 - val_acc: 0.2004\n",
      "Epoch 1703/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2782 - acc: 0.2144 - val_loss: 0.6094 - val_acc: 0.2004\n",
      "Epoch 1704/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2490 - acc: 0.2162 - val_loss: 0.5950 - val_acc: 0.2004\n",
      "Epoch 1705/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2235 - acc: 0.2158 - val_loss: 0.6130 - val_acc: 0.2004\n",
      "Epoch 1706/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2225 - acc: 0.2162 - val_loss: 0.6318 - val_acc: 0.2004\n",
      "Epoch 1707/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2263 - acc: 0.2153 - val_loss: 0.6106 - val_acc: 0.2004\n",
      "Epoch 1708/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2345 - acc: 0.2167 - val_loss: 0.6078 - val_acc: 0.2004\n",
      "Epoch 1709/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2284 - acc: 0.2153 - val_loss: 0.6207 - val_acc: 0.2004\n",
      "Epoch 1710/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2261 - acc: 0.2167 - val_loss: 0.6267 - val_acc: 0.2004\n",
      "Epoch 1711/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2384 - acc: 0.2162 - val_loss: 0.5934 - val_acc: 0.2004\n",
      "Epoch 1712/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2180 - acc: 0.2158 - val_loss: 0.6064 - val_acc: 0.2004\n",
      "Epoch 1713/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2156 - acc: 0.2148 - val_loss: 0.6185 - val_acc: 0.2004\n",
      "Epoch 1714/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2263 - acc: 0.2162 - val_loss: 0.7162 - val_acc: 0.2004\n",
      "Epoch 1715/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2430 - acc: 0.2153 - val_loss: 0.5954 - val_acc: 0.2004\n",
      "Epoch 1716/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2451 - acc: 0.2153 - val_loss: 0.6574 - val_acc: 0.2004\n",
      "Epoch 1717/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2250 - acc: 0.2158 - val_loss: 0.6900 - val_acc: 0.1985\n",
      "Epoch 1718/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2625 - acc: 0.2167 - val_loss: 0.5902 - val_acc: 0.2004\n",
      "Epoch 1719/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2300 - acc: 0.2162 - val_loss: 0.6231 - val_acc: 0.2004\n",
      "Epoch 1720/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2200 - acc: 0.2153 - val_loss: 0.6209 - val_acc: 0.2004\n",
      "Epoch 1721/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2156 - acc: 0.2162 - val_loss: 0.6148 - val_acc: 0.2004\n",
      "Epoch 1722/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2191 - acc: 0.2158 - val_loss: 0.6359 - val_acc: 0.2004\n",
      "Epoch 1723/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2203 - acc: 0.2158 - val_loss: 0.6004 - val_acc: 0.2004\n",
      "Epoch 1724/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2235 - acc: 0.2162 - val_loss: 0.6426 - val_acc: 0.2004\n",
      "Epoch 1725/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2390 - acc: 0.2158 - val_loss: 0.6325 - val_acc: 0.2004\n",
      "Epoch 1726/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2683 - acc: 0.2153 - val_loss: 0.6329 - val_acc: 0.2004\n",
      "Epoch 1727/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2384 - acc: 0.2158 - val_loss: 0.6444 - val_acc: 0.2004\n",
      "Epoch 1728/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2305 - acc: 0.2162 - val_loss: 0.6610 - val_acc: 0.2004\n",
      "Epoch 1729/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2436 - acc: 0.2162 - val_loss: 0.6372 - val_acc: 0.2004\n",
      "Epoch 1730/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2331 - acc: 0.2158 - val_loss: 0.6390 - val_acc: 0.2004\n",
      "Epoch 1731/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2785 - acc: 0.2148 - val_loss: 0.6762 - val_acc: 0.1985\n",
      "Epoch 1732/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2259 - acc: 0.2162 - val_loss: 0.6412 - val_acc: 0.1985\n",
      "Epoch 1733/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2521 - acc: 0.2158 - val_loss: 0.6155 - val_acc: 0.2004\n",
      "Epoch 1734/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2201 - acc: 0.2158 - val_loss: 0.6189 - val_acc: 0.2004\n",
      "Epoch 1735/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2271 - acc: 0.2158 - val_loss: 0.6077 - val_acc: 0.2004\n",
      "Epoch 1736/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2154 - acc: 0.2162 - val_loss: 0.6445 - val_acc: 0.2004\n",
      "Epoch 1737/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2405 - acc: 0.2148 - val_loss: 0.6577 - val_acc: 0.1985\n",
      "Epoch 1738/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2135 - acc: 0.2162 - val_loss: 0.6145 - val_acc: 0.2004\n",
      "Epoch 1739/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2322 - acc: 0.2153 - val_loss: 0.5915 - val_acc: 0.2004\n",
      "Epoch 1740/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2163 - acc: 0.2158 - val_loss: 0.6014 - val_acc: 0.2004\n",
      "Epoch 1741/4000\n",
      "68/68 [==============================] - 5s 71ms/step - loss: 0.2204 - acc: 0.2158 - val_loss: 0.6506 - val_acc: 0.2004\n",
      "Epoch 1742/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2339 - acc: 0.2158 - val_loss: 0.6410 - val_acc: 0.1985\n",
      "Epoch 1743/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2342 - acc: 0.2162 - val_loss: 0.5826 - val_acc: 0.2004\n",
      "Epoch 1744/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2325 - acc: 0.2158 - val_loss: 0.6535 - val_acc: 0.2004\n",
      "Epoch 1745/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2394 - acc: 0.2158 - val_loss: 0.7737 - val_acc: 0.2004\n",
      "Epoch 1746/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2362 - acc: 0.2167 - val_loss: 0.6727 - val_acc: 0.2004\n",
      "Epoch 1747/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2391 - acc: 0.2158 - val_loss: 0.7327 - val_acc: 0.2004\n",
      "Epoch 1748/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2539 - acc: 0.2158 - val_loss: 0.6696 - val_acc: 0.2004\n",
      "Epoch 1749/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2399 - acc: 0.2153 - val_loss: 0.7309 - val_acc: 0.1985\n",
      "Epoch 1750/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2290 - acc: 0.2148 - val_loss: 0.5895 - val_acc: 0.2004\n",
      "Epoch 1751/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2145 - acc: 0.2148 - val_loss: 0.6359 - val_acc: 0.2004\n",
      "Epoch 1752/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2175 - acc: 0.2158 - val_loss: 0.5994 - val_acc: 0.2004\n",
      "Epoch 1753/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2536 - acc: 0.2148 - val_loss: 0.6315 - val_acc: 0.1985\n",
      "Epoch 1754/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2645 - acc: 0.2153 - val_loss: 0.6197 - val_acc: 0.2004\n",
      "Epoch 1755/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2829 - acc: 0.2148 - val_loss: 0.6202 - val_acc: 0.1985\n",
      "Epoch 1756/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2254 - acc: 0.2162 - val_loss: 0.6174 - val_acc: 0.2004\n",
      "Epoch 1757/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2300 - acc: 0.2162 - val_loss: 0.7167 - val_acc: 0.1985\n",
      "Epoch 1758/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2374 - acc: 0.2153 - val_loss: 0.6342 - val_acc: 0.2004\n",
      "Epoch 1759/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2321 - acc: 0.2158 - val_loss: 0.8966 - val_acc: 0.2004\n",
      "Epoch 1760/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2754 - acc: 0.2144 - val_loss: 0.6475 - val_acc: 0.2004\n",
      "Epoch 1761/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2195 - acc: 0.2162 - val_loss: 0.6309 - val_acc: 0.2004\n",
      "Epoch 1762/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2573 - acc: 0.2153 - val_loss: 0.6210 - val_acc: 0.2004\n",
      "Epoch 1763/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2441 - acc: 0.2162 - val_loss: 0.9215 - val_acc: 0.1967\n",
      "Epoch 1764/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2898 - acc: 0.2162 - val_loss: 0.7003 - val_acc: 0.2004\n",
      "Epoch 1765/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2659 - acc: 0.2158 - val_loss: 0.6536 - val_acc: 0.2004\n",
      "Epoch 1766/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2536 - acc: 0.2148 - val_loss: 0.7988 - val_acc: 0.1985\n",
      "Epoch 1767/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2612 - acc: 0.2162 - val_loss: 0.7358 - val_acc: 0.2004\n",
      "Epoch 1768/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2488 - acc: 0.2162 - val_loss: 0.6250 - val_acc: 0.2004\n",
      "Epoch 1769/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2518 - acc: 0.2153 - val_loss: 0.5763 - val_acc: 0.2004\n",
      "Epoch 1770/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2357 - acc: 0.2162 - val_loss: 0.6581 - val_acc: 0.2004\n",
      "Epoch 1771/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2347 - acc: 0.2158 - val_loss: 0.5978 - val_acc: 0.2004\n",
      "Epoch 1772/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2134 - acc: 0.2158 - val_loss: 0.6537 - val_acc: 0.2004\n",
      "Epoch 1773/4000\n",
      "68/68 [==============================] - 4s 56ms/step - loss: 0.2247 - acc: 0.2162 - val_loss: 0.6009 - val_acc: 0.2004\n",
      "Epoch 1774/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2416 - acc: 0.2162 - val_loss: 0.6538 - val_acc: 0.1985\n",
      "Epoch 1775/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2393 - acc: 0.2158 - val_loss: 0.6771 - val_acc: 0.1985\n",
      "Epoch 1776/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2664 - acc: 0.2158 - val_loss: 0.6497 - val_acc: 0.1985\n",
      "Epoch 1777/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2251 - acc: 0.2158 - val_loss: 0.6781 - val_acc: 0.1985\n",
      "Epoch 1778/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2564 - acc: 0.2148 - val_loss: 0.6448 - val_acc: 0.2004\n",
      "Epoch 1779/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2451 - acc: 0.2158 - val_loss: 0.6102 - val_acc: 0.2004\n",
      "Epoch 1780/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.2257 - acc: 0.2158 - val_loss: 0.6308 - val_acc: 0.2004\n",
      "Epoch 1781/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2128 - acc: 0.2167 - val_loss: 0.6280 - val_acc: 0.2004\n",
      "Epoch 1782/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2215 - acc: 0.2167 - val_loss: 0.6801 - val_acc: 0.1985\n",
      "Epoch 1783/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2361 - acc: 0.2162 - val_loss: 0.6414 - val_acc: 0.2004\n",
      "Epoch 1784/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2301 - acc: 0.2153 - val_loss: 0.6127 - val_acc: 0.1985\n",
      "Epoch 1785/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2410 - acc: 0.2148 - val_loss: 0.6911 - val_acc: 0.1985\n",
      "Epoch 1786/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2696 - acc: 0.2130 - val_loss: 0.6054 - val_acc: 0.2004\n",
      "Epoch 1787/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2231 - acc: 0.2162 - val_loss: 0.6328 - val_acc: 0.1985\n",
      "Epoch 1788/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2125 - acc: 0.2162 - val_loss: 0.6033 - val_acc: 0.2004\n",
      "Epoch 1789/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2285 - acc: 0.2162 - val_loss: 0.7261 - val_acc: 0.1985\n",
      "Epoch 1790/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2331 - acc: 0.2148 - val_loss: 0.6869 - val_acc: 0.1985\n",
      "Epoch 1791/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2139 - acc: 0.2167 - val_loss: 0.7516 - val_acc: 0.1985\n",
      "Epoch 1792/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2629 - acc: 0.2158 - val_loss: 0.6773 - val_acc: 0.2004\n",
      "Epoch 1793/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2435 - acc: 0.2148 - val_loss: 0.5898 - val_acc: 0.1985\n",
      "Epoch 1794/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2388 - acc: 0.2162 - val_loss: 0.6134 - val_acc: 0.2004\n",
      "Epoch 1795/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2598 - acc: 0.2148 - val_loss: 0.5886 - val_acc: 0.2004\n",
      "Epoch 1796/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2674 - acc: 0.2162 - val_loss: 0.7310 - val_acc: 0.1985\n",
      "Epoch 1797/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2418 - acc: 0.2172 - val_loss: 0.6091 - val_acc: 0.1985\n",
      "Epoch 1798/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2530 - acc: 0.2162 - val_loss: 0.6623 - val_acc: 0.2004\n",
      "Epoch 1799/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2717 - acc: 0.2162 - val_loss: 0.6024 - val_acc: 0.2004\n",
      "Epoch 1800/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2373 - acc: 0.2162 - val_loss: 0.6301 - val_acc: 0.2004\n",
      "Epoch 1801/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2282 - acc: 0.2148 - val_loss: 0.6957 - val_acc: 0.2004\n",
      "Epoch 1802/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2231 - acc: 0.2158 - val_loss: 0.6124 - val_acc: 0.2004\n",
      "Epoch 1803/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2411 - acc: 0.2162 - val_loss: 0.6675 - val_acc: 0.1985\n",
      "Epoch 1804/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2363 - acc: 0.2153 - val_loss: 0.6401 - val_acc: 0.1985\n",
      "Epoch 1805/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2867 - acc: 0.2139 - val_loss: 0.8082 - val_acc: 0.2004\n",
      "Epoch 1806/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2413 - acc: 0.2153 - val_loss: 0.7106 - val_acc: 0.2004\n",
      "Epoch 1807/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2476 - acc: 0.2158 - val_loss: 0.6647 - val_acc: 0.2004\n",
      "Epoch 1808/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2438 - acc: 0.2148 - val_loss: 0.6237 - val_acc: 0.2004\n",
      "Epoch 1809/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2168 - acc: 0.2162 - val_loss: 0.6114 - val_acc: 0.2004\n",
      "Epoch 1810/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2137 - acc: 0.2162 - val_loss: 0.6547 - val_acc: 0.1985\n",
      "Epoch 1811/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2175 - acc: 0.2158 - val_loss: 0.6062 - val_acc: 0.2004\n",
      "Epoch 1812/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2233 - acc: 0.2162 - val_loss: 0.6520 - val_acc: 0.1985\n",
      "Epoch 1813/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2166 - acc: 0.2158 - val_loss: 0.6192 - val_acc: 0.2004\n",
      "Epoch 1814/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2180 - acc: 0.2153 - val_loss: 0.6665 - val_acc: 0.2004\n",
      "Epoch 1815/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2110 - acc: 0.2153 - val_loss: 0.6053 - val_acc: 0.2004\n",
      "Epoch 1816/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2469 - acc: 0.2153 - val_loss: 0.6860 - val_acc: 0.2004\n",
      "Epoch 1817/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2259 - acc: 0.2158 - val_loss: 0.6479 - val_acc: 0.1985\n",
      "Epoch 1818/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2224 - acc: 0.2153 - val_loss: 0.7493 - val_acc: 0.1985\n",
      "Epoch 1819/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2430 - acc: 0.2162 - val_loss: 0.6115 - val_acc: 0.1985\n",
      "Epoch 1820/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2417 - acc: 0.2144 - val_loss: 0.6371 - val_acc: 0.2004\n",
      "Epoch 1821/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 0.2255 - acc: 0.2158 - val_loss: 0.7031 - val_acc: 0.1985\n",
      "Epoch 1822/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.2450 - acc: 0.2167 - val_loss: 0.6470 - val_acc: 0.2004\n",
      "Epoch 1823/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2179 - acc: 0.2158 - val_loss: 0.6592 - val_acc: 0.1985\n",
      "Epoch 1824/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2137 - acc: 0.2153 - val_loss: 0.6248 - val_acc: 0.2004\n",
      "Epoch 1825/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2434 - acc: 0.2162 - val_loss: 0.6158 - val_acc: 0.2004\n",
      "Epoch 1826/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2261 - acc: 0.2162 - val_loss: 0.6355 - val_acc: 0.2004\n",
      "Epoch 1827/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2340 - acc: 0.2158 - val_loss: 0.6263 - val_acc: 0.2004\n",
      "Epoch 1828/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2327 - acc: 0.2148 - val_loss: 0.7102 - val_acc: 0.1985\n",
      "Epoch 1829/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2329 - acc: 0.2158 - val_loss: 0.6177 - val_acc: 0.2004\n",
      "Epoch 1830/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2276 - acc: 0.2162 - val_loss: 0.6448 - val_acc: 0.2004\n",
      "Epoch 1831/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2793 - acc: 0.2144 - val_loss: 0.7210 - val_acc: 0.2004\n",
      "Epoch 1832/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2137 - acc: 0.2153 - val_loss: 0.6189 - val_acc: 0.1985\n",
      "Epoch 1833/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.2069 - acc: 0.2158 - val_loss: 0.6216 - val_acc: 0.2004\n",
      "Epoch 1834/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2160 - acc: 0.2162 - val_loss: 0.6384 - val_acc: 0.1985\n",
      "Epoch 1835/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2508 - acc: 0.2153 - val_loss: 1.0292 - val_acc: 0.2004\n",
      "Epoch 1836/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2404 - acc: 0.2148 - val_loss: 0.6474 - val_acc: 0.2004\n",
      "Epoch 1837/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2733 - acc: 0.2153 - val_loss: 0.6946 - val_acc: 0.2004\n",
      "Epoch 1838/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2524 - acc: 0.2153 - val_loss: 0.6513 - val_acc: 0.2004\n",
      "Epoch 1839/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2297 - acc: 0.2162 - val_loss: 0.6254 - val_acc: 0.2004\n",
      "Epoch 1840/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3164 - acc: 0.2148 - val_loss: 0.6697 - val_acc: 0.2004\n",
      "Epoch 1841/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2477 - acc: 0.2153 - val_loss: 0.7516 - val_acc: 0.1985\n",
      "Epoch 1842/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2428 - acc: 0.2162 - val_loss: 0.6866 - val_acc: 0.2004\n",
      "Epoch 1843/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2619 - acc: 0.2144 - val_loss: 0.7745 - val_acc: 0.2004\n",
      "Epoch 1844/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2791 - acc: 0.2153 - val_loss: 0.6246 - val_acc: 0.1985\n",
      "Epoch 1845/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2959 - acc: 0.2162 - val_loss: 0.7742 - val_acc: 0.2004\n",
      "Epoch 1846/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2304 - acc: 0.2158 - val_loss: 0.5997 - val_acc: 0.1985\n",
      "Epoch 1847/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2291 - acc: 0.2158 - val_loss: 0.6994 - val_acc: 0.2004\n",
      "Epoch 1848/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2248 - acc: 0.2167 - val_loss: 0.6372 - val_acc: 0.2004\n",
      "Epoch 1849/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2431 - acc: 0.2148 - val_loss: 0.6352 - val_acc: 0.2004\n",
      "Epoch 1850/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2247 - acc: 0.2158 - val_loss: 0.6177 - val_acc: 0.1985\n",
      "Epoch 1851/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2216 - acc: 0.2167 - val_loss: 0.6251 - val_acc: 0.2004\n",
      "Epoch 1852/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2385 - acc: 0.2158 - val_loss: 0.6200 - val_acc: 0.2004\n",
      "Epoch 1853/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2191 - acc: 0.2153 - val_loss: 0.6257 - val_acc: 0.1985\n",
      "Epoch 1854/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2141 - acc: 0.2158 - val_loss: 0.5957 - val_acc: 0.2004\n",
      "Epoch 1855/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2136 - acc: 0.2153 - val_loss: 0.6145 - val_acc: 0.2004\n",
      "Epoch 1856/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2130 - acc: 0.2162 - val_loss: 0.6292 - val_acc: 0.1985\n",
      "Epoch 1857/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2217 - acc: 0.2158 - val_loss: 0.6314 - val_acc: 0.2004\n",
      "Epoch 1858/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2186 - acc: 0.2162 - val_loss: 0.6079 - val_acc: 0.2004\n",
      "Epoch 1859/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2242 - acc: 0.2148 - val_loss: 0.6241 - val_acc: 0.2004\n",
      "Epoch 1860/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2198 - acc: 0.2158 - val_loss: 0.6375 - val_acc: 0.2004\n",
      "Epoch 1861/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2353 - acc: 0.2158 - val_loss: 0.6154 - val_acc: 0.2004\n",
      "Epoch 1862/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2202 - acc: 0.2148 - val_loss: 0.6933 - val_acc: 0.2004\n",
      "Epoch 1863/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2466 - acc: 0.2153 - val_loss: 0.6318 - val_acc: 0.2004\n",
      "Epoch 1864/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2190 - acc: 0.2153 - val_loss: 0.7019 - val_acc: 0.2004\n",
      "Epoch 1865/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2954 - acc: 0.2130 - val_loss: 0.6448 - val_acc: 0.2004\n",
      "Epoch 1866/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2059 - acc: 0.2162 - val_loss: 0.6837 - val_acc: 0.1985\n",
      "Epoch 1867/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2294 - acc: 0.2153 - val_loss: 0.6241 - val_acc: 0.2004\n",
      "Epoch 1868/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2269 - acc: 0.2144 - val_loss: 0.7343 - val_acc: 0.2004\n",
      "Epoch 1869/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2219 - acc: 0.2158 - val_loss: 0.6306 - val_acc: 0.2004\n",
      "Epoch 1870/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2180 - acc: 0.2148 - val_loss: 0.6182 - val_acc: 0.2004\n",
      "Epoch 1871/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2293 - acc: 0.2158 - val_loss: 0.6747 - val_acc: 0.1985\n",
      "Epoch 1872/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2187 - acc: 0.2158 - val_loss: 0.6696 - val_acc: 0.2004\n",
      "Epoch 1873/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2202 - acc: 0.2153 - val_loss: 0.6116 - val_acc: 0.1985\n",
      "Epoch 1874/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2521 - acc: 0.2162 - val_loss: 0.6076 - val_acc: 0.2004\n",
      "Epoch 1875/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2399 - acc: 0.2172 - val_loss: 0.6633 - val_acc: 0.2004\n",
      "Epoch 1876/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2291 - acc: 0.2167 - val_loss: 0.7252 - val_acc: 0.2004\n",
      "Epoch 1877/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2277 - acc: 0.2158 - val_loss: 0.6286 - val_acc: 0.2004\n",
      "Epoch 1878/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2346 - acc: 0.2158 - val_loss: 0.6157 - val_acc: 0.2004\n",
      "Epoch 1879/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2098 - acc: 0.2158 - val_loss: 0.6467 - val_acc: 0.1985\n",
      "Epoch 1880/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2361 - acc: 0.2153 - val_loss: 0.6779 - val_acc: 0.2004\n",
      "Epoch 1881/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2338 - acc: 0.2148 - val_loss: 0.7785 - val_acc: 0.2004\n",
      "Epoch 1882/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2153 - acc: 0.2162 - val_loss: 0.6231 - val_acc: 0.2004\n",
      "Epoch 1883/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2295 - acc: 0.2148 - val_loss: 0.6348 - val_acc: 0.1985\n",
      "Epoch 1884/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2227 - acc: 0.2148 - val_loss: 0.6440 - val_acc: 0.1985\n",
      "Epoch 1885/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2090 - acc: 0.2172 - val_loss: 0.6513 - val_acc: 0.2004\n",
      "Epoch 1886/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2134 - acc: 0.2158 - val_loss: 0.6253 - val_acc: 0.1985\n",
      "Epoch 1887/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2299 - acc: 0.2158 - val_loss: 0.6113 - val_acc: 0.2004\n",
      "Epoch 1888/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2271 - acc: 0.2139 - val_loss: 0.6414 - val_acc: 0.1985\n",
      "Epoch 1889/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2392 - acc: 0.2153 - val_loss: 0.6189 - val_acc: 0.2004\n",
      "Epoch 1890/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2687 - acc: 0.2153 - val_loss: 0.6236 - val_acc: 0.2004\n",
      "Epoch 1891/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2165 - acc: 0.2158 - val_loss: 0.6366 - val_acc: 0.2004\n",
      "Epoch 1892/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2061 - acc: 0.2158 - val_loss: 0.6648 - val_acc: 0.2004\n",
      "Epoch 1893/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2535 - acc: 0.2148 - val_loss: 0.6184 - val_acc: 0.2004\n",
      "Epoch 1894/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2120 - acc: 0.2162 - val_loss: 0.6105 - val_acc: 0.2004\n",
      "Epoch 1895/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2301 - acc: 0.2158 - val_loss: 0.5978 - val_acc: 0.2004\n",
      "Epoch 1896/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2199 - acc: 0.2144 - val_loss: 0.6338 - val_acc: 0.2004\n",
      "Epoch 1897/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2316 - acc: 0.2158 - val_loss: 0.6994 - val_acc: 0.1985\n",
      "Epoch 1898/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2581 - acc: 0.2172 - val_loss: 0.5964 - val_acc: 0.2004\n",
      "Epoch 1899/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2455 - acc: 0.2162 - val_loss: 0.5956 - val_acc: 0.2004\n",
      "Epoch 1900/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2470 - acc: 0.2158 - val_loss: 0.6852 - val_acc: 0.2004\n",
      "Epoch 1901/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2765 - acc: 0.2158 - val_loss: 0.6793 - val_acc: 0.2004\n",
      "Epoch 1902/4000\n",
      "68/68 [==============================] - 5s 71ms/step - loss: 0.2551 - acc: 0.2158 - val_loss: 0.6345 - val_acc: 0.1985\n",
      "Epoch 1903/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3829 - acc: 0.2148 - val_loss: 0.6445 - val_acc: 0.2004\n",
      "Epoch 1904/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3336 - acc: 0.2162 - val_loss: 0.6168 - val_acc: 0.2004\n",
      "Epoch 1905/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2420 - acc: 0.2158 - val_loss: 0.6410 - val_acc: 0.2004\n",
      "Epoch 1906/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3357 - acc: 0.2167 - val_loss: 0.7215 - val_acc: 0.2004\n",
      "Epoch 1907/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.5517 - acc: 0.2144 - val_loss: 1.0086 - val_acc: 0.1985\n",
      "Epoch 1908/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.9497 - acc: 0.2042 - val_loss: 0.8520 - val_acc: 0.2004\n",
      "Epoch 1909/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.3244 - acc: 0.2153 - val_loss: 0.5691 - val_acc: 0.2004\n",
      "Epoch 1910/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.4330 - acc: 0.2162 - val_loss: 0.5770 - val_acc: 0.2004\n",
      "Epoch 1911/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2750 - acc: 0.2167 - val_loss: 0.6538 - val_acc: 0.2004\n",
      "Epoch 1912/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2245 - acc: 0.2162 - val_loss: 0.5566 - val_acc: 0.2004\n",
      "Epoch 1913/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2160 - acc: 0.2162 - val_loss: 0.5963 - val_acc: 0.2004\n",
      "Epoch 1914/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2228 - acc: 0.2162 - val_loss: 0.6658 - val_acc: 0.1985\n",
      "Epoch 1915/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2119 - acc: 0.2153 - val_loss: 0.5968 - val_acc: 0.2004\n",
      "Epoch 1916/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2411 - acc: 0.2153 - val_loss: 0.5842 - val_acc: 0.2004\n",
      "Epoch 1917/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2054 - acc: 0.2162 - val_loss: 0.6001 - val_acc: 0.2004\n",
      "Epoch 1918/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2109 - acc: 0.2158 - val_loss: 0.6672 - val_acc: 0.1985\n",
      "Epoch 1919/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2345 - acc: 0.2153 - val_loss: 0.6627 - val_acc: 0.1985\n",
      "Epoch 1920/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2119 - acc: 0.2162 - val_loss: 0.6288 - val_acc: 0.1985\n",
      "Epoch 1921/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2376 - acc: 0.2153 - val_loss: 0.7072 - val_acc: 0.2004\n",
      "Epoch 1922/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2210 - acc: 0.2153 - val_loss: 0.6333 - val_acc: 0.1985\n",
      "Epoch 1923/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2183 - acc: 0.2158 - val_loss: 0.5946 - val_acc: 0.2004\n",
      "Epoch 1924/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2046 - acc: 0.2153 - val_loss: 0.5777 - val_acc: 0.2004\n",
      "Epoch 1925/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2244 - acc: 0.2158 - val_loss: 0.6536 - val_acc: 0.2004\n",
      "Epoch 1926/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2170 - acc: 0.2158 - val_loss: 0.6502 - val_acc: 0.2004\n",
      "Epoch 1927/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2357 - acc: 0.2162 - val_loss: 0.5999 - val_acc: 0.2004\n",
      "Epoch 1928/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2225 - acc: 0.2158 - val_loss: 0.6120 - val_acc: 0.2004\n",
      "Epoch 1929/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2346 - acc: 0.2144 - val_loss: 0.5893 - val_acc: 0.2004\n",
      "Epoch 1930/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2119 - acc: 0.2158 - val_loss: 0.5774 - val_acc: 0.2004\n",
      "Epoch 1931/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2226 - acc: 0.2158 - val_loss: 0.6140 - val_acc: 0.2004\n",
      "Epoch 1932/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2138 - acc: 0.2144 - val_loss: 0.7311 - val_acc: 0.2004\n",
      "Epoch 1933/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2164 - acc: 0.2162 - val_loss: 0.5975 - val_acc: 0.2004\n",
      "Epoch 1934/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2225 - acc: 0.2148 - val_loss: 0.5896 - val_acc: 0.2004\n",
      "Epoch 1935/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2656 - acc: 0.2148 - val_loss: 0.7262 - val_acc: 0.1985\n",
      "Epoch 1936/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2424 - acc: 0.2162 - val_loss: 0.6064 - val_acc: 0.2004\n",
      "Epoch 1937/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2110 - acc: 0.2162 - val_loss: 0.5694 - val_acc: 0.2004\n",
      "Epoch 1938/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2552 - acc: 0.2162 - val_loss: 0.6112 - val_acc: 0.2004\n",
      "Epoch 1939/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2415 - acc: 0.2153 - val_loss: 0.6000 - val_acc: 0.2004\n",
      "Epoch 1940/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2470 - acc: 0.2148 - val_loss: 0.6405 - val_acc: 0.2004\n",
      "Epoch 1941/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2201 - acc: 0.2162 - val_loss: 0.6180 - val_acc: 0.2004\n",
      "Epoch 1942/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2100 - acc: 0.2162 - val_loss: 0.5761 - val_acc: 0.2004\n",
      "Epoch 1943/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2078 - acc: 0.2153 - val_loss: 0.6256 - val_acc: 0.2004\n",
      "Epoch 1944/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2109 - acc: 0.2148 - val_loss: 0.5885 - val_acc: 0.2004\n",
      "Epoch 1945/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2323 - acc: 0.2153 - val_loss: 0.7677 - val_acc: 0.1985\n",
      "Epoch 1946/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2497 - acc: 0.2158 - val_loss: 0.6300 - val_acc: 0.2004\n",
      "Epoch 1947/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2248 - acc: 0.2158 - val_loss: 0.6097 - val_acc: 0.2004\n",
      "Epoch 1948/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2073 - acc: 0.2162 - val_loss: 0.6122 - val_acc: 0.2004\n",
      "Epoch 1949/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2187 - acc: 0.2153 - val_loss: 0.5957 - val_acc: 0.2004\n",
      "Epoch 1950/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2527 - acc: 0.2144 - val_loss: 0.6826 - val_acc: 0.2004\n",
      "Epoch 1951/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2131 - acc: 0.2162 - val_loss: 0.6388 - val_acc: 0.1985\n",
      "Epoch 1952/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2110 - acc: 0.2153 - val_loss: 0.6355 - val_acc: 0.2004\n",
      "Epoch 1953/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2284 - acc: 0.2153 - val_loss: 0.6545 - val_acc: 0.2004\n",
      "Epoch 1954/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2103 - acc: 0.2153 - val_loss: 0.6898 - val_acc: 0.2004\n",
      "Epoch 1955/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2185 - acc: 0.2148 - val_loss: 0.6402 - val_acc: 0.2004\n",
      "Epoch 1956/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2283 - acc: 0.2158 - val_loss: 0.6718 - val_acc: 0.1985\n",
      "Epoch 1957/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2231 - acc: 0.2158 - val_loss: 0.6294 - val_acc: 0.2004\n",
      "Epoch 1958/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2268 - acc: 0.2139 - val_loss: 0.5907 - val_acc: 0.2004\n",
      "Epoch 1959/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2132 - acc: 0.2158 - val_loss: 0.6345 - val_acc: 0.2004\n",
      "Epoch 1960/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2209 - acc: 0.2158 - val_loss: 0.6379 - val_acc: 0.2004\n",
      "Epoch 1961/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2470 - acc: 0.2148 - val_loss: 0.6357 - val_acc: 0.2004\n",
      "Epoch 1962/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2121 - acc: 0.2148 - val_loss: 0.5839 - val_acc: 0.2004\n",
      "Epoch 1963/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2542 - acc: 0.2153 - val_loss: 0.6632 - val_acc: 0.1985\n",
      "Epoch 1964/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2190 - acc: 0.2162 - val_loss: 0.6598 - val_acc: 0.2004\n",
      "Epoch 1965/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2051 - acc: 0.2162 - val_loss: 0.6280 - val_acc: 0.2004\n",
      "Epoch 1966/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2381 - acc: 0.2162 - val_loss: 0.6301 - val_acc: 0.2004\n",
      "Epoch 1967/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.2075 - acc: 0.2148 - val_loss: 0.6083 - val_acc: 0.2004\n",
      "Epoch 1968/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2045 - acc: 0.2148 - val_loss: 0.6689 - val_acc: 0.1985\n",
      "Epoch 1969/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2211 - acc: 0.2153 - val_loss: 0.6008 - val_acc: 0.2004\n",
      "Epoch 1970/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2118 - acc: 0.2153 - val_loss: 0.6422 - val_acc: 0.2004\n",
      "Epoch 1971/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2154 - acc: 0.2153 - val_loss: 0.7122 - val_acc: 0.2004\n",
      "Epoch 1972/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2401 - acc: 0.2158 - val_loss: 0.6121 - val_acc: 0.2004\n",
      "Epoch 1973/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2389 - acc: 0.2158 - val_loss: 0.5966 - val_acc: 0.2004\n",
      "Epoch 1974/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2094 - acc: 0.2153 - val_loss: 0.6204 - val_acc: 0.2004\n",
      "Epoch 1975/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2118 - acc: 0.2153 - val_loss: 0.7090 - val_acc: 0.1985\n",
      "Epoch 1976/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2265 - acc: 0.2148 - val_loss: 0.6661 - val_acc: 0.2004\n",
      "Epoch 1977/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2243 - acc: 0.2158 - val_loss: 0.7121 - val_acc: 0.1985\n",
      "Epoch 1978/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2452 - acc: 0.2158 - val_loss: 0.6757 - val_acc: 0.1985\n",
      "Epoch 1979/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2421 - acc: 0.2162 - val_loss: 0.7928 - val_acc: 0.1985\n",
      "Epoch 1980/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2165 - acc: 0.2158 - val_loss: 0.6388 - val_acc: 0.2004\n",
      "Epoch 1981/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2303 - acc: 0.2153 - val_loss: 0.6269 - val_acc: 0.2004\n",
      "Epoch 1982/4000\n",
      "68/68 [==============================] - 5s 71ms/step - loss: 0.2188 - acc: 0.2153 - val_loss: 0.6538 - val_acc: 0.1985\n",
      "Epoch 1983/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.2189 - acc: 0.2162 - val_loss: 0.6050 - val_acc: 0.2004\n",
      "Epoch 1984/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2161 - acc: 0.2162 - val_loss: 0.5864 - val_acc: 0.2004\n",
      "Epoch 1985/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2081 - acc: 0.2162 - val_loss: 0.6129 - val_acc: 0.2004\n",
      "Epoch 1986/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2144 - acc: 0.2153 - val_loss: 0.6111 - val_acc: 0.2004\n",
      "Epoch 1987/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2092 - acc: 0.2162 - val_loss: 0.6649 - val_acc: 0.1985\n",
      "Epoch 1988/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2364 - acc: 0.2158 - val_loss: 0.7066 - val_acc: 0.1985\n",
      "Epoch 1989/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2423 - acc: 0.2158 - val_loss: 0.9450 - val_acc: 0.2004\n",
      "Epoch 1990/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2516 - acc: 0.2158 - val_loss: 0.5935 - val_acc: 0.2004\n",
      "Epoch 1991/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2079 - acc: 0.2167 - val_loss: 0.6461 - val_acc: 0.1985\n",
      "Epoch 1992/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2232 - acc: 0.2158 - val_loss: 0.6621 - val_acc: 0.1985\n",
      "Epoch 1993/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2137 - acc: 0.2158 - val_loss: 0.5823 - val_acc: 0.2004\n",
      "Epoch 1994/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2131 - acc: 0.2148 - val_loss: 0.6417 - val_acc: 0.2004\n",
      "Epoch 1995/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2062 - acc: 0.2162 - val_loss: 0.6181 - val_acc: 0.2004\n",
      "Epoch 1996/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2184 - acc: 0.2153 - val_loss: 0.6391 - val_acc: 0.2004\n",
      "Epoch 1997/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2142 - acc: 0.2158 - val_loss: 0.5830 - val_acc: 0.2004\n",
      "Epoch 1998/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2216 - acc: 0.2158 - val_loss: 0.6244 - val_acc: 0.2004\n",
      "Epoch 1999/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2197 - acc: 0.2158 - val_loss: 0.7190 - val_acc: 0.1985\n",
      "Epoch 2000/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2350 - acc: 0.2148 - val_loss: 0.5881 - val_acc: 0.2004\n",
      "Epoch 2001/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2125 - acc: 0.2153 - val_loss: 0.6239 - val_acc: 0.2004\n",
      "Epoch 2002/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2364 - acc: 0.2158 - val_loss: 0.5571 - val_acc: 0.2004\n",
      "Epoch 2003/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2862 - acc: 0.2144 - val_loss: 0.5832 - val_acc: 0.2004\n",
      "Epoch 2004/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2203 - acc: 0.2158 - val_loss: 0.6364 - val_acc: 0.2004\n",
      "Epoch 2005/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2047 - acc: 0.2162 - val_loss: 0.6170 - val_acc: 0.2004\n",
      "Epoch 2006/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2196 - acc: 0.2139 - val_loss: 0.6046 - val_acc: 0.2004\n",
      "Epoch 2007/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2176 - acc: 0.2158 - val_loss: 0.6320 - val_acc: 0.1985\n",
      "Epoch 2008/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2082 - acc: 0.2158 - val_loss: 0.5722 - val_acc: 0.2004\n",
      "Epoch 2009/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2161 - acc: 0.2162 - val_loss: 0.7060 - val_acc: 0.2004\n",
      "Epoch 2010/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2393 - acc: 0.2158 - val_loss: 0.6873 - val_acc: 0.2004\n",
      "Epoch 2011/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2751 - acc: 0.2153 - val_loss: 0.7837 - val_acc: 0.2004\n",
      "Epoch 2012/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2495 - acc: 0.2144 - val_loss: 0.6557 - val_acc: 0.1985\n",
      "Epoch 2013/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2260 - acc: 0.2153 - val_loss: 0.5794 - val_acc: 0.1985\n",
      "Epoch 2014/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2314 - acc: 0.2139 - val_loss: 0.6426 - val_acc: 0.1985\n",
      "Epoch 2015/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2532 - acc: 0.2153 - val_loss: 0.6759 - val_acc: 0.2004\n",
      "Epoch 2016/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2389 - acc: 0.2158 - val_loss: 0.9177 - val_acc: 0.2004\n",
      "Epoch 2017/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.4476 - acc: 0.2144 - val_loss: 0.6156 - val_acc: 0.1985\n",
      "Epoch 2018/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2427 - acc: 0.2158 - val_loss: 0.6459 - val_acc: 0.2004\n",
      "Epoch 2019/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2643 - acc: 0.2158 - val_loss: 0.7044 - val_acc: 0.1985\n",
      "Epoch 2020/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2694 - acc: 0.2148 - val_loss: 0.6995 - val_acc: 0.2004\n",
      "Epoch 2021/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2399 - acc: 0.2162 - val_loss: 0.5837 - val_acc: 0.2004\n",
      "Epoch 2022/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2202 - acc: 0.2153 - val_loss: 0.6284 - val_acc: 0.2004\n",
      "Epoch 2023/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2165 - acc: 0.2158 - val_loss: 0.7190 - val_acc: 0.1985\n",
      "Epoch 2024/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2204 - acc: 0.2153 - val_loss: 0.6319 - val_acc: 0.1985\n",
      "Epoch 2025/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2046 - acc: 0.2153 - val_loss: 0.6214 - val_acc: 0.2004\n",
      "Epoch 2026/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2223 - acc: 0.2148 - val_loss: 0.5970 - val_acc: 0.2004\n",
      "Epoch 2027/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2141 - acc: 0.2153 - val_loss: 0.6120 - val_acc: 0.2004\n",
      "Epoch 2028/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2175 - acc: 0.2153 - val_loss: 0.6288 - val_acc: 0.1985\n",
      "Epoch 2029/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2180 - acc: 0.2153 - val_loss: 0.6016 - val_acc: 0.2004\n",
      "Epoch 2030/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1998 - acc: 0.2162 - val_loss: 0.6332 - val_acc: 0.2004\n",
      "Epoch 2031/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2285 - acc: 0.2153 - val_loss: 0.6180 - val_acc: 0.2004\n",
      "Epoch 2032/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2176 - acc: 0.2144 - val_loss: 0.6086 - val_acc: 0.2004\n",
      "Epoch 2033/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2118 - acc: 0.2158 - val_loss: 0.6583 - val_acc: 0.1985\n",
      "Epoch 2034/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1990 - acc: 0.2158 - val_loss: 0.6717 - val_acc: 0.2004\n",
      "Epoch 2035/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2036 - acc: 0.2153 - val_loss: 0.6513 - val_acc: 0.1985\n",
      "Epoch 2036/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2144 - acc: 0.2162 - val_loss: 0.6353 - val_acc: 0.2004\n",
      "Epoch 2037/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2358 - acc: 0.2144 - val_loss: 0.5696 - val_acc: 0.2004\n",
      "Epoch 2038/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2160 - acc: 0.2158 - val_loss: 0.5968 - val_acc: 0.2004\n",
      "Epoch 2039/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2391 - acc: 0.2153 - val_loss: 0.6247 - val_acc: 0.2004\n",
      "Epoch 2040/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2159 - acc: 0.2167 - val_loss: 0.6138 - val_acc: 0.2004\n",
      "Epoch 2041/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2035 - acc: 0.2162 - val_loss: 0.5975 - val_acc: 0.2004\n",
      "Epoch 2042/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2073 - acc: 0.2158 - val_loss: 0.5922 - val_acc: 0.2004\n",
      "Epoch 2043/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2141 - acc: 0.2148 - val_loss: 0.6029 - val_acc: 0.2004\n",
      "Epoch 2044/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2138 - acc: 0.2167 - val_loss: 0.5815 - val_acc: 0.2004\n",
      "Epoch 2045/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2164 - acc: 0.2153 - val_loss: 0.6227 - val_acc: 0.2004\n",
      "Epoch 2046/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2107 - acc: 0.2153 - val_loss: 0.6324 - val_acc: 0.1985\n",
      "Epoch 2047/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2137 - acc: 0.2167 - val_loss: 0.6026 - val_acc: 0.2004\n",
      "Epoch 2048/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2386 - acc: 0.2148 - val_loss: 0.7104 - val_acc: 0.2004\n",
      "Epoch 2049/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2304 - acc: 0.2153 - val_loss: 0.6474 - val_acc: 0.2004\n",
      "Epoch 2050/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2044 - acc: 0.2158 - val_loss: 0.6208 - val_acc: 0.2004\n",
      "Epoch 2051/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2102 - acc: 0.2167 - val_loss: 0.6187 - val_acc: 0.2004\n",
      "Epoch 2052/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2039 - acc: 0.2153 - val_loss: 0.6526 - val_acc: 0.2004\n",
      "Epoch 2053/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2045 - acc: 0.2158 - val_loss: 0.5912 - val_acc: 0.1985\n",
      "Epoch 2054/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2050 - acc: 0.2153 - val_loss: 0.8788 - val_acc: 0.1948\n",
      "Epoch 2055/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2337 - acc: 0.2153 - val_loss: 0.6542 - val_acc: 0.2004\n",
      "Epoch 2056/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2051 - acc: 0.2158 - val_loss: 0.6188 - val_acc: 0.2004\n",
      "Epoch 2057/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2102 - acc: 0.2158 - val_loss: 0.6091 - val_acc: 0.2004\n",
      "Epoch 2058/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2150 - acc: 0.2158 - val_loss: 0.6272 - val_acc: 0.1985\n",
      "Epoch 2059/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2199 - acc: 0.2158 - val_loss: 0.6360 - val_acc: 0.1985\n",
      "Epoch 2060/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2371 - acc: 0.2144 - val_loss: 0.6829 - val_acc: 0.2004\n",
      "Epoch 2061/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2174 - acc: 0.2153 - val_loss: 0.6705 - val_acc: 0.2004\n",
      "Epoch 2062/4000\n",
      "68/68 [==============================] - 5s 72ms/step - loss: 0.2274 - acc: 0.2162 - val_loss: 0.5695 - val_acc: 0.2004\n",
      "Epoch 2063/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2199 - acc: 0.2158 - val_loss: 0.6186 - val_acc: 0.2004\n",
      "Epoch 2064/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2307 - acc: 0.2144 - val_loss: 0.6256 - val_acc: 0.2004\n",
      "Epoch 2065/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2275 - acc: 0.2162 - val_loss: 0.6154 - val_acc: 0.2004\n",
      "Epoch 2066/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2211 - acc: 0.2162 - val_loss: 0.7041 - val_acc: 0.1985\n",
      "Epoch 2067/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2214 - acc: 0.2167 - val_loss: 0.6162 - val_acc: 0.2004\n",
      "Epoch 2068/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2075 - acc: 0.2158 - val_loss: 0.6457 - val_acc: 0.1985\n",
      "Epoch 2069/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2164 - acc: 0.2162 - val_loss: 0.6133 - val_acc: 0.2004\n",
      "Epoch 2070/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2476 - acc: 0.2144 - val_loss: 0.6375 - val_acc: 0.2004\n",
      "Epoch 2071/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2207 - acc: 0.2162 - val_loss: 0.7171 - val_acc: 0.2004\n",
      "Epoch 2072/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2120 - acc: 0.2153 - val_loss: 0.6296 - val_acc: 0.2004\n",
      "Epoch 2073/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2163 - acc: 0.2162 - val_loss: 0.6283 - val_acc: 0.1985\n",
      "Epoch 2074/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2295 - acc: 0.2158 - val_loss: 0.6286 - val_acc: 0.2004\n",
      "Epoch 2075/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2048 - acc: 0.2158 - val_loss: 0.6028 - val_acc: 0.2004\n",
      "Epoch 2076/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2073 - acc: 0.2158 - val_loss: 0.6337 - val_acc: 0.1985\n",
      "Epoch 2077/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2261 - acc: 0.2148 - val_loss: 0.5775 - val_acc: 0.2004\n",
      "Epoch 2078/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2543 - acc: 0.2153 - val_loss: 0.6792 - val_acc: 0.2004\n",
      "Epoch 2079/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2223 - acc: 0.2158 - val_loss: 0.5842 - val_acc: 0.2004\n",
      "Epoch 2080/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2253 - acc: 0.2158 - val_loss: 0.6666 - val_acc: 0.2004\n",
      "Epoch 2081/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2280 - acc: 0.2148 - val_loss: 0.5945 - val_acc: 0.2004\n",
      "Epoch 2082/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2289 - acc: 0.2158 - val_loss: 0.7677 - val_acc: 0.1985\n",
      "Epoch 2083/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2467 - acc: 0.2158 - val_loss: 0.9359 - val_acc: 0.1874\n",
      "Epoch 2084/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2517 - acc: 0.2153 - val_loss: 0.6908 - val_acc: 0.2004\n",
      "Epoch 2085/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2435 - acc: 0.2158 - val_loss: 0.8330 - val_acc: 0.1985\n",
      "Epoch 2086/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.4329 - acc: 0.2088 - val_loss: 0.6808 - val_acc: 0.1985\n",
      "Epoch 2087/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3791 - acc: 0.2144 - val_loss: 0.6104 - val_acc: 0.2004\n",
      "Epoch 2088/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3034 - acc: 0.2153 - val_loss: 0.6589 - val_acc: 0.2004\n",
      "Epoch 2089/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2683 - acc: 0.2162 - val_loss: 0.5917 - val_acc: 0.1985\n",
      "Epoch 2090/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2095 - acc: 0.2158 - val_loss: 0.6217 - val_acc: 0.2004\n",
      "Epoch 2091/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2112 - acc: 0.2148 - val_loss: 0.6047 - val_acc: 0.2004\n",
      "Epoch 2092/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2280 - acc: 0.2158 - val_loss: 0.6745 - val_acc: 0.2004\n",
      "Epoch 2093/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2578 - acc: 0.2158 - val_loss: 0.5964 - val_acc: 0.2004\n",
      "Epoch 2094/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2236 - acc: 0.2162 - val_loss: 0.6208 - val_acc: 0.2004\n",
      "Epoch 2095/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2255 - acc: 0.2158 - val_loss: 0.6209 - val_acc: 0.2004\n",
      "Epoch 2096/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2193 - acc: 0.2162 - val_loss: 0.7645 - val_acc: 0.1985\n",
      "Epoch 2097/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2070 - acc: 0.2153 - val_loss: 0.6054 - val_acc: 0.2004\n",
      "Epoch 2098/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2123 - acc: 0.2158 - val_loss: 0.6065 - val_acc: 0.2004\n",
      "Epoch 2099/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1994 - acc: 0.2153 - val_loss: 0.6036 - val_acc: 0.2004\n",
      "Epoch 2100/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2061 - acc: 0.2148 - val_loss: 0.5986 - val_acc: 0.2004\n",
      "Epoch 2101/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2114 - acc: 0.2162 - val_loss: 0.5876 - val_acc: 0.2004\n",
      "Epoch 2102/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2048 - acc: 0.2167 - val_loss: 0.6437 - val_acc: 0.1985\n",
      "Epoch 2103/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2146 - acc: 0.2148 - val_loss: 0.9027 - val_acc: 0.2004\n",
      "Epoch 2104/4000\n",
      "68/68 [==============================] - 5s 75ms/step - loss: 0.2437 - acc: 0.2158 - val_loss: 0.6196 - val_acc: 0.1985\n",
      "Epoch 2105/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2296 - acc: 0.2158 - val_loss: 0.6770 - val_acc: 0.2004\n",
      "Epoch 2106/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2445 - acc: 0.2144 - val_loss: 0.5994 - val_acc: 0.2004\n",
      "Epoch 2107/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2125 - acc: 0.2162 - val_loss: 0.6041 - val_acc: 0.2004\n",
      "Epoch 2108/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2108 - acc: 0.2162 - val_loss: 0.5813 - val_acc: 0.2004\n",
      "Epoch 2109/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1975 - acc: 0.2158 - val_loss: 0.6262 - val_acc: 0.2004\n",
      "Epoch 2110/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2061 - acc: 0.2153 - val_loss: 0.6276 - val_acc: 0.1985\n",
      "Epoch 2111/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2093 - acc: 0.2158 - val_loss: 0.5939 - val_acc: 0.2004\n",
      "Epoch 2112/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2036 - acc: 0.2153 - val_loss: 0.5904 - val_acc: 0.2004\n",
      "Epoch 2113/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2714 - acc: 0.2148 - val_loss: 0.6241 - val_acc: 0.2004\n",
      "Epoch 2114/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1985 - acc: 0.2162 - val_loss: 0.6049 - val_acc: 0.1985\n",
      "Epoch 2115/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1990 - acc: 0.2162 - val_loss: 0.6230 - val_acc: 0.2004\n",
      "Epoch 2116/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2098 - acc: 0.2158 - val_loss: 0.6119 - val_acc: 0.2004\n",
      "Epoch 2117/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2172 - acc: 0.2153 - val_loss: 0.6927 - val_acc: 0.2004\n",
      "Epoch 2118/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2407 - acc: 0.2153 - val_loss: 0.5871 - val_acc: 0.2004\n",
      "Epoch 2119/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.1985 - acc: 0.2158 - val_loss: 0.6165 - val_acc: 0.2004\n",
      "Epoch 2120/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2299 - acc: 0.2153 - val_loss: 0.6662 - val_acc: 0.1985\n",
      "Epoch 2121/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2189 - acc: 0.2153 - val_loss: 0.6020 - val_acc: 0.2004\n",
      "Epoch 2122/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2074 - acc: 0.2148 - val_loss: 0.6116 - val_acc: 0.2004\n",
      "Epoch 2123/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.2058 - acc: 0.2158 - val_loss: 0.6437 - val_acc: 0.2004\n",
      "Epoch 2124/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2241 - acc: 0.2158 - val_loss: 0.9606 - val_acc: 0.2004\n",
      "Epoch 2125/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.2416 - acc: 0.2148 - val_loss: 0.6040 - val_acc: 0.2004\n",
      "Epoch 2126/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2197 - acc: 0.2162 - val_loss: 0.6061 - val_acc: 0.2004\n",
      "Epoch 2127/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2159 - acc: 0.2158 - val_loss: 0.6566 - val_acc: 0.2004\n",
      "Epoch 2128/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2213 - acc: 0.2144 - val_loss: 0.6823 - val_acc: 0.1985\n",
      "Epoch 2129/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2056 - acc: 0.2158 - val_loss: 0.6570 - val_acc: 0.1985\n",
      "Epoch 2130/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2408 - acc: 0.2158 - val_loss: 0.7459 - val_acc: 0.1985\n",
      "Epoch 2131/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.2681 - acc: 0.2162 - val_loss: 0.6536 - val_acc: 0.2004\n",
      "Epoch 2132/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.6129 - acc: 0.2139 - val_loss: 0.9806 - val_acc: 0.1985\n",
      "Epoch 2133/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.6062 - acc: 0.2144 - val_loss: 1.1861 - val_acc: 0.2004\n",
      "Epoch 2134/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.9698 - acc: 0.2060 - val_loss: 0.6640 - val_acc: 0.2004\n",
      "Epoch 2135/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2309 - acc: 0.2162 - val_loss: 0.6014 - val_acc: 0.2004\n",
      "Epoch 2136/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2227 - acc: 0.2158 - val_loss: 0.6023 - val_acc: 0.2004\n",
      "Epoch 2137/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2119 - acc: 0.2158 - val_loss: 0.5502 - val_acc: 0.2004\n",
      "Epoch 2138/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2198 - acc: 0.2148 - val_loss: 0.6177 - val_acc: 0.1985\n",
      "Epoch 2139/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2016 - acc: 0.2167 - val_loss: 0.5840 - val_acc: 0.2004\n",
      "Epoch 2140/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2030 - acc: 0.2158 - val_loss: 0.5817 - val_acc: 0.2004\n",
      "Epoch 2141/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1997 - acc: 0.2158 - val_loss: 0.5742 - val_acc: 0.2004\n",
      "Epoch 2142/4000\n",
      "68/68 [==============================] - 5s 69ms/step - loss: 0.2069 - acc: 0.2153 - val_loss: 0.5873 - val_acc: 0.2004\n",
      "Epoch 2143/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2035 - acc: 0.2162 - val_loss: 0.5789 - val_acc: 0.2004\n",
      "Epoch 2144/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2155 - acc: 0.2158 - val_loss: 0.6385 - val_acc: 0.1985\n",
      "Epoch 2145/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2356 - acc: 0.2153 - val_loss: 0.5489 - val_acc: 0.2004\n",
      "Epoch 2146/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2045 - acc: 0.2158 - val_loss: 0.5933 - val_acc: 0.2004\n",
      "Epoch 2147/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2008 - acc: 0.2162 - val_loss: 0.5978 - val_acc: 0.2004\n",
      "Epoch 2148/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2190 - acc: 0.2148 - val_loss: 0.7876 - val_acc: 0.2004\n",
      "Epoch 2149/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2229 - acc: 0.2158 - val_loss: 0.7061 - val_acc: 0.2004\n",
      "Epoch 2150/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2266 - acc: 0.2158 - val_loss: 0.5940 - val_acc: 0.1985\n",
      "Epoch 2151/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2086 - acc: 0.2153 - val_loss: 0.6135 - val_acc: 0.1985\n",
      "Epoch 2152/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2194 - acc: 0.2158 - val_loss: 0.6229 - val_acc: 0.2004\n",
      "Epoch 2153/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.2087 - acc: 0.2167 - val_loss: 0.5771 - val_acc: 0.2004\n",
      "Epoch 2154/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2111 - acc: 0.2153 - val_loss: 0.5832 - val_acc: 0.2004\n",
      "Epoch 2155/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2053 - acc: 0.2153 - val_loss: 0.5834 - val_acc: 0.2004\n",
      "Epoch 2156/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2017 - acc: 0.2158 - val_loss: 0.6021 - val_acc: 0.2004\n",
      "Epoch 2157/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1906 - acc: 0.2158 - val_loss: 0.5824 - val_acc: 0.2004\n",
      "Epoch 2158/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2175 - acc: 0.2158 - val_loss: 0.6316 - val_acc: 0.1985\n",
      "Epoch 2159/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2296 - acc: 0.2153 - val_loss: 0.5874 - val_acc: 0.2004\n",
      "Epoch 2160/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2052 - acc: 0.2158 - val_loss: 0.6005 - val_acc: 0.2004\n",
      "Epoch 2161/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2265 - acc: 0.2148 - val_loss: 0.6047 - val_acc: 0.2004\n",
      "Epoch 2162/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2067 - acc: 0.2148 - val_loss: 0.6039 - val_acc: 0.2004\n",
      "Epoch 2163/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2130 - acc: 0.2162 - val_loss: 0.6341 - val_acc: 0.2004\n",
      "Epoch 2164/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2146 - acc: 0.2162 - val_loss: 0.5914 - val_acc: 0.2004\n",
      "Epoch 2165/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2021 - acc: 0.2167 - val_loss: 0.5777 - val_acc: 0.2004\n",
      "Epoch 2166/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2100 - acc: 0.2153 - val_loss: 0.6186 - val_acc: 0.2004\n",
      "Epoch 2167/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2269 - acc: 0.2158 - val_loss: 0.6694 - val_acc: 0.1985\n",
      "Epoch 2168/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1987 - acc: 0.2153 - val_loss: 0.5796 - val_acc: 0.2004\n",
      "Epoch 2169/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1981 - acc: 0.2162 - val_loss: 0.6154 - val_acc: 0.2004\n",
      "Epoch 2170/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1977 - acc: 0.2158 - val_loss: 0.6023 - val_acc: 0.1985\n",
      "Epoch 2171/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2010 - acc: 0.2162 - val_loss: 0.5970 - val_acc: 0.2004\n",
      "Epoch 2172/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2239 - acc: 0.2158 - val_loss: 0.6572 - val_acc: 0.2004\n",
      "Epoch 2173/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2210 - acc: 0.2148 - val_loss: 0.8185 - val_acc: 0.1967\n",
      "Epoch 2174/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2120 - acc: 0.2158 - val_loss: 0.5928 - val_acc: 0.2004\n",
      "Epoch 2175/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2077 - acc: 0.2153 - val_loss: 0.6040 - val_acc: 0.1985\n",
      "Epoch 2176/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2148 - acc: 0.2148 - val_loss: 0.6543 - val_acc: 0.1985\n",
      "Epoch 2177/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2203 - acc: 0.2148 - val_loss: 0.6296 - val_acc: 0.1985\n",
      "Epoch 2178/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2324 - acc: 0.2148 - val_loss: 0.5953 - val_acc: 0.2004\n",
      "Epoch 2179/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2181 - acc: 0.2153 - val_loss: 0.5880 - val_acc: 0.2004\n",
      "Epoch 2180/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2025 - acc: 0.2162 - val_loss: 0.6594 - val_acc: 0.2004\n",
      "Epoch 2181/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2006 - acc: 0.2144 - val_loss: 0.6377 - val_acc: 0.1985\n",
      "Epoch 2182/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2045 - acc: 0.2158 - val_loss: 0.6050 - val_acc: 0.2004\n",
      "Epoch 2183/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2303 - acc: 0.2158 - val_loss: 0.6516 - val_acc: 0.1985\n",
      "Epoch 2184/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2142 - acc: 0.2162 - val_loss: 0.6203 - val_acc: 0.2004\n",
      "Epoch 2185/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2077 - acc: 0.2148 - val_loss: 0.5932 - val_acc: 0.2004\n",
      "Epoch 2186/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2064 - acc: 0.2158 - val_loss: 0.5843 - val_acc: 0.2004\n",
      "Epoch 2187/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2243 - acc: 0.2158 - val_loss: 0.6020 - val_acc: 0.2004\n",
      "Epoch 2188/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2392 - acc: 0.2158 - val_loss: 0.5951 - val_acc: 0.2004\n",
      "Epoch 2189/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2059 - acc: 0.2144 - val_loss: 0.6162 - val_acc: 0.2004\n",
      "Epoch 2190/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2195 - acc: 0.2158 - val_loss: 0.6748 - val_acc: 0.1985\n",
      "Epoch 2191/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2124 - acc: 0.2148 - val_loss: 0.5945 - val_acc: 0.2004\n",
      "Epoch 2192/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2267 - acc: 0.2153 - val_loss: 0.5952 - val_acc: 0.2004\n",
      "Epoch 2193/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2075 - acc: 0.2158 - val_loss: 0.6318 - val_acc: 0.2004\n",
      "Epoch 2194/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1992 - acc: 0.2148 - val_loss: 0.6288 - val_acc: 0.2004\n",
      "Epoch 2195/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2054 - acc: 0.2153 - val_loss: 0.7024 - val_acc: 0.2004\n",
      "Epoch 2196/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2032 - acc: 0.2153 - val_loss: 0.6434 - val_acc: 0.1985\n",
      "Epoch 2197/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2082 - acc: 0.2162 - val_loss: 0.6258 - val_acc: 0.2004\n",
      "Epoch 2198/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2192 - acc: 0.2162 - val_loss: 0.5901 - val_acc: 0.2004\n",
      "Epoch 2199/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2060 - acc: 0.2158 - val_loss: 0.6035 - val_acc: 0.2004\n",
      "Epoch 2200/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2051 - acc: 0.2167 - val_loss: 0.6947 - val_acc: 0.1985\n",
      "Epoch 2201/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2303 - acc: 0.2139 - val_loss: 0.6322 - val_acc: 0.1985\n",
      "Epoch 2202/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2161 - acc: 0.2153 - val_loss: 0.6267 - val_acc: 0.1985\n",
      "Epoch 2203/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2446 - acc: 0.2158 - val_loss: 0.6187 - val_acc: 0.2004\n",
      "Epoch 2204/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2158 - acc: 0.2153 - val_loss: 0.7218 - val_acc: 0.2004\n",
      "Epoch 2205/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2234 - acc: 0.2162 - val_loss: 0.6211 - val_acc: 0.2004\n",
      "Epoch 2206/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2047 - acc: 0.2162 - val_loss: 0.6776 - val_acc: 0.1985\n",
      "Epoch 2207/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2069 - acc: 0.2158 - val_loss: 0.6070 - val_acc: 0.2004\n",
      "Epoch 2208/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2095 - acc: 0.2153 - val_loss: 0.5973 - val_acc: 0.2004\n",
      "Epoch 2209/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2031 - acc: 0.2158 - val_loss: 0.5990 - val_acc: 0.1985\n",
      "Epoch 2210/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2314 - acc: 0.2148 - val_loss: 0.6066 - val_acc: 0.2004\n",
      "Epoch 2211/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2546 - acc: 0.2158 - val_loss: 0.8302 - val_acc: 0.1985\n",
      "Epoch 2212/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2387 - acc: 0.2148 - val_loss: 0.6020 - val_acc: 0.2004\n",
      "Epoch 2213/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2113 - acc: 0.2158 - val_loss: 0.6685 - val_acc: 0.2004\n",
      "Epoch 2214/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2382 - acc: 0.2153 - val_loss: 0.6972 - val_acc: 0.2004\n",
      "Epoch 2215/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2094 - acc: 0.2162 - val_loss: 0.6605 - val_acc: 0.1985\n",
      "Epoch 2216/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2564 - acc: 0.2153 - val_loss: 0.6033 - val_acc: 0.2004\n",
      "Epoch 2217/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2180 - acc: 0.2153 - val_loss: 0.6105 - val_acc: 0.2004\n",
      "Epoch 2218/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2111 - acc: 0.2158 - val_loss: 0.5476 - val_acc: 0.2004\n",
      "Epoch 2219/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2941 - acc: 0.2116 - val_loss: 1.0502 - val_acc: 0.1874\n",
      "Epoch 2220/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2519 - acc: 0.2158 - val_loss: 0.6181 - val_acc: 0.2004\n",
      "Epoch 2221/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1956 - acc: 0.2158 - val_loss: 0.6191 - val_acc: 0.2004\n",
      "Epoch 2222/4000\n",
      "68/68 [==============================] - 5s 69ms/step - loss: 0.1934 - acc: 0.2153 - val_loss: 0.6507 - val_acc: 0.1985\n",
      "Epoch 2223/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2145 - acc: 0.2144 - val_loss: 0.6722 - val_acc: 0.2004\n",
      "Epoch 2224/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2072 - acc: 0.2162 - val_loss: 0.6848 - val_acc: 0.2004\n",
      "Epoch 2225/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2000 - acc: 0.2162 - val_loss: 0.5979 - val_acc: 0.2004\n",
      "Epoch 2226/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1926 - acc: 0.2153 - val_loss: 0.5922 - val_acc: 0.2004\n",
      "Epoch 2227/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2151 - acc: 0.2153 - val_loss: 0.5923 - val_acc: 0.2004\n",
      "Epoch 2228/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2000 - acc: 0.2153 - val_loss: 0.7430 - val_acc: 0.1985\n",
      "Epoch 2229/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2325 - acc: 0.2144 - val_loss: 0.8693 - val_acc: 0.2004\n",
      "Epoch 2230/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.2488 - acc: 0.2158 - val_loss: 0.6195 - val_acc: 0.1985\n",
      "Epoch 2231/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2013 - acc: 0.2162 - val_loss: 0.6323 - val_acc: 0.2004\n",
      "Epoch 2232/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2313 - acc: 0.2153 - val_loss: 0.6592 - val_acc: 0.1985\n",
      "Epoch 2233/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2079 - acc: 0.2148 - val_loss: 0.5823 - val_acc: 0.2004\n",
      "Epoch 2234/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2125 - acc: 0.2148 - val_loss: 0.7762 - val_acc: 0.2004\n",
      "Epoch 2235/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2198 - acc: 0.2158 - val_loss: 0.5973 - val_acc: 0.1985\n",
      "Epoch 2236/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2020 - acc: 0.2158 - val_loss: 0.5965 - val_acc: 0.2004\n",
      "Epoch 2237/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2231 - acc: 0.2158 - val_loss: 0.7238 - val_acc: 0.2004\n",
      "Epoch 2238/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2393 - acc: 0.2139 - val_loss: 0.6273 - val_acc: 0.2004\n",
      "Epoch 2239/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2310 - acc: 0.2148 - val_loss: 0.6687 - val_acc: 0.1985\n",
      "Epoch 2240/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2423 - acc: 0.2139 - val_loss: 0.6679 - val_acc: 0.1985\n",
      "Epoch 2241/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1947 - acc: 0.2158 - val_loss: 0.6222 - val_acc: 0.2004\n",
      "Epoch 2242/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.1994 - acc: 0.2153 - val_loss: 0.6257 - val_acc: 0.1985\n",
      "Epoch 2243/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2064 - acc: 0.2153 - val_loss: 0.6135 - val_acc: 0.1985\n",
      "Epoch 2244/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2005 - acc: 0.2148 - val_loss: 0.5981 - val_acc: 0.2004\n",
      "Epoch 2245/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2143 - acc: 0.2158 - val_loss: 0.6203 - val_acc: 0.2004\n",
      "Epoch 2246/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2098 - acc: 0.2148 - val_loss: 0.7021 - val_acc: 0.1985\n",
      "Epoch 2247/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2161 - acc: 0.2158 - val_loss: 0.8220 - val_acc: 0.1929\n",
      "Epoch 2248/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2510 - acc: 0.2158 - val_loss: 0.6156 - val_acc: 0.2004\n",
      "Epoch 2249/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2251 - acc: 0.2158 - val_loss: 0.5854 - val_acc: 0.2004\n",
      "Epoch 2250/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2186 - acc: 0.2148 - val_loss: 0.6064 - val_acc: 0.2004\n",
      "Epoch 2251/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2146 - acc: 0.2144 - val_loss: 0.6251 - val_acc: 0.2004\n",
      "Epoch 2252/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2056 - acc: 0.2162 - val_loss: 0.6451 - val_acc: 0.2004\n",
      "Epoch 2253/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2053 - acc: 0.2153 - val_loss: 0.6081 - val_acc: 0.2004\n",
      "Epoch 2254/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2097 - acc: 0.2158 - val_loss: 0.6908 - val_acc: 0.2004\n",
      "Epoch 2255/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2081 - acc: 0.2153 - val_loss: 0.7901 - val_acc: 0.1967\n",
      "Epoch 2256/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2318 - acc: 0.2148 - val_loss: 0.6096 - val_acc: 0.2004\n",
      "Epoch 2257/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1941 - acc: 0.2158 - val_loss: 0.5813 - val_acc: 0.1985\n",
      "Epoch 2258/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1952 - acc: 0.2158 - val_loss: 0.6428 - val_acc: 0.2004\n",
      "Epoch 2259/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2246 - acc: 0.2158 - val_loss: 0.6221 - val_acc: 0.2004\n",
      "Epoch 2260/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2143 - acc: 0.2153 - val_loss: 0.6129 - val_acc: 0.2004\n",
      "Epoch 2261/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2097 - acc: 0.2158 - val_loss: 0.6333 - val_acc: 0.1985\n",
      "Epoch 2262/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1989 - acc: 0.2158 - val_loss: 0.6083 - val_acc: 0.1985\n",
      "Epoch 2263/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2132 - acc: 0.2153 - val_loss: 0.6663 - val_acc: 0.1985\n",
      "Epoch 2264/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2109 - acc: 0.2162 - val_loss: 0.6179 - val_acc: 0.2004\n",
      "Epoch 2265/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2098 - acc: 0.2162 - val_loss: 0.6375 - val_acc: 0.2004\n",
      "Epoch 2266/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1979 - acc: 0.2148 - val_loss: 0.6097 - val_acc: 0.1985\n",
      "Epoch 2267/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2051 - acc: 0.2158 - val_loss: 0.6471 - val_acc: 0.1985\n",
      "Epoch 2268/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2056 - acc: 0.2158 - val_loss: 0.5728 - val_acc: 0.2004\n",
      "Epoch 2269/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1966 - acc: 0.2162 - val_loss: 0.6061 - val_acc: 0.2004\n",
      "Epoch 2270/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2235 - acc: 0.2158 - val_loss: 0.6287 - val_acc: 0.2004\n",
      "Epoch 2271/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1953 - acc: 0.2158 - val_loss: 0.5672 - val_acc: 0.2004\n",
      "Epoch 2272/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2073 - acc: 0.2162 - val_loss: 0.6553 - val_acc: 0.2004\n",
      "Epoch 2273/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2626 - acc: 0.2148 - val_loss: 0.6767 - val_acc: 0.2004\n",
      "Epoch 2274/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2225 - acc: 0.2162 - val_loss: 0.6251 - val_acc: 0.1985\n",
      "Epoch 2275/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2449 - acc: 0.2153 - val_loss: 0.5961 - val_acc: 0.2004\n",
      "Epoch 2276/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.8623 - acc: 0.2070 - val_loss: 24.6677 - val_acc: 0.0019\n",
      "Epoch 2277/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 2.2372 - acc: 0.1949 - val_loss: 0.4905 - val_acc: 0.2004\n",
      "Epoch 2278/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3268 - acc: 0.2158 - val_loss: 0.6362 - val_acc: 0.2004\n",
      "Epoch 2279/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2752 - acc: 0.2162 - val_loss: 0.6125 - val_acc: 0.2004\n",
      "Epoch 2280/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2089 - acc: 0.2167 - val_loss: 0.6330 - val_acc: 0.1985\n",
      "Epoch 2281/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1921 - acc: 0.2158 - val_loss: 0.5626 - val_acc: 0.2004\n",
      "Epoch 2282/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1830 - acc: 0.2162 - val_loss: 0.5611 - val_acc: 0.2004\n",
      "Epoch 2283/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1893 - acc: 0.2162 - val_loss: 0.5587 - val_acc: 0.2004\n",
      "Epoch 2284/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2115 - acc: 0.2162 - val_loss: 0.5609 - val_acc: 0.2004\n",
      "Epoch 2285/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1896 - acc: 0.2153 - val_loss: 0.5749 - val_acc: 0.2004\n",
      "Epoch 2286/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2207 - acc: 0.2158 - val_loss: 0.5497 - val_acc: 0.2004\n",
      "Epoch 2287/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1829 - acc: 0.2148 - val_loss: 0.5667 - val_acc: 0.2004\n",
      "Epoch 2288/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1949 - acc: 0.2162 - val_loss: 0.5792 - val_acc: 0.1985\n",
      "Epoch 2289/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1968 - acc: 0.2162 - val_loss: 0.5734 - val_acc: 0.2004\n",
      "Epoch 2290/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2054 - acc: 0.2158 - val_loss: 0.5584 - val_acc: 0.2004\n",
      "Epoch 2291/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1862 - acc: 0.2158 - val_loss: 0.5652 - val_acc: 0.2004\n",
      "Epoch 2292/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1836 - acc: 0.2162 - val_loss: 0.5704 - val_acc: 0.2004\n",
      "Epoch 2293/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1929 - acc: 0.2153 - val_loss: 0.5606 - val_acc: 0.2004\n",
      "Epoch 2294/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1869 - acc: 0.2153 - val_loss: 0.5664 - val_acc: 0.2004\n",
      "Epoch 2295/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1841 - acc: 0.2158 - val_loss: 0.5941 - val_acc: 0.1985\n",
      "Epoch 2296/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1972 - acc: 0.2167 - val_loss: 0.6601 - val_acc: 0.1985\n",
      "Epoch 2297/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2081 - acc: 0.2167 - val_loss: 0.5771 - val_acc: 0.2004\n",
      "Epoch 2298/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2025 - acc: 0.2162 - val_loss: 0.6465 - val_acc: 0.1985\n",
      "Epoch 2299/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1954 - acc: 0.2162 - val_loss: 0.6154 - val_acc: 0.2004\n",
      "Epoch 2300/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1844 - acc: 0.2167 - val_loss: 0.5989 - val_acc: 0.2004\n",
      "Epoch 2301/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1894 - acc: 0.2158 - val_loss: 0.5766 - val_acc: 0.2004\n",
      "Epoch 2302/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1910 - acc: 0.2162 - val_loss: 0.6329 - val_acc: 0.2004\n",
      "Epoch 2303/4000\n",
      "68/68 [==============================] - 5s 72ms/step - loss: 0.1984 - acc: 0.2158 - val_loss: 0.6478 - val_acc: 0.2004\n",
      "Epoch 2304/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2059 - acc: 0.2153 - val_loss: 0.6015 - val_acc: 0.1985\n",
      "Epoch 2305/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1951 - acc: 0.2158 - val_loss: 0.5775 - val_acc: 0.2004\n",
      "Epoch 2306/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1921 - acc: 0.2158 - val_loss: 0.5978 - val_acc: 0.1985\n",
      "Epoch 2307/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2069 - acc: 0.2153 - val_loss: 0.5733 - val_acc: 0.2004\n",
      "Epoch 2308/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2002 - acc: 0.2158 - val_loss: 0.5989 - val_acc: 0.2004\n",
      "Epoch 2309/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1862 - acc: 0.2162 - val_loss: 0.5803 - val_acc: 0.2004\n",
      "Epoch 2310/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2122 - acc: 0.2153 - val_loss: 0.5847 - val_acc: 0.1985\n",
      "Epoch 2311/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1999 - acc: 0.2158 - val_loss: 0.6214 - val_acc: 0.2004\n",
      "Epoch 2312/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2072 - acc: 0.2153 - val_loss: 0.5899 - val_acc: 0.2004\n",
      "Epoch 2313/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2143 - acc: 0.2158 - val_loss: 0.5791 - val_acc: 0.2004\n",
      "Epoch 2314/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2124 - acc: 0.2167 - val_loss: 0.5901 - val_acc: 0.2004\n",
      "Epoch 2315/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1857 - acc: 0.2153 - val_loss: 0.5839 - val_acc: 0.2004\n",
      "Epoch 2316/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1933 - acc: 0.2158 - val_loss: 0.6033 - val_acc: 0.2004\n",
      "Epoch 2317/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2034 - acc: 0.2162 - val_loss: 0.5912 - val_acc: 0.2004\n",
      "Epoch 2318/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1874 - acc: 0.2162 - val_loss: 0.5831 - val_acc: 0.2004\n",
      "Epoch 2319/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2028 - acc: 0.2162 - val_loss: 0.6967 - val_acc: 0.2004\n",
      "Epoch 2320/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1999 - acc: 0.2153 - val_loss: 0.5649 - val_acc: 0.2004\n",
      "Epoch 2321/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2314 - acc: 0.2144 - val_loss: 0.6937 - val_acc: 0.2004\n",
      "Epoch 2322/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2060 - acc: 0.2158 - val_loss: 0.5463 - val_acc: 0.2004\n",
      "Epoch 2323/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2102 - acc: 0.2158 - val_loss: 0.7107 - val_acc: 0.2004\n",
      "Epoch 2324/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2240 - acc: 0.2158 - val_loss: 0.5677 - val_acc: 0.2004\n",
      "Epoch 2325/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2006 - acc: 0.2153 - val_loss: 0.6106 - val_acc: 0.2004\n",
      "Epoch 2326/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2025 - acc: 0.2158 - val_loss: 0.5996 - val_acc: 0.2004\n",
      "Epoch 2327/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1968 - acc: 0.2153 - val_loss: 0.5722 - val_acc: 0.2004\n",
      "Epoch 2328/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2127 - acc: 0.2148 - val_loss: 0.5848 - val_acc: 0.2004\n",
      "Epoch 2329/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1912 - acc: 0.2153 - val_loss: 0.5856 - val_acc: 0.2004\n",
      "Epoch 2330/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2035 - acc: 0.2158 - val_loss: 0.6349 - val_acc: 0.1985\n",
      "Epoch 2331/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1856 - acc: 0.2162 - val_loss: 0.5839 - val_acc: 0.2004\n",
      "Epoch 2332/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2024 - acc: 0.2153 - val_loss: 0.5674 - val_acc: 0.2004\n",
      "Epoch 2333/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2146 - acc: 0.2162 - val_loss: 0.5738 - val_acc: 0.2004\n",
      "Epoch 2334/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2079 - acc: 0.2148 - val_loss: 0.6416 - val_acc: 0.1985\n",
      "Epoch 2335/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2092 - acc: 0.2139 - val_loss: 0.6868 - val_acc: 0.2004\n",
      "Epoch 2336/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2308 - acc: 0.2148 - val_loss: 0.5971 - val_acc: 0.2004\n",
      "Epoch 2337/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2467 - acc: 0.2158 - val_loss: 0.5809 - val_acc: 0.2004\n",
      "Epoch 2338/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2230 - acc: 0.2153 - val_loss: 0.5919 - val_acc: 0.2004\n",
      "Epoch 2339/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2269 - acc: 0.2148 - val_loss: 0.5844 - val_acc: 0.2004\n",
      "Epoch 2340/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1940 - acc: 0.2158 - val_loss: 0.5644 - val_acc: 0.2004\n",
      "Epoch 2341/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1951 - acc: 0.2153 - val_loss: 0.5952 - val_acc: 0.2004\n",
      "Epoch 2342/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2136 - acc: 0.2162 - val_loss: 0.5642 - val_acc: 0.2004\n",
      "Epoch 2343/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2334 - acc: 0.2162 - val_loss: 0.6037 - val_acc: 0.1985\n",
      "Epoch 2344/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2374 - acc: 0.2153 - val_loss: 0.6700 - val_acc: 0.1985\n",
      "Epoch 2345/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2118 - acc: 0.2153 - val_loss: 0.7105 - val_acc: 0.1985\n",
      "Epoch 2346/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2134 - acc: 0.2148 - val_loss: 0.5895 - val_acc: 0.2004\n",
      "Epoch 2347/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2087 - acc: 0.2162 - val_loss: 0.5997 - val_acc: 0.2004\n",
      "Epoch 2348/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1990 - acc: 0.2158 - val_loss: 0.6572 - val_acc: 0.1985\n",
      "Epoch 2349/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2047 - acc: 0.2153 - val_loss: 0.6402 - val_acc: 0.2004\n",
      "Epoch 2350/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2071 - acc: 0.2139 - val_loss: 0.5840 - val_acc: 0.1985\n",
      "Epoch 2351/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2145 - acc: 0.2162 - val_loss: 0.5906 - val_acc: 0.2004\n",
      "Epoch 2352/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2223 - acc: 0.2172 - val_loss: 0.8738 - val_acc: 0.1948\n",
      "Epoch 2353/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2161 - acc: 0.2153 - val_loss: 0.5886 - val_acc: 0.2004\n",
      "Epoch 2354/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1859 - acc: 0.2162 - val_loss: 0.6404 - val_acc: 0.1985\n",
      "Epoch 2355/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2272 - acc: 0.2158 - val_loss: 0.5749 - val_acc: 0.2004\n",
      "Epoch 2356/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2078 - acc: 0.2148 - val_loss: 0.5900 - val_acc: 0.2004\n",
      "Epoch 2357/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2041 - acc: 0.2158 - val_loss: 0.5910 - val_acc: 0.1985\n",
      "Epoch 2358/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2373 - acc: 0.2148 - val_loss: 0.5731 - val_acc: 0.2004\n",
      "Epoch 2359/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2037 - acc: 0.2153 - val_loss: 0.6911 - val_acc: 0.1985\n",
      "Epoch 2360/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2115 - acc: 0.2162 - val_loss: 0.6836 - val_acc: 0.1985\n",
      "Epoch 2361/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2497 - acc: 0.2158 - val_loss: 0.6135 - val_acc: 0.2004\n",
      "Epoch 2362/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.2107 - acc: 0.2158 - val_loss: 0.6032 - val_acc: 0.2004\n",
      "Epoch 2363/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1937 - acc: 0.2158 - val_loss: 0.6480 - val_acc: 0.2004\n",
      "Epoch 2364/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2200 - acc: 0.2144 - val_loss: 0.7139 - val_acc: 0.1985\n",
      "Epoch 2365/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2470 - acc: 0.2162 - val_loss: 0.5899 - val_acc: 0.2004\n",
      "Epoch 2366/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2137 - acc: 0.2158 - val_loss: 0.6048 - val_acc: 0.2004\n",
      "Epoch 2367/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2016 - acc: 0.2153 - val_loss: 0.5883 - val_acc: 0.2004\n",
      "Epoch 2368/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1952 - acc: 0.2153 - val_loss: 0.5853 - val_acc: 0.2004\n",
      "Epoch 2369/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2163 - acc: 0.2148 - val_loss: 0.6327 - val_acc: 0.1985\n",
      "Epoch 2370/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1959 - acc: 0.2158 - val_loss: 0.5860 - val_acc: 0.2004\n",
      "Epoch 2371/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1998 - acc: 0.2158 - val_loss: 0.6513 - val_acc: 0.2004\n",
      "Epoch 2372/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1995 - acc: 0.2167 - val_loss: 0.6038 - val_acc: 0.1985\n",
      "Epoch 2373/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2089 - acc: 0.2153 - val_loss: 0.6215 - val_acc: 0.2004\n",
      "Epoch 2374/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2063 - acc: 0.2158 - val_loss: 0.6210 - val_acc: 0.1985\n",
      "Epoch 2375/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2011 - acc: 0.2162 - val_loss: 0.6482 - val_acc: 0.2004\n",
      "Epoch 2376/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2363 - acc: 0.2158 - val_loss: 0.6339 - val_acc: 0.2004\n",
      "Epoch 2377/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2511 - acc: 0.2158 - val_loss: 0.7259 - val_acc: 0.1985\n",
      "Epoch 2378/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2102 - acc: 0.2153 - val_loss: 0.6802 - val_acc: 0.2004\n",
      "Epoch 2379/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2043 - acc: 0.2158 - val_loss: 0.6085 - val_acc: 0.2004\n",
      "Epoch 2380/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2524 - acc: 0.2153 - val_loss: 0.5390 - val_acc: 0.2004\n",
      "Epoch 2381/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.7210 - acc: 0.2023 - val_loss: 0.8275 - val_acc: 0.2004\n",
      "Epoch 2382/4000\n",
      "68/68 [==============================] - 5s 69ms/step - loss: 0.3269 - acc: 0.2158 - val_loss: 0.5972 - val_acc: 0.2004\n",
      "Epoch 2383/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.2852 - acc: 0.2162 - val_loss: 0.6340 - val_acc: 0.1985\n",
      "Epoch 2384/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2225 - acc: 0.2158 - val_loss: 0.6119 - val_acc: 0.2004\n",
      "Epoch 2385/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2250 - acc: 0.2162 - val_loss: 0.5931 - val_acc: 0.2004\n",
      "Epoch 2386/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2189 - acc: 0.2158 - val_loss: 0.5816 - val_acc: 0.2004\n",
      "Epoch 2387/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1926 - acc: 0.2162 - val_loss: 0.5932 - val_acc: 0.2004\n",
      "Epoch 2388/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2241 - acc: 0.2153 - val_loss: 0.7321 - val_acc: 0.2004\n",
      "Epoch 2389/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2158 - acc: 0.2148 - val_loss: 0.5837 - val_acc: 0.2004\n",
      "Epoch 2390/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2012 - acc: 0.2158 - val_loss: 0.5743 - val_acc: 0.2004\n",
      "Epoch 2391/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1947 - acc: 0.2162 - val_loss: 0.5980 - val_acc: 0.1985\n",
      "Epoch 2392/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2075 - acc: 0.2158 - val_loss: 0.5812 - val_acc: 0.2004\n",
      "Epoch 2393/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1978 - acc: 0.2158 - val_loss: 0.6061 - val_acc: 0.1985\n",
      "Epoch 2394/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1914 - acc: 0.2158 - val_loss: 0.5940 - val_acc: 0.2004\n",
      "Epoch 2395/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1958 - acc: 0.2158 - val_loss: 0.5790 - val_acc: 0.2004\n",
      "Epoch 2396/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2222 - acc: 0.2162 - val_loss: 0.6109 - val_acc: 0.2004\n",
      "Epoch 2397/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2096 - acc: 0.2148 - val_loss: 0.6203 - val_acc: 0.1985\n",
      "Epoch 2398/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1942 - acc: 0.2158 - val_loss: 0.6369 - val_acc: 0.1985\n",
      "Epoch 2399/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2164 - acc: 0.2148 - val_loss: 0.5576 - val_acc: 0.2004\n",
      "Epoch 2400/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2225 - acc: 0.2148 - val_loss: 0.6203 - val_acc: 0.1985\n",
      "Epoch 2401/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2140 - acc: 0.2153 - val_loss: 0.5785 - val_acc: 0.2004\n",
      "Epoch 2402/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2158 - acc: 0.2158 - val_loss: 0.6746 - val_acc: 0.1967\n",
      "Epoch 2403/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2250 - acc: 0.2153 - val_loss: 0.6936 - val_acc: 0.1985\n",
      "Epoch 2404/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2006 - acc: 0.2148 - val_loss: 0.6100 - val_acc: 0.2004\n",
      "Epoch 2405/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1950 - acc: 0.2162 - val_loss: 0.5794 - val_acc: 0.2004\n",
      "Epoch 2406/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2006 - acc: 0.2153 - val_loss: 0.6914 - val_acc: 0.1985\n",
      "Epoch 2407/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2206 - acc: 0.2144 - val_loss: 0.5896 - val_acc: 0.2004\n",
      "Epoch 2408/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2170 - acc: 0.2153 - val_loss: 0.6248 - val_acc: 0.1985\n",
      "Epoch 2409/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1863 - acc: 0.2153 - val_loss: 0.6260 - val_acc: 0.1985\n",
      "Epoch 2410/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2225 - acc: 0.2139 - val_loss: 0.7092 - val_acc: 0.1985\n",
      "Epoch 2411/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2201 - acc: 0.2153 - val_loss: 0.6375 - val_acc: 0.2004\n",
      "Epoch 2412/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1984 - acc: 0.2162 - val_loss: 0.5826 - val_acc: 0.2004\n",
      "Epoch 2413/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1943 - acc: 0.2158 - val_loss: 0.5982 - val_acc: 0.1985\n",
      "Epoch 2414/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1912 - acc: 0.2158 - val_loss: 0.5749 - val_acc: 0.2004\n",
      "Epoch 2415/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2061 - acc: 0.2158 - val_loss: 0.6119 - val_acc: 0.2004\n",
      "Epoch 2416/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1907 - acc: 0.2162 - val_loss: 0.5811 - val_acc: 0.2004\n",
      "Epoch 2417/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1981 - acc: 0.2153 - val_loss: 0.6188 - val_acc: 0.2004\n",
      "Epoch 2418/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1896 - acc: 0.2153 - val_loss: 0.6776 - val_acc: 0.2004\n",
      "Epoch 2419/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2138 - acc: 0.2158 - val_loss: 0.6692 - val_acc: 0.2004\n",
      "Epoch 2420/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2021 - acc: 0.2153 - val_loss: 0.5929 - val_acc: 0.1985\n",
      "Epoch 2421/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2000 - acc: 0.2158 - val_loss: 0.6061 - val_acc: 0.2004\n",
      "Epoch 2422/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2039 - acc: 0.2162 - val_loss: 0.6425 - val_acc: 0.1985\n",
      "Epoch 2423/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2187 - acc: 0.2162 - val_loss: 0.6341 - val_acc: 0.2004\n",
      "Epoch 2424/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2856 - acc: 0.2148 - val_loss: 0.6087 - val_acc: 0.1985\n",
      "Epoch 2425/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2011 - acc: 0.2153 - val_loss: 0.5835 - val_acc: 0.2004\n",
      "Epoch 2426/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2091 - acc: 0.2158 - val_loss: 0.6042 - val_acc: 0.2004\n",
      "Epoch 2427/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2205 - acc: 0.2153 - val_loss: 0.5956 - val_acc: 0.2004\n",
      "Epoch 2428/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1951 - acc: 0.2158 - val_loss: 0.5950 - val_acc: 0.2004\n",
      "Epoch 2429/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2019 - acc: 0.2158 - val_loss: 0.7043 - val_acc: 0.2004\n",
      "Epoch 2430/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2190 - acc: 0.2158 - val_loss: 0.5608 - val_acc: 0.1985\n",
      "Epoch 2431/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2080 - acc: 0.2144 - val_loss: 0.6905 - val_acc: 0.1985\n",
      "Epoch 2432/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2047 - acc: 0.2158 - val_loss: 0.6179 - val_acc: 0.2004\n",
      "Epoch 2433/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2319 - acc: 0.2158 - val_loss: 0.8699 - val_acc: 0.2004\n",
      "Epoch 2434/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2249 - acc: 0.2144 - val_loss: 0.5865 - val_acc: 0.2004\n",
      "Epoch 2435/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2026 - acc: 0.2158 - val_loss: 0.6196 - val_acc: 0.2004\n",
      "Epoch 2436/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2196 - acc: 0.2158 - val_loss: 0.5749 - val_acc: 0.2004\n",
      "Epoch 2437/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2061 - acc: 0.2148 - val_loss: 0.6081 - val_acc: 0.1985\n",
      "Epoch 2438/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1934 - acc: 0.2162 - val_loss: 0.6055 - val_acc: 0.2004\n",
      "Epoch 2439/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1914 - acc: 0.2162 - val_loss: 0.6904 - val_acc: 0.1985\n",
      "Epoch 2440/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2013 - acc: 0.2158 - val_loss: 0.8679 - val_acc: 0.1929\n",
      "Epoch 2441/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2419 - acc: 0.2135 - val_loss: 0.7740 - val_acc: 0.1985\n",
      "Epoch 2442/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2300 - acc: 0.2144 - val_loss: 0.6190 - val_acc: 0.2004\n",
      "Epoch 2443/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2089 - acc: 0.2144 - val_loss: 0.7634 - val_acc: 0.2004\n",
      "Epoch 2444/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2179 - acc: 0.2162 - val_loss: 0.5757 - val_acc: 0.2004\n",
      "Epoch 2445/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2052 - acc: 0.2167 - val_loss: 0.6216 - val_acc: 0.2004\n",
      "Epoch 2446/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2173 - acc: 0.2148 - val_loss: 0.6089 - val_acc: 0.2004\n",
      "Epoch 2447/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2089 - acc: 0.2158 - val_loss: 0.6231 - val_acc: 0.2004\n",
      "Epoch 2448/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2140 - acc: 0.2153 - val_loss: 0.5826 - val_acc: 0.2004\n",
      "Epoch 2449/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2144 - acc: 0.2139 - val_loss: 0.5964 - val_acc: 0.2004\n",
      "Epoch 2450/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2168 - acc: 0.2148 - val_loss: 0.5958 - val_acc: 0.1985\n",
      "Epoch 2451/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2089 - acc: 0.2148 - val_loss: 0.5847 - val_acc: 0.2004\n",
      "Epoch 2452/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2060 - acc: 0.2158 - val_loss: 0.5956 - val_acc: 0.2004\n",
      "Epoch 2453/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1959 - acc: 0.2167 - val_loss: 0.6083 - val_acc: 0.2004\n",
      "Epoch 2454/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2048 - acc: 0.2158 - val_loss: 0.5813 - val_acc: 0.2004\n",
      "Epoch 2455/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2101 - acc: 0.2148 - val_loss: 0.6531 - val_acc: 0.2004\n",
      "Epoch 2456/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2749 - acc: 0.2158 - val_loss: 0.6216 - val_acc: 0.1985\n",
      "Epoch 2457/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2571 - acc: 0.2148 - val_loss: 0.6374 - val_acc: 0.2004\n",
      "Epoch 2458/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4938 - acc: 0.2144 - val_loss: 1.0854 - val_acc: 0.1911\n",
      "Epoch 2459/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.8312 - acc: 0.2121 - val_loss: 0.5729 - val_acc: 0.2004\n",
      "Epoch 2460/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.6949 - acc: 0.2148 - val_loss: 0.6239 - val_acc: 0.2004\n",
      "Epoch 2461/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3654 - acc: 0.2162 - val_loss: 0.6208 - val_acc: 0.2004\n",
      "Epoch 2462/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.2041 - acc: 0.2153 - val_loss: 0.5727 - val_acc: 0.2004\n",
      "Epoch 2463/4000\n",
      "68/68 [==============================] - 5s 72ms/step - loss: 0.2169 - acc: 0.2153 - val_loss: 0.6849 - val_acc: 0.2004\n",
      "Epoch 2464/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1973 - acc: 0.2153 - val_loss: 0.5925 - val_acc: 0.1985\n",
      "Epoch 2465/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1954 - acc: 0.2158 - val_loss: 0.6150 - val_acc: 0.2004\n",
      "Epoch 2466/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2208 - acc: 0.2162 - val_loss: 0.5904 - val_acc: 0.1985\n",
      "Epoch 2467/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1942 - acc: 0.2167 - val_loss: 0.6125 - val_acc: 0.1985\n",
      "Epoch 2468/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1859 - acc: 0.2153 - val_loss: 0.5873 - val_acc: 0.1985\n",
      "Epoch 2469/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1972 - acc: 0.2158 - val_loss: 0.5677 - val_acc: 0.2004\n",
      "Epoch 2470/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1848 - acc: 0.2158 - val_loss: 0.5996 - val_acc: 0.1985\n",
      "Epoch 2471/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2063 - acc: 0.2158 - val_loss: 0.5892 - val_acc: 0.2004\n",
      "Epoch 2472/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1869 - acc: 0.2158 - val_loss: 0.6003 - val_acc: 0.1985\n",
      "Epoch 2473/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1873 - acc: 0.2153 - val_loss: 0.5798 - val_acc: 0.2004\n",
      "Epoch 2474/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2263 - acc: 0.2153 - val_loss: 0.7707 - val_acc: 0.2004\n",
      "Epoch 2475/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2252 - acc: 0.2158 - val_loss: 0.6133 - val_acc: 0.2004\n",
      "Epoch 2476/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.1941 - acc: 0.2167 - val_loss: 0.5869 - val_acc: 0.1985\n",
      "Epoch 2477/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1905 - acc: 0.2158 - val_loss: 0.5774 - val_acc: 0.2004\n",
      "Epoch 2478/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2108 - acc: 0.2153 - val_loss: 0.6073 - val_acc: 0.2004\n",
      "Epoch 2479/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2026 - acc: 0.2144 - val_loss: 0.5863 - val_acc: 0.2004\n",
      "Epoch 2480/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1899 - acc: 0.2153 - val_loss: 0.6119 - val_acc: 0.1985\n",
      "Epoch 2481/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2037 - acc: 0.2153 - val_loss: 0.5804 - val_acc: 0.2004\n",
      "Epoch 2482/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.2103 - acc: 0.2153 - val_loss: 0.6055 - val_acc: 0.2004\n",
      "Epoch 2483/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2168 - acc: 0.2153 - val_loss: 0.5690 - val_acc: 0.2004\n",
      "Epoch 2484/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2164 - acc: 0.2148 - val_loss: 0.6117 - val_acc: 0.1985\n",
      "Epoch 2485/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1890 - acc: 0.2153 - val_loss: 0.5853 - val_acc: 0.2004\n",
      "Epoch 2486/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1951 - acc: 0.2158 - val_loss: 0.5643 - val_acc: 0.2004\n",
      "Epoch 2487/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2004 - acc: 0.2148 - val_loss: 0.5668 - val_acc: 0.2004\n",
      "Epoch 2488/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1949 - acc: 0.2148 - val_loss: 0.5840 - val_acc: 0.2004\n",
      "Epoch 2489/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.1927 - acc: 0.2153 - val_loss: 0.6319 - val_acc: 0.2004\n",
      "Epoch 2490/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2417 - acc: 0.2153 - val_loss: 0.6594 - val_acc: 0.2004\n",
      "Epoch 2491/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2264 - acc: 0.2148 - val_loss: 0.5908 - val_acc: 0.2004\n",
      "Epoch 2492/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1947 - acc: 0.2162 - val_loss: 0.6152 - val_acc: 0.1985\n",
      "Epoch 2493/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1900 - acc: 0.2153 - val_loss: 0.7020 - val_acc: 0.2004\n",
      "Epoch 2494/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2306 - acc: 0.2167 - val_loss: 0.6396 - val_acc: 0.1985\n",
      "Epoch 2495/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1979 - acc: 0.2158 - val_loss: 0.5795 - val_acc: 0.2004\n",
      "Epoch 2496/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.1917 - acc: 0.2167 - val_loss: 0.5639 - val_acc: 0.2004\n",
      "Epoch 2497/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1999 - acc: 0.2162 - val_loss: 0.5792 - val_acc: 0.2004\n",
      "Epoch 2498/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2066 - acc: 0.2162 - val_loss: 0.7042 - val_acc: 0.1967\n",
      "Epoch 2499/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2111 - acc: 0.2158 - val_loss: 0.6291 - val_acc: 0.2004\n",
      "Epoch 2500/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1971 - acc: 0.2153 - val_loss: 0.5801 - val_acc: 0.2004\n",
      "Epoch 2501/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.1981 - acc: 0.2158 - val_loss: 0.5934 - val_acc: 0.2004\n",
      "Epoch 2502/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2096 - acc: 0.2153 - val_loss: 0.5850 - val_acc: 0.2004\n",
      "Epoch 2503/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2055 - acc: 0.2153 - val_loss: 0.6068 - val_acc: 0.2004\n",
      "Epoch 2504/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.2046 - acc: 0.2148 - val_loss: 0.6409 - val_acc: 0.2004\n",
      "Epoch 2505/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1988 - acc: 0.2148 - val_loss: 0.6090 - val_acc: 0.1985\n",
      "Epoch 2506/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1943 - acc: 0.2162 - val_loss: 0.5889 - val_acc: 0.2004\n",
      "Epoch 2507/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1850 - acc: 0.2167 - val_loss: 0.5821 - val_acc: 0.1985\n",
      "Epoch 2508/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2001 - acc: 0.2153 - val_loss: 0.6029 - val_acc: 0.2004\n",
      "Epoch 2509/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2068 - acc: 0.2158 - val_loss: 0.6393 - val_acc: 0.2004\n",
      "Epoch 2510/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1927 - acc: 0.2148 - val_loss: 0.7053 - val_acc: 0.2004\n",
      "Epoch 2511/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2135 - acc: 0.2158 - val_loss: 0.6041 - val_acc: 0.2004\n",
      "Epoch 2512/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1907 - acc: 0.2158 - val_loss: 0.6268 - val_acc: 0.2004\n",
      "Epoch 2513/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2013 - acc: 0.2158 - val_loss: 0.6908 - val_acc: 0.2004\n",
      "Epoch 2514/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1939 - acc: 0.2162 - val_loss: 0.5795 - val_acc: 0.2004\n",
      "Epoch 2515/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1978 - acc: 0.2153 - val_loss: 0.6212 - val_acc: 0.2004\n",
      "Epoch 2516/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2106 - acc: 0.2144 - val_loss: 0.6241 - val_acc: 0.1985\n",
      "Epoch 2517/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1991 - acc: 0.2162 - val_loss: 0.6193 - val_acc: 0.2004\n",
      "Epoch 2518/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2050 - acc: 0.2158 - val_loss: 0.5874 - val_acc: 0.2004\n",
      "Epoch 2519/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2173 - acc: 0.2158 - val_loss: 0.6118 - val_acc: 0.1985\n",
      "Epoch 2520/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2051 - acc: 0.2148 - val_loss: 0.6204 - val_acc: 0.2004\n",
      "Epoch 2521/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2025 - acc: 0.2139 - val_loss: 0.5720 - val_acc: 0.2004\n",
      "Epoch 2522/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1990 - acc: 0.2162 - val_loss: 0.7082 - val_acc: 0.1967\n",
      "Epoch 2523/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2124 - acc: 0.2158 - val_loss: 0.6298 - val_acc: 0.1985\n",
      "Epoch 2524/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2258 - acc: 0.2139 - val_loss: 0.5824 - val_acc: 0.2004\n",
      "Epoch 2525/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2092 - acc: 0.2162 - val_loss: 0.6068 - val_acc: 0.2004\n",
      "Epoch 2526/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1900 - acc: 0.2158 - val_loss: 0.5906 - val_acc: 0.2004\n",
      "Epoch 2527/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1952 - acc: 0.2158 - val_loss: 0.5831 - val_acc: 0.2004\n",
      "Epoch 2528/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1970 - acc: 0.2158 - val_loss: 0.6161 - val_acc: 0.1985\n",
      "Epoch 2529/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2065 - acc: 0.2153 - val_loss: 0.6338 - val_acc: 0.2004\n",
      "Epoch 2530/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2152 - acc: 0.2162 - val_loss: 0.5727 - val_acc: 0.2004\n",
      "Epoch 2531/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2048 - acc: 0.2158 - val_loss: 0.5786 - val_acc: 0.2004\n",
      "Epoch 2532/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2000 - acc: 0.2153 - val_loss: 0.5823 - val_acc: 0.2004\n",
      "Epoch 2533/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2035 - acc: 0.2148 - val_loss: 0.5912 - val_acc: 0.2004\n",
      "Epoch 2534/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2395 - acc: 0.2148 - val_loss: 0.6173 - val_acc: 0.2004\n",
      "Epoch 2535/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1967 - acc: 0.2167 - val_loss: 0.6063 - val_acc: 0.2004\n",
      "Epoch 2536/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2284 - acc: 0.2162 - val_loss: 0.6027 - val_acc: 0.2004\n",
      "Epoch 2537/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1846 - acc: 0.2158 - val_loss: 0.5628 - val_acc: 0.2004\n",
      "Epoch 2538/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2093 - acc: 0.2148 - val_loss: 0.5939 - val_acc: 0.2004\n",
      "Epoch 2539/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2344 - acc: 0.2153 - val_loss: 0.9031 - val_acc: 0.1911\n",
      "Epoch 2540/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2216 - acc: 0.2153 - val_loss: 0.6043 - val_acc: 0.2004\n",
      "Epoch 2541/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2013 - acc: 0.2153 - val_loss: 0.6289 - val_acc: 0.1985\n",
      "Epoch 2542/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2127 - acc: 0.2153 - val_loss: 0.7520 - val_acc: 0.2004\n",
      "Epoch 2543/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 0.2087 - acc: 0.2158 - val_loss: 0.5826 - val_acc: 0.2004\n",
      "Epoch 2544/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.1919 - acc: 0.2148 - val_loss: 0.6121 - val_acc: 0.2004\n",
      "Epoch 2545/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.2146 - acc: 0.2158 - val_loss: 0.6157 - val_acc: 0.1985\n",
      "Epoch 2546/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1988 - acc: 0.2153 - val_loss: 0.6438 - val_acc: 0.1985\n",
      "Epoch 2547/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3010 - acc: 0.2135 - val_loss: 0.6081 - val_acc: 0.2004\n",
      "Epoch 2548/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2597 - acc: 0.2153 - val_loss: 0.5738 - val_acc: 0.1985\n",
      "Epoch 2549/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2641 - acc: 0.2158 - val_loss: 0.6304 - val_acc: 0.2004\n",
      "Epoch 2550/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2770 - acc: 0.2135 - val_loss: 0.6283 - val_acc: 0.2004\n",
      "Epoch 2551/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2215 - acc: 0.2153 - val_loss: 0.5823 - val_acc: 0.1985\n",
      "Epoch 2552/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1964 - acc: 0.2153 - val_loss: 0.5839 - val_acc: 0.2004\n",
      "Epoch 2553/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2292 - acc: 0.2162 - val_loss: 0.6938 - val_acc: 0.1985\n",
      "Epoch 2554/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2145 - acc: 0.2153 - val_loss: 0.5753 - val_acc: 0.2004\n",
      "Epoch 2555/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1940 - acc: 0.2162 - val_loss: 0.6592 - val_acc: 0.1985\n",
      "Epoch 2556/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1923 - acc: 0.2158 - val_loss: 0.5946 - val_acc: 0.2004\n",
      "Epoch 2557/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2052 - acc: 0.2135 - val_loss: 0.5983 - val_acc: 0.2004\n",
      "Epoch 2558/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1860 - acc: 0.2172 - val_loss: 0.6075 - val_acc: 0.2004\n",
      "Epoch 2559/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1986 - acc: 0.2162 - val_loss: 0.6306 - val_acc: 0.1985\n",
      "Epoch 2560/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2613 - acc: 0.2144 - val_loss: 0.5934 - val_acc: 0.2004\n",
      "Epoch 2561/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.1941 - acc: 0.2148 - val_loss: 0.5673 - val_acc: 0.2004\n",
      "Epoch 2562/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.1873 - acc: 0.2153 - val_loss: 0.6117 - val_acc: 0.2004\n",
      "Epoch 2563/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2100 - acc: 0.2153 - val_loss: 0.5745 - val_acc: 0.2004\n",
      "Epoch 2564/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1897 - acc: 0.2162 - val_loss: 0.6237 - val_acc: 0.2004\n",
      "Epoch 2565/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2032 - acc: 0.2167 - val_loss: 0.6106 - val_acc: 0.2004\n",
      "Epoch 2566/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2128 - acc: 0.2158 - val_loss: 0.6013 - val_acc: 0.2004\n",
      "Epoch 2567/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1869 - acc: 0.2153 - val_loss: 0.5916 - val_acc: 0.2004\n",
      "Epoch 2568/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1938 - acc: 0.2162 - val_loss: 0.5919 - val_acc: 0.2004\n",
      "Epoch 2569/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1889 - acc: 0.2158 - val_loss: 0.6215 - val_acc: 0.2004\n",
      "Epoch 2570/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1914 - acc: 0.2158 - val_loss: 0.6024 - val_acc: 0.2004\n",
      "Epoch 2571/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1881 - acc: 0.2158 - val_loss: 0.6227 - val_acc: 0.2004\n",
      "Epoch 2572/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1807 - acc: 0.2158 - val_loss: 0.5769 - val_acc: 0.2004\n",
      "Epoch 2573/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1843 - acc: 0.2158 - val_loss: 0.6077 - val_acc: 0.2004\n",
      "Epoch 2574/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2004 - acc: 0.2153 - val_loss: 0.5785 - val_acc: 0.2004\n",
      "Epoch 2575/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2116 - acc: 0.2144 - val_loss: 0.6140 - val_acc: 0.2004\n",
      "Epoch 2576/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2550 - acc: 0.2121 - val_loss: 0.6108 - val_acc: 0.2004\n",
      "Epoch 2577/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.2371 - acc: 0.2148 - val_loss: 0.5796 - val_acc: 0.2004\n",
      "Epoch 2578/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1970 - acc: 0.2158 - val_loss: 0.5887 - val_acc: 0.2004\n",
      "Epoch 2579/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1984 - acc: 0.2144 - val_loss: 0.5946 - val_acc: 0.2004\n",
      "Epoch 2580/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1889 - acc: 0.2162 - val_loss: 0.6319 - val_acc: 0.1985\n",
      "Epoch 2581/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1915 - acc: 0.2158 - val_loss: 0.6280 - val_acc: 0.2004\n",
      "Epoch 2582/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2000 - acc: 0.2148 - val_loss: 0.6024 - val_acc: 0.2004\n",
      "Epoch 2583/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1933 - acc: 0.2162 - val_loss: 0.5632 - val_acc: 0.2004\n",
      "Epoch 2584/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2025 - acc: 0.2153 - val_loss: 0.6009 - val_acc: 0.2004\n",
      "Epoch 2585/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2057 - acc: 0.2153 - val_loss: 0.5995 - val_acc: 0.2004\n",
      "Epoch 2586/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2012 - acc: 0.2153 - val_loss: 0.5984 - val_acc: 0.2004\n",
      "Epoch 2587/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1934 - acc: 0.2158 - val_loss: 0.5931 - val_acc: 0.2004\n",
      "Epoch 2588/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2509 - acc: 0.2158 - val_loss: 0.7642 - val_acc: 0.2004\n",
      "Epoch 2589/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2292 - acc: 0.2148 - val_loss: 0.6414 - val_acc: 0.1985\n",
      "Epoch 2590/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1959 - acc: 0.2148 - val_loss: 0.6199 - val_acc: 0.1985\n",
      "Epoch 2591/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2197 - acc: 0.2139 - val_loss: 0.6696 - val_acc: 0.1985\n",
      "Epoch 2592/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2233 - acc: 0.2158 - val_loss: 0.8033 - val_acc: 0.2004\n",
      "Epoch 2593/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2076 - acc: 0.2148 - val_loss: 0.6040 - val_acc: 0.2004\n",
      "Epoch 2594/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1921 - acc: 0.2162 - val_loss: 0.6592 - val_acc: 0.1985\n",
      "Epoch 2595/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1982 - acc: 0.2158 - val_loss: 0.6626 - val_acc: 0.2004\n",
      "Epoch 2596/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2040 - acc: 0.2144 - val_loss: 0.5892 - val_acc: 0.2004\n",
      "Epoch 2597/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2016 - acc: 0.2148 - val_loss: 0.6254 - val_acc: 0.2004\n",
      "Epoch 2598/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1928 - acc: 0.2158 - val_loss: 0.6039 - val_acc: 0.2004\n",
      "Epoch 2599/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1904 - acc: 0.2153 - val_loss: 0.5968 - val_acc: 0.2004\n",
      "Epoch 2600/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2088 - acc: 0.2153 - val_loss: 0.6188 - val_acc: 0.2004\n",
      "Epoch 2601/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2096 - acc: 0.2162 - val_loss: 0.6328 - val_acc: 0.1985\n",
      "Epoch 2602/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2054 - acc: 0.2144 - val_loss: 0.5990 - val_acc: 0.2004\n",
      "Epoch 2603/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2034 - acc: 0.2153 - val_loss: 0.6425 - val_acc: 0.1967\n",
      "Epoch 2604/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2033 - acc: 0.2167 - val_loss: 0.6098 - val_acc: 0.2004\n",
      "Epoch 2605/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2034 - acc: 0.2153 - val_loss: 0.5960 - val_acc: 0.2004\n",
      "Epoch 2606/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2063 - acc: 0.2158 - val_loss: 0.8273 - val_acc: 0.2004\n",
      "Epoch 2607/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2050 - acc: 0.2153 - val_loss: 0.6051 - val_acc: 0.2004\n",
      "Epoch 2608/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1899 - acc: 0.2148 - val_loss: 0.6610 - val_acc: 0.2004\n",
      "Epoch 2609/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2190 - acc: 0.2153 - val_loss: 0.5676 - val_acc: 0.2004\n",
      "Epoch 2610/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1987 - acc: 0.2153 - val_loss: 0.6032 - val_acc: 0.2004\n",
      "Epoch 2611/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2041 - acc: 0.2162 - val_loss: 0.6619 - val_acc: 0.2004\n",
      "Epoch 2612/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2030 - acc: 0.2148 - val_loss: 0.6191 - val_acc: 0.2004\n",
      "Epoch 2613/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2156 - acc: 0.2148 - val_loss: 0.6362 - val_acc: 0.2004\n",
      "Epoch 2614/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2132 - acc: 0.2144 - val_loss: 0.6502 - val_acc: 0.2004\n",
      "Epoch 2615/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2303 - acc: 0.2153 - val_loss: 0.6673 - val_acc: 0.2004\n",
      "Epoch 2616/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2458 - acc: 0.2144 - val_loss: 0.5524 - val_acc: 0.2004\n",
      "Epoch 2617/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2030 - acc: 0.2153 - val_loss: 0.6032 - val_acc: 0.1985\n",
      "Epoch 2618/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2255 - acc: 0.2158 - val_loss: 0.7218 - val_acc: 0.2004\n",
      "Epoch 2619/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2093 - acc: 0.2148 - val_loss: 0.6049 - val_acc: 0.2004\n",
      "Epoch 2620/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1902 - acc: 0.2158 - val_loss: 0.5856 - val_acc: 0.2004\n",
      "Epoch 2621/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2036 - acc: 0.2144 - val_loss: 0.5976 - val_acc: 0.2004\n",
      "Epoch 2622/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2388 - acc: 0.2158 - val_loss: 0.6068 - val_acc: 0.2004\n",
      "Epoch 2623/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1805 - acc: 0.2158 - val_loss: 0.5817 - val_acc: 0.2004\n",
      "Epoch 2624/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.2106 - acc: 0.2153 - val_loss: 0.6351 - val_acc: 0.1985\n",
      "Epoch 2625/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.1887 - acc: 0.2158 - val_loss: 0.6189 - val_acc: 0.2004\n",
      "Epoch 2626/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2187 - acc: 0.2162 - val_loss: 0.7136 - val_acc: 0.2004\n",
      "Epoch 2627/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2175 - acc: 0.2148 - val_loss: 0.6101 - val_acc: 0.2004\n",
      "Epoch 2628/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1850 - acc: 0.2148 - val_loss: 0.6182 - val_acc: 0.2004\n",
      "Epoch 2629/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1990 - acc: 0.2153 - val_loss: 0.6847 - val_acc: 0.2004\n",
      "Epoch 2630/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1937 - acc: 0.2162 - val_loss: 0.6359 - val_acc: 0.1985\n",
      "Epoch 2631/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1917 - acc: 0.2158 - val_loss: 0.6381 - val_acc: 0.2004\n",
      "Epoch 2632/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1990 - acc: 0.2144 - val_loss: 0.6011 - val_acc: 0.2004\n",
      "Epoch 2633/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2144 - acc: 0.2148 - val_loss: 0.6772 - val_acc: 0.2004\n",
      "Epoch 2634/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2247 - acc: 0.2148 - val_loss: 0.5997 - val_acc: 0.2004\n",
      "Epoch 2635/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1970 - acc: 0.2158 - val_loss: 0.6356 - val_acc: 0.1985\n",
      "Epoch 2636/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1993 - acc: 0.2153 - val_loss: 0.6044 - val_acc: 0.2004\n",
      "Epoch 2637/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1901 - acc: 0.2158 - val_loss: 0.6314 - val_acc: 0.1985\n",
      "Epoch 2638/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2048 - acc: 0.2162 - val_loss: 0.5889 - val_acc: 0.2004\n",
      "Epoch 2639/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1962 - acc: 0.2153 - val_loss: 0.7136 - val_acc: 0.1967\n",
      "Epoch 2640/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2237 - acc: 0.2158 - val_loss: 0.5946 - val_acc: 0.2004\n",
      "Epoch 2641/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1941 - acc: 0.2167 - val_loss: 0.6314 - val_acc: 0.2004\n",
      "Epoch 2642/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2078 - acc: 0.2158 - val_loss: 0.6469 - val_acc: 0.1985\n",
      "Epoch 2643/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2226 - acc: 0.2144 - val_loss: 0.6070 - val_acc: 0.2004\n",
      "Epoch 2644/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2062 - acc: 0.2153 - val_loss: 0.6212 - val_acc: 0.2004\n",
      "Epoch 2645/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1974 - acc: 0.2158 - val_loss: 0.6245 - val_acc: 0.2004\n",
      "Epoch 2646/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2620 - acc: 0.2111 - val_loss: 0.8243 - val_acc: 0.1967\n",
      "Epoch 2647/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2186 - acc: 0.2148 - val_loss: 0.6323 - val_acc: 0.2004\n",
      "Epoch 2648/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1905 - acc: 0.2153 - val_loss: 0.5913 - val_acc: 0.2004\n",
      "Epoch 2649/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1817 - acc: 0.2158 - val_loss: 0.6209 - val_acc: 0.1985\n",
      "Epoch 2650/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2253 - acc: 0.2158 - val_loss: 0.7751 - val_acc: 0.1967\n",
      "Epoch 2651/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.6933 - acc: 0.2139 - val_loss: 0.6893 - val_acc: 0.2004\n",
      "Epoch 2652/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.4224 - acc: 0.2158 - val_loss: 0.8558 - val_acc: 0.2004\n",
      "Epoch 2653/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 2.0873 - acc: 0.1949 - val_loss: 1.3372 - val_acc: 0.2004\n",
      "Epoch 2654/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4079 - acc: 0.2148 - val_loss: 0.5298 - val_acc: 0.2004\n",
      "Epoch 2655/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2191 - acc: 0.2167 - val_loss: 0.5628 - val_acc: 0.2004\n",
      "Epoch 2656/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1936 - acc: 0.2162 - val_loss: 0.5511 - val_acc: 0.2004\n",
      "Epoch 2657/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1894 - acc: 0.2158 - val_loss: 0.5767 - val_acc: 0.2004\n",
      "Epoch 2658/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1928 - acc: 0.2153 - val_loss: 0.5269 - val_acc: 0.2004\n",
      "Epoch 2659/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2158 - acc: 0.2153 - val_loss: 0.5666 - val_acc: 0.2004\n",
      "Epoch 2660/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1932 - acc: 0.2167 - val_loss: 0.5805 - val_acc: 0.2004\n",
      "Epoch 2661/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1839 - acc: 0.2158 - val_loss: 0.6594 - val_acc: 0.2004\n",
      "Epoch 2662/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1867 - acc: 0.2158 - val_loss: 0.5512 - val_acc: 0.2004\n",
      "Epoch 2663/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1785 - acc: 0.2153 - val_loss: 0.5465 - val_acc: 0.2004\n",
      "Epoch 2664/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2063 - acc: 0.2153 - val_loss: 0.5706 - val_acc: 0.2004\n",
      "Epoch 2665/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1790 - acc: 0.2158 - val_loss: 0.5706 - val_acc: 0.2004\n",
      "Epoch 2666/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1864 - acc: 0.2162 - val_loss: 0.5647 - val_acc: 0.2004\n",
      "Epoch 2667/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1882 - acc: 0.2148 - val_loss: 0.5914 - val_acc: 0.1985\n",
      "Epoch 2668/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1853 - acc: 0.2162 - val_loss: 0.5915 - val_acc: 0.2004\n",
      "Epoch 2669/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1790 - acc: 0.2158 - val_loss: 0.6119 - val_acc: 0.2004\n",
      "Epoch 2670/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1805 - acc: 0.2162 - val_loss: 0.6928 - val_acc: 0.1967\n",
      "Epoch 2671/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1880 - acc: 0.2162 - val_loss: 0.6282 - val_acc: 0.1985\n",
      "Epoch 2672/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1923 - acc: 0.2148 - val_loss: 0.5828 - val_acc: 0.2004\n",
      "Epoch 2673/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2048 - acc: 0.2153 - val_loss: 0.5764 - val_acc: 0.2004\n",
      "Epoch 2674/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1982 - acc: 0.2162 - val_loss: 0.5649 - val_acc: 0.2004\n",
      "Epoch 2675/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2267 - acc: 0.2153 - val_loss: 0.5591 - val_acc: 0.2004\n",
      "Epoch 2676/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1835 - acc: 0.2162 - val_loss: 0.5762 - val_acc: 0.2004\n",
      "Epoch 2677/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2038 - acc: 0.2148 - val_loss: 0.6087 - val_acc: 0.2004\n",
      "Epoch 2678/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1972 - acc: 0.2158 - val_loss: 0.5948 - val_acc: 0.2004\n",
      "Epoch 2679/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1861 - acc: 0.2153 - val_loss: 0.6490 - val_acc: 0.2004\n",
      "Epoch 2680/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2008 - acc: 0.2148 - val_loss: 0.6058 - val_acc: 0.2004\n",
      "Epoch 2681/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2220 - acc: 0.2162 - val_loss: 0.6375 - val_acc: 0.2004\n",
      "Epoch 2682/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2016 - acc: 0.2158 - val_loss: 0.6473 - val_acc: 0.2004\n",
      "Epoch 2683/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1954 - acc: 0.2162 - val_loss: 0.5479 - val_acc: 0.2004\n",
      "Epoch 2684/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2120 - acc: 0.2162 - val_loss: 0.5991 - val_acc: 0.2004\n",
      "Epoch 2685/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2231 - acc: 0.2144 - val_loss: 0.6248 - val_acc: 0.2004\n",
      "Epoch 2686/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1830 - acc: 0.2158 - val_loss: 0.5954 - val_acc: 0.2004\n",
      "Epoch 2687/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1878 - acc: 0.2162 - val_loss: 0.5974 - val_acc: 0.2004\n",
      "Epoch 2688/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2000 - acc: 0.2158 - val_loss: 0.5729 - val_acc: 0.2004\n",
      "Epoch 2689/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1834 - acc: 0.2158 - val_loss: 0.6055 - val_acc: 0.2004\n",
      "Epoch 2690/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2187 - acc: 0.2153 - val_loss: 0.6199 - val_acc: 0.2004\n",
      "Epoch 2691/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1934 - acc: 0.2153 - val_loss: 0.5866 - val_acc: 0.2004\n",
      "Epoch 2692/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1884 - acc: 0.2162 - val_loss: 0.6125 - val_acc: 0.2004\n",
      "Epoch 2693/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1860 - acc: 0.2158 - val_loss: 0.5842 - val_acc: 0.2004\n",
      "Epoch 2694/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1954 - acc: 0.2148 - val_loss: 0.6637 - val_acc: 0.1985\n",
      "Epoch 2695/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1834 - acc: 0.2162 - val_loss: 0.6793 - val_acc: 0.1985\n",
      "Epoch 2696/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2161 - acc: 0.2162 - val_loss: 0.6008 - val_acc: 0.2004\n",
      "Epoch 2697/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1883 - acc: 0.2148 - val_loss: 0.6106 - val_acc: 0.1985\n",
      "Epoch 2698/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1974 - acc: 0.2162 - val_loss: 0.6160 - val_acc: 0.1985\n",
      "Epoch 2699/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1898 - acc: 0.2172 - val_loss: 0.5814 - val_acc: 0.2004\n",
      "Epoch 2700/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1815 - acc: 0.2158 - val_loss: 0.6097 - val_acc: 0.2004\n",
      "Epoch 2701/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1970 - acc: 0.2158 - val_loss: 1.0038 - val_acc: 0.2004\n",
      "Epoch 2702/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2498 - acc: 0.2153 - val_loss: 0.6395 - val_acc: 0.2004\n",
      "Epoch 2703/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2215 - acc: 0.2158 - val_loss: 0.6810 - val_acc: 0.1967\n",
      "Epoch 2704/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1961 - acc: 0.2158 - val_loss: 0.6087 - val_acc: 0.2004\n",
      "Epoch 2705/4000\n",
      "68/68 [==============================] - 5s 74ms/step - loss: 0.2141 - acc: 0.2135 - val_loss: 0.5888 - val_acc: 0.2004\n",
      "Epoch 2706/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2121 - acc: 0.2148 - val_loss: 0.6604 - val_acc: 0.2004\n",
      "Epoch 2707/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2362 - acc: 0.2162 - val_loss: 0.6418 - val_acc: 0.2004\n",
      "Epoch 2708/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2340 - acc: 0.2162 - val_loss: 0.7466 - val_acc: 0.2004\n",
      "Epoch 2709/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2142 - acc: 0.2158 - val_loss: 0.5951 - val_acc: 0.2004\n",
      "Epoch 2710/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1978 - acc: 0.2153 - val_loss: 0.6127 - val_acc: 0.2004\n",
      "Epoch 2711/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2040 - acc: 0.2162 - val_loss: 0.7131 - val_acc: 0.2004\n",
      "Epoch 2712/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2157 - acc: 0.2158 - val_loss: 0.5861 - val_acc: 0.2004\n",
      "Epoch 2713/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1993 - acc: 0.2144 - val_loss: 0.5811 - val_acc: 0.2004\n",
      "Epoch 2714/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1880 - acc: 0.2162 - val_loss: 0.5959 - val_acc: 0.2004\n",
      "Epoch 2715/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1952 - acc: 0.2153 - val_loss: 0.5899 - val_acc: 0.2004\n",
      "Epoch 2716/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1827 - acc: 0.2167 - val_loss: 0.5870 - val_acc: 0.2004\n",
      "Epoch 2717/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1953 - acc: 0.2158 - val_loss: 0.6331 - val_acc: 0.2004\n",
      "Epoch 2718/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1869 - acc: 0.2162 - val_loss: 0.6004 - val_acc: 0.1985\n",
      "Epoch 2719/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1901 - acc: 0.2158 - val_loss: 0.6393 - val_acc: 0.2004\n",
      "Epoch 2720/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1975 - acc: 0.2153 - val_loss: 0.5976 - val_acc: 0.1985\n",
      "Epoch 2721/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1958 - acc: 0.2148 - val_loss: 0.6172 - val_acc: 0.2004\n",
      "Epoch 2722/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1873 - acc: 0.2162 - val_loss: 0.6715 - val_acc: 0.1985\n",
      "Epoch 2723/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2846 - acc: 0.2139 - val_loss: 0.7103 - val_acc: 0.2004\n",
      "Epoch 2724/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2103 - acc: 0.2144 - val_loss: 0.6293 - val_acc: 0.1985\n",
      "Epoch 2725/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1882 - acc: 0.2153 - val_loss: 0.6405 - val_acc: 0.2004\n",
      "Epoch 2726/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2002 - acc: 0.2162 - val_loss: 0.6102 - val_acc: 0.2004\n",
      "Epoch 2727/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1987 - acc: 0.2148 - val_loss: 0.5623 - val_acc: 0.1985\n",
      "Epoch 2728/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1866 - acc: 0.2153 - val_loss: 0.6475 - val_acc: 0.1985\n",
      "Epoch 2729/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1972 - acc: 0.2162 - val_loss: 0.6067 - val_acc: 0.2004\n",
      "Epoch 2730/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2090 - acc: 0.2158 - val_loss: 0.5775 - val_acc: 0.2004\n",
      "Epoch 2731/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1907 - acc: 0.2162 - val_loss: 0.7857 - val_acc: 0.2004\n",
      "Epoch 2732/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1930 - acc: 0.2153 - val_loss: 0.5806 - val_acc: 0.2004\n",
      "Epoch 2733/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1866 - acc: 0.2153 - val_loss: 0.5997 - val_acc: 0.2004\n",
      "Epoch 2734/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2014 - acc: 0.2158 - val_loss: 0.6737 - val_acc: 0.1967\n",
      "Epoch 2735/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1858 - acc: 0.2153 - val_loss: 0.6060 - val_acc: 0.2004\n",
      "Epoch 2736/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1815 - acc: 0.2148 - val_loss: 0.5773 - val_acc: 0.2004\n",
      "Epoch 2737/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1867 - acc: 0.2153 - val_loss: 0.6308 - val_acc: 0.1985\n",
      "Epoch 2738/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2001 - acc: 0.2148 - val_loss: 0.6332 - val_acc: 0.1985\n",
      "Epoch 2739/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2057 - acc: 0.2148 - val_loss: 0.6322 - val_acc: 0.1985\n",
      "Epoch 2740/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1920 - acc: 0.2158 - val_loss: 0.6127 - val_acc: 0.1985\n",
      "Epoch 2741/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2356 - acc: 0.2153 - val_loss: 0.6836 - val_acc: 0.1985\n",
      "Epoch 2742/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2182 - acc: 0.2144 - val_loss: 0.6678 - val_acc: 0.2004\n",
      "Epoch 2743/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2105 - acc: 0.2148 - val_loss: 0.6107 - val_acc: 0.2004\n",
      "Epoch 2744/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2004 - acc: 0.2158 - val_loss: 0.6514 - val_acc: 0.1985\n",
      "Epoch 2745/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2097 - acc: 0.2148 - val_loss: 0.6076 - val_acc: 0.1985\n",
      "Epoch 2746/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2574 - acc: 0.2158 - val_loss: 0.6094 - val_acc: 0.2004\n",
      "Epoch 2747/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1964 - acc: 0.2153 - val_loss: 0.5934 - val_acc: 0.2004\n",
      "Epoch 2748/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1881 - acc: 0.2158 - val_loss: 0.6051 - val_acc: 0.2004\n",
      "Epoch 2749/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1986 - acc: 0.2162 - val_loss: 0.7517 - val_acc: 0.1967\n",
      "Epoch 2750/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2047 - acc: 0.2153 - val_loss: 0.5936 - val_acc: 0.2004\n",
      "Epoch 2751/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2373 - acc: 0.2162 - val_loss: 0.5846 - val_acc: 0.2004\n",
      "Epoch 2752/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1975 - acc: 0.2153 - val_loss: 0.6610 - val_acc: 0.1985\n",
      "Epoch 2753/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1877 - acc: 0.2158 - val_loss: 0.5963 - val_acc: 0.2004\n",
      "Epoch 2754/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2015 - acc: 0.2153 - val_loss: 0.8061 - val_acc: 0.2004\n",
      "Epoch 2755/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1931 - acc: 0.2158 - val_loss: 0.6061 - val_acc: 0.2004\n",
      "Epoch 2756/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1869 - acc: 0.2158 - val_loss: 0.6152 - val_acc: 0.2004\n",
      "Epoch 2757/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1825 - acc: 0.2153 - val_loss: 0.6004 - val_acc: 0.2004\n",
      "Epoch 2758/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2070 - acc: 0.2162 - val_loss: 0.5653 - val_acc: 0.2004\n",
      "Epoch 2759/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2039 - acc: 0.2162 - val_loss: 0.6167 - val_acc: 0.2004\n",
      "Epoch 2760/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1827 - acc: 0.2167 - val_loss: 0.6041 - val_acc: 0.2004\n",
      "Epoch 2761/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1894 - acc: 0.2158 - val_loss: 0.6017 - val_acc: 0.2004\n",
      "Epoch 2762/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2028 - acc: 0.2162 - val_loss: 0.5939 - val_acc: 0.2004\n",
      "Epoch 2763/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2006 - acc: 0.2158 - val_loss: 0.6172 - val_acc: 0.1985\n",
      "Epoch 2764/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2044 - acc: 0.2167 - val_loss: 0.5958 - val_acc: 0.2004\n",
      "Epoch 2765/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1918 - acc: 0.2162 - val_loss: 0.6094 - val_acc: 0.2004\n",
      "Epoch 2766/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1947 - acc: 0.2153 - val_loss: 0.6529 - val_acc: 0.1985\n",
      "Epoch 2767/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2010 - acc: 0.2162 - val_loss: 0.6297 - val_acc: 0.2004\n",
      "Epoch 2768/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1916 - acc: 0.2148 - val_loss: 0.6201 - val_acc: 0.1985\n",
      "Epoch 2769/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2028 - acc: 0.2158 - val_loss: 0.6685 - val_acc: 0.2004\n",
      "Epoch 2770/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1890 - acc: 0.2153 - val_loss: 0.5974 - val_acc: 0.1985\n",
      "Epoch 2771/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2022 - acc: 0.2158 - val_loss: 0.7647 - val_acc: 0.2004\n",
      "Epoch 2772/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2600 - acc: 0.2162 - val_loss: 0.7136 - val_acc: 0.2004\n",
      "Epoch 2773/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2247 - acc: 0.2148 - val_loss: 0.6257 - val_acc: 0.1985\n",
      "Epoch 2774/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2053 - acc: 0.2148 - val_loss: 0.6262 - val_acc: 0.1985\n",
      "Epoch 2775/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1927 - acc: 0.2148 - val_loss: 0.6261 - val_acc: 0.2004\n",
      "Epoch 2776/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1838 - acc: 0.2162 - val_loss: 0.6427 - val_acc: 0.2004\n",
      "Epoch 2777/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2291 - acc: 0.2158 - val_loss: 0.6078 - val_acc: 0.2004\n",
      "Epoch 2778/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1938 - acc: 0.2153 - val_loss: 0.6449 - val_acc: 0.1985\n",
      "Epoch 2779/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2021 - acc: 0.2167 - val_loss: 0.6201 - val_acc: 0.2004\n",
      "Epoch 2780/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1885 - acc: 0.2153 - val_loss: 0.6416 - val_acc: 0.2004\n",
      "Epoch 2781/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2142 - acc: 0.2158 - val_loss: 0.6182 - val_acc: 0.2004\n",
      "Epoch 2782/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1918 - acc: 0.2148 - val_loss: 0.5995 - val_acc: 0.2004\n",
      "Epoch 2783/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.4878 - acc: 0.2158 - val_loss: 0.7940 - val_acc: 0.2004\n",
      "Epoch 2784/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.6738 - acc: 0.2125 - val_loss: 0.7541 - val_acc: 0.2004\n",
      "Epoch 2785/4000\n",
      "68/68 [==============================] - 5s 71ms/step - loss: 0.3955 - acc: 0.2153 - val_loss: 0.6441 - val_acc: 0.2004\n",
      "Epoch 2786/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3249 - acc: 0.2158 - val_loss: 0.5971 - val_acc: 0.2004\n",
      "Epoch 2787/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2071 - acc: 0.2162 - val_loss: 0.6146 - val_acc: 0.2004\n",
      "Epoch 2788/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2102 - acc: 0.2167 - val_loss: 0.6679 - val_acc: 0.1985\n",
      "Epoch 2789/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1895 - acc: 0.2167 - val_loss: 0.6245 - val_acc: 0.2004\n",
      "Epoch 2790/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2077 - acc: 0.2167 - val_loss: 0.5697 - val_acc: 0.2004\n",
      "Epoch 2791/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1961 - acc: 0.2162 - val_loss: 0.6443 - val_acc: 0.1985\n",
      "Epoch 2792/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1892 - acc: 0.2158 - val_loss: 0.6057 - val_acc: 0.2004\n",
      "Epoch 2793/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1832 - acc: 0.2158 - val_loss: 0.6226 - val_acc: 0.2004\n",
      "Epoch 2794/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2029 - acc: 0.2153 - val_loss: 0.6048 - val_acc: 0.2004\n",
      "Epoch 2795/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2108 - acc: 0.2158 - val_loss: 0.5829 - val_acc: 0.2004\n",
      "Epoch 2796/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1874 - acc: 0.2153 - val_loss: 0.6349 - val_acc: 0.2004\n",
      "Epoch 2797/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2043 - acc: 0.2144 - val_loss: 0.6164 - val_acc: 0.2004\n",
      "Epoch 2798/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2116 - acc: 0.2144 - val_loss: 0.5968 - val_acc: 0.2004\n",
      "Epoch 2799/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1909 - acc: 0.2158 - val_loss: 0.5849 - val_acc: 0.2004\n",
      "Epoch 2800/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.1936 - acc: 0.2148 - val_loss: 0.6722 - val_acc: 0.1985\n",
      "Epoch 2801/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1850 - acc: 0.2148 - val_loss: 0.6310 - val_acc: 0.1985\n",
      "Epoch 2802/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1896 - acc: 0.2153 - val_loss: 0.6195 - val_acc: 0.2004\n",
      "Epoch 2803/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2058 - acc: 0.2153 - val_loss: 0.6040 - val_acc: 0.2004\n",
      "Epoch 2804/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1978 - acc: 0.2144 - val_loss: 0.5987 - val_acc: 0.2004\n",
      "Epoch 2805/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1888 - acc: 0.2162 - val_loss: 0.5930 - val_acc: 0.2004\n",
      "Epoch 2806/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1829 - acc: 0.2153 - val_loss: 0.6223 - val_acc: 0.2004\n",
      "Epoch 2807/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.1766 - acc: 0.2158 - val_loss: 0.6059 - val_acc: 0.2004\n",
      "Epoch 2808/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1870 - acc: 0.2158 - val_loss: 0.5935 - val_acc: 0.2004\n",
      "Epoch 2809/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2022 - acc: 0.2153 - val_loss: 0.6028 - val_acc: 0.2004\n",
      "Epoch 2810/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1951 - acc: 0.2148 - val_loss: 0.8170 - val_acc: 0.2004\n",
      "Epoch 2811/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1999 - acc: 0.2148 - val_loss: 0.6071 - val_acc: 0.2004\n",
      "Epoch 2812/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1809 - acc: 0.2148 - val_loss: 0.6021 - val_acc: 0.2004\n",
      "Epoch 2813/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2223 - acc: 0.2158 - val_loss: 0.7541 - val_acc: 0.1967\n",
      "Epoch 2814/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2002 - acc: 0.2148 - val_loss: 0.6852 - val_acc: 0.1985\n",
      "Epoch 2815/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2004 - acc: 0.2162 - val_loss: 0.5975 - val_acc: 0.2004\n",
      "Epoch 2816/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2187 - acc: 0.2153 - val_loss: 0.7540 - val_acc: 0.1967\n",
      "Epoch 2817/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2024 - acc: 0.2158 - val_loss: 0.5861 - val_acc: 0.2004\n",
      "Epoch 2818/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1844 - acc: 0.2158 - val_loss: 0.6862 - val_acc: 0.1967\n",
      "Epoch 2819/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1835 - acc: 0.2158 - val_loss: 0.6195 - val_acc: 0.2004\n",
      "Epoch 2820/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1897 - acc: 0.2153 - val_loss: 0.7492 - val_acc: 0.1967\n",
      "Epoch 2821/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2186 - acc: 0.2148 - val_loss: 0.6924 - val_acc: 0.1985\n",
      "Epoch 2822/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2101 - acc: 0.2144 - val_loss: 0.6475 - val_acc: 0.1985\n",
      "Epoch 2823/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1891 - acc: 0.2139 - val_loss: 0.6373 - val_acc: 0.2004\n",
      "Epoch 2824/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1866 - acc: 0.2158 - val_loss: 0.6073 - val_acc: 0.2004\n",
      "Epoch 2825/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1856 - acc: 0.2167 - val_loss: 0.5794 - val_acc: 0.2004\n",
      "Epoch 2826/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.3193 - acc: 0.2037 - val_loss: 0.5943 - val_acc: 0.2004\n",
      "Epoch 2827/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1797 - acc: 0.2158 - val_loss: 0.6707 - val_acc: 0.1967\n",
      "Epoch 2828/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1869 - acc: 0.2158 - val_loss: 0.6634 - val_acc: 0.1985\n",
      "Epoch 2829/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2004 - acc: 0.2153 - val_loss: 0.6007 - val_acc: 0.1985\n",
      "Epoch 2830/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1826 - acc: 0.2158 - val_loss: 0.6186 - val_acc: 0.2004\n",
      "Epoch 2831/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1961 - acc: 0.2144 - val_loss: 0.6239 - val_acc: 0.2004\n",
      "Epoch 2832/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1903 - acc: 0.2158 - val_loss: 0.6142 - val_acc: 0.2004\n",
      "Epoch 2833/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.1795 - acc: 0.2158 - val_loss: 0.6014 - val_acc: 0.2004\n",
      "Epoch 2834/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1903 - acc: 0.2153 - val_loss: 0.5938 - val_acc: 0.2004\n",
      "Epoch 2835/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1975 - acc: 0.2158 - val_loss: 0.6118 - val_acc: 0.2004\n",
      "Epoch 2836/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1893 - acc: 0.2162 - val_loss: 0.5990 - val_acc: 0.2004\n",
      "Epoch 2837/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1797 - acc: 0.2144 - val_loss: 0.6246 - val_acc: 0.2004\n",
      "Epoch 2838/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1954 - acc: 0.2153 - val_loss: 0.6537 - val_acc: 0.1967\n",
      "Epoch 2839/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1891 - acc: 0.2158 - val_loss: 0.6287 - val_acc: 0.1985\n",
      "Epoch 2840/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.1810 - acc: 0.2153 - val_loss: 0.6668 - val_acc: 0.2004\n",
      "Epoch 2841/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2226 - acc: 0.2158 - val_loss: 0.6573 - val_acc: 0.2004\n",
      "Epoch 2842/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1967 - acc: 0.2162 - val_loss: 0.6085 - val_acc: 0.2004\n",
      "Epoch 2843/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1792 - acc: 0.2153 - val_loss: 0.6112 - val_acc: 0.1985\n",
      "Epoch 2844/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1832 - acc: 0.2167 - val_loss: 0.5907 - val_acc: 0.2004\n",
      "Epoch 2845/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2105 - acc: 0.2153 - val_loss: 0.6009 - val_acc: 0.2004\n",
      "Epoch 2846/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1874 - acc: 0.2162 - val_loss: 0.6035 - val_acc: 0.2004\n",
      "Epoch 2847/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2050 - acc: 0.2153 - val_loss: 0.7042 - val_acc: 0.1967\n",
      "Epoch 2848/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.2190 - acc: 0.2167 - val_loss: 0.5942 - val_acc: 0.2004\n",
      "Epoch 2849/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1875 - acc: 0.2158 - val_loss: 0.6081 - val_acc: 0.2004\n",
      "Epoch 2850/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1928 - acc: 0.2148 - val_loss: 0.6894 - val_acc: 0.2004\n",
      "Epoch 2851/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1975 - acc: 0.2148 - val_loss: 0.6145 - val_acc: 0.2004\n",
      "Epoch 2852/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1996 - acc: 0.2153 - val_loss: 0.5947 - val_acc: 0.2004\n",
      "Epoch 2853/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2003 - acc: 0.2153 - val_loss: 0.7037 - val_acc: 0.1967\n",
      "Epoch 2854/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2056 - acc: 0.2148 - val_loss: 0.6372 - val_acc: 0.2004\n",
      "Epoch 2855/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.1963 - acc: 0.2158 - val_loss: 0.5881 - val_acc: 0.2004\n",
      "Epoch 2856/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1927 - acc: 0.2158 - val_loss: 0.5924 - val_acc: 0.2004\n",
      "Epoch 2857/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1994 - acc: 0.2153 - val_loss: 0.6463 - val_acc: 0.1985\n",
      "Epoch 2858/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1992 - acc: 0.2153 - val_loss: 0.7114 - val_acc: 0.1967\n",
      "Epoch 2859/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2112 - acc: 0.2162 - val_loss: 0.6710 - val_acc: 0.2004\n",
      "Epoch 2860/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2047 - acc: 0.2167 - val_loss: 0.6305 - val_acc: 0.2004\n",
      "Epoch 2861/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2096 - acc: 0.2158 - val_loss: 0.6123 - val_acc: 0.2004\n",
      "Epoch 2862/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1848 - acc: 0.2153 - val_loss: 0.5846 - val_acc: 0.2004\n",
      "Epoch 2863/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1898 - acc: 0.2153 - val_loss: 0.7334 - val_acc: 0.2004\n",
      "Epoch 2864/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1829 - acc: 0.2162 - val_loss: 0.5994 - val_acc: 0.2004\n",
      "Epoch 2865/4000\n",
      "68/68 [==============================] - 5s 71ms/step - loss: 0.2295 - acc: 0.2144 - val_loss: 0.7067 - val_acc: 0.2004\n",
      "Epoch 2866/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2001 - acc: 0.2162 - val_loss: 0.6009 - val_acc: 0.2004\n",
      "Epoch 2867/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2140 - acc: 0.2158 - val_loss: 0.6334 - val_acc: 0.2004\n",
      "Epoch 2868/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2327 - acc: 0.2153 - val_loss: 0.5734 - val_acc: 0.2004\n",
      "Epoch 2869/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2926 - acc: 0.2162 - val_loss: 0.7642 - val_acc: 0.1985\n",
      "Epoch 2870/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2633 - acc: 0.2153 - val_loss: 0.5739 - val_acc: 0.1985\n",
      "Epoch 2871/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2581 - acc: 0.2148 - val_loss: 0.5823 - val_acc: 0.2004\n",
      "Epoch 2872/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2748 - acc: 0.2144 - val_loss: 0.5561 - val_acc: 0.2004\n",
      "Epoch 2873/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3659 - acc: 0.2158 - val_loss: 0.7920 - val_acc: 0.2004\n",
      "Epoch 2874/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3008 - acc: 0.2153 - val_loss: 0.6632 - val_acc: 0.2004\n",
      "Epoch 2875/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.4490 - acc: 0.2148 - val_loss: 0.5580 - val_acc: 0.2004\n",
      "Epoch 2876/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2274 - acc: 0.2158 - val_loss: 0.7390 - val_acc: 0.2004\n",
      "Epoch 2877/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2413 - acc: 0.2139 - val_loss: 0.5807 - val_acc: 0.2004\n",
      "Epoch 2878/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2088 - acc: 0.2162 - val_loss: 0.5759 - val_acc: 0.1985\n",
      "Epoch 2879/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2178 - acc: 0.2162 - val_loss: 0.5898 - val_acc: 0.2004\n",
      "Epoch 2880/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2326 - acc: 0.2162 - val_loss: 0.7750 - val_acc: 0.2004\n",
      "Epoch 2881/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2045 - acc: 0.2162 - val_loss: 0.5823 - val_acc: 0.2004\n",
      "Epoch 2882/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1980 - acc: 0.2153 - val_loss: 0.6142 - val_acc: 0.2004\n",
      "Epoch 2883/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2074 - acc: 0.2148 - val_loss: 0.6669 - val_acc: 0.1985\n",
      "Epoch 2884/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1897 - acc: 0.2158 - val_loss: 0.5584 - val_acc: 0.2004\n",
      "Epoch 2885/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1943 - acc: 0.2153 - val_loss: 0.7209 - val_acc: 0.2004\n",
      "Epoch 2886/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1852 - acc: 0.2158 - val_loss: 0.7161 - val_acc: 0.1967\n",
      "Epoch 2887/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1981 - acc: 0.2158 - val_loss: 0.5876 - val_acc: 0.2004\n",
      "Epoch 2888/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1787 - acc: 0.2167 - val_loss: 0.5869 - val_acc: 0.2004\n",
      "Epoch 2889/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1895 - acc: 0.2167 - val_loss: 0.6610 - val_acc: 0.2004\n",
      "Epoch 2890/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2034 - acc: 0.2158 - val_loss: 0.5736 - val_acc: 0.2004\n",
      "Epoch 2891/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2011 - acc: 0.2158 - val_loss: 0.6240 - val_acc: 0.2004\n",
      "Epoch 2892/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2222 - acc: 0.2162 - val_loss: 0.6077 - val_acc: 0.2004\n",
      "Epoch 2893/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1962 - acc: 0.2148 - val_loss: 0.5688 - val_acc: 0.2004\n",
      "Epoch 2894/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1827 - acc: 0.2148 - val_loss: 0.6652 - val_acc: 0.2004\n",
      "Epoch 2895/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1936 - acc: 0.2148 - val_loss: 0.6035 - val_acc: 0.2004\n",
      "Epoch 2896/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1967 - acc: 0.2153 - val_loss: 0.5787 - val_acc: 0.2004\n",
      "Epoch 2897/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1781 - acc: 0.2167 - val_loss: 0.5936 - val_acc: 0.1985\n",
      "Epoch 2898/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1836 - acc: 0.2153 - val_loss: 0.6207 - val_acc: 0.1985\n",
      "Epoch 2899/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1931 - acc: 0.2162 - val_loss: 0.6323 - val_acc: 0.2004\n",
      "Epoch 2900/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2120 - acc: 0.2162 - val_loss: 0.5860 - val_acc: 0.2004\n",
      "Epoch 2901/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2048 - acc: 0.2153 - val_loss: 0.5910 - val_acc: 0.2004\n",
      "Epoch 2902/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2463 - acc: 0.2153 - val_loss: 0.5859 - val_acc: 0.1985\n",
      "Epoch 2903/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1969 - acc: 0.2148 - val_loss: 0.5760 - val_acc: 0.2004\n",
      "Epoch 2904/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1817 - acc: 0.2153 - val_loss: 0.5964 - val_acc: 0.2004\n",
      "Epoch 2905/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1802 - acc: 0.2172 - val_loss: 0.5819 - val_acc: 0.2004\n",
      "Epoch 2906/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1845 - acc: 0.2162 - val_loss: 0.6592 - val_acc: 0.2004\n",
      "Epoch 2907/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2023 - acc: 0.2144 - val_loss: 0.6050 - val_acc: 0.2004\n",
      "Epoch 2908/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2106 - acc: 0.2144 - val_loss: 0.6662 - val_acc: 0.2004\n",
      "Epoch 2909/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1933 - acc: 0.2153 - val_loss: 0.6043 - val_acc: 0.1985\n",
      "Epoch 2910/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1893 - acc: 0.2162 - val_loss: 0.5851 - val_acc: 0.2004\n",
      "Epoch 2911/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1787 - acc: 0.2144 - val_loss: 0.6502 - val_acc: 0.2004\n",
      "Epoch 2912/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1952 - acc: 0.2153 - val_loss: 0.7064 - val_acc: 0.2004\n",
      "Epoch 2913/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2037 - acc: 0.2153 - val_loss: 0.8040 - val_acc: 0.1929\n",
      "Epoch 2914/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2084 - acc: 0.2153 - val_loss: 0.6139 - val_acc: 0.2004\n",
      "Epoch 2915/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1956 - acc: 0.2144 - val_loss: 0.6029 - val_acc: 0.2004\n",
      "Epoch 2916/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1794 - acc: 0.2162 - val_loss: 0.5678 - val_acc: 0.2004\n",
      "Epoch 2917/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1978 - acc: 0.2153 - val_loss: 0.5933 - val_acc: 0.2004\n",
      "Epoch 2918/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1796 - acc: 0.2158 - val_loss: 0.5708 - val_acc: 0.2004\n",
      "Epoch 2919/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2028 - acc: 0.2148 - val_loss: 0.8954 - val_acc: 0.2004\n",
      "Epoch 2920/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2039 - acc: 0.2158 - val_loss: 0.6364 - val_acc: 0.1985\n",
      "Epoch 2921/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1859 - acc: 0.2148 - val_loss: 0.6014 - val_acc: 0.2004\n",
      "Epoch 2922/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1882 - acc: 0.2162 - val_loss: 0.5738 - val_acc: 0.2004\n",
      "Epoch 2923/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1858 - acc: 0.2158 - val_loss: 0.5965 - val_acc: 0.2004\n",
      "Epoch 2924/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2174 - acc: 0.2158 - val_loss: 0.5981 - val_acc: 0.2004\n",
      "Epoch 2925/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1983 - acc: 0.2153 - val_loss: 0.6171 - val_acc: 0.2004\n",
      "Epoch 2926/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2195 - acc: 0.2167 - val_loss: 0.6477 - val_acc: 0.2004\n",
      "Epoch 2927/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1895 - acc: 0.2167 - val_loss: 0.6103 - val_acc: 0.2004\n",
      "Epoch 2928/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1831 - acc: 0.2153 - val_loss: 0.6038 - val_acc: 0.1985\n",
      "Epoch 2929/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2297 - acc: 0.2144 - val_loss: 0.5946 - val_acc: 0.1985\n",
      "Epoch 2930/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1928 - acc: 0.2158 - val_loss: 0.5577 - val_acc: 0.2004\n",
      "Epoch 2931/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1928 - acc: 0.2153 - val_loss: 0.6229 - val_acc: 0.2004\n",
      "Epoch 2932/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1796 - acc: 0.2153 - val_loss: 0.5870 - val_acc: 0.2004\n",
      "Epoch 2933/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1839 - acc: 0.2162 - val_loss: 0.7620 - val_acc: 0.2004\n",
      "Epoch 2934/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1987 - acc: 0.2153 - val_loss: 0.5724 - val_acc: 0.2004\n",
      "Epoch 2935/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2257 - acc: 0.2148 - val_loss: 0.6010 - val_acc: 0.2004\n",
      "Epoch 2936/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1995 - acc: 0.2148 - val_loss: 0.6026 - val_acc: 0.2004\n",
      "Epoch 2937/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1891 - acc: 0.2148 - val_loss: 0.5893 - val_acc: 0.2004\n",
      "Epoch 2938/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1815 - acc: 0.2158 - val_loss: 0.6154 - val_acc: 0.1985\n",
      "Epoch 2939/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1850 - acc: 0.2158 - val_loss: 0.6811 - val_acc: 0.1967\n",
      "Epoch 2940/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2497 - acc: 0.2144 - val_loss: 0.6251 - val_acc: 0.2004\n",
      "Epoch 2941/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2203 - acc: 0.2144 - val_loss: 0.6936 - val_acc: 0.2004\n",
      "Epoch 2942/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2014 - acc: 0.2162 - val_loss: 0.6908 - val_acc: 0.2004\n",
      "Epoch 2943/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2185 - acc: 0.2153 - val_loss: 0.5783 - val_acc: 0.2004\n",
      "Epoch 2944/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2067 - acc: 0.2167 - val_loss: 0.6076 - val_acc: 0.2004\n",
      "Epoch 2945/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1896 - acc: 0.2158 - val_loss: 0.5955 - val_acc: 0.2004\n",
      "Epoch 2946/4000\n",
      "68/68 [==============================] - 5s 73ms/step - loss: 0.1819 - acc: 0.2144 - val_loss: 0.6032 - val_acc: 0.2004\n",
      "Epoch 2947/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1827 - acc: 0.2158 - val_loss: 0.6067 - val_acc: 0.2004\n",
      "Epoch 2948/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1964 - acc: 0.2153 - val_loss: 0.5688 - val_acc: 0.2004\n",
      "Epoch 2949/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1961 - acc: 0.2153 - val_loss: 0.6237 - val_acc: 0.1985\n",
      "Epoch 2950/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1938 - acc: 0.2162 - val_loss: 0.5950 - val_acc: 0.2004\n",
      "Epoch 2951/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1861 - acc: 0.2172 - val_loss: 0.5931 - val_acc: 0.2004\n",
      "Epoch 2952/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2237 - acc: 0.2130 - val_loss: 0.6371 - val_acc: 0.2004\n",
      "Epoch 2953/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1819 - acc: 0.2153 - val_loss: 0.6022 - val_acc: 0.2004\n",
      "Epoch 2954/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2099 - acc: 0.2148 - val_loss: 0.6227 - val_acc: 0.2004\n",
      "Epoch 2955/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1892 - acc: 0.2153 - val_loss: 0.6195 - val_acc: 0.2004\n",
      "Epoch 2956/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1928 - acc: 0.2153 - val_loss: 0.6185 - val_acc: 0.2004\n",
      "Epoch 2957/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1788 - acc: 0.2148 - val_loss: 0.6158 - val_acc: 0.2004\n",
      "Epoch 2958/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1889 - acc: 0.2148 - val_loss: 0.6201 - val_acc: 0.2004\n",
      "Epoch 2959/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1866 - acc: 0.2158 - val_loss: 0.5834 - val_acc: 0.2004\n",
      "Epoch 2960/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2338 - acc: 0.2162 - val_loss: 0.7116 - val_acc: 0.2004\n",
      "Epoch 2961/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.1971 - acc: 0.2144 - val_loss: 0.5789 - val_acc: 0.2004\n",
      "Epoch 2962/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2316 - acc: 0.2139 - val_loss: 0.7303 - val_acc: 0.1967\n",
      "Epoch 2963/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2121 - acc: 0.2153 - val_loss: 0.6358 - val_acc: 0.2004\n",
      "Epoch 2964/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1854 - acc: 0.2153 - val_loss: 0.5778 - val_acc: 0.2004\n",
      "Epoch 2965/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1770 - acc: 0.2162 - val_loss: 0.5594 - val_acc: 0.2004\n",
      "Epoch 2966/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1956 - acc: 0.2162 - val_loss: 0.7198 - val_acc: 0.2004\n",
      "Epoch 2967/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2234 - acc: 0.2144 - val_loss: 0.7713 - val_acc: 0.1967\n",
      "Epoch 2968/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2050 - acc: 0.2153 - val_loss: 0.6372 - val_acc: 0.1967\n",
      "Epoch 2969/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2119 - acc: 0.2148 - val_loss: 0.6194 - val_acc: 0.2004\n",
      "Epoch 2970/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1890 - acc: 0.2158 - val_loss: 0.5963 - val_acc: 0.2004\n",
      "Epoch 2971/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1808 - acc: 0.2153 - val_loss: 0.6375 - val_acc: 0.2004\n",
      "Epoch 2972/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1958 - acc: 0.2153 - val_loss: 0.6488 - val_acc: 0.2004\n",
      "Epoch 2973/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1894 - acc: 0.2158 - val_loss: 0.6128 - val_acc: 0.2004\n",
      "Epoch 2974/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1937 - acc: 0.2153 - val_loss: 0.6522 - val_acc: 0.1985\n",
      "Epoch 2975/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1913 - acc: 0.2158 - val_loss: 0.6051 - val_acc: 0.2004\n",
      "Epoch 2976/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1846 - acc: 0.2158 - val_loss: 0.5834 - val_acc: 0.2004\n",
      "Epoch 2977/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2067 - acc: 0.2153 - val_loss: 0.6426 - val_acc: 0.2004\n",
      "Epoch 2978/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1983 - acc: 0.2153 - val_loss: 0.7276 - val_acc: 0.2004\n",
      "Epoch 2979/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2097 - acc: 0.2153 - val_loss: 0.8072 - val_acc: 0.1948\n",
      "Epoch 2980/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2000 - acc: 0.2158 - val_loss: 0.5959 - val_acc: 0.2004\n",
      "Epoch 2981/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1823 - acc: 0.2172 - val_loss: 0.6100 - val_acc: 0.2004\n",
      "Epoch 2982/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1752 - acc: 0.2144 - val_loss: 0.6224 - val_acc: 0.2004\n",
      "Epoch 2983/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1843 - acc: 0.2162 - val_loss: 0.5946 - val_acc: 0.2004\n",
      "Epoch 2984/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2211 - acc: 0.2153 - val_loss: 0.5960 - val_acc: 0.2004\n",
      "Epoch 2985/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1823 - acc: 0.2158 - val_loss: 0.6592 - val_acc: 0.1967\n",
      "Epoch 2986/4000\n",
      "68/68 [==============================] - 5s 70ms/step - loss: 0.1893 - acc: 0.2148 - val_loss: 0.5907 - val_acc: 0.2004\n",
      "Epoch 2987/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1915 - acc: 0.2153 - val_loss: 0.5857 - val_acc: 0.2004\n",
      "Epoch 2988/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1897 - acc: 0.2148 - val_loss: 0.6665 - val_acc: 0.2004\n",
      "Epoch 2989/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1873 - acc: 0.2153 - val_loss: 0.5964 - val_acc: 0.1985\n",
      "Epoch 2990/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1780 - acc: 0.2158 - val_loss: 0.6249 - val_acc: 0.1967\n",
      "Epoch 2991/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1857 - acc: 0.2158 - val_loss: 0.6066 - val_acc: 0.2004\n",
      "Epoch 2992/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1948 - acc: 0.2144 - val_loss: 0.5957 - val_acc: 0.2004\n",
      "Epoch 2993/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2450 - acc: 0.2148 - val_loss: 0.8203 - val_acc: 0.2004\n",
      "Epoch 2994/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2054 - acc: 0.2139 - val_loss: 0.5978 - val_acc: 0.2004\n",
      "Epoch 2995/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2050 - acc: 0.2162 - val_loss: 0.6143 - val_acc: 0.1967\n",
      "Epoch 2996/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1930 - acc: 0.2153 - val_loss: 0.6087 - val_acc: 0.2004\n",
      "Epoch 2997/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2080 - acc: 0.2148 - val_loss: 0.7139 - val_acc: 0.2004\n",
      "Epoch 2998/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1910 - acc: 0.2148 - val_loss: 0.6326 - val_acc: 0.2004\n",
      "Epoch 2999/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1999 - acc: 0.2148 - val_loss: 0.7087 - val_acc: 0.2004\n",
      "Epoch 3000/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2022 - acc: 0.2153 - val_loss: 0.5984 - val_acc: 0.2004\n",
      "Epoch 3001/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1919 - acc: 0.2144 - val_loss: 0.5875 - val_acc: 0.2004\n",
      "Epoch 3002/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1838 - acc: 0.2148 - val_loss: 0.6395 - val_acc: 0.2004\n",
      "Epoch 3003/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1839 - acc: 0.2158 - val_loss: 0.5936 - val_acc: 0.2004\n",
      "Epoch 3004/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1979 - acc: 0.2148 - val_loss: 0.6120 - val_acc: 0.2004\n",
      "Epoch 3005/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1987 - acc: 0.2153 - val_loss: 0.6377 - val_acc: 0.2004\n",
      "Epoch 3006/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1980 - acc: 0.2148 - val_loss: 0.6578 - val_acc: 0.2004\n",
      "Epoch 3007/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1831 - acc: 0.2144 - val_loss: 0.6121 - val_acc: 0.2004\n",
      "Epoch 3008/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2171 - acc: 0.2135 - val_loss: 0.7383 - val_acc: 0.1967\n",
      "Epoch 3009/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.7589 - acc: 0.2000 - val_loss: 1.1211 - val_acc: 0.2004\n",
      "Epoch 3010/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.7090 - acc: 0.2121 - val_loss: 1.0776 - val_acc: 0.2004\n",
      "Epoch 3011/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.5693 - acc: 0.2148 - val_loss: 0.6257 - val_acc: 0.2004\n",
      "Epoch 3012/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3834 - acc: 0.2162 - val_loss: 0.6698 - val_acc: 0.2004\n",
      "Epoch 3013/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2475 - acc: 0.2144 - val_loss: 0.6049 - val_acc: 0.2004\n",
      "Epoch 3014/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1869 - acc: 0.2158 - val_loss: 0.5897 - val_acc: 0.2004\n",
      "Epoch 3015/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1739 - acc: 0.2148 - val_loss: 0.6173 - val_acc: 0.2004\n",
      "Epoch 3016/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2107 - acc: 0.2162 - val_loss: 0.6296 - val_acc: 0.1985\n",
      "Epoch 3017/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1842 - acc: 0.2158 - val_loss: 0.6082 - val_acc: 0.2004\n",
      "Epoch 3018/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1755 - acc: 0.2153 - val_loss: 0.6470 - val_acc: 0.2004\n",
      "Epoch 3019/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1836 - acc: 0.2158 - val_loss: 0.5850 - val_acc: 0.2004\n",
      "Epoch 3020/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1858 - acc: 0.2144 - val_loss: 0.5954 - val_acc: 0.2004\n",
      "Epoch 3021/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1789 - acc: 0.2162 - val_loss: 0.5944 - val_acc: 0.1985\n",
      "Epoch 3022/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1861 - acc: 0.2158 - val_loss: 0.5791 - val_acc: 0.2004\n",
      "Epoch 3023/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1947 - acc: 0.2158 - val_loss: 0.5832 - val_acc: 0.2004\n",
      "Epoch 3024/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1732 - acc: 0.2158 - val_loss: 0.5837 - val_acc: 0.2004\n",
      "Epoch 3025/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2102 - acc: 0.2158 - val_loss: 0.6695 - val_acc: 0.2004\n",
      "Epoch 3026/4000\n",
      "68/68 [==============================] - 5s 70ms/step - loss: 0.2468 - acc: 0.2148 - val_loss: 0.5979 - val_acc: 0.2004\n",
      "Epoch 3027/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1955 - acc: 0.2172 - val_loss: 0.6546 - val_acc: 0.2004\n",
      "Epoch 3028/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2120 - acc: 0.2158 - val_loss: 0.5927 - val_acc: 0.2004\n",
      "Epoch 3029/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1917 - acc: 0.2158 - val_loss: 0.6017 - val_acc: 0.2004\n",
      "Epoch 3030/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1740 - acc: 0.2162 - val_loss: 0.5845 - val_acc: 0.2004\n",
      "Epoch 3031/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1732 - acc: 0.2153 - val_loss: 0.6058 - val_acc: 0.2004\n",
      "Epoch 3032/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1848 - acc: 0.2153 - val_loss: 0.5756 - val_acc: 0.2004\n",
      "Epoch 3033/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1982 - acc: 0.2153 - val_loss: 0.5996 - val_acc: 0.2004\n",
      "Epoch 3034/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1928 - acc: 0.2162 - val_loss: 0.5890 - val_acc: 0.2004\n",
      "Epoch 3035/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1776 - acc: 0.2162 - val_loss: 0.5904 - val_acc: 0.2004\n",
      "Epoch 3036/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1866 - acc: 0.2158 - val_loss: 0.6534 - val_acc: 0.2004\n",
      "Epoch 3037/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1857 - acc: 0.2158 - val_loss: 0.6195 - val_acc: 0.1985\n",
      "Epoch 3038/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1985 - acc: 0.2153 - val_loss: 0.6001 - val_acc: 0.2004\n",
      "Epoch 3039/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1916 - acc: 0.2167 - val_loss: 0.6858 - val_acc: 0.1967\n",
      "Epoch 3040/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1731 - acc: 0.2153 - val_loss: 0.6287 - val_acc: 0.1985\n",
      "Epoch 3041/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1849 - acc: 0.2167 - val_loss: 0.6562 - val_acc: 0.1985\n",
      "Epoch 3042/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1802 - acc: 0.2158 - val_loss: 0.5848 - val_acc: 0.2004\n",
      "Epoch 3043/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1791 - acc: 0.2162 - val_loss: 0.6399 - val_acc: 0.2004\n",
      "Epoch 3044/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1887 - acc: 0.2158 - val_loss: 0.6196 - val_acc: 0.1985\n",
      "Epoch 3045/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1789 - acc: 0.2158 - val_loss: 0.5785 - val_acc: 0.2004\n",
      "Epoch 3046/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1724 - acc: 0.2153 - val_loss: 0.5871 - val_acc: 0.2004\n",
      "Epoch 3047/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1833 - acc: 0.2158 - val_loss: 0.7488 - val_acc: 0.2004\n",
      "Epoch 3048/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2208 - acc: 0.2153 - val_loss: 0.6354 - val_acc: 0.1985\n",
      "Epoch 3049/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1827 - acc: 0.2158 - val_loss: 0.5955 - val_acc: 0.2004\n",
      "Epoch 3050/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1941 - acc: 0.2158 - val_loss: 0.6375 - val_acc: 0.2004\n",
      "Epoch 3051/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1896 - acc: 0.2158 - val_loss: 0.6521 - val_acc: 0.2004\n",
      "Epoch 3052/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1958 - acc: 0.2158 - val_loss: 0.7115 - val_acc: 0.2004\n",
      "Epoch 3053/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2210 - acc: 0.2162 - val_loss: 0.6103 - val_acc: 0.1985\n",
      "Epoch 3054/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2355 - acc: 0.2139 - val_loss: 0.5999 - val_acc: 0.2004\n",
      "Epoch 3055/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1805 - acc: 0.2153 - val_loss: 0.6225 - val_acc: 0.2004\n",
      "Epoch 3056/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1895 - acc: 0.2167 - val_loss: 0.5972 - val_acc: 0.2004\n",
      "Epoch 3057/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1875 - acc: 0.2158 - val_loss: 0.5995 - val_acc: 0.2004\n",
      "Epoch 3058/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1705 - acc: 0.2153 - val_loss: 0.6424 - val_acc: 0.1985\n",
      "Epoch 3059/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2073 - acc: 0.2144 - val_loss: 0.6131 - val_acc: 0.2004\n",
      "Epoch 3060/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1874 - acc: 0.2153 - val_loss: 0.5844 - val_acc: 0.2004\n",
      "Epoch 3061/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1917 - acc: 0.2158 - val_loss: 0.6142 - val_acc: 0.2004\n",
      "Epoch 3062/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1922 - acc: 0.2139 - val_loss: 0.6075 - val_acc: 0.2004\n",
      "Epoch 3063/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1867 - acc: 0.2162 - val_loss: 0.6172 - val_acc: 0.2004\n",
      "Epoch 3064/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1894 - acc: 0.2167 - val_loss: 0.6560 - val_acc: 0.1985\n",
      "Epoch 3065/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1729 - acc: 0.2162 - val_loss: 0.5808 - val_acc: 0.2004\n",
      "Epoch 3066/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1988 - acc: 0.2148 - val_loss: 0.6073 - val_acc: 0.2004\n",
      "Epoch 3067/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1889 - acc: 0.2162 - val_loss: 0.6229 - val_acc: 0.2004\n",
      "Epoch 3068/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1814 - acc: 0.2158 - val_loss: 0.5899 - val_acc: 0.2004\n",
      "Epoch 3069/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1928 - acc: 0.2162 - val_loss: 0.6954 - val_acc: 0.1967\n",
      "Epoch 3070/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1850 - acc: 0.2153 - val_loss: 0.6222 - val_acc: 0.2004\n",
      "Epoch 3071/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1932 - acc: 0.2158 - val_loss: 0.6382 - val_acc: 0.2004\n",
      "Epoch 3072/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2252 - acc: 0.2153 - val_loss: 0.8182 - val_acc: 0.2004\n",
      "Epoch 3073/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2151 - acc: 0.2148 - val_loss: 0.6380 - val_acc: 0.2004\n",
      "Epoch 3074/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1923 - acc: 0.2158 - val_loss: 0.6139 - val_acc: 0.2004\n",
      "Epoch 3075/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1882 - acc: 0.2158 - val_loss: 0.6246 - val_acc: 0.2004\n",
      "Epoch 3076/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1844 - acc: 0.2167 - val_loss: 0.5990 - val_acc: 0.2004\n",
      "Epoch 3077/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1960 - acc: 0.2148 - val_loss: 0.6207 - val_acc: 0.1967\n",
      "Epoch 3078/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1996 - acc: 0.2153 - val_loss: 0.6164 - val_acc: 0.2004\n",
      "Epoch 3079/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1806 - acc: 0.2148 - val_loss: 0.5830 - val_acc: 0.2004\n",
      "Epoch 3080/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1875 - acc: 0.2148 - val_loss: 0.6537 - val_acc: 0.1985\n",
      "Epoch 3081/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1983 - acc: 0.2153 - val_loss: 0.7216 - val_acc: 0.2004\n",
      "Epoch 3082/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1809 - acc: 0.2153 - val_loss: 0.5760 - val_acc: 0.2004\n",
      "Epoch 3083/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1690 - acc: 0.2148 - val_loss: 0.5942 - val_acc: 0.2004\n",
      "Epoch 3084/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1874 - acc: 0.2148 - val_loss: 0.8994 - val_acc: 0.2004\n",
      "Epoch 3085/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2192 - acc: 0.2139 - val_loss: 0.6015 - val_acc: 0.2004\n",
      "Epoch 3086/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1817 - acc: 0.2153 - val_loss: 0.6504 - val_acc: 0.2004\n",
      "Epoch 3087/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1795 - acc: 0.2153 - val_loss: 0.7890 - val_acc: 0.2004\n",
      "Epoch 3088/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2148 - acc: 0.2153 - val_loss: 0.6078 - val_acc: 0.2004\n",
      "Epoch 3089/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1855 - acc: 0.2148 - val_loss: 0.6232 - val_acc: 0.2004\n",
      "Epoch 3090/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1990 - acc: 0.2144 - val_loss: 0.6298 - val_acc: 0.2004\n",
      "Epoch 3091/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2307 - acc: 0.2158 - val_loss: 0.6079 - val_acc: 0.2004\n",
      "Epoch 3092/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1984 - acc: 0.2158 - val_loss: 0.6113 - val_acc: 0.2004\n",
      "Epoch 3093/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1912 - acc: 0.2153 - val_loss: 0.5880 - val_acc: 0.2004\n",
      "Epoch 3094/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1860 - acc: 0.2153 - val_loss: 0.5958 - val_acc: 0.2004\n",
      "Epoch 3095/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1777 - acc: 0.2162 - val_loss: 0.6140 - val_acc: 0.2004\n",
      "Epoch 3096/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1996 - acc: 0.2158 - val_loss: 0.6181 - val_acc: 0.2004\n",
      "Epoch 3097/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2396 - acc: 0.2158 - val_loss: 0.8411 - val_acc: 0.1929\n",
      "Epoch 3098/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2103 - acc: 0.2162 - val_loss: 0.6474 - val_acc: 0.2004\n",
      "Epoch 3099/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2126 - acc: 0.2148 - val_loss: 0.6735 - val_acc: 0.2004\n",
      "Epoch 3100/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1943 - acc: 0.2139 - val_loss: 0.6059 - val_acc: 0.2004\n",
      "Epoch 3101/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1853 - acc: 0.2144 - val_loss: 0.6321 - val_acc: 0.2004\n",
      "Epoch 3102/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1919 - acc: 0.2167 - val_loss: 0.6570 - val_acc: 0.1967\n",
      "Epoch 3103/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1868 - acc: 0.2158 - val_loss: 0.6528 - val_acc: 0.1985\n",
      "Epoch 3104/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1974 - acc: 0.2162 - val_loss: 0.6485 - val_acc: 0.2004\n",
      "Epoch 3105/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1781 - acc: 0.2153 - val_loss: 0.5929 - val_acc: 0.2004\n",
      "Epoch 3106/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.1956 - acc: 0.2153 - val_loss: 0.6071 - val_acc: 0.2004\n",
      "Epoch 3107/4000\n",
      "68/68 [==============================] - 5s 69ms/step - loss: 0.1817 - acc: 0.2158 - val_loss: 0.6454 - val_acc: 0.2004\n",
      "Epoch 3108/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1888 - acc: 0.2162 - val_loss: 0.6195 - val_acc: 0.2004\n",
      "Epoch 3109/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1872 - acc: 0.2153 - val_loss: 0.6277 - val_acc: 0.2004\n",
      "Epoch 3110/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1935 - acc: 0.2153 - val_loss: 0.6300 - val_acc: 0.2004\n",
      "Epoch 3111/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1706 - acc: 0.2162 - val_loss: 0.6477 - val_acc: 0.2004\n",
      "Epoch 3112/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1967 - acc: 0.2167 - val_loss: 0.7217 - val_acc: 0.1967\n",
      "Epoch 3113/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2149 - acc: 0.2158 - val_loss: 0.7309 - val_acc: 0.1967\n",
      "Epoch 3114/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2434 - acc: 0.2153 - val_loss: 0.6187 - val_acc: 0.2004\n",
      "Epoch 3115/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1744 - acc: 0.2153 - val_loss: 0.5791 - val_acc: 0.2004\n",
      "Epoch 3116/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1871 - acc: 0.2158 - val_loss: 0.6098 - val_acc: 0.2004\n",
      "Epoch 3117/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2197 - acc: 0.2144 - val_loss: 0.7356 - val_acc: 0.1967\n",
      "Epoch 3118/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1776 - acc: 0.2162 - val_loss: 0.5858 - val_acc: 0.2004\n",
      "Epoch 3119/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1844 - acc: 0.2153 - val_loss: 0.6000 - val_acc: 0.2004\n",
      "Epoch 3120/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1739 - acc: 0.2148 - val_loss: 0.6314 - val_acc: 0.2004\n",
      "Epoch 3121/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1932 - acc: 0.2162 - val_loss: 0.6211 - val_acc: 0.2004\n",
      "Epoch 3122/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1811 - acc: 0.2153 - val_loss: 0.6096 - val_acc: 0.2004\n",
      "Epoch 3123/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1886 - acc: 0.2158 - val_loss: 0.6147 - val_acc: 0.2004\n",
      "Epoch 3124/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2025 - acc: 0.2153 - val_loss: 0.6654 - val_acc: 0.1967\n",
      "Epoch 3125/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2121 - acc: 0.2144 - val_loss: 0.5967 - val_acc: 0.2004\n",
      "Epoch 3126/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2533 - acc: 0.2135 - val_loss: 0.7154 - val_acc: 0.2004\n",
      "Epoch 3127/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1949 - acc: 0.2153 - val_loss: 0.5674 - val_acc: 0.2004\n",
      "Epoch 3128/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2482 - acc: 0.2153 - val_loss: 0.6663 - val_acc: 0.2004\n",
      "Epoch 3129/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1844 - acc: 0.2148 - val_loss: 0.6555 - val_acc: 0.2004\n",
      "Epoch 3130/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2351 - acc: 0.2158 - val_loss: 0.8233 - val_acc: 0.2004\n",
      "Epoch 3131/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4344 - acc: 0.2153 - val_loss: 0.5490 - val_acc: 0.2004\n",
      "Epoch 3132/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3510 - acc: 0.2144 - val_loss: 0.7235 - val_acc: 0.2004\n",
      "Epoch 3133/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3578 - acc: 0.2153 - val_loss: 0.6489 - val_acc: 0.1985\n",
      "Epoch 3134/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.5041 - acc: 0.2139 - val_loss: 0.9644 - val_acc: 0.2004\n",
      "Epoch 3135/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3573 - acc: 0.2144 - val_loss: 0.7860 - val_acc: 0.2004\n",
      "Epoch 3136/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3723 - acc: 0.2144 - val_loss: 0.5753 - val_acc: 0.2004\n",
      "Epoch 3137/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2102 - acc: 0.2148 - val_loss: 0.5895 - val_acc: 0.2004\n",
      "Epoch 3138/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3781 - acc: 0.2158 - val_loss: 0.7318 - val_acc: 0.1985\n",
      "Epoch 3139/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2093 - acc: 0.2139 - val_loss: 0.6347 - val_acc: 0.1985\n",
      "Epoch 3140/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1785 - acc: 0.2153 - val_loss: 0.5854 - val_acc: 0.2004\n",
      "Epoch 3141/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1767 - acc: 0.2153 - val_loss: 0.5951 - val_acc: 0.2004\n",
      "Epoch 3142/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1801 - acc: 0.2162 - val_loss: 0.5869 - val_acc: 0.2004\n",
      "Epoch 3143/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1865 - acc: 0.2162 - val_loss: 0.5861 - val_acc: 0.2004\n",
      "Epoch 3144/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1732 - acc: 0.2158 - val_loss: 0.6388 - val_acc: 0.1985\n",
      "Epoch 3145/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1724 - acc: 0.2158 - val_loss: 0.5978 - val_acc: 0.2004\n",
      "Epoch 3146/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1775 - acc: 0.2167 - val_loss: 0.5829 - val_acc: 0.2004\n",
      "Epoch 3147/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1797 - acc: 0.2158 - val_loss: 0.5979 - val_acc: 0.2004\n",
      "Epoch 3148/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1730 - acc: 0.2139 - val_loss: 0.5935 - val_acc: 0.2004\n",
      "Epoch 3149/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1833 - acc: 0.2162 - val_loss: 0.5894 - val_acc: 0.2004\n",
      "Epoch 3150/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1785 - acc: 0.2162 - val_loss: 0.5817 - val_acc: 0.2004\n",
      "Epoch 3151/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1967 - acc: 0.2158 - val_loss: 0.6053 - val_acc: 0.1985\n",
      "Epoch 3152/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2076 - acc: 0.2158 - val_loss: 0.5833 - val_acc: 0.2004\n",
      "Epoch 3153/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1900 - acc: 0.2167 - val_loss: 0.5833 - val_acc: 0.2004\n",
      "Epoch 3154/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1702 - acc: 0.2162 - val_loss: 0.6176 - val_acc: 0.2004\n",
      "Epoch 3155/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1822 - acc: 0.2158 - val_loss: 0.6387 - val_acc: 0.1985\n",
      "Epoch 3156/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1765 - acc: 0.2158 - val_loss: 0.5778 - val_acc: 0.2004\n",
      "Epoch 3157/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1772 - acc: 0.2153 - val_loss: 0.6230 - val_acc: 0.2004\n",
      "Epoch 3158/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1770 - acc: 0.2144 - val_loss: 0.6467 - val_acc: 0.1985\n",
      "Epoch 3159/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1721 - acc: 0.2158 - val_loss: 0.6160 - val_acc: 0.1985\n",
      "Epoch 3160/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1885 - acc: 0.2153 - val_loss: 0.6180 - val_acc: 0.2004\n",
      "Epoch 3161/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1823 - acc: 0.2153 - val_loss: 0.6180 - val_acc: 0.1985\n",
      "Epoch 3162/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1771 - acc: 0.2162 - val_loss: 0.5922 - val_acc: 0.1985\n",
      "Epoch 3163/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1912 - acc: 0.2167 - val_loss: 0.6458 - val_acc: 0.1967\n",
      "Epoch 3164/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2142 - acc: 0.2139 - val_loss: 0.9548 - val_acc: 0.1874\n",
      "Epoch 3165/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2060 - acc: 0.2144 - val_loss: 0.6207 - val_acc: 0.1985\n",
      "Epoch 3166/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1734 - acc: 0.2162 - val_loss: 0.6262 - val_acc: 0.1985\n",
      "Epoch 3167/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1666 - acc: 0.2148 - val_loss: 0.6102 - val_acc: 0.2004\n",
      "Epoch 3168/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2034 - acc: 0.2144 - val_loss: 0.5815 - val_acc: 0.2004\n",
      "Epoch 3169/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1810 - acc: 0.2139 - val_loss: 0.6342 - val_acc: 0.2004\n",
      "Epoch 3170/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1828 - acc: 0.2158 - val_loss: 0.5994 - val_acc: 0.1985\n",
      "Epoch 3171/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1899 - acc: 0.2148 - val_loss: 0.5795 - val_acc: 0.2004\n",
      "Epoch 3172/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1815 - acc: 0.2158 - val_loss: 0.6448 - val_acc: 0.1985\n",
      "Epoch 3173/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2130 - acc: 0.2148 - val_loss: 0.6363 - val_acc: 0.1985\n",
      "Epoch 3174/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1863 - acc: 0.2153 - val_loss: 0.6338 - val_acc: 0.2004\n",
      "Epoch 3175/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1739 - acc: 0.2158 - val_loss: 0.6712 - val_acc: 0.2004\n",
      "Epoch 3176/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1919 - acc: 0.2158 - val_loss: 0.5927 - val_acc: 0.1985\n",
      "Epoch 3177/4000\n",
      "68/68 [==============================] - 4s 56ms/step - loss: 0.1817 - acc: 0.2162 - val_loss: 0.5942 - val_acc: 0.2004\n",
      "Epoch 3178/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1889 - acc: 0.2148 - val_loss: 0.6221 - val_acc: 0.2004\n",
      "Epoch 3179/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1975 - acc: 0.2153 - val_loss: 0.6577 - val_acc: 0.2004\n",
      "Epoch 3180/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1841 - acc: 0.2144 - val_loss: 0.7006 - val_acc: 0.2004\n",
      "Epoch 3181/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1993 - acc: 0.2144 - val_loss: 0.6290 - val_acc: 0.2004\n",
      "Epoch 3182/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1796 - acc: 0.2153 - val_loss: 0.6479 - val_acc: 0.2004\n",
      "Epoch 3183/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1958 - acc: 0.2139 - val_loss: 0.6212 - val_acc: 0.2004\n",
      "Epoch 3184/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.1819 - acc: 0.2162 - val_loss: 0.6090 - val_acc: 0.2004\n",
      "Epoch 3185/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1850 - acc: 0.2162 - val_loss: 0.6038 - val_acc: 0.2004\n",
      "Epoch 3186/4000\n",
      "68/68 [==============================] - 5s 71ms/step - loss: 0.1734 - acc: 0.2153 - val_loss: 0.5881 - val_acc: 0.2004\n",
      "Epoch 3187/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1851 - acc: 0.2158 - val_loss: 0.6176 - val_acc: 0.2004\n",
      "Epoch 3188/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2016 - acc: 0.2153 - val_loss: 0.5990 - val_acc: 0.2004\n",
      "Epoch 3189/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1910 - acc: 0.2162 - val_loss: 0.6015 - val_acc: 0.1985\n",
      "Epoch 3190/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1942 - acc: 0.2162 - val_loss: 0.5918 - val_acc: 0.2004\n",
      "Epoch 3191/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1759 - acc: 0.2144 - val_loss: 0.5995 - val_acc: 0.2004\n",
      "Epoch 3192/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1832 - acc: 0.2158 - val_loss: 0.6044 - val_acc: 0.2004\n",
      "Epoch 3193/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1750 - acc: 0.2153 - val_loss: 0.5746 - val_acc: 0.2004\n",
      "Epoch 3194/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2024 - acc: 0.2153 - val_loss: 0.6190 - val_acc: 0.2004\n",
      "Epoch 3195/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1883 - acc: 0.2139 - val_loss: 0.6216 - val_acc: 0.1985\n",
      "Epoch 3196/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1775 - acc: 0.2158 - val_loss: 0.6204 - val_acc: 0.1985\n",
      "Epoch 3197/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2023 - acc: 0.2153 - val_loss: 0.5810 - val_acc: 0.2004\n",
      "Epoch 3198/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.2176 - acc: 0.2148 - val_loss: 0.6389 - val_acc: 0.2004\n",
      "Epoch 3199/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1798 - acc: 0.2158 - val_loss: 0.5553 - val_acc: 0.2004\n",
      "Epoch 3200/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1836 - acc: 0.2153 - val_loss: 0.5934 - val_acc: 0.2004\n",
      "Epoch 3201/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2037 - acc: 0.2144 - val_loss: 0.7019 - val_acc: 0.2004\n",
      "Epoch 3202/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2562 - acc: 0.2162 - val_loss: 0.5750 - val_acc: 0.2004\n",
      "Epoch 3203/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2157 - acc: 0.2153 - val_loss: 0.6464 - val_acc: 0.1985\n",
      "Epoch 3204/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2286 - acc: 0.2153 - val_loss: 0.5976 - val_acc: 0.2004\n",
      "Epoch 3205/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.5543 - acc: 0.2023 - val_loss: 0.9626 - val_acc: 0.2004\n",
      "Epoch 3206/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3938 - acc: 0.2158 - val_loss: 0.7204 - val_acc: 0.2004\n",
      "Epoch 3207/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2567 - acc: 0.2153 - val_loss: 0.5581 - val_acc: 0.2004\n",
      "Epoch 3208/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2629 - acc: 0.2162 - val_loss: 0.5937 - val_acc: 0.2004\n",
      "Epoch 3209/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2105 - acc: 0.2162 - val_loss: 0.6137 - val_acc: 0.2004\n",
      "Epoch 3210/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1794 - acc: 0.2162 - val_loss: 0.5819 - val_acc: 0.2004\n",
      "Epoch 3211/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1800 - acc: 0.2158 - val_loss: 0.6880 - val_acc: 0.1967\n",
      "Epoch 3212/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1855 - acc: 0.2153 - val_loss: 0.5948 - val_acc: 0.2004\n",
      "Epoch 3213/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2194 - acc: 0.2139 - val_loss: 0.7309 - val_acc: 0.2004\n",
      "Epoch 3214/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1805 - acc: 0.2153 - val_loss: 0.5749 - val_acc: 0.2004\n",
      "Epoch 3215/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1704 - acc: 0.2148 - val_loss: 0.6135 - val_acc: 0.2004\n",
      "Epoch 3216/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1709 - acc: 0.2158 - val_loss: 0.6326 - val_acc: 0.2004\n",
      "Epoch 3217/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1700 - acc: 0.2158 - val_loss: 0.5996 - val_acc: 0.2004\n",
      "Epoch 3218/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1699 - acc: 0.2153 - val_loss: 0.5802 - val_acc: 0.2004\n",
      "Epoch 3219/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1798 - acc: 0.2153 - val_loss: 0.7687 - val_acc: 0.1967\n",
      "Epoch 3220/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2118 - acc: 0.2144 - val_loss: 0.5817 - val_acc: 0.2004\n",
      "Epoch 3221/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1792 - acc: 0.2153 - val_loss: 0.5838 - val_acc: 0.2004\n",
      "Epoch 3222/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1702 - acc: 0.2162 - val_loss: 0.5918 - val_acc: 0.2004\n",
      "Epoch 3223/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1676 - acc: 0.2158 - val_loss: 0.5937 - val_acc: 0.2004\n",
      "Epoch 3224/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1682 - acc: 0.2158 - val_loss: 0.5977 - val_acc: 0.2004\n",
      "Epoch 3225/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1906 - acc: 0.2162 - val_loss: 0.5871 - val_acc: 0.2004\n",
      "Epoch 3226/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1942 - acc: 0.2153 - val_loss: 0.5968 - val_acc: 0.2004\n",
      "Epoch 3227/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1877 - acc: 0.2167 - val_loss: 0.5983 - val_acc: 0.2004\n",
      "Epoch 3228/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2046 - acc: 0.2158 - val_loss: 0.6211 - val_acc: 0.2004\n",
      "Epoch 3229/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1809 - acc: 0.2172 - val_loss: 0.5871 - val_acc: 0.2004\n",
      "Epoch 3230/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1716 - acc: 0.2148 - val_loss: 0.6101 - val_acc: 0.2004\n",
      "Epoch 3231/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1798 - acc: 0.2162 - val_loss: 0.6709 - val_acc: 0.2004\n",
      "Epoch 3232/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1777 - acc: 0.2162 - val_loss: 0.5894 - val_acc: 0.2004\n",
      "Epoch 3233/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1730 - acc: 0.2167 - val_loss: 0.6009 - val_acc: 0.2004\n",
      "Epoch 3234/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1664 - acc: 0.2158 - val_loss: 0.6187 - val_acc: 0.2004\n",
      "Epoch 3235/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1816 - acc: 0.2153 - val_loss: 0.6029 - val_acc: 0.2004\n",
      "Epoch 3236/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1833 - acc: 0.2162 - val_loss: 0.5814 - val_acc: 0.2004\n",
      "Epoch 3237/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1920 - acc: 0.2153 - val_loss: 0.6100 - val_acc: 0.2004\n",
      "Epoch 3238/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1831 - acc: 0.2158 - val_loss: 0.5974 - val_acc: 0.2004\n",
      "Epoch 3239/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1836 - acc: 0.2144 - val_loss: 0.5887 - val_acc: 0.2004\n",
      "Epoch 3240/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1957 - acc: 0.2158 - val_loss: 0.6736 - val_acc: 0.1967\n",
      "Epoch 3241/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2097 - acc: 0.2153 - val_loss: 0.6588 - val_acc: 0.2004\n",
      "Epoch 3242/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2050 - acc: 0.2162 - val_loss: 0.5864 - val_acc: 0.2004\n",
      "Epoch 3243/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1720 - acc: 0.2148 - val_loss: 0.5960 - val_acc: 0.2004\n",
      "Epoch 3244/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1764 - acc: 0.2158 - val_loss: 0.5944 - val_acc: 0.2004\n",
      "Epoch 3245/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1776 - acc: 0.2148 - val_loss: 0.5990 - val_acc: 0.2004\n",
      "Epoch 3246/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1767 - acc: 0.2153 - val_loss: 0.6320 - val_acc: 0.2004\n",
      "Epoch 3247/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1852 - acc: 0.2148 - val_loss: 0.5922 - val_acc: 0.2004\n",
      "Epoch 3248/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1863 - acc: 0.2148 - val_loss: 0.6292 - val_acc: 0.1985\n",
      "Epoch 3249/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1917 - acc: 0.2148 - val_loss: 0.6457 - val_acc: 0.2004\n",
      "Epoch 3250/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1886 - acc: 0.2148 - val_loss: 0.5879 - val_acc: 0.2004\n",
      "Epoch 3251/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1785 - acc: 0.2167 - val_loss: 0.5777 - val_acc: 0.2004\n",
      "Epoch 3252/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1905 - acc: 0.2158 - val_loss: 0.7189 - val_acc: 0.2004\n",
      "Epoch 3253/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1883 - acc: 0.2162 - val_loss: 0.6279 - val_acc: 0.2004\n",
      "Epoch 3254/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1821 - acc: 0.2162 - val_loss: 0.6238 - val_acc: 0.2004\n",
      "Epoch 3255/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1894 - acc: 0.2153 - val_loss: 0.6112 - val_acc: 0.2004\n",
      "Epoch 3256/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2015 - acc: 0.2158 - val_loss: 0.6515 - val_acc: 0.2004\n",
      "Epoch 3257/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1841 - acc: 0.2167 - val_loss: 0.5899 - val_acc: 0.2004\n",
      "Epoch 3258/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1736 - acc: 0.2158 - val_loss: 0.6185 - val_acc: 0.2004\n",
      "Epoch 3259/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1693 - acc: 0.2158 - val_loss: 0.6135 - val_acc: 0.2004\n",
      "Epoch 3260/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1782 - acc: 0.2148 - val_loss: 0.5912 - val_acc: 0.2004\n",
      "Epoch 3261/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1804 - acc: 0.2153 - val_loss: 0.5992 - val_acc: 0.2004\n",
      "Epoch 3262/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1903 - acc: 0.2153 - val_loss: 0.6438 - val_acc: 0.1967\n",
      "Epoch 3263/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1782 - acc: 0.2162 - val_loss: 0.6925 - val_acc: 0.2004\n",
      "Epoch 3264/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2035 - acc: 0.2148 - val_loss: 0.6078 - val_acc: 0.2004\n",
      "Epoch 3265/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1850 - acc: 0.2158 - val_loss: 0.6410 - val_acc: 0.1985\n",
      "Epoch 3266/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.1872 - acc: 0.2153 - val_loss: 0.6128 - val_acc: 0.2004\n",
      "Epoch 3267/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.1825 - acc: 0.2153 - val_loss: 0.6205 - val_acc: 0.2004\n",
      "Epoch 3268/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1921 - acc: 0.2158 - val_loss: 0.6532 - val_acc: 0.2004\n",
      "Epoch 3269/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1850 - acc: 0.2148 - val_loss: 0.6239 - val_acc: 0.2004\n",
      "Epoch 3270/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2285 - acc: 0.2148 - val_loss: 0.5963 - val_acc: 0.2004\n",
      "Epoch 3271/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1943 - acc: 0.2144 - val_loss: 0.6214 - val_acc: 0.2004\n",
      "Epoch 3272/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1742 - acc: 0.2158 - val_loss: 0.6140 - val_acc: 0.2004\n",
      "Epoch 3273/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1776 - acc: 0.2167 - val_loss: 0.6280 - val_acc: 0.2004\n",
      "Epoch 3274/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1818 - acc: 0.2153 - val_loss: 0.6383 - val_acc: 0.1985\n",
      "Epoch 3275/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1964 - acc: 0.2153 - val_loss: 0.6016 - val_acc: 0.2004\n",
      "Epoch 3276/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1962 - acc: 0.2153 - val_loss: 0.6042 - val_acc: 0.2004\n",
      "Epoch 3277/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1788 - acc: 0.2153 - val_loss: 0.6335 - val_acc: 0.2004\n",
      "Epoch 3278/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1730 - acc: 0.2162 - val_loss: 0.5760 - val_acc: 0.2004\n",
      "Epoch 3279/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1668 - acc: 0.2153 - val_loss: 0.6775 - val_acc: 0.1967\n",
      "Epoch 3280/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2168 - acc: 0.2148 - val_loss: 0.8302 - val_acc: 0.1929\n",
      "Epoch 3281/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2240 - acc: 0.2153 - val_loss: 0.6606 - val_acc: 0.2004\n",
      "Epoch 3282/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2435 - acc: 0.2144 - val_loss: 0.7146 - val_acc: 0.1967\n",
      "Epoch 3283/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2432 - acc: 0.2144 - val_loss: 0.8963 - val_acc: 0.2004\n",
      "Epoch 3284/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2260 - acc: 0.2153 - val_loss: 0.6283 - val_acc: 0.2004\n",
      "Epoch 3285/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1942 - acc: 0.2158 - val_loss: 0.7658 - val_acc: 0.1967\n",
      "Epoch 3286/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1827 - acc: 0.2162 - val_loss: 0.6026 - val_acc: 0.2004\n",
      "Epoch 3287/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1880 - acc: 0.2162 - val_loss: 0.6528 - val_acc: 0.1985\n",
      "Epoch 3288/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1734 - acc: 0.2167 - val_loss: 0.6014 - val_acc: 0.2004\n",
      "Epoch 3289/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1824 - acc: 0.2153 - val_loss: 0.6195 - val_acc: 0.2004\n",
      "Epoch 3290/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2066 - acc: 0.2158 - val_loss: 0.6240 - val_acc: 0.2004\n",
      "Epoch 3291/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1906 - acc: 0.2158 - val_loss: 0.6136 - val_acc: 0.2004\n",
      "Epoch 3292/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1738 - acc: 0.2153 - val_loss: 0.5989 - val_acc: 0.2004\n",
      "Epoch 3293/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1847 - acc: 0.2162 - val_loss: 0.6098 - val_acc: 0.2004\n",
      "Epoch 3294/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1856 - acc: 0.2158 - val_loss: 0.5761 - val_acc: 0.2004\n",
      "Epoch 3295/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1810 - acc: 0.2153 - val_loss: 0.5924 - val_acc: 0.2004\n",
      "Epoch 3296/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1860 - acc: 0.2148 - val_loss: 0.6324 - val_acc: 0.2004\n",
      "Epoch 3297/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1855 - acc: 0.2158 - val_loss: 0.5969 - val_acc: 0.2004\n",
      "Epoch 3298/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1770 - acc: 0.2148 - val_loss: 0.6486 - val_acc: 0.2004\n",
      "Epoch 3299/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1787 - acc: 0.2148 - val_loss: 0.6203 - val_acc: 0.2004\n",
      "Epoch 3300/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1926 - acc: 0.2158 - val_loss: 0.5786 - val_acc: 0.2004\n",
      "Epoch 3301/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2122 - acc: 0.2139 - val_loss: 0.6066 - val_acc: 0.2004\n",
      "Epoch 3302/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2042 - acc: 0.2158 - val_loss: 0.5993 - val_acc: 0.2004\n",
      "Epoch 3303/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2149 - acc: 0.2144 - val_loss: 0.6594 - val_acc: 0.2004\n",
      "Epoch 3304/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1779 - acc: 0.2167 - val_loss: 0.6044 - val_acc: 0.2004\n",
      "Epoch 3305/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1718 - acc: 0.2158 - val_loss: 0.6091 - val_acc: 0.2004\n",
      "Epoch 3306/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1794 - acc: 0.2153 - val_loss: 0.6387 - val_acc: 0.2004\n",
      "Epoch 3307/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1743 - acc: 0.2162 - val_loss: 0.6725 - val_acc: 0.1985\n",
      "Epoch 3308/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2026 - acc: 0.2158 - val_loss: 0.6993 - val_acc: 0.2004\n",
      "Epoch 3309/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1952 - acc: 0.2158 - val_loss: 0.6340 - val_acc: 0.2004\n",
      "Epoch 3310/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1776 - acc: 0.2158 - val_loss: 0.7463 - val_acc: 0.1967\n",
      "Epoch 3311/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1948 - acc: 0.2162 - val_loss: 0.6104 - val_acc: 0.2004\n",
      "Epoch 3312/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1665 - acc: 0.2162 - val_loss: 0.6336 - val_acc: 0.2004\n",
      "Epoch 3313/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1859 - acc: 0.2153 - val_loss: 0.6404 - val_acc: 0.2004\n",
      "Epoch 3314/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2009 - acc: 0.2162 - val_loss: 0.6833 - val_acc: 0.1967\n",
      "Epoch 3315/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1772 - acc: 0.2153 - val_loss: 0.6410 - val_acc: 0.2004\n",
      "Epoch 3316/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1765 - acc: 0.2158 - val_loss: 0.5822 - val_acc: 0.2004\n",
      "Epoch 3317/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1847 - acc: 0.2158 - val_loss: 0.6821 - val_acc: 0.2004\n",
      "Epoch 3318/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1937 - acc: 0.2158 - val_loss: 0.6037 - val_acc: 0.2004\n",
      "Epoch 3319/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1852 - acc: 0.2153 - val_loss: 0.6279 - val_acc: 0.2004\n",
      "Epoch 3320/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1757 - acc: 0.2162 - val_loss: 0.5891 - val_acc: 0.2004\n",
      "Epoch 3321/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1674 - acc: 0.2167 - val_loss: 0.6109 - val_acc: 0.2004\n",
      "Epoch 3322/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1795 - acc: 0.2158 - val_loss: 0.7764 - val_acc: 0.1948\n",
      "Epoch 3323/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2123 - acc: 0.2148 - val_loss: 0.5923 - val_acc: 0.2004\n",
      "Epoch 3324/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1669 - acc: 0.2158 - val_loss: 0.6240 - val_acc: 0.2004\n",
      "Epoch 3325/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1695 - acc: 0.2148 - val_loss: 0.5938 - val_acc: 0.2004\n",
      "Epoch 3326/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1824 - acc: 0.2148 - val_loss: 0.7593 - val_acc: 0.2004\n",
      "Epoch 3327/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2174 - acc: 0.2153 - val_loss: 0.6890 - val_acc: 0.2004\n",
      "Epoch 3328/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2091 - acc: 0.2148 - val_loss: 0.6535 - val_acc: 0.2004\n",
      "Epoch 3329/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1982 - acc: 0.2135 - val_loss: 0.6492 - val_acc: 0.1985\n",
      "Epoch 3330/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1943 - acc: 0.2158 - val_loss: 0.7540 - val_acc: 0.2004\n",
      "Epoch 3331/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4948 - acc: 0.2144 - val_loss: 0.6326 - val_acc: 0.2004\n",
      "Epoch 3332/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3456 - acc: 0.2153 - val_loss: 0.7877 - val_acc: 0.1967\n",
      "Epoch 3333/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2852 - acc: 0.2153 - val_loss: 0.8277 - val_acc: 0.2004\n",
      "Epoch 3334/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2330 - acc: 0.2148 - val_loss: 0.6088 - val_acc: 0.1985\n",
      "Epoch 3335/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1925 - acc: 0.2144 - val_loss: 0.5993 - val_acc: 0.2004\n",
      "Epoch 3336/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1983 - acc: 0.2153 - val_loss: 0.6616 - val_acc: 0.2004\n",
      "Epoch 3337/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1742 - acc: 0.2153 - val_loss: 0.6206 - val_acc: 0.1985\n",
      "Epoch 3338/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1758 - acc: 0.2153 - val_loss: 0.6344 - val_acc: 0.1985\n",
      "Epoch 3339/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1999 - acc: 0.2139 - val_loss: 0.5953 - val_acc: 0.2004\n",
      "Epoch 3340/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1728 - acc: 0.2167 - val_loss: 0.7670 - val_acc: 0.2004\n",
      "Epoch 3341/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1929 - acc: 0.2162 - val_loss: 0.5693 - val_acc: 0.2004\n",
      "Epoch 3342/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1668 - acc: 0.2162 - val_loss: 0.6473 - val_acc: 0.1967\n",
      "Epoch 3343/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1767 - acc: 0.2158 - val_loss: 0.5777 - val_acc: 0.2004\n",
      "Epoch 3344/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1781 - acc: 0.2162 - val_loss: 0.5719 - val_acc: 0.2004\n",
      "Epoch 3345/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1711 - acc: 0.2162 - val_loss: 0.6319 - val_acc: 0.1985\n",
      "Epoch 3346/4000\n",
      "68/68 [==============================] - 5s 69ms/step - loss: 0.1953 - acc: 0.2144 - val_loss: 0.7132 - val_acc: 0.2004\n",
      "Epoch 3347/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.1780 - acc: 0.2158 - val_loss: 0.5976 - val_acc: 0.2004\n",
      "Epoch 3348/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1697 - acc: 0.2158 - val_loss: 0.5974 - val_acc: 0.2004\n",
      "Epoch 3349/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1724 - acc: 0.2148 - val_loss: 0.5904 - val_acc: 0.2004\n",
      "Epoch 3350/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1833 - acc: 0.2153 - val_loss: 0.6009 - val_acc: 0.2004\n",
      "Epoch 3351/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1697 - acc: 0.2158 - val_loss: 0.5992 - val_acc: 0.2004\n",
      "Epoch 3352/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1662 - acc: 0.2158 - val_loss: 0.6022 - val_acc: 0.2004\n",
      "Epoch 3353/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1633 - acc: 0.2162 - val_loss: 0.6073 - val_acc: 0.2004\n",
      "Epoch 3354/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1781 - acc: 0.2158 - val_loss: 0.6049 - val_acc: 0.2004\n",
      "Epoch 3355/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1932 - acc: 0.2148 - val_loss: 0.6343 - val_acc: 0.1985\n",
      "Epoch 3356/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1973 - acc: 0.2148 - val_loss: 0.5864 - val_acc: 0.2004\n",
      "Epoch 3357/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1837 - acc: 0.2153 - val_loss: 0.6036 - val_acc: 0.2004\n",
      "Epoch 3358/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1876 - acc: 0.2139 - val_loss: 0.5688 - val_acc: 0.2004\n",
      "Epoch 3359/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1882 - acc: 0.2158 - val_loss: 0.6168 - val_acc: 0.2004\n",
      "Epoch 3360/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2081 - acc: 0.2135 - val_loss: 1.1796 - val_acc: 0.2004\n",
      "Epoch 3361/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2313 - acc: 0.2148 - val_loss: 0.6456 - val_acc: 0.1985\n",
      "Epoch 3362/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1752 - acc: 0.2158 - val_loss: 0.5977 - val_acc: 0.2004\n",
      "Epoch 3363/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1869 - acc: 0.2162 - val_loss: 0.6777 - val_acc: 0.2004\n",
      "Epoch 3364/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1842 - acc: 0.2139 - val_loss: 0.6475 - val_acc: 0.2004\n",
      "Epoch 3365/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1768 - acc: 0.2153 - val_loss: 0.6022 - val_acc: 0.2004\n",
      "Epoch 3366/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1813 - acc: 0.2148 - val_loss: 0.6091 - val_acc: 0.2004\n",
      "Epoch 3367/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1920 - acc: 0.2148 - val_loss: 0.6249 - val_acc: 0.2004\n",
      "Epoch 3368/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1662 - acc: 0.2162 - val_loss: 0.6096 - val_acc: 0.2004\n",
      "Epoch 3369/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1799 - acc: 0.2148 - val_loss: 0.6265 - val_acc: 0.1967\n",
      "Epoch 3370/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1801 - acc: 0.2162 - val_loss: 0.6543 - val_acc: 0.2004\n",
      "Epoch 3371/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1706 - acc: 0.2153 - val_loss: 0.6053 - val_acc: 0.2004\n",
      "Epoch 3372/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1671 - acc: 0.2158 - val_loss: 0.6021 - val_acc: 0.2004\n",
      "Epoch 3373/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1906 - acc: 0.2162 - val_loss: 0.6119 - val_acc: 0.2004\n",
      "Epoch 3374/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2035 - acc: 0.2158 - val_loss: 0.6929 - val_acc: 0.1985\n",
      "Epoch 3375/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1892 - acc: 0.2144 - val_loss: 0.6033 - val_acc: 0.2004\n",
      "Epoch 3376/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1783 - acc: 0.2153 - val_loss: 0.6629 - val_acc: 0.2004\n",
      "Epoch 3377/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1766 - acc: 0.2148 - val_loss: 0.6003 - val_acc: 0.2004\n",
      "Epoch 3378/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1815 - acc: 0.2158 - val_loss: 0.6054 - val_acc: 0.2004\n",
      "Epoch 3379/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2482 - acc: 0.2153 - val_loss: 0.5940 - val_acc: 0.2004\n",
      "Epoch 3380/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1730 - acc: 0.2148 - val_loss: 0.8014 - val_acc: 0.2004\n",
      "Epoch 3381/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1941 - acc: 0.2162 - val_loss: 0.6004 - val_acc: 0.2004\n",
      "Epoch 3382/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1924 - acc: 0.2153 - val_loss: 0.7244 - val_acc: 0.1967\n",
      "Epoch 3383/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1890 - acc: 0.2153 - val_loss: 0.6764 - val_acc: 0.2004\n",
      "Epoch 3384/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1742 - acc: 0.2158 - val_loss: 0.6013 - val_acc: 0.2004\n",
      "Epoch 3385/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1876 - acc: 0.2148 - val_loss: 0.6034 - val_acc: 0.2004\n",
      "Epoch 3386/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2186 - acc: 0.2144 - val_loss: 0.7089 - val_acc: 0.2004\n",
      "Epoch 3387/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2052 - acc: 0.2144 - val_loss: 0.5916 - val_acc: 0.2004\n",
      "Epoch 3388/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1871 - acc: 0.2158 - val_loss: 0.6404 - val_acc: 0.2004\n",
      "Epoch 3389/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1694 - acc: 0.2162 - val_loss: 0.6334 - val_acc: 0.2004\n",
      "Epoch 3390/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1783 - acc: 0.2158 - val_loss: 0.6169 - val_acc: 0.2004\n",
      "Epoch 3391/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1835 - acc: 0.2153 - val_loss: 0.5955 - val_acc: 0.2004\n",
      "Epoch 3392/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1743 - acc: 0.2148 - val_loss: 0.6087 - val_acc: 0.2004\n",
      "Epoch 3393/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1829 - acc: 0.2153 - val_loss: 0.6210 - val_acc: 0.2004\n",
      "Epoch 3394/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2010 - acc: 0.2153 - val_loss: 0.6328 - val_acc: 0.2004\n",
      "Epoch 3395/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1795 - acc: 0.2162 - val_loss: 0.6421 - val_acc: 0.2004\n",
      "Epoch 3396/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1890 - acc: 0.2158 - val_loss: 0.6941 - val_acc: 0.2004\n",
      "Epoch 3397/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2637 - acc: 0.2153 - val_loss: 1.1146 - val_acc: 0.2004\n",
      "Epoch 3398/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.5882 - acc: 0.2088 - val_loss: 0.7200 - val_acc: 0.2004\n",
      "Epoch 3399/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2378 - acc: 0.2153 - val_loss: 0.6383 - val_acc: 0.2004\n",
      "Epoch 3400/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2173 - acc: 0.2158 - val_loss: 0.6642 - val_acc: 0.2004\n",
      "Epoch 3401/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1822 - acc: 0.2148 - val_loss: 0.5589 - val_acc: 0.2004\n",
      "Epoch 3402/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1897 - acc: 0.2158 - val_loss: 0.6090 - val_acc: 0.2004\n",
      "Epoch 3403/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1664 - acc: 0.2158 - val_loss: 0.5966 - val_acc: 0.2004\n",
      "Epoch 3404/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1687 - acc: 0.2153 - val_loss: 0.6042 - val_acc: 0.2004\n",
      "Epoch 3405/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1663 - acc: 0.2167 - val_loss: 0.6018 - val_acc: 0.2004\n",
      "Epoch 3406/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1610 - acc: 0.2158 - val_loss: 0.6780 - val_acc: 0.1967\n",
      "Epoch 3407/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1754 - acc: 0.2153 - val_loss: 0.6116 - val_acc: 0.1985\n",
      "Epoch 3408/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1720 - acc: 0.2158 - val_loss: 0.6132 - val_acc: 0.2004\n",
      "Epoch 3409/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1714 - acc: 0.2153 - val_loss: 0.5916 - val_acc: 0.2004\n",
      "Epoch 3410/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1789 - acc: 0.2153 - val_loss: 0.6318 - val_acc: 0.1985\n",
      "Epoch 3411/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1876 - acc: 0.2153 - val_loss: 0.6109 - val_acc: 0.2004\n",
      "Epoch 3412/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1762 - acc: 0.2167 - val_loss: 0.6241 - val_acc: 0.2004\n",
      "Epoch 3413/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1946 - acc: 0.2139 - val_loss: 0.6147 - val_acc: 0.2004\n",
      "Epoch 3414/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1799 - acc: 0.2158 - val_loss: 0.6002 - val_acc: 0.2004\n",
      "Epoch 3415/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1754 - acc: 0.2158 - val_loss: 0.5888 - val_acc: 0.2004\n",
      "Epoch 3416/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1755 - acc: 0.2162 - val_loss: 0.6347 - val_acc: 0.2004\n",
      "Epoch 3417/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1692 - acc: 0.2162 - val_loss: 0.6573 - val_acc: 0.1985\n",
      "Epoch 3418/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1932 - acc: 0.2153 - val_loss: 0.6126 - val_acc: 0.2004\n",
      "Epoch 3419/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1664 - acc: 0.2158 - val_loss: 0.6237 - val_acc: 0.2004\n",
      "Epoch 3420/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1775 - acc: 0.2139 - val_loss: 0.6081 - val_acc: 0.2004\n",
      "Epoch 3421/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1755 - acc: 0.2148 - val_loss: 0.6016 - val_acc: 0.2004\n",
      "Epoch 3422/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1740 - acc: 0.2144 - val_loss: 0.6248 - val_acc: 0.2004\n",
      "Epoch 3423/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1799 - acc: 0.2158 - val_loss: 0.6626 - val_acc: 0.2004\n",
      "Epoch 3424/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1732 - acc: 0.2148 - val_loss: 0.6031 - val_acc: 0.2004\n",
      "Epoch 3425/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1651 - acc: 0.2162 - val_loss: 0.6346 - val_acc: 0.2004\n",
      "Epoch 3426/4000\n",
      "68/68 [==============================] - 5s 74ms/step - loss: 0.1775 - acc: 0.2153 - val_loss: 0.6224 - val_acc: 0.2004\n",
      "Epoch 3427/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1762 - acc: 0.2139 - val_loss: 0.6027 - val_acc: 0.2004\n",
      "Epoch 3428/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1971 - acc: 0.2162 - val_loss: 0.7352 - val_acc: 0.2004\n",
      "Epoch 3429/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1960 - acc: 0.2148 - val_loss: 0.6555 - val_acc: 0.1967\n",
      "Epoch 3430/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2173 - acc: 0.2153 - val_loss: 0.6907 - val_acc: 0.2004\n",
      "Epoch 3431/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1747 - acc: 0.2158 - val_loss: 0.6325 - val_acc: 0.1985\n",
      "Epoch 3432/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1809 - acc: 0.2153 - val_loss: 0.6959 - val_acc: 0.2004\n",
      "Epoch 3433/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1857 - acc: 0.2158 - val_loss: 0.6178 - val_acc: 0.2004\n",
      "Epoch 3434/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1840 - acc: 0.2162 - val_loss: 0.6343 - val_acc: 0.2004\n",
      "Epoch 3435/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1753 - acc: 0.2162 - val_loss: 0.6232 - val_acc: 0.1985\n",
      "Epoch 3436/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1726 - acc: 0.2153 - val_loss: 0.6206 - val_acc: 0.2004\n",
      "Epoch 3437/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1777 - acc: 0.2153 - val_loss: 0.7826 - val_acc: 0.2004\n",
      "Epoch 3438/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1872 - acc: 0.2153 - val_loss: 0.6151 - val_acc: 0.2004\n",
      "Epoch 3439/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1849 - acc: 0.2148 - val_loss: 0.6319 - val_acc: 0.2004\n",
      "Epoch 3440/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1878 - acc: 0.2144 - val_loss: 0.6117 - val_acc: 0.2004\n",
      "Epoch 3441/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1709 - acc: 0.2162 - val_loss: 0.6157 - val_acc: 0.2004\n",
      "Epoch 3442/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2061 - acc: 0.2158 - val_loss: 0.6334 - val_acc: 0.2004\n",
      "Epoch 3443/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1832 - acc: 0.2153 - val_loss: 0.6942 - val_acc: 0.1967\n",
      "Epoch 3444/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2003 - acc: 0.2158 - val_loss: 0.7162 - val_acc: 0.2004\n",
      "Epoch 3445/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1943 - acc: 0.2153 - val_loss: 0.6409 - val_acc: 0.2004\n",
      "Epoch 3446/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1682 - acc: 0.2158 - val_loss: 0.6093 - val_acc: 0.1967\n",
      "Epoch 3447/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.1772 - acc: 0.2144 - val_loss: 0.6290 - val_acc: 0.2004\n",
      "Epoch 3448/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1887 - acc: 0.2144 - val_loss: 0.6849 - val_acc: 0.1967\n",
      "Epoch 3449/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1954 - acc: 0.2153 - val_loss: 0.6210 - val_acc: 0.2004\n",
      "Epoch 3450/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1863 - acc: 0.2162 - val_loss: 0.6045 - val_acc: 0.2004\n",
      "Epoch 3451/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2085 - acc: 0.2144 - val_loss: 0.6682 - val_acc: 0.1985\n",
      "Epoch 3452/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1799 - acc: 0.2158 - val_loss: 0.6034 - val_acc: 0.2004\n",
      "Epoch 3453/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1797 - acc: 0.2153 - val_loss: 0.7301 - val_acc: 0.2004\n",
      "Epoch 3454/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1983 - acc: 0.2153 - val_loss: 0.6726 - val_acc: 0.1967\n",
      "Epoch 3455/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1843 - acc: 0.2153 - val_loss: 0.6311 - val_acc: 0.2004\n",
      "Epoch 3456/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1783 - acc: 0.2153 - val_loss: 0.6420 - val_acc: 0.2004\n",
      "Epoch 3457/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1817 - acc: 0.2162 - val_loss: 0.6914 - val_acc: 0.1967\n",
      "Epoch 3458/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1931 - acc: 0.2153 - val_loss: 0.6091 - val_acc: 0.2004\n",
      "Epoch 3459/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1849 - acc: 0.2158 - val_loss: 0.7195 - val_acc: 0.2004\n",
      "Epoch 3460/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2350 - acc: 0.2153 - val_loss: 0.6250 - val_acc: 0.2004\n",
      "Epoch 3461/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2007 - acc: 0.2158 - val_loss: 0.6866 - val_acc: 0.2004\n",
      "Epoch 3462/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1718 - acc: 0.2167 - val_loss: 0.7226 - val_acc: 0.2004\n",
      "Epoch 3463/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1959 - acc: 0.2148 - val_loss: 0.6043 - val_acc: 0.2004\n",
      "Epoch 3464/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1771 - acc: 0.2158 - val_loss: 0.6197 - val_acc: 0.2004\n",
      "Epoch 3465/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1894 - acc: 0.2158 - val_loss: 0.6778 - val_acc: 0.1985\n",
      "Epoch 3466/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1886 - acc: 0.2148 - val_loss: 0.6250 - val_acc: 0.2004\n",
      "Epoch 3467/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1983 - acc: 0.2148 - val_loss: 0.8293 - val_acc: 0.2004\n",
      "Epoch 3468/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2112 - acc: 0.2158 - val_loss: 0.6034 - val_acc: 0.2004\n",
      "Epoch 3469/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1927 - acc: 0.2162 - val_loss: 0.7231 - val_acc: 0.1967\n",
      "Epoch 3470/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1919 - acc: 0.2148 - val_loss: 0.6332 - val_acc: 0.2004\n",
      "Epoch 3471/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1883 - acc: 0.2167 - val_loss: 0.6352 - val_acc: 0.2004\n",
      "Epoch 3472/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1974 - acc: 0.2139 - val_loss: 0.6671 - val_acc: 0.1967\n",
      "Epoch 3473/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1960 - acc: 0.2158 - val_loss: 0.6779 - val_acc: 0.2004\n",
      "Epoch 3474/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1771 - acc: 0.2167 - val_loss: 0.6409 - val_acc: 0.1967\n",
      "Epoch 3475/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1920 - acc: 0.2144 - val_loss: 0.6553 - val_acc: 0.2004\n",
      "Epoch 3476/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1744 - acc: 0.2162 - val_loss: 0.6639 - val_acc: 0.1967\n",
      "Epoch 3477/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1915 - acc: 0.2148 - val_loss: 0.7179 - val_acc: 0.1967\n",
      "Epoch 3478/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1748 - acc: 0.2158 - val_loss: 0.6064 - val_acc: 0.2004\n",
      "Epoch 3479/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1893 - acc: 0.2162 - val_loss: 0.6511 - val_acc: 0.2004\n",
      "Epoch 3480/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1767 - acc: 0.2153 - val_loss: 0.6068 - val_acc: 0.2004\n",
      "Epoch 3481/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1748 - acc: 0.2153 - val_loss: 0.6938 - val_acc: 0.2004\n",
      "Epoch 3482/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1801 - acc: 0.2148 - val_loss: 0.6157 - val_acc: 0.2004\n",
      "Epoch 3483/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1668 - acc: 0.2162 - val_loss: 0.6208 - val_acc: 0.2004\n",
      "Epoch 3484/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1778 - acc: 0.2158 - val_loss: 0.6143 - val_acc: 0.2004\n",
      "Epoch 3485/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1768 - acc: 0.2158 - val_loss: 0.6377 - val_acc: 0.2004\n",
      "Epoch 3486/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1633 - acc: 0.2158 - val_loss: 0.6149 - val_acc: 0.2004\n",
      "Epoch 3487/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1764 - acc: 0.2162 - val_loss: 0.6717 - val_acc: 0.2004\n",
      "Epoch 3488/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1822 - acc: 0.2148 - val_loss: 0.6348 - val_acc: 0.1985\n",
      "Epoch 3489/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1910 - acc: 0.2162 - val_loss: 0.7442 - val_acc: 0.2004\n",
      "Epoch 3490/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1881 - acc: 0.2148 - val_loss: 0.5937 - val_acc: 0.2004\n",
      "Epoch 3491/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1755 - acc: 0.2148 - val_loss: 0.6524 - val_acc: 0.1985\n",
      "Epoch 3492/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2114 - acc: 0.2148 - val_loss: 0.7213 - val_acc: 0.2004\n",
      "Epoch 3493/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1768 - acc: 0.2158 - val_loss: 0.6608 - val_acc: 0.2004\n",
      "Epoch 3494/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1902 - acc: 0.2158 - val_loss: 0.6705 - val_acc: 0.1967\n",
      "Epoch 3495/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1915 - acc: 0.2144 - val_loss: 0.6395 - val_acc: 0.2004\n",
      "Epoch 3496/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1731 - acc: 0.2167 - val_loss: 0.6490 - val_acc: 0.2004\n",
      "Epoch 3497/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1740 - acc: 0.2162 - val_loss: 0.6386 - val_acc: 0.2004\n",
      "Epoch 3498/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1951 - acc: 0.2153 - val_loss: 0.5768 - val_acc: 0.2004\n",
      "Epoch 3499/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2399 - acc: 0.2144 - val_loss: 0.7164 - val_acc: 0.2004\n",
      "Epoch 3500/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2691 - acc: 0.2158 - val_loss: 0.6365 - val_acc: 0.2004\n",
      "Epoch 3501/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3030 - acc: 0.2153 - val_loss: 0.7657 - val_acc: 0.2004\n",
      "Epoch 3502/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3142 - acc: 0.2139 - val_loss: 0.9864 - val_acc: 0.1948\n",
      "Epoch 3503/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2775 - acc: 0.2153 - val_loss: 0.5902 - val_acc: 0.2004\n",
      "Epoch 3504/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3306 - acc: 0.2162 - val_loss: 0.7383 - val_acc: 0.1948\n",
      "Epoch 3505/4000\n",
      "68/68 [==============================] - 5s 72ms/step - loss: 0.2412 - acc: 0.2153 - val_loss: 0.5700 - val_acc: 0.2004\n",
      "Epoch 3506/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2523 - acc: 0.2167 - val_loss: 0.8073 - val_acc: 0.2004\n",
      "Epoch 3507/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2713 - acc: 0.2158 - val_loss: 0.5786 - val_acc: 0.2004\n",
      "Epoch 3508/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1941 - acc: 0.2153 - val_loss: 0.6150 - val_acc: 0.2004\n",
      "Epoch 3509/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1728 - acc: 0.2162 - val_loss: 0.5981 - val_acc: 0.2004\n",
      "Epoch 3510/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1906 - acc: 0.2158 - val_loss: 0.6177 - val_acc: 0.2004\n",
      "Epoch 3511/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1841 - acc: 0.2162 - val_loss: 0.7129 - val_acc: 0.2004\n",
      "Epoch 3512/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1909 - acc: 0.2158 - val_loss: 0.5945 - val_acc: 0.2004\n",
      "Epoch 3513/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1854 - acc: 0.2158 - val_loss: 0.6861 - val_acc: 0.1967\n",
      "Epoch 3514/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1895 - acc: 0.2148 - val_loss: 0.6465 - val_acc: 0.2004\n",
      "Epoch 3515/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2022 - acc: 0.2167 - val_loss: 0.6578 - val_acc: 0.2004\n",
      "Epoch 3516/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1804 - acc: 0.2162 - val_loss: 0.6182 - val_acc: 0.2004\n",
      "Epoch 3517/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1841 - acc: 0.2162 - val_loss: 0.6224 - val_acc: 0.2004\n",
      "Epoch 3518/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1691 - acc: 0.2158 - val_loss: 0.6217 - val_acc: 0.2004\n",
      "Epoch 3519/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1649 - acc: 0.2158 - val_loss: 0.6093 - val_acc: 0.2004\n",
      "Epoch 3520/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1723 - acc: 0.2162 - val_loss: 0.6096 - val_acc: 0.2004\n",
      "Epoch 3521/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1634 - acc: 0.2162 - val_loss: 0.6159 - val_acc: 0.2004\n",
      "Epoch 3522/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1845 - acc: 0.2148 - val_loss: 0.6697 - val_acc: 0.2004\n",
      "Epoch 3523/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2108 - acc: 0.2153 - val_loss: 0.6128 - val_acc: 0.2004\n",
      "Epoch 3524/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1816 - acc: 0.2167 - val_loss: 0.6713 - val_acc: 0.2004\n",
      "Epoch 3525/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1856 - acc: 0.2144 - val_loss: 0.8552 - val_acc: 0.2004\n",
      "Epoch 3526/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2059 - acc: 0.2162 - val_loss: 0.6130 - val_acc: 0.2004\n",
      "Epoch 3527/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2055 - acc: 0.2144 - val_loss: 0.6224 - val_acc: 0.2004\n",
      "Epoch 3528/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.1741 - acc: 0.2162 - val_loss: 0.6430 - val_acc: 0.2004\n",
      "Epoch 3529/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.1774 - acc: 0.2153 - val_loss: 0.6800 - val_acc: 0.1967\n",
      "Epoch 3530/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2260 - acc: 0.2139 - val_loss: 0.6509 - val_acc: 0.2004\n",
      "Epoch 3531/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1921 - acc: 0.2162 - val_loss: 0.6233 - val_acc: 0.2004\n",
      "Epoch 3532/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1727 - acc: 0.2158 - val_loss: 0.6435 - val_acc: 0.2004\n",
      "Epoch 3533/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1751 - acc: 0.2153 - val_loss: 0.6109 - val_acc: 0.2004\n",
      "Epoch 3534/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1713 - acc: 0.2162 - val_loss: 0.6286 - val_acc: 0.2004\n",
      "Epoch 3535/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1868 - acc: 0.2158 - val_loss: 0.5963 - val_acc: 0.2004\n",
      "Epoch 3536/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1643 - acc: 0.2148 - val_loss: 0.6150 - val_acc: 0.2004\n",
      "Epoch 3537/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1849 - acc: 0.2162 - val_loss: 0.7466 - val_acc: 0.2004\n",
      "Epoch 3538/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1818 - acc: 0.2162 - val_loss: 0.6919 - val_acc: 0.2004\n",
      "Epoch 3539/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1689 - acc: 0.2153 - val_loss: 0.6389 - val_acc: 0.2004\n",
      "Epoch 3540/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1665 - acc: 0.2153 - val_loss: 0.6484 - val_acc: 0.2004\n",
      "Epoch 3541/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1843 - acc: 0.2148 - val_loss: 0.6699 - val_acc: 0.2004\n",
      "Epoch 3542/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.1894 - acc: 0.2148 - val_loss: 0.6388 - val_acc: 0.2004\n",
      "Epoch 3543/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2004 - acc: 0.2144 - val_loss: 0.6078 - val_acc: 0.2004\n",
      "Epoch 3544/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1743 - acc: 0.2153 - val_loss: 0.6252 - val_acc: 0.2004\n",
      "Epoch 3545/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2259 - acc: 0.2130 - val_loss: 0.6600 - val_acc: 0.2004\n",
      "Epoch 3546/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1910 - acc: 0.2153 - val_loss: 0.6558 - val_acc: 0.1985\n",
      "Epoch 3547/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1684 - acc: 0.2167 - val_loss: 0.7576 - val_acc: 0.2004\n",
      "Epoch 3548/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1736 - acc: 0.2148 - val_loss: 0.7280 - val_acc: 0.2004\n",
      "Epoch 3549/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1947 - acc: 0.2158 - val_loss: 0.6104 - val_acc: 0.2004\n",
      "Epoch 3550/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2011 - acc: 0.2153 - val_loss: 0.6398 - val_acc: 0.2004\n",
      "Epoch 3551/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1876 - acc: 0.2144 - val_loss: 0.6342 - val_acc: 0.2004\n",
      "Epoch 3552/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1904 - acc: 0.2148 - val_loss: 0.7090 - val_acc: 0.2004\n",
      "Epoch 3553/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1821 - acc: 0.2158 - val_loss: 0.6675 - val_acc: 0.1967\n",
      "Epoch 3554/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2176 - acc: 0.2158 - val_loss: 0.6176 - val_acc: 0.2004\n",
      "Epoch 3555/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1723 - acc: 0.2162 - val_loss: 0.6092 - val_acc: 0.2004\n",
      "Epoch 3556/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1648 - acc: 0.2158 - val_loss: 0.6105 - val_acc: 0.2004\n",
      "Epoch 3557/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1825 - acc: 0.2158 - val_loss: 0.5905 - val_acc: 0.2004\n",
      "Epoch 3558/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1705 - acc: 0.2144 - val_loss: 0.6649 - val_acc: 0.1985\n",
      "Epoch 3559/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1821 - acc: 0.2158 - val_loss: 0.6531 - val_acc: 0.2004\n",
      "Epoch 3560/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1938 - acc: 0.2144 - val_loss: 0.6461 - val_acc: 0.2004\n",
      "Epoch 3561/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1845 - acc: 0.2153 - val_loss: 0.6580 - val_acc: 0.2004\n",
      "Epoch 3562/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1760 - acc: 0.2162 - val_loss: 0.6188 - val_acc: 0.2004\n",
      "Epoch 3563/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1798 - acc: 0.2153 - val_loss: 0.6861 - val_acc: 0.1967\n",
      "Epoch 3564/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1915 - acc: 0.2153 - val_loss: 0.6512 - val_acc: 0.2004\n",
      "Epoch 3565/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1710 - acc: 0.2153 - val_loss: 0.6684 - val_acc: 0.1985\n",
      "Epoch 3566/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1900 - acc: 0.2158 - val_loss: 0.6453 - val_acc: 0.2004\n",
      "Epoch 3567/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1908 - acc: 0.2148 - val_loss: 0.7368 - val_acc: 0.1967\n",
      "Epoch 3568/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1807 - acc: 0.2153 - val_loss: 0.6771 - val_acc: 0.2004\n",
      "Epoch 3569/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1988 - acc: 0.2144 - val_loss: 0.5993 - val_acc: 0.2004\n",
      "Epoch 3570/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1725 - acc: 0.2158 - val_loss: 0.6166 - val_acc: 0.2004\n",
      "Epoch 3571/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1681 - acc: 0.2167 - val_loss: 0.6709 - val_acc: 0.2004\n",
      "Epoch 3572/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1699 - acc: 0.2162 - val_loss: 0.6926 - val_acc: 0.1967\n",
      "Epoch 3573/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1803 - acc: 0.2158 - val_loss: 0.6823 - val_acc: 0.1967\n",
      "Epoch 3574/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1791 - acc: 0.2148 - val_loss: 0.6430 - val_acc: 0.2004\n",
      "Epoch 3575/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1832 - acc: 0.2158 - val_loss: 0.6387 - val_acc: 0.2004\n",
      "Epoch 3576/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1674 - acc: 0.2148 - val_loss: 0.6105 - val_acc: 0.2004\n",
      "Epoch 3577/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1722 - acc: 0.2153 - val_loss: 0.6473 - val_acc: 0.2004\n",
      "Epoch 3578/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1708 - acc: 0.2158 - val_loss: 0.6764 - val_acc: 0.1967\n",
      "Epoch 3579/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1982 - acc: 0.2148 - val_loss: 0.6227 - val_acc: 0.2004\n",
      "Epoch 3580/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1751 - acc: 0.2158 - val_loss: 0.6255 - val_acc: 0.2004\n",
      "Epoch 3581/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1766 - acc: 0.2162 - val_loss: 0.6594 - val_acc: 0.2004\n",
      "Epoch 3582/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1727 - acc: 0.2162 - val_loss: 0.6527 - val_acc: 0.2004\n",
      "Epoch 3583/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1782 - acc: 0.2167 - val_loss: 0.6447 - val_acc: 0.2004\n",
      "Epoch 3584/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1946 - acc: 0.2158 - val_loss: 0.7337 - val_acc: 0.2004\n",
      "Epoch 3585/4000\n",
      "68/68 [==============================] - 5s 69ms/step - loss: 0.2764 - acc: 0.2111 - val_loss: 2.2960 - val_acc: 0.2004\n",
      "Epoch 3586/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4239 - acc: 0.2116 - val_loss: 0.6999 - val_acc: 0.2004\n",
      "Epoch 3587/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1930 - acc: 0.2158 - val_loss: 0.6378 - val_acc: 0.2004\n",
      "Epoch 3588/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3730 - acc: 0.2162 - val_loss: 0.8752 - val_acc: 0.2004\n",
      "Epoch 3589/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2357 - acc: 0.2162 - val_loss: 0.7640 - val_acc: 0.1967\n",
      "Epoch 3590/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2156 - acc: 0.2153 - val_loss: 0.5490 - val_acc: 0.2004\n",
      "Epoch 3591/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1996 - acc: 0.2158 - val_loss: 0.6083 - val_acc: 0.2004\n",
      "Epoch 3592/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1887 - acc: 0.2144 - val_loss: 0.6960 - val_acc: 0.2004\n",
      "Epoch 3593/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2210 - acc: 0.2144 - val_loss: 0.6217 - val_acc: 0.2004\n",
      "Epoch 3594/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1766 - acc: 0.2162 - val_loss: 0.5981 - val_acc: 0.2004\n",
      "Epoch 3595/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1679 - acc: 0.2162 - val_loss: 0.6607 - val_acc: 0.2004\n",
      "Epoch 3596/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1722 - acc: 0.2158 - val_loss: 0.7168 - val_acc: 0.2004\n",
      "Epoch 3597/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1702 - acc: 0.2139 - val_loss: 0.6305 - val_acc: 0.2004\n",
      "Epoch 3598/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1752 - acc: 0.2158 - val_loss: 0.6288 - val_acc: 0.2004\n",
      "Epoch 3599/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1920 - acc: 0.2144 - val_loss: 0.6277 - val_acc: 0.2004\n",
      "Epoch 3600/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1648 - acc: 0.2148 - val_loss: 0.6522 - val_acc: 0.2004\n",
      "Epoch 3601/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1918 - acc: 0.2139 - val_loss: 0.6266 - val_acc: 0.2004\n",
      "Epoch 3602/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1715 - acc: 0.2153 - val_loss: 0.6914 - val_acc: 0.1967\n",
      "Epoch 3603/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1771 - acc: 0.2162 - val_loss: 0.6085 - val_acc: 0.2004\n",
      "Epoch 3604/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1699 - acc: 0.2153 - val_loss: 0.6773 - val_acc: 0.1967\n",
      "Epoch 3605/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1657 - acc: 0.2162 - val_loss: 0.6690 - val_acc: 0.2004\n",
      "Epoch 3606/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1666 - acc: 0.2158 - val_loss: 0.6862 - val_acc: 0.2004\n",
      "Epoch 3607/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1771 - acc: 0.2148 - val_loss: 0.7034 - val_acc: 0.2004\n",
      "Epoch 3608/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1825 - acc: 0.2148 - val_loss: 0.6748 - val_acc: 0.2004\n",
      "Epoch 3609/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1717 - acc: 0.2158 - val_loss: 0.6058 - val_acc: 0.2004\n",
      "Epoch 3610/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1781 - acc: 0.2158 - val_loss: 0.6411 - val_acc: 0.2004\n",
      "Epoch 3611/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1673 - acc: 0.2153 - val_loss: 0.6225 - val_acc: 0.2004\n",
      "Epoch 3612/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1681 - acc: 0.2148 - val_loss: 0.7706 - val_acc: 0.1967\n",
      "Epoch 3613/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1739 - acc: 0.2139 - val_loss: 0.6571 - val_acc: 0.2004\n",
      "Epoch 3614/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1788 - acc: 0.2153 - val_loss: 0.9559 - val_acc: 0.1874\n",
      "Epoch 3615/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2426 - acc: 0.2097 - val_loss: 0.6366 - val_acc: 0.2004\n",
      "Epoch 3616/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1606 - acc: 0.2167 - val_loss: 0.6428 - val_acc: 0.2004\n",
      "Epoch 3617/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1758 - acc: 0.2162 - val_loss: 0.6884 - val_acc: 0.2004\n",
      "Epoch 3618/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1772 - acc: 0.2153 - val_loss: 0.6577 - val_acc: 0.2004\n",
      "Epoch 3619/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1730 - acc: 0.2158 - val_loss: 0.7423 - val_acc: 0.2004\n",
      "Epoch 3620/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1742 - acc: 0.2162 - val_loss: 0.6068 - val_acc: 0.2004\n",
      "Epoch 3621/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1808 - acc: 0.2148 - val_loss: 0.6381 - val_acc: 0.2004\n",
      "Epoch 3622/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1711 - acc: 0.2162 - val_loss: 0.6475 - val_acc: 0.2004\n",
      "Epoch 3623/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1679 - acc: 0.2148 - val_loss: 0.6493 - val_acc: 0.2004\n",
      "Epoch 3624/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1776 - acc: 0.2167 - val_loss: 0.6802 - val_acc: 0.2004\n",
      "Epoch 3625/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1701 - acc: 0.2162 - val_loss: 0.7636 - val_acc: 0.1948\n",
      "Epoch 3626/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1806 - acc: 0.2148 - val_loss: 0.6828 - val_acc: 0.2004\n",
      "Epoch 3627/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2226 - acc: 0.2153 - val_loss: 0.6180 - val_acc: 0.2004\n",
      "Epoch 3628/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1665 - acc: 0.2162 - val_loss: 0.6246 - val_acc: 0.2004\n",
      "Epoch 3629/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2078 - acc: 0.2139 - val_loss: 0.7624 - val_acc: 0.2004\n",
      "Epoch 3630/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1675 - acc: 0.2167 - val_loss: 0.6431 - val_acc: 0.2004\n",
      "Epoch 3631/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1615 - acc: 0.2153 - val_loss: 0.6415 - val_acc: 0.2004\n",
      "Epoch 3632/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1728 - acc: 0.2158 - val_loss: 0.6546 - val_acc: 0.2004\n",
      "Epoch 3633/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1634 - acc: 0.2162 - val_loss: 0.6746 - val_acc: 0.2004\n",
      "Epoch 3634/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1871 - acc: 0.2153 - val_loss: 0.6497 - val_acc: 0.2004\n",
      "Epoch 3635/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1668 - acc: 0.2158 - val_loss: 0.7149 - val_acc: 0.1967\n",
      "Epoch 3636/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1643 - acc: 0.2162 - val_loss: 0.6633 - val_acc: 0.2004\n",
      "Epoch 3637/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1800 - acc: 0.2158 - val_loss: 0.8885 - val_acc: 0.2004\n",
      "Epoch 3638/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1857 - acc: 0.2158 - val_loss: 0.6828 - val_acc: 0.2004\n",
      "Epoch 3639/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1754 - acc: 0.2148 - val_loss: 0.6397 - val_acc: 0.2004\n",
      "Epoch 3640/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1757 - acc: 0.2153 - val_loss: 0.6163 - val_acc: 0.2004\n",
      "Epoch 3641/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1707 - acc: 0.2153 - val_loss: 0.6109 - val_acc: 0.2004\n",
      "Epoch 3642/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1832 - acc: 0.2148 - val_loss: 0.6459 - val_acc: 0.2004\n",
      "Epoch 3643/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1859 - acc: 0.2153 - val_loss: 0.6479 - val_acc: 0.2004\n",
      "Epoch 3644/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1647 - acc: 0.2153 - val_loss: 0.6825 - val_acc: 0.2004\n",
      "Epoch 3645/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1774 - acc: 0.2162 - val_loss: 0.6049 - val_acc: 0.2004\n",
      "Epoch 3646/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1855 - acc: 0.2162 - val_loss: 0.7084 - val_acc: 0.1967\n",
      "Epoch 3647/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1896 - acc: 0.2153 - val_loss: 0.7172 - val_acc: 0.2004\n",
      "Epoch 3648/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1852 - acc: 0.2139 - val_loss: 0.6797 - val_acc: 0.2004\n",
      "Epoch 3649/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1742 - acc: 0.2158 - val_loss: 0.6096 - val_acc: 0.2004\n",
      "Epoch 3650/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1785 - acc: 0.2148 - val_loss: 0.6658 - val_acc: 0.2004\n",
      "Epoch 3651/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1726 - acc: 0.2153 - val_loss: 0.6410 - val_acc: 0.1985\n",
      "Epoch 3652/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1853 - acc: 0.2153 - val_loss: 0.6608 - val_acc: 0.2004\n",
      "Epoch 3653/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1913 - acc: 0.2167 - val_loss: 0.7426 - val_acc: 0.2004\n",
      "Epoch 3654/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2725 - acc: 0.2148 - val_loss: 0.7557 - val_acc: 0.1967\n",
      "Epoch 3655/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2118 - acc: 0.2153 - val_loss: 0.7368 - val_acc: 0.2004\n",
      "Epoch 3656/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1935 - acc: 0.2167 - val_loss: 0.6570 - val_acc: 0.2004\n",
      "Epoch 3657/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1859 - acc: 0.2144 - val_loss: 0.6770 - val_acc: 0.1967\n",
      "Epoch 3658/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1901 - acc: 0.2158 - val_loss: 0.7324 - val_acc: 0.1967\n",
      "Epoch 3659/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1791 - acc: 0.2153 - val_loss: 0.6917 - val_acc: 0.2004\n",
      "Epoch 3660/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1604 - acc: 0.2162 - val_loss: 0.6474 - val_acc: 0.2004\n",
      "Epoch 3661/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1752 - acc: 0.2162 - val_loss: 0.7010 - val_acc: 0.1967\n",
      "Epoch 3662/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1690 - acc: 0.2135 - val_loss: 0.6374 - val_acc: 0.2004\n",
      "Epoch 3663/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1948 - acc: 0.2158 - val_loss: 0.6288 - val_acc: 0.2004\n",
      "Epoch 3664/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1674 - acc: 0.2158 - val_loss: 0.7183 - val_acc: 0.2004\n",
      "Epoch 3665/4000\n",
      "68/68 [==============================] - 5s 70ms/step - loss: 0.1804 - acc: 0.2153 - val_loss: 0.6536 - val_acc: 0.2004\n",
      "Epoch 3666/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1697 - acc: 0.2153 - val_loss: 0.7142 - val_acc: 0.1967\n",
      "Epoch 3667/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1708 - acc: 0.2158 - val_loss: 0.7118 - val_acc: 0.1967\n",
      "Epoch 3668/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1792 - acc: 0.2153 - val_loss: 0.6015 - val_acc: 0.2004\n",
      "Epoch 3669/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1978 - acc: 0.2158 - val_loss: 0.7530 - val_acc: 0.1967\n",
      "Epoch 3670/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1789 - acc: 0.2162 - val_loss: 0.6668 - val_acc: 0.2004\n",
      "Epoch 3671/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2715 - acc: 0.2139 - val_loss: 0.6620 - val_acc: 0.2004\n",
      "Epoch 3672/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2048 - acc: 0.2153 - val_loss: 0.6388 - val_acc: 0.2004\n",
      "Epoch 3673/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1858 - acc: 0.2158 - val_loss: 0.6098 - val_acc: 0.2004\n",
      "Epoch 3674/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1919 - acc: 0.2153 - val_loss: 0.6245 - val_acc: 0.2004\n",
      "Epoch 3675/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2505 - acc: 0.2153 - val_loss: 0.6498 - val_acc: 0.2004\n",
      "Epoch 3676/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1920 - acc: 0.2148 - val_loss: 0.7100 - val_acc: 0.2004\n",
      "Epoch 3677/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2232 - acc: 0.2158 - val_loss: 0.6442 - val_acc: 0.2004\n",
      "Epoch 3678/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1663 - acc: 0.2153 - val_loss: 0.6396 - val_acc: 0.2004\n",
      "Epoch 3679/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1890 - acc: 0.2144 - val_loss: 0.8245 - val_acc: 0.1929\n",
      "Epoch 3680/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1955 - acc: 0.2153 - val_loss: 0.6517 - val_acc: 0.2004\n",
      "Epoch 3681/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1659 - acc: 0.2158 - val_loss: 0.7448 - val_acc: 0.2004\n",
      "Epoch 3682/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1692 - acc: 0.2162 - val_loss: 0.6227 - val_acc: 0.2004\n",
      "Epoch 3683/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1868 - acc: 0.2158 - val_loss: 0.6271 - val_acc: 0.2004\n",
      "Epoch 3684/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1691 - acc: 0.2162 - val_loss: 0.7853 - val_acc: 0.1967\n",
      "Epoch 3685/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1782 - acc: 0.2148 - val_loss: 0.6507 - val_acc: 0.2004\n",
      "Epoch 3686/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1979 - acc: 0.2162 - val_loss: 0.6501 - val_acc: 0.2004\n",
      "Epoch 3687/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1649 - acc: 0.2158 - val_loss: 0.6668 - val_acc: 0.2004\n",
      "Epoch 3688/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1618 - acc: 0.2162 - val_loss: 0.6337 - val_acc: 0.2004\n",
      "Epoch 3689/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1861 - acc: 0.2148 - val_loss: 0.6813 - val_acc: 0.2004\n",
      "Epoch 3690/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1792 - acc: 0.2158 - val_loss: 0.6647 - val_acc: 0.2004\n",
      "Epoch 3691/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1787 - acc: 0.2139 - val_loss: 0.6625 - val_acc: 0.2004\n",
      "Epoch 3692/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1878 - acc: 0.2144 - val_loss: 0.6346 - val_acc: 0.2004\n",
      "Epoch 3693/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1691 - acc: 0.2162 - val_loss: 0.6574 - val_acc: 0.2004\n",
      "Epoch 3694/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1886 - acc: 0.2148 - val_loss: 0.6763 - val_acc: 0.2004\n",
      "Epoch 3695/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1849 - acc: 0.2148 - val_loss: 0.6395 - val_acc: 0.2004\n",
      "Epoch 3696/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1766 - acc: 0.2153 - val_loss: 0.6833 - val_acc: 0.1967\n",
      "Epoch 3697/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1640 - acc: 0.2167 - val_loss: 0.6355 - val_acc: 0.2004\n",
      "Epoch 3698/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1733 - acc: 0.2158 - val_loss: 0.7641 - val_acc: 0.2004\n",
      "Epoch 3699/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2257 - acc: 0.2139 - val_loss: 0.6202 - val_acc: 0.2004\n",
      "Epoch 3700/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1723 - acc: 0.2162 - val_loss: 0.7171 - val_acc: 0.1967\n",
      "Epoch 3701/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1807 - acc: 0.2153 - val_loss: 0.6196 - val_acc: 0.2004\n",
      "Epoch 3702/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1587 - acc: 0.2158 - val_loss: 0.6375 - val_acc: 0.2004\n",
      "Epoch 3703/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1747 - acc: 0.2153 - val_loss: 0.6683 - val_acc: 0.2004\n",
      "Epoch 3704/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1759 - acc: 0.2144 - val_loss: 0.6397 - val_acc: 0.2004\n",
      "Epoch 3705/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1691 - acc: 0.2162 - val_loss: 0.7636 - val_acc: 0.2004\n",
      "Epoch 3706/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1778 - acc: 0.2162 - val_loss: 0.6814 - val_acc: 0.1967\n",
      "Epoch 3707/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1745 - acc: 0.2158 - val_loss: 0.6448 - val_acc: 0.2004\n",
      "Epoch 3708/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1704 - acc: 0.2167 - val_loss: 0.6537 - val_acc: 0.2004\n",
      "Epoch 3709/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1805 - acc: 0.2148 - val_loss: 0.6492 - val_acc: 0.2004\n",
      "Epoch 3710/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1792 - acc: 0.2148 - val_loss: 0.6753 - val_acc: 0.2004\n",
      "Epoch 3711/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2142 - acc: 0.2135 - val_loss: 0.7131 - val_acc: 0.2004\n",
      "Epoch 3712/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2630 - acc: 0.2148 - val_loss: 0.6369 - val_acc: 0.2004\n",
      "Epoch 3713/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2151 - acc: 0.2148 - val_loss: 0.6853 - val_acc: 0.2004\n",
      "Epoch 3714/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1681 - acc: 0.2167 - val_loss: 0.5935 - val_acc: 0.2004\n",
      "Epoch 3715/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1887 - acc: 0.2148 - val_loss: 0.6414 - val_acc: 0.2004\n",
      "Epoch 3716/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.1904 - acc: 0.2148 - val_loss: 0.6304 - val_acc: 0.2004\n",
      "Epoch 3717/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1750 - acc: 0.2158 - val_loss: 0.6706 - val_acc: 0.2004\n",
      "Epoch 3718/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1992 - acc: 0.2148 - val_loss: 0.6295 - val_acc: 0.2004\n",
      "Epoch 3719/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2047 - acc: 0.2158 - val_loss: 0.6418 - val_acc: 0.2004\n",
      "Epoch 3720/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1582 - acc: 0.2158 - val_loss: 0.6585 - val_acc: 0.2004\n",
      "Epoch 3721/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1813 - acc: 0.2148 - val_loss: 0.6367 - val_acc: 0.2004\n",
      "Epoch 3722/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1728 - acc: 0.2162 - val_loss: 0.6752 - val_acc: 0.1967\n",
      "Epoch 3723/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1744 - acc: 0.2148 - val_loss: 0.6884 - val_acc: 0.2004\n",
      "Epoch 3724/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1758 - acc: 0.2158 - val_loss: 0.6258 - val_acc: 0.2004\n",
      "Epoch 3725/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1684 - acc: 0.2148 - val_loss: 0.6884 - val_acc: 0.2004\n",
      "Epoch 3726/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1722 - acc: 0.2158 - val_loss: 0.6771 - val_acc: 0.2004\n",
      "Epoch 3727/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1742 - acc: 0.2162 - val_loss: 0.7161 - val_acc: 0.1985\n",
      "Epoch 3728/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1773 - acc: 0.2162 - val_loss: 0.7394 - val_acc: 0.1967\n",
      "Epoch 3729/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1701 - acc: 0.2158 - val_loss: 0.6358 - val_acc: 0.2004\n",
      "Epoch 3730/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1828 - acc: 0.2167 - val_loss: 0.6629 - val_acc: 0.2004\n",
      "Epoch 3731/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2113 - acc: 0.2153 - val_loss: 0.7337 - val_acc: 0.1967\n",
      "Epoch 3732/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1745 - acc: 0.2153 - val_loss: 0.6571 - val_acc: 0.2004\n",
      "Epoch 3733/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1663 - acc: 0.2158 - val_loss: 0.7050 - val_acc: 0.1967\n",
      "Epoch 3734/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1818 - acc: 0.2153 - val_loss: 0.7278 - val_acc: 0.2004\n",
      "Epoch 3735/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1741 - acc: 0.2162 - val_loss: 0.6104 - val_acc: 0.2004\n",
      "Epoch 3736/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1709 - acc: 0.2162 - val_loss: 0.6264 - val_acc: 0.2004\n",
      "Epoch 3737/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1768 - acc: 0.2162 - val_loss: 0.8989 - val_acc: 0.2004\n",
      "Epoch 3738/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1812 - acc: 0.2153 - val_loss: 0.6063 - val_acc: 0.2004\n",
      "Epoch 3739/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1663 - acc: 0.2162 - val_loss: 0.6822 - val_acc: 0.1985\n",
      "Epoch 3740/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1686 - acc: 0.2153 - val_loss: 0.6823 - val_acc: 0.2004\n",
      "Epoch 3741/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2720 - acc: 0.2130 - val_loss: 0.6277 - val_acc: 0.2004\n",
      "Epoch 3742/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1950 - acc: 0.2162 - val_loss: 0.6312 - val_acc: 0.2004\n",
      "Epoch 3743/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1763 - acc: 0.2158 - val_loss: 0.6446 - val_acc: 0.2004\n",
      "Epoch 3744/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.1608 - acc: 0.2162 - val_loss: 0.6323 - val_acc: 0.2004\n",
      "Epoch 3745/4000\n",
      "68/68 [==============================] - 5s 69ms/step - loss: 0.1604 - acc: 0.2158 - val_loss: 0.6730 - val_acc: 0.2004\n",
      "Epoch 3746/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1723 - acc: 0.2139 - val_loss: 0.7320 - val_acc: 0.1967\n",
      "Epoch 3747/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1748 - acc: 0.2148 - val_loss: 0.6501 - val_acc: 0.2004\n",
      "Epoch 3748/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1749 - acc: 0.2158 - val_loss: 0.6460 - val_acc: 0.1985\n",
      "Epoch 3749/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1880 - acc: 0.2148 - val_loss: 0.6214 - val_acc: 0.2004\n",
      "Epoch 3750/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1675 - acc: 0.2158 - val_loss: 0.6346 - val_acc: 0.2004\n",
      "Epoch 3751/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1768 - acc: 0.2158 - val_loss: 0.7049 - val_acc: 0.2004\n",
      "Epoch 3752/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1695 - acc: 0.2167 - val_loss: 0.6264 - val_acc: 0.2004\n",
      "Epoch 3753/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1839 - acc: 0.2158 - val_loss: 0.7512 - val_acc: 0.2004\n",
      "Epoch 3754/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1850 - acc: 0.2144 - val_loss: 0.6352 - val_acc: 0.2004\n",
      "Epoch 3755/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1807 - acc: 0.2153 - val_loss: 0.6666 - val_acc: 0.1985\n",
      "Epoch 3756/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1730 - acc: 0.2153 - val_loss: 0.6556 - val_acc: 0.2004\n",
      "Epoch 3757/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1713 - acc: 0.2148 - val_loss: 0.6314 - val_acc: 0.2004\n",
      "Epoch 3758/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1745 - acc: 0.2158 - val_loss: 0.6291 - val_acc: 0.2004\n",
      "Epoch 3759/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1608 - acc: 0.2153 - val_loss: 0.6768 - val_acc: 0.1985\n",
      "Epoch 3760/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1846 - acc: 0.2144 - val_loss: 0.6572 - val_acc: 0.2004\n",
      "Epoch 3761/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1852 - acc: 0.2153 - val_loss: 0.8054 - val_acc: 0.1929\n",
      "Epoch 3762/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1815 - acc: 0.2162 - val_loss: 0.6659 - val_acc: 0.2004\n",
      "Epoch 3763/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1856 - acc: 0.2148 - val_loss: 0.6282 - val_acc: 0.2004\n",
      "Epoch 3764/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1784 - acc: 0.2148 - val_loss: 0.6760 - val_acc: 0.2004\n",
      "Epoch 3765/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1711 - acc: 0.2167 - val_loss: 0.6421 - val_acc: 0.2004\n",
      "Epoch 3766/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1793 - acc: 0.2148 - val_loss: 0.7041 - val_acc: 0.1967\n",
      "Epoch 3767/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2017 - acc: 0.2144 - val_loss: 0.6220 - val_acc: 0.2004\n",
      "Epoch 3768/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1686 - acc: 0.2158 - val_loss: 0.6863 - val_acc: 0.2004\n",
      "Epoch 3769/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1880 - acc: 0.2153 - val_loss: 0.6483 - val_acc: 0.2004\n",
      "Epoch 3770/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1955 - acc: 0.2148 - val_loss: 0.7259 - val_acc: 0.1967\n",
      "Epoch 3771/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1596 - acc: 0.2162 - val_loss: 0.6263 - val_acc: 0.2004\n",
      "Epoch 3772/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1712 - acc: 0.2167 - val_loss: 0.7643 - val_acc: 0.2004\n",
      "Epoch 3773/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1762 - acc: 0.2144 - val_loss: 0.6533 - val_acc: 0.2004\n",
      "Epoch 3774/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1808 - acc: 0.2148 - val_loss: 0.7102 - val_acc: 0.2004\n",
      "Epoch 3775/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1764 - acc: 0.2158 - val_loss: 0.6752 - val_acc: 0.2004\n",
      "Epoch 3776/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1804 - acc: 0.2153 - val_loss: 0.6440 - val_acc: 0.2004\n",
      "Epoch 3777/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1724 - acc: 0.2153 - val_loss: 0.6774 - val_acc: 0.1985\n",
      "Epoch 3778/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2009 - acc: 0.2158 - val_loss: 0.6399 - val_acc: 0.2004\n",
      "Epoch 3779/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2422 - acc: 0.2148 - val_loss: 0.6118 - val_acc: 0.2004\n",
      "Epoch 3780/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3290 - acc: 0.2153 - val_loss: 0.7711 - val_acc: 0.2004\n",
      "Epoch 3781/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4018 - acc: 0.2144 - val_loss: 0.7165 - val_acc: 0.2004\n",
      "Epoch 3782/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3179 - acc: 0.2162 - val_loss: 1.0998 - val_acc: 0.2004\n",
      "Epoch 3783/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2966 - acc: 0.2139 - val_loss: 0.6811 - val_acc: 0.2004\n",
      "Epoch 3784/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2011 - acc: 0.2158 - val_loss: 0.7019 - val_acc: 0.2004\n",
      "Epoch 3785/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1893 - acc: 0.2153 - val_loss: 0.6551 - val_acc: 0.2004\n",
      "Epoch 3786/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1686 - acc: 0.2162 - val_loss: 0.6667 - val_acc: 0.2004\n",
      "Epoch 3787/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1668 - acc: 0.2153 - val_loss: 0.6963 - val_acc: 0.2004\n",
      "Epoch 3788/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1674 - acc: 0.2167 - val_loss: 0.6437 - val_acc: 0.2004\n",
      "Epoch 3789/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1689 - acc: 0.2158 - val_loss: 0.6330 - val_acc: 0.2004\n",
      "Epoch 3790/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1705 - acc: 0.2153 - val_loss: 0.7001 - val_acc: 0.1967\n",
      "Epoch 3791/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1656 - acc: 0.2162 - val_loss: 0.7100 - val_acc: 0.2004\n",
      "Epoch 3792/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1692 - acc: 0.2162 - val_loss: 0.6344 - val_acc: 0.2004\n",
      "Epoch 3793/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1698 - acc: 0.2158 - val_loss: 0.6382 - val_acc: 0.2004\n",
      "Epoch 3794/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1646 - acc: 0.2158 - val_loss: 0.6385 - val_acc: 0.2004\n",
      "Epoch 3795/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1676 - acc: 0.2148 - val_loss: 0.7490 - val_acc: 0.2004\n",
      "Epoch 3796/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1688 - acc: 0.2158 - val_loss: 0.6299 - val_acc: 0.2004\n",
      "Epoch 3797/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1689 - acc: 0.2153 - val_loss: 0.6435 - val_acc: 0.2004\n",
      "Epoch 3798/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1841 - acc: 0.2148 - val_loss: 0.6525 - val_acc: 0.2004\n",
      "Epoch 3799/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1989 - acc: 0.2148 - val_loss: 0.6715 - val_acc: 0.2004\n",
      "Epoch 3800/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1787 - acc: 0.2158 - val_loss: 0.6513 - val_acc: 0.2004\n",
      "Epoch 3801/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1803 - acc: 0.2144 - val_loss: 0.6374 - val_acc: 0.2004\n",
      "Epoch 3802/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1714 - acc: 0.2158 - val_loss: 0.7181 - val_acc: 0.1967\n",
      "Epoch 3803/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1751 - acc: 0.2158 - val_loss: 0.6796 - val_acc: 0.2004\n",
      "Epoch 3804/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1650 - acc: 0.2158 - val_loss: 0.6722 - val_acc: 0.2004\n",
      "Epoch 3805/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1663 - acc: 0.2158 - val_loss: 0.6403 - val_acc: 0.2004\n",
      "Epoch 3806/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1570 - acc: 0.2167 - val_loss: 0.6474 - val_acc: 0.2004\n",
      "Epoch 3807/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1563 - acc: 0.2153 - val_loss: 0.6410 - val_acc: 0.2004\n",
      "Epoch 3808/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1826 - acc: 0.2153 - val_loss: 0.6619 - val_acc: 0.2004\n",
      "Epoch 3809/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1780 - acc: 0.2148 - val_loss: 0.6447 - val_acc: 0.2004\n",
      "Epoch 3810/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1862 - acc: 0.2153 - val_loss: 0.6488 - val_acc: 0.1967\n",
      "Epoch 3811/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1680 - acc: 0.2153 - val_loss: 0.6480 - val_acc: 0.2004\n",
      "Epoch 3812/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1978 - acc: 0.2153 - val_loss: 0.6982 - val_acc: 0.2004\n",
      "Epoch 3813/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1698 - acc: 0.2167 - val_loss: 0.6530 - val_acc: 0.2004\n",
      "Epoch 3814/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1872 - acc: 0.2153 - val_loss: 0.7196 - val_acc: 0.1985\n",
      "Epoch 3815/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1923 - acc: 0.2158 - val_loss: 0.6443 - val_acc: 0.2004\n",
      "Epoch 3816/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1644 - acc: 0.2153 - val_loss: 0.6822 - val_acc: 0.1985\n",
      "Epoch 3817/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1761 - acc: 0.2144 - val_loss: 0.6607 - val_acc: 0.2004\n",
      "Epoch 3818/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1735 - acc: 0.2153 - val_loss: 0.7264 - val_acc: 0.2004\n",
      "Epoch 3819/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2061 - acc: 0.2139 - val_loss: 0.6977 - val_acc: 0.2004\n",
      "Epoch 3820/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1769 - acc: 0.2144 - val_loss: 0.6727 - val_acc: 0.2004\n",
      "Epoch 3821/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1939 - acc: 0.2148 - val_loss: 0.6994 - val_acc: 0.2004\n",
      "Epoch 3822/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1721 - acc: 0.2162 - val_loss: 0.7260 - val_acc: 0.1985\n",
      "Epoch 3823/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1687 - acc: 0.2158 - val_loss: 0.6456 - val_acc: 0.2004\n",
      "Epoch 3824/4000\n",
      "68/68 [==============================] - 5s 73ms/step - loss: 0.1698 - acc: 0.2162 - val_loss: 0.6632 - val_acc: 0.2004\n",
      "Epoch 3825/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1679 - acc: 0.2162 - val_loss: 0.7049 - val_acc: 0.2004\n",
      "Epoch 3826/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1935 - acc: 0.2162 - val_loss: 0.6453 - val_acc: 0.2004\n",
      "Epoch 3827/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1694 - acc: 0.2148 - val_loss: 0.8756 - val_acc: 0.2004\n",
      "Epoch 3828/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2156 - acc: 0.2153 - val_loss: 0.6726 - val_acc: 0.2004\n",
      "Epoch 3829/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1811 - acc: 0.2162 - val_loss: 0.6913 - val_acc: 0.2004\n",
      "Epoch 3830/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2177 - acc: 0.2158 - val_loss: 0.6554 - val_acc: 0.2004\n",
      "Epoch 3831/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1673 - acc: 0.2148 - val_loss: 0.6667 - val_acc: 0.2004\n",
      "Epoch 3832/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.2309 - acc: 0.2158 - val_loss: 0.7089 - val_acc: 0.2004\n",
      "Epoch 3833/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1923 - acc: 0.2153 - val_loss: 0.6766 - val_acc: 0.2004\n",
      "Epoch 3834/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2537 - acc: 0.2162 - val_loss: 0.6423 - val_acc: 0.2004\n",
      "Epoch 3835/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2904 - acc: 0.2148 - val_loss: 0.8368 - val_acc: 0.1948\n",
      "Epoch 3836/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2382 - acc: 0.2158 - val_loss: 0.7178 - val_acc: 0.2004\n",
      "Epoch 3837/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1936 - acc: 0.2158 - val_loss: 0.6543 - val_acc: 0.2004\n",
      "Epoch 3838/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1676 - acc: 0.2158 - val_loss: 0.6480 - val_acc: 0.2004\n",
      "Epoch 3839/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1688 - acc: 0.2162 - val_loss: 0.6815 - val_acc: 0.2004\n",
      "Epoch 3840/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1619 - acc: 0.2153 - val_loss: 0.6445 - val_acc: 0.2004\n",
      "Epoch 3841/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1745 - acc: 0.2153 - val_loss: 0.6312 - val_acc: 0.2004\n",
      "Epoch 3842/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1611 - acc: 0.2158 - val_loss: 0.6388 - val_acc: 0.2004\n",
      "Epoch 3843/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1541 - acc: 0.2162 - val_loss: 0.8364 - val_acc: 0.1948\n",
      "Epoch 3844/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1738 - acc: 0.2153 - val_loss: 0.6484 - val_acc: 0.2004\n",
      "Epoch 3845/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1787 - acc: 0.2153 - val_loss: 0.6998 - val_acc: 0.1967\n",
      "Epoch 3846/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2375 - acc: 0.2135 - val_loss: 0.7545 - val_acc: 0.1967\n",
      "Epoch 3847/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1872 - acc: 0.2144 - val_loss: 0.6619 - val_acc: 0.2004\n",
      "Epoch 3848/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1703 - acc: 0.2158 - val_loss: 0.6233 - val_acc: 0.2004\n",
      "Epoch 3849/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1671 - acc: 0.2158 - val_loss: 0.6622 - val_acc: 0.2004\n",
      "Epoch 3850/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1680 - acc: 0.2162 - val_loss: 0.6513 - val_acc: 0.2004\n",
      "Epoch 3851/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1845 - acc: 0.2153 - val_loss: 0.6647 - val_acc: 0.2004\n",
      "Epoch 3852/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1802 - acc: 0.2158 - val_loss: 0.6786 - val_acc: 0.2004\n",
      "Epoch 3853/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1641 - acc: 0.2162 - val_loss: 0.7034 - val_acc: 0.1967\n",
      "Epoch 3854/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1928 - acc: 0.2158 - val_loss: 0.6617 - val_acc: 0.2004\n",
      "Epoch 3855/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1830 - acc: 0.2153 - val_loss: 0.6663 - val_acc: 0.2004\n",
      "Epoch 3856/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1657 - acc: 0.2153 - val_loss: 0.6434 - val_acc: 0.2004\n",
      "Epoch 3857/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1739 - acc: 0.2153 - val_loss: 0.6636 - val_acc: 0.2004\n",
      "Epoch 3858/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1718 - acc: 0.2158 - val_loss: 0.6705 - val_acc: 0.2004\n",
      "Epoch 3859/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1872 - acc: 0.2148 - val_loss: 0.6580 - val_acc: 0.2004\n",
      "Epoch 3860/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1767 - acc: 0.2158 - val_loss: 0.6819 - val_acc: 0.1967\n",
      "Epoch 3861/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1687 - acc: 0.2153 - val_loss: 0.6682 - val_acc: 0.2004\n",
      "Epoch 3862/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1647 - acc: 0.2148 - val_loss: 0.7458 - val_acc: 0.1967\n",
      "Epoch 3863/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1777 - acc: 0.2153 - val_loss: 0.6655 - val_acc: 0.2004\n",
      "Epoch 3864/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2122 - acc: 0.2144 - val_loss: 0.6769 - val_acc: 0.2004\n",
      "Epoch 3865/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1889 - acc: 0.2144 - val_loss: 0.6497 - val_acc: 0.2004\n",
      "Epoch 3866/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1650 - acc: 0.2153 - val_loss: 0.6773 - val_acc: 0.2004\n",
      "Epoch 3867/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1646 - acc: 0.2158 - val_loss: 0.6286 - val_acc: 0.2004\n",
      "Epoch 3868/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1695 - acc: 0.2158 - val_loss: 0.6618 - val_acc: 0.1985\n",
      "Epoch 3869/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1758 - acc: 0.2158 - val_loss: 0.6510 - val_acc: 0.2004\n",
      "Epoch 3870/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1706 - acc: 0.2153 - val_loss: 0.6895 - val_acc: 0.2004\n",
      "Epoch 3871/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1935 - acc: 0.2144 - val_loss: 0.7198 - val_acc: 0.1985\n",
      "Epoch 3872/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1632 - acc: 0.2162 - val_loss: 0.7178 - val_acc: 0.1967\n",
      "Epoch 3873/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1865 - acc: 0.2158 - val_loss: 0.6728 - val_acc: 0.2004\n",
      "Epoch 3874/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1925 - acc: 0.2153 - val_loss: 0.6527 - val_acc: 0.2004\n",
      "Epoch 3875/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1787 - acc: 0.2153 - val_loss: 0.6528 - val_acc: 0.2004\n",
      "Epoch 3876/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1736 - acc: 0.2158 - val_loss: 0.6357 - val_acc: 0.2004\n",
      "Epoch 3877/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1685 - acc: 0.2153 - val_loss: 0.6795 - val_acc: 0.2004\n",
      "Epoch 3878/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1890 - acc: 0.2144 - val_loss: 0.6334 - val_acc: 0.1967\n",
      "Epoch 3879/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2103 - acc: 0.2153 - val_loss: 0.6349 - val_acc: 0.2004\n",
      "Epoch 3880/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.1996 - acc: 0.2158 - val_loss: 0.6756 - val_acc: 0.2004\n",
      "Epoch 3881/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1895 - acc: 0.2158 - val_loss: 0.6662 - val_acc: 0.2004\n",
      "Epoch 3882/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2265 - acc: 0.2148 - val_loss: 0.7050 - val_acc: 0.2004\n",
      "Epoch 3883/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1923 - acc: 0.2144 - val_loss: 0.6575 - val_acc: 0.2004\n",
      "Epoch 3884/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2527 - acc: 0.2153 - val_loss: 0.6741 - val_acc: 0.2004\n",
      "Epoch 3885/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2779 - acc: 0.2158 - val_loss: 0.6655 - val_acc: 0.2004\n",
      "Epoch 3886/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1956 - acc: 0.2153 - val_loss: 0.7306 - val_acc: 0.1985\n",
      "Epoch 3887/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1752 - acc: 0.2153 - val_loss: 0.6357 - val_acc: 0.2004\n",
      "Epoch 3888/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2205 - acc: 0.2167 - val_loss: 0.6805 - val_acc: 0.2004\n",
      "Epoch 3889/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1633 - acc: 0.2162 - val_loss: 0.6977 - val_acc: 0.2004\n",
      "Epoch 3890/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1702 - acc: 0.2162 - val_loss: 0.7667 - val_acc: 0.2004\n",
      "Epoch 3891/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2088 - acc: 0.2144 - val_loss: 0.7290 - val_acc: 0.1967\n",
      "Epoch 3892/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1723 - acc: 0.2153 - val_loss: 0.7601 - val_acc: 0.1967\n",
      "Epoch 3893/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1625 - acc: 0.2167 - val_loss: 0.6646 - val_acc: 0.2004\n",
      "Epoch 3894/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.1836 - acc: 0.2162 - val_loss: 0.6317 - val_acc: 0.2004\n",
      "Epoch 3895/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1580 - acc: 0.2158 - val_loss: 0.6472 - val_acc: 0.2004\n",
      "Epoch 3896/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1758 - acc: 0.2158 - val_loss: 0.6643 - val_acc: 0.2004\n",
      "Epoch 3897/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1887 - acc: 0.2153 - val_loss: 0.6363 - val_acc: 0.2004\n",
      "Epoch 3898/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1754 - acc: 0.2144 - val_loss: 0.6492 - val_acc: 0.2004\n",
      "Epoch 3899/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1669 - acc: 0.2153 - val_loss: 0.6362 - val_acc: 0.2004\n",
      "Epoch 3900/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1584 - acc: 0.2162 - val_loss: 0.6823 - val_acc: 0.1985\n",
      "Epoch 3901/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1660 - acc: 0.2162 - val_loss: 0.6551 - val_acc: 0.2004\n",
      "Epoch 3902/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1840 - acc: 0.2139 - val_loss: 0.7716 - val_acc: 0.2004\n",
      "Epoch 3903/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.1809 - acc: 0.2158 - val_loss: 0.6414 - val_acc: 0.2004\n",
      "Epoch 3904/4000\n",
      "68/68 [==============================] - 5s 72ms/step - loss: 0.1692 - acc: 0.2158 - val_loss: 0.6623 - val_acc: 0.2004\n",
      "Epoch 3905/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1857 - acc: 0.2153 - val_loss: 0.6227 - val_acc: 0.2004\n",
      "Epoch 3906/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1769 - acc: 0.2148 - val_loss: 0.6646 - val_acc: 0.2004\n",
      "Epoch 3907/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1680 - acc: 0.2153 - val_loss: 0.7624 - val_acc: 0.2004\n",
      "Epoch 3908/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1785 - acc: 0.2158 - val_loss: 0.6731 - val_acc: 0.1985\n",
      "Epoch 3909/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1914 - acc: 0.2144 - val_loss: 0.6739 - val_acc: 0.2004\n",
      "Epoch 3910/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1655 - acc: 0.2162 - val_loss: 0.6787 - val_acc: 0.2004\n",
      "Epoch 3911/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1619 - acc: 0.2162 - val_loss: 0.6711 - val_acc: 0.2004\n",
      "Epoch 3912/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1745 - acc: 0.2139 - val_loss: 0.6394 - val_acc: 0.2004\n",
      "Epoch 3913/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1993 - acc: 0.2158 - val_loss: 0.6633 - val_acc: 0.2004\n",
      "Epoch 3914/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1905 - acc: 0.2158 - val_loss: 0.6152 - val_acc: 0.2004\n",
      "Epoch 3915/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1736 - acc: 0.2158 - val_loss: 0.6803 - val_acc: 0.2004\n",
      "Epoch 3916/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1796 - acc: 0.2153 - val_loss: 0.6493 - val_acc: 0.2004\n",
      "Epoch 3917/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1682 - acc: 0.2158 - val_loss: 0.6542 - val_acc: 0.2004\n",
      "Epoch 3918/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1745 - acc: 0.2162 - val_loss: 0.6464 - val_acc: 0.2004\n",
      "Epoch 3919/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1587 - acc: 0.2158 - val_loss: 0.6378 - val_acc: 0.2004\n",
      "Epoch 3920/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1655 - acc: 0.2158 - val_loss: 0.8318 - val_acc: 0.2004\n",
      "Epoch 3921/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1846 - acc: 0.2144 - val_loss: 0.6541 - val_acc: 0.2004\n",
      "Epoch 3922/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1717 - acc: 0.2162 - val_loss: 0.6777 - val_acc: 0.2004\n",
      "Epoch 3923/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1678 - acc: 0.2153 - val_loss: 0.7168 - val_acc: 0.2004\n",
      "Epoch 3924/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1614 - acc: 0.2148 - val_loss: 0.6263 - val_acc: 0.2004\n",
      "Epoch 3925/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1730 - acc: 0.2144 - val_loss: 0.6603 - val_acc: 0.2004\n",
      "Epoch 3926/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1751 - acc: 0.2162 - val_loss: 0.6423 - val_acc: 0.2004\n",
      "Epoch 3927/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1757 - acc: 0.2144 - val_loss: 0.6435 - val_acc: 0.2004\n",
      "Epoch 3928/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1852 - acc: 0.2167 - val_loss: 0.6426 - val_acc: 0.2004\n",
      "Epoch 3929/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1903 - acc: 0.2158 - val_loss: 0.6737 - val_acc: 0.2004\n",
      "Epoch 3930/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1632 - acc: 0.2162 - val_loss: 0.6743 - val_acc: 0.2004\n",
      "Epoch 3931/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1766 - acc: 0.2148 - val_loss: 0.6547 - val_acc: 0.2004\n",
      "Epoch 3932/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1626 - acc: 0.2162 - val_loss: 0.6778 - val_acc: 0.2004\n",
      "Epoch 3933/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1709 - acc: 0.2144 - val_loss: 0.6534 - val_acc: 0.2004\n",
      "Epoch 3934/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1637 - acc: 0.2153 - val_loss: 0.6724 - val_acc: 0.1985\n",
      "Epoch 3935/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1840 - acc: 0.2153 - val_loss: 0.7446 - val_acc: 0.2004\n",
      "Epoch 3936/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1604 - acc: 0.2158 - val_loss: 0.6448 - val_acc: 0.2004\n",
      "Epoch 3937/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1720 - acc: 0.2162 - val_loss: 0.6267 - val_acc: 0.2004\n",
      "Epoch 3938/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1691 - acc: 0.2158 - val_loss: 0.6800 - val_acc: 0.2004\n",
      "Epoch 3939/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1689 - acc: 0.2153 - val_loss: 0.6545 - val_acc: 0.2004\n",
      "Epoch 3940/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1800 - acc: 0.2148 - val_loss: 0.7828 - val_acc: 0.2004\n",
      "Epoch 3941/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1980 - acc: 0.2153 - val_loss: 0.6612 - val_acc: 0.2004\n",
      "Epoch 3942/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1711 - acc: 0.2148 - val_loss: 0.6611 - val_acc: 0.2004\n",
      "Epoch 3943/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1663 - acc: 0.2144 - val_loss: 0.6523 - val_acc: 0.2004\n",
      "Epoch 3944/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1695 - acc: 0.2158 - val_loss: 0.6343 - val_acc: 0.2004\n",
      "Epoch 3945/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1590 - acc: 0.2148 - val_loss: 0.6897 - val_acc: 0.2004\n",
      "Epoch 3946/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1776 - acc: 0.2153 - val_loss: 0.6231 - val_acc: 0.2004\n",
      "Epoch 3947/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1918 - acc: 0.2158 - val_loss: 0.6826 - val_acc: 0.2004\n",
      "Epoch 3948/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1650 - acc: 0.2153 - val_loss: 0.7075 - val_acc: 0.1985\n",
      "Epoch 3949/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1666 - acc: 0.2153 - val_loss: 0.6901 - val_acc: 0.2004\n",
      "Epoch 3950/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1769 - acc: 0.2148 - val_loss: 0.6529 - val_acc: 0.2004\n",
      "Epoch 3951/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1907 - acc: 0.2148 - val_loss: 0.7195 - val_acc: 0.2004\n",
      "Epoch 3952/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1585 - acc: 0.2162 - val_loss: 0.6487 - val_acc: 0.2004\n",
      "Epoch 3953/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1724 - acc: 0.2162 - val_loss: 0.6590 - val_acc: 0.2004\n",
      "Epoch 3954/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2042 - acc: 0.2139 - val_loss: 0.6361 - val_acc: 0.2004\n",
      "Epoch 3955/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1945 - acc: 0.2158 - val_loss: 0.7940 - val_acc: 0.1967\n",
      "Epoch 3956/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1895 - acc: 0.2162 - val_loss: 0.7731 - val_acc: 0.2004\n",
      "Epoch 3957/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1715 - acc: 0.2153 - val_loss: 0.6867 - val_acc: 0.2004\n",
      "Epoch 3958/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1720 - acc: 0.2158 - val_loss: 0.7497 - val_acc: 0.1967\n",
      "Epoch 3959/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1689 - acc: 0.2144 - val_loss: 0.6685 - val_acc: 0.2004\n",
      "Epoch 3960/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1606 - acc: 0.2153 - val_loss: 0.7425 - val_acc: 0.1967\n",
      "Epoch 3961/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1917 - acc: 0.2148 - val_loss: 0.7132 - val_acc: 0.1985\n",
      "Epoch 3962/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1739 - acc: 0.2153 - val_loss: 0.6569 - val_acc: 0.2004\n",
      "Epoch 3963/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1622 - acc: 0.2162 - val_loss: 0.7533 - val_acc: 0.2004\n",
      "Epoch 3964/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1674 - acc: 0.2158 - val_loss: 0.6414 - val_acc: 0.2004\n",
      "Epoch 3965/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1714 - acc: 0.2148 - val_loss: 0.7354 - val_acc: 0.2004\n",
      "Epoch 3966/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1796 - acc: 0.2158 - val_loss: 0.6750 - val_acc: 0.2004\n",
      "Epoch 3967/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1731 - acc: 0.2144 - val_loss: 0.6875 - val_acc: 0.2004\n",
      "Epoch 3968/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1620 - acc: 0.2153 - val_loss: 0.6395 - val_acc: 0.2004\n",
      "Epoch 3969/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1683 - acc: 0.2162 - val_loss: 0.6973 - val_acc: 0.1985\n",
      "Epoch 3970/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1555 - acc: 0.2162 - val_loss: 0.6708 - val_acc: 0.2004\n",
      "Epoch 3971/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1798 - acc: 0.2158 - val_loss: 0.6171 - val_acc: 0.2004\n",
      "Epoch 3972/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1715 - acc: 0.2158 - val_loss: 0.6799 - val_acc: 0.2004\n",
      "Epoch 3973/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1599 - acc: 0.2162 - val_loss: 0.6769 - val_acc: 0.2004\n",
      "Epoch 3974/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1836 - acc: 0.2153 - val_loss: 0.7097 - val_acc: 0.2004\n",
      "Epoch 3975/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1956 - acc: 0.2153 - val_loss: 0.7309 - val_acc: 0.1967\n",
      "Epoch 3976/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1970 - acc: 0.2144 - val_loss: 0.6990 - val_acc: 0.2004\n",
      "Epoch 3977/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1846 - acc: 0.2158 - val_loss: 0.6983 - val_acc: 0.1985\n",
      "Epoch 3978/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2003 - acc: 0.2148 - val_loss: 0.6403 - val_acc: 0.2004\n",
      "Epoch 3979/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2238 - acc: 0.2144 - val_loss: 0.6153 - val_acc: 0.2004\n",
      "Epoch 3980/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1890 - acc: 0.2158 - val_loss: 0.6614 - val_acc: 0.2004\n",
      "Epoch 3981/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2092 - acc: 0.2148 - val_loss: 0.6867 - val_acc: 0.1967\n",
      "Epoch 3982/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1768 - acc: 0.2162 - val_loss: 0.7751 - val_acc: 0.2004\n",
      "Epoch 3983/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.3776 - acc: 0.2139 - val_loss: 0.7420 - val_acc: 0.2004\n",
      "Epoch 3984/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.2346 - acc: 0.2158 - val_loss: 0.7114 - val_acc: 0.2004\n",
      "Epoch 3985/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2325 - acc: 0.2158 - val_loss: 0.6970 - val_acc: 0.2004\n",
      "Epoch 3986/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2283 - acc: 0.2139 - val_loss: 0.7165 - val_acc: 0.2004\n",
      "Epoch 3987/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2014 - acc: 0.2158 - val_loss: 0.6698 - val_acc: 0.2004\n",
      "Epoch 3988/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1853 - acc: 0.2158 - val_loss: 0.6903 - val_acc: 0.2004\n",
      "Epoch 3989/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1645 - acc: 0.2158 - val_loss: 0.7731 - val_acc: 0.2004\n",
      "Epoch 3990/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1726 - acc: 0.2158 - val_loss: 0.6592 - val_acc: 0.2004\n",
      "Epoch 3991/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1586 - acc: 0.2162 - val_loss: 0.6416 - val_acc: 0.2004\n",
      "Epoch 3992/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1707 - acc: 0.2139 - val_loss: 0.8705 - val_acc: 0.2004\n",
      "Epoch 3993/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1701 - acc: 0.2162 - val_loss: 0.6900 - val_acc: 0.2004\n",
      "Epoch 3994/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1597 - acc: 0.2158 - val_loss: 0.6614 - val_acc: 0.2004\n",
      "Epoch 3995/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1602 - acc: 0.2153 - val_loss: 0.6439 - val_acc: 0.2004\n",
      "Epoch 3996/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2058 - acc: 0.2153 - val_loss: 0.6562 - val_acc: 0.2004\n",
      "Epoch 3997/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1706 - acc: 0.2148 - val_loss: 0.6448 - val_acc: 0.2004\n",
      "Epoch 3998/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1550 - acc: 0.2158 - val_loss: 0.6449 - val_acc: 0.2004\n",
      "Epoch 3999/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1647 - acc: 0.2144 - val_loss: 0.7307 - val_acc: 0.2004\n",
      "Epoch 4000/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1806 - acc: 0.2158 - val_loss: 0.7279 - val_acc: 0.1967\n"
     ]
    }
   ],
   "source": [
    "size_history = cnn_size_model.fit([size_x_train1, size_x_train2, size_x_train3], size_y_train, epochs=4000, validation_data=([size_x_test1,size_x_test2,size_x_test3], size_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 17ms/step - loss: 0.7279 - acc: 0.1967\n",
      "Test loss: 0.7279127240180969\n",
      "Test accuracy: 0.19666048884391785\n"
     ]
    }
   ],
   "source": [
    "# モデルの評価(大きさ)\n",
    "score = cnn_size_model.evaluate([size_x_test1, size_x_test2, size_x_test3], size_y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 学習経過の可視化(大きさ)\n",
    "loss     = size_history.history['loss']\n",
    "val_loss = size_history.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss,     marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大きさ1の正答率：0.7962962962962963\n",
      "大きさ2の正答率：0.192\n",
      "大きさ3の正答率：0.8598130841121495\n",
      "大きさ4の正答率：0.8\n",
      "大きさ5の正答率：0.75\n"
     ]
    }
   ],
   "source": [
    "#大きさごとの推定精度の確認：20%以下\n",
    "size_predict = cnn_size_model.predict([size_x_test1,size_x_test2,size_x_test3])\n",
    "size_answer = size_y_test\n",
    "one_total = 0\n",
    "one_ok = 0\n",
    "two_total = 0\n",
    "two_ok = 0\n",
    "three_total = 0\n",
    "three_ok = 0\n",
    "four_total = 0\n",
    "four_ok = 0\n",
    "five_total = 0\n",
    "five_ok = 0\n",
    "for i in range(len(size_predict)):\n",
    "    if size_answer[i] == 1:\n",
    "        one_total = one_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.2):\n",
    "            one_ok = one_ok + 1\n",
    "    if size_answer[i] == 2:\n",
    "        two_total = two_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.4):\n",
    "            two_ok = two_ok + 1\n",
    "    if size_answer[i] == 3:\n",
    "        three_total = three_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.6):\n",
    "            three_ok = three_ok + 1\n",
    "    if size_answer[i] == 4:\n",
    "        four_total = four_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.8):\n",
    "            four_ok = four_ok + 1\n",
    "    if size_answer[i] == 5:\n",
    "        five_total = five_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 1):\n",
    "            five_ok = five_ok + 1\n",
    "print(\"大きさ1の正答率：\"+str(one_ok/one_total))\n",
    "print(\"大きさ2の正答率：\"+str(two_ok/two_total))\n",
    "print(\"大きさ3の正答率：\"+str(three_ok/three_total))\n",
    "print(\"大きさ4の正答率：\"+str(four_ok/four_total))\n",
    "print(\"大きさ5の正答率：\"+str(five_ok/five_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "left = np.array([1,2,3,4,5])\n",
    "height = np.array([one_ok/one_total,two_ok/two_total,three_ok/three_total,four_ok/four_total,five_ok/five_total])\n",
    "plt.bar(left, height)\n",
    "plt.xlabel(\"size\")\n",
    "plt.ylabel(\"size acc\")\n",
    "plt.ylim(top=1, bottom=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大きさ1の正答率：0.9351851851851852\n",
      "大きさ2の正答率：0.312\n",
      "大きさ3の正答率：0.822429906542056\n",
      "大きさ4の正答率：0.5684210526315789\n",
      "大きさ5の正答率：0.4230769230769231\n"
     ]
    }
   ],
   "source": [
    "#大きさごとの推定精度の確認：最も近く予測\n",
    "size_predict = cnn_size_model.predict([size_x_test1,size_x_test2,size_x_test3])\n",
    "size_answer = size_y_test\n",
    "one_total = 0\n",
    "one_ok = 0\n",
    "two_total = 0\n",
    "two_ok = 0\n",
    "three_total = 0\n",
    "three_ok = 0\n",
    "four_total = 0\n",
    "four_ok = 0\n",
    "five_total = 0\n",
    "five_ok = 0\n",
    "for i in range(len(size_predict)):\n",
    "    if size_answer[i] == 1:\n",
    "        one_total = one_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.5):\n",
    "            one_ok = one_ok + 1\n",
    "    if size_answer[i] == 2:\n",
    "        two_total = two_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.5):\n",
    "            two_ok = two_ok + 1\n",
    "    if size_answer[i] == 3:\n",
    "        three_total = three_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.5):\n",
    "            three_ok = three_ok + 1\n",
    "    if size_answer[i] == 4:\n",
    "        four_total = four_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.5):\n",
    "            four_ok = four_ok + 1\n",
    "    if size_answer[i] == 5:\n",
    "        five_total = five_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.5):\n",
    "            five_ok = five_ok + 1\n",
    "print(\"大きさ1の正答率：\"+str(one_ok/one_total))\n",
    "print(\"大きさ2の正答率：\"+str(two_ok/two_total))\n",
    "print(\"大きさ3の正答率：\"+str(three_ok/three_total))\n",
    "print(\"大きさ4の正答率：\"+str(four_ok/four_total))\n",
    "print(\"大きさ5の正答率：\"+str(five_ok/five_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "left = np.array([1,2,3,4,5])\n",
    "height = np.array([one_ok/one_total,two_ok/two_total,three_ok/three_total,four_ok/four_total,five_ok/five_total])\n",
    "plt.bar(left, height)\n",
    "plt.xlabel(\"size\")\n",
    "plt.ylabel(\"size acc\")\n",
    "plt.ylim(top=1, bottom=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
