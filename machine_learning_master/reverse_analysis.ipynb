{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 必要なライブラリのimport\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## データについて\n",
    "\n",
    "### データファイルのpath\n",
    "no_hole_path = './../vibration_simulation/vibration_data/no_hole_data.csv'\n",
    "one_hole_path = './../vibration_simulation/vibration_data/one_hole_data.csv'\n",
    "four_holes_path = './../vibration_simulation/vibration_data/four_holes_data.csv'\n",
    "nine_holes_path = './../vibration_simulation/vibration_data/nine_holes_data.csv'\n",
    "sixteen_holes_path = './../vibration_simulation/vibration_data/sixteen_holes_data.csv'\n",
    "twentyfive_holes_path = './../vibration_simulation/vibration_data/twentyfive_holes_data.csv'\n",
    "\n",
    "### 入力データと正解データ\n",
    "no_hole_data1 = []\n",
    "no_hole_data2 = []\n",
    "no_hole_data3 = []\n",
    "size_x_data = []\n",
    "size_x_data1 = []\n",
    "size_x_data2 = []\n",
    "size_x_data3 = []\n",
    "size_y_data = []\n",
    "position_x_data = []\n",
    "position_x_data1 = []\n",
    "position_x_data2 = []\n",
    "position_x_data3 = []\n",
    "position_one_data1 = []\n",
    "position_one_data2 = []\n",
    "position_one_data3 = []\n",
    "position_two_data1 = []\n",
    "position_two_data2 = []\n",
    "position_two_data3 = []\n",
    "position_three_data1 = []\n",
    "position_three_data2 = []\n",
    "position_three_data3 = []\n",
    "position_four_data1 = []\n",
    "position_four_data2 = []\n",
    "position_four_data3 = []\n",
    "position_five_data1 = []\n",
    "position_five_data2 = []\n",
    "position_five_data3 = []\n",
    "position_y_data = []\n",
    "\n",
    "### ファイル読み込み\n",
    "\n",
    "#### 欠陥がない場合のデータ\n",
    "with open(no_hole_path) as f:\n",
    "    for line in f:\n",
    "        data_array = line.split(' ')\n",
    "        no_hole_data1 = data_array[0:1251]\n",
    "        no_hole_data2 = data_array[1251:2502]\n",
    "        no_hole_data3 = data_array[2502:-1]\n",
    "        \n",
    "#### 大きさに関するデータ\n",
    "with open(one_hole_path) as fs1:\n",
    "  for line in fs1:\n",
    "    data_array = line.split(' ')\n",
    "    size_x_data1.append(data_array[3:1254])\n",
    "    size_x_data2.append(data_array[1254:2505])\n",
    "    size_x_data3.append(data_array[2505:-1])\n",
    "    size_y_data.append(data_array[0])\n",
    "with open(four_holes_path) as fs2:\n",
    "  for line in fs2:\n",
    "    data_array = line.split(' ')\n",
    "    size_x_data1.append(data_array[3:1254])\n",
    "    size_x_data2.append(data_array[1254:2505])\n",
    "    size_x_data3.append(data_array[2505:-1])\n",
    "    size_y_data.append(data_array[0])\n",
    "with open(nine_holes_path) as fs3:\n",
    "  for line in fs3:\n",
    "    data_array = line.split(' ')\n",
    "    size_x_data1.append(data_array[3:1254])\n",
    "    size_x_data2.append(data_array[1254:2505])\n",
    "    size_x_data3.append(data_array[2505:-1])\n",
    "    size_y_data.append(data_array[0])\n",
    "with open(sixteen_holes_path) as fs4:\n",
    "  for line in fs4:\n",
    "    data_array = line.split(' ')\n",
    "    size_x_data1.append(data_array[3:1254])\n",
    "    size_x_data2.append(data_array[1254:2505])\n",
    "    size_x_data3.append(data_array[2505:-1])\n",
    "    size_y_data.append(data_array[0])\n",
    "with open(twentyfive_holes_path) as fs5:\n",
    "  for line in fs5:\n",
    "    data_array = line.split(' ')\n",
    "    size_x_data1.append(data_array[3:1254])\n",
    "    size_x_data2.append(data_array[1254:2505])\n",
    "    size_x_data3.append(data_array[2505:-1])\n",
    "    size_y_data.append(data_array[0])\n",
    "\n",
    "#### 位置に関するデータ\n",
    "with open(one_hole_path) as fp1:\n",
    "  for line in fp1:\n",
    "    data_array = line.split(' ')\n",
    "    position_x_data1.append(data_array[3:1254])\n",
    "    position_x_data2.append(data_array[1254:2505])\n",
    "    position_x_data3.append(data_array[2505:-1])\n",
    "    position_one_data1.append(data_array[3:1254])\n",
    "    position_one_data2.append(data_array[1254:2505])\n",
    "    position_one_data3.append(data_array[2505:-1])\n",
    "    position_y_data.append(data_array[1:3])\n",
    "with open(four_holes_path) as fp2:\n",
    "  for line in fp2:\n",
    "    data_array = line.split(' ')\n",
    "    position_x_data1.append(data_array[3:1254])\n",
    "    position_x_data2.append(data_array[1254:2505])\n",
    "    position_x_data3.append(data_array[2505:-1])\n",
    "    position_two_data1.append(data_array[3:1254])\n",
    "    position_two_data2.append(data_array[1254:2505])\n",
    "    position_two_data3.append(data_array[2505:-1])\n",
    "    position_y_data.append(data_array[1:3])\n",
    "with open(nine_holes_path) as fp3:\n",
    "  for line in fp3:\n",
    "    data_array = line.split(' ')\n",
    "    position_x_data1.append(data_array[3:1254])\n",
    "    position_x_data2.append(data_array[1254:2505])\n",
    "    position_x_data3.append(data_array[2505:-1])\n",
    "    position_three_data1.append(data_array[3:1254])\n",
    "    position_three_data2.append(data_array[1254:2505])\n",
    "    position_three_data3.append(data_array[2505:-1])\n",
    "    position_y_data.append(data_array[1:3])\n",
    "with open(sixteen_holes_path) as fp4:\n",
    "  for line in fp4:\n",
    "    data_array = line.split(' ')\n",
    "    position_x_data1.append(data_array[3:1254])\n",
    "    position_x_data2.append(data_array[1254:2505])\n",
    "    position_x_data3.append(data_array[2505:-1])\n",
    "    position_four_data1.append(data_array[3:1254])\n",
    "    position_four_data2.append(data_array[1254:2505])\n",
    "    position_four_data3.append(data_array[2505:-1])\n",
    "    position_y_data.append(data_array[1:3])\n",
    "with open(twentyfive_holes_path) as fp5:\n",
    "  for line in fp5:\n",
    "    data_array = line.split(' ')\n",
    "    position_x_data1.append(data_array[3:1254])\n",
    "    position_x_data2.append(data_array[1254:2505])\n",
    "    position_x_data3.append(data_array[2505:-1])\n",
    "    position_five_data1.append(data_array[3:1254])\n",
    "    position_five_data2.append(data_array[1254:2505])\n",
    "    position_five_data3.append(data_array[2505:-1])\n",
    "    position_y_data.append(data_array[1:3])\n",
    "\n",
    "### 各配列をnp.array型にして各要素を型変換\n",
    "no_hole_data1 = np.array(no_hole_data1, dtype=float)\n",
    "no_hole_data2 = np.array(no_hole_data2, dtype=float)\n",
    "no_hole_data3 = np.array(no_hole_data3, dtype=float)\n",
    "size_x_data1 = np.array(size_x_data1, dtype=float)\n",
    "size_x_data2 = np.array(size_x_data2, dtype=float)\n",
    "size_x_data3 = np.array(size_x_data3, dtype=float)\n",
    "size_y_data = np.array(size_y_data, dtype=int)\n",
    "position_x_data1 = np.array(position_x_data1, dtype=float)\n",
    "position_x_data2 = np.array(position_x_data2, dtype=float)\n",
    "position_x_data3 = np.array(position_x_data3, dtype=float)\n",
    "position_one_data1 = np.array(position_one_data1, dtype=float)\n",
    "position_two_data1 = np.array(position_two_data1, dtype=float)\n",
    "position_three_data1 = np.array(position_three_data1, dtype=float)\n",
    "position_four_data1 = np.array(position_four_data1, dtype=float)\n",
    "position_five_data1 = np.array(position_five_data1, dtype=float)\n",
    "position_one_data2 = np.array(position_one_data2, dtype=float)\n",
    "position_two_data2 = np.array(position_two_data2, dtype=float)\n",
    "position_three_data2 = np.array(position_three_data2, dtype=float)\n",
    "position_four_data2 = np.array(position_four_data2, dtype=float)\n",
    "position_five_data2 = np.array(position_five_data2, dtype=float)\n",
    "position_one_data3 = np.array(position_one_data3, dtype=float)\n",
    "position_two_data3 = np.array(position_two_data3, dtype=float)\n",
    "position_three_data3 = np.array(position_three_data3, dtype=float)\n",
    "position_four_data3 = np.array(position_four_data3, dtype=float)\n",
    "position_five_data3 = np.array(position_five_data3, dtype=float)\n",
    "position_y_data = np.array(position_y_data, dtype=float)\n",
    "\n",
    "### データの加工\n",
    "# 最大値で割る\n",
    "max_displacement = size_x_data2.max()\n",
    "size_x_data1 = size_x_data1/max_displacement\n",
    "size_x_data2 = size_x_data2/max_displacement\n",
    "size_x_data3 = size_x_data3/max_displacement\n",
    "position_x_data1 = position_x_data1/max_displacement\n",
    "position_x_data2 = position_x_data2/max_displacement\n",
    "position_x_data3 = position_x_data3/max_displacement\n",
    "position_one_data1 = position_one_data1/max_displacement\n",
    "position_one_data2 = position_one_data2/max_displacement\n",
    "position_one_data3 = position_one_data3/max_displacement\n",
    "position_two_data1 = position_two_data1/max_displacement\n",
    "position_two_data2 = position_two_data2/max_displacement\n",
    "position_two_data3 = position_two_data3/max_displacement\n",
    "position_three_data1 = position_three_data1/max_displacement\n",
    "position_three_data2 = position_three_data2/max_displacement\n",
    "position_three_data3 = position_three_data3/max_displacement\n",
    "position_four_data1 = position_four_data1/max_displacement\n",
    "position_four_data2 = position_four_data2/max_displacement\n",
    "position_four_data3 = position_four_data3/max_displacement\n",
    "position_five_data1 = position_five_data1/max_displacement\n",
    "position_five_data2 = position_five_data2/max_displacement\n",
    "position_five_data3 = position_five_data3/max_displacement\n",
    "\n",
    "# 実験2:差をとると精度が向上するか\n",
    "# size_x_data = (size_x_data-no_hole_data)\n",
    "# position_x_data = (position_x_data-no_hole_data)\n",
    "\n",
    "# position_one_data = (position_one_data-no_hole_data)\n",
    "# position_two_data = (position_two_data-no_hole_data)\n",
    "# position_three_data = (position_three_data-no_hole_data)\n",
    "# position_four_data = (position_four_data-no_hole_data)\n",
    "# position_five_data = (position_five_data-no_hole_data)\n",
    "position_y_data = position_y_data/50\n",
    "\n",
    "### train用とtest用に分割(9:1)\n",
    "size_x_train1, size_x_test1, size_x_train2, size_x_test2, size_x_train3, size_x_test3, size_y_train, size_y_test = train_test_split(size_x_data1, size_x_data2, size_x_data3, size_y_data, test_size=0.10)\n",
    "position_x_train1, position_x_test1, position_x_train2, position_x_test2, position_x_train3, position_x_test3, position_y_train, position_y_test = train_test_split(position_x_data1, position_x_data2, position_x_data3, position_y_data, test_size=0.10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2424, 1251)\n",
      "(270, 1251)\n",
      "(484, 1251)\n",
      "(529, 1251)\n",
      "(529, 1251)\n",
      "(576, 1251)\n",
      "(576, 1251)\n",
      "2694\n"
     ]
    }
   ],
   "source": [
    "print(size_x_train1.shape)\n",
    "print(size_x_test1.shape)\n",
    "print(position_five_data1.shape)\n",
    "print(position_four_data1.shape)\n",
    "print(position_three_data1.shape)\n",
    "print(position_two_data1.shape)\n",
    "print(position_one_data1.shape)\n",
    "print(484+529+529+576+576)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1251)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1251)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 1251)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            1252        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            1252        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            1252        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 3)            0           dense[0][0]                      \n",
      "                                                                 dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           128         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            33          dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,917\n",
      "Trainable params: 3,917\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#単純モデル\n",
    "# import\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, concatenate, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
    "\n",
    "# 入力を定義\n",
    "input1 = Input(shape=(1251,))\n",
    "input2 = Input(shape=(1251,))\n",
    "input3 = Input(shape=(1251,))\n",
    "\n",
    "# 入力1から結合前まで\n",
    "x = Dense(1, activation=\"linear\")(input1)\n",
    "x = Model(inputs=input1, outputs=x)\n",
    "# 入力2から結合前まで\n",
    "y = Dense(1, activation=\"linear\")(input2)\n",
    "y = Model(inputs=input2, outputs=y)\n",
    "# 入力3から結合前まで\n",
    "z = Dense(1, activation=\"linear\")(input3)\n",
    "z = Model(inputs=input3, outputs=z)\n",
    "\n",
    "# 結合\n",
    "combined = concatenate([x.output, y.output, z.output])\n",
    "\n",
    "# 密結合\n",
    "w = Dense(32, activation=\"tanh\")(combined)\n",
    "w = Dense(1, activation=\"linear\")(w)\n",
    "\n",
    "# モデル定義とコンパイル\n",
    "model = Model(inputs=[x.input, y.input, z.input], outputs=w)\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['acc'])\n",
    "model.summary()\n",
    "plot_model(model, show_shapes=True, show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 1251, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 1251, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 1251, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 1251, 32)     128         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 1251, 32)     128         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1251, 32)     128         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 626, 32)      0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 626, 32)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 626, 32)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 626, 96)      0           max_pooling1d[0][0]              \n",
      "                                                                 max_pooling1d_1[0][0]            \n",
      "                                                                 max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 60096)        0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            60097       flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 60,481\n",
      "Trainable params: 60,481\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNNモデルで大きさ推定\n",
    "# import\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, concatenate, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
    "\n",
    "# 入力を定義\n",
    "input1 = Input(shape=(1251,1))\n",
    "input2 = Input(shape=(1251,1))\n",
    "input3 = Input(shape=(1251,1))\n",
    "\n",
    "# 入力1から結合前まで\n",
    "x = Conv1D(32, 3, padding='same', activation='tanh')(input1)\n",
    "x = MaxPooling1D(2, padding='same')(x)\n",
    "x = Model(inputs=input1, outputs=x)\n",
    "# 入力2から結合前まで\n",
    "y = Conv1D(32, 3, padding='same', activation='tanh')(input2)\n",
    "y = MaxPooling1D(2, padding='same')(y)\n",
    "y = Model(inputs=input2, outputs=y)\n",
    "# 入力3から結合前まで\n",
    "z = Conv1D(32, 3, padding='same', activation='tanh')(input3)\n",
    "z = MaxPooling1D(2, padding='same')(z)\n",
    "z = Model(inputs=input3, outputs=z)\n",
    "\n",
    "# 結合\n",
    "combined = concatenate([x.output, y.output, z.output])\n",
    "\n",
    "# 密結合\n",
    "cnn = Flatten()(combined)\n",
    "cnn = Dense(1, activation=\"relu\")(cnn)\n",
    "\n",
    "# モデル定義とコンパイル\n",
    "cnn_size_model = Model(inputs=[x.input, y.input, z.input], outputs=cnn)\n",
    "cnn_size_model.compile(loss='mse', optimizer='adam', metrics=['acc'])\n",
    "cnn_size_model.summary()\n",
    "plot_model(cnn_size_model, show_shapes=True, show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 2.4453 - acc: 0.2063 - val_loss: 2.0402 - val_acc: 0.2444\n",
      "Epoch 2/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 1.9473 - acc: 0.2104 - val_loss: 2.0120 - val_acc: 0.2444\n",
      "Epoch 3/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 1.8989 - acc: 0.2104 - val_loss: 2.0878 - val_acc: 0.2444\n",
      "Epoch 4/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 1.8527 - acc: 0.2104 - val_loss: 1.9831 - val_acc: 0.2444\n",
      "Epoch 5/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 1.8000 - acc: 0.2104 - val_loss: 1.9417 - val_acc: 0.2444\n",
      "Epoch 6/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 1.7978 - acc: 0.2104 - val_loss: 1.8851 - val_acc: 0.2444\n",
      "Epoch 7/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 1.7167 - acc: 0.2104 - val_loss: 1.8483 - val_acc: 0.2444\n",
      "Epoch 8/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 1.7058 - acc: 0.2104 - val_loss: 1.8198 - val_acc: 0.2444\n",
      "Epoch 9/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 1.6593 - acc: 0.2104 - val_loss: 1.7823 - val_acc: 0.2444\n",
      "Epoch 10/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 1.6096 - acc: 0.2104 - val_loss: 1.7972 - val_acc: 0.2444\n",
      "Epoch 11/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 1.6282 - acc: 0.2104 - val_loss: 1.8365 - val_acc: 0.2444\n",
      "Epoch 12/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 1.5770 - acc: 0.2104 - val_loss: 1.7082 - val_acc: 0.2444\n",
      "Epoch 13/10000\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 1.5226 - acc: 0.2104 - val_loss: 1.6526 - val_acc: 0.2444\n",
      "Epoch 14/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 1.4887 - acc: 0.2104 - val_loss: 1.6305 - val_acc: 0.2444\n",
      "Epoch 15/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 1.5491 - acc: 0.2104 - val_loss: 1.6226 - val_acc: 0.2444\n",
      "Epoch 16/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 1.4581 - acc: 0.2104 - val_loss: 1.6953 - val_acc: 0.2444\n",
      "Epoch 17/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 1.4793 - acc: 0.2104 - val_loss: 1.5984 - val_acc: 0.2444\n",
      "Epoch 18/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 1.4068 - acc: 0.2104 - val_loss: 1.5392 - val_acc: 0.2444\n",
      "Epoch 19/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 1.3895 - acc: 0.2104 - val_loss: 1.5159 - val_acc: 0.2444\n",
      "Epoch 20/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 1.3555 - acc: 0.2104 - val_loss: 1.4768 - val_acc: 0.2444\n",
      "Epoch 21/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 1.3810 - acc: 0.2104 - val_loss: 1.4601 - val_acc: 0.2444\n",
      "Epoch 22/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 1.3329 - acc: 0.2104 - val_loss: 1.6351 - val_acc: 0.2444\n",
      "Epoch 23/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 1.3353 - acc: 0.2104 - val_loss: 1.4197 - val_acc: 0.2444\n",
      "Epoch 24/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 1.2792 - acc: 0.2104 - val_loss: 1.4165 - val_acc: 0.2444\n",
      "Epoch 25/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 1.2963 - acc: 0.2104 - val_loss: 1.4267 - val_acc: 0.2444\n",
      "Epoch 26/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 1.3013 - acc: 0.2104 - val_loss: 1.3884 - val_acc: 0.2444\n",
      "Epoch 27/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 1.3485 - acc: 0.2104 - val_loss: 1.4099 - val_acc: 0.2444\n",
      "Epoch 28/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 1.2455 - acc: 0.2104 - val_loss: 1.3577 - val_acc: 0.2444\n",
      "Epoch 29/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 1.2367 - acc: 0.2104 - val_loss: 1.3635 - val_acc: 0.2444\n",
      "Epoch 30/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 1.2119 - acc: 0.2104 - val_loss: 1.3602 - val_acc: 0.2444\n",
      "Epoch 31/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 1.2303 - acc: 0.2104 - val_loss: 1.3547 - val_acc: 0.2444\n",
      "Epoch 32/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 1.1709 - acc: 0.2104 - val_loss: 1.3288 - val_acc: 0.2444\n",
      "Epoch 33/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 1.1907 - acc: 0.2104 - val_loss: 1.3770 - val_acc: 0.2444\n",
      "Epoch 34/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 1.2143 - acc: 0.2104 - val_loss: 1.2980 - val_acc: 0.2444\n",
      "Epoch 35/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 1.1840 - acc: 0.2104 - val_loss: 1.2811 - val_acc: 0.2444\n",
      "Epoch 36/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 1.2297 - acc: 0.2104 - val_loss: 1.2737 - val_acc: 0.2444\n",
      "Epoch 37/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 1.0906 - acc: 0.2104 - val_loss: 1.2414 - val_acc: 0.2444\n",
      "Epoch 38/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 1.0862 - acc: 0.2104 - val_loss: 1.2509 - val_acc: 0.2444\n",
      "Epoch 39/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 1.1317 - acc: 0.2104 - val_loss: 1.2400 - val_acc: 0.2444\n",
      "Epoch 40/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 1.0892 - acc: 0.2104 - val_loss: 1.2229 - val_acc: 0.2444\n",
      "Epoch 41/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 1.0736 - acc: 0.2104 - val_loss: 1.3418 - val_acc: 0.2444\n",
      "Epoch 42/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 1.1377 - acc: 0.2104 - val_loss: 1.2864 - val_acc: 0.2444\n",
      "Epoch 43/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 1.1196 - acc: 0.2104 - val_loss: 1.2438 - val_acc: 0.2444\n",
      "Epoch 44/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 1.1517 - acc: 0.2104 - val_loss: 1.3914 - val_acc: 0.2444\n",
      "Epoch 45/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 1.0889 - acc: 0.2104 - val_loss: 1.1663 - val_acc: 0.2444\n",
      "Epoch 46/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 1.0817 - acc: 0.2104 - val_loss: 1.2286 - val_acc: 0.2444\n",
      "Epoch 47/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 1.0164 - acc: 0.2104 - val_loss: 1.2495 - val_acc: 0.2444\n",
      "Epoch 48/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 1.0204 - acc: 0.2104 - val_loss: 1.2416 - val_acc: 0.2444\n",
      "Epoch 49/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 1.0390 - acc: 0.2104 - val_loss: 1.1354 - val_acc: 0.2444\n",
      "Epoch 50/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.9820 - acc: 0.2104 - val_loss: 1.3837 - val_acc: 0.2444\n",
      "Epoch 51/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.9859 - acc: 0.2104 - val_loss: 1.1028 - val_acc: 0.2444\n",
      "Epoch 52/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.9813 - acc: 0.2104 - val_loss: 1.1499 - val_acc: 0.2444\n",
      "Epoch 53/10000\n",
      "76/76 [==============================] - 4s 46ms/step - loss: 1.0017 - acc: 0.2104 - val_loss: 1.1099 - val_acc: 0.2444\n",
      "Epoch 54/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.9799 - acc: 0.2104 - val_loss: 1.1682 - val_acc: 0.2444\n",
      "Epoch 55/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.9545 - acc: 0.2104 - val_loss: 1.3217 - val_acc: 0.2444\n",
      "Epoch 56/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 1.0001 - acc: 0.2104 - val_loss: 1.0743 - val_acc: 0.2444\n",
      "Epoch 57/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 1.0312 - acc: 0.2104 - val_loss: 1.0724 - val_acc: 0.2444\n",
      "Epoch 58/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.9669 - acc: 0.2104 - val_loss: 1.0891 - val_acc: 0.2444\n",
      "Epoch 59/10000\n",
      "76/76 [==============================] - 6s 77ms/step - loss: 0.9987 - acc: 0.2104 - val_loss: 1.2129 - val_acc: 0.2444\n",
      "Epoch 60/10000\n",
      "76/76 [==============================] - 5s 69ms/step - loss: 1.0339 - acc: 0.2104 - val_loss: 1.1307 - val_acc: 0.2444\n",
      "Epoch 61/10000\n",
      "76/76 [==============================] - 4s 57ms/step - loss: 0.9801 - acc: 0.2104 - val_loss: 1.0776 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/10000\n",
      "76/76 [==============================] - 4s 56ms/step - loss: 0.9775 - acc: 0.2104 - val_loss: 1.1066 - val_acc: 0.2444\n",
      "Epoch 63/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.9256 - acc: 0.2104 - val_loss: 1.1000 - val_acc: 0.2444\n",
      "Epoch 64/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.9664 - acc: 0.2104 - val_loss: 1.4020 - val_acc: 0.2444\n",
      "Epoch 65/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.9834 - acc: 0.2104 - val_loss: 1.0416 - val_acc: 0.2444\n",
      "Epoch 66/10000\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 0.9416 - acc: 0.2104 - val_loss: 1.0987 - val_acc: 0.2444\n",
      "Epoch 67/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.9181 - acc: 0.2104 - val_loss: 1.0618 - val_acc: 0.2444\n",
      "Epoch 68/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.8944 - acc: 0.2104 - val_loss: 1.0808 - val_acc: 0.2444\n",
      "Epoch 69/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.9048 - acc: 0.2104 - val_loss: 1.0988 - val_acc: 0.2444\n",
      "Epoch 70/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.9707 - acc: 0.2104 - val_loss: 0.9969 - val_acc: 0.2444\n",
      "Epoch 71/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.8973 - acc: 0.2104 - val_loss: 0.9748 - val_acc: 0.2444\n",
      "Epoch 72/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.8885 - acc: 0.2104 - val_loss: 1.1841 - val_acc: 0.2444\n",
      "Epoch 73/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.9063 - acc: 0.2104 - val_loss: 0.9803 - val_acc: 0.2444\n",
      "Epoch 74/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.8550 - acc: 0.2104 - val_loss: 0.9674 - val_acc: 0.2444\n",
      "Epoch 75/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.8783 - acc: 0.2104 - val_loss: 0.9914 - val_acc: 0.2444\n",
      "Epoch 76/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.8675 - acc: 0.2104 - val_loss: 0.9702 - val_acc: 0.2444\n",
      "Epoch 77/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.9015 - acc: 0.2100 - val_loss: 0.9651 - val_acc: 0.2444\n",
      "Epoch 78/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.8394 - acc: 0.2104 - val_loss: 0.9455 - val_acc: 0.2444\n",
      "Epoch 79/10000\n",
      "76/76 [==============================] - 3s 46ms/step - loss: 0.8571 - acc: 0.2100 - val_loss: 1.0590 - val_acc: 0.2444\n",
      "Epoch 80/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.9287 - acc: 0.2104 - val_loss: 0.9473 - val_acc: 0.2444\n",
      "Epoch 81/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.8501 - acc: 0.2100 - val_loss: 0.9629 - val_acc: 0.2444\n",
      "Epoch 82/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.8221 - acc: 0.2100 - val_loss: 0.9266 - val_acc: 0.2444\n",
      "Epoch 83/10000\n",
      "76/76 [==============================] - 3s 46ms/step - loss: 0.8255 - acc: 0.2100 - val_loss: 0.9407 - val_acc: 0.2444\n",
      "Epoch 84/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.8424 - acc: 0.2104 - val_loss: 1.0006 - val_acc: 0.2444\n",
      "Epoch 85/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.7955 - acc: 0.2100 - val_loss: 0.9039 - val_acc: 0.2444\n",
      "Epoch 86/10000\n",
      "76/76 [==============================] - 4s 46ms/step - loss: 0.8175 - acc: 0.2096 - val_loss: 0.9757 - val_acc: 0.2444\n",
      "Epoch 87/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.7961 - acc: 0.2100 - val_loss: 0.8961 - val_acc: 0.2444\n",
      "Epoch 88/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.8089 - acc: 0.2100 - val_loss: 0.8739 - val_acc: 0.2444\n",
      "Epoch 89/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.7883 - acc: 0.2100 - val_loss: 1.1836 - val_acc: 0.2444\n",
      "Epoch 90/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.8295 - acc: 0.2096 - val_loss: 0.9145 - val_acc: 0.2444\n",
      "Epoch 91/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.8779 - acc: 0.2100 - val_loss: 0.9452 - val_acc: 0.2444\n",
      "Epoch 92/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.8091 - acc: 0.2096 - val_loss: 0.8960 - val_acc: 0.2444\n",
      "Epoch 93/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.8189 - acc: 0.2096 - val_loss: 0.9190 - val_acc: 0.2444\n",
      "Epoch 94/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.7896 - acc: 0.2096 - val_loss: 0.9212 - val_acc: 0.2444\n",
      "Epoch 95/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.8008 - acc: 0.2096 - val_loss: 0.9773 - val_acc: 0.2444\n",
      "Epoch 96/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.7914 - acc: 0.2096 - val_loss: 1.0231 - val_acc: 0.2444\n",
      "Epoch 97/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.7929 - acc: 0.2096 - val_loss: 0.8383 - val_acc: 0.2444\n",
      "Epoch 98/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.7596 - acc: 0.2096 - val_loss: 0.9552 - val_acc: 0.2444\n",
      "Epoch 99/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.7639 - acc: 0.2096 - val_loss: 0.8284 - val_acc: 0.2444\n",
      "Epoch 100/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.7714 - acc: 0.2092 - val_loss: 0.8349 - val_acc: 0.2444\n",
      "Epoch 101/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.8265 - acc: 0.2096 - val_loss: 0.8249 - val_acc: 0.2444\n",
      "Epoch 102/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.8078 - acc: 0.2096 - val_loss: 0.8142 - val_acc: 0.2444\n",
      "Epoch 103/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.7943 - acc: 0.2096 - val_loss: 0.8243 - val_acc: 0.2444\n",
      "Epoch 104/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.7165 - acc: 0.2096 - val_loss: 0.8318 - val_acc: 0.2444\n",
      "Epoch 105/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.7128 - acc: 0.2096 - val_loss: 0.9224 - val_acc: 0.2444\n",
      "Epoch 106/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.7474 - acc: 0.2092 - val_loss: 0.8485 - val_acc: 0.2444\n",
      "Epoch 107/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.7304 - acc: 0.2096 - val_loss: 0.8141 - val_acc: 0.2444\n",
      "Epoch 108/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.8015 - acc: 0.2092 - val_loss: 0.8334 - val_acc: 0.2444\n",
      "Epoch 109/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.7346 - acc: 0.2096 - val_loss: 0.8886 - val_acc: 0.2444\n",
      "Epoch 110/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.8042 - acc: 0.2087 - val_loss: 1.0776 - val_acc: 0.2444\n",
      "Epoch 111/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.7453 - acc: 0.2096 - val_loss: 0.9253 - val_acc: 0.2444\n",
      "Epoch 112/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.7089 - acc: 0.2096 - val_loss: 0.7979 - val_acc: 0.2444\n",
      "Epoch 113/10000\n",
      "76/76 [==============================] - 3s 46ms/step - loss: 0.7285 - acc: 0.2096 - val_loss: 0.7783 - val_acc: 0.2444\n",
      "Epoch 114/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.7648 - acc: 0.2100 - val_loss: 0.7702 - val_acc: 0.2444\n",
      "Epoch 115/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.7397 - acc: 0.2087 - val_loss: 0.7817 - val_acc: 0.2444\n",
      "Epoch 116/10000\n",
      "76/76 [==============================] - 3s 46ms/step - loss: 0.7417 - acc: 0.2096 - val_loss: 0.7606 - val_acc: 0.2444\n",
      "Epoch 117/10000\n",
      "76/76 [==============================] - 5s 61ms/step - loss: 0.7583 - acc: 0.2092 - val_loss: 1.0267 - val_acc: 0.2407\n",
      "Epoch 118/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.7549 - acc: 0.2087 - val_loss: 0.8726 - val_acc: 0.2444\n",
      "Epoch 119/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.7243 - acc: 0.2092 - val_loss: 0.8053 - val_acc: 0.2444\n",
      "Epoch 120/10000\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 0.7159 - acc: 0.2096 - val_loss: 0.7543 - val_acc: 0.2444\n",
      "Epoch 121/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.7645 - acc: 0.2096 - val_loss: 0.7632 - val_acc: 0.2444\n",
      "Epoch 122/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 3s 34ms/step - loss: 0.7045 - acc: 0.2096 - val_loss: 0.7577 - val_acc: 0.2444\n",
      "Epoch 123/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.7049 - acc: 0.2096 - val_loss: 0.7533 - val_acc: 0.2444\n",
      "Epoch 124/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.6711 - acc: 0.2092 - val_loss: 0.8016 - val_acc: 0.2444\n",
      "Epoch 125/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.6884 - acc: 0.2092 - val_loss: 0.7576 - val_acc: 0.2444\n",
      "Epoch 126/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.6730 - acc: 0.2092 - val_loss: 0.7299 - val_acc: 0.2444\n",
      "Epoch 127/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.6632 - acc: 0.2096 - val_loss: 0.7576 - val_acc: 0.2444\n",
      "Epoch 128/10000\n",
      "76/76 [==============================] - 5s 61ms/step - loss: 0.6936 - acc: 0.2096 - val_loss: 0.7513 - val_acc: 0.2444\n",
      "Epoch 129/10000\n",
      "76/76 [==============================] - 4s 58ms/step - loss: 0.6772 - acc: 0.2092 - val_loss: 0.7346 - val_acc: 0.2444\n",
      "Epoch 130/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.6752 - acc: 0.2092 - val_loss: 0.7414 - val_acc: 0.2444\n",
      "Epoch 131/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.6973 - acc: 0.2092 - val_loss: 0.7603 - val_acc: 0.2444\n",
      "Epoch 132/10000\n",
      "76/76 [==============================] - 4s 57ms/step - loss: 0.6747 - acc: 0.2083 - val_loss: 0.7295 - val_acc: 0.2444\n",
      "Epoch 133/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.6539 - acc: 0.2092 - val_loss: 0.7206 - val_acc: 0.2444\n",
      "Epoch 134/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.6652 - acc: 0.2092 - val_loss: 0.7115 - val_acc: 0.2444\n",
      "Epoch 135/10000\n",
      "76/76 [==============================] - 6s 78ms/step - loss: 0.6670 - acc: 0.2092 - val_loss: 0.7070 - val_acc: 0.2444\n",
      "Epoch 136/10000\n",
      "76/76 [==============================] - 5s 60ms/step - loss: 0.6714 - acc: 0.2087 - val_loss: 0.7661 - val_acc: 0.2444\n",
      "Epoch 137/10000\n",
      "76/76 [==============================] - 4s 58ms/step - loss: 0.6347 - acc: 0.2092 - val_loss: 0.7295 - val_acc: 0.2444\n",
      "Epoch 138/10000\n",
      "76/76 [==============================] - 5s 62ms/step - loss: 0.7210 - acc: 0.2092 - val_loss: 0.9924 - val_acc: 0.2444\n",
      "Epoch 139/10000\n",
      "76/76 [==============================] - 4s 58ms/step - loss: 0.6548 - acc: 0.2083 - val_loss: 0.7005 - val_acc: 0.2444\n",
      "Epoch 140/10000\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 0.6538 - acc: 0.2092 - val_loss: 0.7056 - val_acc: 0.2444\n",
      "Epoch 141/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.6483 - acc: 0.2096 - val_loss: 0.6983 - val_acc: 0.2444\n",
      "Epoch 142/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.6720 - acc: 0.2087 - val_loss: 0.6995 - val_acc: 0.2444\n",
      "Epoch 143/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.6506 - acc: 0.2087 - val_loss: 0.7072 - val_acc: 0.2444\n",
      "Epoch 144/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.6462 - acc: 0.2092 - val_loss: 0.6917 - val_acc: 0.2444\n",
      "Epoch 145/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.6435 - acc: 0.2083 - val_loss: 0.7999 - val_acc: 0.2444\n",
      "Epoch 146/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.6287 - acc: 0.2092 - val_loss: 0.6826 - val_acc: 0.2444\n",
      "Epoch 147/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.6541 - acc: 0.2083 - val_loss: 0.7223 - val_acc: 0.2444\n",
      "Epoch 148/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.6458 - acc: 0.2092 - val_loss: 0.7580 - val_acc: 0.2444\n",
      "Epoch 149/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.6583 - acc: 0.2092 - val_loss: 0.9462 - val_acc: 0.2444\n",
      "Epoch 150/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.7351 - acc: 0.2083 - val_loss: 1.0571 - val_acc: 0.2370\n",
      "Epoch 151/10000\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 0.6695 - acc: 0.2079 - val_loss: 0.6946 - val_acc: 0.2444\n",
      "Epoch 152/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.6277 - acc: 0.2083 - val_loss: 0.7487 - val_acc: 0.2444\n",
      "Epoch 153/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.6515 - acc: 0.2092 - val_loss: 0.7539 - val_acc: 0.2444\n",
      "Epoch 154/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.6606 - acc: 0.2092 - val_loss: 0.7211 - val_acc: 0.2444\n",
      "Epoch 155/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.6336 - acc: 0.2092 - val_loss: 0.6851 - val_acc: 0.2444\n",
      "Epoch 156/10000\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 0.6760 - acc: 0.2079 - val_loss: 0.7229 - val_acc: 0.2444\n",
      "Epoch 157/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.6343 - acc: 0.2087 - val_loss: 0.6980 - val_acc: 0.2444\n",
      "Epoch 158/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.7199 - acc: 0.2079 - val_loss: 0.8655 - val_acc: 0.2444\n",
      "Epoch 159/10000\n",
      "76/76 [==============================] - 5s 63ms/step - loss: 0.6375 - acc: 0.2083 - val_loss: 0.8042 - val_acc: 0.2444\n",
      "Epoch 160/10000\n",
      "76/76 [==============================] - 5s 59ms/step - loss: 0.6666 - acc: 0.2092 - val_loss: 0.6708 - val_acc: 0.2444\n",
      "Epoch 161/10000\n",
      "76/76 [==============================] - 4s 56ms/step - loss: 0.6018 - acc: 0.2092 - val_loss: 0.7493 - val_acc: 0.2444\n",
      "Epoch 162/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.6483 - acc: 0.2083 - val_loss: 0.6746 - val_acc: 0.2444\n",
      "Epoch 163/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.6471 - acc: 0.2087 - val_loss: 0.6803 - val_acc: 0.2444\n",
      "Epoch 164/10000\n",
      "76/76 [==============================] - 3s 46ms/step - loss: 0.6012 - acc: 0.2083 - val_loss: 0.6755 - val_acc: 0.2444\n",
      "Epoch 165/10000\n",
      "76/76 [==============================] - 3s 46ms/step - loss: 0.6541 - acc: 0.2083 - val_loss: 0.6659 - val_acc: 0.2444\n",
      "Epoch 166/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.6226 - acc: 0.2083 - val_loss: 0.6843 - val_acc: 0.2444\n",
      "Epoch 167/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.6610 - acc: 0.2083 - val_loss: 0.6817 - val_acc: 0.2444\n",
      "Epoch 168/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.6239 - acc: 0.2075 - val_loss: 0.7233 - val_acc: 0.2444\n",
      "Epoch 169/10000\n",
      "76/76 [==============================] - 5s 62ms/step - loss: 0.6273 - acc: 0.2087 - val_loss: 0.7003 - val_acc: 0.2444\n",
      "Epoch 170/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.6189 - acc: 0.2083 - val_loss: 0.7546 - val_acc: 0.2444\n",
      "Epoch 171/10000\n",
      "76/76 [==============================] - 5s 68ms/step - loss: 0.6439 - acc: 0.2083 - val_loss: 0.7466 - val_acc: 0.2444\n",
      "Epoch 172/10000\n",
      "76/76 [==============================] - 5s 64ms/step - loss: 0.6201 - acc: 0.2087 - val_loss: 0.6460 - val_acc: 0.2444\n",
      "Epoch 173/10000\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 0.6150 - acc: 0.2079 - val_loss: 0.9175 - val_acc: 0.2407\n",
      "Epoch 174/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.6542 - acc: 0.2079 - val_loss: 0.7051 - val_acc: 0.2444\n",
      "Epoch 175/10000\n",
      "76/76 [==============================] - 4s 57ms/step - loss: 0.6245 - acc: 0.2087 - val_loss: 0.6724 - val_acc: 0.2444\n",
      "Epoch 176/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.6054 - acc: 0.2087 - val_loss: 0.6900 - val_acc: 0.2444\n",
      "Epoch 177/10000\n",
      "76/76 [==============================] - 4s 57ms/step - loss: 0.6475 - acc: 0.2083 - val_loss: 0.7557 - val_acc: 0.2444\n",
      "Epoch 178/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.6523 - acc: 0.2071 - val_loss: 0.8110 - val_acc: 0.2444\n",
      "Epoch 179/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.6626 - acc: 0.2087 - val_loss: 0.9828 - val_acc: 0.2370\n",
      "Epoch 180/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.6323 - acc: 0.2075 - val_loss: 0.7136 - val_acc: 0.2444\n",
      "Epoch 181/10000\n",
      "76/76 [==============================] - 4s 56ms/step - loss: 0.5982 - acc: 0.2087 - val_loss: 0.6644 - val_acc: 0.2444\n",
      "Epoch 182/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 4s 54ms/step - loss: 0.6033 - acc: 0.2083 - val_loss: 0.7182 - val_acc: 0.2444\n",
      "Epoch 183/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.6560 - acc: 0.2083 - val_loss: 0.8133 - val_acc: 0.2407\n",
      "Epoch 184/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.6327 - acc: 0.2092 - val_loss: 0.7413 - val_acc: 0.2444\n",
      "Epoch 185/10000\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 0.6186 - acc: 0.2075 - val_loss: 0.7985 - val_acc: 0.2407\n",
      "Epoch 186/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.6611 - acc: 0.2079 - val_loss: 0.6959 - val_acc: 0.2444\n",
      "Epoch 187/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.7017 - acc: 0.2079 - val_loss: 0.8795 - val_acc: 0.2407\n",
      "Epoch 188/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.6225 - acc: 0.2087 - val_loss: 0.7737 - val_acc: 0.2444\n",
      "Epoch 189/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.6098 - acc: 0.2087 - val_loss: 0.6499 - val_acc: 0.2444\n",
      "Epoch 190/10000\n",
      "76/76 [==============================] - 4s 56ms/step - loss: 0.5823 - acc: 0.2092 - val_loss: 0.6469 - val_acc: 0.2444\n",
      "Epoch 191/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.5866 - acc: 0.2087 - val_loss: 0.6957 - val_acc: 0.2444\n",
      "Epoch 192/10000\n",
      "76/76 [==============================] - 4s 46ms/step - loss: 0.5999 - acc: 0.2079 - val_loss: 0.6955 - val_acc: 0.2444\n",
      "Epoch 193/10000\n",
      "76/76 [==============================] - 4s 56ms/step - loss: 0.6378 - acc: 0.2092 - val_loss: 0.7709 - val_acc: 0.2444\n",
      "Epoch 194/10000\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 0.5864 - acc: 0.2083 - val_loss: 0.6538 - val_acc: 0.2444\n",
      "Epoch 195/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.6446 - acc: 0.2079 - val_loss: 0.6772 - val_acc: 0.2444\n",
      "Epoch 196/10000\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 0.6116 - acc: 0.2087 - val_loss: 0.6469 - val_acc: 0.2444\n",
      "Epoch 197/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.5774 - acc: 0.2087 - val_loss: 0.7304 - val_acc: 0.2444\n",
      "Epoch 198/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.5910 - acc: 0.2087 - val_loss: 0.6804 - val_acc: 0.2444\n",
      "Epoch 199/10000\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 0.6062 - acc: 0.2075 - val_loss: 0.6483 - val_acc: 0.2444\n",
      "Epoch 200/10000\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 0.6064 - acc: 0.2087 - val_loss: 0.6470 - val_acc: 0.2444\n",
      "Epoch 201/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.5843 - acc: 0.2083 - val_loss: 0.6437 - val_acc: 0.2444\n",
      "Epoch 202/10000\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 0.5862 - acc: 0.2083 - val_loss: 0.6670 - val_acc: 0.2444\n",
      "Epoch 203/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.5794 - acc: 0.2087 - val_loss: 0.6558 - val_acc: 0.2444\n",
      "Epoch 204/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.5990 - acc: 0.2079 - val_loss: 0.6660 - val_acc: 0.2444\n",
      "Epoch 205/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.6513 - acc: 0.2063 - val_loss: 1.0338 - val_acc: 0.2444\n",
      "Epoch 206/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.6222 - acc: 0.2067 - val_loss: 0.7791 - val_acc: 0.2407\n",
      "Epoch 207/10000\n",
      "76/76 [==============================] - 5s 60ms/step - loss: 0.6050 - acc: 0.2087 - val_loss: 0.6587 - val_acc: 0.2444\n",
      "Epoch 208/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.5952 - acc: 0.2083 - val_loss: 0.7409 - val_acc: 0.2407\n",
      "Epoch 209/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.6003 - acc: 0.2075 - val_loss: 0.7959 - val_acc: 0.2444\n",
      "Epoch 210/10000\n",
      "76/76 [==============================] - 6s 79ms/step - loss: 0.6315 - acc: 0.2079 - val_loss: 0.7786 - val_acc: 0.2407\n",
      "Epoch 211/10000\n",
      "76/76 [==============================] - 4s 56ms/step - loss: 0.6440 - acc: 0.2071 - val_loss: 0.8940 - val_acc: 0.2407\n",
      "Epoch 212/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.6290 - acc: 0.2079 - val_loss: 0.6599 - val_acc: 0.2444\n",
      "Epoch 213/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.5795 - acc: 0.2079 - val_loss: 0.6673 - val_acc: 0.2444\n",
      "Epoch 214/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.5838 - acc: 0.2071 - val_loss: 0.6763 - val_acc: 0.2444\n",
      "Epoch 215/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.5764 - acc: 0.2083 - val_loss: 0.6450 - val_acc: 0.2444\n",
      "Epoch 216/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.5847 - acc: 0.2087 - val_loss: 0.6499 - val_acc: 0.2444\n",
      "Epoch 217/10000\n",
      "76/76 [==============================] - 4s 57ms/step - loss: 0.5846 - acc: 0.2075 - val_loss: 0.6589 - val_acc: 0.2444\n",
      "Epoch 218/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.5747 - acc: 0.2075 - val_loss: 0.6534 - val_acc: 0.2444\n",
      "Epoch 219/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.5843 - acc: 0.2067 - val_loss: 0.7395 - val_acc: 0.2407\n",
      "Epoch 220/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.6300 - acc: 0.2075 - val_loss: 0.7694 - val_acc: 0.2444\n",
      "Epoch 221/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.5845 - acc: 0.2075 - val_loss: 0.6414 - val_acc: 0.2444\n",
      "Epoch 222/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.5867 - acc: 0.2075 - val_loss: 0.6820 - val_acc: 0.2444\n",
      "Epoch 223/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.5948 - acc: 0.2071 - val_loss: 0.6551 - val_acc: 0.2444\n",
      "Epoch 224/10000\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 0.5873 - acc: 0.2075 - val_loss: 0.6391 - val_acc: 0.2444\n",
      "Epoch 225/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.5787 - acc: 0.2079 - val_loss: 0.8196 - val_acc: 0.2407\n",
      "Epoch 226/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.6188 - acc: 0.2092 - val_loss: 0.6839 - val_acc: 0.2444\n",
      "Epoch 227/10000\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 0.5736 - acc: 0.2075 - val_loss: 0.7069 - val_acc: 0.2444\n",
      "Epoch 228/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.5668 - acc: 0.2079 - val_loss: 0.6881 - val_acc: 0.2444\n",
      "Epoch 229/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.5994 - acc: 0.2079 - val_loss: 0.8262 - val_acc: 0.2407\n",
      "Epoch 230/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.6376 - acc: 0.2083 - val_loss: 0.7632 - val_acc: 0.2444\n",
      "Epoch 231/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.5693 - acc: 0.2087 - val_loss: 0.6592 - val_acc: 0.2444\n",
      "Epoch 232/10000\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 0.5633 - acc: 0.2083 - val_loss: 0.6405 - val_acc: 0.2444\n",
      "Epoch 233/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.5668 - acc: 0.2079 - val_loss: 0.6729 - val_acc: 0.2444\n",
      "Epoch 234/10000\n",
      "76/76 [==============================] - 4s 58ms/step - loss: 0.6054 - acc: 0.2079 - val_loss: 0.8378 - val_acc: 0.2407\n",
      "Epoch 235/10000\n",
      "76/76 [==============================] - 4s 57ms/step - loss: 0.6252 - acc: 0.2087 - val_loss: 0.6315 - val_acc: 0.2444\n",
      "Epoch 236/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.5642 - acc: 0.2075 - val_loss: 0.7347 - val_acc: 0.2407\n",
      "Epoch 237/10000\n",
      "76/76 [==============================] - 4s 56ms/step - loss: 0.5814 - acc: 0.2079 - val_loss: 0.8099 - val_acc: 0.2444\n",
      "Epoch 238/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.5717 - acc: 0.2079 - val_loss: 0.6601 - val_acc: 0.2444\n",
      "Epoch 239/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.5891 - acc: 0.2075 - val_loss: 0.6726 - val_acc: 0.2444\n",
      "Epoch 240/10000\n",
      "76/76 [==============================] - 5s 66ms/step - loss: 0.5753 - acc: 0.2083 - val_loss: 0.6773 - val_acc: 0.2444\n",
      "Epoch 241/10000\n",
      "76/76 [==============================] - 5s 66ms/step - loss: 0.5782 - acc: 0.2075 - val_loss: 0.6308 - val_acc: 0.2444\n",
      "Epoch 242/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 4s 53ms/step - loss: 0.5717 - acc: 0.2079 - val_loss: 0.6742 - val_acc: 0.2444\n",
      "Epoch 243/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.6000 - acc: 0.2079 - val_loss: 0.6513 - val_acc: 0.2444\n",
      "Epoch 244/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.5615 - acc: 0.2075 - val_loss: 0.6507 - val_acc: 0.2444\n",
      "Epoch 245/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.5595 - acc: 0.2079 - val_loss: 0.6500 - val_acc: 0.2444\n",
      "Epoch 246/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.5862 - acc: 0.2079 - val_loss: 0.7708 - val_acc: 0.2407\n",
      "Epoch 247/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.6003 - acc: 0.2067 - val_loss: 0.7431 - val_acc: 0.2444\n",
      "Epoch 248/10000\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 0.6244 - acc: 0.2079 - val_loss: 0.6671 - val_acc: 0.2444\n",
      "Epoch 249/10000\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 0.5781 - acc: 0.2075 - val_loss: 0.6167 - val_acc: 0.2444\n",
      "Epoch 250/10000\n",
      "76/76 [==============================] - 6s 75ms/step - loss: 0.5857 - acc: 0.2079 - val_loss: 0.6976 - val_acc: 0.2444\n",
      "Epoch 251/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.5737 - acc: 0.2075 - val_loss: 0.6502 - val_acc: 0.2444\n",
      "Epoch 252/10000\n",
      "76/76 [==============================] - 6s 78ms/step - loss: 0.5768 - acc: 0.2075 - val_loss: 0.6680 - val_acc: 0.2444\n",
      "Epoch 253/10000\n",
      "76/76 [==============================] - 5s 67ms/step - loss: 0.5519 - acc: 0.2079 - val_loss: 0.6432 - val_acc: 0.2444\n",
      "Epoch 254/10000\n",
      "76/76 [==============================] - 4s 58ms/step - loss: 0.5580 - acc: 0.2071 - val_loss: 0.7200 - val_acc: 0.2444\n",
      "Epoch 255/10000\n",
      "76/76 [==============================] - 5s 64ms/step - loss: 0.5900 - acc: 0.2067 - val_loss: 0.8785 - val_acc: 0.2407\n",
      "Epoch 256/10000\n",
      "76/76 [==============================] - 5s 64ms/step - loss: 0.6375 - acc: 0.2067 - val_loss: 0.6225 - val_acc: 0.2444\n",
      "Epoch 257/10000\n",
      "76/76 [==============================] - 4s 57ms/step - loss: 0.5496 - acc: 0.2071 - val_loss: 0.6132 - val_acc: 0.2444\n",
      "Epoch 258/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.5497 - acc: 0.2075 - val_loss: 0.7657 - val_acc: 0.2444\n",
      "Epoch 259/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.5555 - acc: 0.2079 - val_loss: 0.7213 - val_acc: 0.2407\n",
      "Epoch 260/10000\n",
      "76/76 [==============================] - 4s 57ms/step - loss: 0.5722 - acc: 0.2067 - val_loss: 0.6484 - val_acc: 0.2444\n",
      "Epoch 261/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.5701 - acc: 0.2075 - val_loss: 0.6300 - val_acc: 0.2444\n",
      "Epoch 262/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.6093 - acc: 0.2067 - val_loss: 0.6297 - val_acc: 0.2444\n",
      "Epoch 263/10000\n",
      "76/76 [==============================] - 4s 58ms/step - loss: 0.5748 - acc: 0.2079 - val_loss: 1.2510 - val_acc: 0.2444\n",
      "Epoch 264/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.6187 - acc: 0.2075 - val_loss: 0.6541 - val_acc: 0.2444\n",
      "Epoch 265/10000\n",
      "76/76 [==============================] - 4s 46ms/step - loss: 0.5712 - acc: 0.2071 - val_loss: 0.8521 - val_acc: 0.2407\n",
      "Epoch 266/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.5831 - acc: 0.2071 - val_loss: 0.7194 - val_acc: 0.2407\n",
      "Epoch 267/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.5719 - acc: 0.2083 - val_loss: 0.6230 - val_acc: 0.2444\n",
      "Epoch 268/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.5973 - acc: 0.2063 - val_loss: 0.6312 - val_acc: 0.2444\n",
      "Epoch 269/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.5839 - acc: 0.2079 - val_loss: 0.6786 - val_acc: 0.2444\n",
      "Epoch 270/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.5657 - acc: 0.2083 - val_loss: 0.6159 - val_acc: 0.2444\n",
      "Epoch 271/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.6047 - acc: 0.2071 - val_loss: 0.6088 - val_acc: 0.2444\n",
      "Epoch 272/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.5560 - acc: 0.2079 - val_loss: 0.7474 - val_acc: 0.2444\n",
      "Epoch 273/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.5447 - acc: 0.2083 - val_loss: 0.6046 - val_acc: 0.2444\n",
      "Epoch 274/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.5728 - acc: 0.2075 - val_loss: 0.7816 - val_acc: 0.2407\n",
      "Epoch 275/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.5989 - acc: 0.2075 - val_loss: 0.5942 - val_acc: 0.2444\n",
      "Epoch 276/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.5497 - acc: 0.2071 - val_loss: 0.8727 - val_acc: 0.2407\n",
      "Epoch 277/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.5734 - acc: 0.2063 - val_loss: 0.6026 - val_acc: 0.2444\n",
      "Epoch 278/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.5912 - acc: 0.2071 - val_loss: 0.7027 - val_acc: 0.2444\n",
      "Epoch 279/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.5735 - acc: 0.2067 - val_loss: 0.6495 - val_acc: 0.2444\n",
      "Epoch 280/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.5482 - acc: 0.2071 - val_loss: 0.7332 - val_acc: 0.2444\n",
      "Epoch 281/10000\n",
      "76/76 [==============================] - 5s 63ms/step - loss: 0.5465 - acc: 0.2079 - val_loss: 0.6162 - val_acc: 0.2444\n",
      "Epoch 282/10000\n",
      "76/76 [==============================] - 4s 58ms/step - loss: 0.6084 - acc: 0.2079 - val_loss: 0.6153 - val_acc: 0.2444\n",
      "Epoch 283/10000\n",
      "76/76 [==============================] - 5s 62ms/step - loss: 0.5943 - acc: 0.2063 - val_loss: 0.6034 - val_acc: 0.2444\n",
      "Epoch 284/10000\n",
      "76/76 [==============================] - 4s 56ms/step - loss: 0.5385 - acc: 0.2079 - val_loss: 0.6059 - val_acc: 0.2444\n",
      "Epoch 285/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.5597 - acc: 0.2075 - val_loss: 0.5994 - val_acc: 0.2444\n",
      "Epoch 286/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.5877 - acc: 0.2071 - val_loss: 0.6982 - val_acc: 0.2444\n",
      "Epoch 287/10000\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 0.6147 - acc: 0.2079 - val_loss: 0.6885 - val_acc: 0.2444\n",
      "Epoch 288/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.5595 - acc: 0.2079 - val_loss: 0.5952 - val_acc: 0.2444\n",
      "Epoch 289/10000\n",
      "76/76 [==============================] - 4s 56ms/step - loss: 0.5678 - acc: 0.2063 - val_loss: 0.6383 - val_acc: 0.2444\n",
      "Epoch 290/10000\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 0.5756 - acc: 0.2071 - val_loss: 0.7154 - val_acc: 0.2444\n",
      "Epoch 291/10000\n",
      "76/76 [==============================] - 4s 56ms/step - loss: 0.5379 - acc: 0.2075 - val_loss: 0.7195 - val_acc: 0.2407\n",
      "Epoch 292/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.5580 - acc: 0.2067 - val_loss: 0.6096 - val_acc: 0.2444\n",
      "Epoch 293/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.5398 - acc: 0.2071 - val_loss: 0.6658 - val_acc: 0.2444\n",
      "Epoch 294/10000\n",
      "76/76 [==============================] - 4s 56ms/step - loss: 0.5959 - acc: 0.2067 - val_loss: 0.6203 - val_acc: 0.2444\n",
      "Epoch 295/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.6042 - acc: 0.2071 - val_loss: 0.7822 - val_acc: 0.2444\n",
      "Epoch 296/10000\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 0.5543 - acc: 0.2087 - val_loss: 0.6462 - val_acc: 0.2444\n",
      "Epoch 297/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.5517 - acc: 0.2075 - val_loss: 0.6024 - val_acc: 0.2444\n",
      "Epoch 298/10000\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 0.6012 - acc: 0.2059 - val_loss: 0.6874 - val_acc: 0.2444\n",
      "Epoch 299/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.5544 - acc: 0.2071 - val_loss: 0.6092 - val_acc: 0.2444\n",
      "Epoch 300/10000\n",
      "76/76 [==============================] - 3s 46ms/step - loss: 0.5385 - acc: 0.2071 - val_loss: 0.7751 - val_acc: 0.2407\n",
      "Epoch 301/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.5757 - acc: 0.2075 - val_loss: 0.6678 - val_acc: 0.2444\n",
      "Epoch 302/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 4s 56ms/step - loss: 0.5728 - acc: 0.2071 - val_loss: 0.6190 - val_acc: 0.2444\n",
      "Epoch 303/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.6196 - acc: 0.2067 - val_loss: 0.7197 - val_acc: 0.2407\n",
      "Epoch 304/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.5401 - acc: 0.2071 - val_loss: 0.6544 - val_acc: 0.2444\n",
      "Epoch 305/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.5449 - acc: 0.2075 - val_loss: 0.5985 - val_acc: 0.2444\n",
      "Epoch 306/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.5311 - acc: 0.2071 - val_loss: 0.5952 - val_acc: 0.2444\n",
      "Epoch 307/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.5640 - acc: 0.2059 - val_loss: 0.6558 - val_acc: 0.2444\n",
      "Epoch 308/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.5776 - acc: 0.2067 - val_loss: 0.9154 - val_acc: 0.2444\n",
      "Epoch 309/10000\n",
      "76/76 [==============================] - 4s 46ms/step - loss: 0.5663 - acc: 0.2075 - val_loss: 0.8685 - val_acc: 0.2444\n",
      "Epoch 310/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.5897 - acc: 0.2079 - val_loss: 0.7824 - val_acc: 0.2444\n",
      "Epoch 311/10000\n",
      "76/76 [==============================] - 3s 46ms/step - loss: 0.5645 - acc: 0.2079 - val_loss: 0.6390 - val_acc: 0.2444\n",
      "Epoch 312/10000\n",
      "76/76 [==============================] - 3s 46ms/step - loss: 0.5244 - acc: 0.2075 - val_loss: 0.6436 - val_acc: 0.2444\n",
      "Epoch 313/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.5471 - acc: 0.2063 - val_loss: 0.5910 - val_acc: 0.2444\n",
      "Epoch 314/10000\n",
      "76/76 [==============================] - 5s 60ms/step - loss: 0.5369 - acc: 0.2079 - val_loss: 0.5982 - val_acc: 0.2444\n",
      "Epoch 315/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.5577 - acc: 0.2075 - val_loss: 0.5991 - val_acc: 0.2444\n",
      "Epoch 316/10000\n",
      "76/76 [==============================] - 5s 61ms/step - loss: 0.5545 - acc: 0.2079 - val_loss: 0.6215 - val_acc: 0.2444\n",
      "Epoch 317/10000\n",
      "76/76 [==============================] - 5s 67ms/step - loss: 0.5630 - acc: 0.2071 - val_loss: 0.5875 - val_acc: 0.2444\n",
      "Epoch 318/10000\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 0.5309 - acc: 0.2075 - val_loss: 0.6422 - val_acc: 0.2444\n",
      "Epoch 319/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.5328 - acc: 0.2071 - val_loss: 0.5942 - val_acc: 0.2444\n",
      "Epoch 320/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.6319 - acc: 0.2075 - val_loss: 0.6298 - val_acc: 0.2444\n",
      "Epoch 321/10000\n",
      "76/76 [==============================] - 5s 67ms/step - loss: 0.5299 - acc: 0.2083 - val_loss: 0.6127 - val_acc: 0.2444\n",
      "Epoch 322/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.5557 - acc: 0.2079 - val_loss: 0.6108 - val_acc: 0.2444\n",
      "Epoch 323/10000\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 0.5758 - acc: 0.2071 - val_loss: 0.6932 - val_acc: 0.2444\n",
      "Epoch 324/10000\n",
      "76/76 [==============================] - 4s 46ms/step - loss: 0.5228 - acc: 0.2079 - val_loss: 0.6459 - val_acc: 0.2444\n",
      "Epoch 325/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.6072 - acc: 0.2071 - val_loss: 0.5941 - val_acc: 0.2444\n",
      "Epoch 326/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.5452 - acc: 0.2079 - val_loss: 0.6296 - val_acc: 0.2444\n",
      "Epoch 327/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.5925 - acc: 0.2071 - val_loss: 0.7931 - val_acc: 0.2407\n",
      "Epoch 328/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.5787 - acc: 0.2059 - val_loss: 0.5904 - val_acc: 0.2444\n",
      "Epoch 329/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.5151 - acc: 0.2075 - val_loss: 0.5967 - val_acc: 0.2444\n",
      "Epoch 330/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.5217 - acc: 0.2079 - val_loss: 0.6431 - val_acc: 0.2444\n",
      "Epoch 331/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.6027 - acc: 0.2063 - val_loss: 0.8821 - val_acc: 0.2444\n",
      "Epoch 332/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.5830 - acc: 0.2067 - val_loss: 0.5850 - val_acc: 0.2444\n",
      "Epoch 333/10000\n",
      "76/76 [==============================] - 4s 46ms/step - loss: 0.5174 - acc: 0.2067 - val_loss: 0.6029 - val_acc: 0.2444\n",
      "Epoch 334/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.5486 - acc: 0.2079 - val_loss: 0.5939 - val_acc: 0.2444\n",
      "Epoch 335/10000\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 0.5564 - acc: 0.2071 - val_loss: 0.5883 - val_acc: 0.2444\n",
      "Epoch 336/10000\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 0.5145 - acc: 0.2075 - val_loss: 0.6365 - val_acc: 0.2444\n",
      "Epoch 337/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.5519 - acc: 0.2071 - val_loss: 0.6094 - val_acc: 0.2444\n",
      "Epoch 338/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.5421 - acc: 0.2067 - val_loss: 0.6490 - val_acc: 0.2444\n",
      "Epoch 339/10000\n",
      "76/76 [==============================] - 5s 60ms/step - loss: 0.5454 - acc: 0.2067 - val_loss: 0.6144 - val_acc: 0.2444\n",
      "Epoch 340/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.5502 - acc: 0.2071 - val_loss: 0.5870 - val_acc: 0.2444\n",
      "Epoch 341/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.5650 - acc: 0.2071 - val_loss: 0.5777 - val_acc: 0.2444\n",
      "Epoch 342/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.5227 - acc: 0.2079 - val_loss: 0.6368 - val_acc: 0.2444\n",
      "Epoch 343/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.5441 - acc: 0.2067 - val_loss: 0.6076 - val_acc: 0.2444\n",
      "Epoch 344/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.6124 - acc: 0.2071 - val_loss: 0.6233 - val_acc: 0.2444\n",
      "Epoch 345/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.5461 - acc: 0.2067 - val_loss: 0.6148 - val_acc: 0.2444\n",
      "Epoch 346/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.5831 - acc: 0.2071 - val_loss: 0.6017 - val_acc: 0.2444\n",
      "Epoch 347/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.5767 - acc: 0.2063 - val_loss: 0.6093 - val_acc: 0.2444\n",
      "Epoch 348/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.5324 - acc: 0.2079 - val_loss: 0.6054 - val_acc: 0.2444\n",
      "Epoch 349/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.5334 - acc: 0.2071 - val_loss: 0.6313 - val_acc: 0.2444\n",
      "Epoch 350/10000\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 0.5622 - acc: 0.2075 - val_loss: 0.6177 - val_acc: 0.2444\n",
      "Epoch 351/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.5818 - acc: 0.2067 - val_loss: 0.5947 - val_acc: 0.2444\n",
      "Epoch 352/10000\n",
      "76/76 [==============================] - 6s 74ms/step - loss: 0.5273 - acc: 0.2075 - val_loss: 0.6017 - val_acc: 0.2444\n",
      "Epoch 353/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.5214 - acc: 0.2079 - val_loss: 0.6211 - val_acc: 0.2444\n",
      "Epoch 354/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.5284 - acc: 0.2067 - val_loss: 0.6660 - val_acc: 0.2444\n",
      "Epoch 355/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.5500 - acc: 0.2083 - val_loss: 0.5888 - val_acc: 0.2444\n",
      "Epoch 356/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.5120 - acc: 0.2075 - val_loss: 0.6915 - val_acc: 0.2444\n",
      "Epoch 357/10000\n",
      "76/76 [==============================] - 5s 60ms/step - loss: 0.5751 - acc: 0.2075 - val_loss: 0.6032 - val_acc: 0.2444\n",
      "Epoch 358/10000\n",
      "76/76 [==============================] - 5s 61ms/step - loss: 0.5649 - acc: 0.2071 - val_loss: 0.7700 - val_acc: 0.2407\n",
      "Epoch 359/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.5854 - acc: 0.2075 - val_loss: 0.6248 - val_acc: 0.2444\n",
      "Epoch 360/10000\n",
      "76/76 [==============================] - 4s 56ms/step - loss: 0.5255 - acc: 0.2083 - val_loss: 0.5926 - val_acc: 0.2444\n",
      "Epoch 361/10000\n",
      "76/76 [==============================] - 5s 61ms/step - loss: 0.5506 - acc: 0.2079 - val_loss: 0.6031 - val_acc: 0.2444\n",
      "Epoch 362/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 4s 54ms/step - loss: 0.5549 - acc: 0.2063 - val_loss: 0.6240 - val_acc: 0.2444\n",
      "Epoch 363/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.5137 - acc: 0.2079 - val_loss: 0.5837 - val_acc: 0.2444\n",
      "Epoch 364/10000\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 0.6175 - acc: 0.2075 - val_loss: 0.7324 - val_acc: 0.2444\n",
      "Epoch 365/10000\n",
      "76/76 [==============================] - 4s 46ms/step - loss: 0.5766 - acc: 0.2079 - val_loss: 0.5997 - val_acc: 0.2444\n",
      "Epoch 366/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.5319 - acc: 0.2075 - val_loss: 0.5927 - val_acc: 0.2444\n",
      "Epoch 367/10000\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 0.5646 - acc: 0.2071 - val_loss: 0.5813 - val_acc: 0.2444\n",
      "Epoch 368/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.5406 - acc: 0.2067 - val_loss: 0.6559 - val_acc: 0.2444\n",
      "Epoch 369/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.5429 - acc: 0.2083 - val_loss: 0.5863 - val_acc: 0.2444\n",
      "Epoch 370/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.5407 - acc: 0.2075 - val_loss: 0.6968 - val_acc: 0.2444\n",
      "Epoch 371/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.5146 - acc: 0.2075 - val_loss: 0.6818 - val_acc: 0.2444\n",
      "Epoch 372/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.5459 - acc: 0.2075 - val_loss: 0.6383 - val_acc: 0.2444\n",
      "Epoch 373/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.5505 - acc: 0.2071 - val_loss: 0.9151 - val_acc: 0.2444\n",
      "Epoch 374/10000\n",
      "76/76 [==============================] - 3s 46ms/step - loss: 0.5385 - acc: 0.2075 - val_loss: 0.6429 - val_acc: 0.2444\n",
      "Epoch 375/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.5477 - acc: 0.2067 - val_loss: 0.7091 - val_acc: 0.2444\n",
      "Epoch 376/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.5724 - acc: 0.2071 - val_loss: 0.5908 - val_acc: 0.2444\n",
      "Epoch 377/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.5298 - acc: 0.2071 - val_loss: 0.5923 - val_acc: 0.2444\n",
      "Epoch 378/10000\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 0.5121 - acc: 0.2067 - val_loss: 0.5758 - val_acc: 0.2444\n",
      "Epoch 379/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.5581 - acc: 0.2067 - val_loss: 0.7044 - val_acc: 0.2444\n",
      "Epoch 380/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.5446 - acc: 0.2071 - val_loss: 0.7724 - val_acc: 0.2407\n",
      "Epoch 381/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.5195 - acc: 0.2067 - val_loss: 0.6101 - val_acc: 0.2444\n",
      "Epoch 382/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.5202 - acc: 0.2083 - val_loss: 0.7405 - val_acc: 0.2444\n",
      "Epoch 383/10000\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 0.5153 - acc: 0.2071 - val_loss: 0.5771 - val_acc: 0.2444\n",
      "Epoch 384/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.5216 - acc: 0.2071 - val_loss: 0.5944 - val_acc: 0.2444\n",
      "Epoch 385/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.5121 - acc: 0.2075 - val_loss: 0.6236 - val_acc: 0.2444\n",
      "Epoch 386/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.5247 - acc: 0.2079 - val_loss: 0.5807 - val_acc: 0.2444\n",
      "Epoch 387/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.5176 - acc: 0.2067 - val_loss: 0.7324 - val_acc: 0.2444\n",
      "Epoch 388/10000\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 0.5407 - acc: 0.2071 - val_loss: 0.5803 - val_acc: 0.2444\n",
      "Epoch 389/10000\n",
      "76/76 [==============================] - 4s 59ms/step - loss: 0.5155 - acc: 0.2071 - val_loss: 0.6457 - val_acc: 0.2444\n",
      "Epoch 390/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.5157 - acc: 0.2067 - val_loss: 0.6437 - val_acc: 0.2444\n",
      "Epoch 391/10000\n",
      "76/76 [==============================] - 4s 56ms/step - loss: 0.5194 - acc: 0.2063 - val_loss: 0.5904 - val_acc: 0.2444\n",
      "Epoch 392/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.5515 - acc: 0.2067 - val_loss: 0.5924 - val_acc: 0.2444\n",
      "Epoch 393/10000\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 0.5140 - acc: 0.2071 - val_loss: 0.5730 - val_acc: 0.2444\n",
      "Epoch 394/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.5190 - acc: 0.2079 - val_loss: 0.6165 - val_acc: 0.2444\n",
      "Epoch 395/10000\n",
      "76/76 [==============================] - 4s 57ms/step - loss: 0.5303 - acc: 0.2071 - val_loss: 0.6592 - val_acc: 0.2444\n",
      "Epoch 396/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.5188 - acc: 0.2063 - val_loss: 0.6022 - val_acc: 0.2444\n",
      "Epoch 397/10000\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 0.5506 - acc: 0.2063 - val_loss: 0.5897 - val_acc: 0.2444\n",
      "Epoch 398/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.5683 - acc: 0.2067 - val_loss: 0.6914 - val_acc: 0.2444\n",
      "Epoch 399/10000\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 0.5286 - acc: 0.2067 - val_loss: 0.5777 - val_acc: 0.2444\n",
      "Epoch 400/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.5161 - acc: 0.2079 - val_loss: 0.6390 - val_acc: 0.2444\n",
      "Epoch 401/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.5005 - acc: 0.2071 - val_loss: 0.6333 - val_acc: 0.2444\n",
      "Epoch 402/10000\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 0.5200 - acc: 0.2071 - val_loss: 0.5864 - val_acc: 0.2444\n",
      "Epoch 403/10000\n",
      "76/76 [==============================] - 4s 57ms/step - loss: 0.5538 - acc: 0.2067 - val_loss: 0.5980 - val_acc: 0.2444\n",
      "Epoch 404/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.5927 - acc: 0.2071 - val_loss: 0.9315 - val_acc: 0.2370\n",
      "Epoch 405/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.5096 - acc: 0.2067 - val_loss: 0.5796 - val_acc: 0.2444\n",
      "Epoch 406/10000\n",
      "76/76 [==============================] - 3s 46ms/step - loss: 0.5684 - acc: 0.2079 - val_loss: 0.6933 - val_acc: 0.2444\n",
      "Epoch 407/10000\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 0.5253 - acc: 0.2071 - val_loss: 0.7705 - val_acc: 0.2407\n",
      "Epoch 408/10000\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.5619 - acc: 0.2059 - val_loss: 0.5858 - val_acc: 0.2444\n",
      "Epoch 409/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.5052 - acc: 0.2079 - val_loss: 0.5708 - val_acc: 0.2444\n",
      "Epoch 410/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.5687 - acc: 0.2071 - val_loss: 0.8529 - val_acc: 0.2444\n",
      "Epoch 411/10000\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 0.5696 - acc: 0.2063 - val_loss: 0.5941 - val_acc: 0.2444\n",
      "Epoch 412/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5323 - acc: 0.2083 - val_loss: 0.5699 - val_acc: 0.2444\n",
      "Epoch 413/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5370 - acc: 0.2075 - val_loss: 0.5670 - val_acc: 0.2444\n",
      "Epoch 414/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5272 - acc: 0.2071 - val_loss: 0.5956 - val_acc: 0.2444\n",
      "Epoch 415/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5285 - acc: 0.2075 - val_loss: 0.6183 - val_acc: 0.2444\n",
      "Epoch 416/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5469 - acc: 0.2071 - val_loss: 0.6064 - val_acc: 0.2444\n",
      "Epoch 417/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5134 - acc: 0.2075 - val_loss: 0.6507 - val_acc: 0.2444\n",
      "Epoch 418/10000\n",
      "76/76 [==============================] - 4s 46ms/step - loss: 0.5040 - acc: 0.2075 - val_loss: 0.5822 - val_acc: 0.2444\n",
      "Epoch 419/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.5275 - acc: 0.2067 - val_loss: 0.5728 - val_acc: 0.2444\n",
      "Epoch 420/10000\n",
      "76/76 [==============================] - 5s 61ms/step - loss: 0.5520 - acc: 0.2075 - val_loss: 0.6345 - val_acc: 0.2444\n",
      "Epoch 421/10000\n",
      "76/76 [==============================] - 4s 46ms/step - loss: 0.5331 - acc: 0.2063 - val_loss: 0.6076 - val_acc: 0.2444\n",
      "Epoch 422/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4918 - acc: 0.2067 - val_loss: 0.6964 - val_acc: 0.2444\n",
      "Epoch 423/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5357 - acc: 0.2063 - val_loss: 0.5883 - val_acc: 0.2444\n",
      "Epoch 424/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5413 - acc: 0.2079 - val_loss: 0.6096 - val_acc: 0.2444\n",
      "Epoch 425/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5080 - acc: 0.2067 - val_loss: 0.7571 - val_acc: 0.2407\n",
      "Epoch 426/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5277 - acc: 0.2071 - val_loss: 0.5885 - val_acc: 0.2444\n",
      "Epoch 427/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5186 - acc: 0.2075 - val_loss: 0.5874 - val_acc: 0.2444\n",
      "Epoch 428/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4996 - acc: 0.2075 - val_loss: 0.6177 - val_acc: 0.2444\n",
      "Epoch 429/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5948 - acc: 0.2071 - val_loss: 0.5643 - val_acc: 0.2444\n",
      "Epoch 430/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.4889 - acc: 0.2079 - val_loss: 0.5996 - val_acc: 0.2444\n",
      "Epoch 431/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5072 - acc: 0.2075 - val_loss: 0.5931 - val_acc: 0.2444\n",
      "Epoch 432/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5184 - acc: 0.2067 - val_loss: 0.6117 - val_acc: 0.2444\n",
      "Epoch 433/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5252 - acc: 0.2083 - val_loss: 0.5781 - val_acc: 0.2444\n",
      "Epoch 434/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5371 - acc: 0.2067 - val_loss: 0.7156 - val_acc: 0.2444\n",
      "Epoch 435/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5065 - acc: 0.2071 - val_loss: 0.5883 - val_acc: 0.2444\n",
      "Epoch 436/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4923 - acc: 0.2067 - val_loss: 0.5749 - val_acc: 0.2444\n",
      "Epoch 437/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5138 - acc: 0.2075 - val_loss: 0.6417 - val_acc: 0.2444\n",
      "Epoch 438/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5571 - acc: 0.2067 - val_loss: 0.5652 - val_acc: 0.2444\n",
      "Epoch 439/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5305 - acc: 0.2079 - val_loss: 0.7265 - val_acc: 0.2444\n",
      "Epoch 440/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5335 - acc: 0.2071 - val_loss: 0.7045 - val_acc: 0.2444\n",
      "Epoch 441/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5497 - acc: 0.2079 - val_loss: 0.6546 - val_acc: 0.2444\n",
      "Epoch 442/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5131 - acc: 0.2067 - val_loss: 0.6651 - val_acc: 0.2444\n",
      "Epoch 443/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5501 - acc: 0.2075 - val_loss: 0.6248 - val_acc: 0.2444\n",
      "Epoch 444/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5429 - acc: 0.2067 - val_loss: 0.6466 - val_acc: 0.2444\n",
      "Epoch 445/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4977 - acc: 0.2079 - val_loss: 0.5647 - val_acc: 0.2444\n",
      "Epoch 446/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5201 - acc: 0.2075 - val_loss: 0.5701 - val_acc: 0.2444\n",
      "Epoch 447/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5075 - acc: 0.2071 - val_loss: 0.6489 - val_acc: 0.2444\n",
      "Epoch 448/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4981 - acc: 0.2067 - val_loss: 0.7078 - val_acc: 0.2444\n",
      "Epoch 449/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5259 - acc: 0.2071 - val_loss: 0.5710 - val_acc: 0.2444\n",
      "Epoch 450/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4979 - acc: 0.2063 - val_loss: 0.5969 - val_acc: 0.2444\n",
      "Epoch 451/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5373 - acc: 0.2071 - val_loss: 0.6929 - val_acc: 0.2444\n",
      "Epoch 452/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5465 - acc: 0.2071 - val_loss: 0.7306 - val_acc: 0.2407\n",
      "Epoch 453/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5248 - acc: 0.2071 - val_loss: 0.9294 - val_acc: 0.2444\n",
      "Epoch 454/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5413 - acc: 0.2075 - val_loss: 0.5692 - val_acc: 0.2444\n",
      "Epoch 455/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4987 - acc: 0.2071 - val_loss: 0.5642 - val_acc: 0.2444\n",
      "Epoch 456/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5034 - acc: 0.2071 - val_loss: 0.5637 - val_acc: 0.2444\n",
      "Epoch 457/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5584 - acc: 0.2071 - val_loss: 0.6452 - val_acc: 0.2444\n",
      "Epoch 458/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.6215 - acc: 0.2067 - val_loss: 0.5759 - val_acc: 0.2444\n",
      "Epoch 459/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5222 - acc: 0.2067 - val_loss: 0.6790 - val_acc: 0.2444\n",
      "Epoch 460/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5010 - acc: 0.2079 - val_loss: 0.5623 - val_acc: 0.2444\n",
      "Epoch 461/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5040 - acc: 0.2067 - val_loss: 0.5679 - val_acc: 0.2444\n",
      "Epoch 462/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5637 - acc: 0.2063 - val_loss: 0.5714 - val_acc: 0.2444\n",
      "Epoch 463/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4954 - acc: 0.2071 - val_loss: 0.5752 - val_acc: 0.2444\n",
      "Epoch 464/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5412 - acc: 0.2075 - val_loss: 0.5676 - val_acc: 0.2444\n",
      "Epoch 465/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4943 - acc: 0.2067 - val_loss: 0.8117 - val_acc: 0.2407\n",
      "Epoch 466/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5327 - acc: 0.2079 - val_loss: 0.6166 - val_acc: 0.2444\n",
      "Epoch 467/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4978 - acc: 0.2075 - val_loss: 0.5772 - val_acc: 0.2444\n",
      "Epoch 468/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5464 - acc: 0.2067 - val_loss: 0.5652 - val_acc: 0.2444\n",
      "Epoch 469/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5292 - acc: 0.2075 - val_loss: 0.5664 - val_acc: 0.2444\n",
      "Epoch 470/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5967 - acc: 0.2071 - val_loss: 0.5618 - val_acc: 0.2444\n",
      "Epoch 471/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5703 - acc: 0.2063 - val_loss: 0.6486 - val_acc: 0.2444\n",
      "Epoch 472/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5359 - acc: 0.2075 - val_loss: 0.6245 - val_acc: 0.2444\n",
      "Epoch 473/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5159 - acc: 0.2079 - val_loss: 0.5678 - val_acc: 0.2444\n",
      "Epoch 474/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5214 - acc: 0.2075 - val_loss: 0.5675 - val_acc: 0.2444\n",
      "Epoch 475/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4875 - acc: 0.2071 - val_loss: 0.5766 - val_acc: 0.2444\n",
      "Epoch 476/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5253 - acc: 0.2071 - val_loss: 0.8457 - val_acc: 0.2407\n",
      "Epoch 477/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5018 - acc: 0.2079 - val_loss: 0.7647 - val_acc: 0.2444\n",
      "Epoch 478/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5819 - acc: 0.2075 - val_loss: 0.6237 - val_acc: 0.2444\n",
      "Epoch 479/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5090 - acc: 0.2075 - val_loss: 0.5873 - val_acc: 0.2444\n",
      "Epoch 480/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5027 - acc: 0.2071 - val_loss: 0.5698 - val_acc: 0.2444\n",
      "Epoch 481/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4965 - acc: 0.2067 - val_loss: 0.6661 - val_acc: 0.2444\n",
      "Epoch 482/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4845 - acc: 0.2075 - val_loss: 0.6419 - val_acc: 0.2444\n",
      "Epoch 483/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5348 - acc: 0.2071 - val_loss: 0.7041 - val_acc: 0.2444\n",
      "Epoch 484/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4949 - acc: 0.2075 - val_loss: 0.9522 - val_acc: 0.2444\n",
      "Epoch 485/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4957 - acc: 0.2071 - val_loss: 0.5700 - val_acc: 0.2444\n",
      "Epoch 486/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5052 - acc: 0.2075 - val_loss: 0.6493 - val_acc: 0.2444\n",
      "Epoch 487/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5070 - acc: 0.2067 - val_loss: 0.5861 - val_acc: 0.2444\n",
      "Epoch 488/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5026 - acc: 0.2075 - val_loss: 0.5652 - val_acc: 0.2444\n",
      "Epoch 489/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5278 - acc: 0.2059 - val_loss: 0.6171 - val_acc: 0.2444\n",
      "Epoch 490/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5460 - acc: 0.2079 - val_loss: 0.6457 - val_acc: 0.2444\n",
      "Epoch 491/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4879 - acc: 0.2067 - val_loss: 0.5831 - val_acc: 0.2444\n",
      "Epoch 492/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4943 - acc: 0.2071 - val_loss: 0.5585 - val_acc: 0.2444\n",
      "Epoch 493/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5137 - acc: 0.2075 - val_loss: 0.5849 - val_acc: 0.2444\n",
      "Epoch 494/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5664 - acc: 0.2067 - val_loss: 0.6305 - val_acc: 0.2444\n",
      "Epoch 495/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5428 - acc: 0.2067 - val_loss: 0.5657 - val_acc: 0.2444\n",
      "Epoch 496/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5407 - acc: 0.2067 - val_loss: 0.5843 - val_acc: 0.2444\n",
      "Epoch 497/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5074 - acc: 0.2075 - val_loss: 0.6433 - val_acc: 0.2444\n",
      "Epoch 498/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5168 - acc: 0.2071 - val_loss: 0.5608 - val_acc: 0.2444\n",
      "Epoch 499/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5229 - acc: 0.2075 - val_loss: 0.5735 - val_acc: 0.2444\n",
      "Epoch 500/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4923 - acc: 0.2063 - val_loss: 0.6005 - val_acc: 0.2444\n",
      "Epoch 501/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5332 - acc: 0.2071 - val_loss: 0.9576 - val_acc: 0.2444\n",
      "Epoch 502/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5588 - acc: 0.2075 - val_loss: 0.7019 - val_acc: 0.2444\n",
      "Epoch 503/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5212 - acc: 0.2063 - val_loss: 0.5753 - val_acc: 0.2444\n",
      "Epoch 504/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4894 - acc: 0.2067 - val_loss: 0.5678 - val_acc: 0.2444\n",
      "Epoch 505/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4831 - acc: 0.2067 - val_loss: 0.6083 - val_acc: 0.2444\n",
      "Epoch 506/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5223 - acc: 0.2067 - val_loss: 0.5505 - val_acc: 0.2444\n",
      "Epoch 507/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5012 - acc: 0.2079 - val_loss: 0.5764 - val_acc: 0.2444\n",
      "Epoch 508/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5047 - acc: 0.2075 - val_loss: 0.6102 - val_acc: 0.2444\n",
      "Epoch 509/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5288 - acc: 0.2063 - val_loss: 0.5753 - val_acc: 0.2444\n",
      "Epoch 510/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5120 - acc: 0.2071 - val_loss: 0.5557 - val_acc: 0.2444\n",
      "Epoch 511/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5151 - acc: 0.2071 - val_loss: 0.6192 - val_acc: 0.2444\n",
      "Epoch 512/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5052 - acc: 0.2075 - val_loss: 0.6170 - val_acc: 0.2444\n",
      "Epoch 513/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5022 - acc: 0.2075 - val_loss: 0.6394 - val_acc: 0.2444\n",
      "Epoch 514/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5125 - acc: 0.2071 - val_loss: 0.5577 - val_acc: 0.2444\n",
      "Epoch 515/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5227 - acc: 0.2071 - val_loss: 0.5698 - val_acc: 0.2444\n",
      "Epoch 516/10000\n",
      "76/76 [==============================] - 4s 46ms/step - loss: 0.4981 - acc: 0.2071 - val_loss: 0.6237 - val_acc: 0.2444\n",
      "Epoch 517/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4991 - acc: 0.2067 - val_loss: 0.5810 - val_acc: 0.2444\n",
      "Epoch 518/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5120 - acc: 0.2071 - val_loss: 0.5639 - val_acc: 0.2444\n",
      "Epoch 519/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4916 - acc: 0.2075 - val_loss: 0.5575 - val_acc: 0.2444\n",
      "Epoch 520/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5139 - acc: 0.2075 - val_loss: 0.5555 - val_acc: 0.2444\n",
      "Epoch 521/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4758 - acc: 0.2067 - val_loss: 0.5484 - val_acc: 0.2444\n",
      "Epoch 522/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5178 - acc: 0.2071 - val_loss: 0.7151 - val_acc: 0.2407\n",
      "Epoch 523/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5167 - acc: 0.2071 - val_loss: 0.5851 - val_acc: 0.2444\n",
      "Epoch 524/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5091 - acc: 0.2071 - val_loss: 0.5619 - val_acc: 0.2444\n",
      "Epoch 525/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4893 - acc: 0.2079 - val_loss: 0.5619 - val_acc: 0.2444\n",
      "Epoch 526/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4852 - acc: 0.2063 - val_loss: 0.5598 - val_acc: 0.2444\n",
      "Epoch 527/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5169 - acc: 0.2071 - val_loss: 0.5786 - val_acc: 0.2444\n",
      "Epoch 528/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4942 - acc: 0.2075 - val_loss: 0.5581 - val_acc: 0.2444\n",
      "Epoch 529/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4873 - acc: 0.2067 - val_loss: 0.5882 - val_acc: 0.2444\n",
      "Epoch 530/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5142 - acc: 0.2071 - val_loss: 0.5618 - val_acc: 0.2444\n",
      "Epoch 531/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5414 - acc: 0.2071 - val_loss: 0.6105 - val_acc: 0.2444\n",
      "Epoch 532/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4898 - acc: 0.2063 - val_loss: 0.5641 - val_acc: 0.2444\n",
      "Epoch 533/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5128 - acc: 0.2075 - val_loss: 0.6080 - val_acc: 0.2444\n",
      "Epoch 534/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4847 - acc: 0.2075 - val_loss: 0.7290 - val_acc: 0.2444\n",
      "Epoch 535/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5401 - acc: 0.2059 - val_loss: 0.6057 - val_acc: 0.2444\n",
      "Epoch 536/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4889 - acc: 0.2067 - val_loss: 0.5532 - val_acc: 0.2444\n",
      "Epoch 537/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5409 - acc: 0.2075 - val_loss: 0.5811 - val_acc: 0.2444\n",
      "Epoch 538/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5061 - acc: 0.2079 - val_loss: 0.5803 - val_acc: 0.2444\n",
      "Epoch 539/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4819 - acc: 0.2083 - val_loss: 0.5744 - val_acc: 0.2444\n",
      "Epoch 540/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4879 - acc: 0.2075 - val_loss: 0.6177 - val_acc: 0.2444\n",
      "Epoch 541/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5267 - acc: 0.2075 - val_loss: 0.5554 - val_acc: 0.2444\n",
      "Epoch 542/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5160 - acc: 0.2075 - val_loss: 0.5955 - val_acc: 0.2444\n",
      "Epoch 543/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4888 - acc: 0.2075 - val_loss: 0.5950 - val_acc: 0.2444\n",
      "Epoch 544/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4945 - acc: 0.2075 - val_loss: 0.5628 - val_acc: 0.2444\n",
      "Epoch 545/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4843 - acc: 0.2071 - val_loss: 0.7487 - val_acc: 0.2407\n",
      "Epoch 546/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4802 - acc: 0.2071 - val_loss: 0.5546 - val_acc: 0.2444\n",
      "Epoch 547/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5064 - acc: 0.2067 - val_loss: 0.5745 - val_acc: 0.2444\n",
      "Epoch 548/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5064 - acc: 0.2063 - val_loss: 0.5913 - val_acc: 0.2444\n",
      "Epoch 549/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4996 - acc: 0.2059 - val_loss: 0.5568 - val_acc: 0.2444\n",
      "Epoch 550/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4854 - acc: 0.2067 - val_loss: 0.8962 - val_acc: 0.2444\n",
      "Epoch 551/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5130 - acc: 0.2075 - val_loss: 0.5444 - val_acc: 0.2444\n",
      "Epoch 552/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.5295 - acc: 0.2059 - val_loss: 0.6308 - val_acc: 0.2444\n",
      "Epoch 553/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4926 - acc: 0.2075 - val_loss: 0.6791 - val_acc: 0.2407\n",
      "Epoch 554/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5196 - acc: 0.2075 - val_loss: 0.5683 - val_acc: 0.2444\n",
      "Epoch 555/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5068 - acc: 0.2071 - val_loss: 0.5565 - val_acc: 0.2444\n",
      "Epoch 556/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5229 - acc: 0.2071 - val_loss: 0.5578 - val_acc: 0.2444\n",
      "Epoch 557/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4848 - acc: 0.2067 - val_loss: 0.5656 - val_acc: 0.2444\n",
      "Epoch 558/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5454 - acc: 0.2071 - val_loss: 0.7355 - val_acc: 0.2444\n",
      "Epoch 559/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5115 - acc: 0.2071 - val_loss: 0.5554 - val_acc: 0.2444\n",
      "Epoch 560/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4843 - acc: 0.2067 - val_loss: 0.6065 - val_acc: 0.2444\n",
      "Epoch 561/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5436 - acc: 0.2063 - val_loss: 0.5564 - val_acc: 0.2444\n",
      "Epoch 562/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5236 - acc: 0.2079 - val_loss: 0.6219 - val_acc: 0.2444\n",
      "Epoch 563/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4826 - acc: 0.2075 - val_loss: 0.5624 - val_acc: 0.2444\n",
      "Epoch 564/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5136 - acc: 0.2075 - val_loss: 0.6068 - val_acc: 0.2444\n",
      "Epoch 565/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4761 - acc: 0.2075 - val_loss: 0.5704 - val_acc: 0.2444\n",
      "Epoch 566/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5137 - acc: 0.2075 - val_loss: 0.5487 - val_acc: 0.2444\n",
      "Epoch 567/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5046 - acc: 0.2075 - val_loss: 0.5948 - val_acc: 0.2444\n",
      "Epoch 568/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4887 - acc: 0.2063 - val_loss: 0.5564 - val_acc: 0.2444\n",
      "Epoch 569/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4868 - acc: 0.2067 - val_loss: 0.5475 - val_acc: 0.2444\n",
      "Epoch 570/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5246 - acc: 0.2075 - val_loss: 0.6960 - val_acc: 0.2444\n",
      "Epoch 571/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5056 - acc: 0.2067 - val_loss: 0.6275 - val_acc: 0.2444\n",
      "Epoch 572/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4915 - acc: 0.2075 - val_loss: 0.5596 - val_acc: 0.2444\n",
      "Epoch 573/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5068 - acc: 0.2075 - val_loss: 0.5633 - val_acc: 0.2444\n",
      "Epoch 574/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.4956 - acc: 0.2071 - val_loss: 0.6794 - val_acc: 0.2444\n",
      "Epoch 575/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5513 - acc: 0.2075 - val_loss: 0.5907 - val_acc: 0.2444\n",
      "Epoch 576/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4906 - acc: 0.2071 - val_loss: 0.5514 - val_acc: 0.2444\n",
      "Epoch 577/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5061 - acc: 0.2067 - val_loss: 0.6675 - val_acc: 0.2444\n",
      "Epoch 578/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4823 - acc: 0.2071 - val_loss: 0.5642 - val_acc: 0.2444\n",
      "Epoch 579/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4780 - acc: 0.2079 - val_loss: 0.5584 - val_acc: 0.2444\n",
      "Epoch 580/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4735 - acc: 0.2075 - val_loss: 0.5828 - val_acc: 0.2444\n",
      "Epoch 581/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4830 - acc: 0.2075 - val_loss: 0.5620 - val_acc: 0.2444\n",
      "Epoch 582/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4976 - acc: 0.2063 - val_loss: 0.5813 - val_acc: 0.2444\n",
      "Epoch 583/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4787 - acc: 0.2067 - val_loss: 0.7842 - val_acc: 0.2444\n",
      "Epoch 584/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4925 - acc: 0.2067 - val_loss: 0.5816 - val_acc: 0.2444\n",
      "Epoch 585/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4810 - acc: 0.2071 - val_loss: 0.5574 - val_acc: 0.2444\n",
      "Epoch 586/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4782 - acc: 0.2071 - val_loss: 0.5420 - val_acc: 0.2444\n",
      "Epoch 587/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4856 - acc: 0.2075 - val_loss: 0.5569 - val_acc: 0.2444\n",
      "Epoch 588/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5072 - acc: 0.2071 - val_loss: 0.6211 - val_acc: 0.2407\n",
      "Epoch 589/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4730 - acc: 0.2071 - val_loss: 0.8179 - val_acc: 0.2407\n",
      "Epoch 590/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5250 - acc: 0.2067 - val_loss: 0.5895 - val_acc: 0.2444\n",
      "Epoch 591/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4731 - acc: 0.2071 - val_loss: 0.5834 - val_acc: 0.2444\n",
      "Epoch 592/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5595 - acc: 0.2067 - val_loss: 0.6102 - val_acc: 0.2444\n",
      "Epoch 593/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4802 - acc: 0.2063 - val_loss: 0.5465 - val_acc: 0.2444\n",
      "Epoch 594/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5123 - acc: 0.2075 - val_loss: 0.6410 - val_acc: 0.2444\n",
      "Epoch 595/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5113 - acc: 0.2075 - val_loss: 0.6129 - val_acc: 0.2444\n",
      "Epoch 596/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5511 - acc: 0.2075 - val_loss: 0.6414 - val_acc: 0.2407\n",
      "Epoch 597/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4818 - acc: 0.2075 - val_loss: 0.6303 - val_acc: 0.2407\n",
      "Epoch 598/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5559 - acc: 0.2067 - val_loss: 0.5732 - val_acc: 0.2444\n",
      "Epoch 599/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4796 - acc: 0.2071 - val_loss: 0.6503 - val_acc: 0.2407\n",
      "Epoch 600/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4874 - acc: 0.2071 - val_loss: 0.5427 - val_acc: 0.2444\n",
      "Epoch 601/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5278 - acc: 0.2059 - val_loss: 0.5418 - val_acc: 0.2444\n",
      "Epoch 602/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4822 - acc: 0.2071 - val_loss: 0.5593 - val_acc: 0.2444\n",
      "Epoch 603/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5065 - acc: 0.2063 - val_loss: 0.5870 - val_acc: 0.2444\n",
      "Epoch 604/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5292 - acc: 0.2079 - val_loss: 0.5472 - val_acc: 0.2444\n",
      "Epoch 605/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4861 - acc: 0.2075 - val_loss: 0.5967 - val_acc: 0.2444\n",
      "Epoch 606/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5297 - acc: 0.2075 - val_loss: 0.5806 - val_acc: 0.2444\n",
      "Epoch 607/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4972 - acc: 0.2075 - val_loss: 0.5699 - val_acc: 0.2444\n",
      "Epoch 608/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4800 - acc: 0.2071 - val_loss: 0.5620 - val_acc: 0.2444\n",
      "Epoch 609/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5063 - acc: 0.2071 - val_loss: 0.5419 - val_acc: 0.2444\n",
      "Epoch 610/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4908 - acc: 0.2075 - val_loss: 0.5537 - val_acc: 0.2444\n",
      "Epoch 611/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5024 - acc: 0.2063 - val_loss: 0.5449 - val_acc: 0.2444\n",
      "Epoch 612/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4856 - acc: 0.2067 - val_loss: 0.5670 - val_acc: 0.2444\n",
      "Epoch 613/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5360 - acc: 0.2075 - val_loss: 0.6886 - val_acc: 0.2407\n",
      "Epoch 614/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4985 - acc: 0.2079 - val_loss: 0.6461 - val_acc: 0.2407\n",
      "Epoch 615/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5067 - acc: 0.2059 - val_loss: 0.5660 - val_acc: 0.2444\n",
      "Epoch 616/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4811 - acc: 0.2075 - val_loss: 0.5523 - val_acc: 0.2444\n",
      "Epoch 617/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4830 - acc: 0.2071 - val_loss: 0.5437 - val_acc: 0.2444\n",
      "Epoch 618/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4844 - acc: 0.2067 - val_loss: 0.5715 - val_acc: 0.2444\n",
      "Epoch 619/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5236 - acc: 0.2079 - val_loss: 0.5933 - val_acc: 0.2444\n",
      "Epoch 620/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4908 - acc: 0.2075 - val_loss: 0.5514 - val_acc: 0.2444\n",
      "Epoch 621/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5306 - acc: 0.2071 - val_loss: 0.6947 - val_acc: 0.2444\n",
      "Epoch 622/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5284 - acc: 0.2063 - val_loss: 0.6635 - val_acc: 0.2444\n",
      "Epoch 623/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4766 - acc: 0.2079 - val_loss: 0.5451 - val_acc: 0.2444\n",
      "Epoch 624/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4681 - acc: 0.2075 - val_loss: 0.6234 - val_acc: 0.2407\n",
      "Epoch 625/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4942 - acc: 0.2075 - val_loss: 0.6836 - val_acc: 0.2407\n",
      "Epoch 626/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4896 - acc: 0.2071 - val_loss: 0.5444 - val_acc: 0.2444\n",
      "Epoch 627/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4751 - acc: 0.2075 - val_loss: 0.5572 - val_acc: 0.2444\n",
      "Epoch 628/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5080 - acc: 0.2071 - val_loss: 0.5392 - val_acc: 0.2444\n",
      "Epoch 629/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4881 - acc: 0.2063 - val_loss: 0.6270 - val_acc: 0.2444\n",
      "Epoch 630/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4888 - acc: 0.2075 - val_loss: 0.5588 - val_acc: 0.2444\n",
      "Epoch 631/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5405 - acc: 0.2067 - val_loss: 0.5447 - val_acc: 0.2444\n",
      "Epoch 632/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4770 - acc: 0.2071 - val_loss: 0.5430 - val_acc: 0.2444\n",
      "Epoch 633/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5064 - acc: 0.2075 - val_loss: 0.6022 - val_acc: 0.2444\n",
      "Epoch 634/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.4640 - acc: 0.2075 - val_loss: 0.5464 - val_acc: 0.2444\n",
      "Epoch 635/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4884 - acc: 0.2071 - val_loss: 0.5453 - val_acc: 0.2444\n",
      "Epoch 636/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4691 - acc: 0.2079 - val_loss: 0.5441 - val_acc: 0.2444\n",
      "Epoch 637/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5227 - acc: 0.2067 - val_loss: 0.5403 - val_acc: 0.2444\n",
      "Epoch 638/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4873 - acc: 0.2075 - val_loss: 0.5976 - val_acc: 0.2444\n",
      "Epoch 639/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5283 - acc: 0.2075 - val_loss: 0.5448 - val_acc: 0.2444\n",
      "Epoch 640/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4735 - acc: 0.2071 - val_loss: 0.6236 - val_acc: 0.2407\n",
      "Epoch 641/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5491 - acc: 0.2067 - val_loss: 0.7074 - val_acc: 0.2444\n",
      "Epoch 642/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4895 - acc: 0.2075 - val_loss: 0.5421 - val_acc: 0.2444\n",
      "Epoch 643/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4963 - acc: 0.2075 - val_loss: 0.6295 - val_acc: 0.2407\n",
      "Epoch 644/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5220 - acc: 0.2063 - val_loss: 0.5370 - val_acc: 0.2444\n",
      "Epoch 645/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4880 - acc: 0.2071 - val_loss: 0.5510 - val_acc: 0.2444\n",
      "Epoch 646/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5387 - acc: 0.2079 - val_loss: 0.5453 - val_acc: 0.2444\n",
      "Epoch 647/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5216 - acc: 0.2067 - val_loss: 0.5932 - val_acc: 0.2407\n",
      "Epoch 648/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5021 - acc: 0.2071 - val_loss: 0.5455 - val_acc: 0.2444\n",
      "Epoch 649/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4789 - acc: 0.2079 - val_loss: 0.5806 - val_acc: 0.2444\n",
      "Epoch 650/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4955 - acc: 0.2071 - val_loss: 0.5645 - val_acc: 0.2444\n",
      "Epoch 651/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4988 - acc: 0.2067 - val_loss: 0.5795 - val_acc: 0.2444\n",
      "Epoch 652/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4750 - acc: 0.2079 - val_loss: 0.5399 - val_acc: 0.2444\n",
      "Epoch 653/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4878 - acc: 0.2075 - val_loss: 0.6804 - val_acc: 0.2444\n",
      "Epoch 654/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5292 - acc: 0.2063 - val_loss: 0.6260 - val_acc: 0.2407\n",
      "Epoch 655/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4780 - acc: 0.2067 - val_loss: 0.6332 - val_acc: 0.2407\n",
      "Epoch 656/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4961 - acc: 0.2067 - val_loss: 0.5555 - val_acc: 0.2444\n",
      "Epoch 657/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4954 - acc: 0.2075 - val_loss: 0.6201 - val_acc: 0.2444\n",
      "Epoch 658/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4688 - acc: 0.2071 - val_loss: 0.6218 - val_acc: 0.2407\n",
      "Epoch 659/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4972 - acc: 0.2067 - val_loss: 0.5874 - val_acc: 0.2444\n",
      "Epoch 660/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5088 - acc: 0.2067 - val_loss: 0.5493 - val_acc: 0.2444\n",
      "Epoch 661/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4798 - acc: 0.2075 - val_loss: 0.5468 - val_acc: 0.2444\n",
      "Epoch 662/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5303 - acc: 0.2079 - val_loss: 0.5935 - val_acc: 0.2407\n",
      "Epoch 663/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5496 - acc: 0.2063 - val_loss: 0.6057 - val_acc: 0.2407\n",
      "Epoch 664/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5470 - acc: 0.2063 - val_loss: 0.7856 - val_acc: 0.2407\n",
      "Epoch 665/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5211 - acc: 0.2075 - val_loss: 0.6961 - val_acc: 0.2444\n",
      "Epoch 666/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5143 - acc: 0.2075 - val_loss: 0.5603 - val_acc: 0.2444\n",
      "Epoch 667/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4884 - acc: 0.2075 - val_loss: 0.5788 - val_acc: 0.2444\n",
      "Epoch 668/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4542 - acc: 0.2079 - val_loss: 0.5682 - val_acc: 0.2444\n",
      "Epoch 669/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4877 - acc: 0.2071 - val_loss: 0.6186 - val_acc: 0.2444\n",
      "Epoch 670/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5183 - acc: 0.2071 - val_loss: 0.6130 - val_acc: 0.2444\n",
      "Epoch 671/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4885 - acc: 0.2075 - val_loss: 0.5446 - val_acc: 0.2444\n",
      "Epoch 672/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4686 - acc: 0.2071 - val_loss: 0.5522 - val_acc: 0.2444\n",
      "Epoch 673/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5246 - acc: 0.2071 - val_loss: 0.5771 - val_acc: 0.2444\n",
      "Epoch 674/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4757 - acc: 0.2071 - val_loss: 0.5374 - val_acc: 0.2444\n",
      "Epoch 675/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4687 - acc: 0.2067 - val_loss: 0.8352 - val_acc: 0.2444\n",
      "Epoch 676/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4885 - acc: 0.2071 - val_loss: 0.5403 - val_acc: 0.2444\n",
      "Epoch 677/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5289 - acc: 0.2059 - val_loss: 0.5424 - val_acc: 0.2444\n",
      "Epoch 678/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4944 - acc: 0.2067 - val_loss: 0.5465 - val_acc: 0.2444\n",
      "Epoch 679/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4907 - acc: 0.2071 - val_loss: 0.6215 - val_acc: 0.2444\n",
      "Epoch 680/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5009 - acc: 0.2063 - val_loss: 0.5735 - val_acc: 0.2444\n",
      "Epoch 681/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4707 - acc: 0.2075 - val_loss: 0.5345 - val_acc: 0.2444\n",
      "Epoch 682/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4766 - acc: 0.2071 - val_loss: 0.5898 - val_acc: 0.2407\n",
      "Epoch 683/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4603 - acc: 0.2071 - val_loss: 0.5477 - val_acc: 0.2444\n",
      "Epoch 684/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4749 - acc: 0.2071 - val_loss: 0.5565 - val_acc: 0.2444\n",
      "Epoch 685/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4664 - acc: 0.2075 - val_loss: 0.5764 - val_acc: 0.2444\n",
      "Epoch 686/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5025 - acc: 0.2071 - val_loss: 0.6772 - val_acc: 0.2444\n",
      "Epoch 687/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4996 - acc: 0.2075 - val_loss: 0.5860 - val_acc: 0.2444\n",
      "Epoch 688/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4692 - acc: 0.2075 - val_loss: 0.5583 - val_acc: 0.2444\n",
      "Epoch 689/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5294 - acc: 0.2067 - val_loss: 0.5346 - val_acc: 0.2444\n",
      "Epoch 690/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4802 - acc: 0.2071 - val_loss: 0.7600 - val_acc: 0.2444\n",
      "Epoch 691/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4975 - acc: 0.2079 - val_loss: 0.6859 - val_acc: 0.2444\n",
      "Epoch 692/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4809 - acc: 0.2067 - val_loss: 0.5410 - val_acc: 0.2444\n",
      "Epoch 693/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4798 - acc: 0.2071 - val_loss: 0.6870 - val_acc: 0.2444\n",
      "Epoch 694/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4839 - acc: 0.2071 - val_loss: 0.5309 - val_acc: 0.2444\n",
      "Epoch 695/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4985 - acc: 0.2071 - val_loss: 0.5789 - val_acc: 0.2444\n",
      "Epoch 696/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4975 - acc: 0.2079 - val_loss: 0.6341 - val_acc: 0.2407\n",
      "Epoch 697/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4869 - acc: 0.2059 - val_loss: 0.5886 - val_acc: 0.2407\n",
      "Epoch 698/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4590 - acc: 0.2071 - val_loss: 0.5449 - val_acc: 0.2444\n",
      "Epoch 699/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4975 - acc: 0.2079 - val_loss: 0.5665 - val_acc: 0.2444\n",
      "Epoch 700/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4554 - acc: 0.2079 - val_loss: 0.5353 - val_acc: 0.2444\n",
      "Epoch 701/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4838 - acc: 0.2071 - val_loss: 0.5412 - val_acc: 0.2444\n",
      "Epoch 702/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4839 - acc: 0.2079 - val_loss: 0.5469 - val_acc: 0.2444\n",
      "Epoch 703/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5511 - acc: 0.2067 - val_loss: 0.5910 - val_acc: 0.2407\n",
      "Epoch 704/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5317 - acc: 0.2075 - val_loss: 0.5454 - val_acc: 0.2444\n",
      "Epoch 705/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4803 - acc: 0.2063 - val_loss: 0.5324 - val_acc: 0.2444\n",
      "Epoch 706/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5035 - acc: 0.2063 - val_loss: 0.6377 - val_acc: 0.2407\n",
      "Epoch 707/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4628 - acc: 0.2075 - val_loss: 0.5313 - val_acc: 0.2444\n",
      "Epoch 708/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4797 - acc: 0.2067 - val_loss: 0.6283 - val_acc: 0.2407\n",
      "Epoch 709/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5266 - acc: 0.2067 - val_loss: 0.6974 - val_acc: 0.2407\n",
      "Epoch 710/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5106 - acc: 0.2063 - val_loss: 0.5362 - val_acc: 0.2444\n",
      "Epoch 711/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4604 - acc: 0.2071 - val_loss: 0.5494 - val_acc: 0.2444\n",
      "Epoch 712/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4916 - acc: 0.2071 - val_loss: 0.5401 - val_acc: 0.2444\n",
      "Epoch 713/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4658 - acc: 0.2067 - val_loss: 0.5533 - val_acc: 0.2444\n",
      "Epoch 714/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4734 - acc: 0.2071 - val_loss: 0.5298 - val_acc: 0.2444\n",
      "Epoch 715/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4929 - acc: 0.2075 - val_loss: 0.5709 - val_acc: 0.2444\n",
      "Epoch 716/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4913 - acc: 0.2075 - val_loss: 0.6261 - val_acc: 0.2407\n",
      "Epoch 717/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4880 - acc: 0.2075 - val_loss: 0.6210 - val_acc: 0.2407\n",
      "Epoch 718/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4952 - acc: 0.2075 - val_loss: 0.6304 - val_acc: 0.2407\n",
      "Epoch 719/10000\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.4824 - acc: 0.207 - 3s 35ms/step - loss: 0.4832 - acc: 0.2071 - val_loss: 0.5457 - val_acc: 0.2444\n",
      "Epoch 720/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4639 - acc: 0.2075 - val_loss: 0.5887 - val_acc: 0.2407\n",
      "Epoch 721/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4961 - acc: 0.2075 - val_loss: 0.5426 - val_acc: 0.2444\n",
      "Epoch 722/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4950 - acc: 0.2071 - val_loss: 0.5322 - val_acc: 0.2444\n",
      "Epoch 723/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4714 - acc: 0.2075 - val_loss: 0.5341 - val_acc: 0.2444\n",
      "Epoch 724/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4843 - acc: 0.2067 - val_loss: 0.5367 - val_acc: 0.2444\n",
      "Epoch 725/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4697 - acc: 0.2071 - val_loss: 0.5312 - val_acc: 0.2444\n",
      "Epoch 726/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4763 - acc: 0.2071 - val_loss: 0.5548 - val_acc: 0.2444\n",
      "Epoch 727/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5002 - acc: 0.2075 - val_loss: 0.5295 - val_acc: 0.2444\n",
      "Epoch 728/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4841 - acc: 0.2071 - val_loss: 0.5300 - val_acc: 0.2444\n",
      "Epoch 729/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4665 - acc: 0.2063 - val_loss: 0.6088 - val_acc: 0.2444\n",
      "Epoch 730/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5133 - acc: 0.2067 - val_loss: 0.5833 - val_acc: 0.2444\n",
      "Epoch 731/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4797 - acc: 0.2075 - val_loss: 0.8013 - val_acc: 0.2444\n",
      "Epoch 732/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5419 - acc: 0.2071 - val_loss: 0.5241 - val_acc: 0.2444\n",
      "Epoch 733/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4836 - acc: 0.2067 - val_loss: 0.5597 - val_acc: 0.2444\n",
      "Epoch 734/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5128 - acc: 0.2067 - val_loss: 0.5807 - val_acc: 0.2444\n",
      "Epoch 735/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4843 - acc: 0.2075 - val_loss: 0.5357 - val_acc: 0.2444\n",
      "Epoch 736/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4788 - acc: 0.2075 - val_loss: 0.5571 - val_acc: 0.2407\n",
      "Epoch 737/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4833 - acc: 0.2071 - val_loss: 0.5540 - val_acc: 0.2444\n",
      "Epoch 738/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4843 - acc: 0.2075 - val_loss: 0.6074 - val_acc: 0.2444\n",
      "Epoch 739/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5185 - acc: 0.2079 - val_loss: 0.5778 - val_acc: 0.2444\n",
      "Epoch 740/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5005 - acc: 0.2063 - val_loss: 0.9414 - val_acc: 0.2444\n",
      "Epoch 741/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5150 - acc: 0.2079 - val_loss: 0.5441 - val_acc: 0.2444\n",
      "Epoch 742/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4496 - acc: 0.2075 - val_loss: 0.5286 - val_acc: 0.2444\n",
      "Epoch 743/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4665 - acc: 0.2075 - val_loss: 0.5504 - val_acc: 0.2444\n",
      "Epoch 744/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4686 - acc: 0.2075 - val_loss: 0.5272 - val_acc: 0.2444\n",
      "Epoch 745/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4824 - acc: 0.2067 - val_loss: 0.5344 - val_acc: 0.2444\n",
      "Epoch 746/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4715 - acc: 0.2071 - val_loss: 0.5328 - val_acc: 0.2444\n",
      "Epoch 747/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5129 - acc: 0.2063 - val_loss: 0.5378 - val_acc: 0.2444\n",
      "Epoch 748/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4639 - acc: 0.2071 - val_loss: 0.5861 - val_acc: 0.2444\n",
      "Epoch 749/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4664 - acc: 0.2071 - val_loss: 0.5465 - val_acc: 0.2444\n",
      "Epoch 750/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4628 - acc: 0.2071 - val_loss: 0.5259 - val_acc: 0.2444\n",
      "Epoch 751/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4920 - acc: 0.2063 - val_loss: 0.6048 - val_acc: 0.2444\n",
      "Epoch 752/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4882 - acc: 0.2063 - val_loss: 0.5299 - val_acc: 0.2444\n",
      "Epoch 753/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4793 - acc: 0.2083 - val_loss: 0.5399 - val_acc: 0.2444\n",
      "Epoch 754/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4945 - acc: 0.2075 - val_loss: 0.5361 - val_acc: 0.2444\n",
      "Epoch 755/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4563 - acc: 0.2075 - val_loss: 0.5295 - val_acc: 0.2444\n",
      "Epoch 756/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4565 - acc: 0.2071 - val_loss: 0.5840 - val_acc: 0.2444\n",
      "Epoch 757/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4973 - acc: 0.2075 - val_loss: 0.5447 - val_acc: 0.2444\n",
      "Epoch 758/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5103 - acc: 0.2079 - val_loss: 0.6071 - val_acc: 0.2444\n",
      "Epoch 759/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5026 - acc: 0.2075 - val_loss: 0.5267 - val_acc: 0.2444\n",
      "Epoch 760/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4662 - acc: 0.2075 - val_loss: 0.5994 - val_acc: 0.2407\n",
      "Epoch 761/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5045 - acc: 0.2063 - val_loss: 0.9030 - val_acc: 0.2444\n",
      "Epoch 762/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5126 - acc: 0.2067 - val_loss: 0.5261 - val_acc: 0.2444\n",
      "Epoch 763/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4684 - acc: 0.2071 - val_loss: 0.5518 - val_acc: 0.2444\n",
      "Epoch 764/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4872 - acc: 0.2075 - val_loss: 0.5443 - val_acc: 0.2444\n",
      "Epoch 765/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4802 - acc: 0.2071 - val_loss: 0.5289 - val_acc: 0.2444\n",
      "Epoch 766/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4841 - acc: 0.2063 - val_loss: 0.5420 - val_acc: 0.2444\n",
      "Epoch 767/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5091 - acc: 0.2079 - val_loss: 0.7880 - val_acc: 0.2444\n",
      "Epoch 768/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5184 - acc: 0.2067 - val_loss: 0.5830 - val_acc: 0.2407\n",
      "Epoch 769/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4915 - acc: 0.2071 - val_loss: 0.8045 - val_acc: 0.2407\n",
      "Epoch 770/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4836 - acc: 0.2063 - val_loss: 0.5291 - val_acc: 0.2444\n",
      "Epoch 771/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4761 - acc: 0.2075 - val_loss: 0.5350 - val_acc: 0.2444\n",
      "Epoch 772/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4982 - acc: 0.2071 - val_loss: 0.5472 - val_acc: 0.2444\n",
      "Epoch 773/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4660 - acc: 0.2071 - val_loss: 0.5348 - val_acc: 0.2444\n",
      "Epoch 774/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5199 - acc: 0.2075 - val_loss: 0.6159 - val_acc: 0.2444\n",
      "Epoch 775/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4638 - acc: 0.2075 - val_loss: 0.5729 - val_acc: 0.2444\n",
      "Epoch 776/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4937 - acc: 0.2067 - val_loss: 1.0092 - val_acc: 0.2370\n",
      "Epoch 777/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5195 - acc: 0.2059 - val_loss: 0.5280 - val_acc: 0.2444\n",
      "Epoch 778/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4937 - acc: 0.2075 - val_loss: 0.5308 - val_acc: 0.2444\n",
      "Epoch 779/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4824 - acc: 0.2071 - val_loss: 0.6835 - val_acc: 0.2444\n",
      "Epoch 780/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4993 - acc: 0.2063 - val_loss: 0.7469 - val_acc: 0.2444\n",
      "Epoch 781/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4681 - acc: 0.2071 - val_loss: 0.6028 - val_acc: 0.2407\n",
      "Epoch 782/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4693 - acc: 0.2071 - val_loss: 0.5222 - val_acc: 0.2444\n",
      "Epoch 783/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4832 - acc: 0.2075 - val_loss: 0.5697 - val_acc: 0.2444\n",
      "Epoch 784/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4681 - acc: 0.2075 - val_loss: 0.5634 - val_acc: 0.2444\n",
      "Epoch 785/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5191 - acc: 0.2075 - val_loss: 0.6625 - val_acc: 0.2444\n",
      "Epoch 786/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4623 - acc: 0.2079 - val_loss: 0.5484 - val_acc: 0.2444\n",
      "Epoch 787/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4851 - acc: 0.2071 - val_loss: 0.6627 - val_acc: 0.2407\n",
      "Epoch 788/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5016 - acc: 0.2071 - val_loss: 0.6864 - val_acc: 0.2444\n",
      "Epoch 789/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4884 - acc: 0.2079 - val_loss: 0.6847 - val_acc: 0.2444\n",
      "Epoch 790/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5169 - acc: 0.2071 - val_loss: 0.6899 - val_acc: 0.2407\n",
      "Epoch 791/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4726 - acc: 0.2075 - val_loss: 0.6446 - val_acc: 0.2444\n",
      "Epoch 792/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4995 - acc: 0.2071 - val_loss: 0.5545 - val_acc: 0.2444\n",
      "Epoch 793/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4613 - acc: 0.2071 - val_loss: 0.5666 - val_acc: 0.2444\n",
      "Epoch 794/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4761 - acc: 0.2067 - val_loss: 0.5755 - val_acc: 0.2407\n",
      "Epoch 795/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4945 - acc: 0.2079 - val_loss: 0.5377 - val_acc: 0.2444\n",
      "Epoch 796/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4843 - acc: 0.2075 - val_loss: 0.5243 - val_acc: 0.2444\n",
      "Epoch 797/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4681 - acc: 0.2071 - val_loss: 0.8125 - val_acc: 0.2407\n",
      "Epoch 798/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4956 - acc: 0.2071 - val_loss: 0.5537 - val_acc: 0.2407\n",
      "Epoch 799/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4526 - acc: 0.2079 - val_loss: 0.5494 - val_acc: 0.2407\n",
      "Epoch 800/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4531 - acc: 0.2079 - val_loss: 0.5419 - val_acc: 0.2444\n",
      "Epoch 801/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5308 - acc: 0.2071 - val_loss: 0.5437 - val_acc: 0.2444\n",
      "Epoch 802/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4671 - acc: 0.2071 - val_loss: 0.5379 - val_acc: 0.2444\n",
      "Epoch 803/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4716 - acc: 0.2067 - val_loss: 0.5919 - val_acc: 0.2407\n",
      "Epoch 804/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5025 - acc: 0.2075 - val_loss: 0.5292 - val_acc: 0.2444\n",
      "Epoch 805/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4531 - acc: 0.2071 - val_loss: 0.6700 - val_acc: 0.2444\n",
      "Epoch 806/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4888 - acc: 0.2079 - val_loss: 0.5362 - val_acc: 0.2444\n",
      "Epoch 807/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4891 - acc: 0.2067 - val_loss: 0.5281 - val_acc: 0.2444\n",
      "Epoch 808/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4846 - acc: 0.2071 - val_loss: 0.6860 - val_acc: 0.2444\n",
      "Epoch 809/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4831 - acc: 0.2071 - val_loss: 0.5689 - val_acc: 0.2444\n",
      "Epoch 810/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4786 - acc: 0.2075 - val_loss: 0.5602 - val_acc: 0.2444\n",
      "Epoch 811/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4483 - acc: 0.2071 - val_loss: 0.5220 - val_acc: 0.2444\n",
      "Epoch 812/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4986 - acc: 0.2071 - val_loss: 0.6068 - val_acc: 0.2407\n",
      "Epoch 813/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4594 - acc: 0.2075 - val_loss: 0.5223 - val_acc: 0.2444\n",
      "Epoch 814/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4874 - acc: 0.2063 - val_loss: 0.5230 - val_acc: 0.2444\n",
      "Epoch 815/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4692 - acc: 0.2075 - val_loss: 0.5425 - val_acc: 0.2444\n",
      "Epoch 816/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4545 - acc: 0.2079 - val_loss: 0.5685 - val_acc: 0.2444\n",
      "Epoch 817/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4701 - acc: 0.2075 - val_loss: 0.5334 - val_acc: 0.2444\n",
      "Epoch 818/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5082 - acc: 0.2063 - val_loss: 0.6079 - val_acc: 0.2407\n",
      "Epoch 819/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4881 - acc: 0.2079 - val_loss: 0.5284 - val_acc: 0.2444\n",
      "Epoch 820/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4601 - acc: 0.2079 - val_loss: 0.5465 - val_acc: 0.2407\n",
      "Epoch 821/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4647 - acc: 0.2071 - val_loss: 0.6191 - val_acc: 0.2407\n",
      "Epoch 822/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5136 - acc: 0.2075 - val_loss: 0.5304 - val_acc: 0.2444\n",
      "Epoch 823/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4551 - acc: 0.2071 - val_loss: 0.8498 - val_acc: 0.2370\n",
      "Epoch 824/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5017 - acc: 0.2071 - val_loss: 0.5423 - val_acc: 0.2444\n",
      "Epoch 825/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5078 - acc: 0.2075 - val_loss: 0.5397 - val_acc: 0.2407\n",
      "Epoch 826/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4556 - acc: 0.2075 - val_loss: 0.5251 - val_acc: 0.2444\n",
      "Epoch 827/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5092 - acc: 0.2067 - val_loss: 0.5607 - val_acc: 0.2444\n",
      "Epoch 828/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5210 - acc: 0.2075 - val_loss: 0.6073 - val_acc: 0.2407\n",
      "Epoch 829/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4592 - acc: 0.2063 - val_loss: 0.5578 - val_acc: 0.2444\n",
      "Epoch 830/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4691 - acc: 0.2071 - val_loss: 0.5247 - val_acc: 0.2444\n",
      "Epoch 831/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4769 - acc: 0.2071 - val_loss: 0.6509 - val_acc: 0.2444\n",
      "Epoch 832/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4757 - acc: 0.2075 - val_loss: 0.5349 - val_acc: 0.2444\n",
      "Epoch 833/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4519 - acc: 0.2075 - val_loss: 0.5298 - val_acc: 0.2444\n",
      "Epoch 834/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4596 - acc: 0.2071 - val_loss: 0.5645 - val_acc: 0.2407\n",
      "Epoch 835/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4969 - acc: 0.2059 - val_loss: 0.6456 - val_acc: 0.2444\n",
      "Epoch 836/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4896 - acc: 0.2075 - val_loss: 0.5212 - val_acc: 0.2444\n",
      "Epoch 837/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5079 - acc: 0.2079 - val_loss: 0.5418 - val_acc: 0.2444\n",
      "Epoch 838/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4788 - acc: 0.2075 - val_loss: 0.5307 - val_acc: 0.2444\n",
      "Epoch 839/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4681 - acc: 0.2075 - val_loss: 0.5708 - val_acc: 0.2444\n",
      "Epoch 840/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4581 - acc: 0.2071 - val_loss: 0.5606 - val_acc: 0.2407\n",
      "Epoch 841/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4741 - acc: 0.2079 - val_loss: 0.5297 - val_acc: 0.2444\n",
      "Epoch 842/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4839 - acc: 0.2079 - val_loss: 0.5417 - val_acc: 0.2444\n",
      "Epoch 843/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4712 - acc: 0.2071 - val_loss: 0.5287 - val_acc: 0.2444\n",
      "Epoch 844/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4507 - acc: 0.2079 - val_loss: 0.5368 - val_acc: 0.2444\n",
      "Epoch 845/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4452 - acc: 0.2075 - val_loss: 0.5296 - val_acc: 0.2444\n",
      "Epoch 846/10000\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.4977 - acc: 0.207 - 3s 35ms/step - loss: 0.4947 - acc: 0.2067 - val_loss: 0.5422 - val_acc: 0.2444\n",
      "Epoch 847/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4620 - acc: 0.2071 - val_loss: 0.5249 - val_acc: 0.2444\n",
      "Epoch 848/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4876 - acc: 0.2075 - val_loss: 0.5402 - val_acc: 0.2407\n",
      "Epoch 849/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.5077 - acc: 0.2071 - val_loss: 0.5430 - val_acc: 0.2407\n",
      "Epoch 850/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4605 - acc: 0.2071 - val_loss: 0.5155 - val_acc: 0.2444\n",
      "Epoch 851/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4942 - acc: 0.2071 - val_loss: 0.5369 - val_acc: 0.2407\n",
      "Epoch 852/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4484 - acc: 0.2075 - val_loss: 0.5408 - val_acc: 0.2407\n",
      "Epoch 853/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4582 - acc: 0.2075 - val_loss: 0.5147 - val_acc: 0.2444\n",
      "Epoch 854/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4767 - acc: 0.2071 - val_loss: 0.5293 - val_acc: 0.2407\n",
      "Epoch 855/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4652 - acc: 0.2075 - val_loss: 0.5272 - val_acc: 0.2407\n",
      "Epoch 856/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4783 - acc: 0.2079 - val_loss: 0.5181 - val_acc: 0.2444\n",
      "Epoch 857/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4687 - acc: 0.2079 - val_loss: 0.5388 - val_acc: 0.2444\n",
      "Epoch 858/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4550 - acc: 0.2067 - val_loss: 0.5391 - val_acc: 0.2407\n",
      "Epoch 859/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4680 - acc: 0.2067 - val_loss: 0.6615 - val_acc: 0.2407\n",
      "Epoch 860/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.5202 - acc: 0.2071 - val_loss: 0.6574 - val_acc: 0.2444\n",
      "Epoch 861/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4805 - acc: 0.2079 - val_loss: 0.5288 - val_acc: 0.2407\n",
      "Epoch 862/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4864 - acc: 0.2071 - val_loss: 0.5798 - val_acc: 0.2407\n",
      "Epoch 863/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4710 - acc: 0.2079 - val_loss: 0.7494 - val_acc: 0.2444\n",
      "Epoch 864/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.4789 - acc: 0.2075 - val_loss: 0.5233 - val_acc: 0.2444\n",
      "Epoch 865/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4519 - acc: 0.2079 - val_loss: 0.5255 - val_acc: 0.2407\n",
      "Epoch 866/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4752 - acc: 0.2071 - val_loss: 0.6667 - val_acc: 0.2444\n",
      "Epoch 867/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4609 - acc: 0.2075 - val_loss: 0.5198 - val_acc: 0.2444\n",
      "Epoch 868/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4605 - acc: 0.2075 - val_loss: 0.5245 - val_acc: 0.2444\n",
      "Epoch 869/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4654 - acc: 0.2075 - val_loss: 0.7210 - val_acc: 0.2407\n",
      "Epoch 870/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4625 - acc: 0.2071 - val_loss: 0.5581 - val_acc: 0.2444\n",
      "Epoch 871/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4571 - acc: 0.2075 - val_loss: 0.5310 - val_acc: 0.2407\n",
      "Epoch 872/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4615 - acc: 0.2067 - val_loss: 0.5569 - val_acc: 0.2407\n",
      "Epoch 873/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4896 - acc: 0.2071 - val_loss: 0.5403 - val_acc: 0.2444\n",
      "Epoch 874/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4749 - acc: 0.2075 - val_loss: 0.5419 - val_acc: 0.2407\n",
      "Epoch 875/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4607 - acc: 0.2079 - val_loss: 0.5204 - val_acc: 0.2444\n",
      "Epoch 876/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.4683 - acc: 0.2075 - val_loss: 0.6009 - val_acc: 0.2407\n",
      "Epoch 877/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4896 - acc: 0.2067 - val_loss: 0.5663 - val_acc: 0.2444\n",
      "Epoch 878/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4718 - acc: 0.2075 - val_loss: 0.5984 - val_acc: 0.2407\n",
      "Epoch 879/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4629 - acc: 0.2071 - val_loss: 0.5441 - val_acc: 0.2444\n",
      "Epoch 880/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4563 - acc: 0.2075 - val_loss: 0.5436 - val_acc: 0.2407\n",
      "Epoch 881/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4549 - acc: 0.2075 - val_loss: 0.5234 - val_acc: 0.2444\n",
      "Epoch 882/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4630 - acc: 0.2075 - val_loss: 0.5277 - val_acc: 0.2444\n",
      "Epoch 883/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4455 - acc: 0.2075 - val_loss: 0.5359 - val_acc: 0.2407\n",
      "Epoch 884/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4945 - acc: 0.2071 - val_loss: 0.5248 - val_acc: 0.2444\n",
      "Epoch 885/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4825 - acc: 0.2071 - val_loss: 0.9068 - val_acc: 0.2444\n",
      "Epoch 886/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4655 - acc: 0.2075 - val_loss: 0.6237 - val_acc: 0.2444\n",
      "Epoch 887/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4691 - acc: 0.2067 - val_loss: 0.5239 - val_acc: 0.2444\n",
      "Epoch 888/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4865 - acc: 0.2075 - val_loss: 0.5191 - val_acc: 0.2444\n",
      "Epoch 889/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4785 - acc: 0.2063 - val_loss: 0.5201 - val_acc: 0.2444\n",
      "Epoch 890/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5038 - acc: 0.2071 - val_loss: 0.6952 - val_acc: 0.2407\n",
      "Epoch 891/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4616 - acc: 0.2075 - val_loss: 0.6306 - val_acc: 0.2444\n",
      "Epoch 892/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4813 - acc: 0.2071 - val_loss: 0.5283 - val_acc: 0.2444\n",
      "Epoch 893/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4833 - acc: 0.2075 - val_loss: 0.7872 - val_acc: 0.2444\n",
      "Epoch 894/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5062 - acc: 0.2071 - val_loss: 0.7599 - val_acc: 0.2444\n",
      "Epoch 895/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4826 - acc: 0.2067 - val_loss: 0.5943 - val_acc: 0.2444\n",
      "Epoch 896/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4568 - acc: 0.2079 - val_loss: 0.5303 - val_acc: 0.2407\n",
      "Epoch 897/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4457 - acc: 0.2079 - val_loss: 0.5248 - val_acc: 0.2444\n",
      "Epoch 898/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4577 - acc: 0.2071 - val_loss: 0.5395 - val_acc: 0.2407\n",
      "Epoch 899/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4771 - acc: 0.2071 - val_loss: 0.5407 - val_acc: 0.2407\n",
      "Epoch 900/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4776 - acc: 0.2063 - val_loss: 0.5339 - val_acc: 0.2444\n",
      "Epoch 901/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4708 - acc: 0.2075 - val_loss: 0.5206 - val_acc: 0.2407\n",
      "Epoch 902/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4670 - acc: 0.2079 - val_loss: 0.5278 - val_acc: 0.2407\n",
      "Epoch 903/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4687 - acc: 0.2079 - val_loss: 0.5268 - val_acc: 0.2407\n",
      "Epoch 904/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4514 - acc: 0.2075 - val_loss: 0.5888 - val_acc: 0.2444\n",
      "Epoch 905/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4894 - acc: 0.2079 - val_loss: 0.5207 - val_acc: 0.2444\n",
      "Epoch 906/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4734 - acc: 0.2079 - val_loss: 0.5928 - val_acc: 0.2407\n",
      "Epoch 907/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4823 - acc: 0.2075 - val_loss: 0.7615 - val_acc: 0.2444\n",
      "Epoch 908/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4940 - acc: 0.2071 - val_loss: 0.5315 - val_acc: 0.2407\n",
      "Epoch 909/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5071 - acc: 0.2075 - val_loss: 0.5183 - val_acc: 0.2444\n",
      "Epoch 910/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4500 - acc: 0.2075 - val_loss: 0.5546 - val_acc: 0.2407\n",
      "Epoch 911/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4386 - acc: 0.2075 - val_loss: 0.6816 - val_acc: 0.2444\n",
      "Epoch 912/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4751 - acc: 0.2079 - val_loss: 0.5190 - val_acc: 0.2407\n",
      "Epoch 913/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4570 - acc: 0.2071 - val_loss: 0.7504 - val_acc: 0.2444\n",
      "Epoch 914/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4777 - acc: 0.2075 - val_loss: 0.6670 - val_acc: 0.2444\n",
      "Epoch 915/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4753 - acc: 0.2071 - val_loss: 0.5266 - val_acc: 0.2444\n",
      "Epoch 916/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4987 - acc: 0.2075 - val_loss: 0.7115 - val_acc: 0.2444\n",
      "Epoch 917/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4729 - acc: 0.2075 - val_loss: 0.5590 - val_acc: 0.2444\n",
      "Epoch 918/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4591 - acc: 0.2071 - val_loss: 0.5906 - val_acc: 0.2444\n",
      "Epoch 919/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4674 - acc: 0.2079 - val_loss: 0.6196 - val_acc: 0.2407\n",
      "Epoch 920/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4702 - acc: 0.2075 - val_loss: 0.5153 - val_acc: 0.2444\n",
      "Epoch 921/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5002 - acc: 0.2075 - val_loss: 0.5260 - val_acc: 0.2444\n",
      "Epoch 922/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4592 - acc: 0.2075 - val_loss: 0.5146 - val_acc: 0.2407\n",
      "Epoch 923/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4501 - acc: 0.2079 - val_loss: 0.5554 - val_acc: 0.2444\n",
      "Epoch 924/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4435 - acc: 0.2075 - val_loss: 0.5193 - val_acc: 0.2444\n",
      "Epoch 925/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4784 - acc: 0.2071 - val_loss: 0.5220 - val_acc: 0.2444\n",
      "Epoch 926/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4418 - acc: 0.2075 - val_loss: 0.5474 - val_acc: 0.2407\n",
      "Epoch 927/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4712 - acc: 0.2075 - val_loss: 0.5361 - val_acc: 0.2407\n",
      "Epoch 928/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5024 - acc: 0.2067 - val_loss: 0.5428 - val_acc: 0.2407\n",
      "Epoch 929/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4459 - acc: 0.2075 - val_loss: 0.5875 - val_acc: 0.2444\n",
      "Epoch 930/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5102 - acc: 0.2071 - val_loss: 0.5439 - val_acc: 0.2407\n",
      "Epoch 931/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4482 - acc: 0.2071 - val_loss: 0.5247 - val_acc: 0.2444\n",
      "Epoch 932/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4512 - acc: 0.2075 - val_loss: 0.5715 - val_acc: 0.2407\n",
      "Epoch 933/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4819 - acc: 0.2071 - val_loss: 0.5156 - val_acc: 0.2444\n",
      "Epoch 934/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4582 - acc: 0.2071 - val_loss: 0.5619 - val_acc: 0.2444\n",
      "Epoch 935/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4707 - acc: 0.2067 - val_loss: 0.5732 - val_acc: 0.2407\n",
      "Epoch 936/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4695 - acc: 0.2075 - val_loss: 0.5162 - val_acc: 0.2444\n",
      "Epoch 937/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4498 - acc: 0.2075 - val_loss: 0.5474 - val_acc: 0.2407\n",
      "Epoch 938/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5146 - acc: 0.2071 - val_loss: 0.5450 - val_acc: 0.2444\n",
      "Epoch 939/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4663 - acc: 0.2071 - val_loss: 0.6257 - val_acc: 0.2407\n",
      "Epoch 940/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4508 - acc: 0.2079 - val_loss: 0.5513 - val_acc: 0.2407\n",
      "Epoch 941/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4763 - acc: 0.2079 - val_loss: 0.5454 - val_acc: 0.2407\n",
      "Epoch 942/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4842 - acc: 0.2075 - val_loss: 0.5487 - val_acc: 0.2444\n",
      "Epoch 943/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4750 - acc: 0.2063 - val_loss: 0.5821 - val_acc: 0.2407\n",
      "Epoch 944/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4611 - acc: 0.2071 - val_loss: 0.6772 - val_acc: 0.2444\n",
      "Epoch 945/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4580 - acc: 0.2079 - val_loss: 0.5157 - val_acc: 0.2444\n",
      "Epoch 946/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4583 - acc: 0.2071 - val_loss: 0.5150 - val_acc: 0.2407\n",
      "Epoch 947/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4627 - acc: 0.2075 - val_loss: 0.5753 - val_acc: 0.2444\n",
      "Epoch 948/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4797 - acc: 0.2063 - val_loss: 0.6467 - val_acc: 0.2444\n",
      "Epoch 949/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5011 - acc: 0.2067 - val_loss: 0.5220 - val_acc: 0.2407\n",
      "Epoch 950/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4454 - acc: 0.2071 - val_loss: 0.5390 - val_acc: 0.2444\n",
      "Epoch 951/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4557 - acc: 0.2079 - val_loss: 0.6321 - val_acc: 0.2407\n",
      "Epoch 952/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4663 - acc: 0.2075 - val_loss: 0.5482 - val_acc: 0.2407\n",
      "Epoch 953/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4749 - acc: 0.2075 - val_loss: 0.5233 - val_acc: 0.2444\n",
      "Epoch 954/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4474 - acc: 0.2067 - val_loss: 0.5206 - val_acc: 0.2407\n",
      "Epoch 955/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4355 - acc: 0.2079 - val_loss: 0.7623 - val_acc: 0.2444\n",
      "Epoch 956/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4752 - acc: 0.2075 - val_loss: 0.6005 - val_acc: 0.2444\n",
      "Epoch 957/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4683 - acc: 0.2075 - val_loss: 0.5438 - val_acc: 0.2407\n",
      "Epoch 958/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4460 - acc: 0.2075 - val_loss: 0.5055 - val_acc: 0.2444\n",
      "Epoch 959/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4779 - acc: 0.2075 - val_loss: 0.5215 - val_acc: 0.2444\n",
      "Epoch 960/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4695 - acc: 0.2071 - val_loss: 0.5110 - val_acc: 0.2444\n",
      "Epoch 961/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4829 - acc: 0.2071 - val_loss: 0.7189 - val_acc: 0.2407\n",
      "Epoch 962/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4633 - acc: 0.2075 - val_loss: 0.5215 - val_acc: 0.2407\n",
      "Epoch 963/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4765 - acc: 0.2075 - val_loss: 0.5244 - val_acc: 0.2444\n",
      "Epoch 964/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4496 - acc: 0.2071 - val_loss: 0.4890 - val_acc: 0.2444\n",
      "Epoch 965/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4571 - acc: 0.2071 - val_loss: 0.5472 - val_acc: 0.2444\n",
      "Epoch 966/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4700 - acc: 0.2067 - val_loss: 0.5117 - val_acc: 0.2444\n",
      "Epoch 967/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4654 - acc: 0.2079 - val_loss: 0.5564 - val_acc: 0.2407\n",
      "Epoch 968/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4632 - acc: 0.2067 - val_loss: 0.7325 - val_acc: 0.2407\n",
      "Epoch 969/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4821 - acc: 0.2075 - val_loss: 0.5224 - val_acc: 0.2407\n",
      "Epoch 970/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4677 - acc: 0.2075 - val_loss: 0.7190 - val_acc: 0.2444\n",
      "Epoch 971/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4672 - acc: 0.2075 - val_loss: 0.5102 - val_acc: 0.2444\n",
      "Epoch 972/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4451 - acc: 0.2075 - val_loss: 0.5384 - val_acc: 0.2407\n",
      "Epoch 973/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5013 - acc: 0.2071 - val_loss: 0.6633 - val_acc: 0.2407\n",
      "Epoch 974/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5543 - acc: 0.2059 - val_loss: 0.6146 - val_acc: 0.2444\n",
      "Epoch 975/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4776 - acc: 0.2071 - val_loss: 0.5175 - val_acc: 0.2444\n",
      "Epoch 976/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4420 - acc: 0.2075 - val_loss: 0.6243 - val_acc: 0.2407\n",
      "Epoch 977/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4826 - acc: 0.2071 - val_loss: 0.5141 - val_acc: 0.2444\n",
      "Epoch 978/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4424 - acc: 0.2079 - val_loss: 0.5106 - val_acc: 0.2444\n",
      "Epoch 979/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4515 - acc: 0.2071 - val_loss: 0.5180 - val_acc: 0.2444\n",
      "Epoch 980/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4453 - acc: 0.2079 - val_loss: 0.5219 - val_acc: 0.2444\n",
      "Epoch 981/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4581 - acc: 0.2075 - val_loss: 0.5473 - val_acc: 0.2444\n",
      "Epoch 982/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4585 - acc: 0.2075 - val_loss: 0.6107 - val_acc: 0.2444\n",
      "Epoch 983/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4561 - acc: 0.2075 - val_loss: 0.4993 - val_acc: 0.2444\n",
      "Epoch 984/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4677 - acc: 0.2071 - val_loss: 0.7454 - val_acc: 0.2407\n",
      "Epoch 985/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4641 - acc: 0.2067 - val_loss: 0.5131 - val_acc: 0.2444\n",
      "Epoch 986/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4471 - acc: 0.2075 - val_loss: 0.5093 - val_acc: 0.2444\n",
      "Epoch 987/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4575 - acc: 0.2063 - val_loss: 0.5304 - val_acc: 0.2444\n",
      "Epoch 988/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5078 - acc: 0.2054 - val_loss: 0.5825 - val_acc: 0.2444\n",
      "Epoch 989/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4688 - acc: 0.2075 - val_loss: 0.5066 - val_acc: 0.2407\n",
      "Epoch 990/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4727 - acc: 0.2079 - val_loss: 0.5141 - val_acc: 0.2407\n",
      "Epoch 991/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4488 - acc: 0.2067 - val_loss: 0.5181 - val_acc: 0.2407\n",
      "Epoch 992/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4876 - acc: 0.2075 - val_loss: 0.8318 - val_acc: 0.2444\n",
      "Epoch 993/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4657 - acc: 0.2079 - val_loss: 0.5138 - val_acc: 0.2407\n",
      "Epoch 994/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4503 - acc: 0.2075 - val_loss: 0.5226 - val_acc: 0.2407\n",
      "Epoch 995/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4403 - acc: 0.2079 - val_loss: 0.5412 - val_acc: 0.2444\n",
      "Epoch 996/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4533 - acc: 0.2075 - val_loss: 0.5354 - val_acc: 0.2444\n",
      "Epoch 997/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4691 - acc: 0.2071 - val_loss: 0.5226 - val_acc: 0.2407\n",
      "Epoch 998/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4605 - acc: 0.2071 - val_loss: 0.6246 - val_acc: 0.2407\n",
      "Epoch 999/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5073 - acc: 0.2071 - val_loss: 0.5093 - val_acc: 0.2444\n",
      "Epoch 1000/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4471 - acc: 0.2079 - val_loss: 0.5157 - val_acc: 0.2407\n",
      "Epoch 1001/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4450 - acc: 0.2075 - val_loss: 0.5157 - val_acc: 0.2444\n",
      "Epoch 1002/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4573 - acc: 0.2075 - val_loss: 0.8039 - val_acc: 0.2407\n",
      "Epoch 1003/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5313 - acc: 0.2071 - val_loss: 0.5004 - val_acc: 0.2407\n",
      "Epoch 1004/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4400 - acc: 0.2079 - val_loss: 0.5182 - val_acc: 0.2444\n",
      "Epoch 1005/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4584 - acc: 0.2079 - val_loss: 0.5193 - val_acc: 0.2444\n",
      "Epoch 1006/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4421 - acc: 0.2071 - val_loss: 0.5370 - val_acc: 0.2407\n",
      "Epoch 1007/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4822 - acc: 0.2067 - val_loss: 0.5147 - val_acc: 0.2444\n",
      "Epoch 1008/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5017 - acc: 0.2079 - val_loss: 0.5084 - val_acc: 0.2444\n",
      "Epoch 1009/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4631 - acc: 0.2079 - val_loss: 0.5212 - val_acc: 0.2444\n",
      "Epoch 1010/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4489 - acc: 0.2083 - val_loss: 0.5921 - val_acc: 0.2407\n",
      "Epoch 1011/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5010 - acc: 0.2067 - val_loss: 0.5216 - val_acc: 0.2407\n",
      "Epoch 1012/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4497 - acc: 0.2071 - val_loss: 0.5701 - val_acc: 0.2444\n",
      "Epoch 1013/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4637 - acc: 0.2075 - val_loss: 0.5249 - val_acc: 0.2444\n",
      "Epoch 1014/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4638 - acc: 0.2075 - val_loss: 0.5296 - val_acc: 0.2444\n",
      "Epoch 1015/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4546 - acc: 0.2079 - val_loss: 0.5537 - val_acc: 0.2407\n",
      "Epoch 1016/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4660 - acc: 0.2075 - val_loss: 0.5239 - val_acc: 0.2444\n",
      "Epoch 1017/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4605 - acc: 0.2079 - val_loss: 0.5686 - val_acc: 0.2407\n",
      "Epoch 1018/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4624 - acc: 0.2071 - val_loss: 0.5223 - val_acc: 0.2407\n",
      "Epoch 1019/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4525 - acc: 0.2075 - val_loss: 0.5596 - val_acc: 0.2444\n",
      "Epoch 1020/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4572 - acc: 0.2071 - val_loss: 0.6667 - val_acc: 0.2407\n",
      "Epoch 1021/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4779 - acc: 0.2079 - val_loss: 0.5262 - val_acc: 0.2444\n",
      "Epoch 1022/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4483 - acc: 0.2079 - val_loss: 0.5243 - val_acc: 0.2407\n",
      "Epoch 1023/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4450 - acc: 0.2071 - val_loss: 0.5578 - val_acc: 0.2444\n",
      "Epoch 1024/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4717 - acc: 0.2079 - val_loss: 0.5166 - val_acc: 0.2444\n",
      "Epoch 1025/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4605 - acc: 0.2067 - val_loss: 0.5116 - val_acc: 0.2444\n",
      "Epoch 1026/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4354 - acc: 0.2079 - val_loss: 0.5170 - val_acc: 0.2444\n",
      "Epoch 1027/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4526 - acc: 0.2071 - val_loss: 0.6002 - val_acc: 0.2444\n",
      "Epoch 1028/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4829 - acc: 0.2067 - val_loss: 0.5084 - val_acc: 0.2444\n",
      "Epoch 1029/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4583 - acc: 0.2075 - val_loss: 0.7535 - val_acc: 0.2444\n",
      "Epoch 1030/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4733 - acc: 0.2075 - val_loss: 0.6753 - val_acc: 0.2444\n",
      "Epoch 1031/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4595 - acc: 0.2075 - val_loss: 0.5468 - val_acc: 0.2407\n",
      "Epoch 1032/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4488 - acc: 0.2071 - val_loss: 0.5258 - val_acc: 0.2407\n",
      "Epoch 1033/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4403 - acc: 0.2079 - val_loss: 0.5243 - val_acc: 0.2444\n",
      "Epoch 1034/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4328 - acc: 0.2075 - val_loss: 0.5345 - val_acc: 0.2407\n",
      "Epoch 1035/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4690 - acc: 0.2075 - val_loss: 0.8262 - val_acc: 0.2444\n",
      "Epoch 1036/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4892 - acc: 0.2075 - val_loss: 0.5803 - val_acc: 0.2407\n",
      "Epoch 1037/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4786 - acc: 0.2067 - val_loss: 0.5562 - val_acc: 0.2407\n",
      "Epoch 1038/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4687 - acc: 0.2075 - val_loss: 0.5061 - val_acc: 0.2444\n",
      "Epoch 1039/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4678 - acc: 0.2083 - val_loss: 0.5143 - val_acc: 0.2444\n",
      "Epoch 1040/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4675 - acc: 0.2067 - val_loss: 0.7668 - val_acc: 0.2407\n",
      "Epoch 1041/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4607 - acc: 0.2075 - val_loss: 0.5210 - val_acc: 0.2444\n",
      "Epoch 1042/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4450 - acc: 0.2075 - val_loss: 0.5341 - val_acc: 0.2407\n",
      "Epoch 1043/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4340 - acc: 0.2075 - val_loss: 0.5417 - val_acc: 0.2407\n",
      "Epoch 1044/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4628 - acc: 0.2075 - val_loss: 0.6680 - val_acc: 0.2444\n",
      "Epoch 1045/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4627 - acc: 0.2079 - val_loss: 0.5035 - val_acc: 0.2444\n",
      "Epoch 1046/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4433 - acc: 0.2071 - val_loss: 0.5426 - val_acc: 0.2444\n",
      "Epoch 1047/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4615 - acc: 0.2071 - val_loss: 0.5266 - val_acc: 0.2444\n",
      "Epoch 1048/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4634 - acc: 0.2071 - val_loss: 0.5967 - val_acc: 0.2407\n",
      "Epoch 1049/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5119 - acc: 0.2083 - val_loss: 0.5876 - val_acc: 0.2407\n",
      "Epoch 1050/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4721 - acc: 0.2079 - val_loss: 0.5141 - val_acc: 0.2407\n",
      "Epoch 1051/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4476 - acc: 0.2071 - val_loss: 0.5106 - val_acc: 0.2407\n",
      "Epoch 1052/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4704 - acc: 0.2071 - val_loss: 0.5117 - val_acc: 0.2444\n",
      "Epoch 1053/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4592 - acc: 0.2071 - val_loss: 0.5778 - val_acc: 0.2407\n",
      "Epoch 1054/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4921 - acc: 0.2075 - val_loss: 0.6073 - val_acc: 0.2444\n",
      "Epoch 1055/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4801 - acc: 0.2075 - val_loss: 0.5585 - val_acc: 0.2444\n",
      "Epoch 1056/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4475 - acc: 0.2079 - val_loss: 0.5047 - val_acc: 0.2407\n",
      "Epoch 1057/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4627 - acc: 0.2063 - val_loss: 0.5996 - val_acc: 0.2407\n",
      "Epoch 1058/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4271 - acc: 0.2075 - val_loss: 0.5053 - val_acc: 0.2407\n",
      "Epoch 1059/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4512 - acc: 0.2067 - val_loss: 0.5510 - val_acc: 0.2407\n",
      "Epoch 1060/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4511 - acc: 0.2079 - val_loss: 0.5855 - val_acc: 0.2407\n",
      "Epoch 1061/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4543 - acc: 0.2075 - val_loss: 0.5109 - val_acc: 0.2444\n",
      "Epoch 1062/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5052 - acc: 0.2075 - val_loss: 0.6930 - val_acc: 0.2407\n",
      "Epoch 1063/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4723 - acc: 0.2079 - val_loss: 0.5411 - val_acc: 0.2444\n",
      "Epoch 1064/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4605 - acc: 0.2067 - val_loss: 0.5110 - val_acc: 0.2444\n",
      "Epoch 1065/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4373 - acc: 0.2075 - val_loss: 0.5079 - val_acc: 0.2444\n",
      "Epoch 1066/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4546 - acc: 0.2075 - val_loss: 0.5325 - val_acc: 0.2407\n",
      "Epoch 1067/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4566 - acc: 0.2071 - val_loss: 0.5445 - val_acc: 0.2407\n",
      "Epoch 1068/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5096 - acc: 0.2067 - val_loss: 0.6921 - val_acc: 0.2407\n",
      "Epoch 1069/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4578 - acc: 0.2071 - val_loss: 0.5136 - val_acc: 0.2444\n",
      "Epoch 1070/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4466 - acc: 0.2079 - val_loss: 0.5086 - val_acc: 0.2444\n",
      "Epoch 1071/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4353 - acc: 0.2079 - val_loss: 0.5090 - val_acc: 0.2444\n",
      "Epoch 1072/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4678 - acc: 0.2075 - val_loss: 0.5537 - val_acc: 0.2444\n",
      "Epoch 1073/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4725 - acc: 0.2079 - val_loss: 0.5591 - val_acc: 0.2407\n",
      "Epoch 1074/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4613 - acc: 0.2063 - val_loss: 0.5071 - val_acc: 0.2407\n",
      "Epoch 1075/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4743 - acc: 0.2067 - val_loss: 0.5030 - val_acc: 0.2444\n",
      "Epoch 1076/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4392 - acc: 0.2079 - val_loss: 0.5992 - val_acc: 0.2407\n",
      "Epoch 1077/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4715 - acc: 0.2071 - val_loss: 0.9037 - val_acc: 0.2444\n",
      "Epoch 1078/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4920 - acc: 0.2067 - val_loss: 0.4934 - val_acc: 0.2407\n",
      "Epoch 1079/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4337 - acc: 0.2075 - val_loss: 0.5164 - val_acc: 0.2407\n",
      "Epoch 1080/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4516 - acc: 0.2079 - val_loss: 0.5110 - val_acc: 0.2444\n",
      "Epoch 1081/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4638 - acc: 0.2079 - val_loss: 0.5095 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1082/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4538 - acc: 0.2075 - val_loss: 0.6626 - val_acc: 0.2444\n",
      "Epoch 1083/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4717 - acc: 0.2067 - val_loss: 0.5257 - val_acc: 0.2444\n",
      "Epoch 1084/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4743 - acc: 0.2079 - val_loss: 0.5111 - val_acc: 0.2444\n",
      "Epoch 1085/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4538 - acc: 0.2071 - val_loss: 0.5197 - val_acc: 0.2444\n",
      "Epoch 1086/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4808 - acc: 0.2075 - val_loss: 0.5556 - val_acc: 0.2407\n",
      "Epoch 1087/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4482 - acc: 0.2079 - val_loss: 0.6418 - val_acc: 0.2407\n",
      "Epoch 1088/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4334 - acc: 0.2071 - val_loss: 0.5542 - val_acc: 0.2407\n",
      "Epoch 1089/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4474 - acc: 0.2067 - val_loss: 0.5038 - val_acc: 0.2444\n",
      "Epoch 1090/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4458 - acc: 0.2063 - val_loss: 0.5391 - val_acc: 0.2444\n",
      "Epoch 1091/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4439 - acc: 0.2075 - val_loss: 0.5057 - val_acc: 0.2407\n",
      "Epoch 1092/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4740 - acc: 0.2059 - val_loss: 0.5530 - val_acc: 0.2407\n",
      "Epoch 1093/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4657 - acc: 0.2071 - val_loss: 0.5233 - val_acc: 0.2444\n",
      "Epoch 1094/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4502 - acc: 0.2071 - val_loss: 0.5026 - val_acc: 0.2407\n",
      "Epoch 1095/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4922 - acc: 0.2079 - val_loss: 0.7189 - val_acc: 0.2407\n",
      "Epoch 1096/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4341 - acc: 0.2075 - val_loss: 0.5110 - val_acc: 0.2444\n",
      "Epoch 1097/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4579 - acc: 0.2075 - val_loss: 0.5125 - val_acc: 0.2444\n",
      "Epoch 1098/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4605 - acc: 0.2079 - val_loss: 0.5334 - val_acc: 0.2444\n",
      "Epoch 1099/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4425 - acc: 0.2075 - val_loss: 0.5110 - val_acc: 0.2444\n",
      "Epoch 1100/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4287 - acc: 0.2075 - val_loss: 0.5670 - val_acc: 0.2444\n",
      "Epoch 1101/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4503 - acc: 0.2071 - val_loss: 0.5480 - val_acc: 0.2444\n",
      "Epoch 1102/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4276 - acc: 0.2075 - val_loss: 0.5053 - val_acc: 0.2407\n",
      "Epoch 1103/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4541 - acc: 0.2075 - val_loss: 0.5705 - val_acc: 0.2444\n",
      "Epoch 1104/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4574 - acc: 0.2067 - val_loss: 0.5181 - val_acc: 0.2444\n",
      "Epoch 1105/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4730 - acc: 0.2075 - val_loss: 0.5019 - val_acc: 0.2407\n",
      "Epoch 1106/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4479 - acc: 0.2071 - val_loss: 0.6131 - val_acc: 0.2407\n",
      "Epoch 1107/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4662 - acc: 0.2079 - val_loss: 0.4994 - val_acc: 0.2407\n",
      "Epoch 1108/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4416 - acc: 0.2075 - val_loss: 0.7000 - val_acc: 0.2407\n",
      "Epoch 1109/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4676 - acc: 0.2075 - val_loss: 0.5283 - val_acc: 0.2407\n",
      "Epoch 1110/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4559 - acc: 0.2071 - val_loss: 0.4963 - val_acc: 0.2407\n",
      "Epoch 1111/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4727 - acc: 0.2075 - val_loss: 0.5164 - val_acc: 0.2407\n",
      "Epoch 1112/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4617 - acc: 0.2079 - val_loss: 0.5405 - val_acc: 0.2407\n",
      "Epoch 1113/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4617 - acc: 0.2075 - val_loss: 0.6301 - val_acc: 0.2407\n",
      "Epoch 1114/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4494 - acc: 0.2075 - val_loss: 0.5239 - val_acc: 0.2407\n",
      "Epoch 1115/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4576 - acc: 0.2071 - val_loss: 0.4966 - val_acc: 0.2407\n",
      "Epoch 1116/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4611 - acc: 0.2075 - val_loss: 0.5333 - val_acc: 0.2444\n",
      "Epoch 1117/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4572 - acc: 0.2079 - val_loss: 0.5868 - val_acc: 0.2407\n",
      "Epoch 1118/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4317 - acc: 0.2075 - val_loss: 0.5127 - val_acc: 0.2407\n",
      "Epoch 1119/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4560 - acc: 0.2079 - val_loss: 0.5348 - val_acc: 0.2444\n",
      "Epoch 1120/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4331 - acc: 0.2067 - val_loss: 0.4950 - val_acc: 0.2407\n",
      "Epoch 1121/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4840 - acc: 0.2075 - val_loss: 0.5052 - val_acc: 0.2444\n",
      "Epoch 1122/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4436 - acc: 0.2067 - val_loss: 0.5515 - val_acc: 0.2407\n",
      "Epoch 1123/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4874 - acc: 0.2067 - val_loss: 0.4953 - val_acc: 0.2444\n",
      "Epoch 1124/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4762 - acc: 0.2075 - val_loss: 0.5406 - val_acc: 0.2444\n",
      "Epoch 1125/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4752 - acc: 0.2075 - val_loss: 0.5231 - val_acc: 0.2444\n",
      "Epoch 1126/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4520 - acc: 0.2075 - val_loss: 0.5701 - val_acc: 0.2444\n",
      "Epoch 1127/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4678 - acc: 0.2075 - val_loss: 0.5575 - val_acc: 0.2407\n",
      "Epoch 1128/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4880 - acc: 0.2067 - val_loss: 0.5753 - val_acc: 0.2407\n",
      "Epoch 1129/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4807 - acc: 0.2071 - val_loss: 0.5035 - val_acc: 0.2444\n",
      "Epoch 1130/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4364 - acc: 0.2079 - val_loss: 0.4945 - val_acc: 0.2407\n",
      "Epoch 1131/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4415 - acc: 0.2071 - val_loss: 0.5042 - val_acc: 0.2407\n",
      "Epoch 1132/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4451 - acc: 0.2075 - val_loss: 0.5087 - val_acc: 0.2444\n",
      "Epoch 1133/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4734 - acc: 0.2075 - val_loss: 0.6155 - val_acc: 0.2407\n",
      "Epoch 1134/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4698 - acc: 0.2063 - val_loss: 0.5048 - val_acc: 0.2407\n",
      "Epoch 1135/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4367 - acc: 0.2075 - val_loss: 0.5454 - val_acc: 0.2444\n",
      "Epoch 1136/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4387 - acc: 0.2075 - val_loss: 0.5284 - val_acc: 0.2444\n",
      "Epoch 1137/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4629 - acc: 0.2071 - val_loss: 0.5054 - val_acc: 0.2407\n",
      "Epoch 1138/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4696 - acc: 0.2067 - val_loss: 0.5507 - val_acc: 0.2407\n",
      "Epoch 1139/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4549 - acc: 0.2079 - val_loss: 0.5039 - val_acc: 0.2407\n",
      "Epoch 1140/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4443 - acc: 0.2071 - val_loss: 0.5274 - val_acc: 0.2407\n",
      "Epoch 1141/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4426 - acc: 0.2075 - val_loss: 0.5783 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1142/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4582 - acc: 0.2075 - val_loss: 0.5669 - val_acc: 0.2444\n",
      "Epoch 1143/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4366 - acc: 0.2079 - val_loss: 0.5159 - val_acc: 0.2444\n",
      "Epoch 1144/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4348 - acc: 0.2075 - val_loss: 0.7665 - val_acc: 0.2444\n",
      "Epoch 1145/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4630 - acc: 0.2075 - val_loss: 0.5205 - val_acc: 0.2444\n",
      "Epoch 1146/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4535 - acc: 0.2071 - val_loss: 0.5072 - val_acc: 0.2407\n",
      "Epoch 1147/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4554 - acc: 0.2075 - val_loss: 0.5873 - val_acc: 0.2407\n",
      "Epoch 1148/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4408 - acc: 0.2075 - val_loss: 0.5116 - val_acc: 0.2444\n",
      "Epoch 1149/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4582 - acc: 0.2067 - val_loss: 0.5177 - val_acc: 0.2444\n",
      "Epoch 1150/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4907 - acc: 0.2071 - val_loss: 0.4866 - val_acc: 0.2407\n",
      "Epoch 1151/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4420 - acc: 0.2075 - val_loss: 0.5086 - val_acc: 0.2407\n",
      "Epoch 1152/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4457 - acc: 0.2079 - val_loss: 0.5757 - val_acc: 0.2407\n",
      "Epoch 1153/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4543 - acc: 0.2071 - val_loss: 0.6184 - val_acc: 0.2444\n",
      "Epoch 1154/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4387 - acc: 0.2079 - val_loss: 0.5041 - val_acc: 0.2407\n",
      "Epoch 1155/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4436 - acc: 0.2079 - val_loss: 0.5405 - val_acc: 0.2444\n",
      "Epoch 1156/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.5395 - acc: 0.2067 - val_loss: 0.4962 - val_acc: 0.2407\n",
      "Epoch 1157/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4625 - acc: 0.2075 - val_loss: 0.5062 - val_acc: 0.2407\n",
      "Epoch 1158/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4749 - acc: 0.2067 - val_loss: 0.5166 - val_acc: 0.2444\n",
      "Epoch 1159/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4665 - acc: 0.2071 - val_loss: 0.5342 - val_acc: 0.2407\n",
      "Epoch 1160/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4411 - acc: 0.2075 - val_loss: 0.5452 - val_acc: 0.2444\n",
      "Epoch 1161/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4350 - acc: 0.2075 - val_loss: 0.5124 - val_acc: 0.2444\n",
      "Epoch 1162/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4261 - acc: 0.2079 - val_loss: 0.5286 - val_acc: 0.2407\n",
      "Epoch 1163/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4486 - acc: 0.2075 - val_loss: 0.4873 - val_acc: 0.2407\n",
      "Epoch 1164/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4742 - acc: 0.2071 - val_loss: 0.5084 - val_acc: 0.2407\n",
      "Epoch 1165/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4731 - acc: 0.2075 - val_loss: 0.5095 - val_acc: 0.2407\n",
      "Epoch 1166/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4408 - acc: 0.2075 - val_loss: 0.4974 - val_acc: 0.2407\n",
      "Epoch 1167/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4471 - acc: 0.2079 - val_loss: 0.5348 - val_acc: 0.2444\n",
      "Epoch 1168/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4433 - acc: 0.2075 - val_loss: 0.5111 - val_acc: 0.2407\n",
      "Epoch 1169/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4440 - acc: 0.2075 - val_loss: 0.4859 - val_acc: 0.2444\n",
      "Epoch 1170/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4624 - acc: 0.2075 - val_loss: 0.5692 - val_acc: 0.2444\n",
      "Epoch 1171/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4599 - acc: 0.2071 - val_loss: 0.5125 - val_acc: 0.2444\n",
      "Epoch 1172/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4654 - acc: 0.2075 - val_loss: 0.5817 - val_acc: 0.2407\n",
      "Epoch 1173/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4288 - acc: 0.2071 - val_loss: 0.5638 - val_acc: 0.2444\n",
      "Epoch 1174/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4332 - acc: 0.2075 - val_loss: 0.5138 - val_acc: 0.2407\n",
      "Epoch 1175/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4519 - acc: 0.2067 - val_loss: 0.7424 - val_acc: 0.2444\n",
      "Epoch 1176/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4955 - acc: 0.2067 - val_loss: 0.5264 - val_acc: 0.2407\n",
      "Epoch 1177/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4508 - acc: 0.2075 - val_loss: 0.5025 - val_acc: 0.2407\n",
      "Epoch 1178/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4925 - acc: 0.2071 - val_loss: 0.5430 - val_acc: 0.2407\n",
      "Epoch 1179/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4370 - acc: 0.2079 - val_loss: 0.5512 - val_acc: 0.2407\n",
      "Epoch 1180/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4349 - acc: 0.2079 - val_loss: 0.4914 - val_acc: 0.2407\n",
      "Epoch 1181/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4980 - acc: 0.2071 - val_loss: 0.5388 - val_acc: 0.2407\n",
      "Epoch 1182/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4465 - acc: 0.2079 - val_loss: 0.5220 - val_acc: 0.2407\n",
      "Epoch 1183/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4833 - acc: 0.2075 - val_loss: 0.6030 - val_acc: 0.2444\n",
      "Epoch 1184/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5150 - acc: 0.2075 - val_loss: 0.6495 - val_acc: 0.2444\n",
      "Epoch 1185/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5020 - acc: 0.2079 - val_loss: 0.5349 - val_acc: 0.2444\n",
      "Epoch 1186/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4312 - acc: 0.2075 - val_loss: 0.5166 - val_acc: 0.2407\n",
      "Epoch 1187/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4598 - acc: 0.2063 - val_loss: 0.4984 - val_acc: 0.2407\n",
      "Epoch 1188/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4535 - acc: 0.2071 - val_loss: 0.5559 - val_acc: 0.2444\n",
      "Epoch 1189/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4896 - acc: 0.2071 - val_loss: 0.4868 - val_acc: 0.2407\n",
      "Epoch 1190/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4722 - acc: 0.2067 - val_loss: 0.5175 - val_acc: 0.2407\n",
      "Epoch 1191/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4307 - acc: 0.2079 - val_loss: 0.4942 - val_acc: 0.2444\n",
      "Epoch 1192/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4401 - acc: 0.2079 - val_loss: 0.5091 - val_acc: 0.2444\n",
      "Epoch 1193/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4605 - acc: 0.2071 - val_loss: 0.5299 - val_acc: 0.2444\n",
      "Epoch 1194/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4311 - acc: 0.2079 - val_loss: 0.4838 - val_acc: 0.2407\n",
      "Epoch 1195/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.5069 - acc: 0.2063 - val_loss: 0.5528 - val_acc: 0.2407\n",
      "Epoch 1196/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4584 - acc: 0.2075 - val_loss: 0.5251 - val_acc: 0.2444\n",
      "Epoch 1197/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4568 - acc: 0.2075 - val_loss: 0.5870 - val_acc: 0.2407\n",
      "Epoch 1198/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4956 - acc: 0.2075 - val_loss: 0.4936 - val_acc: 0.2407\n",
      "Epoch 1199/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4449 - acc: 0.2067 - val_loss: 0.5255 - val_acc: 0.2444\n",
      "Epoch 1200/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4319 - acc: 0.2075 - val_loss: 0.5255 - val_acc: 0.2444\n",
      "Epoch 1201/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4393 - acc: 0.2075 - val_loss: 0.4919 - val_acc: 0.2407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1202/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4447 - acc: 0.2079 - val_loss: 0.4912 - val_acc: 0.2407\n",
      "Epoch 1203/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4547 - acc: 0.2075 - val_loss: 0.5004 - val_acc: 0.2444\n",
      "Epoch 1204/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4813 - acc: 0.2075 - val_loss: 0.7216 - val_acc: 0.2407\n",
      "Epoch 1205/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4485 - acc: 0.2071 - val_loss: 0.5031 - val_acc: 0.2407\n",
      "Epoch 1206/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4475 - acc: 0.2071 - val_loss: 0.5106 - val_acc: 0.2407\n",
      "Epoch 1207/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4972 - acc: 0.2071 - val_loss: 0.5143 - val_acc: 0.2444\n",
      "Epoch 1208/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4828 - acc: 0.2067 - val_loss: 0.7070 - val_acc: 0.2444\n",
      "Epoch 1209/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4563 - acc: 0.2071 - val_loss: 0.5783 - val_acc: 0.2444\n",
      "Epoch 1210/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4428 - acc: 0.2075 - val_loss: 0.4892 - val_acc: 0.2444\n",
      "Epoch 1211/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4446 - acc: 0.2075 - val_loss: 0.5639 - val_acc: 0.2444\n",
      "Epoch 1212/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4460 - acc: 0.2067 - val_loss: 0.7209 - val_acc: 0.2444\n",
      "Epoch 1213/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5050 - acc: 0.2071 - val_loss: 0.5134 - val_acc: 0.2444\n",
      "Epoch 1214/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4568 - acc: 0.2075 - val_loss: 0.4916 - val_acc: 0.2407\n",
      "Epoch 1215/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4546 - acc: 0.2067 - val_loss: 0.7789 - val_acc: 0.2407\n",
      "Epoch 1216/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4536 - acc: 0.2075 - val_loss: 0.5973 - val_acc: 0.2407\n",
      "Epoch 1217/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4891 - acc: 0.2071 - val_loss: 0.5300 - val_acc: 0.2407\n",
      "Epoch 1218/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4333 - acc: 0.2075 - val_loss: 0.5225 - val_acc: 0.2444\n",
      "Epoch 1219/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4473 - acc: 0.2075 - val_loss: 0.5506 - val_acc: 0.2407\n",
      "Epoch 1220/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4989 - acc: 0.2079 - val_loss: 0.5691 - val_acc: 0.2407\n",
      "Epoch 1221/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4611 - acc: 0.2071 - val_loss: 0.5312 - val_acc: 0.2407\n",
      "Epoch 1222/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4737 - acc: 0.2075 - val_loss: 0.6153 - val_acc: 0.2407\n",
      "Epoch 1223/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4895 - acc: 0.2083 - val_loss: 0.7271 - val_acc: 0.2407\n",
      "Epoch 1224/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4867 - acc: 0.2071 - val_loss: 0.6777 - val_acc: 0.2444\n",
      "Epoch 1225/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4503 - acc: 0.2079 - val_loss: 0.5397 - val_acc: 0.2444\n",
      "Epoch 1226/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4534 - acc: 0.2079 - val_loss: 0.5564 - val_acc: 0.2444\n",
      "Epoch 1227/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4518 - acc: 0.2071 - val_loss: 0.5206 - val_acc: 0.2407\n",
      "Epoch 1228/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4338 - acc: 0.2071 - val_loss: 0.5053 - val_acc: 0.2407\n",
      "Epoch 1229/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4333 - acc: 0.2075 - val_loss: 0.5161 - val_acc: 0.2407\n",
      "Epoch 1230/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4418 - acc: 0.2079 - val_loss: 0.8781 - val_acc: 0.2370\n",
      "Epoch 1231/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5050 - acc: 0.2071 - val_loss: 0.6343 - val_acc: 0.2444\n",
      "Epoch 1232/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4459 - acc: 0.2075 - val_loss: 0.5119 - val_acc: 0.2444\n",
      "Epoch 1233/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4734 - acc: 0.2079 - val_loss: 0.5099 - val_acc: 0.2407\n",
      "Epoch 1234/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4267 - acc: 0.2075 - val_loss: 0.5545 - val_acc: 0.2444\n",
      "Epoch 1235/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4471 - acc: 0.2079 - val_loss: 0.4998 - val_acc: 0.2407\n",
      "Epoch 1236/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4445 - acc: 0.2075 - val_loss: 0.5233 - val_acc: 0.2407\n",
      "Epoch 1237/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4473 - acc: 0.2075 - val_loss: 0.4921 - val_acc: 0.2407\n",
      "Epoch 1238/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4393 - acc: 0.2075 - val_loss: 0.6326 - val_acc: 0.2407\n",
      "Epoch 1239/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4480 - acc: 0.2075 - val_loss: 0.4974 - val_acc: 0.2444\n",
      "Epoch 1240/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4717 - acc: 0.2079 - val_loss: 0.4947 - val_acc: 0.2407\n",
      "Epoch 1241/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4384 - acc: 0.2079 - val_loss: 0.5502 - val_acc: 0.2407\n",
      "Epoch 1242/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4611 - acc: 0.2075 - val_loss: 0.6324 - val_acc: 0.2444\n",
      "Epoch 1243/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4309 - acc: 0.2079 - val_loss: 0.5394 - val_acc: 0.2444\n",
      "Epoch 1244/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4387 - acc: 0.2079 - val_loss: 0.5121 - val_acc: 0.2407\n",
      "Epoch 1245/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4761 - acc: 0.2063 - val_loss: 0.5526 - val_acc: 0.2407\n",
      "Epoch 1246/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4810 - acc: 0.2079 - val_loss: 0.5254 - val_acc: 0.2444\n",
      "Epoch 1247/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4501 - acc: 0.2071 - val_loss: 0.6174 - val_acc: 0.2444\n",
      "Epoch 1248/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4398 - acc: 0.2075 - val_loss: 0.4995 - val_acc: 0.2407\n",
      "Epoch 1249/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4452 - acc: 0.2071 - val_loss: 0.4875 - val_acc: 0.2407\n",
      "Epoch 1250/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4533 - acc: 0.2071 - val_loss: 0.5497 - val_acc: 0.2444\n",
      "Epoch 1251/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4505 - acc: 0.2079 - val_loss: 0.4967 - val_acc: 0.2407\n",
      "Epoch 1252/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4332 - acc: 0.2071 - val_loss: 0.4977 - val_acc: 0.2407\n",
      "Epoch 1253/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4364 - acc: 0.2075 - val_loss: 0.4848 - val_acc: 0.2407\n",
      "Epoch 1254/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4436 - acc: 0.2071 - val_loss: 0.5022 - val_acc: 0.2407\n",
      "Epoch 1255/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4319 - acc: 0.2071 - val_loss: 0.4978 - val_acc: 0.2444\n",
      "Epoch 1256/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4518 - acc: 0.2067 - val_loss: 0.4937 - val_acc: 0.2407\n",
      "Epoch 1257/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4360 - acc: 0.2079 - val_loss: 0.5254 - val_acc: 0.2407\n",
      "Epoch 1258/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4463 - acc: 0.2071 - val_loss: 0.5092 - val_acc: 0.2407\n",
      "Epoch 1259/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4373 - acc: 0.2071 - val_loss: 0.4907 - val_acc: 0.2407\n",
      "Epoch 1260/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4570 - acc: 0.2079 - val_loss: 0.5277 - val_acc: 0.2444\n",
      "Epoch 1261/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4414 - acc: 0.2071 - val_loss: 0.5171 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1262/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4316 - acc: 0.2075 - val_loss: 0.4993 - val_acc: 0.2444\n",
      "Epoch 1263/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4494 - acc: 0.2079 - val_loss: 0.4859 - val_acc: 0.2407\n",
      "Epoch 1264/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4267 - acc: 0.2075 - val_loss: 0.5207 - val_acc: 0.2407\n",
      "Epoch 1265/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4573 - acc: 0.2075 - val_loss: 0.5023 - val_acc: 0.2407\n",
      "Epoch 1266/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4462 - acc: 0.2079 - val_loss: 0.6627 - val_acc: 0.2407\n",
      "Epoch 1267/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4661 - acc: 0.2071 - val_loss: 0.4995 - val_acc: 0.2407\n",
      "Epoch 1268/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4662 - acc: 0.2075 - val_loss: 0.5240 - val_acc: 0.2407\n",
      "Epoch 1269/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4754 - acc: 0.2083 - val_loss: 0.5457 - val_acc: 0.2444\n",
      "Epoch 1270/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4418 - acc: 0.2075 - val_loss: 0.4916 - val_acc: 0.2444\n",
      "Epoch 1271/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.5643 - acc: 0.2067 - val_loss: 0.6781 - val_acc: 0.2444\n",
      "Epoch 1272/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4785 - acc: 0.2075 - val_loss: 0.6406 - val_acc: 0.2444\n",
      "Epoch 1273/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4504 - acc: 0.2083 - val_loss: 0.5216 - val_acc: 0.2444\n",
      "Epoch 1274/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4308 - acc: 0.2075 - val_loss: 0.5262 - val_acc: 0.2407\n",
      "Epoch 1275/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4323 - acc: 0.2075 - val_loss: 0.5418 - val_acc: 0.2407\n",
      "Epoch 1276/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4291 - acc: 0.2079 - val_loss: 0.6887 - val_acc: 0.2444\n",
      "Epoch 1277/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4769 - acc: 0.2075 - val_loss: 0.5139 - val_acc: 0.2407\n",
      "Epoch 1278/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4646 - acc: 0.2075 - val_loss: 0.4947 - val_acc: 0.2407\n",
      "Epoch 1279/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4396 - acc: 0.2075 - val_loss: 0.4926 - val_acc: 0.2407\n",
      "Epoch 1280/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4648 - acc: 0.2079 - val_loss: 0.7028 - val_acc: 0.2407\n",
      "Epoch 1281/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4607 - acc: 0.2079 - val_loss: 0.5352 - val_acc: 0.2444\n",
      "Epoch 1282/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4259 - acc: 0.2075 - val_loss: 0.5065 - val_acc: 0.2407\n",
      "Epoch 1283/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4491 - acc: 0.2067 - val_loss: 0.4989 - val_acc: 0.2444\n",
      "Epoch 1284/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4974 - acc: 0.2067 - val_loss: 0.5937 - val_acc: 0.2407\n",
      "Epoch 1285/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4626 - acc: 0.2071 - val_loss: 0.5415 - val_acc: 0.2444\n",
      "Epoch 1286/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4423 - acc: 0.2079 - val_loss: 0.4833 - val_acc: 0.2407\n",
      "Epoch 1287/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4331 - acc: 0.2071 - val_loss: 0.4944 - val_acc: 0.2444\n",
      "Epoch 1288/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4488 - acc: 0.2075 - val_loss: 0.4899 - val_acc: 0.2407\n",
      "Epoch 1289/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4560 - acc: 0.2079 - val_loss: 0.5401 - val_acc: 0.2407\n",
      "Epoch 1290/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4345 - acc: 0.2075 - val_loss: 0.6471 - val_acc: 0.2407\n",
      "Epoch 1291/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4480 - acc: 0.2075 - val_loss: 0.5325 - val_acc: 0.2407\n",
      "Epoch 1292/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4261 - acc: 0.2075 - val_loss: 0.5023 - val_acc: 0.2407\n",
      "Epoch 1293/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4303 - acc: 0.2071 - val_loss: 0.7742 - val_acc: 0.2444\n",
      "Epoch 1294/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4667 - acc: 0.2067 - val_loss: 0.4985 - val_acc: 0.2407\n",
      "Epoch 1295/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4205 - acc: 0.2075 - val_loss: 0.5244 - val_acc: 0.2444\n",
      "Epoch 1296/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4668 - acc: 0.2063 - val_loss: 0.5464 - val_acc: 0.2407\n",
      "Epoch 1297/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4573 - acc: 0.2075 - val_loss: 0.5030 - val_acc: 0.2444\n",
      "Epoch 1298/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4329 - acc: 0.2075 - val_loss: 0.5100 - val_acc: 0.2444\n",
      "Epoch 1299/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4561 - acc: 0.2075 - val_loss: 0.5163 - val_acc: 0.2407\n",
      "Epoch 1300/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4537 - acc: 0.2075 - val_loss: 0.4933 - val_acc: 0.2444\n",
      "Epoch 1301/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4323 - acc: 0.2079 - val_loss: 0.5303 - val_acc: 0.2444\n",
      "Epoch 1302/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4396 - acc: 0.2075 - val_loss: 0.5364 - val_acc: 0.2407\n",
      "Epoch 1303/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4434 - acc: 0.2079 - val_loss: 0.4931 - val_acc: 0.2407\n",
      "Epoch 1304/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4764 - acc: 0.2079 - val_loss: 0.5038 - val_acc: 0.2407\n",
      "Epoch 1305/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4523 - acc: 0.2063 - val_loss: 0.5048 - val_acc: 0.2407\n",
      "Epoch 1306/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4659 - acc: 0.2071 - val_loss: 0.4924 - val_acc: 0.2407\n",
      "Epoch 1307/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4329 - acc: 0.2075 - val_loss: 0.4830 - val_acc: 0.2407\n",
      "Epoch 1308/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4418 - acc: 0.2079 - val_loss: 0.4880 - val_acc: 0.2407\n",
      "Epoch 1309/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4386 - acc: 0.2075 - val_loss: 0.5131 - val_acc: 0.2444\n",
      "Epoch 1310/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4770 - acc: 0.2079 - val_loss: 0.5319 - val_acc: 0.2444\n",
      "Epoch 1311/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4255 - acc: 0.2071 - val_loss: 0.5186 - val_acc: 0.2407\n",
      "Epoch 1312/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4290 - acc: 0.2075 - val_loss: 0.5059 - val_acc: 0.2407\n",
      "Epoch 1313/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4323 - acc: 0.2079 - val_loss: 0.4950 - val_acc: 0.2407\n",
      "Epoch 1314/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4440 - acc: 0.2075 - val_loss: 0.6850 - val_acc: 0.2407\n",
      "Epoch 1315/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4811 - acc: 0.2071 - val_loss: 0.5058 - val_acc: 0.2407\n",
      "Epoch 1316/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4268 - acc: 0.2075 - val_loss: 0.4997 - val_acc: 0.2407\n",
      "Epoch 1317/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4380 - acc: 0.2067 - val_loss: 0.5072 - val_acc: 0.2444\n",
      "Epoch 1318/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4506 - acc: 0.2079 - val_loss: 0.6526 - val_acc: 0.2444\n",
      "Epoch 1319/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4503 - acc: 0.2071 - val_loss: 0.5693 - val_acc: 0.2407\n",
      "Epoch 1320/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4633 - acc: 0.2071 - val_loss: 0.4930 - val_acc: 0.2407\n",
      "Epoch 1321/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4645 - acc: 0.2067 - val_loss: 0.4864 - val_acc: 0.2407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1322/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4268 - acc: 0.2079 - val_loss: 0.5096 - val_acc: 0.2407\n",
      "Epoch 1323/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4260 - acc: 0.2079 - val_loss: 0.5410 - val_acc: 0.2444\n",
      "Epoch 1324/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4528 - acc: 0.2075 - val_loss: 0.5072 - val_acc: 0.2407\n",
      "Epoch 1325/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4733 - acc: 0.2075 - val_loss: 0.6087 - val_acc: 0.2407\n",
      "Epoch 1326/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4413 - acc: 0.2071 - val_loss: 0.5155 - val_acc: 0.2407\n",
      "Epoch 1327/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4268 - acc: 0.2079 - val_loss: 0.5097 - val_acc: 0.2407\n",
      "Epoch 1328/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4335 - acc: 0.2079 - val_loss: 0.4908 - val_acc: 0.2444\n",
      "Epoch 1329/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4358 - acc: 0.2079 - val_loss: 0.5038 - val_acc: 0.2407\n",
      "Epoch 1330/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4851 - acc: 0.2075 - val_loss: 0.5031 - val_acc: 0.2444\n",
      "Epoch 1331/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4304 - acc: 0.2079 - val_loss: 0.5273 - val_acc: 0.2444\n",
      "Epoch 1332/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4205 - acc: 0.2075 - val_loss: 0.4827 - val_acc: 0.2444\n",
      "Epoch 1333/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4265 - acc: 0.2079 - val_loss: 0.5272 - val_acc: 0.2407\n",
      "Epoch 1334/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4395 - acc: 0.2075 - val_loss: 0.5076 - val_acc: 0.2407\n",
      "Epoch 1335/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4621 - acc: 0.2075 - val_loss: 0.6591 - val_acc: 0.2444\n",
      "Epoch 1336/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4636 - acc: 0.2059 - val_loss: 0.4857 - val_acc: 0.2444\n",
      "Epoch 1337/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4790 - acc: 0.2075 - val_loss: 0.4927 - val_acc: 0.2444\n",
      "Epoch 1338/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4321 - acc: 0.2075 - val_loss: 0.4808 - val_acc: 0.2407\n",
      "Epoch 1339/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4640 - acc: 0.2071 - val_loss: 0.4865 - val_acc: 0.2407\n",
      "Epoch 1340/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4264 - acc: 0.2079 - val_loss: 0.5126 - val_acc: 0.2444\n",
      "Epoch 1341/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4564 - acc: 0.2075 - val_loss: 0.6413 - val_acc: 0.2444\n",
      "Epoch 1342/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4539 - acc: 0.2079 - val_loss: 0.5090 - val_acc: 0.2407\n",
      "Epoch 1343/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4589 - acc: 0.2075 - val_loss: 0.5369 - val_acc: 0.2407\n",
      "Epoch 1344/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4366 - acc: 0.2075 - val_loss: 0.5586 - val_acc: 0.2407\n",
      "Epoch 1345/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4253 - acc: 0.2079 - val_loss: 0.5268 - val_acc: 0.2444\n",
      "Epoch 1346/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4292 - acc: 0.2083 - val_loss: 0.4855 - val_acc: 0.2444\n",
      "Epoch 1347/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4414 - acc: 0.2071 - val_loss: 0.4801 - val_acc: 0.2407\n",
      "Epoch 1348/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4796 - acc: 0.2071 - val_loss: 0.7286 - val_acc: 0.2407\n",
      "Epoch 1349/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4407 - acc: 0.2075 - val_loss: 0.4927 - val_acc: 0.2444\n",
      "Epoch 1350/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4347 - acc: 0.2071 - val_loss: 0.5034 - val_acc: 0.2407\n",
      "Epoch 1351/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4551 - acc: 0.2079 - val_loss: 0.5173 - val_acc: 0.2444\n",
      "Epoch 1352/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4425 - acc: 0.2071 - val_loss: 0.5074 - val_acc: 0.2444\n",
      "Epoch 1353/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4627 - acc: 0.2075 - val_loss: 0.5833 - val_acc: 0.2444\n",
      "Epoch 1354/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4472 - acc: 0.2071 - val_loss: 0.4894 - val_acc: 0.2407\n",
      "Epoch 1355/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4217 - acc: 0.2075 - val_loss: 0.5167 - val_acc: 0.2407\n",
      "Epoch 1356/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4697 - acc: 0.2071 - val_loss: 0.4932 - val_acc: 0.2407\n",
      "Epoch 1357/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4287 - acc: 0.2079 - val_loss: 0.5018 - val_acc: 0.2407\n",
      "Epoch 1358/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4520 - acc: 0.2075 - val_loss: 0.5009 - val_acc: 0.2444\n",
      "Epoch 1359/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4553 - acc: 0.2075 - val_loss: 0.5033 - val_acc: 0.2407\n",
      "Epoch 1360/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4321 - acc: 0.2079 - val_loss: 0.4992 - val_acc: 0.2407\n",
      "Epoch 1361/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4314 - acc: 0.2079 - val_loss: 0.5382 - val_acc: 0.2407\n",
      "Epoch 1362/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4495 - acc: 0.2079 - val_loss: 0.5003 - val_acc: 0.2407\n",
      "Epoch 1363/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4450 - acc: 0.2079 - val_loss: 0.5653 - val_acc: 0.2444\n",
      "Epoch 1364/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4560 - acc: 0.2075 - val_loss: 0.5235 - val_acc: 0.2407\n",
      "Epoch 1365/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.5143 - acc: 0.2067 - val_loss: 0.4972 - val_acc: 0.2407\n",
      "Epoch 1366/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4716 - acc: 0.2075 - val_loss: 0.5024 - val_acc: 0.2407\n",
      "Epoch 1367/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4739 - acc: 0.2071 - val_loss: 0.7556 - val_acc: 0.2444\n",
      "Epoch 1368/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4922 - acc: 0.2071 - val_loss: 0.5425 - val_acc: 0.2407\n",
      "Epoch 1369/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4472 - acc: 0.2079 - val_loss: 0.4926 - val_acc: 0.2407\n",
      "Epoch 1370/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4529 - acc: 0.2071 - val_loss: 0.4879 - val_acc: 0.2407\n",
      "Epoch 1371/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4422 - acc: 0.2071 - val_loss: 0.5280 - val_acc: 0.2444\n",
      "Epoch 1372/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4520 - acc: 0.2079 - val_loss: 0.5076 - val_acc: 0.2444\n",
      "Epoch 1373/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4253 - acc: 0.2075 - val_loss: 0.5128 - val_acc: 0.2444\n",
      "Epoch 1374/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4355 - acc: 0.2071 - val_loss: 0.5167 - val_acc: 0.2407\n",
      "Epoch 1375/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4347 - acc: 0.2075 - val_loss: 0.4848 - val_acc: 0.2407\n",
      "Epoch 1376/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4342 - acc: 0.2075 - val_loss: 0.6544 - val_acc: 0.2444\n",
      "Epoch 1377/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4982 - acc: 0.2075 - val_loss: 0.4804 - val_acc: 0.2444\n",
      "Epoch 1378/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4283 - acc: 0.2071 - val_loss: 0.6087 - val_acc: 0.2444\n",
      "Epoch 1379/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4584 - acc: 0.2075 - val_loss: 0.4846 - val_acc: 0.2407\n",
      "Epoch 1380/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4296 - acc: 0.2071 - val_loss: 0.4942 - val_acc: 0.2444\n",
      "Epoch 1381/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4542 - acc: 0.2079 - val_loss: 0.4974 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1382/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4752 - acc: 0.2067 - val_loss: 0.4998 - val_acc: 0.2407\n",
      "Epoch 1383/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5023 - acc: 0.2067 - val_loss: 0.4992 - val_acc: 0.2407\n",
      "Epoch 1384/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4318 - acc: 0.2075 - val_loss: 0.4802 - val_acc: 0.2407\n",
      "Epoch 1385/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4538 - acc: 0.2075 - val_loss: 0.5931 - val_acc: 0.2407\n",
      "Epoch 1386/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4595 - acc: 0.2075 - val_loss: 0.5120 - val_acc: 0.2444\n",
      "Epoch 1387/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4550 - acc: 0.2071 - val_loss: 0.5028 - val_acc: 0.2444\n",
      "Epoch 1388/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4574 - acc: 0.2075 - val_loss: 0.5005 - val_acc: 0.2407\n",
      "Epoch 1389/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4392 - acc: 0.2075 - val_loss: 0.5549 - val_acc: 0.2444\n",
      "Epoch 1390/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 1.7661 - acc: 0.2021 - val_loss: 0.8102 - val_acc: 0.2407\n",
      "Epoch 1391/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.7263 - acc: 0.2083 - val_loss: 0.6990 - val_acc: 0.2407\n",
      "Epoch 1392/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5968 - acc: 0.2067 - val_loss: 0.6962 - val_acc: 0.2444\n",
      "Epoch 1393/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5931 - acc: 0.2075 - val_loss: 0.6464 - val_acc: 0.2407\n",
      "Epoch 1394/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.5231 - acc: 0.2075 - val_loss: 0.6711 - val_acc: 0.2444\n",
      "Epoch 1395/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5159 - acc: 0.2079 - val_loss: 0.6189 - val_acc: 0.2444\n",
      "Epoch 1396/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4849 - acc: 0.2075 - val_loss: 0.5977 - val_acc: 0.2444\n",
      "Epoch 1397/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4815 - acc: 0.2079 - val_loss: 0.5920 - val_acc: 0.2444\n",
      "Epoch 1398/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4666 - acc: 0.2079 - val_loss: 0.5420 - val_acc: 0.2407\n",
      "Epoch 1399/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4547 - acc: 0.2079 - val_loss: 0.5352 - val_acc: 0.2407\n",
      "Epoch 1400/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5021 - acc: 0.2075 - val_loss: 0.5932 - val_acc: 0.2407\n",
      "Epoch 1401/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4501 - acc: 0.2075 - val_loss: 0.5092 - val_acc: 0.2444\n",
      "Epoch 1402/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4462 - acc: 0.2079 - val_loss: 0.5116 - val_acc: 0.2444\n",
      "Epoch 1403/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4413 - acc: 0.2079 - val_loss: 0.5399 - val_acc: 0.2407\n",
      "Epoch 1404/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4310 - acc: 0.2079 - val_loss: 0.5066 - val_acc: 0.2444\n",
      "Epoch 1405/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4449 - acc: 0.2071 - val_loss: 0.5257 - val_acc: 0.2444\n",
      "Epoch 1406/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4343 - acc: 0.2071 - val_loss: 0.5245 - val_acc: 0.2407\n",
      "Epoch 1407/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4762 - acc: 0.2075 - val_loss: 0.6294 - val_acc: 0.2444\n",
      "Epoch 1408/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4569 - acc: 0.2079 - val_loss: 0.5746 - val_acc: 0.2407\n",
      "Epoch 1409/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4435 - acc: 0.2071 - val_loss: 0.4973 - val_acc: 0.2444\n",
      "Epoch 1410/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4272 - acc: 0.2079 - val_loss: 0.5260 - val_acc: 0.2407\n",
      "Epoch 1411/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4356 - acc: 0.2075 - val_loss: 0.6495 - val_acc: 0.2444\n",
      "Epoch 1412/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4278 - acc: 0.2075 - val_loss: 0.5475 - val_acc: 0.2407\n",
      "Epoch 1413/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4199 - acc: 0.2079 - val_loss: 0.4993 - val_acc: 0.2407\n",
      "Epoch 1414/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4309 - acc: 0.2071 - val_loss: 0.5212 - val_acc: 0.2444\n",
      "Epoch 1415/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4476 - acc: 0.2075 - val_loss: 0.6171 - val_acc: 0.2444\n",
      "Epoch 1416/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4782 - acc: 0.2071 - val_loss: 0.5210 - val_acc: 0.2407\n",
      "Epoch 1417/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4503 - acc: 0.2075 - val_loss: 0.4936 - val_acc: 0.2444\n",
      "Epoch 1418/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4261 - acc: 0.2075 - val_loss: 0.4994 - val_acc: 0.2444\n",
      "Epoch 1419/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4170 - acc: 0.2075 - val_loss: 0.4882 - val_acc: 0.2444\n",
      "Epoch 1420/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4501 - acc: 0.2067 - val_loss: 0.5503 - val_acc: 0.2407\n",
      "Epoch 1421/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4445 - acc: 0.2075 - val_loss: 0.4897 - val_acc: 0.2444\n",
      "Epoch 1422/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4421 - acc: 0.2079 - val_loss: 0.5048 - val_acc: 0.2444\n",
      "Epoch 1423/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4836 - acc: 0.2067 - val_loss: 0.4943 - val_acc: 0.2407\n",
      "Epoch 1424/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4424 - acc: 0.2071 - val_loss: 0.5201 - val_acc: 0.2444\n",
      "Epoch 1425/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4367 - acc: 0.2079 - val_loss: 0.6481 - val_acc: 0.2444\n",
      "Epoch 1426/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4546 - acc: 0.2071 - val_loss: 0.5147 - val_acc: 0.2407\n",
      "Epoch 1427/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4372 - acc: 0.2071 - val_loss: 0.5753 - val_acc: 0.2444\n",
      "Epoch 1428/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4596 - acc: 0.2071 - val_loss: 0.5376 - val_acc: 0.2444\n",
      "Epoch 1429/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4380 - acc: 0.2075 - val_loss: 0.5823 - val_acc: 0.2444\n",
      "Epoch 1430/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4190 - acc: 0.2075 - val_loss: 0.4875 - val_acc: 0.2444\n",
      "Epoch 1431/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4383 - acc: 0.2079 - val_loss: 0.4902 - val_acc: 0.2407\n",
      "Epoch 1432/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4285 - acc: 0.2079 - val_loss: 0.5613 - val_acc: 0.2407\n",
      "Epoch 1433/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4296 - acc: 0.2079 - val_loss: 0.6293 - val_acc: 0.2407\n",
      "Epoch 1434/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4269 - acc: 0.2075 - val_loss: 0.7091 - val_acc: 0.2407\n",
      "Epoch 1435/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4458 - acc: 0.2075 - val_loss: 0.8255 - val_acc: 0.2370\n",
      "Epoch 1436/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4608 - acc: 0.2071 - val_loss: 0.5335 - val_acc: 0.2444\n",
      "Epoch 1437/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4490 - acc: 0.2075 - val_loss: 0.4876 - val_acc: 0.2444\n",
      "Epoch 1438/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4245 - acc: 0.2079 - val_loss: 0.5362 - val_acc: 0.2444\n",
      "Epoch 1439/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4202 - acc: 0.2079 - val_loss: 0.4906 - val_acc: 0.2407\n",
      "Epoch 1440/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4385 - acc: 0.2079 - val_loss: 0.4998 - val_acc: 0.2407\n",
      "Epoch 1441/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4153 - acc: 0.2075 - val_loss: 0.4899 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1442/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4223 - acc: 0.2079 - val_loss: 0.5015 - val_acc: 0.2407\n",
      "Epoch 1443/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4615 - acc: 0.2075 - val_loss: 0.5275 - val_acc: 0.2407\n",
      "Epoch 1444/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4378 - acc: 0.2071 - val_loss: 0.5161 - val_acc: 0.2444\n",
      "Epoch 1445/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4851 - acc: 0.2067 - val_loss: 0.4885 - val_acc: 0.2407\n",
      "Epoch 1446/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4526 - acc: 0.2067 - val_loss: 0.5193 - val_acc: 0.2407\n",
      "Epoch 1447/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4378 - acc: 0.2079 - val_loss: 0.5192 - val_acc: 0.2444\n",
      "Epoch 1448/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4307 - acc: 0.2071 - val_loss: 0.5544 - val_acc: 0.2444\n",
      "Epoch 1449/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4374 - acc: 0.2079 - val_loss: 0.5130 - val_acc: 0.2407\n",
      "Epoch 1450/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4371 - acc: 0.2075 - val_loss: 0.4976 - val_acc: 0.2444\n",
      "Epoch 1451/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4316 - acc: 0.2071 - val_loss: 0.5842 - val_acc: 0.2444\n",
      "Epoch 1452/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4297 - acc: 0.2079 - val_loss: 0.5531 - val_acc: 0.2444\n",
      "Epoch 1453/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4328 - acc: 0.2075 - val_loss: 0.5328 - val_acc: 0.2407\n",
      "Epoch 1454/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4291 - acc: 0.2075 - val_loss: 0.5248 - val_acc: 0.2444\n",
      "Epoch 1455/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4747 - acc: 0.2079 - val_loss: 0.6222 - val_acc: 0.2407\n",
      "Epoch 1456/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4309 - acc: 0.2079 - val_loss: 0.4941 - val_acc: 0.2444\n",
      "Epoch 1457/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4733 - acc: 0.2075 - val_loss: 0.5380 - val_acc: 0.2407\n",
      "Epoch 1458/10000\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.4422 - acc: 0.207 - 2s 32ms/step - loss: 0.4423 - acc: 0.2079 - val_loss: 0.5627 - val_acc: 0.2407\n",
      "Epoch 1459/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4820 - acc: 0.2075 - val_loss: 0.5742 - val_acc: 0.2444\n",
      "Epoch 1460/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4153 - acc: 0.2079 - val_loss: 0.4844 - val_acc: 0.2407\n",
      "Epoch 1461/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4300 - acc: 0.2075 - val_loss: 0.4999 - val_acc: 0.2444\n",
      "Epoch 1462/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4175 - acc: 0.2075 - val_loss: 0.5429 - val_acc: 0.2444\n",
      "Epoch 1463/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4388 - acc: 0.2071 - val_loss: 0.5485 - val_acc: 0.2407\n",
      "Epoch 1464/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4486 - acc: 0.2075 - val_loss: 0.4896 - val_acc: 0.2407\n",
      "Epoch 1465/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4648 - acc: 0.2075 - val_loss: 0.4972 - val_acc: 0.2444\n",
      "Epoch 1466/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4668 - acc: 0.2075 - val_loss: 0.4986 - val_acc: 0.2444\n",
      "Epoch 1467/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4167 - acc: 0.2079 - val_loss: 0.4922 - val_acc: 0.2444\n",
      "Epoch 1468/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5249 - acc: 0.2067 - val_loss: 0.4812 - val_acc: 0.2407\n",
      "Epoch 1469/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4639 - acc: 0.2067 - val_loss: 0.5023 - val_acc: 0.2444\n",
      "Epoch 1470/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4228 - acc: 0.2079 - val_loss: 0.5198 - val_acc: 0.2407\n",
      "Epoch 1471/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4376 - acc: 0.2079 - val_loss: 0.5641 - val_acc: 0.2444\n",
      "Epoch 1472/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4461 - acc: 0.2079 - val_loss: 0.5036 - val_acc: 0.2407\n",
      "Epoch 1473/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4302 - acc: 0.2079 - val_loss: 0.5100 - val_acc: 0.2444\n",
      "Epoch 1474/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4367 - acc: 0.2075 - val_loss: 0.4979 - val_acc: 0.2407\n",
      "Epoch 1475/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.5187 - acc: 0.2075 - val_loss: 0.5560 - val_acc: 0.2444\n",
      "Epoch 1476/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4401 - acc: 0.2067 - val_loss: 0.5427 - val_acc: 0.2407\n",
      "Epoch 1477/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4574 - acc: 0.2063 - val_loss: 0.5181 - val_acc: 0.2407\n",
      "Epoch 1478/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4536 - acc: 0.2075 - val_loss: 0.4934 - val_acc: 0.2407\n",
      "Epoch 1479/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4534 - acc: 0.2071 - val_loss: 0.5862 - val_acc: 0.2444\n",
      "Epoch 1480/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4163 - acc: 0.2075 - val_loss: 0.5137 - val_acc: 0.2444\n",
      "Epoch 1481/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4252 - acc: 0.2075 - val_loss: 0.4836 - val_acc: 0.2444\n",
      "Epoch 1482/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4263 - acc: 0.2083 - val_loss: 0.5397 - val_acc: 0.2407\n",
      "Epoch 1483/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4481 - acc: 0.2075 - val_loss: 0.5337 - val_acc: 0.2407\n",
      "Epoch 1484/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4626 - acc: 0.2079 - val_loss: 0.4953 - val_acc: 0.2407\n",
      "Epoch 1485/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4287 - acc: 0.2075 - val_loss: 0.4761 - val_acc: 0.2444\n",
      "Epoch 1486/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4326 - acc: 0.2083 - val_loss: 0.5324 - val_acc: 0.2444\n",
      "Epoch 1487/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4394 - acc: 0.2075 - val_loss: 0.6282 - val_acc: 0.2407\n",
      "Epoch 1488/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4464 - acc: 0.2079 - val_loss: 0.5394 - val_acc: 0.2444\n",
      "Epoch 1489/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4491 - acc: 0.2075 - val_loss: 0.6397 - val_acc: 0.2444\n",
      "Epoch 1490/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4383 - acc: 0.2079 - val_loss: 0.6649 - val_acc: 0.2407\n",
      "Epoch 1491/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4543 - acc: 0.2075 - val_loss: 0.4796 - val_acc: 0.2407\n",
      "Epoch 1492/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4314 - acc: 0.2079 - val_loss: 0.4874 - val_acc: 0.2444\n",
      "Epoch 1493/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4555 - acc: 0.2071 - val_loss: 0.5303 - val_acc: 0.2444\n",
      "Epoch 1494/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4313 - acc: 0.2071 - val_loss: 0.5012 - val_acc: 0.2407\n",
      "Epoch 1495/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4491 - acc: 0.2071 - val_loss: 0.5112 - val_acc: 0.2407\n",
      "Epoch 1496/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4475 - acc: 0.2079 - val_loss: 0.4976 - val_acc: 0.2444\n",
      "Epoch 1497/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4419 - acc: 0.2071 - val_loss: 0.5506 - val_acc: 0.2407\n",
      "Epoch 1498/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4542 - acc: 0.2071 - val_loss: 0.5928 - val_acc: 0.2407\n",
      "Epoch 1499/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4424 - acc: 0.2075 - val_loss: 0.5825 - val_acc: 0.2407\n",
      "Epoch 1500/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4477 - acc: 0.2075 - val_loss: 0.4660 - val_acc: 0.2407\n",
      "Epoch 1501/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4606 - acc: 0.2067 - val_loss: 0.5785 - val_acc: 0.2444\n",
      "Epoch 1502/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4194 - acc: 0.2075 - val_loss: 0.4971 - val_acc: 0.2444\n",
      "Epoch 1503/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4158 - acc: 0.2075 - val_loss: 0.4829 - val_acc: 0.2407\n",
      "Epoch 1504/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4677 - acc: 0.2075 - val_loss: 0.4727 - val_acc: 0.2407\n",
      "Epoch 1505/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4399 - acc: 0.2071 - val_loss: 0.5249 - val_acc: 0.2407\n",
      "Epoch 1506/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4583 - acc: 0.2075 - val_loss: 0.5247 - val_acc: 0.2444\n",
      "Epoch 1507/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4422 - acc: 0.2075 - val_loss: 0.4699 - val_acc: 0.2407\n",
      "Epoch 1508/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4350 - acc: 0.2067 - val_loss: 0.4771 - val_acc: 0.2407\n",
      "Epoch 1509/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4684 - acc: 0.2075 - val_loss: 0.4999 - val_acc: 0.2444\n",
      "Epoch 1510/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4444 - acc: 0.2075 - val_loss: 0.4808 - val_acc: 0.2444\n",
      "Epoch 1511/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4180 - acc: 0.2071 - val_loss: 0.6170 - val_acc: 0.2407\n",
      "Epoch 1512/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4777 - acc: 0.2071 - val_loss: 0.5402 - val_acc: 0.2407\n",
      "Epoch 1513/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4296 - acc: 0.2071 - val_loss: 0.4737 - val_acc: 0.2407\n",
      "Epoch 1514/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4425 - acc: 0.2075 - val_loss: 0.5058 - val_acc: 0.2444\n",
      "Epoch 1515/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4289 - acc: 0.2075 - val_loss: 0.5020 - val_acc: 0.2444\n",
      "Epoch 1516/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4407 - acc: 0.2079 - val_loss: 0.4748 - val_acc: 0.2407\n",
      "Epoch 1517/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4409 - acc: 0.2071 - val_loss: 0.4917 - val_acc: 0.2444\n",
      "Epoch 1518/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4460 - acc: 0.2075 - val_loss: 0.4973 - val_acc: 0.2407\n",
      "Epoch 1519/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4405 - acc: 0.2079 - val_loss: 0.5358 - val_acc: 0.2407\n",
      "Epoch 1520/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4538 - acc: 0.2075 - val_loss: 0.5677 - val_acc: 0.2444\n",
      "Epoch 1521/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4681 - acc: 0.2083 - val_loss: 0.5459 - val_acc: 0.2444\n",
      "Epoch 1522/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4754 - acc: 0.2071 - val_loss: 0.6145 - val_acc: 0.2444\n",
      "Epoch 1523/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4344 - acc: 0.2075 - val_loss: 0.5276 - val_acc: 0.2407\n",
      "Epoch 1524/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4441 - acc: 0.2083 - val_loss: 0.5545 - val_acc: 0.2444\n",
      "Epoch 1525/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4225 - acc: 0.2075 - val_loss: 0.4924 - val_acc: 0.2407\n",
      "Epoch 1526/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4156 - acc: 0.2075 - val_loss: 0.4941 - val_acc: 0.2444\n",
      "Epoch 1527/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4267 - acc: 0.2075 - val_loss: 0.4833 - val_acc: 0.2407\n",
      "Epoch 1528/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4511 - acc: 0.2075 - val_loss: 0.6094 - val_acc: 0.2407\n",
      "Epoch 1529/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4433 - acc: 0.2079 - val_loss: 0.4842 - val_acc: 0.2444\n",
      "Epoch 1530/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4221 - acc: 0.2075 - val_loss: 0.4937 - val_acc: 0.2444\n",
      "Epoch 1531/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4389 - acc: 0.2079 - val_loss: 0.5885 - val_acc: 0.2407\n",
      "Epoch 1532/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4511 - acc: 0.2071 - val_loss: 0.4693 - val_acc: 0.2407\n",
      "Epoch 1533/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4845 - acc: 0.2063 - val_loss: 0.5049 - val_acc: 0.2407\n",
      "Epoch 1534/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5000 - acc: 0.2063 - val_loss: 0.5513 - val_acc: 0.2444\n",
      "Epoch 1535/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4534 - acc: 0.2067 - val_loss: 0.5309 - val_acc: 0.2407\n",
      "Epoch 1536/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4447 - acc: 0.2063 - val_loss: 0.4821 - val_acc: 0.2407\n",
      "Epoch 1537/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4547 - acc: 0.2071 - val_loss: 0.5088 - val_acc: 0.2407\n",
      "Epoch 1538/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4464 - acc: 0.2075 - val_loss: 0.7730 - val_acc: 0.2370\n",
      "Epoch 1539/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4771 - acc: 0.2079 - val_loss: 0.4814 - val_acc: 0.2407\n",
      "Epoch 1540/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4409 - acc: 0.2075 - val_loss: 0.4789 - val_acc: 0.2407\n",
      "Epoch 1541/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4522 - acc: 0.2083 - val_loss: 0.4752 - val_acc: 0.2444\n",
      "Epoch 1542/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4481 - acc: 0.2079 - val_loss: 0.5227 - val_acc: 0.2407\n",
      "Epoch 1543/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4547 - acc: 0.2071 - val_loss: 0.4743 - val_acc: 0.2407\n",
      "Epoch 1544/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4326 - acc: 0.2075 - val_loss: 0.6457 - val_acc: 0.2444\n",
      "Epoch 1545/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4314 - acc: 0.2075 - val_loss: 0.5669 - val_acc: 0.2444\n",
      "Epoch 1546/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4136 - acc: 0.2075 - val_loss: 0.6004 - val_acc: 0.2407\n",
      "Epoch 1547/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4734 - acc: 0.2075 - val_loss: 0.7754 - val_acc: 0.2407\n",
      "Epoch 1548/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4618 - acc: 0.2067 - val_loss: 0.4981 - val_acc: 0.2444\n",
      "Epoch 1549/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4683 - acc: 0.2071 - val_loss: 0.4799 - val_acc: 0.2407\n",
      "Epoch 1550/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4538 - acc: 0.2071 - val_loss: 0.5057 - val_acc: 0.2407\n",
      "Epoch 1551/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4237 - acc: 0.2079 - val_loss: 0.4936 - val_acc: 0.2407\n",
      "Epoch 1552/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4364 - acc: 0.2079 - val_loss: 0.4910 - val_acc: 0.2407\n",
      "Epoch 1553/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4175 - acc: 0.2075 - val_loss: 0.5258 - val_acc: 0.2444\n",
      "Epoch 1554/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4463 - acc: 0.2075 - val_loss: 0.5170 - val_acc: 0.2444\n",
      "Epoch 1555/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4296 - acc: 0.2075 - val_loss: 0.4988 - val_acc: 0.2407\n",
      "Epoch 1556/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5010 - acc: 0.2071 - val_loss: 0.5117 - val_acc: 0.2444\n",
      "Epoch 1557/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4184 - acc: 0.2075 - val_loss: 0.5325 - val_acc: 0.2407\n",
      "Epoch 1558/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4629 - acc: 0.2071 - val_loss: 0.6569 - val_acc: 0.2444\n",
      "Epoch 1559/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4865 - acc: 0.2079 - val_loss: 0.4886 - val_acc: 0.2444\n",
      "Epoch 1560/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4497 - acc: 0.2067 - val_loss: 0.5301 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1561/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4275 - acc: 0.2071 - val_loss: 0.4988 - val_acc: 0.2407\n",
      "Epoch 1562/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4467 - acc: 0.2075 - val_loss: 0.5010 - val_acc: 0.2407\n",
      "Epoch 1563/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4665 - acc: 0.2067 - val_loss: 0.4999 - val_acc: 0.2407\n",
      "Epoch 1564/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4308 - acc: 0.2075 - val_loss: 0.4772 - val_acc: 0.2444\n",
      "Epoch 1565/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4182 - acc: 0.2079 - val_loss: 0.6353 - val_acc: 0.2444\n",
      "Epoch 1566/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4819 - acc: 0.2083 - val_loss: 0.6509 - val_acc: 0.2444\n",
      "Epoch 1567/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4240 - acc: 0.2075 - val_loss: 0.4772 - val_acc: 0.2444\n",
      "Epoch 1568/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4240 - acc: 0.2079 - val_loss: 0.5201 - val_acc: 0.2444\n",
      "Epoch 1569/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4298 - acc: 0.2079 - val_loss: 0.4942 - val_acc: 0.2407\n",
      "Epoch 1570/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4986 - acc: 0.2071 - val_loss: 0.4811 - val_acc: 0.2444\n",
      "Epoch 1571/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4447 - acc: 0.2079 - val_loss: 0.4741 - val_acc: 0.2444\n",
      "Epoch 1572/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4134 - acc: 0.2079 - val_loss: 0.5124 - val_acc: 0.2444\n",
      "Epoch 1573/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4298 - acc: 0.2075 - val_loss: 0.5503 - val_acc: 0.2407\n",
      "Epoch 1574/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4216 - acc: 0.2075 - val_loss: 0.5602 - val_acc: 0.2444\n",
      "Epoch 1575/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4488 - acc: 0.2071 - val_loss: 0.4711 - val_acc: 0.2407\n",
      "Epoch 1576/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4227 - acc: 0.2071 - val_loss: 0.4808 - val_acc: 0.2407\n",
      "Epoch 1577/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4086 - acc: 0.2071 - val_loss: 0.5158 - val_acc: 0.2444\n",
      "Epoch 1578/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4605 - acc: 0.2063 - val_loss: 0.5987 - val_acc: 0.2444\n",
      "Epoch 1579/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4579 - acc: 0.2071 - val_loss: 0.6836 - val_acc: 0.2407\n",
      "Epoch 1580/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4497 - acc: 0.2075 - val_loss: 0.6043 - val_acc: 0.2444\n",
      "Epoch 1581/10000\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.4449 - acc: 0.207 - 2s 32ms/step - loss: 0.4444 - acc: 0.2075 - val_loss: 0.6036 - val_acc: 0.2444\n",
      "Epoch 1582/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4357 - acc: 0.2079 - val_loss: 0.5209 - val_acc: 0.2407\n",
      "Epoch 1583/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4236 - acc: 0.2079 - val_loss: 0.5009 - val_acc: 0.2407\n",
      "Epoch 1584/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4268 - acc: 0.2075 - val_loss: 0.4691 - val_acc: 0.2407\n",
      "Epoch 1585/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4332 - acc: 0.2071 - val_loss: 0.5223 - val_acc: 0.2407\n",
      "Epoch 1586/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4325 - acc: 0.2079 - val_loss: 0.4710 - val_acc: 0.2407\n",
      "Epoch 1587/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4640 - acc: 0.2071 - val_loss: 0.5365 - val_acc: 0.2444\n",
      "Epoch 1588/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4399 - acc: 0.2079 - val_loss: 0.5122 - val_acc: 0.2444\n",
      "Epoch 1589/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4736 - acc: 0.2071 - val_loss: 0.5075 - val_acc: 0.2407\n",
      "Epoch 1590/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4606 - acc: 0.2075 - val_loss: 0.5198 - val_acc: 0.2407\n",
      "Epoch 1591/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4322 - acc: 0.2079 - val_loss: 0.4634 - val_acc: 0.2407\n",
      "Epoch 1592/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4497 - acc: 0.2079 - val_loss: 0.4910 - val_acc: 0.2407\n",
      "Epoch 1593/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4120 - acc: 0.2079 - val_loss: 0.4827 - val_acc: 0.2407\n",
      "Epoch 1594/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4254 - acc: 0.2075 - val_loss: 0.4961 - val_acc: 0.2407\n",
      "Epoch 1595/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4294 - acc: 0.2071 - val_loss: 0.5020 - val_acc: 0.2407\n",
      "Epoch 1596/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4382 - acc: 0.2071 - val_loss: 0.4892 - val_acc: 0.2407\n",
      "Epoch 1597/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4260 - acc: 0.2079 - val_loss: 0.4969 - val_acc: 0.2444\n",
      "Epoch 1598/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4371 - acc: 0.2075 - val_loss: 0.5150 - val_acc: 0.2444\n",
      "Epoch 1599/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4412 - acc: 0.2071 - val_loss: 0.4877 - val_acc: 0.2407\n",
      "Epoch 1600/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4435 - acc: 0.2079 - val_loss: 0.4923 - val_acc: 0.2407\n",
      "Epoch 1601/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4304 - acc: 0.2075 - val_loss: 0.5448 - val_acc: 0.2407\n",
      "Epoch 1602/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4193 - acc: 0.2079 - val_loss: 0.4767 - val_acc: 0.2444\n",
      "Epoch 1603/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4171 - acc: 0.2075 - val_loss: 0.4934 - val_acc: 0.2407\n",
      "Epoch 1604/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4592 - acc: 0.2075 - val_loss: 0.4681 - val_acc: 0.2444\n",
      "Epoch 1605/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4380 - acc: 0.2071 - val_loss: 0.5099 - val_acc: 0.2444\n",
      "Epoch 1606/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4312 - acc: 0.2083 - val_loss: 0.4700 - val_acc: 0.2407\n",
      "Epoch 1607/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4282 - acc: 0.2083 - val_loss: 0.5175 - val_acc: 0.2444\n",
      "Epoch 1608/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4360 - acc: 0.2075 - val_loss: 0.4960 - val_acc: 0.2407\n",
      "Epoch 1609/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4997 - acc: 0.2067 - val_loss: 0.5867 - val_acc: 0.2407\n",
      "Epoch 1610/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4323 - acc: 0.2067 - val_loss: 0.5193 - val_acc: 0.2407\n",
      "Epoch 1611/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4284 - acc: 0.2067 - val_loss: 0.4975 - val_acc: 0.2407\n",
      "Epoch 1612/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4294 - acc: 0.2071 - val_loss: 0.5058 - val_acc: 0.2444\n",
      "Epoch 1613/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4308 - acc: 0.2079 - val_loss: 0.4811 - val_acc: 0.2407\n",
      "Epoch 1614/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4158 - acc: 0.2075 - val_loss: 0.4753 - val_acc: 0.2407\n",
      "Epoch 1615/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4353 - acc: 0.2071 - val_loss: 0.5017 - val_acc: 0.2444\n",
      "Epoch 1616/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4171 - acc: 0.2079 - val_loss: 0.5725 - val_acc: 0.2407\n",
      "Epoch 1617/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4504 - acc: 0.2075 - val_loss: 0.4823 - val_acc: 0.2407\n",
      "Epoch 1618/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4279 - acc: 0.2075 - val_loss: 0.5655 - val_acc: 0.2407\n",
      "Epoch 1619/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4437 - acc: 0.2075 - val_loss: 0.4671 - val_acc: 0.2407\n",
      "Epoch 1620/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4497 - acc: 0.2075 - val_loss: 0.4840 - val_acc: 0.2407\n",
      "Epoch 1621/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4653 - acc: 0.2079 - val_loss: 0.5689 - val_acc: 0.2407\n",
      "Epoch 1622/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4325 - acc: 0.2075 - val_loss: 0.4893 - val_acc: 0.2407\n",
      "Epoch 1623/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4205 - acc: 0.2079 - val_loss: 0.4735 - val_acc: 0.2444\n",
      "Epoch 1624/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4601 - acc: 0.2071 - val_loss: 0.5061 - val_acc: 0.2407\n",
      "Epoch 1625/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4814 - acc: 0.2071 - val_loss: 0.6574 - val_acc: 0.2407\n",
      "Epoch 1626/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4336 - acc: 0.2071 - val_loss: 0.5149 - val_acc: 0.2444\n",
      "Epoch 1627/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4376 - acc: 0.2079 - val_loss: 0.6209 - val_acc: 0.2407\n",
      "Epoch 1628/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4657 - acc: 0.2079 - val_loss: 0.7357 - val_acc: 0.2444\n",
      "Epoch 1629/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4276 - acc: 0.2075 - val_loss: 0.5384 - val_acc: 0.2407\n",
      "Epoch 1630/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4119 - acc: 0.2079 - val_loss: 0.4746 - val_acc: 0.2407\n",
      "Epoch 1631/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4428 - acc: 0.2075 - val_loss: 0.6461 - val_acc: 0.2407\n",
      "Epoch 1632/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4481 - acc: 0.2079 - val_loss: 0.5067 - val_acc: 0.2444\n",
      "Epoch 1633/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4762 - acc: 0.2067 - val_loss: 0.5109 - val_acc: 0.2444\n",
      "Epoch 1634/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4205 - acc: 0.2075 - val_loss: 0.4823 - val_acc: 0.2444\n",
      "Epoch 1635/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4310 - acc: 0.2079 - val_loss: 0.5275 - val_acc: 0.2407\n",
      "Epoch 1636/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4510 - acc: 0.2067 - val_loss: 0.5125 - val_acc: 0.2407\n",
      "Epoch 1637/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4310 - acc: 0.2079 - val_loss: 0.4952 - val_acc: 0.2407\n",
      "Epoch 1638/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4231 - acc: 0.2079 - val_loss: 0.4936 - val_acc: 0.2407\n",
      "Epoch 1639/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4264 - acc: 0.2071 - val_loss: 0.4782 - val_acc: 0.2407\n",
      "Epoch 1640/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4263 - acc: 0.2075 - val_loss: 0.4980 - val_acc: 0.2407\n",
      "Epoch 1641/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4813 - acc: 0.2075 - val_loss: 0.4837 - val_acc: 0.2407\n",
      "Epoch 1642/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4269 - acc: 0.2075 - val_loss: 0.5283 - val_acc: 0.2444\n",
      "Epoch 1643/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4204 - acc: 0.2071 - val_loss: 0.5035 - val_acc: 0.2407\n",
      "Epoch 1644/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4372 - acc: 0.2071 - val_loss: 0.5306 - val_acc: 0.2444\n",
      "Epoch 1645/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4400 - acc: 0.2075 - val_loss: 0.5000 - val_acc: 0.2444\n",
      "Epoch 1646/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4436 - acc: 0.2079 - val_loss: 0.4969 - val_acc: 0.2444\n",
      "Epoch 1647/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4246 - acc: 0.2075 - val_loss: 0.4795 - val_acc: 0.2407\n",
      "Epoch 1648/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4271 - acc: 0.2079 - val_loss: 0.5585 - val_acc: 0.2407\n",
      "Epoch 1649/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4831 - acc: 0.2067 - val_loss: 0.4914 - val_acc: 0.2444\n",
      "Epoch 1650/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4577 - acc: 0.2079 - val_loss: 0.4766 - val_acc: 0.2407\n",
      "Epoch 1651/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4343 - acc: 0.2079 - val_loss: 0.4755 - val_acc: 0.2407\n",
      "Epoch 1652/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4170 - acc: 0.2083 - val_loss: 0.5696 - val_acc: 0.2444\n",
      "Epoch 1653/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4254 - acc: 0.2075 - val_loss: 0.5754 - val_acc: 0.2444\n",
      "Epoch 1654/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4381 - acc: 0.2075 - val_loss: 0.5510 - val_acc: 0.2444\n",
      "Epoch 1655/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4259 - acc: 0.2079 - val_loss: 0.5028 - val_acc: 0.2407\n",
      "Epoch 1656/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4264 - acc: 0.2075 - val_loss: 0.6187 - val_acc: 0.2407\n",
      "Epoch 1657/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4203 - acc: 0.2079 - val_loss: 0.4886 - val_acc: 0.2407\n",
      "Epoch 1658/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4344 - acc: 0.2075 - val_loss: 0.5004 - val_acc: 0.2444\n",
      "Epoch 1659/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4282 - acc: 0.2067 - val_loss: 0.5634 - val_acc: 0.2444\n",
      "Epoch 1660/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4156 - acc: 0.2079 - val_loss: 0.4754 - val_acc: 0.2407\n",
      "Epoch 1661/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4673 - acc: 0.2071 - val_loss: 0.6931 - val_acc: 0.2407\n",
      "Epoch 1662/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4253 - acc: 0.2079 - val_loss: 0.5126 - val_acc: 0.2444\n",
      "Epoch 1663/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4306 - acc: 0.2075 - val_loss: 0.5352 - val_acc: 0.2407\n",
      "Epoch 1664/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4223 - acc: 0.2079 - val_loss: 0.5304 - val_acc: 0.2407\n",
      "Epoch 1665/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4700 - acc: 0.2075 - val_loss: 0.5353 - val_acc: 0.2444\n",
      "Epoch 1666/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4812 - acc: 0.2071 - val_loss: 0.4938 - val_acc: 0.2444\n",
      "Epoch 1667/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4283 - acc: 0.2075 - val_loss: 0.4755 - val_acc: 0.2407\n",
      "Epoch 1668/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4414 - acc: 0.2075 - val_loss: 0.4805 - val_acc: 0.2407\n",
      "Epoch 1669/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4429 - acc: 0.2071 - val_loss: 0.4786 - val_acc: 0.2407\n",
      "Epoch 1670/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4303 - acc: 0.2071 - val_loss: 0.4936 - val_acc: 0.2407\n",
      "Epoch 1671/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4353 - acc: 0.2075 - val_loss: 0.5071 - val_acc: 0.2444\n",
      "Epoch 1672/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4183 - acc: 0.2075 - val_loss: 0.5666 - val_acc: 0.2444\n",
      "Epoch 1673/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4617 - acc: 0.2075 - val_loss: 0.4866 - val_acc: 0.2407\n",
      "Epoch 1674/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4149 - acc: 0.2079 - val_loss: 0.4952 - val_acc: 0.2407\n",
      "Epoch 1675/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4756 - acc: 0.2075 - val_loss: 0.4841 - val_acc: 0.2407\n",
      "Epoch 1676/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4310 - acc: 0.2075 - val_loss: 0.5767 - val_acc: 0.2444\n",
      "Epoch 1677/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4108 - acc: 0.2075 - val_loss: 0.4811 - val_acc: 0.2407\n",
      "Epoch 1678/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4495 - acc: 0.2079 - val_loss: 0.5334 - val_acc: 0.2444\n",
      "Epoch 1679/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4503 - acc: 0.2071 - val_loss: 0.6193 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1680/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4789 - acc: 0.2071 - val_loss: 0.5849 - val_acc: 0.2407\n",
      "Epoch 1681/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4324 - acc: 0.2079 - val_loss: 0.4715 - val_acc: 0.2407\n",
      "Epoch 1682/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4230 - acc: 0.2067 - val_loss: 0.4764 - val_acc: 0.2407\n",
      "Epoch 1683/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4104 - acc: 0.2079 - val_loss: 0.4844 - val_acc: 0.2407\n",
      "Epoch 1684/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4281 - acc: 0.2075 - val_loss: 0.5206 - val_acc: 0.2444\n",
      "Epoch 1685/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4621 - acc: 0.2071 - val_loss: 0.4642 - val_acc: 0.2407\n",
      "Epoch 1686/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4033 - acc: 0.2075 - val_loss: 0.5804 - val_acc: 0.2444\n",
      "Epoch 1687/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4162 - acc: 0.2079 - val_loss: 0.5130 - val_acc: 0.2407\n",
      "Epoch 1688/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4515 - acc: 0.2071 - val_loss: 0.5028 - val_acc: 0.2444\n",
      "Epoch 1689/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4404 - acc: 0.2075 - val_loss: 0.5185 - val_acc: 0.2444\n",
      "Epoch 1690/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4255 - acc: 0.2075 - val_loss: 0.4687 - val_acc: 0.2407\n",
      "Epoch 1691/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4292 - acc: 0.2079 - val_loss: 0.4741 - val_acc: 0.2407\n",
      "Epoch 1692/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4257 - acc: 0.2071 - val_loss: 0.4907 - val_acc: 0.2407\n",
      "Epoch 1693/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4506 - acc: 0.2075 - val_loss: 0.4823 - val_acc: 0.2407\n",
      "Epoch 1694/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4236 - acc: 0.2071 - val_loss: 0.4800 - val_acc: 0.2407\n",
      "Epoch 1695/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4286 - acc: 0.2067 - val_loss: 0.4918 - val_acc: 0.2444\n",
      "Epoch 1696/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4316 - acc: 0.2067 - val_loss: 0.4962 - val_acc: 0.2407\n",
      "Epoch 1697/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4221 - acc: 0.2075 - val_loss: 0.4910 - val_acc: 0.2444\n",
      "Epoch 1698/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4165 - acc: 0.2075 - val_loss: 0.4664 - val_acc: 0.2407\n",
      "Epoch 1699/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4356 - acc: 0.2079 - val_loss: 0.4643 - val_acc: 0.2407\n",
      "Epoch 1700/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4365 - acc: 0.2079 - val_loss: 0.5025 - val_acc: 0.2407\n",
      "Epoch 1701/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4317 - acc: 0.2079 - val_loss: 0.5099 - val_acc: 0.2407\n",
      "Epoch 1702/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4398 - acc: 0.2071 - val_loss: 0.4660 - val_acc: 0.2407\n",
      "Epoch 1703/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4318 - acc: 0.2071 - val_loss: 0.4945 - val_acc: 0.2407\n",
      "Epoch 1704/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4460 - acc: 0.2079 - val_loss: 0.6464 - val_acc: 0.2407\n",
      "Epoch 1705/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4620 - acc: 0.2075 - val_loss: 0.4840 - val_acc: 0.2407\n",
      "Epoch 1706/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4242 - acc: 0.2075 - val_loss: 0.4733 - val_acc: 0.2407\n",
      "Epoch 1707/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4527 - acc: 0.2067 - val_loss: 0.8735 - val_acc: 0.2444\n",
      "Epoch 1708/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4256 - acc: 0.2075 - val_loss: 0.4935 - val_acc: 0.2407\n",
      "Epoch 1709/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4075 - acc: 0.2075 - val_loss: 0.4915 - val_acc: 0.2444\n",
      "Epoch 1710/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4347 - acc: 0.2071 - val_loss: 0.4654 - val_acc: 0.2444\n",
      "Epoch 1711/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4435 - acc: 0.2071 - val_loss: 0.6623 - val_acc: 0.2444\n",
      "Epoch 1712/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4394 - acc: 0.2079 - val_loss: 0.4785 - val_acc: 0.2407\n",
      "Epoch 1713/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4372 - acc: 0.2075 - val_loss: 0.4727 - val_acc: 0.2407\n",
      "Epoch 1714/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4418 - acc: 0.2075 - val_loss: 0.5800 - val_acc: 0.2444\n",
      "Epoch 1715/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4476 - acc: 0.2075 - val_loss: 0.5602 - val_acc: 0.2444\n",
      "Epoch 1716/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4464 - acc: 0.2079 - val_loss: 0.4974 - val_acc: 0.2407\n",
      "Epoch 1717/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4107 - acc: 0.2075 - val_loss: 0.5189 - val_acc: 0.2407\n",
      "Epoch 1718/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4339 - acc: 0.2075 - val_loss: 0.4704 - val_acc: 0.2407\n",
      "Epoch 1719/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4090 - acc: 0.2079 - val_loss: 0.6486 - val_acc: 0.2407\n",
      "Epoch 1720/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4389 - acc: 0.2075 - val_loss: 0.5057 - val_acc: 0.2407\n",
      "Epoch 1721/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4188 - acc: 0.2075 - val_loss: 0.4911 - val_acc: 0.2407\n",
      "Epoch 1722/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4502 - acc: 0.2071 - val_loss: 0.5205 - val_acc: 0.2407\n",
      "Epoch 1723/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4306 - acc: 0.2079 - val_loss: 0.5220 - val_acc: 0.2407\n",
      "Epoch 1724/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4326 - acc: 0.2071 - val_loss: 0.4923 - val_acc: 0.2407\n",
      "Epoch 1725/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4122 - acc: 0.2079 - val_loss: 0.4693 - val_acc: 0.2407\n",
      "Epoch 1726/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4071 - acc: 0.2075 - val_loss: 0.5086 - val_acc: 0.2444\n",
      "Epoch 1727/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4305 - acc: 0.2075 - val_loss: 0.8287 - val_acc: 0.2370\n",
      "Epoch 1728/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4697 - acc: 0.2075 - val_loss: 0.5138 - val_acc: 0.2444\n",
      "Epoch 1729/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4351 - acc: 0.2075 - val_loss: 0.6414 - val_acc: 0.2444\n",
      "Epoch 1730/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4441 - acc: 0.2071 - val_loss: 0.4679 - val_acc: 0.2407\n",
      "Epoch 1731/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4342 - acc: 0.2075 - val_loss: 0.4667 - val_acc: 0.2407\n",
      "Epoch 1732/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4211 - acc: 0.2079 - val_loss: 0.4804 - val_acc: 0.2407\n",
      "Epoch 1733/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4267 - acc: 0.2063 - val_loss: 0.4850 - val_acc: 0.2407\n",
      "Epoch 1734/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4297 - acc: 0.2083 - val_loss: 0.6952 - val_acc: 0.2407\n",
      "Epoch 1735/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4807 - acc: 0.2071 - val_loss: 0.5090 - val_acc: 0.2407\n",
      "Epoch 1736/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4204 - acc: 0.2075 - val_loss: 0.5631 - val_acc: 0.2444\n",
      "Epoch 1737/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4360 - acc: 0.2071 - val_loss: 0.5091 - val_acc: 0.2407\n",
      "Epoch 1738/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4257 - acc: 0.2083 - val_loss: 0.5198 - val_acc: 0.2407\n",
      "Epoch 1739/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4190 - acc: 0.2075 - val_loss: 0.4735 - val_acc: 0.2407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1740/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4369 - acc: 0.2063 - val_loss: 0.6784 - val_acc: 0.2407\n",
      "Epoch 1741/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4449 - acc: 0.2075 - val_loss: 0.4648 - val_acc: 0.2407\n",
      "Epoch 1742/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4352 - acc: 0.2075 - val_loss: 0.4973 - val_acc: 0.2407\n",
      "Epoch 1743/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4179 - acc: 0.2079 - val_loss: 0.4813 - val_acc: 0.2407\n",
      "Epoch 1744/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4399 - acc: 0.2075 - val_loss: 0.4702 - val_acc: 0.2444\n",
      "Epoch 1745/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4146 - acc: 0.2071 - val_loss: 0.5230 - val_acc: 0.2407\n",
      "Epoch 1746/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4491 - acc: 0.2071 - val_loss: 0.5621 - val_acc: 0.2407\n",
      "Epoch 1747/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4213 - acc: 0.2075 - val_loss: 0.5283 - val_acc: 0.2407\n",
      "Epoch 1748/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4516 - acc: 0.2063 - val_loss: 0.4912 - val_acc: 0.2444\n",
      "Epoch 1749/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4166 - acc: 0.2075 - val_loss: 0.4755 - val_acc: 0.2407\n",
      "Epoch 1750/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4253 - acc: 0.2071 - val_loss: 0.5259 - val_acc: 0.2444\n",
      "Epoch 1751/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4422 - acc: 0.2075 - val_loss: 0.4608 - val_acc: 0.2407\n",
      "Epoch 1752/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4238 - acc: 0.2075 - val_loss: 0.4931 - val_acc: 0.2444\n",
      "Epoch 1753/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4255 - acc: 0.2079 - val_loss: 0.4529 - val_acc: 0.2407\n",
      "Epoch 1754/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4365 - acc: 0.2071 - val_loss: 0.4693 - val_acc: 0.2407\n",
      "Epoch 1755/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4495 - acc: 0.2079 - val_loss: 0.5063 - val_acc: 0.2444\n",
      "Epoch 1756/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4478 - acc: 0.2071 - val_loss: 0.5727 - val_acc: 0.2407\n",
      "Epoch 1757/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4284 - acc: 0.2079 - val_loss: 0.4864 - val_acc: 0.2407\n",
      "Epoch 1758/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4245 - acc: 0.2075 - val_loss: 0.4789 - val_acc: 0.2407\n",
      "Epoch 1759/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4140 - acc: 0.2079 - val_loss: 0.4601 - val_acc: 0.2407\n",
      "Epoch 1760/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4271 - acc: 0.2075 - val_loss: 0.5089 - val_acc: 0.2407\n",
      "Epoch 1761/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4430 - acc: 0.2075 - val_loss: 0.4794 - val_acc: 0.2407\n",
      "Epoch 1762/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4415 - acc: 0.2075 - val_loss: 0.5079 - val_acc: 0.2407\n",
      "Epoch 1763/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4521 - acc: 0.2083 - val_loss: 0.5209 - val_acc: 0.2407\n",
      "Epoch 1764/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4907 - acc: 0.2071 - val_loss: 0.4866 - val_acc: 0.2407\n",
      "Epoch 1765/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4138 - acc: 0.2079 - val_loss: 0.5252 - val_acc: 0.2407\n",
      "Epoch 1766/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4512 - acc: 0.2075 - val_loss: 0.4676 - val_acc: 0.2407\n",
      "Epoch 1767/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4560 - acc: 0.2075 - val_loss: 0.5221 - val_acc: 0.2407\n",
      "Epoch 1768/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4178 - acc: 0.2079 - val_loss: 0.6081 - val_acc: 0.2407\n",
      "Epoch 1769/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4276 - acc: 0.2075 - val_loss: 0.5913 - val_acc: 0.2407\n",
      "Epoch 1770/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4146 - acc: 0.2083 - val_loss: 0.4973 - val_acc: 0.2407\n",
      "Epoch 1771/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4324 - acc: 0.2079 - val_loss: 0.4770 - val_acc: 0.2407\n",
      "Epoch 1772/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4274 - acc: 0.2075 - val_loss: 0.5167 - val_acc: 0.2444\n",
      "Epoch 1773/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4428 - acc: 0.2083 - val_loss: 0.4700 - val_acc: 0.2407\n",
      "Epoch 1774/10000\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.4090 - acc: 0.207 - 2s 32ms/step - loss: 0.4096 - acc: 0.2079 - val_loss: 0.4979 - val_acc: 0.2444\n",
      "Epoch 1775/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4080 - acc: 0.2075 - val_loss: 0.4617 - val_acc: 0.2407\n",
      "Epoch 1776/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4188 - acc: 0.2075 - val_loss: 0.4952 - val_acc: 0.2444\n",
      "Epoch 1777/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4180 - acc: 0.2079 - val_loss: 0.4716 - val_acc: 0.2407\n",
      "Epoch 1778/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4289 - acc: 0.2075 - val_loss: 0.4582 - val_acc: 0.2407\n",
      "Epoch 1779/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4246 - acc: 0.2075 - val_loss: 0.5031 - val_acc: 0.2444\n",
      "Epoch 1780/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4323 - acc: 0.2075 - val_loss: 0.5271 - val_acc: 0.2444\n",
      "Epoch 1781/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4144 - acc: 0.2075 - val_loss: 0.4918 - val_acc: 0.2407\n",
      "Epoch 1782/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4428 - acc: 0.2075 - val_loss: 0.5017 - val_acc: 0.2407\n",
      "Epoch 1783/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4386 - acc: 0.2075 - val_loss: 0.5173 - val_acc: 0.2444\n",
      "Epoch 1784/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4156 - acc: 0.2083 - val_loss: 0.4649 - val_acc: 0.2407\n",
      "Epoch 1785/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4184 - acc: 0.2075 - val_loss: 0.4785 - val_acc: 0.2444\n",
      "Epoch 1786/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4412 - acc: 0.2071 - val_loss: 0.6113 - val_acc: 0.2444\n",
      "Epoch 1787/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4278 - acc: 0.2067 - val_loss: 0.5170 - val_acc: 0.2407\n",
      "Epoch 1788/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4319 - acc: 0.2071 - val_loss: 0.4649 - val_acc: 0.2407\n",
      "Epoch 1789/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4378 - acc: 0.2067 - val_loss: 0.5050 - val_acc: 0.2444\n",
      "Epoch 1790/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4273 - acc: 0.2067 - val_loss: 0.4697 - val_acc: 0.2407\n",
      "Epoch 1791/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4078 - acc: 0.2075 - val_loss: 0.5021 - val_acc: 0.2444\n",
      "Epoch 1792/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4547 - acc: 0.2079 - val_loss: 0.4631 - val_acc: 0.2407\n",
      "Epoch 1793/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4466 - acc: 0.2079 - val_loss: 0.4661 - val_acc: 0.2407\n",
      "Epoch 1794/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4849 - acc: 0.2075 - val_loss: 0.5586 - val_acc: 0.2444\n",
      "Epoch 1795/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.6004 - acc: 0.2075 - val_loss: 0.9870 - val_acc: 0.2407\n",
      "Epoch 1796/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.6809 - acc: 0.2087 - val_loss: 0.7232 - val_acc: 0.2407\n",
      "Epoch 1797/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5500 - acc: 0.2075 - val_loss: 0.6297 - val_acc: 0.2407\n",
      "Epoch 1798/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4672 - acc: 0.2067 - val_loss: 0.5763 - val_acc: 0.2407\n",
      "Epoch 1799/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4851 - acc: 0.2071 - val_loss: 0.5318 - val_acc: 0.2407\n",
      "Epoch 1800/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4451 - acc: 0.2083 - val_loss: 0.5246 - val_acc: 0.2407\n",
      "Epoch 1801/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4422 - acc: 0.2071 - val_loss: 0.6430 - val_acc: 0.2444\n",
      "Epoch 1802/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4356 - acc: 0.2083 - val_loss: 0.6179 - val_acc: 0.2407\n",
      "Epoch 1803/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4440 - acc: 0.2071 - val_loss: 0.4960 - val_acc: 0.2407\n",
      "Epoch 1804/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4130 - acc: 0.2079 - val_loss: 0.4900 - val_acc: 0.2444\n",
      "Epoch 1805/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4489 - acc: 0.2075 - val_loss: 0.5071 - val_acc: 0.2407\n",
      "Epoch 1806/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4191 - acc: 0.2075 - val_loss: 0.5549 - val_acc: 0.2407\n",
      "Epoch 1807/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4151 - acc: 0.2079 - val_loss: 0.4886 - val_acc: 0.2444\n",
      "Epoch 1808/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4042 - acc: 0.2075 - val_loss: 0.5922 - val_acc: 0.2444\n",
      "Epoch 1809/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4406 - acc: 0.2071 - val_loss: 0.4861 - val_acc: 0.2407\n",
      "Epoch 1810/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4136 - acc: 0.2079 - val_loss: 0.5301 - val_acc: 0.2444\n",
      "Epoch 1811/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4268 - acc: 0.2075 - val_loss: 0.4851 - val_acc: 0.2407\n",
      "Epoch 1812/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4041 - acc: 0.2075 - val_loss: 0.5175 - val_acc: 0.2444\n",
      "Epoch 1813/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4151 - acc: 0.2075 - val_loss: 0.5700 - val_acc: 0.2407\n",
      "Epoch 1814/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4238 - acc: 0.2079 - val_loss: 0.4931 - val_acc: 0.2407\n",
      "Epoch 1815/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4493 - acc: 0.2079 - val_loss: 0.5021 - val_acc: 0.2407\n",
      "Epoch 1816/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4188 - acc: 0.2079 - val_loss: 0.6332 - val_acc: 0.2407\n",
      "Epoch 1817/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4068 - acc: 0.2071 - val_loss: 0.4738 - val_acc: 0.2407\n",
      "Epoch 1818/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4489 - acc: 0.2071 - val_loss: 0.5490 - val_acc: 0.2407\n",
      "Epoch 1819/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4284 - acc: 0.2083 - val_loss: 0.5303 - val_acc: 0.2407\n",
      "Epoch 1820/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4226 - acc: 0.2071 - val_loss: 0.5893 - val_acc: 0.2407\n",
      "Epoch 1821/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4378 - acc: 0.2075 - val_loss: 0.4763 - val_acc: 0.2444\n",
      "Epoch 1822/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4404 - acc: 0.2079 - val_loss: 0.5098 - val_acc: 0.2444\n",
      "Epoch 1823/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4015 - acc: 0.2079 - val_loss: 0.4825 - val_acc: 0.2407\n",
      "Epoch 1824/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4077 - acc: 0.2075 - val_loss: 0.4739 - val_acc: 0.2407\n",
      "Epoch 1825/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4092 - acc: 0.2079 - val_loss: 0.4658 - val_acc: 0.2407\n",
      "Epoch 1826/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4475 - acc: 0.2067 - val_loss: 0.6043 - val_acc: 0.2444\n",
      "Epoch 1827/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4675 - acc: 0.2075 - val_loss: 0.5940 - val_acc: 0.2444\n",
      "Epoch 1828/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4171 - acc: 0.2075 - val_loss: 0.5160 - val_acc: 0.2444\n",
      "Epoch 1829/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4123 - acc: 0.2075 - val_loss: 0.4962 - val_acc: 0.2444\n",
      "Epoch 1830/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4511 - acc: 0.2071 - val_loss: 0.5257 - val_acc: 0.2407\n",
      "Epoch 1831/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4192 - acc: 0.2075 - val_loss: 0.4691 - val_acc: 0.2407\n",
      "Epoch 1832/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4288 - acc: 0.2079 - val_loss: 0.4854 - val_acc: 0.2407\n",
      "Epoch 1833/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4109 - acc: 0.2079 - val_loss: 0.4864 - val_acc: 0.2407\n",
      "Epoch 1834/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4472 - acc: 0.2079 - val_loss: 0.4998 - val_acc: 0.2444\n",
      "Epoch 1835/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4194 - acc: 0.2079 - val_loss: 0.5031 - val_acc: 0.2407\n",
      "Epoch 1836/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4203 - acc: 0.2079 - val_loss: 0.5078 - val_acc: 0.2407\n",
      "Epoch 1837/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4811 - acc: 0.2063 - val_loss: 0.4798 - val_acc: 0.2444\n",
      "Epoch 1838/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4120 - acc: 0.2083 - val_loss: 0.4798 - val_acc: 0.2407\n",
      "Epoch 1839/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4312 - acc: 0.2079 - val_loss: 0.5089 - val_acc: 0.2444\n",
      "Epoch 1840/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4119 - acc: 0.2075 - val_loss: 0.4887 - val_acc: 0.2444\n",
      "Epoch 1841/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4027 - acc: 0.2083 - val_loss: 0.6408 - val_acc: 0.2444\n",
      "Epoch 1842/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4541 - acc: 0.2075 - val_loss: 0.5432 - val_acc: 0.2407\n",
      "Epoch 1843/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4638 - acc: 0.2071 - val_loss: 0.5939 - val_acc: 0.2407\n",
      "Epoch 1844/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4514 - acc: 0.2054 - val_loss: 0.5149 - val_acc: 0.2444\n",
      "Epoch 1845/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4133 - acc: 0.2079 - val_loss: 0.4676 - val_acc: 0.2407\n",
      "Epoch 1846/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4047 - acc: 0.2079 - val_loss: 0.5249 - val_acc: 0.2407\n",
      "Epoch 1847/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4222 - acc: 0.2071 - val_loss: 0.4684 - val_acc: 0.2407\n",
      "Epoch 1848/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4212 - acc: 0.2079 - val_loss: 0.4648 - val_acc: 0.2407\n",
      "Epoch 1849/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4168 - acc: 0.2075 - val_loss: 0.4643 - val_acc: 0.2407\n",
      "Epoch 1850/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4145 - acc: 0.2071 - val_loss: 0.5427 - val_acc: 0.2407\n",
      "Epoch 1851/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4197 - acc: 0.2079 - val_loss: 0.7190 - val_acc: 0.2444\n",
      "Epoch 1852/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4560 - acc: 0.2067 - val_loss: 0.4903 - val_acc: 0.2444\n",
      "Epoch 1853/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4134 - acc: 0.2079 - val_loss: 0.4713 - val_acc: 0.2407\n",
      "Epoch 1854/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4321 - acc: 0.2079 - val_loss: 0.4797 - val_acc: 0.2444\n",
      "Epoch 1855/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4237 - acc: 0.2079 - val_loss: 0.4978 - val_acc: 0.2407\n",
      "Epoch 1856/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4306 - acc: 0.2075 - val_loss: 0.7069 - val_acc: 0.2407\n",
      "Epoch 1857/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4535 - acc: 0.2079 - val_loss: 0.4633 - val_acc: 0.2407\n",
      "Epoch 1858/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4046 - acc: 0.2079 - val_loss: 0.4680 - val_acc: 0.2407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1859/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4232 - acc: 0.2071 - val_loss: 0.4755 - val_acc: 0.2407\n",
      "Epoch 1860/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4111 - acc: 0.2075 - val_loss: 0.5402 - val_acc: 0.2407\n",
      "Epoch 1861/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4345 - acc: 0.2075 - val_loss: 0.7959 - val_acc: 0.2407\n",
      "Epoch 1862/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4773 - acc: 0.2079 - val_loss: 0.5424 - val_acc: 0.2444\n",
      "Epoch 1863/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4115 - acc: 0.2075 - val_loss: 0.5488 - val_acc: 0.2444\n",
      "Epoch 1864/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4040 - acc: 0.2075 - val_loss: 0.4613 - val_acc: 0.2407\n",
      "Epoch 1865/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4059 - acc: 0.2079 - val_loss: 0.4675 - val_acc: 0.2407\n",
      "Epoch 1866/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4481 - acc: 0.2079 - val_loss: 0.4595 - val_acc: 0.2407\n",
      "Epoch 1867/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4305 - acc: 0.2075 - val_loss: 0.4623 - val_acc: 0.2407\n",
      "Epoch 1868/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4782 - acc: 0.2071 - val_loss: 0.5425 - val_acc: 0.2407\n",
      "Epoch 1869/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4301 - acc: 0.2079 - val_loss: 0.4889 - val_acc: 0.2444\n",
      "Epoch 1870/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4427 - acc: 0.2067 - val_loss: 0.6393 - val_acc: 0.2407\n",
      "Epoch 1871/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4352 - acc: 0.2075 - val_loss: 0.5125 - val_acc: 0.2407\n",
      "Epoch 1872/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4450 - acc: 0.2063 - val_loss: 0.7415 - val_acc: 0.2444\n",
      "Epoch 1873/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4432 - acc: 0.2075 - val_loss: 0.4659 - val_acc: 0.2407\n",
      "Epoch 1874/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4200 - acc: 0.2079 - val_loss: 0.5034 - val_acc: 0.2444\n",
      "Epoch 1875/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4303 - acc: 0.2075 - val_loss: 0.4725 - val_acc: 0.2407\n",
      "Epoch 1876/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4200 - acc: 0.2075 - val_loss: 0.4841 - val_acc: 0.2444\n",
      "Epoch 1877/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4120 - acc: 0.2075 - val_loss: 0.4674 - val_acc: 0.2407\n",
      "Epoch 1878/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4190 - acc: 0.2075 - val_loss: 0.5129 - val_acc: 0.2444\n",
      "Epoch 1879/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4207 - acc: 0.2075 - val_loss: 0.4660 - val_acc: 0.2407\n",
      "Epoch 1880/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4138 - acc: 0.2079 - val_loss: 0.4663 - val_acc: 0.2407\n",
      "Epoch 1881/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4348 - acc: 0.2079 - val_loss: 0.4808 - val_acc: 0.2407\n",
      "Epoch 1882/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5982 - acc: 0.2075 - val_loss: 0.6592 - val_acc: 0.2407\n",
      "Epoch 1883/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5532 - acc: 0.2067 - val_loss: 0.5662 - val_acc: 0.2444\n",
      "Epoch 1884/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4188 - acc: 0.2079 - val_loss: 0.4905 - val_acc: 0.2444\n",
      "Epoch 1885/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4186 - acc: 0.2075 - val_loss: 0.5575 - val_acc: 0.2407\n",
      "Epoch 1886/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4503 - acc: 0.2075 - val_loss: 0.4810 - val_acc: 0.2444\n",
      "Epoch 1887/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3988 - acc: 0.2075 - val_loss: 0.4649 - val_acc: 0.2407\n",
      "Epoch 1888/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4277 - acc: 0.2075 - val_loss: 0.4820 - val_acc: 0.2444\n",
      "Epoch 1889/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4115 - acc: 0.2075 - val_loss: 0.6100 - val_acc: 0.2407\n",
      "Epoch 1890/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4381 - acc: 0.2075 - val_loss: 0.5693 - val_acc: 0.2444\n",
      "Epoch 1891/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4236 - acc: 0.2075 - val_loss: 0.4750 - val_acc: 0.2407\n",
      "Epoch 1892/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4401 - acc: 0.2071 - val_loss: 0.5071 - val_acc: 0.2444\n",
      "Epoch 1893/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4170 - acc: 0.2075 - val_loss: 0.4791 - val_acc: 0.2407\n",
      "Epoch 1894/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4420 - acc: 0.2083 - val_loss: 0.4868 - val_acc: 0.2444\n",
      "Epoch 1895/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4273 - acc: 0.2083 - val_loss: 0.4630 - val_acc: 0.2407\n",
      "Epoch 1896/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4238 - acc: 0.2071 - val_loss: 0.4755 - val_acc: 0.2407\n",
      "Epoch 1897/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4132 - acc: 0.2079 - val_loss: 0.4926 - val_acc: 0.2444\n",
      "Epoch 1898/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4547 - acc: 0.2071 - val_loss: 0.4689 - val_acc: 0.2407\n",
      "Epoch 1899/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4075 - acc: 0.2083 - val_loss: 0.4994 - val_acc: 0.2407\n",
      "Epoch 1900/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4735 - acc: 0.2075 - val_loss: 0.5584 - val_acc: 0.2407\n",
      "Epoch 1901/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4163 - acc: 0.2075 - val_loss: 0.5625 - val_acc: 0.2407\n",
      "Epoch 1902/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4150 - acc: 0.2071 - val_loss: 0.6700 - val_acc: 0.2407\n",
      "Epoch 1903/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4903 - acc: 0.2075 - val_loss: 0.5761 - val_acc: 0.2407\n",
      "Epoch 1904/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4244 - acc: 0.2067 - val_loss: 0.4751 - val_acc: 0.2444\n",
      "Epoch 1905/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4142 - acc: 0.2075 - val_loss: 0.4717 - val_acc: 0.2407\n",
      "Epoch 1906/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4304 - acc: 0.2071 - val_loss: 0.6037 - val_acc: 0.2444\n",
      "Epoch 1907/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4229 - acc: 0.2079 - val_loss: 0.4752 - val_acc: 0.2407\n",
      "Epoch 1908/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4211 - acc: 0.2079 - val_loss: 0.5970 - val_acc: 0.2407\n",
      "Epoch 1909/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4194 - acc: 0.2079 - val_loss: 0.4884 - val_acc: 0.2444\n",
      "Epoch 1910/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4268 - acc: 0.2079 - val_loss: 0.5842 - val_acc: 0.2444\n",
      "Epoch 1911/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4555 - acc: 0.2071 - val_loss: 0.4660 - val_acc: 0.2407\n",
      "Epoch 1912/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4133 - acc: 0.2075 - val_loss: 0.4725 - val_acc: 0.2444\n",
      "Epoch 1913/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4114 - acc: 0.2079 - val_loss: 0.5523 - val_acc: 0.2444\n",
      "Epoch 1914/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4548 - acc: 0.2079 - val_loss: 0.6105 - val_acc: 0.2444\n",
      "Epoch 1915/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4275 - acc: 0.2071 - val_loss: 0.4813 - val_acc: 0.2444\n",
      "Epoch 1916/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4445 - acc: 0.2071 - val_loss: 0.4741 - val_acc: 0.2407\n",
      "Epoch 1917/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4196 - acc: 0.2075 - val_loss: 0.4942 - val_acc: 0.2444\n",
      "Epoch 1918/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4283 - acc: 0.2071 - val_loss: 0.4851 - val_acc: 0.2407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1919/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4260 - acc: 0.2071 - val_loss: 0.4801 - val_acc: 0.2444\n",
      "Epoch 1920/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4224 - acc: 0.2071 - val_loss: 0.5012 - val_acc: 0.2444\n",
      "Epoch 1921/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4134 - acc: 0.2075 - val_loss: 0.5876 - val_acc: 0.2407\n",
      "Epoch 1922/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4128 - acc: 0.2071 - val_loss: 0.4542 - val_acc: 0.2407\n",
      "Epoch 1923/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4404 - acc: 0.2075 - val_loss: 0.4580 - val_acc: 0.2407\n",
      "Epoch 1924/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4294 - acc: 0.2063 - val_loss: 0.4960 - val_acc: 0.2444\n",
      "Epoch 1925/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4087 - acc: 0.2083 - val_loss: 0.4985 - val_acc: 0.2407\n",
      "Epoch 1926/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4167 - acc: 0.2075 - val_loss: 0.4955 - val_acc: 0.2407\n",
      "Epoch 1927/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4309 - acc: 0.2079 - val_loss: 0.4735 - val_acc: 0.2407\n",
      "Epoch 1928/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4084 - acc: 0.2075 - val_loss: 0.5498 - val_acc: 0.2407\n",
      "Epoch 1929/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4399 - acc: 0.2075 - val_loss: 0.4648 - val_acc: 0.2407\n",
      "Epoch 1930/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4846 - acc: 0.2083 - val_loss: 0.6157 - val_acc: 0.2407\n",
      "Epoch 1931/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4638 - acc: 0.2050 - val_loss: 0.5012 - val_acc: 0.2407\n",
      "Epoch 1932/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4161 - acc: 0.2075 - val_loss: 0.4826 - val_acc: 0.2444\n",
      "Epoch 1933/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5103 - acc: 0.2079 - val_loss: 0.5355 - val_acc: 0.2407\n",
      "Epoch 1934/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.7464 - acc: 0.2071 - val_loss: 0.6319 - val_acc: 0.2407\n",
      "Epoch 1935/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.5046 - acc: 0.2075 - val_loss: 0.5033 - val_acc: 0.2444\n",
      "Epoch 1936/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4254 - acc: 0.2079 - val_loss: 0.5280 - val_acc: 0.2407\n",
      "Epoch 1937/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4227 - acc: 0.2079 - val_loss: 0.5051 - val_acc: 0.2407\n",
      "Epoch 1938/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4253 - acc: 0.2079 - val_loss: 0.4948 - val_acc: 0.2407\n",
      "Epoch 1939/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4092 - acc: 0.2075 - val_loss: 0.4822 - val_acc: 0.2444\n",
      "Epoch 1940/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4448 - acc: 0.2075 - val_loss: 0.5252 - val_acc: 0.2444\n",
      "Epoch 1941/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4613 - acc: 0.2083 - val_loss: 0.4779 - val_acc: 0.2407\n",
      "Epoch 1942/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4076 - acc: 0.2079 - val_loss: 0.4677 - val_acc: 0.2407\n",
      "Epoch 1943/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4154 - acc: 0.2071 - val_loss: 0.4996 - val_acc: 0.2407\n",
      "Epoch 1944/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4113 - acc: 0.2079 - val_loss: 0.4834 - val_acc: 0.2407\n",
      "Epoch 1945/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4020 - acc: 0.2075 - val_loss: 0.4810 - val_acc: 0.2407\n",
      "Epoch 1946/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4460 - acc: 0.2071 - val_loss: 0.5937 - val_acc: 0.2407\n",
      "Epoch 1947/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4177 - acc: 0.2071 - val_loss: 0.4732 - val_acc: 0.2444\n",
      "Epoch 1948/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4196 - acc: 0.2071 - val_loss: 0.4750 - val_acc: 0.2407\n",
      "Epoch 1949/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4025 - acc: 0.2075 - val_loss: 0.4996 - val_acc: 0.2407\n",
      "Epoch 1950/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4332 - acc: 0.2071 - val_loss: 0.4792 - val_acc: 0.2407\n",
      "Epoch 1951/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4178 - acc: 0.2083 - val_loss: 0.4915 - val_acc: 0.2444\n",
      "Epoch 1952/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4210 - acc: 0.2071 - val_loss: 0.4968 - val_acc: 0.2444\n",
      "Epoch 1953/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4334 - acc: 0.2083 - val_loss: 0.4933 - val_acc: 0.2407\n",
      "Epoch 1954/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4066 - acc: 0.2075 - val_loss: 0.5289 - val_acc: 0.2407\n",
      "Epoch 1955/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4445 - acc: 0.2067 - val_loss: 0.4795 - val_acc: 0.2407\n",
      "Epoch 1956/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4272 - acc: 0.2067 - val_loss: 0.5173 - val_acc: 0.2407\n",
      "Epoch 1957/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4114 - acc: 0.2075 - val_loss: 0.4787 - val_acc: 0.2407\n",
      "Epoch 1958/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4216 - acc: 0.2083 - val_loss: 0.4705 - val_acc: 0.2444\n",
      "Epoch 1959/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4152 - acc: 0.2075 - val_loss: 0.4653 - val_acc: 0.2444\n",
      "Epoch 1960/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4313 - acc: 0.2071 - val_loss: 0.4773 - val_acc: 0.2407\n",
      "Epoch 1961/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4502 - acc: 0.2075 - val_loss: 0.4654 - val_acc: 0.2444\n",
      "Epoch 1962/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4200 - acc: 0.2075 - val_loss: 0.4752 - val_acc: 0.2407\n",
      "Epoch 1963/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4273 - acc: 0.2079 - val_loss: 0.6298 - val_acc: 0.2407\n",
      "Epoch 1964/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4275 - acc: 0.2071 - val_loss: 0.4683 - val_acc: 0.2407\n",
      "Epoch 1965/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4361 - acc: 0.2075 - val_loss: 0.4675 - val_acc: 0.2444\n",
      "Epoch 1966/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4182 - acc: 0.2071 - val_loss: 0.5331 - val_acc: 0.2444\n",
      "Epoch 1967/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4152 - acc: 0.2079 - val_loss: 0.5793 - val_acc: 0.2407\n",
      "Epoch 1968/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4051 - acc: 0.2075 - val_loss: 0.5278 - val_acc: 0.2444\n",
      "Epoch 1969/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4471 - acc: 0.2075 - val_loss: 0.4566 - val_acc: 0.2407\n",
      "Epoch 1970/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4200 - acc: 0.2079 - val_loss: 0.5263 - val_acc: 0.2444\n",
      "Epoch 1971/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4143 - acc: 0.2075 - val_loss: 0.5975 - val_acc: 0.2407\n",
      "Epoch 1972/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4467 - acc: 0.2071 - val_loss: 0.4592 - val_acc: 0.2407\n",
      "Epoch 1973/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4132 - acc: 0.2079 - val_loss: 0.4973 - val_acc: 0.2444\n",
      "Epoch 1974/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4289 - acc: 0.2079 - val_loss: 0.4865 - val_acc: 0.2444\n",
      "Epoch 1975/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4261 - acc: 0.2075 - val_loss: 0.5575 - val_acc: 0.2407\n",
      "Epoch 1976/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4272 - acc: 0.2079 - val_loss: 0.7335 - val_acc: 0.2444\n",
      "Epoch 1977/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4490 - acc: 0.2067 - val_loss: 0.5801 - val_acc: 0.2444\n",
      "Epoch 1978/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4089 - acc: 0.2079 - val_loss: 0.4793 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1979/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4052 - acc: 0.2075 - val_loss: 0.4784 - val_acc: 0.2407\n",
      "Epoch 1980/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4399 - acc: 0.2075 - val_loss: 0.5489 - val_acc: 0.2444\n",
      "Epoch 1981/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4588 - acc: 0.2079 - val_loss: 0.4632 - val_acc: 0.2407\n",
      "Epoch 1982/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4708 - acc: 0.2079 - val_loss: 0.4821 - val_acc: 0.2444\n",
      "Epoch 1983/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4267 - acc: 0.2083 - val_loss: 0.4665 - val_acc: 0.2407\n",
      "Epoch 1984/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3962 - acc: 0.2079 - val_loss: 0.4801 - val_acc: 0.2407\n",
      "Epoch 1985/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4140 - acc: 0.2079 - val_loss: 0.4950 - val_acc: 0.2407\n",
      "Epoch 1986/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4761 - acc: 0.2059 - val_loss: 0.4939 - val_acc: 0.2407\n",
      "Epoch 1987/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4296 - acc: 0.2067 - val_loss: 0.4694 - val_acc: 0.2407\n",
      "Epoch 1988/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4235 - acc: 0.2075 - val_loss: 0.6082 - val_acc: 0.2444\n",
      "Epoch 1989/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.8460 - acc: 0.2071 - val_loss: 0.8170 - val_acc: 0.2407\n",
      "Epoch 1990/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.6851 - acc: 0.2075 - val_loss: 0.6728 - val_acc: 0.2407\n",
      "Epoch 1991/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5300 - acc: 0.2079 - val_loss: 0.6681 - val_acc: 0.2444\n",
      "Epoch 1992/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4918 - acc: 0.2079 - val_loss: 0.5786 - val_acc: 0.2444\n",
      "Epoch 1993/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4809 - acc: 0.2079 - val_loss: 0.7173 - val_acc: 0.2407\n",
      "Epoch 1994/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4705 - acc: 0.2067 - val_loss: 0.5627 - val_acc: 0.2407\n",
      "Epoch 1995/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4271 - acc: 0.2075 - val_loss: 0.5224 - val_acc: 0.2444\n",
      "Epoch 1996/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4332 - acc: 0.2083 - val_loss: 0.4893 - val_acc: 0.2444\n",
      "Epoch 1997/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4131 - acc: 0.2079 - val_loss: 0.4840 - val_acc: 0.2407\n",
      "Epoch 1998/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4151 - acc: 0.2079 - val_loss: 0.5010 - val_acc: 0.2407\n",
      "Epoch 1999/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4185 - acc: 0.2071 - val_loss: 0.5755 - val_acc: 0.2444\n",
      "Epoch 2000/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4140 - acc: 0.2083 - val_loss: 0.5377 - val_acc: 0.2444\n",
      "Epoch 2001/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4194 - acc: 0.2075 - val_loss: 0.4845 - val_acc: 0.2444\n",
      "Epoch 2002/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4019 - acc: 0.2075 - val_loss: 0.4767 - val_acc: 0.2407\n",
      "Epoch 2003/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4871 - acc: 0.2075 - val_loss: 0.5244 - val_acc: 0.2407\n",
      "Epoch 2004/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4382 - acc: 0.2079 - val_loss: 0.4886 - val_acc: 0.2444\n",
      "Epoch 2005/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4000 - acc: 0.2079 - val_loss: 0.4839 - val_acc: 0.2444\n",
      "Epoch 2006/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4080 - acc: 0.2083 - val_loss: 0.4757 - val_acc: 0.2444\n",
      "Epoch 2007/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4132 - acc: 0.2079 - val_loss: 0.4816 - val_acc: 0.2407\n",
      "Epoch 2008/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4203 - acc: 0.2071 - val_loss: 0.4701 - val_acc: 0.2444\n",
      "Epoch 2009/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4108 - acc: 0.2083 - val_loss: 0.5734 - val_acc: 0.2407\n",
      "Epoch 2010/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4147 - acc: 0.2075 - val_loss: 0.4883 - val_acc: 0.2444\n",
      "Epoch 2011/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4116 - acc: 0.2071 - val_loss: 0.4810 - val_acc: 0.2407\n",
      "Epoch 2012/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4373 - acc: 0.2071 - val_loss: 0.4870 - val_acc: 0.2407\n",
      "Epoch 2013/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3984 - acc: 0.2083 - val_loss: 0.4597 - val_acc: 0.2407\n",
      "Epoch 2014/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4236 - acc: 0.2067 - val_loss: 0.4777 - val_acc: 0.2407\n",
      "Epoch 2015/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4154 - acc: 0.2071 - val_loss: 0.4744 - val_acc: 0.2444\n",
      "Epoch 2016/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4053 - acc: 0.2079 - val_loss: 0.5115 - val_acc: 0.2444\n",
      "Epoch 2017/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4367 - acc: 0.2079 - val_loss: 0.4961 - val_acc: 0.2407\n",
      "Epoch 2018/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4018 - acc: 0.2075 - val_loss: 0.5122 - val_acc: 0.2444\n",
      "Epoch 2019/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4665 - acc: 0.2067 - val_loss: 0.6167 - val_acc: 0.2407\n",
      "Epoch 2020/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4233 - acc: 0.2075 - val_loss: 0.4644 - val_acc: 0.2407\n",
      "Epoch 2021/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4103 - acc: 0.2075 - val_loss: 0.4757 - val_acc: 0.2407\n",
      "Epoch 2022/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4225 - acc: 0.2075 - val_loss: 0.4659 - val_acc: 0.2407\n",
      "Epoch 2023/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4453 - acc: 0.2075 - val_loss: 0.4565 - val_acc: 0.2407\n",
      "Epoch 2024/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4099 - acc: 0.2071 - val_loss: 0.4730 - val_acc: 0.2407\n",
      "Epoch 2025/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4184 - acc: 0.2075 - val_loss: 0.4675 - val_acc: 0.2407\n",
      "Epoch 2026/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4365 - acc: 0.2071 - val_loss: 0.4717 - val_acc: 0.2407\n",
      "Epoch 2027/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4174 - acc: 0.2075 - val_loss: 0.4638 - val_acc: 0.2444\n",
      "Epoch 2028/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4161 - acc: 0.2079 - val_loss: 0.6578 - val_acc: 0.2444\n",
      "Epoch 2029/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4296 - acc: 0.2083 - val_loss: 0.5637 - val_acc: 0.2444\n",
      "Epoch 2030/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4850 - acc: 0.2075 - val_loss: 0.5476 - val_acc: 0.2444\n",
      "Epoch 2031/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4250 - acc: 0.2079 - val_loss: 0.5258 - val_acc: 0.2444\n",
      "Epoch 2032/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4308 - acc: 0.2075 - val_loss: 0.4602 - val_acc: 0.2407\n",
      "Epoch 2033/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4402 - acc: 0.2071 - val_loss: 0.4913 - val_acc: 0.2407\n",
      "Epoch 2034/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4102 - acc: 0.2079 - val_loss: 0.4877 - val_acc: 0.2407\n",
      "Epoch 2035/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4051 - acc: 0.2067 - val_loss: 0.4621 - val_acc: 0.2407\n",
      "Epoch 2036/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4167 - acc: 0.2079 - val_loss: 0.4525 - val_acc: 0.2407\n",
      "Epoch 2037/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4115 - acc: 0.2079 - val_loss: 0.4995 - val_acc: 0.2407\n",
      "Epoch 2038/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4410 - acc: 0.2075 - val_loss: 0.6426 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2039/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4503 - acc: 0.2067 - val_loss: 0.5709 - val_acc: 0.2444\n",
      "Epoch 2040/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4314 - acc: 0.2075 - val_loss: 0.4860 - val_acc: 0.2444\n",
      "Epoch 2041/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4344 - acc: 0.2075 - val_loss: 0.4626 - val_acc: 0.2444\n",
      "Epoch 2042/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4178 - acc: 0.2079 - val_loss: 0.4762 - val_acc: 0.2444\n",
      "Epoch 2043/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4143 - acc: 0.2075 - val_loss: 0.4585 - val_acc: 0.2407\n",
      "Epoch 2044/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4035 - acc: 0.2079 - val_loss: 0.4639 - val_acc: 0.2407\n",
      "Epoch 2045/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4089 - acc: 0.2079 - val_loss: 0.4737 - val_acc: 0.2407\n",
      "Epoch 2046/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4288 - acc: 0.2075 - val_loss: 0.4619 - val_acc: 0.2444\n",
      "Epoch 2047/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4194 - acc: 0.2079 - val_loss: 0.4629 - val_acc: 0.2407\n",
      "Epoch 2048/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4223 - acc: 0.2083 - val_loss: 0.6609 - val_acc: 0.2444\n",
      "Epoch 2049/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4187 - acc: 0.2075 - val_loss: 0.4786 - val_acc: 0.2444\n",
      "Epoch 2050/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4498 - acc: 0.2075 - val_loss: 0.4976 - val_acc: 0.2407\n",
      "Epoch 2051/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4631 - acc: 0.2071 - val_loss: 0.4841 - val_acc: 0.2407\n",
      "Epoch 2052/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4170 - acc: 0.2071 - val_loss: 0.4598 - val_acc: 0.2407\n",
      "Epoch 2053/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4580 - acc: 0.2063 - val_loss: 0.5208 - val_acc: 0.2407\n",
      "Epoch 2054/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4258 - acc: 0.2075 - val_loss: 0.4819 - val_acc: 0.2407\n",
      "Epoch 2055/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4165 - acc: 0.2079 - val_loss: 0.5128 - val_acc: 0.2444\n",
      "Epoch 2056/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4180 - acc: 0.2071 - val_loss: 0.4695 - val_acc: 0.2407\n",
      "Epoch 2057/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4198 - acc: 0.2075 - val_loss: 0.4766 - val_acc: 0.2407\n",
      "Epoch 2058/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4365 - acc: 0.2071 - val_loss: 0.4766 - val_acc: 0.2444\n",
      "Epoch 2059/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4228 - acc: 0.2087 - val_loss: 0.4834 - val_acc: 0.2444\n",
      "Epoch 2060/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4064 - acc: 0.2079 - val_loss: 0.4530 - val_acc: 0.2407\n",
      "Epoch 2061/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4351 - acc: 0.2075 - val_loss: 0.6025 - val_acc: 0.2407\n",
      "Epoch 2062/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4402 - acc: 0.2083 - val_loss: 0.4590 - val_acc: 0.2407\n",
      "Epoch 2063/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4415 - acc: 0.2071 - val_loss: 0.5389 - val_acc: 0.2407\n",
      "Epoch 2064/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4301 - acc: 0.2067 - val_loss: 0.5720 - val_acc: 0.2407\n",
      "Epoch 2065/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4294 - acc: 0.2075 - val_loss: 0.4746 - val_acc: 0.2407\n",
      "Epoch 2066/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4040 - acc: 0.2079 - val_loss: 0.4598 - val_acc: 0.2407\n",
      "Epoch 2067/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4246 - acc: 0.2075 - val_loss: 0.5424 - val_acc: 0.2407\n",
      "Epoch 2068/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4350 - acc: 0.2079 - val_loss: 0.5952 - val_acc: 0.2444\n",
      "Epoch 2069/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4106 - acc: 0.2075 - val_loss: 0.4858 - val_acc: 0.2444\n",
      "Epoch 2070/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4268 - acc: 0.2079 - val_loss: 0.4690 - val_acc: 0.2444\n",
      "Epoch 2071/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4120 - acc: 0.2079 - val_loss: 0.5307 - val_acc: 0.2444\n",
      "Epoch 2072/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4331 - acc: 0.2071 - val_loss: 0.4710 - val_acc: 0.2444\n",
      "Epoch 2073/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4486 - acc: 0.2071 - val_loss: 0.4472 - val_acc: 0.2407\n",
      "Epoch 2074/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4460 - acc: 0.2079 - val_loss: 0.5102 - val_acc: 0.2444\n",
      "Epoch 2075/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4158 - acc: 0.2079 - val_loss: 0.4776 - val_acc: 0.2444\n",
      "Epoch 2076/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4108 - acc: 0.2075 - val_loss: 0.4726 - val_acc: 0.2407\n",
      "Epoch 2077/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4124 - acc: 0.2079 - val_loss: 0.4645 - val_acc: 0.2407\n",
      "Epoch 2078/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4702 - acc: 0.2071 - val_loss: 0.5736 - val_acc: 0.2444\n",
      "Epoch 2079/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4636 - acc: 0.2071 - val_loss: 0.4549 - val_acc: 0.2407\n",
      "Epoch 2080/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5942 - acc: 0.2075 - val_loss: 0.7217 - val_acc: 0.2407\n",
      "Epoch 2081/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5412 - acc: 0.2075 - val_loss: 0.6443 - val_acc: 0.2407\n",
      "Epoch 2082/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4233 - acc: 0.2075 - val_loss: 0.5196 - val_acc: 0.2407\n",
      "Epoch 2083/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4256 - acc: 0.2075 - val_loss: 0.5094 - val_acc: 0.2444\n",
      "Epoch 2084/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4153 - acc: 0.2079 - val_loss: 0.4736 - val_acc: 0.2444\n",
      "Epoch 2085/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4158 - acc: 0.2071 - val_loss: 0.4679 - val_acc: 0.2444\n",
      "Epoch 2086/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4280 - acc: 0.2075 - val_loss: 0.4838 - val_acc: 0.2407\n",
      "Epoch 2087/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4206 - acc: 0.2075 - val_loss: 0.4793 - val_acc: 0.2444\n",
      "Epoch 2088/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4040 - acc: 0.2079 - val_loss: 0.4694 - val_acc: 0.2407\n",
      "Epoch 2089/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4054 - acc: 0.2075 - val_loss: 0.4786 - val_acc: 0.2407\n",
      "Epoch 2090/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4320 - acc: 0.2071 - val_loss: 0.5327 - val_acc: 0.2407\n",
      "Epoch 2091/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4580 - acc: 0.2079 - val_loss: 0.5852 - val_acc: 0.2444\n",
      "Epoch 2092/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4123 - acc: 0.2079 - val_loss: 0.5506 - val_acc: 0.2407\n",
      "Epoch 2093/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4277 - acc: 0.2079 - val_loss: 0.5049 - val_acc: 0.2444\n",
      "Epoch 2094/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4013 - acc: 0.2075 - val_loss: 0.4632 - val_acc: 0.2407\n",
      "Epoch 2095/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4013 - acc: 0.2075 - val_loss: 0.4784 - val_acc: 0.2407\n",
      "Epoch 2096/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4207 - acc: 0.2071 - val_loss: 0.4905 - val_acc: 0.2444\n",
      "Epoch 2097/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4135 - acc: 0.2071 - val_loss: 0.5663 - val_acc: 0.2407\n",
      "Epoch 2098/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4190 - acc: 0.2083 - val_loss: 0.7311 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2099/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4434 - acc: 0.2075 - val_loss: 0.4756 - val_acc: 0.2407\n",
      "Epoch 2100/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4050 - acc: 0.2079 - val_loss: 0.4563 - val_acc: 0.2407\n",
      "Epoch 2101/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4256 - acc: 0.2079 - val_loss: 0.4783 - val_acc: 0.2407\n",
      "Epoch 2102/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4064 - acc: 0.2075 - val_loss: 0.4537 - val_acc: 0.2407\n",
      "Epoch 2103/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4075 - acc: 0.2071 - val_loss: 0.4737 - val_acc: 0.2444\n",
      "Epoch 2104/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4268 - acc: 0.2075 - val_loss: 0.4756 - val_acc: 0.2444\n",
      "Epoch 2105/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4174 - acc: 0.2067 - val_loss: 0.4596 - val_acc: 0.2407\n",
      "Epoch 2106/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4368 - acc: 0.2063 - val_loss: 0.4562 - val_acc: 0.2407\n",
      "Epoch 2107/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4613 - acc: 0.2075 - val_loss: 0.4742 - val_acc: 0.2407\n",
      "Epoch 2108/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4005 - acc: 0.2075 - val_loss: 0.4635 - val_acc: 0.2407\n",
      "Epoch 2109/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4211 - acc: 0.2075 - val_loss: 0.4835 - val_acc: 0.2407\n",
      "Epoch 2110/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4390 - acc: 0.2075 - val_loss: 0.5117 - val_acc: 0.2444\n",
      "Epoch 2111/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4106 - acc: 0.2075 - val_loss: 0.5959 - val_acc: 0.2444\n",
      "Epoch 2112/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4260 - acc: 0.2075 - val_loss: 0.5313 - val_acc: 0.2444\n",
      "Epoch 2113/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4204 - acc: 0.2075 - val_loss: 0.4630 - val_acc: 0.2444\n",
      "Epoch 2114/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4043 - acc: 0.2079 - val_loss: 0.4575 - val_acc: 0.2407\n",
      "Epoch 2115/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4319 - acc: 0.2079 - val_loss: 0.4957 - val_acc: 0.2444\n",
      "Epoch 2116/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4198 - acc: 0.2079 - val_loss: 0.6355 - val_acc: 0.2407\n",
      "Epoch 2117/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4154 - acc: 0.2071 - val_loss: 0.5584 - val_acc: 0.2444\n",
      "Epoch 2118/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4265 - acc: 0.2079 - val_loss: 0.4551 - val_acc: 0.2407\n",
      "Epoch 2119/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4295 - acc: 0.2075 - val_loss: 0.4658 - val_acc: 0.2407\n",
      "Epoch 2120/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4012 - acc: 0.2075 - val_loss: 0.5996 - val_acc: 0.2444\n",
      "Epoch 2121/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4776 - acc: 0.2067 - val_loss: 0.4592 - val_acc: 0.2407\n",
      "Epoch 2122/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4195 - acc: 0.2071 - val_loss: 0.4676 - val_acc: 0.2407\n",
      "Epoch 2123/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4273 - acc: 0.2075 - val_loss: 0.6711 - val_acc: 0.2407\n",
      "Epoch 2124/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4357 - acc: 0.2071 - val_loss: 0.4865 - val_acc: 0.2407\n",
      "Epoch 2125/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4060 - acc: 0.2079 - val_loss: 0.5188 - val_acc: 0.2407\n",
      "Epoch 2126/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4238 - acc: 0.2079 - val_loss: 0.4701 - val_acc: 0.2407\n",
      "Epoch 2127/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4183 - acc: 0.2079 - val_loss: 0.5009 - val_acc: 0.2407\n",
      "Epoch 2128/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4157 - acc: 0.2075 - val_loss: 0.4624 - val_acc: 0.2407\n",
      "Epoch 2129/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4063 - acc: 0.2075 - val_loss: 0.4660 - val_acc: 0.2444\n",
      "Epoch 2130/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4580 - acc: 0.2063 - val_loss: 0.5025 - val_acc: 0.2444\n",
      "Epoch 2131/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4268 - acc: 0.2079 - val_loss: 0.8077 - val_acc: 0.2407\n",
      "Epoch 2132/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4135 - acc: 0.2079 - val_loss: 0.5016 - val_acc: 0.2444\n",
      "Epoch 2133/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4091 - acc: 0.2083 - val_loss: 0.4660 - val_acc: 0.2407\n",
      "Epoch 2134/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4461 - acc: 0.2067 - val_loss: 0.4622 - val_acc: 0.2407\n",
      "Epoch 2135/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4318 - acc: 0.2079 - val_loss: 0.4728 - val_acc: 0.2444\n",
      "Epoch 2136/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4234 - acc: 0.2079 - val_loss: 0.4687 - val_acc: 0.2444\n",
      "Epoch 2137/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4270 - acc: 0.2075 - val_loss: 0.6463 - val_acc: 0.2444\n",
      "Epoch 2138/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4144 - acc: 0.2083 - val_loss: 0.7278 - val_acc: 0.2407\n",
      "Epoch 2139/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4241 - acc: 0.2071 - val_loss: 0.4944 - val_acc: 0.2444\n",
      "Epoch 2140/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4282 - acc: 0.2079 - val_loss: 0.5111 - val_acc: 0.2407\n",
      "Epoch 2141/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4201 - acc: 0.2083 - val_loss: 0.4622 - val_acc: 0.2407\n",
      "Epoch 2142/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4005 - acc: 0.2079 - val_loss: 0.4559 - val_acc: 0.2407\n",
      "Epoch 2143/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4021 - acc: 0.2079 - val_loss: 0.5068 - val_acc: 0.2444\n",
      "Epoch 2144/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4182 - acc: 0.2083 - val_loss: 0.4612 - val_acc: 0.2407\n",
      "Epoch 2145/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4117 - acc: 0.2083 - val_loss: 0.5148 - val_acc: 0.2407\n",
      "Epoch 2146/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4582 - acc: 0.2063 - val_loss: 0.5923 - val_acc: 0.2444\n",
      "Epoch 2147/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4420 - acc: 0.2071 - val_loss: 0.4592 - val_acc: 0.2407\n",
      "Epoch 2148/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4137 - acc: 0.2071 - val_loss: 0.4968 - val_acc: 0.2407\n",
      "Epoch 2149/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4473 - acc: 0.2075 - val_loss: 0.5287 - val_acc: 0.2444\n",
      "Epoch 2150/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4673 - acc: 0.2067 - val_loss: 0.5144 - val_acc: 0.2444\n",
      "Epoch 2151/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4063 - acc: 0.2075 - val_loss: 0.4991 - val_acc: 0.2407\n",
      "Epoch 2152/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4246 - acc: 0.2075 - val_loss: 0.4916 - val_acc: 0.2407\n",
      "Epoch 2153/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4194 - acc: 0.2071 - val_loss: 0.4900 - val_acc: 0.2444\n",
      "Epoch 2154/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4272 - acc: 0.2079 - val_loss: 0.4879 - val_acc: 0.2444\n",
      "Epoch 2155/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3999 - acc: 0.2071 - val_loss: 0.4464 - val_acc: 0.2407\n",
      "Epoch 2156/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4617 - acc: 0.2071 - val_loss: 0.4643 - val_acc: 0.2407\n",
      "Epoch 2157/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4392 - acc: 0.2075 - val_loss: 0.4884 - val_acc: 0.2407\n",
      "Epoch 2158/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4179 - acc: 0.2079 - val_loss: 0.5641 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2159/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4490 - acc: 0.2071 - val_loss: 0.5181 - val_acc: 0.2407\n",
      "Epoch 2160/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4192 - acc: 0.2075 - val_loss: 0.4743 - val_acc: 0.2444\n",
      "Epoch 2161/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4126 - acc: 0.2071 - val_loss: 0.4596 - val_acc: 0.2407\n",
      "Epoch 2162/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4385 - acc: 0.2071 - val_loss: 0.5056 - val_acc: 0.2407\n",
      "Epoch 2163/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4250 - acc: 0.2075 - val_loss: 0.4950 - val_acc: 0.2407\n",
      "Epoch 2164/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4407 - acc: 0.2075 - val_loss: 0.5306 - val_acc: 0.2407\n",
      "Epoch 2165/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4128 - acc: 0.2079 - val_loss: 0.4557 - val_acc: 0.2407\n",
      "Epoch 2166/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3979 - acc: 0.2079 - val_loss: 0.5928 - val_acc: 0.2444\n",
      "Epoch 2167/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4442 - acc: 0.2079 - val_loss: 0.4523 - val_acc: 0.2407\n",
      "Epoch 2168/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4112 - acc: 0.2083 - val_loss: 0.4603 - val_acc: 0.2407\n",
      "Epoch 2169/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4033 - acc: 0.2075 - val_loss: 0.4552 - val_acc: 0.2407\n",
      "Epoch 2170/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4153 - acc: 0.2083 - val_loss: 0.4756 - val_acc: 0.2407\n",
      "Epoch 2171/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4055 - acc: 0.2075 - val_loss: 0.4706 - val_acc: 0.2407\n",
      "Epoch 2172/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4206 - acc: 0.2083 - val_loss: 0.4509 - val_acc: 0.2407\n",
      "Epoch 2173/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4055 - acc: 0.2079 - val_loss: 0.5290 - val_acc: 0.2407\n",
      "Epoch 2174/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4133 - acc: 0.2083 - val_loss: 0.5985 - val_acc: 0.2444\n",
      "Epoch 2175/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4629 - acc: 0.2063 - val_loss: 0.5614 - val_acc: 0.2407\n",
      "Epoch 2176/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4134 - acc: 0.2075 - val_loss: 0.4487 - val_acc: 0.2407\n",
      "Epoch 2177/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4262 - acc: 0.2075 - val_loss: 0.4668 - val_acc: 0.2407\n",
      "Epoch 2178/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3979 - acc: 0.2079 - val_loss: 0.5086 - val_acc: 0.2444\n",
      "Epoch 2179/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4164 - acc: 0.2075 - val_loss: 0.5091 - val_acc: 0.2444\n",
      "Epoch 2180/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4367 - acc: 0.2079 - val_loss: 0.4564 - val_acc: 0.2407\n",
      "Epoch 2181/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4187 - acc: 0.2087 - val_loss: 0.4969 - val_acc: 0.2444\n",
      "Epoch 2182/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4125 - acc: 0.2071 - val_loss: 0.4892 - val_acc: 0.2407\n",
      "Epoch 2183/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4207 - acc: 0.2071 - val_loss: 0.4620 - val_acc: 0.2407\n",
      "Epoch 2184/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4413 - acc: 0.2075 - val_loss: 0.4984 - val_acc: 0.2407\n",
      "Epoch 2185/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4168 - acc: 0.2071 - val_loss: 0.5941 - val_acc: 0.2444\n",
      "Epoch 2186/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4120 - acc: 0.2075 - val_loss: 0.4908 - val_acc: 0.2444\n",
      "Epoch 2187/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4153 - acc: 0.2083 - val_loss: 0.4505 - val_acc: 0.2407\n",
      "Epoch 2188/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4016 - acc: 0.2075 - val_loss: 0.4754 - val_acc: 0.2407\n",
      "Epoch 2189/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4260 - acc: 0.2075 - val_loss: 0.4504 - val_acc: 0.2407\n",
      "Epoch 2190/10000\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.4075 - acc: 0.206 - 2s 32ms/step - loss: 0.4083 - acc: 0.2079 - val_loss: 0.5728 - val_acc: 0.2407\n",
      "Epoch 2191/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4789 - acc: 0.2083 - val_loss: 0.4569 - val_acc: 0.2407\n",
      "Epoch 2192/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4174 - acc: 0.2075 - val_loss: 0.4736 - val_acc: 0.2407\n",
      "Epoch 2193/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5912 - acc: 0.2071 - val_loss: 0.7440 - val_acc: 0.2407\n",
      "Epoch 2194/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4981 - acc: 0.2079 - val_loss: 0.5066 - val_acc: 0.2407\n",
      "Epoch 2195/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4168 - acc: 0.2083 - val_loss: 0.5079 - val_acc: 0.2407\n",
      "Epoch 2196/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4249 - acc: 0.2067 - val_loss: 0.6260 - val_acc: 0.2444\n",
      "Epoch 2197/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4123 - acc: 0.2079 - val_loss: 0.4782 - val_acc: 0.2407\n",
      "Epoch 2198/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4385 - acc: 0.2067 - val_loss: 0.5555 - val_acc: 0.2444\n",
      "Epoch 2199/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4036 - acc: 0.2079 - val_loss: 0.4725 - val_acc: 0.2407\n",
      "Epoch 2200/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4287 - acc: 0.2087 - val_loss: 0.4692 - val_acc: 0.2407\n",
      "Epoch 2201/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4192 - acc: 0.2075 - val_loss: 0.4890 - val_acc: 0.2444\n",
      "Epoch 2202/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4295 - acc: 0.2075 - val_loss: 0.4956 - val_acc: 0.2444\n",
      "Epoch 2203/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4189 - acc: 0.2079 - val_loss: 0.6008 - val_acc: 0.2444\n",
      "Epoch 2204/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4923 - acc: 0.2083 - val_loss: 0.4850 - val_acc: 0.2407\n",
      "Epoch 2205/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4246 - acc: 0.2079 - val_loss: 0.5514 - val_acc: 0.2407\n",
      "Epoch 2206/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4177 - acc: 0.2083 - val_loss: 0.4793 - val_acc: 0.2444\n",
      "Epoch 2207/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4218 - acc: 0.2079 - val_loss: 0.6358 - val_acc: 0.2444\n",
      "Epoch 2208/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4143 - acc: 0.2079 - val_loss: 0.5016 - val_acc: 0.2407\n",
      "Epoch 2209/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3973 - acc: 0.2079 - val_loss: 0.4705 - val_acc: 0.2444\n",
      "Epoch 2210/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4042 - acc: 0.2075 - val_loss: 0.4683 - val_acc: 0.2444\n",
      "Epoch 2211/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4379 - acc: 0.2075 - val_loss: 0.4698 - val_acc: 0.2407\n",
      "Epoch 2212/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4769 - acc: 0.2079 - val_loss: 0.7429 - val_acc: 0.2407\n",
      "Epoch 2213/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4223 - acc: 0.2083 - val_loss: 0.4616 - val_acc: 0.2407\n",
      "Epoch 2214/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4128 - acc: 0.2075 - val_loss: 0.6407 - val_acc: 0.2407\n",
      "Epoch 2215/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4119 - acc: 0.2079 - val_loss: 0.5092 - val_acc: 0.2444\n",
      "Epoch 2216/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4206 - acc: 0.2075 - val_loss: 0.4830 - val_acc: 0.2444\n",
      "Epoch 2217/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4135 - acc: 0.2079 - val_loss: 0.4574 - val_acc: 0.2407\n",
      "Epoch 2218/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4039 - acc: 0.2079 - val_loss: 0.5243 - val_acc: 0.2444\n",
      "Epoch 2219/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4318 - acc: 0.2079 - val_loss: 0.4666 - val_acc: 0.2444\n",
      "Epoch 2220/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4135 - acc: 0.2079 - val_loss: 0.5107 - val_acc: 0.2407\n",
      "Epoch 2221/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4052 - acc: 0.2075 - val_loss: 0.4559 - val_acc: 0.2444\n",
      "Epoch 2222/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4117 - acc: 0.2079 - val_loss: 0.4644 - val_acc: 0.2407\n",
      "Epoch 2223/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4083 - acc: 0.2079 - val_loss: 0.4565 - val_acc: 0.2407\n",
      "Epoch 2224/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4102 - acc: 0.2075 - val_loss: 0.4660 - val_acc: 0.2407\n",
      "Epoch 2225/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4702 - acc: 0.2079 - val_loss: 0.7744 - val_acc: 0.2407\n",
      "Epoch 2226/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4309 - acc: 0.2075 - val_loss: 0.4650 - val_acc: 0.2407\n",
      "Epoch 2227/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3962 - acc: 0.2079 - val_loss: 0.4903 - val_acc: 0.2444\n",
      "Epoch 2228/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4285 - acc: 0.2079 - val_loss: 0.6191 - val_acc: 0.2407\n",
      "Epoch 2229/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4192 - acc: 0.2075 - val_loss: 0.5853 - val_acc: 0.2444\n",
      "Epoch 2230/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4346 - acc: 0.2079 - val_loss: 0.6191 - val_acc: 0.2407\n",
      "Epoch 2231/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4099 - acc: 0.2075 - val_loss: 0.5060 - val_acc: 0.2444\n",
      "Epoch 2232/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4458 - acc: 0.2067 - val_loss: 0.6046 - val_acc: 0.2444\n",
      "Epoch 2233/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4385 - acc: 0.2075 - val_loss: 0.4583 - val_acc: 0.2407\n",
      "Epoch 2234/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3984 - acc: 0.2079 - val_loss: 0.4606 - val_acc: 0.2407\n",
      "Epoch 2235/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4183 - acc: 0.2083 - val_loss: 0.5970 - val_acc: 0.2407\n",
      "Epoch 2236/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4171 - acc: 0.2083 - val_loss: 0.4741 - val_acc: 0.2407\n",
      "Epoch 2237/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3995 - acc: 0.2079 - val_loss: 0.4589 - val_acc: 0.2407\n",
      "Epoch 2238/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4124 - acc: 0.2083 - val_loss: 0.5227 - val_acc: 0.2444\n",
      "Epoch 2239/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4101 - acc: 0.2079 - val_loss: 0.4917 - val_acc: 0.2407\n",
      "Epoch 2240/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3980 - acc: 0.2075 - val_loss: 0.5215 - val_acc: 0.2444\n",
      "Epoch 2241/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5818 - acc: 0.2050 - val_loss: 0.9412 - val_acc: 0.2444\n",
      "Epoch 2242/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5281 - acc: 0.2071 - val_loss: 0.4879 - val_acc: 0.2444\n",
      "Epoch 2243/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4274 - acc: 0.2071 - val_loss: 0.4861 - val_acc: 0.2407\n",
      "Epoch 2244/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3904 - acc: 0.2079 - val_loss: 0.4669 - val_acc: 0.2407\n",
      "Epoch 2245/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3918 - acc: 0.2079 - val_loss: 0.4600 - val_acc: 0.2407\n",
      "Epoch 2246/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4092 - acc: 0.2071 - val_loss: 0.4726 - val_acc: 0.2407\n",
      "Epoch 2247/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4194 - acc: 0.2083 - val_loss: 0.4606 - val_acc: 0.2444\n",
      "Epoch 2248/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4247 - acc: 0.2083 - val_loss: 0.4606 - val_acc: 0.2407\n",
      "Epoch 2249/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4219 - acc: 0.2079 - val_loss: 0.4979 - val_acc: 0.2444\n",
      "Epoch 2250/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4015 - acc: 0.2079 - val_loss: 0.6517 - val_acc: 0.2444\n",
      "Epoch 2251/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4077 - acc: 0.2071 - val_loss: 0.4658 - val_acc: 0.2407\n",
      "Epoch 2252/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4125 - acc: 0.2079 - val_loss: 0.4692 - val_acc: 0.2407\n",
      "Epoch 2253/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4381 - acc: 0.2075 - val_loss: 0.4885 - val_acc: 0.2407\n",
      "Epoch 2254/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4157 - acc: 0.2079 - val_loss: 0.4549 - val_acc: 0.2407\n",
      "Epoch 2255/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4028 - acc: 0.2079 - val_loss: 0.5386 - val_acc: 0.2407\n",
      "Epoch 2256/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4285 - acc: 0.2083 - val_loss: 0.4581 - val_acc: 0.2407\n",
      "Epoch 2257/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4155 - acc: 0.2079 - val_loss: 0.4494 - val_acc: 0.2407\n",
      "Epoch 2258/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4056 - acc: 0.2075 - val_loss: 0.4896 - val_acc: 0.2444\n",
      "Epoch 2259/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4189 - acc: 0.2083 - val_loss: 0.6073 - val_acc: 0.2444\n",
      "Epoch 2260/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4077 - acc: 0.2079 - val_loss: 0.5105 - val_acc: 0.2444\n",
      "Epoch 2261/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4173 - acc: 0.2079 - val_loss: 0.4536 - val_acc: 0.2407\n",
      "Epoch 2262/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4129 - acc: 0.2067 - val_loss: 0.4646 - val_acc: 0.2407\n",
      "Epoch 2263/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4017 - acc: 0.2075 - val_loss: 0.5154 - val_acc: 0.2444\n",
      "Epoch 2264/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4166 - acc: 0.2079 - val_loss: 0.4534 - val_acc: 0.2407\n",
      "Epoch 2265/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4011 - acc: 0.2075 - val_loss: 0.4607 - val_acc: 0.2407\n",
      "Epoch 2266/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4238 - acc: 0.2079 - val_loss: 0.4567 - val_acc: 0.2407\n",
      "Epoch 2267/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4261 - acc: 0.2079 - val_loss: 0.4429 - val_acc: 0.2407\n",
      "Epoch 2268/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4227 - acc: 0.2075 - val_loss: 0.5186 - val_acc: 0.2407\n",
      "Epoch 2269/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4061 - acc: 0.2071 - val_loss: 0.4638 - val_acc: 0.2407\n",
      "Epoch 2270/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4038 - acc: 0.2079 - val_loss: 0.5169 - val_acc: 0.2407\n",
      "Epoch 2271/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4131 - acc: 0.2079 - val_loss: 0.5880 - val_acc: 0.2444\n",
      "Epoch 2272/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4287 - acc: 0.2071 - val_loss: 0.5341 - val_acc: 0.2407\n",
      "Epoch 2273/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4263 - acc: 0.2075 - val_loss: 0.4880 - val_acc: 0.2407\n",
      "Epoch 2274/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4140 - acc: 0.2079 - val_loss: 0.4646 - val_acc: 0.2407\n",
      "Epoch 2275/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4046 - acc: 0.2083 - val_loss: 0.4581 - val_acc: 0.2407\n",
      "Epoch 2276/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4100 - acc: 0.2079 - val_loss: 0.4598 - val_acc: 0.2407\n",
      "Epoch 2277/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4251 - acc: 0.2067 - val_loss: 0.6042 - val_acc: 0.2407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2278/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4194 - acc: 0.2083 - val_loss: 0.6467 - val_acc: 0.2407\n",
      "Epoch 2279/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4297 - acc: 0.2071 - val_loss: 0.4951 - val_acc: 0.2444\n",
      "Epoch 2280/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4606 - acc: 0.2071 - val_loss: 0.6983 - val_acc: 0.2407\n",
      "Epoch 2281/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4728 - acc: 0.2063 - val_loss: 0.4469 - val_acc: 0.2407\n",
      "Epoch 2282/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4046 - acc: 0.2075 - val_loss: 0.4743 - val_acc: 0.2407\n",
      "Epoch 2283/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4259 - acc: 0.2071 - val_loss: 0.4548 - val_acc: 0.2407\n",
      "Epoch 2284/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4004 - acc: 0.2079 - val_loss: 0.5224 - val_acc: 0.2444\n",
      "Epoch 2285/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3953 - acc: 0.2079 - val_loss: 0.5065 - val_acc: 0.2444\n",
      "Epoch 2286/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4562 - acc: 0.2071 - val_loss: 0.4964 - val_acc: 0.2444\n",
      "Epoch 2287/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4123 - acc: 0.2075 - val_loss: 0.5380 - val_acc: 0.2444\n",
      "Epoch 2288/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4096 - acc: 0.2079 - val_loss: 0.5430 - val_acc: 0.2407\n",
      "Epoch 2289/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4026 - acc: 0.2075 - val_loss: 0.4430 - val_acc: 0.2407\n",
      "Epoch 2290/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4411 - acc: 0.2079 - val_loss: 0.7032 - val_acc: 0.2444\n",
      "Epoch 2291/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4196 - acc: 0.2079 - val_loss: 0.4955 - val_acc: 0.2407\n",
      "Epoch 2292/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4027 - acc: 0.2079 - val_loss: 0.4703 - val_acc: 0.2407\n",
      "Epoch 2293/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4184 - acc: 0.2079 - val_loss: 0.4697 - val_acc: 0.2407\n",
      "Epoch 2294/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4039 - acc: 0.2075 - val_loss: 0.4837 - val_acc: 0.2407\n",
      "Epoch 2295/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4212 - acc: 0.2071 - val_loss: 0.4776 - val_acc: 0.2407\n",
      "Epoch 2296/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4116 - acc: 0.2083 - val_loss: 0.5061 - val_acc: 0.2444\n",
      "Epoch 2297/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4541 - acc: 0.2071 - val_loss: 0.4819 - val_acc: 0.2407\n",
      "Epoch 2298/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3967 - acc: 0.2083 - val_loss: 0.4727 - val_acc: 0.2407\n",
      "Epoch 2299/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4143 - acc: 0.2079 - val_loss: 0.6153 - val_acc: 0.2444\n",
      "Epoch 2300/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4266 - acc: 0.2075 - val_loss: 0.4772 - val_acc: 0.2407\n",
      "Epoch 2301/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4217 - acc: 0.2079 - val_loss: 0.4617 - val_acc: 0.2407\n",
      "Epoch 2302/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4167 - acc: 0.2075 - val_loss: 0.4844 - val_acc: 0.2407\n",
      "Epoch 2303/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4129 - acc: 0.2079 - val_loss: 0.4808 - val_acc: 0.2407\n",
      "Epoch 2304/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4189 - acc: 0.2087 - val_loss: 0.5479 - val_acc: 0.2444\n",
      "Epoch 2305/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4893 - acc: 0.2079 - val_loss: 0.5087 - val_acc: 0.2407\n",
      "Epoch 2306/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 1.5704 - acc: 0.1988 - val_loss: 1.6583 - val_acc: 0.2444\n",
      "Epoch 2307/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 1.0204 - acc: 0.2030 - val_loss: 0.7396 - val_acc: 0.2407\n",
      "Epoch 2308/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.6140 - acc: 0.2071 - val_loss: 0.6640 - val_acc: 0.2407\n",
      "Epoch 2309/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5315 - acc: 0.2071 - val_loss: 0.6383 - val_acc: 0.2407\n",
      "Epoch 2310/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5000 - acc: 0.2079 - val_loss: 0.6551 - val_acc: 0.2407\n",
      "Epoch 2311/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4928 - acc: 0.2079 - val_loss: 0.5705 - val_acc: 0.2444\n",
      "Epoch 2312/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4526 - acc: 0.2071 - val_loss: 0.6036 - val_acc: 0.2444\n",
      "Epoch 2313/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4355 - acc: 0.2071 - val_loss: 0.5402 - val_acc: 0.2407\n",
      "Epoch 2314/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4341 - acc: 0.2079 - val_loss: 0.5141 - val_acc: 0.2444\n",
      "Epoch 2315/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4197 - acc: 0.2075 - val_loss: 0.5025 - val_acc: 0.2444\n",
      "Epoch 2316/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4114 - acc: 0.2075 - val_loss: 0.5130 - val_acc: 0.2444\n",
      "Epoch 2317/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4052 - acc: 0.2079 - val_loss: 0.4930 - val_acc: 0.2407\n",
      "Epoch 2318/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4142 - acc: 0.2079 - val_loss: 0.4825 - val_acc: 0.2444\n",
      "Epoch 2319/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4162 - acc: 0.2071 - val_loss: 0.5279 - val_acc: 0.2444\n",
      "Epoch 2320/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4157 - acc: 0.2075 - val_loss: 0.4753 - val_acc: 0.2444\n",
      "Epoch 2321/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4225 - acc: 0.2079 - val_loss: 0.4815 - val_acc: 0.2444\n",
      "Epoch 2322/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4087 - acc: 0.2075 - val_loss: 0.4671 - val_acc: 0.2444\n",
      "Epoch 2323/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3903 - acc: 0.2079 - val_loss: 0.4698 - val_acc: 0.2444\n",
      "Epoch 2324/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4016 - acc: 0.2079 - val_loss: 0.5576 - val_acc: 0.2444\n",
      "Epoch 2325/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4008 - acc: 0.2075 - val_loss: 0.4938 - val_acc: 0.2444\n",
      "Epoch 2326/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4023 - acc: 0.2079 - val_loss: 0.4711 - val_acc: 0.2407\n",
      "Epoch 2327/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4054 - acc: 0.2079 - val_loss: 0.6393 - val_acc: 0.2407\n",
      "Epoch 2328/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4243 - acc: 0.2075 - val_loss: 0.4770 - val_acc: 0.2444\n",
      "Epoch 2329/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4614 - acc: 0.2071 - val_loss: 0.5589 - val_acc: 0.2444\n",
      "Epoch 2330/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4048 - acc: 0.2071 - val_loss: 0.4688 - val_acc: 0.2444\n",
      "Epoch 2331/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4128 - acc: 0.2079 - val_loss: 0.4642 - val_acc: 0.2444\n",
      "Epoch 2332/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3997 - acc: 0.2079 - val_loss: 0.4597 - val_acc: 0.2444\n",
      "Epoch 2333/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4100 - acc: 0.2083 - val_loss: 0.4809 - val_acc: 0.2407\n",
      "Epoch 2334/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3912 - acc: 0.2079 - val_loss: 0.4606 - val_acc: 0.2444\n",
      "Epoch 2335/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4014 - acc: 0.2067 - val_loss: 0.5467 - val_acc: 0.2444\n",
      "Epoch 2336/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3970 - acc: 0.2071 - val_loss: 0.5567 - val_acc: 0.2407\n",
      "Epoch 2337/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4284 - acc: 0.2079 - val_loss: 0.4495 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2338/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4346 - acc: 0.2083 - val_loss: 0.5942 - val_acc: 0.2407\n",
      "Epoch 2339/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4208 - acc: 0.2075 - val_loss: 0.4715 - val_acc: 0.2407\n",
      "Epoch 2340/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4447 - acc: 0.2067 - val_loss: 0.4675 - val_acc: 0.2407\n",
      "Epoch 2341/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4498 - acc: 0.2079 - val_loss: 0.4821 - val_acc: 0.2444\n",
      "Epoch 2342/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4080 - acc: 0.2083 - val_loss: 0.4756 - val_acc: 0.2407\n",
      "Epoch 2343/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4368 - acc: 0.2071 - val_loss: 0.6078 - val_acc: 0.2407\n",
      "Epoch 2344/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4283 - acc: 0.2075 - val_loss: 0.5046 - val_acc: 0.2444\n",
      "Epoch 2345/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4025 - acc: 0.2075 - val_loss: 0.4747 - val_acc: 0.2444\n",
      "Epoch 2346/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4325 - acc: 0.2083 - val_loss: 0.4810 - val_acc: 0.2407\n",
      "Epoch 2347/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4005 - acc: 0.2071 - val_loss: 0.5405 - val_acc: 0.2444\n",
      "Epoch 2348/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4155 - acc: 0.2075 - val_loss: 0.4540 - val_acc: 0.2444\n",
      "Epoch 2349/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4058 - acc: 0.2075 - val_loss: 0.4793 - val_acc: 0.2407\n",
      "Epoch 2350/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4041 - acc: 0.2075 - val_loss: 0.4928 - val_acc: 0.2444\n",
      "Epoch 2351/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4012 - acc: 0.2079 - val_loss: 0.4740 - val_acc: 0.2407\n",
      "Epoch 2352/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4344 - acc: 0.2079 - val_loss: 0.5807 - val_acc: 0.2407\n",
      "Epoch 2353/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4094 - acc: 0.2075 - val_loss: 0.4424 - val_acc: 0.2407\n",
      "Epoch 2354/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4116 - acc: 0.2079 - val_loss: 0.4621 - val_acc: 0.2407\n",
      "Epoch 2355/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4223 - acc: 0.2071 - val_loss: 0.5164 - val_acc: 0.2444\n",
      "Epoch 2356/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4205 - acc: 0.2079 - val_loss: 0.4730 - val_acc: 0.2407\n",
      "Epoch 2357/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3956 - acc: 0.2079 - val_loss: 0.5602 - val_acc: 0.2444\n",
      "Epoch 2358/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4030 - acc: 0.2075 - val_loss: 0.4530 - val_acc: 0.2407\n",
      "Epoch 2359/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4070 - acc: 0.2075 - val_loss: 0.4809 - val_acc: 0.2407\n",
      "Epoch 2360/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3967 - acc: 0.2075 - val_loss: 0.4467 - val_acc: 0.2407\n",
      "Epoch 2361/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4175 - acc: 0.2067 - val_loss: 0.4623 - val_acc: 0.2444\n",
      "Epoch 2362/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4481 - acc: 0.2087 - val_loss: 0.5218 - val_acc: 0.2407\n",
      "Epoch 2363/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4159 - acc: 0.2083 - val_loss: 0.4546 - val_acc: 0.2407\n",
      "Epoch 2364/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4351 - acc: 0.2067 - val_loss: 0.4690 - val_acc: 0.2407\n",
      "Epoch 2365/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4447 - acc: 0.2071 - val_loss: 0.4504 - val_acc: 0.2407\n",
      "Epoch 2366/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4056 - acc: 0.2071 - val_loss: 0.4786 - val_acc: 0.2444\n",
      "Epoch 2367/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4171 - acc: 0.2075 - val_loss: 0.4716 - val_acc: 0.2407\n",
      "Epoch 2368/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3968 - acc: 0.2071 - val_loss: 0.4434 - val_acc: 0.2444\n",
      "Epoch 2369/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4156 - acc: 0.2075 - val_loss: 0.4743 - val_acc: 0.2444\n",
      "Epoch 2370/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4359 - acc: 0.2083 - val_loss: 0.5327 - val_acc: 0.2407\n",
      "Epoch 2371/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4423 - acc: 0.2079 - val_loss: 0.5775 - val_acc: 0.2407\n",
      "Epoch 2372/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4394 - acc: 0.2075 - val_loss: 0.7707 - val_acc: 0.2407\n",
      "Epoch 2373/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4387 - acc: 0.2075 - val_loss: 0.4687 - val_acc: 0.2444\n",
      "Epoch 2374/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4323 - acc: 0.2075 - val_loss: 0.4774 - val_acc: 0.2444\n",
      "Epoch 2375/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4016 - acc: 0.2075 - val_loss: 0.4999 - val_acc: 0.2444\n",
      "Epoch 2376/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4013 - acc: 0.2075 - val_loss: 0.4584 - val_acc: 0.2444\n",
      "Epoch 2377/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4240 - acc: 0.2079 - val_loss: 0.4925 - val_acc: 0.2407\n",
      "Epoch 2378/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4026 - acc: 0.2079 - val_loss: 0.4925 - val_acc: 0.2444\n",
      "Epoch 2379/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4194 - acc: 0.2071 - val_loss: 0.4732 - val_acc: 0.2444\n",
      "Epoch 2380/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4204 - acc: 0.2079 - val_loss: 0.4797 - val_acc: 0.2407\n",
      "Epoch 2381/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4359 - acc: 0.2079 - val_loss: 0.5224 - val_acc: 0.2407\n",
      "Epoch 2382/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4095 - acc: 0.2083 - val_loss: 0.5444 - val_acc: 0.2444\n",
      "Epoch 2383/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4804 - acc: 0.2075 - val_loss: 0.4501 - val_acc: 0.2407\n",
      "Epoch 2384/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4394 - acc: 0.2079 - val_loss: 0.5840 - val_acc: 0.2407\n",
      "Epoch 2385/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4198 - acc: 0.2079 - val_loss: 0.4503 - val_acc: 0.2407\n",
      "Epoch 2386/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4067 - acc: 0.2083 - val_loss: 0.6457 - val_acc: 0.2444\n",
      "Epoch 2387/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4402 - acc: 0.2075 - val_loss: 0.4551 - val_acc: 0.2444\n",
      "Epoch 2388/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4828 - acc: 0.2079 - val_loss: 0.5038 - val_acc: 0.2444\n",
      "Epoch 2389/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4257 - acc: 0.2067 - val_loss: 0.4801 - val_acc: 0.2444\n",
      "Epoch 2390/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3963 - acc: 0.2075 - val_loss: 0.5113 - val_acc: 0.2407\n",
      "Epoch 2391/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4873 - acc: 0.2079 - val_loss: 0.6208 - val_acc: 0.2407\n",
      "Epoch 2392/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4941 - acc: 0.2079 - val_loss: 0.5154 - val_acc: 0.2444\n",
      "Epoch 2393/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4108 - acc: 0.2075 - val_loss: 0.4633 - val_acc: 0.2444\n",
      "Epoch 2394/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4144 - acc: 0.2075 - val_loss: 0.4559 - val_acc: 0.2407\n",
      "Epoch 2395/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4134 - acc: 0.2079 - val_loss: 0.4719 - val_acc: 0.2444\n",
      "Epoch 2396/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3901 - acc: 0.2075 - val_loss: 0.4574 - val_acc: 0.2444\n",
      "Epoch 2397/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4107 - acc: 0.2075 - val_loss: 0.4756 - val_acc: 0.2407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2398/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4048 - acc: 0.2079 - val_loss: 0.4652 - val_acc: 0.2444\n",
      "Epoch 2399/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4182 - acc: 0.2083 - val_loss: 0.4532 - val_acc: 0.2407\n",
      "Epoch 2400/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4097 - acc: 0.2075 - val_loss: 0.4720 - val_acc: 0.2444\n",
      "Epoch 2401/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4058 - acc: 0.2083 - val_loss: 0.4989 - val_acc: 0.2444\n",
      "Epoch 2402/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4173 - acc: 0.2071 - val_loss: 0.4630 - val_acc: 0.2444\n",
      "Epoch 2403/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4388 - acc: 0.2079 - val_loss: 0.5038 - val_acc: 0.2407\n",
      "Epoch 2404/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4499 - acc: 0.2067 - val_loss: 0.4543 - val_acc: 0.2444\n",
      "Epoch 2405/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4229 - acc: 0.2079 - val_loss: 0.4604 - val_acc: 0.2444\n",
      "Epoch 2406/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4216 - acc: 0.2075 - val_loss: 0.4959 - val_acc: 0.2444\n",
      "Epoch 2407/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4139 - acc: 0.2079 - val_loss: 0.4573 - val_acc: 0.2444\n",
      "Epoch 2408/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4694 - acc: 0.2071 - val_loss: 0.5204 - val_acc: 0.2407\n",
      "Epoch 2409/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4194 - acc: 0.2079 - val_loss: 0.4515 - val_acc: 0.2407\n",
      "Epoch 2410/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4021 - acc: 0.2079 - val_loss: 0.4621 - val_acc: 0.2407\n",
      "Epoch 2411/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3945 - acc: 0.2083 - val_loss: 0.5050 - val_acc: 0.2407\n",
      "Epoch 2412/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4235 - acc: 0.2075 - val_loss: 0.4928 - val_acc: 0.2407\n",
      "Epoch 2413/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4324 - acc: 0.2075 - val_loss: 0.6118 - val_acc: 0.2407\n",
      "Epoch 2414/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4206 - acc: 0.2075 - val_loss: 0.4534 - val_acc: 0.2444\n",
      "Epoch 2415/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4829 - acc: 0.2079 - val_loss: 0.5913 - val_acc: 0.2407\n",
      "Epoch 2416/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4627 - acc: 0.2075 - val_loss: 0.5234 - val_acc: 0.2407\n",
      "Epoch 2417/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4453 - acc: 0.2079 - val_loss: 0.4891 - val_acc: 0.2444\n",
      "Epoch 2418/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4170 - acc: 0.2079 - val_loss: 0.5350 - val_acc: 0.2407\n",
      "Epoch 2419/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4152 - acc: 0.2079 - val_loss: 0.4622 - val_acc: 0.2444\n",
      "Epoch 2420/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4035 - acc: 0.2075 - val_loss: 0.4883 - val_acc: 0.2444\n",
      "Epoch 2421/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4417 - acc: 0.2071 - val_loss: 0.4480 - val_acc: 0.2407\n",
      "Epoch 2422/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4212 - acc: 0.2075 - val_loss: 0.4638 - val_acc: 0.2444\n",
      "Epoch 2423/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3999 - acc: 0.2083 - val_loss: 0.4828 - val_acc: 0.2407\n",
      "Epoch 2424/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3913 - acc: 0.2079 - val_loss: 0.4762 - val_acc: 0.2407\n",
      "Epoch 2425/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3995 - acc: 0.2071 - val_loss: 0.5097 - val_acc: 0.2407\n",
      "Epoch 2426/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4175 - acc: 0.2079 - val_loss: 0.4789 - val_acc: 0.2444\n",
      "Epoch 2427/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4154 - acc: 0.2083 - val_loss: 0.5060 - val_acc: 0.2407\n",
      "Epoch 2428/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4024 - acc: 0.2079 - val_loss: 0.4592 - val_acc: 0.2407\n",
      "Epoch 2429/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4196 - acc: 0.2067 - val_loss: 0.4845 - val_acc: 0.2444\n",
      "Epoch 2430/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.7822 - acc: 0.2075 - val_loss: 0.8960 - val_acc: 0.2407\n",
      "Epoch 2431/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.7511 - acc: 0.2087 - val_loss: 0.7064 - val_acc: 0.2407\n",
      "Epoch 2432/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5600 - acc: 0.2079 - val_loss: 0.6820 - val_acc: 0.2444\n",
      "Epoch 2433/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5044 - acc: 0.2079 - val_loss: 0.6571 - val_acc: 0.2444\n",
      "Epoch 2434/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4849 - acc: 0.2075 - val_loss: 0.5611 - val_acc: 0.2407\n",
      "Epoch 2435/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4398 - acc: 0.2083 - val_loss: 0.5154 - val_acc: 0.2407\n",
      "Epoch 2436/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4553 - acc: 0.2071 - val_loss: 0.4902 - val_acc: 0.2407\n",
      "Epoch 2437/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4252 - acc: 0.2079 - val_loss: 0.5050 - val_acc: 0.2444\n",
      "Epoch 2438/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4109 - acc: 0.2075 - val_loss: 0.4836 - val_acc: 0.2407\n",
      "Epoch 2439/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4347 - acc: 0.2079 - val_loss: 0.4834 - val_acc: 0.2444\n",
      "Epoch 2440/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4068 - acc: 0.2079 - val_loss: 0.4864 - val_acc: 0.2444\n",
      "Epoch 2441/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4252 - acc: 0.2075 - val_loss: 0.4863 - val_acc: 0.2444\n",
      "Epoch 2442/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4060 - acc: 0.2087 - val_loss: 0.4911 - val_acc: 0.2444\n",
      "Epoch 2443/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4255 - acc: 0.2075 - val_loss: 0.4664 - val_acc: 0.2407\n",
      "Epoch 2444/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4317 - acc: 0.2079 - val_loss: 0.7486 - val_acc: 0.2444\n",
      "Epoch 2445/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4408 - acc: 0.2075 - val_loss: 0.4627 - val_acc: 0.2444\n",
      "Epoch 2446/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4003 - acc: 0.2083 - val_loss: 0.4576 - val_acc: 0.2444\n",
      "Epoch 2447/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4544 - acc: 0.2075 - val_loss: 0.4717 - val_acc: 0.2444\n",
      "Epoch 2448/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4270 - acc: 0.2075 - val_loss: 0.5011 - val_acc: 0.2444\n",
      "Epoch 2449/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4748 - acc: 0.2083 - val_loss: 0.4896 - val_acc: 0.2407\n",
      "Epoch 2450/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3895 - acc: 0.2079 - val_loss: 0.4715 - val_acc: 0.2444\n",
      "Epoch 2451/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4178 - acc: 0.2075 - val_loss: 0.4597 - val_acc: 0.2407\n",
      "Epoch 2452/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4012 - acc: 0.2079 - val_loss: 0.4641 - val_acc: 0.2444\n",
      "Epoch 2453/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4243 - acc: 0.2083 - val_loss: 0.4800 - val_acc: 0.2407\n",
      "Epoch 2454/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3930 - acc: 0.2075 - val_loss: 0.4542 - val_acc: 0.2407\n",
      "Epoch 2455/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3985 - acc: 0.2075 - val_loss: 0.4525 - val_acc: 0.2444\n",
      "Epoch 2456/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3969 - acc: 0.2075 - val_loss: 0.4649 - val_acc: 0.2407\n",
      "Epoch 2457/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4120 - acc: 0.2083 - val_loss: 0.6556 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2458/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3986 - acc: 0.2083 - val_loss: 0.5029 - val_acc: 0.2407\n",
      "Epoch 2459/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.4242 - acc: 0.2083 - val_loss: 0.4740 - val_acc: 0.2444\n",
      "Epoch 2460/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4037 - acc: 0.2075 - val_loss: 0.4943 - val_acc: 0.2407\n",
      "Epoch 2461/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4055 - acc: 0.2075 - val_loss: 0.4838 - val_acc: 0.2407\n",
      "Epoch 2462/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4249 - acc: 0.2087 - val_loss: 0.4686 - val_acc: 0.2444\n",
      "Epoch 2463/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4124 - acc: 0.2075 - val_loss: 0.4604 - val_acc: 0.2444\n",
      "Epoch 2464/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4030 - acc: 0.2075 - val_loss: 0.4704 - val_acc: 0.2407\n",
      "Epoch 2465/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3906 - acc: 0.2079 - val_loss: 0.4807 - val_acc: 0.2407\n",
      "Epoch 2466/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4005 - acc: 0.2071 - val_loss: 0.4612 - val_acc: 0.2444\n",
      "Epoch 2467/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4094 - acc: 0.2083 - val_loss: 0.4458 - val_acc: 0.2444\n",
      "Epoch 2468/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4031 - acc: 0.2079 - val_loss: 0.4659 - val_acc: 0.2444\n",
      "Epoch 2469/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4024 - acc: 0.2083 - val_loss: 0.5314 - val_acc: 0.2407\n",
      "Epoch 2470/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4059 - acc: 0.2079 - val_loss: 0.4793 - val_acc: 0.2407\n",
      "Epoch 2471/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4004 - acc: 0.2083 - val_loss: 0.4770 - val_acc: 0.2444\n",
      "Epoch 2472/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4055 - acc: 0.2075 - val_loss: 0.4654 - val_acc: 0.2407\n",
      "Epoch 2473/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4504 - acc: 0.2071 - val_loss: 0.4421 - val_acc: 0.2407\n",
      "Epoch 2474/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4101 - acc: 0.2079 - val_loss: 0.4514 - val_acc: 0.2407\n",
      "Epoch 2475/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4305 - acc: 0.2079 - val_loss: 0.5219 - val_acc: 0.2407\n",
      "Epoch 2476/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4079 - acc: 0.2079 - val_loss: 0.4471 - val_acc: 0.2407\n",
      "Epoch 2477/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4201 - acc: 0.2079 - val_loss: 0.4790 - val_acc: 0.2407\n",
      "Epoch 2478/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4158 - acc: 0.2075 - val_loss: 0.5597 - val_acc: 0.2444\n",
      "Epoch 2479/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4499 - acc: 0.2063 - val_loss: 0.4845 - val_acc: 0.2407\n",
      "Epoch 2480/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3992 - acc: 0.2071 - val_loss: 0.4620 - val_acc: 0.2444\n",
      "Epoch 2481/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4063 - acc: 0.2079 - val_loss: 0.4599 - val_acc: 0.2444\n",
      "Epoch 2482/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3961 - acc: 0.2075 - val_loss: 0.5396 - val_acc: 0.2444\n",
      "Epoch 2483/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4151 - acc: 0.2079 - val_loss: 0.4925 - val_acc: 0.2444\n",
      "Epoch 2484/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4181 - acc: 0.2079 - val_loss: 0.4923 - val_acc: 0.2444\n",
      "Epoch 2485/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3977 - acc: 0.2083 - val_loss: 0.4609 - val_acc: 0.2444\n",
      "Epoch 2486/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4831 - acc: 0.2067 - val_loss: 0.4763 - val_acc: 0.2444\n",
      "Epoch 2487/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4038 - acc: 0.2075 - val_loss: 0.4865 - val_acc: 0.2444\n",
      "Epoch 2488/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3978 - acc: 0.2075 - val_loss: 0.4504 - val_acc: 0.2444\n",
      "Epoch 2489/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4056 - acc: 0.2079 - val_loss: 0.5682 - val_acc: 0.2444\n",
      "Epoch 2490/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4211 - acc: 0.2075 - val_loss: 0.4902 - val_acc: 0.2444\n",
      "Epoch 2491/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4312 - acc: 0.2071 - val_loss: 0.4486 - val_acc: 0.2407\n",
      "Epoch 2492/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4197 - acc: 0.2075 - val_loss: 0.5896 - val_acc: 0.2444\n",
      "Epoch 2493/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4305 - acc: 0.2079 - val_loss: 0.4699 - val_acc: 0.2444\n",
      "Epoch 2494/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4155 - acc: 0.2079 - val_loss: 0.4717 - val_acc: 0.2407\n",
      "Epoch 2495/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4104 - acc: 0.2079 - val_loss: 0.4679 - val_acc: 0.2407\n",
      "Epoch 2496/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3988 - acc: 0.2079 - val_loss: 0.6100 - val_acc: 0.2407\n",
      "Epoch 2497/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4092 - acc: 0.2083 - val_loss: 0.4757 - val_acc: 0.2407\n",
      "Epoch 2498/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4027 - acc: 0.2083 - val_loss: 0.4632 - val_acc: 0.2407\n",
      "Epoch 2499/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4154 - acc: 0.2071 - val_loss: 0.4441 - val_acc: 0.2407\n",
      "Epoch 2500/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4171 - acc: 0.2075 - val_loss: 0.5480 - val_acc: 0.2444\n",
      "Epoch 2501/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3952 - acc: 0.2071 - val_loss: 0.4874 - val_acc: 0.2444\n",
      "Epoch 2502/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3894 - acc: 0.2079 - val_loss: 0.5049 - val_acc: 0.2407\n",
      "Epoch 2503/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4087 - acc: 0.2083 - val_loss: 0.4566 - val_acc: 0.2444\n",
      "Epoch 2504/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3989 - acc: 0.2079 - val_loss: 0.4715 - val_acc: 0.2444\n",
      "Epoch 2505/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4283 - acc: 0.2079 - val_loss: 0.6414 - val_acc: 0.2444\n",
      "Epoch 2506/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4159 - acc: 0.2079 - val_loss: 0.4451 - val_acc: 0.2407\n",
      "Epoch 2507/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4154 - acc: 0.2079 - val_loss: 0.4555 - val_acc: 0.2407\n",
      "Epoch 2508/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4040 - acc: 0.2075 - val_loss: 0.4528 - val_acc: 0.2407\n",
      "Epoch 2509/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4031 - acc: 0.2075 - val_loss: 0.4525 - val_acc: 0.2407\n",
      "Epoch 2510/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4264 - acc: 0.2083 - val_loss: 0.5618 - val_acc: 0.2444\n",
      "Epoch 2511/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4217 - acc: 0.2083 - val_loss: 0.4780 - val_acc: 0.2407\n",
      "Epoch 2512/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3921 - acc: 0.2079 - val_loss: 0.4621 - val_acc: 0.2407\n",
      "Epoch 2513/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4274 - acc: 0.2083 - val_loss: 0.4625 - val_acc: 0.2407\n",
      "Epoch 2514/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3960 - acc: 0.2079 - val_loss: 0.4659 - val_acc: 0.2407\n",
      "Epoch 2515/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4034 - acc: 0.2083 - val_loss: 0.4572 - val_acc: 0.2407\n",
      "Epoch 2516/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4094 - acc: 0.2083 - val_loss: 0.4522 - val_acc: 0.2407\n",
      "Epoch 2517/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3940 - acc: 0.2079 - val_loss: 0.4979 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2518/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3967 - acc: 0.2075 - val_loss: 0.4412 - val_acc: 0.2407\n",
      "Epoch 2519/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4303 - acc: 0.2079 - val_loss: 0.4800 - val_acc: 0.2407\n",
      "Epoch 2520/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3976 - acc: 0.2075 - val_loss: 0.5506 - val_acc: 0.2444\n",
      "Epoch 2521/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4211 - acc: 0.2079 - val_loss: 0.4829 - val_acc: 0.2407\n",
      "Epoch 2522/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4259 - acc: 0.2075 - val_loss: 0.5728 - val_acc: 0.2407\n",
      "Epoch 2523/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4650 - acc: 0.2083 - val_loss: 0.5442 - val_acc: 0.2407\n",
      "Epoch 2524/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4207 - acc: 0.2079 - val_loss: 0.4657 - val_acc: 0.2444\n",
      "Epoch 2525/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4281 - acc: 0.2079 - val_loss: 0.5019 - val_acc: 0.2444\n",
      "Epoch 2526/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3980 - acc: 0.2079 - val_loss: 0.4547 - val_acc: 0.2407\n",
      "Epoch 2527/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4131 - acc: 0.2071 - val_loss: 0.4704 - val_acc: 0.2444\n",
      "Epoch 2528/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3986 - acc: 0.2079 - val_loss: 0.4780 - val_acc: 0.2444\n",
      "Epoch 2529/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4067 - acc: 0.2075 - val_loss: 0.4703 - val_acc: 0.2407\n",
      "Epoch 2530/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3993 - acc: 0.2075 - val_loss: 0.4462 - val_acc: 0.2407\n",
      "Epoch 2531/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4318 - acc: 0.2067 - val_loss: 0.4683 - val_acc: 0.2444\n",
      "Epoch 2532/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4023 - acc: 0.2075 - val_loss: 0.4514 - val_acc: 0.2444\n",
      "Epoch 2533/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3979 - acc: 0.2079 - val_loss: 0.4688 - val_acc: 0.2407\n",
      "Epoch 2534/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4307 - acc: 0.2083 - val_loss: 0.4619 - val_acc: 0.2444\n",
      "Epoch 2535/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4132 - acc: 0.2079 - val_loss: 0.4716 - val_acc: 0.2444\n",
      "Epoch 2536/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4015 - acc: 0.2075 - val_loss: 0.6525 - val_acc: 0.2407\n",
      "Epoch 2537/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 3.8610 - acc: 0.1955 - val_loss: 0.9593 - val_acc: 0.2407\n",
      "Epoch 2538/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.8075 - acc: 0.2067 - val_loss: 0.7560 - val_acc: 0.2444\n",
      "Epoch 2539/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.6428 - acc: 0.2075 - val_loss: 0.7300 - val_acc: 0.2444\n",
      "Epoch 2540/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5963 - acc: 0.2075 - val_loss: 0.6607 - val_acc: 0.2407\n",
      "Epoch 2541/10000\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.5262 - acc: 0.207 - 2s 32ms/step - loss: 0.5262 - acc: 0.2087 - val_loss: 0.6251 - val_acc: 0.2407\n",
      "Epoch 2542/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5036 - acc: 0.2083 - val_loss: 0.6180 - val_acc: 0.2444\n",
      "Epoch 2543/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4599 - acc: 0.2083 - val_loss: 0.5997 - val_acc: 0.2444\n",
      "Epoch 2544/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4830 - acc: 0.2075 - val_loss: 0.5615 - val_acc: 0.2444\n",
      "Epoch 2545/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4480 - acc: 0.2071 - val_loss: 0.5464 - val_acc: 0.2444\n",
      "Epoch 2546/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4216 - acc: 0.2075 - val_loss: 0.5270 - val_acc: 0.2444\n",
      "Epoch 2547/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4057 - acc: 0.2075 - val_loss: 0.5004 - val_acc: 0.2444\n",
      "Epoch 2548/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4037 - acc: 0.2075 - val_loss: 0.5018 - val_acc: 0.2444\n",
      "Epoch 2549/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4024 - acc: 0.2075 - val_loss: 0.5155 - val_acc: 0.2444\n",
      "Epoch 2550/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4183 - acc: 0.2075 - val_loss: 0.4747 - val_acc: 0.2444\n",
      "Epoch 2551/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3987 - acc: 0.2075 - val_loss: 0.5007 - val_acc: 0.2444\n",
      "Epoch 2552/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3996 - acc: 0.2075 - val_loss: 0.4761 - val_acc: 0.2444\n",
      "Epoch 2553/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4034 - acc: 0.2083 - val_loss: 0.5184 - val_acc: 0.2407\n",
      "Epoch 2554/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4224 - acc: 0.2083 - val_loss: 0.4633 - val_acc: 0.2444\n",
      "Epoch 2555/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4040 - acc: 0.2071 - val_loss: 0.4796 - val_acc: 0.2407\n",
      "Epoch 2556/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4369 - acc: 0.2075 - val_loss: 0.5161 - val_acc: 0.2444\n",
      "Epoch 2557/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4517 - acc: 0.2079 - val_loss: 0.5011 - val_acc: 0.2444\n",
      "Epoch 2558/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4103 - acc: 0.2075 - val_loss: 0.4641 - val_acc: 0.2444\n",
      "Epoch 2559/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3916 - acc: 0.2075 - val_loss: 0.4645 - val_acc: 0.2407\n",
      "Epoch 2560/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4117 - acc: 0.2075 - val_loss: 0.4585 - val_acc: 0.2444\n",
      "Epoch 2561/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3920 - acc: 0.2075 - val_loss: 0.4787 - val_acc: 0.2444\n",
      "Epoch 2562/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4042 - acc: 0.2075 - val_loss: 0.5151 - val_acc: 0.2407\n",
      "Epoch 2563/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4082 - acc: 0.2075 - val_loss: 0.4694 - val_acc: 0.2444\n",
      "Epoch 2564/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3929 - acc: 0.2079 - val_loss: 0.4624 - val_acc: 0.2444\n",
      "Epoch 2565/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4119 - acc: 0.2079 - val_loss: 0.4573 - val_acc: 0.2444\n",
      "Epoch 2566/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3887 - acc: 0.2083 - val_loss: 0.5296 - val_acc: 0.2444\n",
      "Epoch 2567/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4027 - acc: 0.2087 - val_loss: 0.4480 - val_acc: 0.2444\n",
      "Epoch 2568/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4085 - acc: 0.2071 - val_loss: 0.6514 - val_acc: 0.2444\n",
      "Epoch 2569/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4141 - acc: 0.2079 - val_loss: 0.4675 - val_acc: 0.2444\n",
      "Epoch 2570/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4176 - acc: 0.2079 - val_loss: 0.5658 - val_acc: 0.2407\n",
      "Epoch 2571/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4123 - acc: 0.2075 - val_loss: 0.4972 - val_acc: 0.2444\n",
      "Epoch 2572/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4069 - acc: 0.2079 - val_loss: 0.4733 - val_acc: 0.2407\n",
      "Epoch 2573/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4069 - acc: 0.2087 - val_loss: 0.5020 - val_acc: 0.2444\n",
      "Epoch 2574/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4036 - acc: 0.2079 - val_loss: 0.4655 - val_acc: 0.2444\n",
      "Epoch 2575/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4009 - acc: 0.2075 - val_loss: 0.4641 - val_acc: 0.2444\n",
      "Epoch 2576/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3973 - acc: 0.2083 - val_loss: 0.4646 - val_acc: 0.2444\n",
      "Epoch 2577/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4024 - acc: 0.2079 - val_loss: 0.4709 - val_acc: 0.2407\n",
      "Epoch 2578/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4044 - acc: 0.2075 - val_loss: 0.5140 - val_acc: 0.2444\n",
      "Epoch 2579/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4134 - acc: 0.2075 - val_loss: 0.4726 - val_acc: 0.2444\n",
      "Epoch 2580/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4117 - acc: 0.2075 - val_loss: 0.5267 - val_acc: 0.2407\n",
      "Epoch 2581/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4089 - acc: 0.2079 - val_loss: 0.5296 - val_acc: 0.2444\n",
      "Epoch 2582/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3961 - acc: 0.2079 - val_loss: 0.5957 - val_acc: 0.2444\n",
      "Epoch 2583/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4424 - acc: 0.2079 - val_loss: 0.4671 - val_acc: 0.2407\n",
      "Epoch 2584/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4274 - acc: 0.2075 - val_loss: 0.4761 - val_acc: 0.2444\n",
      "Epoch 2585/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4333 - acc: 0.2075 - val_loss: 0.5041 - val_acc: 0.2407\n",
      "Epoch 2586/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4068 - acc: 0.2071 - val_loss: 0.7155 - val_acc: 0.2407\n",
      "Epoch 2587/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4492 - acc: 0.2071 - val_loss: 0.4555 - val_acc: 0.2444\n",
      "Epoch 2588/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3854 - acc: 0.2075 - val_loss: 0.4708 - val_acc: 0.2444\n",
      "Epoch 2589/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4023 - acc: 0.2067 - val_loss: 0.5741 - val_acc: 0.2407\n",
      "Epoch 2590/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4199 - acc: 0.2087 - val_loss: 0.4732 - val_acc: 0.2444\n",
      "Epoch 2591/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.4178 - acc: 0.2071 - val_loss: 0.6920 - val_acc: 0.2444\n",
      "Epoch 2592/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4288 - acc: 0.2071 - val_loss: 0.4638 - val_acc: 0.2407\n",
      "Epoch 2593/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3952 - acc: 0.2075 - val_loss: 0.5504 - val_acc: 0.2444\n",
      "Epoch 2594/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4020 - acc: 0.2079 - val_loss: 0.4569 - val_acc: 0.2407\n",
      "Epoch 2595/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3997 - acc: 0.2071 - val_loss: 0.4449 - val_acc: 0.2444\n",
      "Epoch 2596/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3957 - acc: 0.2075 - val_loss: 0.5162 - val_acc: 0.2407\n",
      "Epoch 2597/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4072 - acc: 0.2079 - val_loss: 0.4988 - val_acc: 0.2407\n",
      "Epoch 2598/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4142 - acc: 0.2075 - val_loss: 0.5124 - val_acc: 0.2407\n",
      "Epoch 2599/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4305 - acc: 0.2075 - val_loss: 0.4612 - val_acc: 0.2444\n",
      "Epoch 2600/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4055 - acc: 0.2071 - val_loss: 0.4566 - val_acc: 0.2444\n",
      "Epoch 2601/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4166 - acc: 0.2075 - val_loss: 0.4706 - val_acc: 0.2407\n",
      "Epoch 2602/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4136 - acc: 0.2075 - val_loss: 0.5383 - val_acc: 0.2407\n",
      "Epoch 2603/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3935 - acc: 0.2075 - val_loss: 0.5165 - val_acc: 0.2407\n",
      "Epoch 2604/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4118 - acc: 0.2067 - val_loss: 0.5137 - val_acc: 0.2444\n",
      "Epoch 2605/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4454 - acc: 0.2079 - val_loss: 0.5002 - val_acc: 0.2407\n",
      "Epoch 2606/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4003 - acc: 0.2083 - val_loss: 0.4968 - val_acc: 0.2407\n",
      "Epoch 2607/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4024 - acc: 0.2079 - val_loss: 0.4742 - val_acc: 0.2444\n",
      "Epoch 2608/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4103 - acc: 0.2071 - val_loss: 0.5683 - val_acc: 0.2407\n",
      "Epoch 2609/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3989 - acc: 0.2071 - val_loss: 0.4627 - val_acc: 0.2407\n",
      "Epoch 2610/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3967 - acc: 0.2083 - val_loss: 0.4691 - val_acc: 0.2444\n",
      "Epoch 2611/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4004 - acc: 0.2079 - val_loss: 0.4526 - val_acc: 0.2407\n",
      "Epoch 2612/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4163 - acc: 0.2075 - val_loss: 0.4659 - val_acc: 0.2407\n",
      "Epoch 2613/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4308 - acc: 0.2079 - val_loss: 0.4801 - val_acc: 0.2407\n",
      "Epoch 2614/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4381 - acc: 0.2075 - val_loss: 0.4875 - val_acc: 0.2407\n",
      "Epoch 2615/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4097 - acc: 0.2083 - val_loss: 0.4665 - val_acc: 0.2407\n",
      "Epoch 2616/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4150 - acc: 0.2071 - val_loss: 0.4561 - val_acc: 0.2444\n",
      "Epoch 2617/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3919 - acc: 0.2079 - val_loss: 0.4679 - val_acc: 0.2407\n",
      "Epoch 2618/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.3992 - acc: 0.2075 - val_loss: 0.4473 - val_acc: 0.2444\n",
      "Epoch 2619/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4151 - acc: 0.2071 - val_loss: 0.4496 - val_acc: 0.2444\n",
      "Epoch 2620/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4070 - acc: 0.2075 - val_loss: 0.4651 - val_acc: 0.2407\n",
      "Epoch 2621/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4115 - acc: 0.2083 - val_loss: 0.4395 - val_acc: 0.2444\n",
      "Epoch 2622/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4187 - acc: 0.2075 - val_loss: 0.4439 - val_acc: 0.2444\n",
      "Epoch 2623/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3959 - acc: 0.2087 - val_loss: 0.4526 - val_acc: 0.2407\n",
      "Epoch 2624/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4152 - acc: 0.2079 - val_loss: 0.9067 - val_acc: 0.2444\n",
      "Epoch 2625/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.5359 - acc: 0.2067 - val_loss: 0.5610 - val_acc: 0.2407\n",
      "Epoch 2626/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4398 - acc: 0.2079 - val_loss: 0.4755 - val_acc: 0.2407\n",
      "Epoch 2627/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4145 - acc: 0.2075 - val_loss: 0.5895 - val_acc: 0.2444\n",
      "Epoch 2628/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4137 - acc: 0.2075 - val_loss: 0.4636 - val_acc: 0.2407\n",
      "Epoch 2629/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4245 - acc: 0.2075 - val_loss: 0.7097 - val_acc: 0.2407\n",
      "Epoch 2630/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4233 - acc: 0.2083 - val_loss: 0.4820 - val_acc: 0.2407\n",
      "Epoch 2631/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4145 - acc: 0.2083 - val_loss: 0.4578 - val_acc: 0.2444\n",
      "Epoch 2632/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3923 - acc: 0.2075 - val_loss: 0.4600 - val_acc: 0.2407\n",
      "Epoch 2633/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4000 - acc: 0.2075 - val_loss: 0.4807 - val_acc: 0.2407\n",
      "Epoch 2634/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4476 - acc: 0.2079 - val_loss: 0.4633 - val_acc: 0.2407\n",
      "Epoch 2635/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4106 - acc: 0.2075 - val_loss: 0.5235 - val_acc: 0.2444\n",
      "Epoch 2636/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 1.2480 - acc: 0.2026 - val_loss: 0.7009 - val_acc: 0.2407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2637/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5663 - acc: 0.2067 - val_loss: 0.7950 - val_acc: 0.2444\n",
      "Epoch 2638/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5010 - acc: 0.2067 - val_loss: 0.5846 - val_acc: 0.2407\n",
      "Epoch 2639/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4831 - acc: 0.2083 - val_loss: 0.5674 - val_acc: 0.2444\n",
      "Epoch 2640/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4411 - acc: 0.2083 - val_loss: 0.6131 - val_acc: 0.2407\n",
      "Epoch 2641/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4391 - acc: 0.2079 - val_loss: 0.5122 - val_acc: 0.2444\n",
      "Epoch 2642/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4275 - acc: 0.2075 - val_loss: 0.5529 - val_acc: 0.2407\n",
      "Epoch 2643/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4114 - acc: 0.2079 - val_loss: 0.5263 - val_acc: 0.2444\n",
      "Epoch 2644/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4144 - acc: 0.2083 - val_loss: 0.5198 - val_acc: 0.2407\n",
      "Epoch 2645/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4369 - acc: 0.2083 - val_loss: 0.4853 - val_acc: 0.2444\n",
      "Epoch 2646/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4420 - acc: 0.2075 - val_loss: 0.4891 - val_acc: 0.2407\n",
      "Epoch 2647/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4224 - acc: 0.2067 - val_loss: 0.5049 - val_acc: 0.2407\n",
      "Epoch 2648/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3996 - acc: 0.2083 - val_loss: 0.4656 - val_acc: 0.2444\n",
      "Epoch 2649/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3919 - acc: 0.2075 - val_loss: 0.4680 - val_acc: 0.2444\n",
      "Epoch 2650/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3853 - acc: 0.2071 - val_loss: 0.5275 - val_acc: 0.2444\n",
      "Epoch 2651/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4186 - acc: 0.2087 - val_loss: 0.5290 - val_acc: 0.2407\n",
      "Epoch 2652/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3977 - acc: 0.2075 - val_loss: 0.4603 - val_acc: 0.2444\n",
      "Epoch 2653/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3831 - acc: 0.2075 - val_loss: 0.4610 - val_acc: 0.2444\n",
      "Epoch 2654/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4062 - acc: 0.2075 - val_loss: 0.4923 - val_acc: 0.2444\n",
      "Epoch 2655/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4068 - acc: 0.2071 - val_loss: 0.4573 - val_acc: 0.2444\n",
      "Epoch 2656/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4065 - acc: 0.2079 - val_loss: 0.4596 - val_acc: 0.2444\n",
      "Epoch 2657/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3963 - acc: 0.2079 - val_loss: 0.4595 - val_acc: 0.2444\n",
      "Epoch 2658/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4022 - acc: 0.2071 - val_loss: 0.4584 - val_acc: 0.2444\n",
      "Epoch 2659/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4338 - acc: 0.2079 - val_loss: 0.4735 - val_acc: 0.2444\n",
      "Epoch 2660/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4049 - acc: 0.2079 - val_loss: 0.4476 - val_acc: 0.2444\n",
      "Epoch 2661/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3927 - acc: 0.2079 - val_loss: 0.4504 - val_acc: 0.2444\n",
      "Epoch 2662/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4078 - acc: 0.2075 - val_loss: 0.5004 - val_acc: 0.2407\n",
      "Epoch 2663/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4341 - acc: 0.2067 - val_loss: 0.4596 - val_acc: 0.2444\n",
      "Epoch 2664/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4111 - acc: 0.2071 - val_loss: 0.4860 - val_acc: 0.2407\n",
      "Epoch 2665/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4299 - acc: 0.2075 - val_loss: 0.4467 - val_acc: 0.2444\n",
      "Epoch 2666/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4177 - acc: 0.2079 - val_loss: 0.6279 - val_acc: 0.2444\n",
      "Epoch 2667/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4223 - acc: 0.2079 - val_loss: 0.4566 - val_acc: 0.2444\n",
      "Epoch 2668/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3980 - acc: 0.2075 - val_loss: 0.4729 - val_acc: 0.2407\n",
      "Epoch 2669/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3888 - acc: 0.2079 - val_loss: 0.4602 - val_acc: 0.2444\n",
      "Epoch 2670/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3941 - acc: 0.2079 - val_loss: 0.4729 - val_acc: 0.2407\n",
      "Epoch 2671/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4027 - acc: 0.2071 - val_loss: 0.5087 - val_acc: 0.2444\n",
      "Epoch 2672/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3925 - acc: 0.2083 - val_loss: 0.4882 - val_acc: 0.2407\n",
      "Epoch 2673/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4189 - acc: 0.2075 - val_loss: 0.4803 - val_acc: 0.2407\n",
      "Epoch 2674/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3917 - acc: 0.2075 - val_loss: 0.4427 - val_acc: 0.2444\n",
      "Epoch 2675/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4071 - acc: 0.2075 - val_loss: 0.5229 - val_acc: 0.2407\n",
      "Epoch 2676/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4176 - acc: 0.2075 - val_loss: 0.5724 - val_acc: 0.2407\n",
      "Epoch 2677/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4288 - acc: 0.2079 - val_loss: 0.4692 - val_acc: 0.2444\n",
      "Epoch 2678/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3970 - acc: 0.2083 - val_loss: 0.4840 - val_acc: 0.2407\n",
      "Epoch 2679/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4387 - acc: 0.2079 - val_loss: 0.5387 - val_acc: 0.2407\n",
      "Epoch 2680/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4100 - acc: 0.2079 - val_loss: 0.4811 - val_acc: 0.2407\n",
      "Epoch 2681/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4420 - acc: 0.2079 - val_loss: 0.7555 - val_acc: 0.2407\n",
      "Epoch 2682/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4179 - acc: 0.2079 - val_loss: 0.4554 - val_acc: 0.2444\n",
      "Epoch 2683/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3962 - acc: 0.2083 - val_loss: 0.4464 - val_acc: 0.2444\n",
      "Epoch 2684/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4050 - acc: 0.2079 - val_loss: 0.5028 - val_acc: 0.2444\n",
      "Epoch 2685/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3957 - acc: 0.2079 - val_loss: 0.4856 - val_acc: 0.2407\n",
      "Epoch 2686/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4204 - acc: 0.2083 - val_loss: 0.5891 - val_acc: 0.2407\n",
      "Epoch 2687/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4002 - acc: 0.2075 - val_loss: 0.4982 - val_acc: 0.2407\n",
      "Epoch 2688/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4050 - acc: 0.2079 - val_loss: 0.4559 - val_acc: 0.2444\n",
      "Epoch 2689/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4125 - acc: 0.2071 - val_loss: 0.5487 - val_acc: 0.2444\n",
      "Epoch 2690/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4084 - acc: 0.2083 - val_loss: 0.4450 - val_acc: 0.2444\n",
      "Epoch 2691/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4034 - acc: 0.2079 - val_loss: 0.5035 - val_acc: 0.2444\n",
      "Epoch 2692/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4002 - acc: 0.2071 - val_loss: 0.4532 - val_acc: 0.2444\n",
      "Epoch 2693/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4314 - acc: 0.2075 - val_loss: 0.5675 - val_acc: 0.2407\n",
      "Epoch 2694/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4462 - acc: 0.2071 - val_loss: 0.4459 - val_acc: 0.2444\n",
      "Epoch 2695/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3950 - acc: 0.2079 - val_loss: 0.4457 - val_acc: 0.2407\n",
      "Epoch 2696/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4878 - acc: 0.2079 - val_loss: 0.7581 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2697/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4105 - acc: 0.2079 - val_loss: 0.5045 - val_acc: 0.2407\n",
      "Epoch 2698/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4400 - acc: 0.2067 - val_loss: 0.4734 - val_acc: 0.2444\n",
      "Epoch 2699/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4193 - acc: 0.2071 - val_loss: 0.4768 - val_acc: 0.2444\n",
      "Epoch 2700/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4343 - acc: 0.2083 - val_loss: 0.4494 - val_acc: 0.2444\n",
      "Epoch 2701/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4261 - acc: 0.2075 - val_loss: 0.5265 - val_acc: 0.2444\n",
      "Epoch 2702/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4458 - acc: 0.2075 - val_loss: 0.5208 - val_acc: 0.2407\n",
      "Epoch 2703/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4151 - acc: 0.2083 - val_loss: 0.4506 - val_acc: 0.2407\n",
      "Epoch 2704/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3931 - acc: 0.2083 - val_loss: 0.4577 - val_acc: 0.2444\n",
      "Epoch 2705/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3991 - acc: 0.2075 - val_loss: 0.5011 - val_acc: 0.2407\n",
      "Epoch 2706/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4132 - acc: 0.2083 - val_loss: 0.5543 - val_acc: 0.2407\n",
      "Epoch 2707/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4239 - acc: 0.2075 - val_loss: 0.4987 - val_acc: 0.2407\n",
      "Epoch 2708/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4083 - acc: 0.2075 - val_loss: 0.4548 - val_acc: 0.2444\n",
      "Epoch 2709/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4038 - acc: 0.2079 - val_loss: 0.4598 - val_acc: 0.2444\n",
      "Epoch 2710/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4051 - acc: 0.2079 - val_loss: 0.4457 - val_acc: 0.2444\n",
      "Epoch 2711/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3999 - acc: 0.2083 - val_loss: 0.4441 - val_acc: 0.2444\n",
      "Epoch 2712/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4101 - acc: 0.2075 - val_loss: 0.5551 - val_acc: 0.2444\n",
      "Epoch 2713/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4303 - acc: 0.2083 - val_loss: 0.4629 - val_acc: 0.2444\n",
      "Epoch 2714/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3982 - acc: 0.2075 - val_loss: 0.5034 - val_acc: 0.2407\n",
      "Epoch 2715/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4186 - acc: 0.2075 - val_loss: 0.4722 - val_acc: 0.2444\n",
      "Epoch 2716/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4136 - acc: 0.2083 - val_loss: 0.5407 - val_acc: 0.2407\n",
      "Epoch 2717/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4209 - acc: 0.2079 - val_loss: 0.5506 - val_acc: 0.2444\n",
      "Epoch 2718/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4347 - acc: 0.2079 - val_loss: 0.4783 - val_acc: 0.2444\n",
      "Epoch 2719/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4033 - acc: 0.2079 - val_loss: 0.4438 - val_acc: 0.2444\n",
      "Epoch 2720/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4073 - acc: 0.2075 - val_loss: 0.5005 - val_acc: 0.2407\n",
      "Epoch 2721/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4285 - acc: 0.2071 - val_loss: 0.5365 - val_acc: 0.2407\n",
      "Epoch 2722/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4135 - acc: 0.2075 - val_loss: 0.4800 - val_acc: 0.2407\n",
      "Epoch 2723/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.4107 - acc: 0.2075 - val_loss: 0.4586 - val_acc: 0.2407\n",
      "Epoch 2724/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3918 - acc: 0.2075 - val_loss: 0.4363 - val_acc: 0.2407\n",
      "Epoch 2725/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4225 - acc: 0.2067 - val_loss: 0.5161 - val_acc: 0.2444\n",
      "Epoch 2726/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4108 - acc: 0.2079 - val_loss: 0.4447 - val_acc: 0.2407\n",
      "Epoch 2727/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3995 - acc: 0.2079 - val_loss: 0.4946 - val_acc: 0.2407\n",
      "Epoch 2728/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4328 - acc: 0.2079 - val_loss: 0.4371 - val_acc: 0.2444\n",
      "Epoch 2729/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4104 - acc: 0.2075 - val_loss: 0.4524 - val_acc: 0.2444\n",
      "Epoch 2730/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4113 - acc: 0.2075 - val_loss: 0.5290 - val_acc: 0.2407\n",
      "Epoch 2731/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3891 - acc: 0.2079 - val_loss: 0.4379 - val_acc: 0.2407\n",
      "Epoch 2732/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4419 - acc: 0.2071 - val_loss: 0.4707 - val_acc: 0.2444\n",
      "Epoch 2733/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4240 - acc: 0.2075 - val_loss: 0.5944 - val_acc: 0.2407\n",
      "Epoch 2734/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5017 - acc: 0.2067 - val_loss: 0.5447 - val_acc: 0.2407\n",
      "Epoch 2735/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4010 - acc: 0.2079 - val_loss: 0.4679 - val_acc: 0.2407\n",
      "Epoch 2736/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4107 - acc: 0.2079 - val_loss: 0.4663 - val_acc: 0.2407\n",
      "Epoch 2737/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4109 - acc: 0.2079 - val_loss: 0.4693 - val_acc: 0.2444\n",
      "Epoch 2738/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4331 - acc: 0.2075 - val_loss: 0.4762 - val_acc: 0.2407\n",
      "Epoch 2739/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4081 - acc: 0.2083 - val_loss: 0.4634 - val_acc: 0.2444\n",
      "Epoch 2740/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3966 - acc: 0.2079 - val_loss: 0.4431 - val_acc: 0.2407\n",
      "Epoch 2741/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3880 - acc: 0.2075 - val_loss: 0.4858 - val_acc: 0.2407\n",
      "Epoch 2742/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4275 - acc: 0.2071 - val_loss: 0.6191 - val_acc: 0.2444\n",
      "Epoch 2743/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4179 - acc: 0.2075 - val_loss: 0.5615 - val_acc: 0.2407\n",
      "Epoch 2744/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4378 - acc: 0.2071 - val_loss: 0.4501 - val_acc: 0.2444\n",
      "Epoch 2745/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4208 - acc: 0.2083 - val_loss: 0.4440 - val_acc: 0.2407\n",
      "Epoch 2746/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4116 - acc: 0.2083 - val_loss: 0.4584 - val_acc: 0.2407\n",
      "Epoch 2747/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4105 - acc: 0.2071 - val_loss: 0.5332 - val_acc: 0.2407\n",
      "Epoch 2748/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3961 - acc: 0.2075 - val_loss: 0.4431 - val_acc: 0.2444\n",
      "Epoch 2749/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4314 - acc: 0.2083 - val_loss: 0.4443 - val_acc: 0.2444\n",
      "Epoch 2750/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4218 - acc: 0.2067 - val_loss: 0.5467 - val_acc: 0.2444\n",
      "Epoch 2751/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4038 - acc: 0.2071 - val_loss: 0.4474 - val_acc: 0.2444\n",
      "Epoch 2752/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4077 - acc: 0.2079 - val_loss: 0.5539 - val_acc: 0.2407\n",
      "Epoch 2753/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4047 - acc: 0.2079 - val_loss: 0.4498 - val_acc: 0.2444\n",
      "Epoch 2754/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3966 - acc: 0.2079 - val_loss: 0.4861 - val_acc: 0.2407\n",
      "Epoch 2755/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4084 - acc: 0.2075 - val_loss: 0.4870 - val_acc: 0.2407\n",
      "Epoch 2756/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3980 - acc: 0.2079 - val_loss: 0.5739 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2757/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4290 - acc: 0.2079 - val_loss: 0.7281 - val_acc: 0.2407\n",
      "Epoch 2758/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4206 - acc: 0.2079 - val_loss: 0.4444 - val_acc: 0.2407\n",
      "Epoch 2759/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4118 - acc: 0.2079 - val_loss: 0.4397 - val_acc: 0.2407\n",
      "Epoch 2760/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4516 - acc: 0.2054 - val_loss: 0.6214 - val_acc: 0.2407\n",
      "Epoch 2761/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4186 - acc: 0.2083 - val_loss: 0.5336 - val_acc: 0.2444\n",
      "Epoch 2762/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4089 - acc: 0.2083 - val_loss: 0.5007 - val_acc: 0.2407\n",
      "Epoch 2763/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4997 - acc: 0.2067 - val_loss: 0.4663 - val_acc: 0.2407\n",
      "Epoch 2764/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3971 - acc: 0.2071 - val_loss: 0.5129 - val_acc: 0.2444\n",
      "Epoch 2765/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4413 - acc: 0.2071 - val_loss: 0.4522 - val_acc: 0.2444\n",
      "Epoch 2766/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4005 - acc: 0.2075 - val_loss: 0.4759 - val_acc: 0.2444\n",
      "Epoch 2767/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4000 - acc: 0.2075 - val_loss: 0.4530 - val_acc: 0.2407\n",
      "Epoch 2768/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4087 - acc: 0.2083 - val_loss: 0.4522 - val_acc: 0.2444\n",
      "Epoch 2769/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4063 - acc: 0.2079 - val_loss: 0.4630 - val_acc: 0.2444\n",
      "Epoch 2770/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4003 - acc: 0.2079 - val_loss: 0.4465 - val_acc: 0.2444\n",
      "Epoch 2771/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3923 - acc: 0.2083 - val_loss: 0.4491 - val_acc: 0.2407\n",
      "Epoch 2772/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3904 - acc: 0.2075 - val_loss: 0.4301 - val_acc: 0.2444\n",
      "Epoch 2773/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4399 - acc: 0.2079 - val_loss: 0.7213 - val_acc: 0.2407\n",
      "Epoch 2774/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4055 - acc: 0.2075 - val_loss: 0.4349 - val_acc: 0.2444\n",
      "Epoch 2775/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4023 - acc: 0.2079 - val_loss: 0.4773 - val_acc: 0.2407\n",
      "Epoch 2776/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4311 - acc: 0.2071 - val_loss: 0.5174 - val_acc: 0.2444\n",
      "Epoch 2777/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3992 - acc: 0.2079 - val_loss: 0.4485 - val_acc: 0.2407\n",
      "Epoch 2778/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4131 - acc: 0.2079 - val_loss: 0.4444 - val_acc: 0.2407\n",
      "Epoch 2779/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4435 - acc: 0.2075 - val_loss: 0.5655 - val_acc: 0.2407\n",
      "Epoch 2780/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4179 - acc: 0.2087 - val_loss: 0.4483 - val_acc: 0.2407\n",
      "Epoch 2781/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4231 - acc: 0.2079 - val_loss: 0.5719 - val_acc: 0.2407\n",
      "Epoch 2782/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4466 - acc: 0.2079 - val_loss: 0.4342 - val_acc: 0.2407\n",
      "Epoch 2783/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4023 - acc: 0.2083 - val_loss: 0.5092 - val_acc: 0.2444\n",
      "Epoch 2784/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3928 - acc: 0.2075 - val_loss: 0.4806 - val_acc: 0.2407\n",
      "Epoch 2785/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4079 - acc: 0.2083 - val_loss: 0.4651 - val_acc: 0.2407\n",
      "Epoch 2786/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3822 - acc: 0.2075 - val_loss: 0.4352 - val_acc: 0.2407\n",
      "Epoch 2787/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4250 - acc: 0.2079 - val_loss: 0.4411 - val_acc: 0.2407\n",
      "Epoch 2788/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4063 - acc: 0.2083 - val_loss: 0.4831 - val_acc: 0.2407\n",
      "Epoch 2789/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4114 - acc: 0.2079 - val_loss: 0.4621 - val_acc: 0.2444\n",
      "Epoch 2790/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4073 - acc: 0.2083 - val_loss: 0.4531 - val_acc: 0.2407\n",
      "Epoch 2791/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3940 - acc: 0.2083 - val_loss: 0.4459 - val_acc: 0.2407\n",
      "Epoch 2792/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3971 - acc: 0.2083 - val_loss: 0.4791 - val_acc: 0.2407\n",
      "Epoch 2793/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 1.7724 - acc: 0.2009 - val_loss: 0.9106 - val_acc: 0.2407\n",
      "Epoch 2794/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.7997 - acc: 0.2075 - val_loss: 0.7388 - val_acc: 0.2444\n",
      "Epoch 2795/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.6630 - acc: 0.2075 - val_loss: 0.6667 - val_acc: 0.2444\n",
      "Epoch 2796/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.5551 - acc: 0.2079 - val_loss: 0.6294 - val_acc: 0.2407\n",
      "Epoch 2797/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4905 - acc: 0.2079 - val_loss: 0.6107 - val_acc: 0.2444\n",
      "Epoch 2798/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4834 - acc: 0.2079 - val_loss: 0.6433 - val_acc: 0.2444\n",
      "Epoch 2799/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4442 - acc: 0.2079 - val_loss: 0.5529 - val_acc: 0.2444\n",
      "Epoch 2800/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4434 - acc: 0.2079 - val_loss: 0.5694 - val_acc: 0.2444\n",
      "Epoch 2801/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4338 - acc: 0.2075 - val_loss: 0.7401 - val_acc: 0.2444\n",
      "Epoch 2802/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4112 - acc: 0.2075 - val_loss: 0.6221 - val_acc: 0.2444\n",
      "Epoch 2803/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4118 - acc: 0.2075 - val_loss: 0.5226 - val_acc: 0.2444\n",
      "Epoch 2804/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3916 - acc: 0.2079 - val_loss: 0.5037 - val_acc: 0.2407\n",
      "Epoch 2805/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3984 - acc: 0.2075 - val_loss: 0.5475 - val_acc: 0.2407\n",
      "Epoch 2806/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4020 - acc: 0.2087 - val_loss: 0.4961 - val_acc: 0.2407\n",
      "Epoch 2807/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3912 - acc: 0.2079 - val_loss: 0.4638 - val_acc: 0.2444\n",
      "Epoch 2808/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4194 - acc: 0.2075 - val_loss: 0.4708 - val_acc: 0.2407\n",
      "Epoch 2809/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4044 - acc: 0.2075 - val_loss: 0.4599 - val_acc: 0.2444\n",
      "Epoch 2810/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4588 - acc: 0.2067 - val_loss: 0.4631 - val_acc: 0.2444\n",
      "Epoch 2811/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4245 - acc: 0.2075 - val_loss: 0.4846 - val_acc: 0.2407\n",
      "Epoch 2812/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4070 - acc: 0.2075 - val_loss: 0.4614 - val_acc: 0.2444\n",
      "Epoch 2813/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3974 - acc: 0.2083 - val_loss: 0.5340 - val_acc: 0.2444\n",
      "Epoch 2814/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4745 - acc: 0.2083 - val_loss: 0.4930 - val_acc: 0.2407\n",
      "Epoch 2815/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4027 - acc: 0.2083 - val_loss: 0.4612 - val_acc: 0.2444\n",
      "Epoch 2816/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3997 - acc: 0.2079 - val_loss: 0.5302 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2817/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4177 - acc: 0.2075 - val_loss: 0.4892 - val_acc: 0.2444\n",
      "Epoch 2818/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4119 - acc: 0.2079 - val_loss: 0.4526 - val_acc: 0.2444\n",
      "Epoch 2819/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3905 - acc: 0.2083 - val_loss: 0.4580 - val_acc: 0.2444\n",
      "Epoch 2820/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4050 - acc: 0.2075 - val_loss: 0.6446 - val_acc: 0.2407\n",
      "Epoch 2821/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4369 - acc: 0.2075 - val_loss: 0.5102 - val_acc: 0.2444\n",
      "Epoch 2822/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4202 - acc: 0.2079 - val_loss: 0.6446 - val_acc: 0.2407\n",
      "Epoch 2823/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4096 - acc: 0.2075 - val_loss: 0.4511 - val_acc: 0.2444\n",
      "Epoch 2824/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3884 - acc: 0.2079 - val_loss: 0.5353 - val_acc: 0.2407\n",
      "Epoch 2825/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4012 - acc: 0.2079 - val_loss: 0.5230 - val_acc: 0.2444\n",
      "Epoch 2826/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4005 - acc: 0.2087 - val_loss: 0.5313 - val_acc: 0.2444\n",
      "Epoch 2827/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4119 - acc: 0.2075 - val_loss: 0.5551 - val_acc: 0.2444\n",
      "Epoch 2828/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4075 - acc: 0.2079 - val_loss: 0.4886 - val_acc: 0.2444\n",
      "Epoch 2829/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3919 - acc: 0.2083 - val_loss: 0.4589 - val_acc: 0.2444\n",
      "Epoch 2830/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4007 - acc: 0.2079 - val_loss: 0.4721 - val_acc: 0.2444\n",
      "Epoch 2831/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4366 - acc: 0.2079 - val_loss: 0.4590 - val_acc: 0.2444\n",
      "Epoch 2832/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4044 - acc: 0.2075 - val_loss: 0.4412 - val_acc: 0.2444\n",
      "Epoch 2833/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4374 - acc: 0.2075 - val_loss: 0.4775 - val_acc: 0.2407\n",
      "Epoch 2834/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4243 - acc: 0.2071 - val_loss: 0.5027 - val_acc: 0.2444\n",
      "Epoch 2835/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4223 - acc: 0.2075 - val_loss: 0.4522 - val_acc: 0.2444\n",
      "Epoch 2836/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3901 - acc: 0.2075 - val_loss: 0.4875 - val_acc: 0.2444\n",
      "Epoch 2837/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3999 - acc: 0.2079 - val_loss: 0.4986 - val_acc: 0.2407\n",
      "Epoch 2838/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3878 - acc: 0.2075 - val_loss: 0.4630 - val_acc: 0.2444\n",
      "Epoch 2839/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4057 - acc: 0.2079 - val_loss: 0.4570 - val_acc: 0.2444\n",
      "Epoch 2840/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3896 - acc: 0.2071 - val_loss: 0.4598 - val_acc: 0.2407\n",
      "Epoch 2841/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3890 - acc: 0.2079 - val_loss: 0.4449 - val_acc: 0.2444\n",
      "Epoch 2842/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3919 - acc: 0.2079 - val_loss: 0.5123 - val_acc: 0.2407\n",
      "Epoch 2843/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4032 - acc: 0.2079 - val_loss: 0.5032 - val_acc: 0.2407\n",
      "Epoch 2844/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3957 - acc: 0.2075 - val_loss: 0.5223 - val_acc: 0.2407\n",
      "Epoch 2845/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4020 - acc: 0.2075 - val_loss: 0.5064 - val_acc: 0.2444\n",
      "Epoch 2846/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4178 - acc: 0.2075 - val_loss: 0.4708 - val_acc: 0.2407\n",
      "Epoch 2847/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4311 - acc: 0.2079 - val_loss: 0.4493 - val_acc: 0.2444\n",
      "Epoch 2848/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4301 - acc: 0.2079 - val_loss: 0.4461 - val_acc: 0.2407\n",
      "Epoch 2849/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3896 - acc: 0.2075 - val_loss: 0.4433 - val_acc: 0.2444\n",
      "Epoch 2850/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3961 - acc: 0.2079 - val_loss: 0.4469 - val_acc: 0.2444\n",
      "Epoch 2851/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3983 - acc: 0.2083 - val_loss: 0.4549 - val_acc: 0.2444\n",
      "Epoch 2852/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4083 - acc: 0.2083 - val_loss: 0.4655 - val_acc: 0.2444\n",
      "Epoch 2853/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4080 - acc: 0.2071 - val_loss: 0.4620 - val_acc: 0.2444\n",
      "Epoch 2854/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3988 - acc: 0.2083 - val_loss: 0.4523 - val_acc: 0.2444\n",
      "Epoch 2855/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4051 - acc: 0.2083 - val_loss: 0.5473 - val_acc: 0.2444\n",
      "Epoch 2856/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4147 - acc: 0.2075 - val_loss: 0.5160 - val_acc: 0.2407\n",
      "Epoch 2857/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4135 - acc: 0.2071 - val_loss: 0.4521 - val_acc: 0.2444\n",
      "Epoch 2858/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4040 - acc: 0.2075 - val_loss: 0.4798 - val_acc: 0.2407\n",
      "Epoch 2859/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4081 - acc: 0.2083 - val_loss: 0.4411 - val_acc: 0.2444\n",
      "Epoch 2860/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4029 - acc: 0.2079 - val_loss: 0.4572 - val_acc: 0.2444\n",
      "Epoch 2861/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3937 - acc: 0.2075 - val_loss: 0.4858 - val_acc: 0.2444\n",
      "Epoch 2862/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3926 - acc: 0.2075 - val_loss: 0.4739 - val_acc: 0.2407\n",
      "Epoch 2863/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4064 - acc: 0.2083 - val_loss: 0.5606 - val_acc: 0.2444\n",
      "Epoch 2864/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4470 - acc: 0.2071 - val_loss: 0.4474 - val_acc: 0.2444\n",
      "Epoch 2865/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4279 - acc: 0.2083 - val_loss: 0.4737 - val_acc: 0.2407\n",
      "Epoch 2866/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3977 - acc: 0.2083 - val_loss: 0.4430 - val_acc: 0.2407\n",
      "Epoch 2867/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4096 - acc: 0.2079 - val_loss: 0.4654 - val_acc: 0.2444\n",
      "Epoch 2868/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4005 - acc: 0.2083 - val_loss: 0.4398 - val_acc: 0.2444\n",
      "Epoch 2869/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3935 - acc: 0.2079 - val_loss: 0.4760 - val_acc: 0.2407\n",
      "Epoch 2870/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4014 - acc: 0.2083 - val_loss: 0.4599 - val_acc: 0.2407\n",
      "Epoch 2871/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4227 - acc: 0.2083 - val_loss: 0.5294 - val_acc: 0.2407\n",
      "Epoch 2872/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4273 - acc: 0.2071 - val_loss: 0.5012 - val_acc: 0.2444\n",
      "Epoch 2873/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4173 - acc: 0.2083 - val_loss: 0.5878 - val_acc: 0.2407\n",
      "Epoch 2874/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4198 - acc: 0.2071 - val_loss: 0.5200 - val_acc: 0.2444\n",
      "Epoch 2875/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4210 - acc: 0.2075 - val_loss: 0.4889 - val_acc: 0.2407\n",
      "Epoch 2876/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4245 - acc: 0.2075 - val_loss: 0.5205 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2877/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4231 - acc: 0.2071 - val_loss: 0.4472 - val_acc: 0.2444\n",
      "Epoch 2878/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4174 - acc: 0.2079 - val_loss: 0.4568 - val_acc: 0.2407\n",
      "Epoch 2879/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4543 - acc: 0.2075 - val_loss: 0.5907 - val_acc: 0.2444\n",
      "Epoch 2880/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4219 - acc: 0.2075 - val_loss: 0.4462 - val_acc: 0.2444\n",
      "Epoch 2881/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3811 - acc: 0.2079 - val_loss: 0.5064 - val_acc: 0.2444\n",
      "Epoch 2882/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3982 - acc: 0.2079 - val_loss: 0.4418 - val_acc: 0.2407\n",
      "Epoch 2883/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4034 - acc: 0.2071 - val_loss: 0.4682 - val_acc: 0.2444\n",
      "Epoch 2884/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4053 - acc: 0.2071 - val_loss: 0.5511 - val_acc: 0.2444\n",
      "Epoch 2885/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4030 - acc: 0.2083 - val_loss: 0.4827 - val_acc: 0.2407\n",
      "Epoch 2886/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4121 - acc: 0.2079 - val_loss: 0.5427 - val_acc: 0.2444\n",
      "Epoch 2887/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4204 - acc: 0.2079 - val_loss: 0.5197 - val_acc: 0.2444\n",
      "Epoch 2888/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4324 - acc: 0.2079 - val_loss: 0.5194 - val_acc: 0.2444\n",
      "Epoch 2889/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4032 - acc: 0.2075 - val_loss: 0.5007 - val_acc: 0.2407\n",
      "Epoch 2890/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3987 - acc: 0.2075 - val_loss: 0.4945 - val_acc: 0.2444\n",
      "Epoch 2891/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4054 - acc: 0.2079 - val_loss: 0.5341 - val_acc: 0.2444\n",
      "Epoch 2892/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4419 - acc: 0.2071 - val_loss: 0.4646 - val_acc: 0.2407\n",
      "Epoch 2893/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3978 - acc: 0.2067 - val_loss: 0.4737 - val_acc: 0.2444\n",
      "Epoch 2894/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4018 - acc: 0.2079 - val_loss: 0.4917 - val_acc: 0.2444\n",
      "Epoch 2895/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4436 - acc: 0.2075 - val_loss: 0.5744 - val_acc: 0.2407\n",
      "Epoch 2896/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4096 - acc: 0.2075 - val_loss: 0.6660 - val_acc: 0.2444\n",
      "Epoch 2897/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4192 - acc: 0.2075 - val_loss: 0.4656 - val_acc: 0.2407\n",
      "Epoch 2898/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3957 - acc: 0.2083 - val_loss: 0.4516 - val_acc: 0.2407\n",
      "Epoch 2899/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4062 - acc: 0.2067 - val_loss: 0.4448 - val_acc: 0.2407\n",
      "Epoch 2900/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4424 - acc: 0.2067 - val_loss: 0.5264 - val_acc: 0.2444\n",
      "Epoch 2901/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4689 - acc: 0.2059 - val_loss: 0.6831 - val_acc: 0.2444\n",
      "Epoch 2902/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4121 - acc: 0.2079 - val_loss: 0.4477 - val_acc: 0.2444\n",
      "Epoch 2903/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3879 - acc: 0.2079 - val_loss: 0.5297 - val_acc: 0.2444\n",
      "Epoch 2904/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4208 - acc: 0.2075 - val_loss: 0.4912 - val_acc: 0.2444\n",
      "Epoch 2905/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4051 - acc: 0.2079 - val_loss: 0.4924 - val_acc: 0.2407\n",
      "Epoch 2906/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4056 - acc: 0.2079 - val_loss: 0.5036 - val_acc: 0.2444\n",
      "Epoch 2907/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4309 - acc: 0.2079 - val_loss: 0.4279 - val_acc: 0.2444\n",
      "Epoch 2908/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3909 - acc: 0.2083 - val_loss: 0.4728 - val_acc: 0.2407\n",
      "Epoch 2909/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4217 - acc: 0.2075 - val_loss: 0.4396 - val_acc: 0.2444\n",
      "Epoch 2910/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3975 - acc: 0.2075 - val_loss: 0.4316 - val_acc: 0.2407\n",
      "Epoch 2911/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4223 - acc: 0.2067 - val_loss: 0.4536 - val_acc: 0.2444\n",
      "Epoch 2912/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4184 - acc: 0.2071 - val_loss: 0.4856 - val_acc: 0.2407\n",
      "Epoch 2913/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4001 - acc: 0.2075 - val_loss: 0.4555 - val_acc: 0.2444\n",
      "Epoch 2914/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3932 - acc: 0.2087 - val_loss: 0.4530 - val_acc: 0.2407\n",
      "Epoch 2915/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4135 - acc: 0.2071 - val_loss: 0.5728 - val_acc: 0.2407\n",
      "Epoch 2916/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3979 - acc: 0.2075 - val_loss: 0.5123 - val_acc: 0.2407\n",
      "Epoch 2917/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3881 - acc: 0.2079 - val_loss: 0.4380 - val_acc: 0.2407\n",
      "Epoch 2918/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3999 - acc: 0.2071 - val_loss: 0.4327 - val_acc: 0.2444\n",
      "Epoch 2919/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3984 - acc: 0.2079 - val_loss: 0.5516 - val_acc: 0.2444\n",
      "Epoch 2920/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4064 - acc: 0.2079 - val_loss: 0.4374 - val_acc: 0.2407\n",
      "Epoch 2921/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3915 - acc: 0.2079 - val_loss: 0.5408 - val_acc: 0.2444\n",
      "Epoch 2922/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4406 - acc: 0.2087 - val_loss: 0.4792 - val_acc: 0.2444\n",
      "Epoch 2923/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4100 - acc: 0.2079 - val_loss: 0.4470 - val_acc: 0.2407\n",
      "Epoch 2924/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3971 - acc: 0.2079 - val_loss: 0.4377 - val_acc: 0.2407\n",
      "Epoch 2925/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4013 - acc: 0.2083 - val_loss: 0.4608 - val_acc: 0.2444\n",
      "Epoch 2926/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4197 - acc: 0.2079 - val_loss: 0.4372 - val_acc: 0.2407\n",
      "Epoch 2927/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4020 - acc: 0.2079 - val_loss: 0.4896 - val_acc: 0.2444\n",
      "Epoch 2928/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4290 - acc: 0.2083 - val_loss: 0.4963 - val_acc: 0.2444\n",
      "Epoch 2929/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3989 - acc: 0.2079 - val_loss: 0.4478 - val_acc: 0.2407\n",
      "Epoch 2930/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4068 - acc: 0.2075 - val_loss: 0.4880 - val_acc: 0.2407\n",
      "Epoch 2931/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3969 - acc: 0.2079 - val_loss: 0.4522 - val_acc: 0.2444\n",
      "Epoch 2932/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3960 - acc: 0.2083 - val_loss: 0.4650 - val_acc: 0.2444\n",
      "Epoch 2933/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3936 - acc: 0.2079 - val_loss: 0.4645 - val_acc: 0.2444\n",
      "Epoch 2934/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3962 - acc: 0.2075 - val_loss: 0.5238 - val_acc: 0.2444\n",
      "Epoch 2935/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3964 - acc: 0.2083 - val_loss: 0.4797 - val_acc: 0.2444\n",
      "Epoch 2936/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3992 - acc: 0.2079 - val_loss: 0.6285 - val_acc: 0.2407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2937/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4434 - acc: 0.2079 - val_loss: 0.4570 - val_acc: 0.2444\n",
      "Epoch 2938/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4152 - acc: 0.2079 - val_loss: 0.4642 - val_acc: 0.2444\n",
      "Epoch 2939/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4777 - acc: 0.2075 - val_loss: 0.5389 - val_acc: 0.2444\n",
      "Epoch 2940/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4174 - acc: 0.2079 - val_loss: 0.4662 - val_acc: 0.2444\n",
      "Epoch 2941/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4015 - acc: 0.2079 - val_loss: 0.4866 - val_acc: 0.2407\n",
      "Epoch 2942/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4169 - acc: 0.2079 - val_loss: 0.4656 - val_acc: 0.2444\n",
      "Epoch 2943/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4153 - acc: 0.2079 - val_loss: 0.4639 - val_acc: 0.2407\n",
      "Epoch 2944/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3960 - acc: 0.2079 - val_loss: 0.4894 - val_acc: 0.2444\n",
      "Epoch 2945/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3941 - acc: 0.2083 - val_loss: 0.4982 - val_acc: 0.2444\n",
      "Epoch 2946/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4065 - acc: 0.2075 - val_loss: 0.4648 - val_acc: 0.2444\n",
      "Epoch 2947/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3907 - acc: 0.2079 - val_loss: 0.4482 - val_acc: 0.2407\n",
      "Epoch 2948/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4141 - acc: 0.2071 - val_loss: 0.4692 - val_acc: 0.2444\n",
      "Epoch 2949/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3865 - acc: 0.2083 - val_loss: 0.4605 - val_acc: 0.2444\n",
      "Epoch 2950/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3994 - acc: 0.2083 - val_loss: 0.4504 - val_acc: 0.2444\n",
      "Epoch 2951/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4174 - acc: 0.2079 - val_loss: 0.4475 - val_acc: 0.2407\n",
      "Epoch 2952/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3936 - acc: 0.2079 - val_loss: 0.4484 - val_acc: 0.2444\n",
      "Epoch 2953/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4052 - acc: 0.2083 - val_loss: 0.4516 - val_acc: 0.2407\n",
      "Epoch 2954/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4118 - acc: 0.2079 - val_loss: 0.4457 - val_acc: 0.2407\n",
      "Epoch 2955/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4152 - acc: 0.2075 - val_loss: 0.6114 - val_acc: 0.2407\n",
      "Epoch 2956/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4210 - acc: 0.2071 - val_loss: 0.4541 - val_acc: 0.2444\n",
      "Epoch 2957/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4595 - acc: 0.2067 - val_loss: 0.5426 - val_acc: 0.2407\n",
      "Epoch 2958/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3993 - acc: 0.2083 - val_loss: 0.4676 - val_acc: 0.2444\n",
      "Epoch 2959/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4052 - acc: 0.2075 - val_loss: 0.5470 - val_acc: 0.2407\n",
      "Epoch 2960/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4004 - acc: 0.2059 - val_loss: 0.4367 - val_acc: 0.2407\n",
      "Epoch 2961/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3973 - acc: 0.2083 - val_loss: 0.4720 - val_acc: 0.2407\n",
      "Epoch 2962/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4205 - acc: 0.2079 - val_loss: 0.5686 - val_acc: 0.2444\n",
      "Epoch 2963/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3971 - acc: 0.2075 - val_loss: 0.4839 - val_acc: 0.2407\n",
      "Epoch 2964/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4034 - acc: 0.2083 - val_loss: 0.4824 - val_acc: 0.2444\n",
      "Epoch 2965/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4036 - acc: 0.2079 - val_loss: 0.4554 - val_acc: 0.2444\n",
      "Epoch 2966/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3879 - acc: 0.2083 - val_loss: 0.4529 - val_acc: 0.2407\n",
      "Epoch 2967/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4110 - acc: 0.2075 - val_loss: 0.5398 - val_acc: 0.2407\n",
      "Epoch 2968/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4368 - acc: 0.2083 - val_loss: 0.5692 - val_acc: 0.2407\n",
      "Epoch 2969/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4013 - acc: 0.2075 - val_loss: 0.5466 - val_acc: 0.2407\n",
      "Epoch 2970/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4294 - acc: 0.2071 - val_loss: 0.4706 - val_acc: 0.2407\n",
      "Epoch 2971/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4398 - acc: 0.2079 - val_loss: 0.4574 - val_acc: 0.2444\n",
      "Epoch 2972/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4069 - acc: 0.2075 - val_loss: 0.5048 - val_acc: 0.2444\n",
      "Epoch 2973/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3921 - acc: 0.2083 - val_loss: 0.4953 - val_acc: 0.2444\n",
      "Epoch 2974/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4065 - acc: 0.2075 - val_loss: 0.5164 - val_acc: 0.2407\n",
      "Epoch 2975/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4017 - acc: 0.2075 - val_loss: 0.5160 - val_acc: 0.2444\n",
      "Epoch 2976/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3928 - acc: 0.2079 - val_loss: 0.4733 - val_acc: 0.2444\n",
      "Epoch 2977/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3977 - acc: 0.2087 - val_loss: 0.4635 - val_acc: 0.2407\n",
      "Epoch 2978/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3894 - acc: 0.2079 - val_loss: 0.4586 - val_acc: 0.2407\n",
      "Epoch 2979/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3932 - acc: 0.2079 - val_loss: 0.4538 - val_acc: 0.2444\n",
      "Epoch 2980/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4226 - acc: 0.2075 - val_loss: 0.4567 - val_acc: 0.2444\n",
      "Epoch 2981/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4079 - acc: 0.2075 - val_loss: 0.4535 - val_acc: 0.2407\n",
      "Epoch 2982/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3941 - acc: 0.2079 - val_loss: 0.4412 - val_acc: 0.2407\n",
      "Epoch 2983/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4215 - acc: 0.2075 - val_loss: 0.4410 - val_acc: 0.2444\n",
      "Epoch 2984/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4069 - acc: 0.2079 - val_loss: 0.5530 - val_acc: 0.2407\n",
      "Epoch 2985/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4323 - acc: 0.2079 - val_loss: 0.4650 - val_acc: 0.2407\n",
      "Epoch 2986/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4386 - acc: 0.2075 - val_loss: 0.5623 - val_acc: 0.2407\n",
      "Epoch 2987/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4024 - acc: 0.2079 - val_loss: 0.4825 - val_acc: 0.2407\n",
      "Epoch 2988/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4250 - acc: 0.2067 - val_loss: 0.4511 - val_acc: 0.2444\n",
      "Epoch 2989/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3975 - acc: 0.2083 - val_loss: 0.4597 - val_acc: 0.2444\n",
      "Epoch 2990/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.4083 - acc: 0.2075 - val_loss: 0.4856 - val_acc: 0.2444\n",
      "Epoch 2991/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4525 - acc: 0.2083 - val_loss: 0.5370 - val_acc: 0.2407\n",
      "Epoch 2992/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.6901 - acc: 0.2071 - val_loss: 0.7278 - val_acc: 0.2407\n",
      "Epoch 2993/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5370 - acc: 0.2079 - val_loss: 0.5735 - val_acc: 0.2407\n",
      "Epoch 2994/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4326 - acc: 0.2075 - val_loss: 0.5398 - val_acc: 0.2407\n",
      "Epoch 2995/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4230 - acc: 0.2083 - val_loss: 0.5163 - val_acc: 0.2407\n",
      "Epoch 2996/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4136 - acc: 0.2075 - val_loss: 0.5261 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2997/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4043 - acc: 0.2083 - val_loss: 0.4667 - val_acc: 0.2407\n",
      "Epoch 2998/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3948 - acc: 0.2079 - val_loss: 0.5130 - val_acc: 0.2444\n",
      "Epoch 2999/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3987 - acc: 0.2083 - val_loss: 0.4544 - val_acc: 0.2407\n",
      "Epoch 3000/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3908 - acc: 0.2083 - val_loss: 0.4647 - val_acc: 0.2444\n",
      "Epoch 3001/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3868 - acc: 0.2075 - val_loss: 0.4607 - val_acc: 0.2444\n",
      "Epoch 3002/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4163 - acc: 0.2075 - val_loss: 0.5141 - val_acc: 0.2444\n",
      "Epoch 3003/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3890 - acc: 0.2079 - val_loss: 0.4514 - val_acc: 0.2444\n",
      "Epoch 3004/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3803 - acc: 0.2083 - val_loss: 0.4621 - val_acc: 0.2407\n",
      "Epoch 3005/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4142 - acc: 0.2075 - val_loss: 0.4844 - val_acc: 0.2407\n",
      "Epoch 3006/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3801 - acc: 0.2083 - val_loss: 0.4642 - val_acc: 0.2407\n",
      "Epoch 3007/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4098 - acc: 0.2075 - val_loss: 0.4778 - val_acc: 0.2444\n",
      "Epoch 3008/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3948 - acc: 0.2083 - val_loss: 0.5183 - val_acc: 0.2444\n",
      "Epoch 3009/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4011 - acc: 0.2079 - val_loss: 0.4445 - val_acc: 0.2407\n",
      "Epoch 3010/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4420 - acc: 0.2075 - val_loss: 0.4854 - val_acc: 0.2444\n",
      "Epoch 3011/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3883 - acc: 0.2079 - val_loss: 0.4450 - val_acc: 0.2407\n",
      "Epoch 3012/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4405 - acc: 0.2075 - val_loss: 0.4848 - val_acc: 0.2444\n",
      "Epoch 3013/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4010 - acc: 0.2079 - val_loss: 0.4476 - val_acc: 0.2444\n",
      "Epoch 3014/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3996 - acc: 0.2071 - val_loss: 0.4580 - val_acc: 0.2407\n",
      "Epoch 3015/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3888 - acc: 0.2075 - val_loss: 0.4948 - val_acc: 0.2444\n",
      "Epoch 3016/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4092 - acc: 0.2083 - val_loss: 0.5034 - val_acc: 0.2444\n",
      "Epoch 3017/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3874 - acc: 0.2079 - val_loss: 0.4603 - val_acc: 0.2407\n",
      "Epoch 3018/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3939 - acc: 0.2079 - val_loss: 0.4375 - val_acc: 0.2444\n",
      "Epoch 3019/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4126 - acc: 0.2083 - val_loss: 0.6954 - val_acc: 0.2444\n",
      "Epoch 3020/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4378 - acc: 0.2083 - val_loss: 0.4429 - val_acc: 0.2407\n",
      "Epoch 3021/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3844 - acc: 0.2083 - val_loss: 0.5017 - val_acc: 0.2407\n",
      "Epoch 3022/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4002 - acc: 0.2083 - val_loss: 0.5127 - val_acc: 0.2407\n",
      "Epoch 3023/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4132 - acc: 0.2083 - val_loss: 0.5480 - val_acc: 0.2444\n",
      "Epoch 3024/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4420 - acc: 0.2075 - val_loss: 0.6469 - val_acc: 0.2407\n",
      "Epoch 3025/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4211 - acc: 0.2083 - val_loss: 0.7127 - val_acc: 0.2444\n",
      "Epoch 3026/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3935 - acc: 0.2083 - val_loss: 0.4314 - val_acc: 0.2407\n",
      "Epoch 3027/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4154 - acc: 0.2079 - val_loss: 0.5251 - val_acc: 0.2407\n",
      "Epoch 3028/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3831 - acc: 0.2075 - val_loss: 0.4530 - val_acc: 0.2444\n",
      "Epoch 3029/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3968 - acc: 0.2083 - val_loss: 0.4505 - val_acc: 0.2407\n",
      "Epoch 3030/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4085 - acc: 0.2075 - val_loss: 0.4594 - val_acc: 0.2444\n",
      "Epoch 3031/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4205 - acc: 0.2075 - val_loss: 0.4745 - val_acc: 0.2407\n",
      "Epoch 3032/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3984 - acc: 0.2083 - val_loss: 0.5002 - val_acc: 0.2444\n",
      "Epoch 3033/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3869 - acc: 0.2079 - val_loss: 0.4365 - val_acc: 0.2444\n",
      "Epoch 3034/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3934 - acc: 0.2079 - val_loss: 0.4437 - val_acc: 0.2444\n",
      "Epoch 3035/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3902 - acc: 0.2079 - val_loss: 0.4875 - val_acc: 0.2407\n",
      "Epoch 3036/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3904 - acc: 0.2083 - val_loss: 0.6639 - val_acc: 0.2444\n",
      "Epoch 3037/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4041 - acc: 0.2083 - val_loss: 0.4911 - val_acc: 0.2444\n",
      "Epoch 3038/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4592 - acc: 0.2079 - val_loss: 0.6237 - val_acc: 0.2444\n",
      "Epoch 3039/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4029 - acc: 0.2075 - val_loss: 0.4333 - val_acc: 0.2444\n",
      "Epoch 3040/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3848 - acc: 0.2083 - val_loss: 0.4361 - val_acc: 0.2407\n",
      "Epoch 3041/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3756 - acc: 0.2079 - val_loss: 0.4481 - val_acc: 0.2407\n",
      "Epoch 3042/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3820 - acc: 0.2079 - val_loss: 0.4339 - val_acc: 0.2444\n",
      "Epoch 3043/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3707 - acc: 0.2083 - val_loss: 0.4656 - val_acc: 0.2407\n",
      "Epoch 3044/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4315 - acc: 0.2059 - val_loss: 0.4324 - val_acc: 0.2444\n",
      "Epoch 3045/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3918 - acc: 0.2067 - val_loss: 0.4428 - val_acc: 0.2444\n",
      "Epoch 3046/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3915 - acc: 0.2079 - val_loss: 0.4584 - val_acc: 0.2444\n",
      "Epoch 3047/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4024 - acc: 0.2079 - val_loss: 0.4387 - val_acc: 0.2407\n",
      "Epoch 3048/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3871 - acc: 0.2083 - val_loss: 0.5205 - val_acc: 0.2407\n",
      "Epoch 3049/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3769 - acc: 0.2079 - val_loss: 0.4349 - val_acc: 0.2444\n",
      "Epoch 3050/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3769 - acc: 0.2087 - val_loss: 0.4585 - val_acc: 0.2407\n",
      "Epoch 3051/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3910 - acc: 0.2079 - val_loss: 0.4426 - val_acc: 0.2444\n",
      "Epoch 3052/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3824 - acc: 0.2083 - val_loss: 0.4939 - val_acc: 0.2407\n",
      "Epoch 3053/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4313 - acc: 0.2083 - val_loss: 0.4514 - val_acc: 0.2407\n",
      "Epoch 3054/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 1.2365 - acc: 0.2005 - val_loss: 0.7047 - val_acc: 0.2407\n",
      "Epoch 3055/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5507 - acc: 0.2075 - val_loss: 0.6409 - val_acc: 0.2407\n",
      "Epoch 3056/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4445 - acc: 0.2083 - val_loss: 0.5581 - val_acc: 0.2407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3057/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4231 - acc: 0.2083 - val_loss: 0.5599 - val_acc: 0.2407\n",
      "Epoch 3058/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4152 - acc: 0.2083 - val_loss: 0.5707 - val_acc: 0.2407\n",
      "Epoch 3059/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4029 - acc: 0.2075 - val_loss: 0.6099 - val_acc: 0.2407\n",
      "Epoch 3060/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4215 - acc: 0.2079 - val_loss: 0.5143 - val_acc: 0.2444\n",
      "Epoch 3061/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4434 - acc: 0.2087 - val_loss: 0.4613 - val_acc: 0.2444\n",
      "Epoch 3062/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3867 - acc: 0.2083 - val_loss: 0.4590 - val_acc: 0.2407\n",
      "Epoch 3063/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3970 - acc: 0.2083 - val_loss: 0.4478 - val_acc: 0.2444\n",
      "Epoch 3064/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4001 - acc: 0.2087 - val_loss: 0.4476 - val_acc: 0.2444\n",
      "Epoch 3065/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3938 - acc: 0.2083 - val_loss: 0.4339 - val_acc: 0.2444\n",
      "Epoch 3066/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3900 - acc: 0.2079 - val_loss: 0.4909 - val_acc: 0.2407\n",
      "Epoch 3067/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3941 - acc: 0.2079 - val_loss: 0.7645 - val_acc: 0.2444\n",
      "Epoch 3068/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3987 - acc: 0.2075 - val_loss: 0.4781 - val_acc: 0.2407\n",
      "Epoch 3069/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3800 - acc: 0.2083 - val_loss: 0.4766 - val_acc: 0.2444\n",
      "Epoch 3070/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3914 - acc: 0.2079 - val_loss: 0.4366 - val_acc: 0.2407\n",
      "Epoch 3071/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3769 - acc: 0.2079 - val_loss: 0.4802 - val_acc: 0.2444\n",
      "Epoch 3072/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3838 - acc: 0.2075 - val_loss: 0.4291 - val_acc: 0.2444\n",
      "Epoch 3073/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4058 - acc: 0.2075 - val_loss: 0.4250 - val_acc: 0.2444\n",
      "Epoch 3074/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3923 - acc: 0.2075 - val_loss: 0.4335 - val_acc: 0.2444\n",
      "Epoch 3075/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4496 - acc: 0.2075 - val_loss: 0.4419 - val_acc: 0.2407\n",
      "Epoch 3076/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3915 - acc: 0.2083 - val_loss: 0.4612 - val_acc: 0.2407\n",
      "Epoch 3077/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3960 - acc: 0.2083 - val_loss: 0.4585 - val_acc: 0.2444\n",
      "Epoch 3078/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4234 - acc: 0.2079 - val_loss: 0.5112 - val_acc: 0.2407\n",
      "Epoch 3079/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3939 - acc: 0.2075 - val_loss: 0.4542 - val_acc: 0.2444\n",
      "Epoch 3080/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3808 - acc: 0.2087 - val_loss: 0.4183 - val_acc: 0.2444\n",
      "Epoch 3081/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3693 - acc: 0.2079 - val_loss: 0.4500 - val_acc: 0.2444\n",
      "Epoch 3082/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3843 - acc: 0.2079 - val_loss: 0.4403 - val_acc: 0.2407\n",
      "Epoch 3083/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3918 - acc: 0.2083 - val_loss: 0.4483 - val_acc: 0.2407\n",
      "Epoch 3084/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4112 - acc: 0.2079 - val_loss: 0.4270 - val_acc: 0.2444\n",
      "Epoch 3085/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4121 - acc: 0.2079 - val_loss: 0.4804 - val_acc: 0.2444\n",
      "Epoch 3086/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4065 - acc: 0.2075 - val_loss: 0.5238 - val_acc: 0.2407\n",
      "Epoch 3087/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4344 - acc: 0.2071 - val_loss: 0.5619 - val_acc: 0.2444\n",
      "Epoch 3088/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3902 - acc: 0.2079 - val_loss: 0.4639 - val_acc: 0.2407\n",
      "Epoch 3089/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4173 - acc: 0.2075 - val_loss: 0.4326 - val_acc: 0.2444\n",
      "Epoch 3090/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3741 - acc: 0.2083 - val_loss: 0.4644 - val_acc: 0.2407\n",
      "Epoch 3091/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3801 - acc: 0.2083 - val_loss: 0.4653 - val_acc: 0.2444\n",
      "Epoch 3092/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3982 - acc: 0.2083 - val_loss: 0.4593 - val_acc: 0.2444\n",
      "Epoch 3093/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3782 - acc: 0.2079 - val_loss: 0.4197 - val_acc: 0.2444\n",
      "Epoch 3094/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3806 - acc: 0.2079 - val_loss: 0.4794 - val_acc: 0.2407\n",
      "Epoch 3095/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3804 - acc: 0.2083 - val_loss: 0.4379 - val_acc: 0.2444\n",
      "Epoch 3096/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3809 - acc: 0.2083 - val_loss: 0.4529 - val_acc: 0.2407\n",
      "Epoch 3097/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3875 - acc: 0.2083 - val_loss: 0.4656 - val_acc: 0.2444\n",
      "Epoch 3098/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3844 - acc: 0.2079 - val_loss: 0.4758 - val_acc: 0.2407\n",
      "Epoch 3099/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3933 - acc: 0.2083 - val_loss: 0.4496 - val_acc: 0.2407\n",
      "Epoch 3100/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3900 - acc: 0.2083 - val_loss: 0.5308 - val_acc: 0.2407\n",
      "Epoch 3101/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3988 - acc: 0.2083 - val_loss: 0.4341 - val_acc: 0.2444\n",
      "Epoch 3102/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3782 - acc: 0.2083 - val_loss: 0.4561 - val_acc: 0.2407\n",
      "Epoch 3103/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3831 - acc: 0.2071 - val_loss: 0.4704 - val_acc: 0.2407\n",
      "Epoch 3104/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3961 - acc: 0.2075 - val_loss: 0.4359 - val_acc: 0.2407\n",
      "Epoch 3105/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3701 - acc: 0.2083 - val_loss: 0.4514 - val_acc: 0.2407\n",
      "Epoch 3106/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3962 - acc: 0.2083 - val_loss: 0.4259 - val_acc: 0.2444\n",
      "Epoch 3107/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3906 - acc: 0.2079 - val_loss: 0.5219 - val_acc: 0.2407\n",
      "Epoch 3108/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4090 - acc: 0.2075 - val_loss: 0.4323 - val_acc: 0.2444\n",
      "Epoch 3109/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3860 - acc: 0.2071 - val_loss: 0.5168 - val_acc: 0.2444\n",
      "Epoch 3110/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3843 - acc: 0.2079 - val_loss: 0.4782 - val_acc: 0.2407\n",
      "Epoch 3111/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4004 - acc: 0.2087 - val_loss: 0.4275 - val_acc: 0.2444\n",
      "Epoch 3112/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3861 - acc: 0.2075 - val_loss: 0.4365 - val_acc: 0.2444\n",
      "Epoch 3113/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4217 - acc: 0.2071 - val_loss: 0.6776 - val_acc: 0.2444\n",
      "Epoch 3114/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3964 - acc: 0.2087 - val_loss: 0.4189 - val_acc: 0.2407\n",
      "Epoch 3115/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3897 - acc: 0.2079 - val_loss: 0.4387 - val_acc: 0.2407\n",
      "Epoch 3116/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4005 - acc: 0.2075 - val_loss: 0.5841 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3117/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3745 - acc: 0.2083 - val_loss: 0.4317 - val_acc: 0.2407\n",
      "Epoch 3118/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3881 - acc: 0.2075 - val_loss: 0.4570 - val_acc: 0.2444\n",
      "Epoch 3119/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3821 - acc: 0.2079 - val_loss: 0.4424 - val_acc: 0.2407\n",
      "Epoch 3120/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3865 - acc: 0.2079 - val_loss: 0.4649 - val_acc: 0.2444\n",
      "Epoch 3121/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3741 - acc: 0.2083 - val_loss: 0.4755 - val_acc: 0.2407\n",
      "Epoch 3122/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4116 - acc: 0.2079 - val_loss: 0.4528 - val_acc: 0.2444\n",
      "Epoch 3123/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4166 - acc: 0.2083 - val_loss: 0.4526 - val_acc: 0.2444\n",
      "Epoch 3124/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4029 - acc: 0.2079 - val_loss: 0.4949 - val_acc: 0.2444\n",
      "Epoch 3125/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3963 - acc: 0.2083 - val_loss: 0.4807 - val_acc: 0.2444\n",
      "Epoch 3126/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3854 - acc: 0.2087 - val_loss: 0.4427 - val_acc: 0.2444\n",
      "Epoch 3127/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3806 - acc: 0.2075 - val_loss: 0.4737 - val_acc: 0.2407\n",
      "Epoch 3128/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4340 - acc: 0.2079 - val_loss: 0.4584 - val_acc: 0.2444\n",
      "Epoch 3129/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3702 - acc: 0.2079 - val_loss: 0.4687 - val_acc: 0.2407\n",
      "Epoch 3130/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3942 - acc: 0.2079 - val_loss: 0.4317 - val_acc: 0.2444\n",
      "Epoch 3131/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3734 - acc: 0.2083 - val_loss: 0.4661 - val_acc: 0.2444\n",
      "Epoch 3132/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3798 - acc: 0.2079 - val_loss: 0.4487 - val_acc: 0.2444\n",
      "Epoch 3133/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4035 - acc: 0.2075 - val_loss: 0.5501 - val_acc: 0.2444\n",
      "Epoch 3134/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3996 - acc: 0.2067 - val_loss: 0.4245 - val_acc: 0.2444\n",
      "Epoch 3135/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3891 - acc: 0.2083 - val_loss: 0.5835 - val_acc: 0.2407\n",
      "Epoch 3136/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4198 - acc: 0.2075 - val_loss: 0.4292 - val_acc: 0.2444\n",
      "Epoch 3137/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3863 - acc: 0.2075 - val_loss: 0.4251 - val_acc: 0.2444\n",
      "Epoch 3138/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3781 - acc: 0.2079 - val_loss: 0.4370 - val_acc: 0.2407\n",
      "Epoch 3139/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3843 - acc: 0.2083 - val_loss: 0.4794 - val_acc: 0.2407\n",
      "Epoch 3140/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3872 - acc: 0.2083 - val_loss: 0.4867 - val_acc: 0.2407\n",
      "Epoch 3141/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3917 - acc: 0.2087 - val_loss: 0.5093 - val_acc: 0.2407\n",
      "Epoch 3142/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3959 - acc: 0.2075 - val_loss: 0.4423 - val_acc: 0.2444\n",
      "Epoch 3143/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3674 - acc: 0.2083 - val_loss: 0.4406 - val_acc: 0.2407\n",
      "Epoch 3144/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3971 - acc: 0.2079 - val_loss: 0.4499 - val_acc: 0.2444\n",
      "Epoch 3145/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3902 - acc: 0.2079 - val_loss: 0.4986 - val_acc: 0.2444\n",
      "Epoch 3146/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3740 - acc: 0.2079 - val_loss: 0.4358 - val_acc: 0.2444\n",
      "Epoch 3147/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3813 - acc: 0.2075 - val_loss: 0.4467 - val_acc: 0.2444\n",
      "Epoch 3148/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3909 - acc: 0.2079 - val_loss: 0.4402 - val_acc: 0.2407\n",
      "Epoch 3149/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3885 - acc: 0.2083 - val_loss: 0.4585 - val_acc: 0.2407\n",
      "Epoch 3150/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3987 - acc: 0.2079 - val_loss: 0.4386 - val_acc: 0.2407\n",
      "Epoch 3151/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3743 - acc: 0.2083 - val_loss: 0.5000 - val_acc: 0.2407\n",
      "Epoch 3152/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3856 - acc: 0.2079 - val_loss: 0.4765 - val_acc: 0.2407\n",
      "Epoch 3153/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3834 - acc: 0.2075 - val_loss: 0.4638 - val_acc: 0.2444\n",
      "Epoch 3154/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3984 - acc: 0.2083 - val_loss: 0.4542 - val_acc: 0.2444\n",
      "Epoch 3155/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4042 - acc: 0.2087 - val_loss: 0.4402 - val_acc: 0.2444\n",
      "Epoch 3156/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3945 - acc: 0.2079 - val_loss: 0.4778 - val_acc: 0.2444\n",
      "Epoch 3157/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3962 - acc: 0.2075 - val_loss: 0.4704 - val_acc: 0.2444\n",
      "Epoch 3158/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3738 - acc: 0.2079 - val_loss: 0.4730 - val_acc: 0.2444\n",
      "Epoch 3159/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3781 - acc: 0.2075 - val_loss: 0.4422 - val_acc: 0.2444\n",
      "Epoch 3160/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3841 - acc: 0.2079 - val_loss: 0.4244 - val_acc: 0.2444\n",
      "Epoch 3161/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4204 - acc: 0.2067 - val_loss: 0.6344 - val_acc: 0.2407\n",
      "Epoch 3162/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3826 - acc: 0.2083 - val_loss: 0.4286 - val_acc: 0.2444\n",
      "Epoch 3163/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4132 - acc: 0.2079 - val_loss: 0.4628 - val_acc: 0.2444\n",
      "Epoch 3164/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3896 - acc: 0.2083 - val_loss: 0.4652 - val_acc: 0.2444\n",
      "Epoch 3165/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4859 - acc: 0.2083 - val_loss: 0.6450 - val_acc: 0.2444\n",
      "Epoch 3166/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.7653 - acc: 0.2075 - val_loss: 0.7575 - val_acc: 0.2407\n",
      "Epoch 3167/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.5007 - acc: 0.2083 - val_loss: 0.5601 - val_acc: 0.2444\n",
      "Epoch 3168/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4291 - acc: 0.2079 - val_loss: 0.4758 - val_acc: 0.2444\n",
      "Epoch 3169/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3852 - acc: 0.2079 - val_loss: 0.4679 - val_acc: 0.2444\n",
      "Epoch 3170/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3900 - acc: 0.2079 - val_loss: 0.4545 - val_acc: 0.2407\n",
      "Epoch 3171/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3713 - acc: 0.2083 - val_loss: 0.4323 - val_acc: 0.2444\n",
      "Epoch 3172/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3974 - acc: 0.2071 - val_loss: 0.5682 - val_acc: 0.2407\n",
      "Epoch 3173/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3895 - acc: 0.2079 - val_loss: 0.4195 - val_acc: 0.2444\n",
      "Epoch 3174/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3710 - acc: 0.2083 - val_loss: 0.5146 - val_acc: 0.2407\n",
      "Epoch 3175/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3780 - acc: 0.2079 - val_loss: 0.4387 - val_acc: 0.2444\n",
      "Epoch 3176/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3893 - acc: 0.2083 - val_loss: 0.4409 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3177/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3877 - acc: 0.2075 - val_loss: 0.4472 - val_acc: 0.2444\n",
      "Epoch 3178/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3650 - acc: 0.2087 - val_loss: 0.4368 - val_acc: 0.2444\n",
      "Epoch 3179/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3826 - acc: 0.2087 - val_loss: 0.4332 - val_acc: 0.2444\n",
      "Epoch 3180/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3989 - acc: 0.2075 - val_loss: 0.6024 - val_acc: 0.2407\n",
      "Epoch 3181/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3742 - acc: 0.2075 - val_loss: 0.4558 - val_acc: 0.2407\n",
      "Epoch 3182/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3814 - acc: 0.2083 - val_loss: 0.4453 - val_acc: 0.2444\n",
      "Epoch 3183/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3743 - acc: 0.2079 - val_loss: 0.4318 - val_acc: 0.2444\n",
      "Epoch 3184/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4012 - acc: 0.2079 - val_loss: 0.4411 - val_acc: 0.2444\n",
      "Epoch 3185/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3884 - acc: 0.2083 - val_loss: 0.4709 - val_acc: 0.2444\n",
      "Epoch 3186/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.7898 - acc: 0.2083 - val_loss: 0.7275 - val_acc: 0.2407\n",
      "Epoch 3187/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4414 - acc: 0.2087 - val_loss: 0.5106 - val_acc: 0.2407\n",
      "Epoch 3188/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3913 - acc: 0.2083 - val_loss: 0.4505 - val_acc: 0.2444\n",
      "Epoch 3189/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3942 - acc: 0.2083 - val_loss: 0.4688 - val_acc: 0.2444\n",
      "Epoch 3190/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3998 - acc: 0.2087 - val_loss: 0.4217 - val_acc: 0.2444\n",
      "Epoch 3191/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3777 - acc: 0.2083 - val_loss: 0.4425 - val_acc: 0.2444\n",
      "Epoch 3192/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3803 - acc: 0.2087 - val_loss: 0.4273 - val_acc: 0.2444\n",
      "Epoch 3193/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3740 - acc: 0.2083 - val_loss: 0.4449 - val_acc: 0.2444\n",
      "Epoch 3194/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4013 - acc: 0.2083 - val_loss: 0.4468 - val_acc: 0.2444\n",
      "Epoch 3195/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3902 - acc: 0.2079 - val_loss: 0.5398 - val_acc: 0.2407\n",
      "Epoch 3196/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4080 - acc: 0.2071 - val_loss: 0.4361 - val_acc: 0.2444\n",
      "Epoch 3197/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3876 - acc: 0.2083 - val_loss: 0.8221 - val_acc: 0.2407\n",
      "Epoch 3198/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4173 - acc: 0.2079 - val_loss: 0.4520 - val_acc: 0.2444\n",
      "Epoch 3199/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3712 - acc: 0.2083 - val_loss: 0.4649 - val_acc: 0.2407\n",
      "Epoch 3200/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3718 - acc: 0.2079 - val_loss: 0.4346 - val_acc: 0.2444\n",
      "Epoch 3201/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3854 - acc: 0.2083 - val_loss: 0.5093 - val_acc: 0.2407\n",
      "Epoch 3202/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4311 - acc: 0.2075 - val_loss: 0.4311 - val_acc: 0.2444\n",
      "Epoch 3203/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3928 - acc: 0.2083 - val_loss: 0.5107 - val_acc: 0.2407\n",
      "Epoch 3204/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3792 - acc: 0.2087 - val_loss: 0.4324 - val_acc: 0.2444\n",
      "Epoch 3205/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3737 - acc: 0.2079 - val_loss: 0.4443 - val_acc: 0.2444\n",
      "Epoch 3206/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3697 - acc: 0.2075 - val_loss: 0.4349 - val_acc: 0.2444\n",
      "Epoch 3207/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3648 - acc: 0.2079 - val_loss: 0.4572 - val_acc: 0.2444\n",
      "Epoch 3208/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3636 - acc: 0.2083 - val_loss: 0.4654 - val_acc: 0.2407\n",
      "Epoch 3209/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3786 - acc: 0.2079 - val_loss: 0.4400 - val_acc: 0.2444\n",
      "Epoch 3210/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3729 - acc: 0.2079 - val_loss: 0.4868 - val_acc: 0.2407\n",
      "Epoch 3211/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3902 - acc: 0.2083 - val_loss: 0.5037 - val_acc: 0.2407\n",
      "Epoch 3212/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3636 - acc: 0.2083 - val_loss: 0.4707 - val_acc: 0.2444\n",
      "Epoch 3213/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3713 - acc: 0.2083 - val_loss: 0.7714 - val_acc: 0.2444\n",
      "Epoch 3214/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 1.0429 - acc: 0.2083 - val_loss: 0.6873 - val_acc: 0.2407\n",
      "Epoch 3215/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.5174 - acc: 0.2083 - val_loss: 0.6401 - val_acc: 0.2407\n",
      "Epoch 3216/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4413 - acc: 0.2083 - val_loss: 0.5516 - val_acc: 0.2444\n",
      "Epoch 3217/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4257 - acc: 0.2083 - val_loss: 0.5374 - val_acc: 0.2444\n",
      "Epoch 3218/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4140 - acc: 0.2083 - val_loss: 0.5380 - val_acc: 0.2444\n",
      "Epoch 3219/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3942 - acc: 0.2083 - val_loss: 0.4887 - val_acc: 0.2444\n",
      "Epoch 3220/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3886 - acc: 0.2083 - val_loss: 0.4934 - val_acc: 0.2444\n",
      "Epoch 3221/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4021 - acc: 0.2083 - val_loss: 0.4593 - val_acc: 0.2444\n",
      "Epoch 3222/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3951 - acc: 0.2083 - val_loss: 0.4607 - val_acc: 0.2444\n",
      "Epoch 3223/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3875 - acc: 0.2083 - val_loss: 0.4602 - val_acc: 0.2444\n",
      "Epoch 3224/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3996 - acc: 0.2083 - val_loss: 0.4456 - val_acc: 0.2444\n",
      "Epoch 3225/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3986 - acc: 0.2083 - val_loss: 0.4672 - val_acc: 0.2444\n",
      "Epoch 3226/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3908 - acc: 0.2083 - val_loss: 0.5185 - val_acc: 0.2444\n",
      "Epoch 3227/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3792 - acc: 0.2083 - val_loss: 0.4835 - val_acc: 0.2444\n",
      "Epoch 3228/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3845 - acc: 0.2087 - val_loss: 0.4464 - val_acc: 0.2444\n",
      "Epoch 3229/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3902 - acc: 0.2079 - val_loss: 0.5426 - val_acc: 0.2444\n",
      "Epoch 3230/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3911 - acc: 0.2083 - val_loss: 0.4389 - val_acc: 0.2444\n",
      "Epoch 3231/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4070 - acc: 0.2079 - val_loss: 0.4261 - val_acc: 0.2444\n",
      "Epoch 3232/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4047 - acc: 0.2079 - val_loss: 0.4368 - val_acc: 0.2444\n",
      "Epoch 3233/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4198 - acc: 0.2083 - val_loss: 0.5376 - val_acc: 0.2444\n",
      "Epoch 3234/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3878 - acc: 0.2079 - val_loss: 0.4789 - val_acc: 0.2444\n",
      "Epoch 3235/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3766 - acc: 0.2083 - val_loss: 0.4441 - val_acc: 0.2444\n",
      "Epoch 3236/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3830 - acc: 0.2075 - val_loss: 0.4722 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3237/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3866 - acc: 0.2083 - val_loss: 0.4537 - val_acc: 0.2444\n",
      "Epoch 3238/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3813 - acc: 0.2087 - val_loss: 0.4437 - val_acc: 0.2444\n",
      "Epoch 3239/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3678 - acc: 0.2075 - val_loss: 0.4510 - val_acc: 0.2444\n",
      "Epoch 3240/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3705 - acc: 0.2075 - val_loss: 0.4851 - val_acc: 0.2444\n",
      "Epoch 3241/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3908 - acc: 0.2083 - val_loss: 0.4378 - val_acc: 0.2444\n",
      "Epoch 3242/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4011 - acc: 0.2083 - val_loss: 0.4795 - val_acc: 0.2444\n",
      "Epoch 3243/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3945 - acc: 0.2079 - val_loss: 0.4471 - val_acc: 0.2444\n",
      "Epoch 3244/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3656 - acc: 0.2083 - val_loss: 0.4372 - val_acc: 0.2444\n",
      "Epoch 3245/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3621 - acc: 0.2079 - val_loss: 0.4363 - val_acc: 0.2444\n",
      "Epoch 3246/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3675 - acc: 0.2075 - val_loss: 0.4476 - val_acc: 0.2444\n",
      "Epoch 3247/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3784 - acc: 0.2083 - val_loss: 0.5581 - val_acc: 0.2444\n",
      "Epoch 3248/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3999 - acc: 0.2075 - val_loss: 0.4498 - val_acc: 0.2444\n",
      "Epoch 3249/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3927 - acc: 0.2087 - val_loss: 0.4306 - val_acc: 0.2444\n",
      "Epoch 3250/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3995 - acc: 0.2087 - val_loss: 0.4558 - val_acc: 0.2444\n",
      "Epoch 3251/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3857 - acc: 0.2079 - val_loss: 0.4418 - val_acc: 0.2444\n",
      "Epoch 3252/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3754 - acc: 0.2083 - val_loss: 0.4396 - val_acc: 0.2444\n",
      "Epoch 3253/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4331 - acc: 0.2075 - val_loss: 0.4375 - val_acc: 0.2444\n",
      "Epoch 3254/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3763 - acc: 0.2083 - val_loss: 0.4431 - val_acc: 0.2444\n",
      "Epoch 3255/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3629 - acc: 0.2079 - val_loss: 0.4257 - val_acc: 0.2444\n",
      "Epoch 3256/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3688 - acc: 0.2075 - val_loss: 0.4683 - val_acc: 0.2407\n",
      "Epoch 3257/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3964 - acc: 0.2087 - val_loss: 0.4873 - val_acc: 0.2444\n",
      "Epoch 3258/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3908 - acc: 0.2083 - val_loss: 0.4536 - val_acc: 0.2444\n",
      "Epoch 3259/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3975 - acc: 0.2075 - val_loss: 0.4640 - val_acc: 0.2407\n",
      "Epoch 3260/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3863 - acc: 0.2087 - val_loss: 0.4526 - val_acc: 0.2444\n",
      "Epoch 3261/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3693 - acc: 0.2075 - val_loss: 0.4718 - val_acc: 0.2407\n",
      "Epoch 3262/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3707 - acc: 0.2079 - val_loss: 0.4539 - val_acc: 0.2407\n",
      "Epoch 3263/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3933 - acc: 0.2083 - val_loss: 0.4629 - val_acc: 0.2444\n",
      "Epoch 3264/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3801 - acc: 0.2083 - val_loss: 0.4423 - val_acc: 0.2444\n",
      "Epoch 3265/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4246 - acc: 0.2071 - val_loss: 0.4276 - val_acc: 0.2444\n",
      "Epoch 3266/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3673 - acc: 0.2079 - val_loss: 0.4504 - val_acc: 0.2444\n",
      "Epoch 3267/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3845 - acc: 0.2083 - val_loss: 0.4362 - val_acc: 0.2444\n",
      "Epoch 3268/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3835 - acc: 0.2079 - val_loss: 0.4870 - val_acc: 0.2444\n",
      "Epoch 3269/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3983 - acc: 0.2083 - val_loss: 0.4474 - val_acc: 0.2407\n",
      "Epoch 3270/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3657 - acc: 0.2079 - val_loss: 0.4967 - val_acc: 0.2444\n",
      "Epoch 3271/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4117 - acc: 0.2083 - val_loss: 0.4869 - val_acc: 0.2444\n",
      "Epoch 3272/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3765 - acc: 0.2083 - val_loss: 0.4265 - val_acc: 0.2444\n",
      "Epoch 3273/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4005 - acc: 0.2079 - val_loss: 0.5294 - val_acc: 0.2407\n",
      "Epoch 3274/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3887 - acc: 0.2079 - val_loss: 0.4201 - val_acc: 0.2444\n",
      "Epoch 3275/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3903 - acc: 0.2083 - val_loss: 0.5064 - val_acc: 0.2407\n",
      "Epoch 3276/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4108 - acc: 0.2079 - val_loss: 0.4575 - val_acc: 0.2444\n",
      "Epoch 3277/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3750 - acc: 0.2075 - val_loss: 0.4781 - val_acc: 0.2407\n",
      "Epoch 3278/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4497 - acc: 0.2075 - val_loss: 0.5917 - val_acc: 0.2444\n",
      "Epoch 3279/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3882 - acc: 0.2079 - val_loss: 0.4410 - val_acc: 0.2444\n",
      "Epoch 3280/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3715 - acc: 0.2079 - val_loss: 0.4856 - val_acc: 0.2444\n",
      "Epoch 3281/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3678 - acc: 0.2083 - val_loss: 0.5052 - val_acc: 0.2444\n",
      "Epoch 3282/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3950 - acc: 0.2075 - val_loss: 0.4494 - val_acc: 0.2444\n",
      "Epoch 3283/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3876 - acc: 0.2067 - val_loss: 0.4373 - val_acc: 0.2444\n",
      "Epoch 3284/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3667 - acc: 0.2079 - val_loss: 0.4491 - val_acc: 0.2444\n",
      "Epoch 3285/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3763 - acc: 0.2083 - val_loss: 0.4772 - val_acc: 0.2407\n",
      "Epoch 3286/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4131 - acc: 0.2067 - val_loss: 0.4703 - val_acc: 0.2444\n",
      "Epoch 3287/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3841 - acc: 0.2087 - val_loss: 0.4426 - val_acc: 0.2444\n",
      "Epoch 3288/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3825 - acc: 0.2079 - val_loss: 0.5361 - val_acc: 0.2444\n",
      "Epoch 3289/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4099 - acc: 0.2075 - val_loss: 0.4567 - val_acc: 0.2444\n",
      "Epoch 3290/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3754 - acc: 0.2079 - val_loss: 0.4495 - val_acc: 0.2444\n",
      "Epoch 3291/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3757 - acc: 0.2075 - val_loss: 0.4486 - val_acc: 0.2444\n",
      "Epoch 3292/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3693 - acc: 0.2075 - val_loss: 0.4481 - val_acc: 0.2444\n",
      "Epoch 3293/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3743 - acc: 0.2083 - val_loss: 0.4619 - val_acc: 0.2444\n",
      "Epoch 3294/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4096 - acc: 0.2075 - val_loss: 0.4667 - val_acc: 0.2407\n",
      "Epoch 3295/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3962 - acc: 0.2083 - val_loss: 0.4873 - val_acc: 0.2444\n",
      "Epoch 3296/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3660 - acc: 0.2083 - val_loss: 0.4374 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3297/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3742 - acc: 0.2083 - val_loss: 0.4435 - val_acc: 0.2444\n",
      "Epoch 3298/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3677 - acc: 0.2079 - val_loss: 0.4320 - val_acc: 0.2444\n",
      "Epoch 3299/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3802 - acc: 0.2083 - val_loss: 0.4500 - val_acc: 0.2407\n",
      "Epoch 3300/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3719 - acc: 0.2079 - val_loss: 0.4700 - val_acc: 0.2407\n",
      "Epoch 3301/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3754 - acc: 0.2075 - val_loss: 0.4572 - val_acc: 0.2444\n",
      "Epoch 3302/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3928 - acc: 0.2071 - val_loss: 0.4578 - val_acc: 0.2444\n",
      "Epoch 3303/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4183 - acc: 0.2083 - val_loss: 0.4502 - val_acc: 0.2444\n",
      "Epoch 3304/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3764 - acc: 0.2079 - val_loss: 0.5033 - val_acc: 0.2444\n",
      "Epoch 3305/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3785 - acc: 0.2079 - val_loss: 0.4347 - val_acc: 0.2407\n",
      "Epoch 3306/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3645 - acc: 0.2083 - val_loss: 0.4336 - val_acc: 0.2444\n",
      "Epoch 3307/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3722 - acc: 0.2079 - val_loss: 0.4371 - val_acc: 0.2444\n",
      "Epoch 3308/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3656 - acc: 0.2083 - val_loss: 0.4164 - val_acc: 0.2444\n",
      "Epoch 3309/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3907 - acc: 0.2079 - val_loss: 0.4749 - val_acc: 0.2444\n",
      "Epoch 3310/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3852 - acc: 0.2083 - val_loss: 0.4511 - val_acc: 0.2407\n",
      "Epoch 3311/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3966 - acc: 0.2075 - val_loss: 0.4911 - val_acc: 0.2407\n",
      "Epoch 3312/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4098 - acc: 0.2083 - val_loss: 0.4669 - val_acc: 0.2444\n",
      "Epoch 3313/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3829 - acc: 0.2083 - val_loss: 0.4586 - val_acc: 0.2407\n",
      "Epoch 3314/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3907 - acc: 0.2087 - val_loss: 0.4254 - val_acc: 0.2444\n",
      "Epoch 3315/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3941 - acc: 0.2079 - val_loss: 0.4857 - val_acc: 0.2444\n",
      "Epoch 3316/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3830 - acc: 0.2083 - val_loss: 0.4595 - val_acc: 0.2444\n",
      "Epoch 3317/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4059 - acc: 0.2079 - val_loss: 0.4599 - val_acc: 0.2444\n",
      "Epoch 3318/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3683 - acc: 0.2083 - val_loss: 0.4352 - val_acc: 0.2444\n",
      "Epoch 3319/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4181 - acc: 0.2075 - val_loss: 0.4422 - val_acc: 0.2407\n",
      "Epoch 3320/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3734 - acc: 0.2087 - val_loss: 0.4534 - val_acc: 0.2444\n",
      "Epoch 3321/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3878 - acc: 0.2083 - val_loss: 0.4367 - val_acc: 0.2444\n",
      "Epoch 3322/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3657 - acc: 0.2083 - val_loss: 0.4717 - val_acc: 0.2444\n",
      "Epoch 3323/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3734 - acc: 0.2079 - val_loss: 0.4250 - val_acc: 0.2444\n",
      "Epoch 3324/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3743 - acc: 0.2079 - val_loss: 0.4448 - val_acc: 0.2444\n",
      "Epoch 3325/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3772 - acc: 0.2079 - val_loss: 0.5050 - val_acc: 0.2444\n",
      "Epoch 3326/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3923 - acc: 0.2083 - val_loss: 0.4690 - val_acc: 0.2444\n",
      "Epoch 3327/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3682 - acc: 0.2079 - val_loss: 0.4186 - val_acc: 0.2444\n",
      "Epoch 3328/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4123 - acc: 0.2075 - val_loss: 0.6865 - val_acc: 0.2407\n",
      "Epoch 3329/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 1.0377 - acc: 0.2034 - val_loss: 0.9856 - val_acc: 0.2407\n",
      "Epoch 3330/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.6919 - acc: 0.2079 - val_loss: 0.8237 - val_acc: 0.2444\n",
      "Epoch 3331/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.5048 - acc: 0.2079 - val_loss: 0.7039 - val_acc: 0.2444\n",
      "Epoch 3332/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4644 - acc: 0.2079 - val_loss: 0.5527 - val_acc: 0.2444\n",
      "Epoch 3333/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4252 - acc: 0.2079 - val_loss: 0.5485 - val_acc: 0.2407\n",
      "Epoch 3334/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4016 - acc: 0.2083 - val_loss: 0.5318 - val_acc: 0.2444\n",
      "Epoch 3335/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3971 - acc: 0.2075 - val_loss: 0.5243 - val_acc: 0.2407\n",
      "Epoch 3336/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4077 - acc: 0.2083 - val_loss: 0.4769 - val_acc: 0.2444\n",
      "Epoch 3337/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4014 - acc: 0.2079 - val_loss: 0.4687 - val_acc: 0.2407\n",
      "Epoch 3338/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3764 - acc: 0.2079 - val_loss: 0.4864 - val_acc: 0.2444\n",
      "Epoch 3339/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4014 - acc: 0.2083 - val_loss: 0.5155 - val_acc: 0.2407\n",
      "Epoch 3340/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3869 - acc: 0.2079 - val_loss: 0.4758 - val_acc: 0.2407\n",
      "Epoch 3341/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3800 - acc: 0.2075 - val_loss: 0.5441 - val_acc: 0.2407\n",
      "Epoch 3342/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4248 - acc: 0.2083 - val_loss: 0.4719 - val_acc: 0.2407\n",
      "Epoch 3343/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3807 - acc: 0.2075 - val_loss: 0.5118 - val_acc: 0.2444\n",
      "Epoch 3344/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4376 - acc: 0.2083 - val_loss: 0.5485 - val_acc: 0.2407\n",
      "Epoch 3345/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3687 - acc: 0.2079 - val_loss: 0.4578 - val_acc: 0.2444\n",
      "Epoch 3346/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3936 - acc: 0.2075 - val_loss: 0.4442 - val_acc: 0.2444\n",
      "Epoch 3347/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3739 - acc: 0.2083 - val_loss: 0.5212 - val_acc: 0.2407\n",
      "Epoch 3348/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3923 - acc: 0.2083 - val_loss: 0.4465 - val_acc: 0.2444\n",
      "Epoch 3349/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3652 - acc: 0.2083 - val_loss: 0.4421 - val_acc: 0.2444\n",
      "Epoch 3350/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3778 - acc: 0.2079 - val_loss: 0.4502 - val_acc: 0.2444\n",
      "Epoch 3351/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3799 - acc: 0.2083 - val_loss: 0.4270 - val_acc: 0.2444\n",
      "Epoch 3352/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3759 - acc: 0.2083 - val_loss: 0.5065 - val_acc: 0.2444\n",
      "Epoch 3353/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3806 - acc: 0.2087 - val_loss: 0.4505 - val_acc: 0.2444\n",
      "Epoch 3354/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3675 - acc: 0.2083 - val_loss: 0.4486 - val_acc: 0.2444\n",
      "Epoch 3355/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3761 - acc: 0.2083 - val_loss: 0.4731 - val_acc: 0.2444\n",
      "Epoch 3356/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3659 - acc: 0.2087 - val_loss: 0.4364 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3357/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3772 - acc: 0.2083 - val_loss: 0.4555 - val_acc: 0.2444\n",
      "Epoch 3358/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3824 - acc: 0.2079 - val_loss: 0.4390 - val_acc: 0.2444\n",
      "Epoch 3359/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3862 - acc: 0.2083 - val_loss: 0.4594 - val_acc: 0.2444\n",
      "Epoch 3360/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3691 - acc: 0.2079 - val_loss: 0.5100 - val_acc: 0.2407\n",
      "Epoch 3361/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3802 - acc: 0.2079 - val_loss: 0.4477 - val_acc: 0.2444\n",
      "Epoch 3362/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3889 - acc: 0.2083 - val_loss: 0.4844 - val_acc: 0.2444\n",
      "Epoch 3363/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4185 - acc: 0.2075 - val_loss: 0.4858 - val_acc: 0.2444\n",
      "Epoch 3364/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3928 - acc: 0.2079 - val_loss: 0.4444 - val_acc: 0.2444\n",
      "Epoch 3365/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3942 - acc: 0.2087 - val_loss: 0.4448 - val_acc: 0.2444\n",
      "Epoch 3366/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3896 - acc: 0.2079 - val_loss: 0.5169 - val_acc: 0.2444\n",
      "Epoch 3367/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3955 - acc: 0.2071 - val_loss: 0.4802 - val_acc: 0.2444\n",
      "Epoch 3368/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3621 - acc: 0.2079 - val_loss: 0.4796 - val_acc: 0.2444\n",
      "Epoch 3369/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3596 - acc: 0.2083 - val_loss: 0.4462 - val_acc: 0.2444\n",
      "Epoch 3370/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4119 - acc: 0.2079 - val_loss: 0.4447 - val_acc: 0.2444\n",
      "Epoch 3371/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3814 - acc: 0.2087 - val_loss: 0.4344 - val_acc: 0.2444\n",
      "Epoch 3372/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3759 - acc: 0.2087 - val_loss: 0.4716 - val_acc: 0.2444\n",
      "Epoch 3373/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4407 - acc: 0.2083 - val_loss: 0.4430 - val_acc: 0.2444\n",
      "Epoch 3374/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3775 - acc: 0.2079 - val_loss: 0.4467 - val_acc: 0.2444\n",
      "Epoch 3375/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3745 - acc: 0.2083 - val_loss: 0.4412 - val_acc: 0.2444\n",
      "Epoch 3376/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3680 - acc: 0.2083 - val_loss: 0.4479 - val_acc: 0.2444\n",
      "Epoch 3377/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4174 - acc: 0.2079 - val_loss: 0.4793 - val_acc: 0.2444\n",
      "Epoch 3378/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3668 - acc: 0.2075 - val_loss: 0.4871 - val_acc: 0.2407\n",
      "Epoch 3379/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4118 - acc: 0.2079 - val_loss: 0.7716 - val_acc: 0.2444\n",
      "Epoch 3380/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4122 - acc: 0.2079 - val_loss: 0.5374 - val_acc: 0.2444\n",
      "Epoch 3381/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3881 - acc: 0.2087 - val_loss: 0.4902 - val_acc: 0.2407\n",
      "Epoch 3382/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3634 - acc: 0.2083 - val_loss: 0.5049 - val_acc: 0.2407\n",
      "Epoch 3383/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3810 - acc: 0.2079 - val_loss: 0.4976 - val_acc: 0.2444\n",
      "Epoch 3384/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3745 - acc: 0.2079 - val_loss: 0.4371 - val_acc: 0.2444\n",
      "Epoch 3385/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.4008 - acc: 0.2071 - val_loss: 0.4722 - val_acc: 0.2407\n",
      "Epoch 3386/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.4269 - acc: 0.2079 - val_loss: 0.4698 - val_acc: 0.2444\n",
      "Epoch 3387/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4023 - acc: 0.2075 - val_loss: 0.4495 - val_acc: 0.2444\n",
      "Epoch 3388/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3704 - acc: 0.2079 - val_loss: 0.5161 - val_acc: 0.2407\n",
      "Epoch 3389/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3716 - acc: 0.2075 - val_loss: 0.4813 - val_acc: 0.2407\n",
      "Epoch 3390/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4297 - acc: 0.2079 - val_loss: 0.6363 - val_acc: 0.2407\n",
      "Epoch 3391/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3863 - acc: 0.2075 - val_loss: 0.4362 - val_acc: 0.2444\n",
      "Epoch 3392/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3728 - acc: 0.2087 - val_loss: 0.4321 - val_acc: 0.2444\n",
      "Epoch 3393/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3654 - acc: 0.2083 - val_loss: 0.4568 - val_acc: 0.2444\n",
      "Epoch 3394/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3694 - acc: 0.2083 - val_loss: 0.4465 - val_acc: 0.2444\n",
      "Epoch 3395/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3716 - acc: 0.2087 - val_loss: 0.4475 - val_acc: 0.2444\n",
      "Epoch 3396/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3794 - acc: 0.2083 - val_loss: 0.5164 - val_acc: 0.2444\n",
      "Epoch 3397/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3824 - acc: 0.2079 - val_loss: 0.4687 - val_acc: 0.2407\n",
      "Epoch 3398/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3976 - acc: 0.2075 - val_loss: 0.4593 - val_acc: 0.2444\n",
      "Epoch 3399/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3903 - acc: 0.2083 - val_loss: 0.5770 - val_acc: 0.2444\n",
      "Epoch 3400/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3725 - acc: 0.2083 - val_loss: 0.4909 - val_acc: 0.2444\n",
      "Epoch 3401/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3719 - acc: 0.2083 - val_loss: 0.5150 - val_acc: 0.2407\n",
      "Epoch 3402/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3792 - acc: 0.2079 - val_loss: 0.4408 - val_acc: 0.2444\n",
      "Epoch 3403/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3617 - acc: 0.2083 - val_loss: 0.4885 - val_acc: 0.2444\n",
      "Epoch 3404/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3710 - acc: 0.2083 - val_loss: 0.5022 - val_acc: 0.2444\n",
      "Epoch 3405/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3798 - acc: 0.2083 - val_loss: 0.4532 - val_acc: 0.2444\n",
      "Epoch 3406/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3764 - acc: 0.2079 - val_loss: 0.4657 - val_acc: 0.2444\n",
      "Epoch 3407/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3641 - acc: 0.2083 - val_loss: 0.4241 - val_acc: 0.2444\n",
      "Epoch 3408/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3731 - acc: 0.2079 - val_loss: 0.4421 - val_acc: 0.2444\n",
      "Epoch 3409/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3738 - acc: 0.2083 - val_loss: 0.7365 - val_acc: 0.2407\n",
      "Epoch 3410/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4089 - acc: 0.2079 - val_loss: 0.4352 - val_acc: 0.2444\n",
      "Epoch 3411/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3685 - acc: 0.2087 - val_loss: 0.4306 - val_acc: 0.2444\n",
      "Epoch 3412/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3944 - acc: 0.2079 - val_loss: 0.4428 - val_acc: 0.2444\n",
      "Epoch 3413/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4356 - acc: 0.2071 - val_loss: 0.5128 - val_acc: 0.2444\n",
      "Epoch 3414/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3673 - acc: 0.2083 - val_loss: 0.4392 - val_acc: 0.2444\n",
      "Epoch 3415/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3980 - acc: 0.2075 - val_loss: 0.4539 - val_acc: 0.2444\n",
      "Epoch 3416/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3889 - acc: 0.2083 - val_loss: 0.4642 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3417/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3752 - acc: 0.2087 - val_loss: 0.4649 - val_acc: 0.2407\n",
      "Epoch 3418/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3712 - acc: 0.2075 - val_loss: 0.5345 - val_acc: 0.2407\n",
      "Epoch 3419/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3651 - acc: 0.2087 - val_loss: 0.4474 - val_acc: 0.2444\n",
      "Epoch 3420/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4018 - acc: 0.2079 - val_loss: 0.5073 - val_acc: 0.2407\n",
      "Epoch 3421/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3783 - acc: 0.2083 - val_loss: 0.4398 - val_acc: 0.2444\n",
      "Epoch 3422/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3892 - acc: 0.2083 - val_loss: 0.5323 - val_acc: 0.2407\n",
      "Epoch 3423/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3943 - acc: 0.2083 - val_loss: 0.4332 - val_acc: 0.2444\n",
      "Epoch 3424/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3632 - acc: 0.2087 - val_loss: 0.4591 - val_acc: 0.2444\n",
      "Epoch 3425/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3990 - acc: 0.2071 - val_loss: 0.4350 - val_acc: 0.2444\n",
      "Epoch 3426/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3789 - acc: 0.2079 - val_loss: 0.4923 - val_acc: 0.2444\n",
      "Epoch 3427/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3841 - acc: 0.2075 - val_loss: 0.4937 - val_acc: 0.2407\n",
      "Epoch 3428/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3851 - acc: 0.2075 - val_loss: 0.5088 - val_acc: 0.2444\n",
      "Epoch 3429/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3804 - acc: 0.2079 - val_loss: 0.4380 - val_acc: 0.2444\n",
      "Epoch 3430/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3793 - acc: 0.2079 - val_loss: 0.4761 - val_acc: 0.2444\n",
      "Epoch 3431/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3857 - acc: 0.2087 - val_loss: 0.6386 - val_acc: 0.2407\n",
      "Epoch 3432/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4032 - acc: 0.2083 - val_loss: 0.5481 - val_acc: 0.2444\n",
      "Epoch 3433/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3849 - acc: 0.2079 - val_loss: 0.4832 - val_acc: 0.2444\n",
      "Epoch 3434/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3769 - acc: 0.2083 - val_loss: 0.4929 - val_acc: 0.2407\n",
      "Epoch 3435/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3765 - acc: 0.2087 - val_loss: 0.4477 - val_acc: 0.2444\n",
      "Epoch 3436/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4090 - acc: 0.2083 - val_loss: 0.4343 - val_acc: 0.2444\n",
      "Epoch 3437/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3839 - acc: 0.2083 - val_loss: 0.4813 - val_acc: 0.2444\n",
      "Epoch 3438/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3905 - acc: 0.2083 - val_loss: 0.4481 - val_acc: 0.2444\n",
      "Epoch 3439/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4458 - acc: 0.2075 - val_loss: 0.4411 - val_acc: 0.2444\n",
      "Epoch 3440/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3850 - acc: 0.2083 - val_loss: 0.4657 - val_acc: 0.2407\n",
      "Epoch 3441/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3736 - acc: 0.2087 - val_loss: 0.4356 - val_acc: 0.2444\n",
      "Epoch 3442/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3589 - acc: 0.2083 - val_loss: 0.4504 - val_acc: 0.2444\n",
      "Epoch 3443/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4070 - acc: 0.2083 - val_loss: 0.4541 - val_acc: 0.2444\n",
      "Epoch 3444/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4056 - acc: 0.2083 - val_loss: 0.5034 - val_acc: 0.2407\n",
      "Epoch 3445/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3976 - acc: 0.2083 - val_loss: 0.4325 - val_acc: 0.2444\n",
      "Epoch 3446/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3700 - acc: 0.2079 - val_loss: 0.4445 - val_acc: 0.2444\n",
      "Epoch 3447/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3878 - acc: 0.2083 - val_loss: 0.5338 - val_acc: 0.2407\n",
      "Epoch 3448/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4067 - acc: 0.2067 - val_loss: 0.4589 - val_acc: 0.2407\n",
      "Epoch 3449/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4209 - acc: 0.2067 - val_loss: 0.4175 - val_acc: 0.2444\n",
      "Epoch 3450/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4163 - acc: 0.2079 - val_loss: 0.4773 - val_acc: 0.2444\n",
      "Epoch 3451/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3807 - acc: 0.2079 - val_loss: 0.5219 - val_acc: 0.2407\n",
      "Epoch 3452/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4089 - acc: 0.2083 - val_loss: 0.4824 - val_acc: 0.2407\n",
      "Epoch 3453/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4443 - acc: 0.2079 - val_loss: 0.4767 - val_acc: 0.2444\n",
      "Epoch 3454/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3718 - acc: 0.2079 - val_loss: 0.4280 - val_acc: 0.2444\n",
      "Epoch 3455/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4199 - acc: 0.2075 - val_loss: 0.4853 - val_acc: 0.2407\n",
      "Epoch 3456/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3758 - acc: 0.2083 - val_loss: 0.5376 - val_acc: 0.2407\n",
      "Epoch 3457/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3731 - acc: 0.2083 - val_loss: 0.4505 - val_acc: 0.2444\n",
      "Epoch 3458/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3850 - acc: 0.2083 - val_loss: 0.4425 - val_acc: 0.2444\n",
      "Epoch 3459/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3817 - acc: 0.2079 - val_loss: 0.4513 - val_acc: 0.2444\n",
      "Epoch 3460/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3751 - acc: 0.2071 - val_loss: 0.4685 - val_acc: 0.2407\n",
      "Epoch 3461/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3830 - acc: 0.2079 - val_loss: 0.4505 - val_acc: 0.2444\n",
      "Epoch 3462/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3876 - acc: 0.2083 - val_loss: 0.4372 - val_acc: 0.2444\n",
      "Epoch 3463/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3767 - acc: 0.2075 - val_loss: 0.4797 - val_acc: 0.2407\n",
      "Epoch 3464/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3838 - acc: 0.2079 - val_loss: 0.4699 - val_acc: 0.2444\n",
      "Epoch 3465/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3821 - acc: 0.2087 - val_loss: 0.4199 - val_acc: 0.2444\n",
      "Epoch 3466/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3981 - acc: 0.2087 - val_loss: 0.4824 - val_acc: 0.2444\n",
      "Epoch 3467/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3787 - acc: 0.2079 - val_loss: 0.4775 - val_acc: 0.2444\n",
      "Epoch 3468/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3808 - acc: 0.2083 - val_loss: 0.4410 - val_acc: 0.2444\n",
      "Epoch 3469/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3681 - acc: 0.2075 - val_loss: 0.4351 - val_acc: 0.2444\n",
      "Epoch 3470/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3900 - acc: 0.2083 - val_loss: 0.4827 - val_acc: 0.2444\n",
      "Epoch 3471/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3862 - acc: 0.2075 - val_loss: 0.4680 - val_acc: 0.2444\n",
      "Epoch 3472/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4450 - acc: 0.2075 - val_loss: 0.4210 - val_acc: 0.2444\n",
      "Epoch 3473/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3756 - acc: 0.2083 - val_loss: 0.4727 - val_acc: 0.2407\n",
      "Epoch 3474/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3646 - acc: 0.2079 - val_loss: 0.4253 - val_acc: 0.2444\n",
      "Epoch 3475/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3728 - acc: 0.2083 - val_loss: 0.4229 - val_acc: 0.2444\n",
      "Epoch 3476/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3625 - acc: 0.2079 - val_loss: 0.4075 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3477/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3882 - acc: 0.2079 - val_loss: 0.4610 - val_acc: 0.2444\n",
      "Epoch 3478/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3879 - acc: 0.2075 - val_loss: 0.4583 - val_acc: 0.2444\n",
      "Epoch 3479/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3739 - acc: 0.2083 - val_loss: 0.4417 - val_acc: 0.2444\n",
      "Epoch 3480/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3855 - acc: 0.2079 - val_loss: 0.4455 - val_acc: 0.2444\n",
      "Epoch 3481/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3905 - acc: 0.2083 - val_loss: 0.5047 - val_acc: 0.2407\n",
      "Epoch 3482/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3887 - acc: 0.2079 - val_loss: 0.4352 - val_acc: 0.2444\n",
      "Epoch 3483/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3652 - acc: 0.2083 - val_loss: 0.4464 - val_acc: 0.2444\n",
      "Epoch 3484/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3784 - acc: 0.2083 - val_loss: 0.5823 - val_acc: 0.2444\n",
      "Epoch 3485/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4001 - acc: 0.2083 - val_loss: 0.4529 - val_acc: 0.2444\n",
      "Epoch 3486/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3838 - acc: 0.2079 - val_loss: 0.4637 - val_acc: 0.2444\n",
      "Epoch 3487/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3944 - acc: 0.2087 - val_loss: 0.7065 - val_acc: 0.2444\n",
      "Epoch 3488/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3834 - acc: 0.2079 - val_loss: 0.5234 - val_acc: 0.2444\n",
      "Epoch 3489/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3757 - acc: 0.2079 - val_loss: 0.4245 - val_acc: 0.2444\n",
      "Epoch 3490/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3950 - acc: 0.2083 - val_loss: 0.5336 - val_acc: 0.2444\n",
      "Epoch 3491/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3993 - acc: 0.2079 - val_loss: 0.5181 - val_acc: 0.2407\n",
      "Epoch 3492/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3710 - acc: 0.2079 - val_loss: 0.4345 - val_acc: 0.2444\n",
      "Epoch 3493/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3672 - acc: 0.2087 - val_loss: 0.4371 - val_acc: 0.2444\n",
      "Epoch 3494/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3615 - acc: 0.2083 - val_loss: 0.4383 - val_acc: 0.2444\n",
      "Epoch 3495/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3793 - acc: 0.2083 - val_loss: 0.4160 - val_acc: 0.2444\n",
      "Epoch 3496/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3694 - acc: 0.2079 - val_loss: 0.4040 - val_acc: 0.2444\n",
      "Epoch 3497/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3973 - acc: 0.2087 - val_loss: 0.4953 - val_acc: 0.2444\n",
      "Epoch 3498/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3957 - acc: 0.2079 - val_loss: 0.4257 - val_acc: 0.2444\n",
      "Epoch 3499/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4389 - acc: 0.2075 - val_loss: 0.4108 - val_acc: 0.2444\n",
      "Epoch 3500/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.6933 - acc: 0.2071 - val_loss: 0.7066 - val_acc: 0.2407\n",
      "Epoch 3501/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4995 - acc: 0.2079 - val_loss: 0.5397 - val_acc: 0.2444\n",
      "Epoch 3502/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4214 - acc: 0.2079 - val_loss: 0.4909 - val_acc: 0.2444\n",
      "Epoch 3503/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4145 - acc: 0.2083 - val_loss: 0.4922 - val_acc: 0.2444\n",
      "Epoch 3504/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3852 - acc: 0.2083 - val_loss: 0.4508 - val_acc: 0.2444\n",
      "Epoch 3505/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3719 - acc: 0.2079 - val_loss: 0.6007 - val_acc: 0.2407\n",
      "Epoch 3506/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3762 - acc: 0.2083 - val_loss: 0.4268 - val_acc: 0.2444\n",
      "Epoch 3507/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3785 - acc: 0.2083 - val_loss: 0.6192 - val_acc: 0.2444\n",
      "Epoch 3508/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4056 - acc: 0.2071 - val_loss: 0.5270 - val_acc: 0.2407\n",
      "Epoch 3509/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3794 - acc: 0.2083 - val_loss: 0.4724 - val_acc: 0.2444\n",
      "Epoch 3510/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3635 - acc: 0.2079 - val_loss: 0.4421 - val_acc: 0.2444\n",
      "Epoch 3511/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3738 - acc: 0.2083 - val_loss: 0.4544 - val_acc: 0.2444\n",
      "Epoch 3512/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3966 - acc: 0.2079 - val_loss: 0.5417 - val_acc: 0.2407\n",
      "Epoch 3513/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3933 - acc: 0.2083 - val_loss: 0.4229 - val_acc: 0.2444\n",
      "Epoch 3514/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3595 - acc: 0.2083 - val_loss: 0.4247 - val_acc: 0.2444\n",
      "Epoch 3515/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3589 - acc: 0.2075 - val_loss: 0.4523 - val_acc: 0.2444\n",
      "Epoch 3516/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.3787 - acc: 0.2071 - val_loss: 0.5200 - val_acc: 0.2444\n",
      "Epoch 3517/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.3874 - acc: 0.2083 - val_loss: 0.4241 - val_acc: 0.2444\n",
      "Epoch 3518/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3592 - acc: 0.2079 - val_loss: 0.4303 - val_acc: 0.2444\n",
      "Epoch 3519/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3965 - acc: 0.2079 - val_loss: 0.4553 - val_acc: 0.2444\n",
      "Epoch 3520/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3822 - acc: 0.2083 - val_loss: 0.5402 - val_acc: 0.2444\n",
      "Epoch 3521/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3615 - acc: 0.2087 - val_loss: 0.4703 - val_acc: 0.2444\n",
      "Epoch 3522/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3670 - acc: 0.2083 - val_loss: 0.5091 - val_acc: 0.2407\n",
      "Epoch 3523/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3590 - acc: 0.2079 - val_loss: 0.4219 - val_acc: 0.2444\n",
      "Epoch 3524/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3748 - acc: 0.2083 - val_loss: 0.4358 - val_acc: 0.2444\n",
      "Epoch 3525/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3649 - acc: 0.2083 - val_loss: 0.4084 - val_acc: 0.2444\n",
      "Epoch 3526/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3764 - acc: 0.2083 - val_loss: 0.4681 - val_acc: 0.2444\n",
      "Epoch 3527/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3792 - acc: 0.2087 - val_loss: 0.4313 - val_acc: 0.2444\n",
      "Epoch 3528/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3708 - acc: 0.2079 - val_loss: 0.4266 - val_acc: 0.2444\n",
      "Epoch 3529/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3731 - acc: 0.2083 - val_loss: 0.4203 - val_acc: 0.2444\n",
      "Epoch 3530/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4171 - acc: 0.2083 - val_loss: 0.4438 - val_acc: 0.2444\n",
      "Epoch 3531/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3862 - acc: 0.2075 - val_loss: 0.4486 - val_acc: 0.2444\n",
      "Epoch 3532/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3817 - acc: 0.2075 - val_loss: 0.4388 - val_acc: 0.2444\n",
      "Epoch 3533/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3745 - acc: 0.2075 - val_loss: 0.4259 - val_acc: 0.2444\n",
      "Epoch 3534/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3707 - acc: 0.2083 - val_loss: 0.4211 - val_acc: 0.2444\n",
      "Epoch 3535/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3659 - acc: 0.2087 - val_loss: 0.4550 - val_acc: 0.2444\n",
      "Epoch 3536/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3687 - acc: 0.2075 - val_loss: 0.4136 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3537/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3950 - acc: 0.2087 - val_loss: 0.4210 - val_acc: 0.2444\n",
      "Epoch 3538/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3651 - acc: 0.2075 - val_loss: 0.4875 - val_acc: 0.2444\n",
      "Epoch 3539/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3882 - acc: 0.2083 - val_loss: 0.4673 - val_acc: 0.2444\n",
      "Epoch 3540/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3730 - acc: 0.2079 - val_loss: 0.4362 - val_acc: 0.2444\n",
      "Epoch 3541/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3625 - acc: 0.2079 - val_loss: 0.4360 - val_acc: 0.2444\n",
      "Epoch 3542/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3614 - acc: 0.2087 - val_loss: 0.4207 - val_acc: 0.2444\n",
      "Epoch 3543/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4154 - acc: 0.2071 - val_loss: 0.5551 - val_acc: 0.2444\n",
      "Epoch 3544/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3747 - acc: 0.2079 - val_loss: 0.4373 - val_acc: 0.2444\n",
      "Epoch 3545/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3842 - acc: 0.2083 - val_loss: 0.4270 - val_acc: 0.2444\n",
      "Epoch 3546/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3963 - acc: 0.2087 - val_loss: 0.4476 - val_acc: 0.2444\n",
      "Epoch 3547/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3764 - acc: 0.2079 - val_loss: 0.5690 - val_acc: 0.2444\n",
      "Epoch 3548/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3643 - acc: 0.2083 - val_loss: 0.5688 - val_acc: 0.2444\n",
      "Epoch 3549/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3852 - acc: 0.2083 - val_loss: 0.4519 - val_acc: 0.2444\n",
      "Epoch 3550/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3629 - acc: 0.2083 - val_loss: 0.4382 - val_acc: 0.2444\n",
      "Epoch 3551/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3626 - acc: 0.2083 - val_loss: 0.4797 - val_acc: 0.2444\n",
      "Epoch 3552/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3688 - acc: 0.2083 - val_loss: 0.5719 - val_acc: 0.2444\n",
      "Epoch 3553/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3742 - acc: 0.2079 - val_loss: 0.4259 - val_acc: 0.2444\n",
      "Epoch 3554/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3813 - acc: 0.2079 - val_loss: 0.4713 - val_acc: 0.2444\n",
      "Epoch 3555/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3800 - acc: 0.2083 - val_loss: 0.4810 - val_acc: 0.2444\n",
      "Epoch 3556/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3952 - acc: 0.2079 - val_loss: 0.4341 - val_acc: 0.2444\n",
      "Epoch 3557/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3766 - acc: 0.2083 - val_loss: 0.4357 - val_acc: 0.2444\n",
      "Epoch 3558/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3691 - acc: 0.2079 - val_loss: 0.4323 - val_acc: 0.2444\n",
      "Epoch 3559/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3779 - acc: 0.2079 - val_loss: 0.4668 - val_acc: 0.2444\n",
      "Epoch 3560/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3789 - acc: 0.2075 - val_loss: 0.6382 - val_acc: 0.2444\n",
      "Epoch 3561/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3825 - acc: 0.2083 - val_loss: 0.4871 - val_acc: 0.2444\n",
      "Epoch 3562/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3755 - acc: 0.2079 - val_loss: 0.4427 - val_acc: 0.2444\n",
      "Epoch 3563/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3651 - acc: 0.2083 - val_loss: 0.4139 - val_acc: 0.2444\n",
      "Epoch 3564/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4133 - acc: 0.2083 - val_loss: 0.4926 - val_acc: 0.2407\n",
      "Epoch 3565/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3896 - acc: 0.2083 - val_loss: 0.4603 - val_acc: 0.2444\n",
      "Epoch 3566/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3759 - acc: 0.2071 - val_loss: 0.5166 - val_acc: 0.2444\n",
      "Epoch 3567/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3755 - acc: 0.2083 - val_loss: 0.4194 - val_acc: 0.2444\n",
      "Epoch 3568/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3732 - acc: 0.2083 - val_loss: 0.4204 - val_acc: 0.2444\n",
      "Epoch 3569/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4137 - acc: 0.2079 - val_loss: 0.4443 - val_acc: 0.2444\n",
      "Epoch 3570/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3667 - acc: 0.2079 - val_loss: 0.4495 - val_acc: 0.2444\n",
      "Epoch 3571/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3672 - acc: 0.2075 - val_loss: 0.4499 - val_acc: 0.2444\n",
      "Epoch 3572/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3758 - acc: 0.2075 - val_loss: 0.4233 - val_acc: 0.2444\n",
      "Epoch 3573/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3909 - acc: 0.2083 - val_loss: 0.5255 - val_acc: 0.2407\n",
      "Epoch 3574/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3739 - acc: 0.2083 - val_loss: 0.4485 - val_acc: 0.2444\n",
      "Epoch 3575/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3951 - acc: 0.2087 - val_loss: 0.4294 - val_acc: 0.2444\n",
      "Epoch 3576/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3834 - acc: 0.2083 - val_loss: 0.4544 - val_acc: 0.2444\n",
      "Epoch 3577/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3950 - acc: 0.2083 - val_loss: 0.4666 - val_acc: 0.2444\n",
      "Epoch 3578/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3688 - acc: 0.2083 - val_loss: 0.4708 - val_acc: 0.2444\n",
      "Epoch 3579/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4040 - acc: 0.2071 - val_loss: 0.6443 - val_acc: 0.2407\n",
      "Epoch 3580/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3809 - acc: 0.2087 - val_loss: 0.4324 - val_acc: 0.2444\n",
      "Epoch 3581/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3765 - acc: 0.2071 - val_loss: 0.4172 - val_acc: 0.2444\n",
      "Epoch 3582/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3801 - acc: 0.2079 - val_loss: 0.4122 - val_acc: 0.2444\n",
      "Epoch 3583/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3989 - acc: 0.2083 - val_loss: 0.4449 - val_acc: 0.2444\n",
      "Epoch 3584/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3717 - acc: 0.2079 - val_loss: 0.4208 - val_acc: 0.2444\n",
      "Epoch 3585/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3695 - acc: 0.2075 - val_loss: 0.5294 - val_acc: 0.2407\n",
      "Epoch 3586/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3933 - acc: 0.2075 - val_loss: 0.5002 - val_acc: 0.2444\n",
      "Epoch 3587/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3761 - acc: 0.2083 - val_loss: 0.4279 - val_acc: 0.2444\n",
      "Epoch 3588/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3758 - acc: 0.2079 - val_loss: 0.4069 - val_acc: 0.2444\n",
      "Epoch 3589/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3650 - acc: 0.2083 - val_loss: 0.5148 - val_acc: 0.2407\n",
      "Epoch 3590/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3719 - acc: 0.2079 - val_loss: 0.4301 - val_acc: 0.2444\n",
      "Epoch 3591/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3864 - acc: 0.2083 - val_loss: 0.4484 - val_acc: 0.2444\n",
      "Epoch 3592/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3666 - acc: 0.2083 - val_loss: 0.4776 - val_acc: 0.2444\n",
      "Epoch 3593/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3778 - acc: 0.2075 - val_loss: 0.5129 - val_acc: 0.2444\n",
      "Epoch 3594/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3971 - acc: 0.2079 - val_loss: 0.4216 - val_acc: 0.2444\n",
      "Epoch 3595/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3732 - acc: 0.2079 - val_loss: 0.4787 - val_acc: 0.2444\n",
      "Epoch 3596/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3722 - acc: 0.2087 - val_loss: 0.4592 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3597/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3957 - acc: 0.2083 - val_loss: 0.4483 - val_acc: 0.2444\n",
      "Epoch 3598/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3682 - acc: 0.2079 - val_loss: 0.4478 - val_acc: 0.2444\n",
      "Epoch 3599/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3682 - acc: 0.2075 - val_loss: 0.4107 - val_acc: 0.2444\n",
      "Epoch 3600/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3787 - acc: 0.2075 - val_loss: 0.4330 - val_acc: 0.2444\n",
      "Epoch 3601/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3730 - acc: 0.2083 - val_loss: 0.4590 - val_acc: 0.2444\n",
      "Epoch 3602/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3641 - acc: 0.2087 - val_loss: 0.4675 - val_acc: 0.2444\n",
      "Epoch 3603/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3718 - acc: 0.2075 - val_loss: 0.5372 - val_acc: 0.2444\n",
      "Epoch 3604/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3866 - acc: 0.2079 - val_loss: 0.4557 - val_acc: 0.2444\n",
      "Epoch 3605/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3773 - acc: 0.2083 - val_loss: 0.4651 - val_acc: 0.2444\n",
      "Epoch 3606/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3738 - acc: 0.2087 - val_loss: 0.5093 - val_acc: 0.2407\n",
      "Epoch 3607/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3876 - acc: 0.2079 - val_loss: 0.5250 - val_acc: 0.2444\n",
      "Epoch 3608/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3968 - acc: 0.2075 - val_loss: 0.5261 - val_acc: 0.2444\n",
      "Epoch 3609/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4026 - acc: 0.2067 - val_loss: 0.4974 - val_acc: 0.2444\n",
      "Epoch 3610/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4005 - acc: 0.2083 - val_loss: 0.4187 - val_acc: 0.2444\n",
      "Epoch 3611/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3588 - acc: 0.2083 - val_loss: 0.4328 - val_acc: 0.2444\n",
      "Epoch 3612/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4173 - acc: 0.2067 - val_loss: 0.4874 - val_acc: 0.2407\n",
      "Epoch 3613/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3965 - acc: 0.2075 - val_loss: 0.4184 - val_acc: 0.2444\n",
      "Epoch 3614/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3835 - acc: 0.2067 - val_loss: 0.4285 - val_acc: 0.2444\n",
      "Epoch 3615/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3680 - acc: 0.2079 - val_loss: 0.4105 - val_acc: 0.2444\n",
      "Epoch 3616/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3960 - acc: 0.2079 - val_loss: 0.4306 - val_acc: 0.2444\n",
      "Epoch 3617/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3801 - acc: 0.2083 - val_loss: 0.4145 - val_acc: 0.2444\n",
      "Epoch 3618/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3662 - acc: 0.2083 - val_loss: 0.4107 - val_acc: 0.2444\n",
      "Epoch 3619/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3807 - acc: 0.2087 - val_loss: 0.4399 - val_acc: 0.2444\n",
      "Epoch 3620/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3636 - acc: 0.2083 - val_loss: 0.5724 - val_acc: 0.2407\n",
      "Epoch 3621/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3889 - acc: 0.2079 - val_loss: 0.4271 - val_acc: 0.2444\n",
      "Epoch 3622/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4052 - acc: 0.2079 - val_loss: 0.4809 - val_acc: 0.2407\n",
      "Epoch 3623/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3728 - acc: 0.2083 - val_loss: 0.4152 - val_acc: 0.2444\n",
      "Epoch 3624/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4074 - acc: 0.2083 - val_loss: 0.4566 - val_acc: 0.2444\n",
      "Epoch 3625/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3693 - acc: 0.2083 - val_loss: 0.4188 - val_acc: 0.2444\n",
      "Epoch 3626/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3889 - acc: 0.2087 - val_loss: 0.4636 - val_acc: 0.2444\n",
      "Epoch 3627/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3602 - acc: 0.2079 - val_loss: 0.4291 - val_acc: 0.2444\n",
      "Epoch 3628/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3544 - acc: 0.2079 - val_loss: 0.4251 - val_acc: 0.2444\n",
      "Epoch 3629/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3913 - acc: 0.2087 - val_loss: 0.5207 - val_acc: 0.2444\n",
      "Epoch 3630/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3601 - acc: 0.2083 - val_loss: 0.5129 - val_acc: 0.2444\n",
      "Epoch 3631/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3903 - acc: 0.2083 - val_loss: 0.6370 - val_acc: 0.2407\n",
      "Epoch 3632/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4100 - acc: 0.2071 - val_loss: 0.4471 - val_acc: 0.2444\n",
      "Epoch 3633/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4124 - acc: 0.2079 - val_loss: 0.4236 - val_acc: 0.2444\n",
      "Epoch 3634/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3692 - acc: 0.2079 - val_loss: 0.4099 - val_acc: 0.2444\n",
      "Epoch 3635/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3636 - acc: 0.2083 - val_loss: 0.4234 - val_acc: 0.2444\n",
      "Epoch 3636/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3653 - acc: 0.2083 - val_loss: 0.4306 - val_acc: 0.2444\n",
      "Epoch 3637/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3695 - acc: 0.2083 - val_loss: 0.4547 - val_acc: 0.2444\n",
      "Epoch 3638/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3617 - acc: 0.2079 - val_loss: 0.4141 - val_acc: 0.2444\n",
      "Epoch 3639/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3795 - acc: 0.2083 - val_loss: 0.4282 - val_acc: 0.2444\n",
      "Epoch 3640/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3868 - acc: 0.2079 - val_loss: 0.4269 - val_acc: 0.2444\n",
      "Epoch 3641/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3996 - acc: 0.2075 - val_loss: 0.6913 - val_acc: 0.2407\n",
      "Epoch 3642/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3887 - acc: 0.2071 - val_loss: 0.4475 - val_acc: 0.2444\n",
      "Epoch 3643/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3743 - acc: 0.2083 - val_loss: 0.4234 - val_acc: 0.2444\n",
      "Epoch 3644/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3557 - acc: 0.2079 - val_loss: 0.4214 - val_acc: 0.2444\n",
      "Epoch 3645/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4100 - acc: 0.2083 - val_loss: 0.4147 - val_acc: 0.2444\n",
      "Epoch 3646/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4002 - acc: 0.2083 - val_loss: 0.4872 - val_acc: 0.2444\n",
      "Epoch 3647/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3815 - acc: 0.2079 - val_loss: 0.4170 - val_acc: 0.2444\n",
      "Epoch 3648/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.3613 - acc: 0.2083 - val_loss: 0.4426 - val_acc: 0.2444\n",
      "Epoch 3649/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3801 - acc: 0.2071 - val_loss: 0.4402 - val_acc: 0.2444\n",
      "Epoch 3650/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3707 - acc: 0.2079 - val_loss: 0.4415 - val_acc: 0.2444\n",
      "Epoch 3651/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4026 - acc: 0.2079 - val_loss: 0.5047 - val_acc: 0.2444\n",
      "Epoch 3652/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3899 - acc: 0.2083 - val_loss: 0.4306 - val_acc: 0.2444\n",
      "Epoch 3653/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3675 - acc: 0.2079 - val_loss: 0.4284 - val_acc: 0.2444\n",
      "Epoch 3654/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3605 - acc: 0.2087 - val_loss: 0.4228 - val_acc: 0.2444\n",
      "Epoch 3655/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3848 - acc: 0.2079 - val_loss: 0.4391 - val_acc: 0.2444\n",
      "Epoch 3656/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3932 - acc: 0.2079 - val_loss: 0.4634 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3657/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3909 - acc: 0.2083 - val_loss: 0.4374 - val_acc: 0.2444\n",
      "Epoch 3658/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3628 - acc: 0.2087 - val_loss: 0.5047 - val_acc: 0.2444\n",
      "Epoch 3659/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3634 - acc: 0.2083 - val_loss: 0.4250 - val_acc: 0.2444\n",
      "Epoch 3660/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3796 - acc: 0.2083 - val_loss: 0.4196 - val_acc: 0.2444\n",
      "Epoch 3661/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3893 - acc: 0.2083 - val_loss: 0.4284 - val_acc: 0.2444\n",
      "Epoch 3662/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3985 - acc: 0.2071 - val_loss: 0.5434 - val_acc: 0.2407\n",
      "Epoch 3663/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3771 - acc: 0.2083 - val_loss: 0.4107 - val_acc: 0.2444\n",
      "Epoch 3664/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3754 - acc: 0.2087 - val_loss: 0.4288 - val_acc: 0.2444\n",
      "Epoch 3665/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3759 - acc: 0.2071 - val_loss: 0.5282 - val_acc: 0.2444\n",
      "Epoch 3666/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3943 - acc: 0.2079 - val_loss: 0.4349 - val_acc: 0.2444\n",
      "Epoch 3667/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3716 - acc: 0.2075 - val_loss: 0.5424 - val_acc: 0.2407\n",
      "Epoch 3668/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3951 - acc: 0.2083 - val_loss: 0.4221 - val_acc: 0.2444\n",
      "Epoch 3669/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3937 - acc: 0.2075 - val_loss: 0.4279 - val_acc: 0.2444\n",
      "Epoch 3670/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3646 - acc: 0.2079 - val_loss: 0.4376 - val_acc: 0.2444\n",
      "Epoch 3671/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3648 - acc: 0.2087 - val_loss: 0.4163 - val_acc: 0.2444\n",
      "Epoch 3672/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4167 - acc: 0.2079 - val_loss: 0.5363 - val_acc: 0.2444\n",
      "Epoch 3673/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3874 - acc: 0.2083 - val_loss: 0.4334 - val_acc: 0.2444\n",
      "Epoch 3674/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3681 - acc: 0.2079 - val_loss: 0.5169 - val_acc: 0.2444\n",
      "Epoch 3675/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3692 - acc: 0.2083 - val_loss: 0.5104 - val_acc: 0.2444\n",
      "Epoch 3676/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4006 - acc: 0.2079 - val_loss: 0.4354 - val_acc: 0.2444\n",
      "Epoch 3677/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3601 - acc: 0.2083 - val_loss: 0.4591 - val_acc: 0.2444\n",
      "Epoch 3678/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3830 - acc: 0.2079 - val_loss: 0.4212 - val_acc: 0.2444\n",
      "Epoch 3679/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3689 - acc: 0.2079 - val_loss: 0.4384 - val_acc: 0.2444\n",
      "Epoch 3680/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3784 - acc: 0.2075 - val_loss: 0.5680 - val_acc: 0.2444\n",
      "Epoch 3681/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3964 - acc: 0.2079 - val_loss: 0.4880 - val_acc: 0.2444\n",
      "Epoch 3682/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3735 - acc: 0.2079 - val_loss: 0.5872 - val_acc: 0.2407\n",
      "Epoch 3683/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4518 - acc: 0.2079 - val_loss: 0.4862 - val_acc: 0.2444\n",
      "Epoch 3684/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3751 - acc: 0.2087 - val_loss: 0.4338 - val_acc: 0.2444\n",
      "Epoch 3685/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3863 - acc: 0.2083 - val_loss: 0.4637 - val_acc: 0.2444\n",
      "Epoch 3686/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3925 - acc: 0.2079 - val_loss: 0.5891 - val_acc: 0.2407\n",
      "Epoch 3687/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3818 - acc: 0.2075 - val_loss: 0.4825 - val_acc: 0.2444\n",
      "Epoch 3688/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3601 - acc: 0.2083 - val_loss: 0.4149 - val_acc: 0.2444\n",
      "Epoch 3689/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3682 - acc: 0.2083 - val_loss: 0.4308 - val_acc: 0.2444\n",
      "Epoch 3690/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3901 - acc: 0.2075 - val_loss: 0.4559 - val_acc: 0.2444\n",
      "Epoch 3691/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3591 - acc: 0.2083 - val_loss: 0.4396 - val_acc: 0.2444\n",
      "Epoch 3692/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3656 - acc: 0.2083 - val_loss: 0.4659 - val_acc: 0.2444\n",
      "Epoch 3693/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3816 - acc: 0.2071 - val_loss: 0.4459 - val_acc: 0.2444\n",
      "Epoch 3694/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3614 - acc: 0.2083 - val_loss: 0.5763 - val_acc: 0.2444\n",
      "Epoch 3695/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3845 - acc: 0.2079 - val_loss: 0.4208 - val_acc: 0.2444\n",
      "Epoch 3696/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3717 - acc: 0.2075 - val_loss: 0.5898 - val_acc: 0.2407\n",
      "Epoch 3697/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3767 - acc: 0.2075 - val_loss: 0.4365 - val_acc: 0.2444\n",
      "Epoch 3698/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4028 - acc: 0.2083 - val_loss: 0.4224 - val_acc: 0.2444\n",
      "Epoch 3699/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3690 - acc: 0.2083 - val_loss: 0.4359 - val_acc: 0.2444\n",
      "Epoch 3700/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3737 - acc: 0.2079 - val_loss: 0.4619 - val_acc: 0.2444\n",
      "Epoch 3701/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3585 - acc: 0.2079 - val_loss: 0.4708 - val_acc: 0.2444\n",
      "Epoch 3702/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3974 - acc: 0.2075 - val_loss: 0.4475 - val_acc: 0.2444\n",
      "Epoch 3703/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3582 - acc: 0.2079 - val_loss: 0.4423 - val_acc: 0.2444\n",
      "Epoch 3704/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4120 - acc: 0.2079 - val_loss: 0.4219 - val_acc: 0.2444\n",
      "Epoch 3705/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3576 - acc: 0.2087 - val_loss: 0.4359 - val_acc: 0.2444\n",
      "Epoch 3706/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3643 - acc: 0.2079 - val_loss: 0.4432 - val_acc: 0.2444\n",
      "Epoch 3707/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3602 - acc: 0.2083 - val_loss: 0.4499 - val_acc: 0.2444\n",
      "Epoch 3708/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3814 - acc: 0.2079 - val_loss: 0.4707 - val_acc: 0.2444\n",
      "Epoch 3709/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3730 - acc: 0.2087 - val_loss: 0.4400 - val_acc: 0.2444\n",
      "Epoch 3710/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3897 - acc: 0.2071 - val_loss: 0.4319 - val_acc: 0.2444\n",
      "Epoch 3711/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3767 - acc: 0.2079 - val_loss: 0.4266 - val_acc: 0.2444\n",
      "Epoch 3712/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4083 - acc: 0.2087 - val_loss: 0.6202 - val_acc: 0.2444\n",
      "Epoch 3713/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3835 - acc: 0.2079 - val_loss: 0.4954 - val_acc: 0.2444\n",
      "Epoch 3714/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3930 - acc: 0.2079 - val_loss: 0.4096 - val_acc: 0.2444\n",
      "Epoch 3715/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3866 - acc: 0.2075 - val_loss: 0.4463 - val_acc: 0.2444\n",
      "Epoch 3716/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3784 - acc: 0.2083 - val_loss: 0.4662 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3717/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3694 - acc: 0.2083 - val_loss: 0.5175 - val_acc: 0.2444\n",
      "Epoch 3718/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4009 - acc: 0.2075 - val_loss: 0.4132 - val_acc: 0.2444\n",
      "Epoch 3719/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3600 - acc: 0.2083 - val_loss: 0.4485 - val_acc: 0.2444\n",
      "Epoch 3720/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3842 - acc: 0.2079 - val_loss: 0.4145 - val_acc: 0.2444\n",
      "Epoch 3721/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3671 - acc: 0.2075 - val_loss: 0.4290 - val_acc: 0.2444\n",
      "Epoch 3722/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3664 - acc: 0.2079 - val_loss: 0.5217 - val_acc: 0.2407\n",
      "Epoch 3723/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3724 - acc: 0.2083 - val_loss: 0.4181 - val_acc: 0.2444\n",
      "Epoch 3724/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3713 - acc: 0.2075 - val_loss: 0.4094 - val_acc: 0.2444\n",
      "Epoch 3725/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3698 - acc: 0.2083 - val_loss: 0.4614 - val_acc: 0.2444\n",
      "Epoch 3726/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3796 - acc: 0.2079 - val_loss: 0.4289 - val_acc: 0.2444\n",
      "Epoch 3727/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3925 - acc: 0.2083 - val_loss: 0.4497 - val_acc: 0.2444\n",
      "Epoch 3728/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3789 - acc: 0.2083 - val_loss: 0.4285 - val_acc: 0.2444\n",
      "Epoch 3729/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4079 - acc: 0.2071 - val_loss: 0.4942 - val_acc: 0.2444\n",
      "Epoch 3730/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3881 - acc: 0.2079 - val_loss: 0.4730 - val_acc: 0.2444\n",
      "Epoch 3731/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3783 - acc: 0.2079 - val_loss: 0.5557 - val_acc: 0.2407\n",
      "Epoch 3732/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3936 - acc: 0.2083 - val_loss: 0.4323 - val_acc: 0.2444\n",
      "Epoch 3733/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3727 - acc: 0.2079 - val_loss: 0.4327 - val_acc: 0.2444\n",
      "Epoch 3734/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3891 - acc: 0.2075 - val_loss: 0.4910 - val_acc: 0.2444\n",
      "Epoch 3735/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3712 - acc: 0.2083 - val_loss: 0.5009 - val_acc: 0.2444\n",
      "Epoch 3736/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3730 - acc: 0.2075 - val_loss: 0.5577 - val_acc: 0.2444\n",
      "Epoch 3737/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3829 - acc: 0.2083 - val_loss: 0.4691 - val_acc: 0.2444\n",
      "Epoch 3738/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3591 - acc: 0.2083 - val_loss: 0.4253 - val_acc: 0.2444\n",
      "Epoch 3739/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3885 - acc: 0.2071 - val_loss: 0.4981 - val_acc: 0.2407\n",
      "Epoch 3740/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3744 - acc: 0.2079 - val_loss: 0.4205 - val_acc: 0.2444\n",
      "Epoch 3741/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3738 - acc: 0.2083 - val_loss: 0.5131 - val_acc: 0.2444\n",
      "Epoch 3742/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3749 - acc: 0.2079 - val_loss: 0.4314 - val_acc: 0.2444\n",
      "Epoch 3743/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3650 - acc: 0.2083 - val_loss: 0.4686 - val_acc: 0.2444\n",
      "Epoch 3744/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3692 - acc: 0.2083 - val_loss: 0.4373 - val_acc: 0.2444\n",
      "Epoch 3745/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3748 - acc: 0.2079 - val_loss: 0.4883 - val_acc: 0.2444\n",
      "Epoch 3746/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3816 - acc: 0.2079 - val_loss: 0.4371 - val_acc: 0.2444\n",
      "Epoch 3747/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3711 - acc: 0.2083 - val_loss: 0.4254 - val_acc: 0.2444\n",
      "Epoch 3748/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3832 - acc: 0.2071 - val_loss: 0.4357 - val_acc: 0.2444\n",
      "Epoch 3749/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3982 - acc: 0.2079 - val_loss: 0.4143 - val_acc: 0.2444\n",
      "Epoch 3750/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3634 - acc: 0.2075 - val_loss: 0.4324 - val_acc: 0.2444\n",
      "Epoch 3751/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3601 - acc: 0.2079 - val_loss: 0.4409 - val_acc: 0.2444\n",
      "Epoch 3752/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3979 - acc: 0.2083 - val_loss: 0.4181 - val_acc: 0.2444\n",
      "Epoch 3753/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3631 - acc: 0.2079 - val_loss: 0.4338 - val_acc: 0.2444\n",
      "Epoch 3754/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3775 - acc: 0.2083 - val_loss: 0.4492 - val_acc: 0.2444\n",
      "Epoch 3755/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3898 - acc: 0.2079 - val_loss: 0.5973 - val_acc: 0.2407\n",
      "Epoch 3756/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3801 - acc: 0.2075 - val_loss: 0.4816 - val_acc: 0.2444\n",
      "Epoch 3757/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3773 - acc: 0.2079 - val_loss: 0.5935 - val_acc: 0.2444\n",
      "Epoch 3758/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3939 - acc: 0.2075 - val_loss: 0.4320 - val_acc: 0.2444\n",
      "Epoch 3759/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4071 - acc: 0.2075 - val_loss: 0.5585 - val_acc: 0.2444\n",
      "Epoch 3760/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3912 - acc: 0.2079 - val_loss: 0.4422 - val_acc: 0.2444\n",
      "Epoch 3761/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3606 - acc: 0.2079 - val_loss: 0.4232 - val_acc: 0.2444\n",
      "Epoch 3762/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3742 - acc: 0.2079 - val_loss: 0.4335 - val_acc: 0.2444\n",
      "Epoch 3763/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3548 - acc: 0.2083 - val_loss: 0.5171 - val_acc: 0.2407\n",
      "Epoch 3764/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3780 - acc: 0.2083 - val_loss: 0.6043 - val_acc: 0.2444\n",
      "Epoch 3765/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3925 - acc: 0.2079 - val_loss: 0.4549 - val_acc: 0.2444\n",
      "Epoch 3766/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3659 - acc: 0.2083 - val_loss: 0.4135 - val_acc: 0.2444\n",
      "Epoch 3767/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3650 - acc: 0.2083 - val_loss: 0.4336 - val_acc: 0.2444\n",
      "Epoch 3768/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3784 - acc: 0.2083 - val_loss: 0.4132 - val_acc: 0.2444\n",
      "Epoch 3769/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3575 - acc: 0.2079 - val_loss: 0.4170 - val_acc: 0.2444\n",
      "Epoch 3770/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3652 - acc: 0.2087 - val_loss: 0.5212 - val_acc: 0.2407\n",
      "Epoch 3771/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3868 - acc: 0.2083 - val_loss: 0.4105 - val_acc: 0.2444\n",
      "Epoch 3772/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4044 - acc: 0.2087 - val_loss: 0.5139 - val_acc: 0.2407\n",
      "Epoch 3773/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4316 - acc: 0.2087 - val_loss: 0.4305 - val_acc: 0.2444\n",
      "Epoch 3774/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3702 - acc: 0.2079 - val_loss: 0.4516 - val_acc: 0.2444\n",
      "Epoch 3775/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3705 - acc: 0.2083 - val_loss: 0.4202 - val_acc: 0.2444\n",
      "Epoch 3776/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3583 - acc: 0.2087 - val_loss: 0.4305 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3777/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3704 - acc: 0.2083 - val_loss: 0.4312 - val_acc: 0.2444\n",
      "Epoch 3778/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3948 - acc: 0.2087 - val_loss: 0.4030 - val_acc: 0.2444\n",
      "Epoch 3779/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.3630 - acc: 0.2079 - val_loss: 0.4438 - val_acc: 0.2444\n",
      "Epoch 3780/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4249 - acc: 0.2079 - val_loss: 0.4833 - val_acc: 0.2444\n",
      "Epoch 3781/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3692 - acc: 0.2075 - val_loss: 0.4472 - val_acc: 0.2444\n",
      "Epoch 3782/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3842 - acc: 0.2075 - val_loss: 0.4140 - val_acc: 0.2444\n",
      "Epoch 3783/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4284 - acc: 0.2071 - val_loss: 0.4428 - val_acc: 0.2444\n",
      "Epoch 3784/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3550 - acc: 0.2079 - val_loss: 0.4586 - val_acc: 0.2444\n",
      "Epoch 3785/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3890 - acc: 0.2075 - val_loss: 0.4420 - val_acc: 0.2444\n",
      "Epoch 3786/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3828 - acc: 0.2083 - val_loss: 0.8117 - val_acc: 0.2407\n",
      "Epoch 3787/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3981 - acc: 0.2079 - val_loss: 0.4160 - val_acc: 0.2444\n",
      "Epoch 3788/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3844 - acc: 0.2079 - val_loss: 0.4377 - val_acc: 0.2444\n",
      "Epoch 3789/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3809 - acc: 0.2075 - val_loss: 0.5102 - val_acc: 0.2407\n",
      "Epoch 3790/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3704 - acc: 0.2079 - val_loss: 0.5122 - val_acc: 0.2407\n",
      "Epoch 3791/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3567 - acc: 0.2087 - val_loss: 0.4284 - val_acc: 0.2444\n",
      "Epoch 3792/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3822 - acc: 0.2087 - val_loss: 0.5195 - val_acc: 0.2407\n",
      "Epoch 3793/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3927 - acc: 0.2083 - val_loss: 0.4311 - val_acc: 0.2444\n",
      "Epoch 3794/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3664 - acc: 0.2083 - val_loss: 0.4460 - val_acc: 0.2444\n",
      "Epoch 3795/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3878 - acc: 0.2083 - val_loss: 0.4623 - val_acc: 0.2444\n",
      "Epoch 3796/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3705 - acc: 0.2079 - val_loss: 0.4473 - val_acc: 0.2444\n",
      "Epoch 3797/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3650 - acc: 0.2079 - val_loss: 0.5489 - val_acc: 0.2444\n",
      "Epoch 3798/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3687 - acc: 0.2083 - val_loss: 0.4447 - val_acc: 0.2444\n",
      "Epoch 3799/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3749 - acc: 0.2075 - val_loss: 0.4353 - val_acc: 0.2444\n",
      "Epoch 3800/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3757 - acc: 0.2087 - val_loss: 0.4174 - val_acc: 0.2444\n",
      "Epoch 3801/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3697 - acc: 0.2075 - val_loss: 0.5628 - val_acc: 0.2407\n",
      "Epoch 3802/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3839 - acc: 0.2083 - val_loss: 0.4583 - val_acc: 0.2444\n",
      "Epoch 3803/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3971 - acc: 0.2079 - val_loss: 0.4368 - val_acc: 0.2444\n",
      "Epoch 3804/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3806 - acc: 0.2075 - val_loss: 0.4403 - val_acc: 0.2444\n",
      "Epoch 3805/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3621 - acc: 0.2079 - val_loss: 0.4829 - val_acc: 0.2444\n",
      "Epoch 3806/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3656 - acc: 0.2079 - val_loss: 0.4085 - val_acc: 0.2444\n",
      "Epoch 3807/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3863 - acc: 0.2083 - val_loss: 0.4845 - val_acc: 0.2444\n",
      "Epoch 3808/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3651 - acc: 0.2092 - val_loss: 0.4259 - val_acc: 0.2444\n",
      "Epoch 3809/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3827 - acc: 0.2079 - val_loss: 0.4852 - val_acc: 0.2444\n",
      "Epoch 3810/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3901 - acc: 0.2079 - val_loss: 0.4179 - val_acc: 0.2444\n",
      "Epoch 3811/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3678 - acc: 0.2075 - val_loss: 0.4509 - val_acc: 0.2444\n",
      "Epoch 3812/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3903 - acc: 0.2075 - val_loss: 0.4293 - val_acc: 0.2444\n",
      "Epoch 3813/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3945 - acc: 0.2087 - val_loss: 0.4375 - val_acc: 0.2444\n",
      "Epoch 3814/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3748 - acc: 0.2079 - val_loss: 0.4447 - val_acc: 0.2444\n",
      "Epoch 3815/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3821 - acc: 0.2067 - val_loss: 0.4503 - val_acc: 0.2444\n",
      "Epoch 3816/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3926 - acc: 0.2079 - val_loss: 0.4296 - val_acc: 0.2444\n",
      "Epoch 3817/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3644 - acc: 0.2079 - val_loss: 0.4208 - val_acc: 0.2444\n",
      "Epoch 3818/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4239 - acc: 0.2087 - val_loss: 0.4243 - val_acc: 0.2444\n",
      "Epoch 3819/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3916 - acc: 0.2071 - val_loss: 0.4168 - val_acc: 0.2444\n",
      "Epoch 3820/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3706 - acc: 0.2083 - val_loss: 0.4422 - val_acc: 0.2444\n",
      "Epoch 3821/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3601 - acc: 0.2083 - val_loss: 0.4129 - val_acc: 0.2444\n",
      "Epoch 3822/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3770 - acc: 0.2083 - val_loss: 0.4464 - val_acc: 0.2444\n",
      "Epoch 3823/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3622 - acc: 0.2083 - val_loss: 0.4278 - val_acc: 0.2444\n",
      "Epoch 3824/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4537 - acc: 0.2075 - val_loss: 0.5968 - val_acc: 0.2444\n",
      "Epoch 3825/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3905 - acc: 0.2087 - val_loss: 0.4549 - val_acc: 0.2444\n",
      "Epoch 3826/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3792 - acc: 0.2079 - val_loss: 0.4964 - val_acc: 0.2444\n",
      "Epoch 3827/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3819 - acc: 0.2079 - val_loss: 0.4752 - val_acc: 0.2444\n",
      "Epoch 3828/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3615 - acc: 0.2079 - val_loss: 0.4062 - val_acc: 0.2444\n",
      "Epoch 3829/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4002 - acc: 0.2083 - val_loss: 0.4152 - val_acc: 0.2444\n",
      "Epoch 3830/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3662 - acc: 0.2079 - val_loss: 0.4891 - val_acc: 0.2444\n",
      "Epoch 3831/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3592 - acc: 0.2083 - val_loss: 0.4082 - val_acc: 0.2444\n",
      "Epoch 3832/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3802 - acc: 0.2087 - val_loss: 0.4201 - val_acc: 0.2444\n",
      "Epoch 3833/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3682 - acc: 0.2083 - val_loss: 0.5118 - val_acc: 0.2444\n",
      "Epoch 3834/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3867 - acc: 0.2083 - val_loss: 0.4560 - val_acc: 0.2444\n",
      "Epoch 3835/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3698 - acc: 0.2083 - val_loss: 0.4463 - val_acc: 0.2444\n",
      "Epoch 3836/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3686 - acc: 0.2079 - val_loss: 0.4353 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3837/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3691 - acc: 0.2079 - val_loss: 0.4554 - val_acc: 0.2444\n",
      "Epoch 3838/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3867 - acc: 0.2083 - val_loss: 0.5343 - val_acc: 0.2444\n",
      "Epoch 3839/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3638 - acc: 0.2079 - val_loss: 0.4335 - val_acc: 0.2444\n",
      "Epoch 3840/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3764 - acc: 0.2079 - val_loss: 0.4220 - val_acc: 0.2444\n",
      "Epoch 3841/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4009 - acc: 0.2075 - val_loss: 0.4338 - val_acc: 0.2444\n",
      "Epoch 3842/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3736 - acc: 0.2083 - val_loss: 0.4708 - val_acc: 0.2444\n",
      "Epoch 3843/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3663 - acc: 0.2079 - val_loss: 0.4399 - val_acc: 0.2444\n",
      "Epoch 3844/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3618 - acc: 0.2079 - val_loss: 0.4576 - val_acc: 0.2444\n",
      "Epoch 3845/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3777 - acc: 0.2083 - val_loss: 0.4275 - val_acc: 0.2444\n",
      "Epoch 3846/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3610 - acc: 0.2079 - val_loss: 0.4602 - val_acc: 0.2444\n",
      "Epoch 3847/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3620 - acc: 0.2079 - val_loss: 0.5024 - val_acc: 0.2444\n",
      "Epoch 3848/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4105 - acc: 0.2063 - val_loss: 0.5830 - val_acc: 0.2407\n",
      "Epoch 3849/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3859 - acc: 0.2083 - val_loss: 0.4229 - val_acc: 0.2444\n",
      "Epoch 3850/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3659 - acc: 0.2083 - val_loss: 0.4473 - val_acc: 0.2444\n",
      "Epoch 3851/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3653 - acc: 0.2083 - val_loss: 0.4178 - val_acc: 0.2444\n",
      "Epoch 3852/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3756 - acc: 0.2075 - val_loss: 0.4969 - val_acc: 0.2444\n",
      "Epoch 3853/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3718 - acc: 0.2083 - val_loss: 0.4154 - val_acc: 0.2444\n",
      "Epoch 3854/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3521 - acc: 0.2075 - val_loss: 0.4343 - val_acc: 0.2444\n",
      "Epoch 3855/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3645 - acc: 0.2079 - val_loss: 0.4602 - val_acc: 0.2444\n",
      "Epoch 3856/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3858 - acc: 0.2071 - val_loss: 0.4582 - val_acc: 0.2444\n",
      "Epoch 3857/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3847 - acc: 0.2079 - val_loss: 0.4144 - val_acc: 0.2444\n",
      "Epoch 3858/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3875 - acc: 0.2079 - val_loss: 0.4903 - val_acc: 0.2444\n",
      "Epoch 3859/10000\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.3656 - acc: 0.207 - 2s 33ms/step - loss: 0.3659 - acc: 0.2079 - val_loss: 0.4375 - val_acc: 0.2444\n",
      "Epoch 3860/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3797 - acc: 0.2083 - val_loss: 0.4228 - val_acc: 0.2444\n",
      "Epoch 3861/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3873 - acc: 0.2079 - val_loss: 0.4177 - val_acc: 0.2444\n",
      "Epoch 3862/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3902 - acc: 0.2087 - val_loss: 0.4718 - val_acc: 0.2444\n",
      "Epoch 3863/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3970 - acc: 0.2079 - val_loss: 0.4087 - val_acc: 0.2444\n",
      "Epoch 3864/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3605 - acc: 0.2087 - val_loss: 0.4849 - val_acc: 0.2444\n",
      "Epoch 3865/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3817 - acc: 0.2075 - val_loss: 0.4054 - val_acc: 0.2444\n",
      "Epoch 3866/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3649 - acc: 0.2079 - val_loss: 0.4397 - val_acc: 0.2444\n",
      "Epoch 3867/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3765 - acc: 0.2083 - val_loss: 0.4118 - val_acc: 0.2444\n",
      "Epoch 3868/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3607 - acc: 0.2083 - val_loss: 0.4919 - val_acc: 0.2444\n",
      "Epoch 3869/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3758 - acc: 0.2083 - val_loss: 0.4288 - val_acc: 0.2444\n",
      "Epoch 3870/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3826 - acc: 0.2079 - val_loss: 0.4691 - val_acc: 0.2444\n",
      "Epoch 3871/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3619 - acc: 0.2083 - val_loss: 0.4775 - val_acc: 0.2444\n",
      "Epoch 3872/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3836 - acc: 0.2079 - val_loss: 0.5991 - val_acc: 0.2407\n",
      "Epoch 3873/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3988 - acc: 0.2087 - val_loss: 0.4083 - val_acc: 0.2444\n",
      "Epoch 3874/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3609 - acc: 0.2079 - val_loss: 0.4233 - val_acc: 0.2444\n",
      "Epoch 3875/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3716 - acc: 0.2079 - val_loss: 0.4335 - val_acc: 0.2444\n",
      "Epoch 3876/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4011 - acc: 0.2083 - val_loss: 0.4434 - val_acc: 0.2444\n",
      "Epoch 3877/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3890 - acc: 0.2071 - val_loss: 0.4047 - val_acc: 0.2444\n",
      "Epoch 3878/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3741 - acc: 0.2083 - val_loss: 0.4250 - val_acc: 0.2444\n",
      "Epoch 3879/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3651 - acc: 0.2083 - val_loss: 0.4218 - val_acc: 0.2444\n",
      "Epoch 3880/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3765 - acc: 0.2079 - val_loss: 0.4415 - val_acc: 0.2444\n",
      "Epoch 3881/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3740 - acc: 0.2083 - val_loss: 0.4177 - val_acc: 0.2444\n",
      "Epoch 3882/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3677 - acc: 0.2079 - val_loss: 0.4347 - val_acc: 0.2444\n",
      "Epoch 3883/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3570 - acc: 0.2083 - val_loss: 0.4051 - val_acc: 0.2444\n",
      "Epoch 3884/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3620 - acc: 0.2075 - val_loss: 0.4173 - val_acc: 0.2444\n",
      "Epoch 3885/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3952 - acc: 0.2079 - val_loss: 0.4907 - val_acc: 0.2444\n",
      "Epoch 3886/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3790 - acc: 0.2083 - val_loss: 0.5504 - val_acc: 0.2444\n",
      "Epoch 3887/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3810 - acc: 0.2083 - val_loss: 0.4388 - val_acc: 0.2444\n",
      "Epoch 3888/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3588 - acc: 0.2079 - val_loss: 0.4338 - val_acc: 0.2444\n",
      "Epoch 3889/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4060 - acc: 0.2079 - val_loss: 0.4546 - val_acc: 0.2444\n",
      "Epoch 3890/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3739 - acc: 0.2083 - val_loss: 0.5089 - val_acc: 0.2444\n",
      "Epoch 3891/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3891 - acc: 0.2087 - val_loss: 0.4622 - val_acc: 0.2444\n",
      "Epoch 3892/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4125 - acc: 0.2075 - val_loss: 0.4133 - val_acc: 0.2444\n",
      "Epoch 3893/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3920 - acc: 0.2079 - val_loss: 0.4062 - val_acc: 0.2444\n",
      "Epoch 3894/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3894 - acc: 0.2083 - val_loss: 0.7688 - val_acc: 0.2444\n",
      "Epoch 3895/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3888 - acc: 0.2083 - val_loss: 0.4915 - val_acc: 0.2444\n",
      "Epoch 3896/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3856 - acc: 0.2083 - val_loss: 0.4216 - val_acc: 0.2444\n",
      "Epoch 3897/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4061 - acc: 0.2079 - val_loss: 0.5058 - val_acc: 0.2444\n",
      "Epoch 3898/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3537 - acc: 0.2079 - val_loss: 0.4166 - val_acc: 0.2444\n",
      "Epoch 3899/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3646 - acc: 0.2087 - val_loss: 0.4039 - val_acc: 0.2444\n",
      "Epoch 3900/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3983 - acc: 0.2075 - val_loss: 0.4561 - val_acc: 0.2444\n",
      "Epoch 3901/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3619 - acc: 0.2083 - val_loss: 0.4419 - val_acc: 0.2444\n",
      "Epoch 3902/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3658 - acc: 0.2075 - val_loss: 0.4352 - val_acc: 0.2444\n",
      "Epoch 3903/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3559 - acc: 0.2075 - val_loss: 0.4625 - val_acc: 0.2444\n",
      "Epoch 3904/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3800 - acc: 0.2071 - val_loss: 0.4441 - val_acc: 0.2444\n",
      "Epoch 3905/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3613 - acc: 0.2079 - val_loss: 0.4138 - val_acc: 0.2444\n",
      "Epoch 3906/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3636 - acc: 0.2083 - val_loss: 0.4581 - val_acc: 0.2444\n",
      "Epoch 3907/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3887 - acc: 0.2079 - val_loss: 0.4250 - val_acc: 0.2444\n",
      "Epoch 3908/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3550 - acc: 0.2079 - val_loss: 0.4126 - val_acc: 0.2444\n",
      "Epoch 3909/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3700 - acc: 0.2079 - val_loss: 0.5004 - val_acc: 0.2444\n",
      "Epoch 3910/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3777 - acc: 0.2083 - val_loss: 0.4350 - val_acc: 0.2444\n",
      "Epoch 3911/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.3704 - acc: 0.2079 - val_loss: 0.4138 - val_acc: 0.2444\n",
      "Epoch 3912/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3678 - acc: 0.2079 - val_loss: 0.4338 - val_acc: 0.2444\n",
      "Epoch 3913/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4052 - acc: 0.2075 - val_loss: 0.4252 - val_acc: 0.2444\n",
      "Epoch 3914/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3561 - acc: 0.2083 - val_loss: 0.4781 - val_acc: 0.2444\n",
      "Epoch 3915/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3940 - acc: 0.2083 - val_loss: 0.4424 - val_acc: 0.2444\n",
      "Epoch 3916/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3559 - acc: 0.2075 - val_loss: 0.4636 - val_acc: 0.2444\n",
      "Epoch 3917/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3694 - acc: 0.2087 - val_loss: 0.4304 - val_acc: 0.2444\n",
      "Epoch 3918/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3743 - acc: 0.2079 - val_loss: 0.4526 - val_acc: 0.2444\n",
      "Epoch 3919/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3657 - acc: 0.2079 - val_loss: 0.4383 - val_acc: 0.2444\n",
      "Epoch 3920/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3838 - acc: 0.2083 - val_loss: 0.4032 - val_acc: 0.2444\n",
      "Epoch 3921/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3730 - acc: 0.2083 - val_loss: 0.4158 - val_acc: 0.2444\n",
      "Epoch 3922/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3770 - acc: 0.2079 - val_loss: 0.4228 - val_acc: 0.2444\n",
      "Epoch 3923/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3808 - acc: 0.2071 - val_loss: 0.4720 - val_acc: 0.2444\n",
      "Epoch 3924/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3771 - acc: 0.2079 - val_loss: 0.5312 - val_acc: 0.2407\n",
      "Epoch 3925/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3849 - acc: 0.2071 - val_loss: 0.4252 - val_acc: 0.2444\n",
      "Epoch 3926/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3891 - acc: 0.2087 - val_loss: 0.4984 - val_acc: 0.2444\n",
      "Epoch 3927/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3843 - acc: 0.2079 - val_loss: 0.4792 - val_acc: 0.2444\n",
      "Epoch 3928/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3731 - acc: 0.2071 - val_loss: 0.5312 - val_acc: 0.2407\n",
      "Epoch 3929/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3695 - acc: 0.2079 - val_loss: 0.4565 - val_acc: 0.2444\n",
      "Epoch 3930/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3582 - acc: 0.2083 - val_loss: 0.4414 - val_acc: 0.2444\n",
      "Epoch 3931/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3603 - acc: 0.2087 - val_loss: 0.4435 - val_acc: 0.2444\n",
      "Epoch 3932/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3963 - acc: 0.2075 - val_loss: 0.4471 - val_acc: 0.2444\n",
      "Epoch 3933/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4779 - acc: 0.2067 - val_loss: 0.5784 - val_acc: 0.2444\n",
      "Epoch 3934/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3993 - acc: 0.2079 - val_loss: 0.5035 - val_acc: 0.2444\n",
      "Epoch 3935/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4159 - acc: 0.2083 - val_loss: 0.4352 - val_acc: 0.2444\n",
      "Epoch 3936/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3744 - acc: 0.2071 - val_loss: 0.4724 - val_acc: 0.2444\n",
      "Epoch 3937/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3724 - acc: 0.2083 - val_loss: 0.4455 - val_acc: 0.2444\n",
      "Epoch 3938/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3589 - acc: 0.2075 - val_loss: 0.4771 - val_acc: 0.2444\n",
      "Epoch 3939/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3908 - acc: 0.2071 - val_loss: 0.4516 - val_acc: 0.2444\n",
      "Epoch 3940/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3448 - acc: 0.2083 - val_loss: 0.4276 - val_acc: 0.2444\n",
      "Epoch 3941/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3620 - acc: 0.2083 - val_loss: 0.4228 - val_acc: 0.2444\n",
      "Epoch 3942/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3771 - acc: 0.2087 - val_loss: 0.6890 - val_acc: 0.2444\n",
      "Epoch 3943/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3634 - acc: 0.2083 - val_loss: 0.4222 - val_acc: 0.2444\n",
      "Epoch 3944/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3641 - acc: 0.2087 - val_loss: 0.4715 - val_acc: 0.2444\n",
      "Epoch 3945/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3623 - acc: 0.2079 - val_loss: 0.4232 - val_acc: 0.2444\n",
      "Epoch 3946/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3800 - acc: 0.2079 - val_loss: 0.6389 - val_acc: 0.2444\n",
      "Epoch 3947/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3806 - acc: 0.2083 - val_loss: 0.4464 - val_acc: 0.2444\n",
      "Epoch 3948/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3688 - acc: 0.2079 - val_loss: 0.5106 - val_acc: 0.2444\n",
      "Epoch 3949/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3755 - acc: 0.2083 - val_loss: 0.4182 - val_acc: 0.2444\n",
      "Epoch 3950/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3623 - acc: 0.2083 - val_loss: 0.4255 - val_acc: 0.2444\n",
      "Epoch 3951/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3975 - acc: 0.2079 - val_loss: 0.6152 - val_acc: 0.2407\n",
      "Epoch 3952/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3838 - acc: 0.2087 - val_loss: 0.4055 - val_acc: 0.2444\n",
      "Epoch 3953/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3629 - acc: 0.2079 - val_loss: 0.4282 - val_acc: 0.2444\n",
      "Epoch 3954/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3544 - acc: 0.2083 - val_loss: 0.4336 - val_acc: 0.2444\n",
      "Epoch 3955/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3712 - acc: 0.2079 - val_loss: 0.4047 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3956/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3819 - acc: 0.2075 - val_loss: 0.4122 - val_acc: 0.2444\n",
      "Epoch 3957/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3929 - acc: 0.2075 - val_loss: 0.4212 - val_acc: 0.2444\n",
      "Epoch 3958/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3657 - acc: 0.2087 - val_loss: 0.4287 - val_acc: 0.2444\n",
      "Epoch 3959/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3802 - acc: 0.2083 - val_loss: 0.6127 - val_acc: 0.2444\n",
      "Epoch 3960/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3648 - acc: 0.2083 - val_loss: 0.4247 - val_acc: 0.2444\n",
      "Epoch 3961/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3555 - acc: 0.2083 - val_loss: 0.4848 - val_acc: 0.2444\n",
      "Epoch 3962/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3765 - acc: 0.2083 - val_loss: 0.4230 - val_acc: 0.2444\n",
      "Epoch 3963/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3664 - acc: 0.2083 - val_loss: 0.4558 - val_acc: 0.2444\n",
      "Epoch 3964/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3895 - acc: 0.2083 - val_loss: 0.4420 - val_acc: 0.2444\n",
      "Epoch 3965/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.3587 - acc: 0.2087 - val_loss: 0.4159 - val_acc: 0.2444\n",
      "Epoch 3966/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3609 - acc: 0.2079 - val_loss: 0.4073 - val_acc: 0.2444\n",
      "Epoch 3967/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3645 - acc: 0.2079 - val_loss: 0.4509 - val_acc: 0.2444\n",
      "Epoch 3968/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3705 - acc: 0.2079 - val_loss: 0.4244 - val_acc: 0.2444\n",
      "Epoch 3969/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3580 - acc: 0.2079 - val_loss: 0.6413 - val_acc: 0.2407\n",
      "Epoch 3970/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3773 - acc: 0.2075 - val_loss: 0.4245 - val_acc: 0.2444\n",
      "Epoch 3971/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3673 - acc: 0.2079 - val_loss: 0.4245 - val_acc: 0.2444\n",
      "Epoch 3972/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3872 - acc: 0.2087 - val_loss: 0.4935 - val_acc: 0.2444\n",
      "Epoch 3973/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3530 - acc: 0.2079 - val_loss: 0.4158 - val_acc: 0.2444\n",
      "Epoch 3974/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3756 - acc: 0.2083 - val_loss: 0.4316 - val_acc: 0.2444\n",
      "Epoch 3975/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3591 - acc: 0.2079 - val_loss: 0.4750 - val_acc: 0.2444\n",
      "Epoch 3976/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3787 - acc: 0.2083 - val_loss: 0.4493 - val_acc: 0.2444\n",
      "Epoch 3977/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3992 - acc: 0.2087 - val_loss: 0.5072 - val_acc: 0.2407\n",
      "Epoch 3978/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.3892 - acc: 0.2083 - val_loss: 0.4298 - val_acc: 0.2444\n",
      "Epoch 3979/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3748 - acc: 0.2079 - val_loss: 0.4076 - val_acc: 0.2444\n",
      "Epoch 3980/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3655 - acc: 0.2083 - val_loss: 0.4377 - val_acc: 0.2444\n",
      "Epoch 3981/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3977 - acc: 0.2083 - val_loss: 0.4292 - val_acc: 0.2444\n",
      "Epoch 3982/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3642 - acc: 0.2083 - val_loss: 0.5436 - val_acc: 0.2444\n",
      "Epoch 3983/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3692 - acc: 0.2083 - val_loss: 0.4260 - val_acc: 0.2444\n",
      "Epoch 3984/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3638 - acc: 0.2087 - val_loss: 0.4357 - val_acc: 0.2444\n",
      "Epoch 3985/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3689 - acc: 0.2087 - val_loss: 0.4329 - val_acc: 0.2444\n",
      "Epoch 3986/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3696 - acc: 0.2079 - val_loss: 0.4632 - val_acc: 0.2444\n",
      "Epoch 3987/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3624 - acc: 0.2083 - val_loss: 0.4395 - val_acc: 0.2444\n",
      "Epoch 3988/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3608 - acc: 0.2083 - val_loss: 0.4161 - val_acc: 0.2444\n",
      "Epoch 3989/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3619 - acc: 0.2087 - val_loss: 0.4513 - val_acc: 0.2444\n",
      "Epoch 3990/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.3727 - acc: 0.2079 - val_loss: 0.4405 - val_acc: 0.2444\n",
      "Epoch 3991/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3603 - acc: 0.2079 - val_loss: 0.4584 - val_acc: 0.2444\n",
      "Epoch 3992/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4087 - acc: 0.2079 - val_loss: 0.5074 - val_acc: 0.2444\n",
      "Epoch 3993/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3759 - acc: 0.2079 - val_loss: 0.4443 - val_acc: 0.2444\n",
      "Epoch 3994/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3668 - acc: 0.2092 - val_loss: 0.4085 - val_acc: 0.2444\n",
      "Epoch 3995/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3802 - acc: 0.2079 - val_loss: 0.4235 - val_acc: 0.2444\n",
      "Epoch 3996/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3683 - acc: 0.2087 - val_loss: 0.4684 - val_acc: 0.2444\n",
      "Epoch 3997/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3968 - acc: 0.2075 - val_loss: 0.6343 - val_acc: 0.2407\n",
      "Epoch 3998/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3922 - acc: 0.2079 - val_loss: 0.5589 - val_acc: 0.2407\n",
      "Epoch 3999/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3949 - acc: 0.2083 - val_loss: 0.4424 - val_acc: 0.2444\n",
      "Epoch 4000/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3811 - acc: 0.2092 - val_loss: 0.4457 - val_acc: 0.2444\n",
      "Epoch 4001/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3812 - acc: 0.2083 - val_loss: 0.5575 - val_acc: 0.2444\n",
      "Epoch 4002/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3795 - acc: 0.2079 - val_loss: 0.7664 - val_acc: 0.2444\n",
      "Epoch 4003/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3914 - acc: 0.2079 - val_loss: 0.6425 - val_acc: 0.2444\n",
      "Epoch 4004/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3624 - acc: 0.2083 - val_loss: 0.4280 - val_acc: 0.2444\n",
      "Epoch 4005/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3671 - acc: 0.2083 - val_loss: 0.4336 - val_acc: 0.2444\n",
      "Epoch 4006/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3825 - acc: 0.2083 - val_loss: 0.4951 - val_acc: 0.2444\n",
      "Epoch 4007/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3719 - acc: 0.2087 - val_loss: 0.4193 - val_acc: 0.2444\n",
      "Epoch 4008/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3833 - acc: 0.2079 - val_loss: 0.4828 - val_acc: 0.2444\n",
      "Epoch 4009/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3801 - acc: 0.2079 - val_loss: 0.4338 - val_acc: 0.2444\n",
      "Epoch 4010/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3549 - acc: 0.2083 - val_loss: 0.4266 - val_acc: 0.2444\n",
      "Epoch 4011/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3627 - acc: 0.2083 - val_loss: 0.4295 - val_acc: 0.2444\n",
      "Epoch 4012/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3821 - acc: 0.2083 - val_loss: 0.4146 - val_acc: 0.2444\n",
      "Epoch 4013/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3612 - acc: 0.2079 - val_loss: 0.5028 - val_acc: 0.2444\n",
      "Epoch 4014/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3788 - acc: 0.2079 - val_loss: 0.5184 - val_acc: 0.2444\n",
      "Epoch 4015/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3700 - acc: 0.2087 - val_loss: 0.4379 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4016/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3653 - acc: 0.2071 - val_loss: 0.4200 - val_acc: 0.2444\n",
      "Epoch 4017/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3557 - acc: 0.2075 - val_loss: 0.4432 - val_acc: 0.2444\n",
      "Epoch 4018/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3608 - acc: 0.2075 - val_loss: 0.4115 - val_acc: 0.2444\n",
      "Epoch 4019/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3573 - acc: 0.2083 - val_loss: 0.4244 - val_acc: 0.2444\n",
      "Epoch 4020/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3659 - acc: 0.2083 - val_loss: 0.4529 - val_acc: 0.2444\n",
      "Epoch 4021/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3839 - acc: 0.2087 - val_loss: 0.4374 - val_acc: 0.2444\n",
      "Epoch 4022/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3958 - acc: 0.2087 - val_loss: 0.4153 - val_acc: 0.2444\n",
      "Epoch 4023/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3761 - acc: 0.2075 - val_loss: 0.4426 - val_acc: 0.2444\n",
      "Epoch 4024/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3812 - acc: 0.2075 - val_loss: 0.4180 - val_acc: 0.2444\n",
      "Epoch 4025/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3726 - acc: 0.2075 - val_loss: 0.4224 - val_acc: 0.2444\n",
      "Epoch 4026/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4007 - acc: 0.2079 - val_loss: 0.4509 - val_acc: 0.2444\n",
      "Epoch 4027/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3796 - acc: 0.2087 - val_loss: 0.4129 - val_acc: 0.2444\n",
      "Epoch 4028/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3553 - acc: 0.2083 - val_loss: 0.4565 - val_acc: 0.2444\n",
      "Epoch 4029/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3630 - acc: 0.2083 - val_loss: 0.4102 - val_acc: 0.2444\n",
      "Epoch 4030/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3803 - acc: 0.2079 - val_loss: 0.4820 - val_acc: 0.2444\n",
      "Epoch 4031/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4114 - acc: 0.2071 - val_loss: 0.4494 - val_acc: 0.2444\n",
      "Epoch 4032/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3643 - acc: 0.2083 - val_loss: 0.4272 - val_acc: 0.2444\n",
      "Epoch 4033/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3613 - acc: 0.2079 - val_loss: 0.4264 - val_acc: 0.2444\n",
      "Epoch 4034/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3649 - acc: 0.2083 - val_loss: 0.4147 - val_acc: 0.2444\n",
      "Epoch 4035/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3569 - acc: 0.2083 - val_loss: 0.4142 - val_acc: 0.2444\n",
      "Epoch 4036/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3706 - acc: 0.2083 - val_loss: 0.4239 - val_acc: 0.2444\n",
      "Epoch 4037/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3755 - acc: 0.2079 - val_loss: 0.4213 - val_acc: 0.2444\n",
      "Epoch 4038/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3702 - acc: 0.2087 - val_loss: 0.5925 - val_acc: 0.2444\n",
      "Epoch 4039/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3707 - acc: 0.2083 - val_loss: 0.4140 - val_acc: 0.2444\n",
      "Epoch 4040/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3645 - acc: 0.2083 - val_loss: 0.4229 - val_acc: 0.2444\n",
      "Epoch 4041/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3587 - acc: 0.2079 - val_loss: 0.4299 - val_acc: 0.2444\n",
      "Epoch 4042/10000\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 0.3686 - acc: 0.2087 - val_loss: 0.4294 - val_acc: 0.2444\n",
      "Epoch 4043/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3541 - acc: 0.2079 - val_loss: 0.4162 - val_acc: 0.2444\n",
      "Epoch 4044/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3682 - acc: 0.2079 - val_loss: 0.4093 - val_acc: 0.2444\n",
      "Epoch 4045/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4010 - acc: 0.2079 - val_loss: 0.4516 - val_acc: 0.2444\n",
      "Epoch 4046/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3737 - acc: 0.2083 - val_loss: 0.4165 - val_acc: 0.2444\n",
      "Epoch 4047/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3587 - acc: 0.2083 - val_loss: 0.4429 - val_acc: 0.2444\n",
      "Epoch 4048/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3773 - acc: 0.2079 - val_loss: 0.4044 - val_acc: 0.2444\n",
      "Epoch 4049/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3548 - acc: 0.2083 - val_loss: 0.4788 - val_acc: 0.2444\n",
      "Epoch 4050/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3902 - acc: 0.2079 - val_loss: 0.4635 - val_acc: 0.2444\n",
      "Epoch 4051/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4015 - acc: 0.2083 - val_loss: 0.4974 - val_acc: 0.2407\n",
      "Epoch 4052/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3716 - acc: 0.2087 - val_loss: 0.4218 - val_acc: 0.2444\n",
      "Epoch 4053/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3830 - acc: 0.2071 - val_loss: 0.4701 - val_acc: 0.2444\n",
      "Epoch 4054/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3784 - acc: 0.2087 - val_loss: 0.4341 - val_acc: 0.2444\n",
      "Epoch 4055/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3691 - acc: 0.2083 - val_loss: 0.4232 - val_acc: 0.2444\n",
      "Epoch 4056/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3730 - acc: 0.2075 - val_loss: 0.4221 - val_acc: 0.2444\n",
      "Epoch 4057/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3647 - acc: 0.2083 - val_loss: 0.4793 - val_acc: 0.2444\n",
      "Epoch 4058/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3779 - acc: 0.2087 - val_loss: 0.5571 - val_acc: 0.2444\n",
      "Epoch 4059/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3792 - acc: 0.2079 - val_loss: 0.4187 - val_acc: 0.2444\n",
      "Epoch 4060/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3816 - acc: 0.2079 - val_loss: 0.5064 - val_acc: 0.2407\n",
      "Epoch 4061/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3679 - acc: 0.2083 - val_loss: 0.4420 - val_acc: 0.2444\n",
      "Epoch 4062/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3607 - acc: 0.2079 - val_loss: 0.4177 - val_acc: 0.2444\n",
      "Epoch 4063/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3765 - acc: 0.2075 - val_loss: 0.5131 - val_acc: 0.2444\n",
      "Epoch 4064/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3700 - acc: 0.2079 - val_loss: 0.4256 - val_acc: 0.2444\n",
      "Epoch 4065/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3683 - acc: 0.2087 - val_loss: 0.4990 - val_acc: 0.2407\n",
      "Epoch 4066/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3571 - acc: 0.2075 - val_loss: 0.4476 - val_acc: 0.2444\n",
      "Epoch 4067/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3989 - acc: 0.2087 - val_loss: 0.4757 - val_acc: 0.2407\n",
      "Epoch 4068/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3723 - acc: 0.2083 - val_loss: 0.4380 - val_acc: 0.2444\n",
      "Epoch 4069/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3625 - acc: 0.2083 - val_loss: 0.4253 - val_acc: 0.2444\n",
      "Epoch 4070/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3630 - acc: 0.2083 - val_loss: 0.4520 - val_acc: 0.2444\n",
      "Epoch 4071/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3665 - acc: 0.2075 - val_loss: 0.4135 - val_acc: 0.2444\n",
      "Epoch 4072/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3763 - acc: 0.2079 - val_loss: 0.4252 - val_acc: 0.2444\n",
      "Epoch 4073/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3604 - acc: 0.2083 - val_loss: 0.4274 - val_acc: 0.2444\n",
      "Epoch 4074/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4437 - acc: 0.2063 - val_loss: 0.4182 - val_acc: 0.2444\n",
      "Epoch 4075/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4010 - acc: 0.2079 - val_loss: 0.4147 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4076/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4029 - acc: 0.2083 - val_loss: 0.4399 - val_acc: 0.2444\n",
      "Epoch 4077/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3509 - acc: 0.2075 - val_loss: 0.4142 - val_acc: 0.2444\n",
      "Epoch 4078/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3882 - acc: 0.2083 - val_loss: 0.4542 - val_acc: 0.2444\n",
      "Epoch 4079/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3627 - acc: 0.2079 - val_loss: 0.4091 - val_acc: 0.2444\n",
      "Epoch 4080/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3674 - acc: 0.2083 - val_loss: 0.4066 - val_acc: 0.2444\n",
      "Epoch 4081/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3840 - acc: 0.2083 - val_loss: 0.4391 - val_acc: 0.2444\n",
      "Epoch 4082/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3682 - acc: 0.2079 - val_loss: 0.4719 - val_acc: 0.2444\n",
      "Epoch 4083/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3794 - acc: 0.2083 - val_loss: 0.4279 - val_acc: 0.2444\n",
      "Epoch 4084/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3554 - acc: 0.2083 - val_loss: 0.4666 - val_acc: 0.2444\n",
      "Epoch 4085/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3953 - acc: 0.2071 - val_loss: 0.5737 - val_acc: 0.2444\n",
      "Epoch 4086/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3862 - acc: 0.2079 - val_loss: 0.4947 - val_acc: 0.2444\n",
      "Epoch 4087/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3616 - acc: 0.2079 - val_loss: 0.4725 - val_acc: 0.2444\n",
      "Epoch 4088/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3601 - acc: 0.2092 - val_loss: 0.4114 - val_acc: 0.2444\n",
      "Epoch 4089/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3669 - acc: 0.2083 - val_loss: 0.4203 - val_acc: 0.2444\n",
      "Epoch 4090/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3815 - acc: 0.2079 - val_loss: 0.4598 - val_acc: 0.2444\n",
      "Epoch 4091/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3749 - acc: 0.2075 - val_loss: 0.4246 - val_acc: 0.2444\n",
      "Epoch 4092/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3763 - acc: 0.2083 - val_loss: 0.4399 - val_acc: 0.2444\n",
      "Epoch 4093/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3831 - acc: 0.2083 - val_loss: 0.4159 - val_acc: 0.2444\n",
      "Epoch 4094/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3595 - acc: 0.2083 - val_loss: 0.4274 - val_acc: 0.2444\n",
      "Epoch 4095/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3683 - acc: 0.2083 - val_loss: 0.4533 - val_acc: 0.2444\n",
      "Epoch 4096/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3692 - acc: 0.2079 - val_loss: 0.4237 - val_acc: 0.2444\n",
      "Epoch 4097/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3705 - acc: 0.2079 - val_loss: 0.4193 - val_acc: 0.2444\n",
      "Epoch 4098/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3753 - acc: 0.2079 - val_loss: 0.4152 - val_acc: 0.2444\n",
      "Epoch 4099/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3828 - acc: 0.2083 - val_loss: 0.4107 - val_acc: 0.2444\n",
      "Epoch 4100/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3510 - acc: 0.2079 - val_loss: 0.4273 - val_acc: 0.2444\n",
      "Epoch 4101/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3580 - acc: 0.2079 - val_loss: 0.4943 - val_acc: 0.2444\n",
      "Epoch 4102/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4001 - acc: 0.2075 - val_loss: 0.4374 - val_acc: 0.2444\n",
      "Epoch 4103/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3607 - acc: 0.2083 - val_loss: 0.4398 - val_acc: 0.2444\n",
      "Epoch 4104/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3710 - acc: 0.2079 - val_loss: 0.4288 - val_acc: 0.2444\n",
      "Epoch 4105/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3519 - acc: 0.2087 - val_loss: 0.4389 - val_acc: 0.2444\n",
      "Epoch 4106/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3629 - acc: 0.2079 - val_loss: 0.4102 - val_acc: 0.2444\n",
      "Epoch 4107/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3765 - acc: 0.2079 - val_loss: 0.4325 - val_acc: 0.2444\n",
      "Epoch 4108/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3767 - acc: 0.2079 - val_loss: 0.4091 - val_acc: 0.2444\n",
      "Epoch 4109/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3590 - acc: 0.2087 - val_loss: 0.4713 - val_acc: 0.2407\n",
      "Epoch 4110/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3962 - acc: 0.2079 - val_loss: 0.4634 - val_acc: 0.2444\n",
      "Epoch 4111/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3956 - acc: 0.2071 - val_loss: 0.4163 - val_acc: 0.2444\n",
      "Epoch 4112/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3634 - acc: 0.2079 - val_loss: 0.4520 - val_acc: 0.2444\n",
      "Epoch 4113/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3578 - acc: 0.2071 - val_loss: 0.4133 - val_acc: 0.2444\n",
      "Epoch 4114/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3652 - acc: 0.2075 - val_loss: 0.4296 - val_acc: 0.2444\n",
      "Epoch 4115/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3693 - acc: 0.2083 - val_loss: 0.4036 - val_acc: 0.2444\n",
      "Epoch 4116/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3672 - acc: 0.2075 - val_loss: 0.4053 - val_acc: 0.2444\n",
      "Epoch 4117/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3595 - acc: 0.2075 - val_loss: 0.4388 - val_acc: 0.2444\n",
      "Epoch 4118/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3816 - acc: 0.2083 - val_loss: 0.4306 - val_acc: 0.2444\n",
      "Epoch 4119/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3693 - acc: 0.2079 - val_loss: 0.4209 - val_acc: 0.2444\n",
      "Epoch 4120/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3697 - acc: 0.2075 - val_loss: 0.4146 - val_acc: 0.2444\n",
      "Epoch 4121/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3596 - acc: 0.2079 - val_loss: 0.4275 - val_acc: 0.2444\n",
      "Epoch 4122/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4032 - acc: 0.2087 - val_loss: 0.5569 - val_acc: 0.2444\n",
      "Epoch 4123/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3717 - acc: 0.2083 - val_loss: 0.5155 - val_acc: 0.2407\n",
      "Epoch 4124/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3683 - acc: 0.2079 - val_loss: 0.4323 - val_acc: 0.2444\n",
      "Epoch 4125/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3688 - acc: 0.2083 - val_loss: 0.4125 - val_acc: 0.2444\n",
      "Epoch 4126/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3559 - acc: 0.2079 - val_loss: 0.4329 - val_acc: 0.2444\n",
      "Epoch 4127/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3735 - acc: 0.2079 - val_loss: 0.4099 - val_acc: 0.2444\n",
      "Epoch 4128/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3745 - acc: 0.2087 - val_loss: 0.4221 - val_acc: 0.2444\n",
      "Epoch 4129/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3680 - acc: 0.2075 - val_loss: 0.4437 - val_acc: 0.2444\n",
      "Epoch 4130/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3564 - acc: 0.2083 - val_loss: 0.4817 - val_acc: 0.2407\n",
      "Epoch 4131/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3825 - acc: 0.2071 - val_loss: 0.4079 - val_acc: 0.2444\n",
      "Epoch 4132/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3763 - acc: 0.2079 - val_loss: 0.4089 - val_acc: 0.2444\n",
      "Epoch 4133/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3482 - acc: 0.2079 - val_loss: 0.4246 - val_acc: 0.2444\n",
      "Epoch 4134/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4166 - acc: 0.2071 - val_loss: 0.4074 - val_acc: 0.2444\n",
      "Epoch 4135/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3901 - acc: 0.2087 - val_loss: 0.6325 - val_acc: 0.2407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4136/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3909 - acc: 0.2083 - val_loss: 0.4026 - val_acc: 0.2444\n",
      "Epoch 4137/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3723 - acc: 0.2087 - val_loss: 0.4452 - val_acc: 0.2444\n",
      "Epoch 4138/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3800 - acc: 0.2083 - val_loss: 0.4091 - val_acc: 0.2444\n",
      "Epoch 4139/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3489 - acc: 0.2087 - val_loss: 0.4319 - val_acc: 0.2444\n",
      "Epoch 4140/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3575 - acc: 0.2079 - val_loss: 0.4463 - val_acc: 0.2444\n",
      "Epoch 4141/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3843 - acc: 0.2083 - val_loss: 0.4097 - val_acc: 0.2444\n",
      "Epoch 4142/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4067 - acc: 0.2075 - val_loss: 0.4567 - val_acc: 0.2444\n",
      "Epoch 4143/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3707 - acc: 0.2079 - val_loss: 0.4291 - val_acc: 0.2444\n",
      "Epoch 4144/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3839 - acc: 0.2075 - val_loss: 0.4970 - val_acc: 0.2444\n",
      "Epoch 4145/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3794 - acc: 0.2079 - val_loss: 0.3959 - val_acc: 0.2444\n",
      "Epoch 4146/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4179 - acc: 0.2079 - val_loss: 0.4796 - val_acc: 0.2407\n",
      "Epoch 4147/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3636 - acc: 0.2087 - val_loss: 0.4852 - val_acc: 0.2444\n",
      "Epoch 4148/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3558 - acc: 0.2079 - val_loss: 0.4423 - val_acc: 0.2444\n",
      "Epoch 4149/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3677 - acc: 0.2083 - val_loss: 0.4337 - val_acc: 0.2444\n",
      "Epoch 4150/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3525 - acc: 0.2083 - val_loss: 0.4374 - val_acc: 0.2444\n",
      "Epoch 4151/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3696 - acc: 0.2083 - val_loss: 0.4246 - val_acc: 0.2444\n",
      "Epoch 4152/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3699 - acc: 0.2079 - val_loss: 0.4148 - val_acc: 0.2444\n",
      "Epoch 4153/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3756 - acc: 0.2079 - val_loss: 0.4107 - val_acc: 0.2444\n",
      "Epoch 4154/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3538 - acc: 0.2079 - val_loss: 0.5257 - val_acc: 0.2444\n",
      "Epoch 4155/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3648 - acc: 0.2079 - val_loss: 0.4358 - val_acc: 0.2444\n",
      "Epoch 4156/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3615 - acc: 0.2087 - val_loss: 0.4031 - val_acc: 0.2444\n",
      "Epoch 4157/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3713 - acc: 0.2079 - val_loss: 0.4077 - val_acc: 0.2444\n",
      "Epoch 4158/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3661 - acc: 0.2083 - val_loss: 0.4649 - val_acc: 0.2444\n",
      "Epoch 4159/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3686 - acc: 0.2079 - val_loss: 0.5551 - val_acc: 0.2444\n",
      "Epoch 4160/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3748 - acc: 0.2087 - val_loss: 0.4188 - val_acc: 0.2444\n",
      "Epoch 4161/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3721 - acc: 0.2083 - val_loss: 0.4334 - val_acc: 0.2444\n",
      "Epoch 4162/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3700 - acc: 0.2071 - val_loss: 0.4456 - val_acc: 0.2444\n",
      "Epoch 4163/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3772 - acc: 0.2075 - val_loss: 0.5948 - val_acc: 0.2444\n",
      "Epoch 4164/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3641 - acc: 0.2083 - val_loss: 0.4944 - val_acc: 0.2444\n",
      "Epoch 4165/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3576 - acc: 0.2079 - val_loss: 0.4263 - val_acc: 0.2444\n",
      "Epoch 4166/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3597 - acc: 0.2079 - val_loss: 0.5027 - val_acc: 0.2407\n",
      "Epoch 4167/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3595 - acc: 0.2079 - val_loss: 0.4382 - val_acc: 0.2444\n",
      "Epoch 4168/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3575 - acc: 0.2079 - val_loss: 0.5711 - val_acc: 0.2407\n",
      "Epoch 4169/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4038 - acc: 0.2071 - val_loss: 0.5829 - val_acc: 0.2407\n",
      "Epoch 4170/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3741 - acc: 0.2083 - val_loss: 0.4326 - val_acc: 0.2444\n",
      "Epoch 4171/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3916 - acc: 0.2083 - val_loss: 0.5830 - val_acc: 0.2407\n",
      "Epoch 4172/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.3832 - acc: 0.2079 - val_loss: 0.4322 - val_acc: 0.2444\n",
      "Epoch 4173/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.3591 - acc: 0.2083 - val_loss: 0.4395 - val_acc: 0.2444\n",
      "Epoch 4174/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3664 - acc: 0.2087 - val_loss: 0.4239 - val_acc: 0.2444\n",
      "Epoch 4175/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3610 - acc: 0.2083 - val_loss: 0.4262 - val_acc: 0.2444\n",
      "Epoch 4176/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3486 - acc: 0.2083 - val_loss: 0.4067 - val_acc: 0.2444\n",
      "Epoch 4177/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3516 - acc: 0.2083 - val_loss: 0.4494 - val_acc: 0.2444\n",
      "Epoch 4178/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4036 - acc: 0.2083 - val_loss: 0.4634 - val_acc: 0.2444\n",
      "Epoch 4179/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3661 - acc: 0.2083 - val_loss: 0.4143 - val_acc: 0.2444\n",
      "Epoch 4180/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3647 - acc: 0.2079 - val_loss: 0.4171 - val_acc: 0.2444\n",
      "Epoch 4181/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3873 - acc: 0.2079 - val_loss: 0.4336 - val_acc: 0.2444\n",
      "Epoch 4182/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3809 - acc: 0.2079 - val_loss: 0.4927 - val_acc: 0.2444\n",
      "Epoch 4183/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3580 - acc: 0.2075 - val_loss: 0.4208 - val_acc: 0.2444\n",
      "Epoch 4184/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3541 - acc: 0.2079 - val_loss: 0.4231 - val_acc: 0.2444\n",
      "Epoch 4185/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3715 - acc: 0.2087 - val_loss: 0.4502 - val_acc: 0.2444\n",
      "Epoch 4186/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3654 - acc: 0.2087 - val_loss: 0.4456 - val_acc: 0.2444\n",
      "Epoch 4187/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3669 - acc: 0.2075 - val_loss: 0.4066 - val_acc: 0.2444\n",
      "Epoch 4188/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3531 - acc: 0.2083 - val_loss: 0.5123 - val_acc: 0.2407\n",
      "Epoch 4189/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3676 - acc: 0.2087 - val_loss: 0.4147 - val_acc: 0.2444\n",
      "Epoch 4190/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4065 - acc: 0.2075 - val_loss: 0.4267 - val_acc: 0.2444\n",
      "Epoch 4191/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3835 - acc: 0.2079 - val_loss: 0.4345 - val_acc: 0.2444\n",
      "Epoch 4192/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3687 - acc: 0.2079 - val_loss: 0.4330 - val_acc: 0.2444\n",
      "Epoch 4193/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3671 - acc: 0.2075 - val_loss: 0.4330 - val_acc: 0.2444\n",
      "Epoch 4194/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3856 - acc: 0.2079 - val_loss: 0.5692 - val_acc: 0.2407\n",
      "Epoch 4195/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3892 - acc: 0.2079 - val_loss: 0.4304 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4196/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3727 - acc: 0.2092 - val_loss: 0.4503 - val_acc: 0.2444\n",
      "Epoch 4197/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3804 - acc: 0.2071 - val_loss: 0.4248 - val_acc: 0.2444\n",
      "Epoch 4198/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3504 - acc: 0.2083 - val_loss: 0.4441 - val_acc: 0.2444\n",
      "Epoch 4199/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3821 - acc: 0.2075 - val_loss: 0.4311 - val_acc: 0.2444\n",
      "Epoch 4200/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3880 - acc: 0.2083 - val_loss: 0.4512 - val_acc: 0.2444\n",
      "Epoch 4201/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3516 - acc: 0.2075 - val_loss: 0.4641 - val_acc: 0.2444\n",
      "Epoch 4202/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3893 - acc: 0.2079 - val_loss: 0.4283 - val_acc: 0.2444\n",
      "Epoch 4203/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3862 - acc: 0.2071 - val_loss: 0.5191 - val_acc: 0.2407\n",
      "Epoch 4204/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3930 - acc: 0.2087 - val_loss: 0.4376 - val_acc: 0.2444\n",
      "Epoch 4205/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3659 - acc: 0.2083 - val_loss: 0.4097 - val_acc: 0.2444\n",
      "Epoch 4206/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3989 - acc: 0.2075 - val_loss: 0.4852 - val_acc: 0.2444\n",
      "Epoch 4207/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3684 - acc: 0.2083 - val_loss: 0.4057 - val_acc: 0.2444\n",
      "Epoch 4208/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3659 - acc: 0.2087 - val_loss: 0.4101 - val_acc: 0.2444\n",
      "Epoch 4209/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3761 - acc: 0.2071 - val_loss: 0.4219 - val_acc: 0.2444\n",
      "Epoch 4210/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3929 - acc: 0.2079 - val_loss: 0.4589 - val_acc: 0.2444\n",
      "Epoch 4211/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3627 - acc: 0.2079 - val_loss: 0.4099 - val_acc: 0.2444\n",
      "Epoch 4212/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3508 - acc: 0.2083 - val_loss: 0.4160 - val_acc: 0.2444\n",
      "Epoch 4213/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3496 - acc: 0.2071 - val_loss: 0.4173 - val_acc: 0.2444\n",
      "Epoch 4214/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3716 - acc: 0.2087 - val_loss: 0.4439 - val_acc: 0.2444\n",
      "Epoch 4215/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3669 - acc: 0.2075 - val_loss: 0.5204 - val_acc: 0.2407\n",
      "Epoch 4216/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3698 - acc: 0.2083 - val_loss: 0.4260 - val_acc: 0.2444\n",
      "Epoch 4217/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3621 - acc: 0.2075 - val_loss: 0.4315 - val_acc: 0.2444\n",
      "Epoch 4218/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3937 - acc: 0.2083 - val_loss: 0.4071 - val_acc: 0.2444\n",
      "Epoch 4219/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3726 - acc: 0.2079 - val_loss: 0.5212 - val_acc: 0.2444\n",
      "Epoch 4220/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3792 - acc: 0.2087 - val_loss: 0.4718 - val_acc: 0.2444\n",
      "Epoch 4221/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3596 - acc: 0.2083 - val_loss: 0.4228 - val_acc: 0.2444\n",
      "Epoch 4222/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3782 - acc: 0.2079 - val_loss: 0.5572 - val_acc: 0.2407\n",
      "Epoch 4223/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3627 - acc: 0.2079 - val_loss: 0.4621 - val_acc: 0.2444\n",
      "Epoch 4224/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3833 - acc: 0.2071 - val_loss: 0.4563 - val_acc: 0.2444\n",
      "Epoch 4225/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3511 - acc: 0.2079 - val_loss: 0.4410 - val_acc: 0.2444\n",
      "Epoch 4226/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3677 - acc: 0.2075 - val_loss: 0.4469 - val_acc: 0.2444\n",
      "Epoch 4227/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3546 - acc: 0.2083 - val_loss: 0.4385 - val_acc: 0.2444\n",
      "Epoch 4228/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3560 - acc: 0.2083 - val_loss: 0.4245 - val_acc: 0.2444\n",
      "Epoch 4229/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3608 - acc: 0.2083 - val_loss: 0.4233 - val_acc: 0.2444\n",
      "Epoch 4230/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3552 - acc: 0.2079 - val_loss: 0.4389 - val_acc: 0.2444\n",
      "Epoch 4231/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3672 - acc: 0.2075 - val_loss: 0.4625 - val_acc: 0.2444\n",
      "Epoch 4232/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4105 - acc: 0.2071 - val_loss: 0.4118 - val_acc: 0.2444\n",
      "Epoch 4233/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3632 - acc: 0.2092 - val_loss: 0.4325 - val_acc: 0.2444\n",
      "Epoch 4234/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3830 - acc: 0.2083 - val_loss: 0.5706 - val_acc: 0.2444\n",
      "Epoch 4235/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3812 - acc: 0.2083 - val_loss: 0.4185 - val_acc: 0.2444\n",
      "Epoch 4236/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3652 - acc: 0.2083 - val_loss: 0.4810 - val_acc: 0.2444\n",
      "Epoch 4237/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3597 - acc: 0.2083 - val_loss: 0.4711 - val_acc: 0.2444\n",
      "Epoch 4238/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3791 - acc: 0.2079 - val_loss: 0.4440 - val_acc: 0.2444\n",
      "Epoch 4239/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3860 - acc: 0.2079 - val_loss: 0.5311 - val_acc: 0.2444\n",
      "Epoch 4240/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3771 - acc: 0.2083 - val_loss: 0.4045 - val_acc: 0.2444\n",
      "Epoch 4241/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3793 - acc: 0.2083 - val_loss: 0.4166 - val_acc: 0.2444\n",
      "Epoch 4242/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3543 - acc: 0.2087 - val_loss: 0.4075 - val_acc: 0.2444\n",
      "Epoch 4243/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3574 - acc: 0.2087 - val_loss: 0.4956 - val_acc: 0.2444\n",
      "Epoch 4244/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3672 - acc: 0.2087 - val_loss: 0.4042 - val_acc: 0.2444\n",
      "Epoch 4245/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3620 - acc: 0.2079 - val_loss: 0.4110 - val_acc: 0.2444\n",
      "Epoch 4246/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3678 - acc: 0.2083 - val_loss: 0.4127 - val_acc: 0.2444\n",
      "Epoch 4247/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3767 - acc: 0.2079 - val_loss: 0.4517 - val_acc: 0.2444\n",
      "Epoch 4248/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3723 - acc: 0.2092 - val_loss: 0.5585 - val_acc: 0.2444\n",
      "Epoch 4249/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3647 - acc: 0.2083 - val_loss: 0.4098 - val_acc: 0.2444\n",
      "Epoch 4250/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3658 - acc: 0.2087 - val_loss: 0.4800 - val_acc: 0.2444\n",
      "Epoch 4251/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3831 - acc: 0.2071 - val_loss: 0.4028 - val_acc: 0.2444\n",
      "Epoch 4252/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3618 - acc: 0.2079 - val_loss: 0.4426 - val_acc: 0.2444\n",
      "Epoch 4253/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3559 - acc: 0.2083 - val_loss: 0.4055 - val_acc: 0.2444\n",
      "Epoch 4254/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3909 - acc: 0.2083 - val_loss: 0.4206 - val_acc: 0.2444\n",
      "Epoch 4255/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3517 - acc: 0.2083 - val_loss: 0.4085 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4256/10000\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.3665 - acc: 0.208 - 3s 33ms/step - loss: 0.3661 - acc: 0.2087 - val_loss: 0.4560 - val_acc: 0.2444\n",
      "Epoch 4257/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4013 - acc: 0.2083 - val_loss: 0.4350 - val_acc: 0.2444\n",
      "Epoch 4258/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3903 - acc: 0.2079 - val_loss: 0.4155 - val_acc: 0.2444\n",
      "Epoch 4259/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3501 - acc: 0.2083 - val_loss: 0.4111 - val_acc: 0.2444\n",
      "Epoch 4260/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3652 - acc: 0.2083 - val_loss: 0.4244 - val_acc: 0.2444\n",
      "Epoch 4261/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3596 - acc: 0.2075 - val_loss: 0.4140 - val_acc: 0.2444\n",
      "Epoch 4262/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3623 - acc: 0.2079 - val_loss: 0.4386 - val_acc: 0.2444\n",
      "Epoch 4263/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3820 - acc: 0.2083 - val_loss: 0.4114 - val_acc: 0.2444\n",
      "Epoch 4264/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3844 - acc: 0.2079 - val_loss: 0.4711 - val_acc: 0.2444\n",
      "Epoch 4265/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4107 - acc: 0.2087 - val_loss: 0.5141 - val_acc: 0.2407\n",
      "Epoch 4266/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3813 - acc: 0.2079 - val_loss: 0.4164 - val_acc: 0.2444\n",
      "Epoch 4267/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3626 - acc: 0.2079 - val_loss: 0.4253 - val_acc: 0.2444\n",
      "Epoch 4268/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3769 - acc: 0.2087 - val_loss: 0.4862 - val_acc: 0.2444\n",
      "Epoch 4269/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3951 - acc: 0.2071 - val_loss: 0.4212 - val_acc: 0.2444\n",
      "Epoch 4270/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3964 - acc: 0.2075 - val_loss: 0.5568 - val_acc: 0.2407\n",
      "Epoch 4271/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3821 - acc: 0.2079 - val_loss: 0.4165 - val_acc: 0.2444\n",
      "Epoch 4272/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3791 - acc: 0.2083 - val_loss: 0.4262 - val_acc: 0.2444\n",
      "Epoch 4273/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3661 - acc: 0.2079 - val_loss: 0.4070 - val_acc: 0.2444\n",
      "Epoch 4274/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3779 - acc: 0.2087 - val_loss: 0.4226 - val_acc: 0.2444\n",
      "Epoch 4275/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3833 - acc: 0.2083 - val_loss: 0.4415 - val_acc: 0.2444\n",
      "Epoch 4276/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3824 - acc: 0.2079 - val_loss: 0.4379 - val_acc: 0.2444\n",
      "Epoch 4277/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3993 - acc: 0.2083 - val_loss: 0.7157 - val_acc: 0.2444\n",
      "Epoch 4278/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3770 - acc: 0.2083 - val_loss: 0.4547 - val_acc: 0.2444\n",
      "Epoch 4279/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3683 - acc: 0.2075 - val_loss: 0.4577 - val_acc: 0.2444\n",
      "Epoch 4280/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3749 - acc: 0.2083 - val_loss: 0.4811 - val_acc: 0.2444\n",
      "Epoch 4281/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3691 - acc: 0.2075 - val_loss: 0.4452 - val_acc: 0.2444\n",
      "Epoch 4282/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3677 - acc: 0.2083 - val_loss: 0.4181 - val_acc: 0.2444\n",
      "Epoch 4283/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3753 - acc: 0.2092 - val_loss: 0.4257 - val_acc: 0.2444\n",
      "Epoch 4284/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3632 - acc: 0.2087 - val_loss: 0.4503 - val_acc: 0.2444\n",
      "Epoch 4285/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3535 - acc: 0.2075 - val_loss: 0.4326 - val_acc: 0.2444\n",
      "Epoch 4286/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3718 - acc: 0.2079 - val_loss: 0.4413 - val_acc: 0.2444\n",
      "Epoch 4287/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3700 - acc: 0.2079 - val_loss: 0.4238 - val_acc: 0.2444\n",
      "Epoch 4288/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3601 - acc: 0.2079 - val_loss: 0.4407 - val_acc: 0.2444\n",
      "Epoch 4289/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3562 - acc: 0.2087 - val_loss: 0.4235 - val_acc: 0.2444\n",
      "Epoch 4290/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3500 - acc: 0.2087 - val_loss: 0.4275 - val_acc: 0.2444\n",
      "Epoch 4291/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3856 - acc: 0.2075 - val_loss: 0.4010 - val_acc: 0.2444\n",
      "Epoch 4292/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3558 - acc: 0.2083 - val_loss: 0.4272 - val_acc: 0.2444\n",
      "Epoch 4293/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3687 - acc: 0.2079 - val_loss: 0.4252 - val_acc: 0.2444\n",
      "Epoch 4294/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3630 - acc: 0.2079 - val_loss: 0.4996 - val_acc: 0.2407\n",
      "Epoch 4295/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3683 - acc: 0.2075 - val_loss: 0.4633 - val_acc: 0.2444\n",
      "Epoch 4296/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3914 - acc: 0.2087 - val_loss: 0.4988 - val_acc: 0.2407\n",
      "Epoch 4297/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3668 - acc: 0.2083 - val_loss: 0.5742 - val_acc: 0.2444\n",
      "Epoch 4298/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3841 - acc: 0.2083 - val_loss: 0.4232 - val_acc: 0.2444\n",
      "Epoch 4299/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3582 - acc: 0.2079 - val_loss: 0.4010 - val_acc: 0.2444\n",
      "Epoch 4300/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3667 - acc: 0.2079 - val_loss: 0.4539 - val_acc: 0.2444\n",
      "Epoch 4301/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3741 - acc: 0.2075 - val_loss: 0.4312 - val_acc: 0.2444\n",
      "Epoch 4302/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3586 - acc: 0.2075 - val_loss: 0.4161 - val_acc: 0.2444\n",
      "Epoch 4303/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3453 - acc: 0.2087 - val_loss: 0.4161 - val_acc: 0.2444\n",
      "Epoch 4304/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.3547 - acc: 0.2087 - val_loss: 0.4194 - val_acc: 0.2444\n",
      "Epoch 4305/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.4064 - acc: 0.2087 - val_loss: 0.4370 - val_acc: 0.2444\n",
      "Epoch 4306/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3777 - acc: 0.2083 - val_loss: 0.4255 - val_acc: 0.2444\n",
      "Epoch 4307/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3676 - acc: 0.2083 - val_loss: 0.4643 - val_acc: 0.2444\n",
      "Epoch 4308/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3864 - acc: 0.2071 - val_loss: 0.4395 - val_acc: 0.2444\n",
      "Epoch 4309/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3888 - acc: 0.2075 - val_loss: 0.4340 - val_acc: 0.2444\n",
      "Epoch 4310/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3796 - acc: 0.2087 - val_loss: 0.4642 - val_acc: 0.2444\n",
      "Epoch 4311/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3627 - acc: 0.2083 - val_loss: 0.4179 - val_acc: 0.2444\n",
      "Epoch 4312/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3707 - acc: 0.2083 - val_loss: 0.4953 - val_acc: 0.2444\n",
      "Epoch 4313/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3537 - acc: 0.2083 - val_loss: 0.4264 - val_acc: 0.2444\n",
      "Epoch 4314/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3644 - acc: 0.2079 - val_loss: 0.4236 - val_acc: 0.2444\n",
      "Epoch 4315/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3656 - acc: 0.2075 - val_loss: 0.4374 - val_acc: 0.2444\n",
      "Epoch 4316/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3647 - acc: 0.2071 - val_loss: 0.4204 - val_acc: 0.2444\n",
      "Epoch 4317/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3663 - acc: 0.2079 - val_loss: 0.4630 - val_acc: 0.2444\n",
      "Epoch 4318/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3565 - acc: 0.2079 - val_loss: 0.4723 - val_acc: 0.2444\n",
      "Epoch 4319/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3847 - acc: 0.2075 - val_loss: 0.4151 - val_acc: 0.2444\n",
      "Epoch 4320/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3816 - acc: 0.2079 - val_loss: 0.4524 - val_acc: 0.2444\n",
      "Epoch 4321/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3637 - acc: 0.2079 - val_loss: 0.4172 - val_acc: 0.2444\n",
      "Epoch 4322/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3737 - acc: 0.2079 - val_loss: 0.4874 - val_acc: 0.2444\n",
      "Epoch 4323/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3566 - acc: 0.2079 - val_loss: 0.4181 - val_acc: 0.2444\n",
      "Epoch 4324/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3828 - acc: 0.2075 - val_loss: 0.4810 - val_acc: 0.2444\n",
      "Epoch 4325/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3773 - acc: 0.2079 - val_loss: 0.4702 - val_acc: 0.2444\n",
      "Epoch 4326/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3676 - acc: 0.2075 - val_loss: 0.5492 - val_acc: 0.2444\n",
      "Epoch 4327/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4080 - acc: 0.2075 - val_loss: 0.3969 - val_acc: 0.2444\n",
      "Epoch 4328/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3552 - acc: 0.2083 - val_loss: 0.4643 - val_acc: 0.2444\n",
      "Epoch 4329/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3495 - acc: 0.2083 - val_loss: 0.4246 - val_acc: 0.2444\n",
      "Epoch 4330/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3544 - acc: 0.2079 - val_loss: 0.4044 - val_acc: 0.2444\n",
      "Epoch 4331/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3529 - acc: 0.2083 - val_loss: 0.4927 - val_acc: 0.2444\n",
      "Epoch 4332/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3770 - acc: 0.2075 - val_loss: 0.4339 - val_acc: 0.2444\n",
      "Epoch 4333/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3816 - acc: 0.2067 - val_loss: 0.4278 - val_acc: 0.2444\n",
      "Epoch 4334/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3537 - acc: 0.2079 - val_loss: 0.4897 - val_acc: 0.2444\n",
      "Epoch 4335/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3801 - acc: 0.2087 - val_loss: 0.4853 - val_acc: 0.2444\n",
      "Epoch 4336/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3774 - acc: 0.2087 - val_loss: 0.4799 - val_acc: 0.2444\n",
      "Epoch 4337/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4031 - acc: 0.2075 - val_loss: 0.4308 - val_acc: 0.2444\n",
      "Epoch 4338/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3691 - acc: 0.2083 - val_loss: 0.4335 - val_acc: 0.2444\n",
      "Epoch 4339/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3645 - acc: 0.2075 - val_loss: 0.4148 - val_acc: 0.2444\n",
      "Epoch 4340/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3626 - acc: 0.2083 - val_loss: 0.5219 - val_acc: 0.2407\n",
      "Epoch 4341/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3729 - acc: 0.2079 - val_loss: 0.4416 - val_acc: 0.2444\n",
      "Epoch 4342/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3592 - acc: 0.2071 - val_loss: 0.4284 - val_acc: 0.2444\n",
      "Epoch 4343/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3583 - acc: 0.2083 - val_loss: 0.4816 - val_acc: 0.2444\n",
      "Epoch 4344/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3655 - acc: 0.2087 - val_loss: 0.4790 - val_acc: 0.2444\n",
      "Epoch 4345/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3617 - acc: 0.2087 - val_loss: 0.4333 - val_acc: 0.2444\n",
      "Epoch 4346/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3528 - acc: 0.2083 - val_loss: 0.4207 - val_acc: 0.2444\n",
      "Epoch 4347/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3596 - acc: 0.2083 - val_loss: 0.4829 - val_acc: 0.2444\n",
      "Epoch 4348/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3583 - acc: 0.2083 - val_loss: 0.4283 - val_acc: 0.2444\n",
      "Epoch 4349/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4039 - acc: 0.2083 - val_loss: 0.4408 - val_acc: 0.2444\n",
      "Epoch 4350/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3634 - acc: 0.2079 - val_loss: 0.4186 - val_acc: 0.2444\n",
      "Epoch 4351/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3617 - acc: 0.2083 - val_loss: 0.4159 - val_acc: 0.2444\n",
      "Epoch 4352/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3745 - acc: 0.2087 - val_loss: 0.4100 - val_acc: 0.2444\n",
      "Epoch 4353/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.3544 - acc: 0.2083 - val_loss: 0.4327 - val_acc: 0.2444\n",
      "Epoch 4354/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.3664 - acc: 0.2079 - val_loss: 0.4142 - val_acc: 0.2444\n",
      "Epoch 4355/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3643 - acc: 0.2087 - val_loss: 0.4144 - val_acc: 0.2444\n",
      "Epoch 4356/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3671 - acc: 0.2075 - val_loss: 0.4243 - val_acc: 0.2444\n",
      "Epoch 4357/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3894 - acc: 0.2079 - val_loss: 0.4563 - val_acc: 0.2444\n",
      "Epoch 4358/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3773 - acc: 0.2083 - val_loss: 0.6380 - val_acc: 0.2407\n",
      "Epoch 4359/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3903 - acc: 0.2079 - val_loss: 0.4194 - val_acc: 0.2444\n",
      "Epoch 4360/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4006 - acc: 0.2079 - val_loss: 0.4205 - val_acc: 0.2444\n",
      "Epoch 4361/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3868 - acc: 0.2071 - val_loss: 0.4976 - val_acc: 0.2444\n",
      "Epoch 4362/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3488 - acc: 0.2083 - val_loss: 0.4598 - val_acc: 0.2444\n",
      "Epoch 4363/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.3555 - acc: 0.2075 - val_loss: 0.4149 - val_acc: 0.2444\n",
      "Epoch 4364/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3802 - acc: 0.2083 - val_loss: 0.4248 - val_acc: 0.2444\n",
      "Epoch 4365/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3707 - acc: 0.2079 - val_loss: 0.4343 - val_acc: 0.2444\n",
      "Epoch 4366/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3656 - acc: 0.2083 - val_loss: 0.4558 - val_acc: 0.2444\n",
      "Epoch 4367/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3633 - acc: 0.2087 - val_loss: 0.4413 - val_acc: 0.2444\n",
      "Epoch 4368/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3558 - acc: 0.2083 - val_loss: 0.4383 - val_acc: 0.2444\n",
      "Epoch 4369/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3512 - acc: 0.2079 - val_loss: 0.4062 - val_acc: 0.2444\n",
      "Epoch 4370/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3978 - acc: 0.2071 - val_loss: 0.5748 - val_acc: 0.2444\n",
      "Epoch 4371/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3868 - acc: 0.2083 - val_loss: 0.4299 - val_acc: 0.2444\n",
      "Epoch 4372/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3877 - acc: 0.2083 - val_loss: 0.4344 - val_acc: 0.2444\n",
      "Epoch 4373/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3656 - acc: 0.2079 - val_loss: 0.4209 - val_acc: 0.2444\n",
      "Epoch 4374/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3767 - acc: 0.2079 - val_loss: 0.4763 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4375/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4041 - acc: 0.2071 - val_loss: 0.4241 - val_acc: 0.2444\n",
      "Epoch 4376/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3694 - acc: 0.2079 - val_loss: 0.4365 - val_acc: 0.2444\n",
      "Epoch 4377/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3508 - acc: 0.2079 - val_loss: 0.4266 - val_acc: 0.2444\n",
      "Epoch 4378/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3633 - acc: 0.2087 - val_loss: 0.6154 - val_acc: 0.2444\n",
      "Epoch 4379/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4121 - acc: 0.2083 - val_loss: 0.5060 - val_acc: 0.2444\n",
      "Epoch 4380/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3875 - acc: 0.2083 - val_loss: 0.4249 - val_acc: 0.2444\n",
      "Epoch 4381/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3629 - acc: 0.2083 - val_loss: 0.4144 - val_acc: 0.2444\n",
      "Epoch 4382/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3517 - acc: 0.2079 - val_loss: 0.4912 - val_acc: 0.2444\n",
      "Epoch 4383/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3872 - acc: 0.2075 - val_loss: 0.4788 - val_acc: 0.2444\n",
      "Epoch 4384/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3808 - acc: 0.2087 - val_loss: 0.4369 - val_acc: 0.2444\n",
      "Epoch 4385/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3627 - acc: 0.2079 - val_loss: 0.4221 - val_acc: 0.2444\n",
      "Epoch 4386/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3722 - acc: 0.2087 - val_loss: 0.4383 - val_acc: 0.2444\n",
      "Epoch 4387/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3681 - acc: 0.2083 - val_loss: 0.4592 - val_acc: 0.2444\n",
      "Epoch 4388/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3601 - acc: 0.2083 - val_loss: 0.4178 - val_acc: 0.2444\n",
      "Epoch 4389/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3528 - acc: 0.2079 - val_loss: 0.4162 - val_acc: 0.2444\n",
      "Epoch 4390/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3802 - acc: 0.2083 - val_loss: 0.4701 - val_acc: 0.2444\n",
      "Epoch 4391/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3531 - acc: 0.2083 - val_loss: 0.4298 - val_acc: 0.2444\n",
      "Epoch 4392/10000\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.3842 - acc: 0.207 - 2s 32ms/step - loss: 0.3834 - acc: 0.2075 - val_loss: 0.4092 - val_acc: 0.2444\n",
      "Epoch 4393/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3595 - acc: 0.2079 - val_loss: 0.4447 - val_acc: 0.2444\n",
      "Epoch 4394/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3756 - acc: 0.2079 - val_loss: 0.5794 - val_acc: 0.2407\n",
      "Epoch 4395/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3735 - acc: 0.2079 - val_loss: 0.4244 - val_acc: 0.2444\n",
      "Epoch 4396/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3702 - acc: 0.2083 - val_loss: 0.4886 - val_acc: 0.2444\n",
      "Epoch 4397/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3729 - acc: 0.2083 - val_loss: 0.4378 - val_acc: 0.2444\n",
      "Epoch 4398/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3540 - acc: 0.2079 - val_loss: 0.4319 - val_acc: 0.2444\n",
      "Epoch 4399/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3831 - acc: 0.2071 - val_loss: 0.4059 - val_acc: 0.2444\n",
      "Epoch 4400/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3692 - acc: 0.2079 - val_loss: 0.4224 - val_acc: 0.2444\n",
      "Epoch 4401/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3559 - acc: 0.2083 - val_loss: 0.4402 - val_acc: 0.2444\n",
      "Epoch 4402/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3555 - acc: 0.2079 - val_loss: 0.4423 - val_acc: 0.2444\n",
      "Epoch 4403/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3630 - acc: 0.2079 - val_loss: 0.4441 - val_acc: 0.2444\n",
      "Epoch 4404/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3565 - acc: 0.2087 - val_loss: 0.4218 - val_acc: 0.2444\n",
      "Epoch 4405/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3773 - acc: 0.2079 - val_loss: 0.4879 - val_acc: 0.2444\n",
      "Epoch 4406/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3735 - acc: 0.2079 - val_loss: 0.4263 - val_acc: 0.2444\n",
      "Epoch 4407/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3487 - acc: 0.2083 - val_loss: 0.4590 - val_acc: 0.2444\n",
      "Epoch 4408/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3784 - acc: 0.2079 - val_loss: 0.4360 - val_acc: 0.2444\n",
      "Epoch 4409/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3598 - acc: 0.2079 - val_loss: 0.4938 - val_acc: 0.2444\n",
      "Epoch 4410/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3796 - acc: 0.2075 - val_loss: 0.4215 - val_acc: 0.2444\n",
      "Epoch 4411/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3695 - acc: 0.2083 - val_loss: 0.4214 - val_acc: 0.2444\n",
      "Epoch 4412/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3805 - acc: 0.2075 - val_loss: 0.4333 - val_acc: 0.2444\n",
      "Epoch 4413/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3540 - acc: 0.2079 - val_loss: 0.4712 - val_acc: 0.2444\n",
      "Epoch 4414/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3718 - acc: 0.2079 - val_loss: 0.4442 - val_acc: 0.2444\n",
      "Epoch 4415/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3822 - acc: 0.2083 - val_loss: 0.4801 - val_acc: 0.2444\n",
      "Epoch 4416/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3815 - acc: 0.2071 - val_loss: 0.4385 - val_acc: 0.2444\n",
      "Epoch 4417/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3620 - acc: 0.2079 - val_loss: 0.4056 - val_acc: 0.2444\n",
      "Epoch 4418/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3530 - acc: 0.2083 - val_loss: 0.4208 - val_acc: 0.2444\n",
      "Epoch 4419/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3500 - acc: 0.2079 - val_loss: 0.4051 - val_acc: 0.2444\n",
      "Epoch 4420/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3874 - acc: 0.2075 - val_loss: 0.4817 - val_acc: 0.2407\n",
      "Epoch 4421/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3601 - acc: 0.2087 - val_loss: 0.4772 - val_acc: 0.2407\n",
      "Epoch 4422/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3723 - acc: 0.2075 - val_loss: 0.4463 - val_acc: 0.2444\n",
      "Epoch 4423/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3846 - acc: 0.2083 - val_loss: 0.4089 - val_acc: 0.2444\n",
      "Epoch 4424/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3684 - acc: 0.2083 - val_loss: 0.5995 - val_acc: 0.2407\n",
      "Epoch 4425/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4147 - acc: 0.2075 - val_loss: 0.4198 - val_acc: 0.2444\n",
      "Epoch 4426/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3940 - acc: 0.2087 - val_loss: 0.4271 - val_acc: 0.2444\n",
      "Epoch 4427/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3665 - acc: 0.2087 - val_loss: 0.4141 - val_acc: 0.2444\n",
      "Epoch 4428/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3627 - acc: 0.2079 - val_loss: 0.4237 - val_acc: 0.2444\n",
      "Epoch 4429/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3607 - acc: 0.2075 - val_loss: 0.4896 - val_acc: 0.2444\n",
      "Epoch 4430/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3829 - acc: 0.2079 - val_loss: 0.4452 - val_acc: 0.2444\n",
      "Epoch 4431/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3996 - acc: 0.2092 - val_loss: 0.6706 - val_acc: 0.2444\n",
      "Epoch 4432/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3683 - acc: 0.2083 - val_loss: 0.5013 - val_acc: 0.2444\n",
      "Epoch 4433/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3542 - acc: 0.2079 - val_loss: 0.4262 - val_acc: 0.2444\n",
      "Epoch 4434/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3508 - acc: 0.2087 - val_loss: 0.4169 - val_acc: 0.2444\n",
      "Epoch 4435/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3781 - acc: 0.2083 - val_loss: 0.4220 - val_acc: 0.2444\n",
      "Epoch 4436/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3625 - acc: 0.2083 - val_loss: 0.3994 - val_acc: 0.2444\n",
      "Epoch 4437/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.3701 - acc: 0.2079 - val_loss: 0.5140 - val_acc: 0.2444\n",
      "Epoch 4438/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3551 - acc: 0.2083 - val_loss: 0.4319 - val_acc: 0.2444\n",
      "Epoch 4439/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3613 - acc: 0.2083 - val_loss: 0.4293 - val_acc: 0.2444\n",
      "Epoch 4440/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3564 - acc: 0.2087 - val_loss: 0.4089 - val_acc: 0.2444\n",
      "Epoch 4441/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3637 - acc: 0.2083 - val_loss: 0.4443 - val_acc: 0.2444\n",
      "Epoch 4442/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3768 - acc: 0.2083 - val_loss: 0.4199 - val_acc: 0.2444\n",
      "Epoch 4443/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3673 - acc: 0.2083 - val_loss: 0.4250 - val_acc: 0.2444\n",
      "Epoch 4444/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3669 - acc: 0.2083 - val_loss: 0.4143 - val_acc: 0.2444\n",
      "Epoch 4445/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3580 - acc: 0.2083 - val_loss: 0.4384 - val_acc: 0.2444\n",
      "Epoch 4446/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3508 - acc: 0.2083 - val_loss: 0.4194 - val_acc: 0.2444\n",
      "Epoch 4447/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3531 - acc: 0.2079 - val_loss: 0.4258 - val_acc: 0.2444\n",
      "Epoch 4448/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3692 - acc: 0.2083 - val_loss: 0.4849 - val_acc: 0.2444\n",
      "Epoch 4449/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3686 - acc: 0.2071 - val_loss: 0.4280 - val_acc: 0.2444\n",
      "Epoch 4450/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3550 - acc: 0.2079 - val_loss: 0.5222 - val_acc: 0.2407\n",
      "Epoch 4451/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3692 - acc: 0.2071 - val_loss: 0.4292 - val_acc: 0.2444\n",
      "Epoch 4452/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3540 - acc: 0.2083 - val_loss: 0.4493 - val_acc: 0.2444\n",
      "Epoch 4453/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3787 - acc: 0.2071 - val_loss: 0.4973 - val_acc: 0.2444\n",
      "Epoch 4454/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3615 - acc: 0.2075 - val_loss: 0.4052 - val_acc: 0.2444\n",
      "Epoch 4455/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3884 - acc: 0.2087 - val_loss: 0.4259 - val_acc: 0.2444\n",
      "Epoch 4456/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3648 - acc: 0.2079 - val_loss: 0.4237 - val_acc: 0.2444\n",
      "Epoch 4457/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3631 - acc: 0.2079 - val_loss: 0.4358 - val_acc: 0.2444\n",
      "Epoch 4458/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3576 - acc: 0.2075 - val_loss: 0.4220 - val_acc: 0.2444\n",
      "Epoch 4459/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3928 - acc: 0.2087 - val_loss: 0.4015 - val_acc: 0.2444\n",
      "Epoch 4460/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3613 - acc: 0.2079 - val_loss: 0.4904 - val_acc: 0.2444\n",
      "Epoch 4461/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3655 - acc: 0.2083 - val_loss: 0.4341 - val_acc: 0.2444\n",
      "Epoch 4462/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3589 - acc: 0.2079 - val_loss: 0.4421 - val_acc: 0.2444\n",
      "Epoch 4463/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3611 - acc: 0.2083 - val_loss: 0.4432 - val_acc: 0.2444\n",
      "Epoch 4464/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3481 - acc: 0.2087 - val_loss: 0.4273 - val_acc: 0.2444\n",
      "Epoch 4465/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3569 - acc: 0.2087 - val_loss: 0.4243 - val_acc: 0.2444\n",
      "Epoch 4466/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3539 - acc: 0.2087 - val_loss: 0.4168 - val_acc: 0.2444\n",
      "Epoch 4467/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3954 - acc: 0.2079 - val_loss: 0.4202 - val_acc: 0.2444\n",
      "Epoch 4468/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3701 - acc: 0.2087 - val_loss: 0.5371 - val_acc: 0.2407\n",
      "Epoch 4469/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3694 - acc: 0.2087 - val_loss: 0.4701 - val_acc: 0.2444\n",
      "Epoch 4470/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3578 - acc: 0.2087 - val_loss: 0.4047 - val_acc: 0.2444\n",
      "Epoch 4471/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3738 - acc: 0.2087 - val_loss: 0.4173 - val_acc: 0.2444\n",
      "Epoch 4472/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3692 - acc: 0.2083 - val_loss: 0.4476 - val_acc: 0.2444\n",
      "Epoch 4473/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3521 - acc: 0.2083 - val_loss: 0.4059 - val_acc: 0.2444\n",
      "Epoch 4474/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3544 - acc: 0.2087 - val_loss: 0.4227 - val_acc: 0.2444\n",
      "Epoch 4475/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4286 - acc: 0.2079 - val_loss: 0.6200 - val_acc: 0.2407\n",
      "Epoch 4476/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3608 - acc: 0.2083 - val_loss: 0.4855 - val_acc: 0.2444\n",
      "Epoch 4477/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3735 - acc: 0.2079 - val_loss: 0.4014 - val_acc: 0.2444\n",
      "Epoch 4478/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3557 - acc: 0.2083 - val_loss: 0.4196 - val_acc: 0.2444\n",
      "Epoch 4479/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3558 - acc: 0.2083 - val_loss: 0.4193 - val_acc: 0.2444\n",
      "Epoch 4480/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3492 - acc: 0.2079 - val_loss: 0.4334 - val_acc: 0.2444\n",
      "Epoch 4481/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4108 - acc: 0.2075 - val_loss: 0.4235 - val_acc: 0.2444\n",
      "Epoch 4482/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3743 - acc: 0.2079 - val_loss: 0.4267 - val_acc: 0.2444\n",
      "Epoch 4483/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3526 - acc: 0.2083 - val_loss: 0.4325 - val_acc: 0.2444\n",
      "Epoch 4484/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3851 - acc: 0.2083 - val_loss: 0.4357 - val_acc: 0.2444\n",
      "Epoch 4485/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3689 - acc: 0.2075 - val_loss: 0.4343 - val_acc: 0.2444\n",
      "Epoch 4486/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3794 - acc: 0.2079 - val_loss: 0.4024 - val_acc: 0.2444\n",
      "Epoch 4487/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3723 - acc: 0.2075 - val_loss: 0.4073 - val_acc: 0.2444\n",
      "Epoch 4488/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3630 - acc: 0.2087 - val_loss: 0.4248 - val_acc: 0.2444\n",
      "Epoch 4489/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3592 - acc: 0.2079 - val_loss: 0.4561 - val_acc: 0.2444\n",
      "Epoch 4490/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3592 - acc: 0.2079 - val_loss: 0.4231 - val_acc: 0.2444\n",
      "Epoch 4491/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3649 - acc: 0.2083 - val_loss: 0.4240 - val_acc: 0.2444\n",
      "Epoch 4492/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3548 - acc: 0.2083 - val_loss: 0.4015 - val_acc: 0.2444\n",
      "Epoch 4493/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3588 - acc: 0.2079 - val_loss: 0.4822 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4494/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3771 - acc: 0.2083 - val_loss: 0.4474 - val_acc: 0.2444\n",
      "Epoch 4495/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3776 - acc: 0.2079 - val_loss: 0.4204 - val_acc: 0.2444\n",
      "Epoch 4496/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3511 - acc: 0.2083 - val_loss: 0.4137 - val_acc: 0.2444\n",
      "Epoch 4497/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3988 - acc: 0.2075 - val_loss: 0.5000 - val_acc: 0.2444\n",
      "Epoch 4498/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3937 - acc: 0.2083 - val_loss: 0.6286 - val_acc: 0.2407\n",
      "Epoch 4499/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3687 - acc: 0.2079 - val_loss: 0.4066 - val_acc: 0.2444\n",
      "Epoch 4500/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3720 - acc: 0.2079 - val_loss: 0.4638 - val_acc: 0.2444\n",
      "Epoch 4501/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3587 - acc: 0.2087 - val_loss: 0.4499 - val_acc: 0.2444\n",
      "Epoch 4502/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3710 - acc: 0.2083 - val_loss: 0.4213 - val_acc: 0.2444\n",
      "Epoch 4503/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3599 - acc: 0.2079 - val_loss: 0.4712 - val_acc: 0.2444\n",
      "Epoch 4504/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3655 - acc: 0.2087 - val_loss: 0.4193 - val_acc: 0.2444\n",
      "Epoch 4505/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3508 - acc: 0.2092 - val_loss: 0.4829 - val_acc: 0.2444\n",
      "Epoch 4506/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3855 - acc: 0.2083 - val_loss: 0.4466 - val_acc: 0.2444\n",
      "Epoch 4507/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3624 - acc: 0.2087 - val_loss: 0.5055 - val_acc: 0.2444\n",
      "Epoch 4508/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3907 - acc: 0.2071 - val_loss: 0.4788 - val_acc: 0.2444\n",
      "Epoch 4509/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3673 - acc: 0.2083 - val_loss: 0.5251 - val_acc: 0.2444\n",
      "Epoch 4510/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3800 - acc: 0.2079 - val_loss: 0.4084 - val_acc: 0.2444\n",
      "Epoch 4511/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3852 - acc: 0.2087 - val_loss: 0.5164 - val_acc: 0.2407\n",
      "Epoch 4512/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3505 - acc: 0.2079 - val_loss: 0.4374 - val_acc: 0.2444\n",
      "Epoch 4513/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3807 - acc: 0.2079 - val_loss: 0.4186 - val_acc: 0.2444\n",
      "Epoch 4514/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3892 - acc: 0.2083 - val_loss: 0.4340 - val_acc: 0.2444\n",
      "Epoch 4515/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3727 - acc: 0.2071 - val_loss: 0.4137 - val_acc: 0.2444\n",
      "Epoch 4516/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3596 - acc: 0.2079 - val_loss: 0.4451 - val_acc: 0.2444\n",
      "Epoch 4517/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3703 - acc: 0.2083 - val_loss: 0.4353 - val_acc: 0.2444\n",
      "Epoch 4518/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3833 - acc: 0.2075 - val_loss: 0.4730 - val_acc: 0.2444\n",
      "Epoch 4519/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3810 - acc: 0.2087 - val_loss: 0.4265 - val_acc: 0.2444\n",
      "Epoch 4520/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3984 - acc: 0.2079 - val_loss: 0.4236 - val_acc: 0.2444\n",
      "Epoch 4521/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3592 - acc: 0.2087 - val_loss: 0.4742 - val_acc: 0.2444\n",
      "Epoch 4522/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3686 - acc: 0.2075 - val_loss: 0.4351 - val_acc: 0.2444\n",
      "Epoch 4523/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3569 - acc: 0.2083 - val_loss: 0.4395 - val_acc: 0.2444\n",
      "Epoch 4524/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3692 - acc: 0.2079 - val_loss: 0.4184 - val_acc: 0.2444\n",
      "Epoch 4525/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3918 - acc: 0.2075 - val_loss: 0.4189 - val_acc: 0.2444\n",
      "Epoch 4526/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3593 - acc: 0.2083 - val_loss: 0.4697 - val_acc: 0.2444\n",
      "Epoch 4527/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3982 - acc: 0.2079 - val_loss: 0.4175 - val_acc: 0.2444\n",
      "Epoch 4528/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3666 - acc: 0.2083 - val_loss: 0.4848 - val_acc: 0.2444\n",
      "Epoch 4529/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3674 - acc: 0.2083 - val_loss: 0.4372 - val_acc: 0.2444\n",
      "Epoch 4530/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3823 - acc: 0.2087 - val_loss: 0.4362 - val_acc: 0.2444\n",
      "Epoch 4531/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3791 - acc: 0.2083 - val_loss: 0.4281 - val_acc: 0.2444\n",
      "Epoch 4532/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3821 - acc: 0.2087 - val_loss: 0.4357 - val_acc: 0.2444\n",
      "Epoch 4533/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3724 - acc: 0.2079 - val_loss: 0.4037 - val_acc: 0.2444\n",
      "Epoch 4534/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3564 - acc: 0.2087 - val_loss: 0.4317 - val_acc: 0.2444\n",
      "Epoch 4535/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3607 - acc: 0.2079 - val_loss: 0.4405 - val_acc: 0.2444\n",
      "Epoch 4536/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3666 - acc: 0.2083 - val_loss: 0.4105 - val_acc: 0.2444\n",
      "Epoch 4537/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3631 - acc: 0.2083 - val_loss: 0.4651 - val_acc: 0.2444\n",
      "Epoch 4538/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3525 - acc: 0.2087 - val_loss: 0.4330 - val_acc: 0.2444\n",
      "Epoch 4539/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3458 - acc: 0.2079 - val_loss: 0.4321 - val_acc: 0.2444\n",
      "Epoch 4540/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3720 - acc: 0.2083 - val_loss: 0.5212 - val_acc: 0.2444\n",
      "Epoch 4541/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3495 - acc: 0.2087 - val_loss: 0.4159 - val_acc: 0.2444\n",
      "Epoch 4542/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3531 - acc: 0.2087 - val_loss: 0.4128 - val_acc: 0.2444\n",
      "Epoch 4543/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3697 - acc: 0.2083 - val_loss: 0.4270 - val_acc: 0.2444\n",
      "Epoch 4544/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3688 - acc: 0.2079 - val_loss: 0.5556 - val_acc: 0.2407\n",
      "Epoch 4545/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3874 - acc: 0.2087 - val_loss: 0.4881 - val_acc: 0.2444\n",
      "Epoch 4546/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3800 - acc: 0.2071 - val_loss: 0.4239 - val_acc: 0.2444\n",
      "Epoch 4547/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3638 - acc: 0.2083 - val_loss: 0.4152 - val_acc: 0.2444\n",
      "Epoch 4548/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3499 - acc: 0.2079 - val_loss: 0.4326 - val_acc: 0.2444\n",
      "Epoch 4549/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3505 - acc: 0.2087 - val_loss: 0.4213 - val_acc: 0.2444\n",
      "Epoch 4550/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3726 - acc: 0.2087 - val_loss: 0.4351 - val_acc: 0.2444\n",
      "Epoch 4551/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3564 - acc: 0.2083 - val_loss: 0.3992 - val_acc: 0.2444\n",
      "Epoch 4552/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3469 - acc: 0.2079 - val_loss: 0.4334 - val_acc: 0.2444\n",
      "Epoch 4553/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3486 - acc: 0.2083 - val_loss: 0.4518 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4554/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3625 - acc: 0.2079 - val_loss: 0.4150 - val_acc: 0.2444\n",
      "Epoch 4555/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3847 - acc: 0.2083 - val_loss: 0.4148 - val_acc: 0.2444\n",
      "Epoch 4556/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3789 - acc: 0.2087 - val_loss: 0.4047 - val_acc: 0.2444\n",
      "Epoch 4557/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3559 - acc: 0.2075 - val_loss: 0.4851 - val_acc: 0.2407\n",
      "Epoch 4558/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3943 - acc: 0.2071 - val_loss: 0.4307 - val_acc: 0.2444\n",
      "Epoch 4559/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3791 - acc: 0.2075 - val_loss: 0.4336 - val_acc: 0.2444\n",
      "Epoch 4560/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3765 - acc: 0.2075 - val_loss: 0.4225 - val_acc: 0.2444\n",
      "Epoch 4561/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3601 - acc: 0.2083 - val_loss: 0.4364 - val_acc: 0.2444\n",
      "Epoch 4562/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3431 - acc: 0.2087 - val_loss: 0.4150 - val_acc: 0.2444\n",
      "Epoch 4563/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3929 - acc: 0.2071 - val_loss: 0.4760 - val_acc: 0.2444\n",
      "Epoch 4564/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3536 - acc: 0.2083 - val_loss: 0.4254 - val_acc: 0.2444\n",
      "Epoch 4565/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3707 - acc: 0.2071 - val_loss: 0.4429 - val_acc: 0.2444\n",
      "Epoch 4566/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3651 - acc: 0.2087 - val_loss: 0.5450 - val_acc: 0.2444\n",
      "Epoch 4567/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3815 - acc: 0.2083 - val_loss: 0.4072 - val_acc: 0.2444\n",
      "Epoch 4568/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3655 - acc: 0.2079 - val_loss: 0.4402 - val_acc: 0.2444\n",
      "Epoch 4569/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3620 - acc: 0.2087 - val_loss: 0.4134 - val_acc: 0.2444\n",
      "Epoch 4570/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3671 - acc: 0.2083 - val_loss: 0.5128 - val_acc: 0.2444\n",
      "Epoch 4571/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3732 - acc: 0.2087 - val_loss: 0.4666 - val_acc: 0.2444\n",
      "Epoch 4572/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.3629 - acc: 0.2092 - val_loss: 0.5643 - val_acc: 0.2407\n",
      "Epoch 4573/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4003 - acc: 0.2075 - val_loss: 0.4224 - val_acc: 0.2444\n",
      "Epoch 4574/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3973 - acc: 0.2083 - val_loss: 0.5314 - val_acc: 0.2407\n",
      "Epoch 4575/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3788 - acc: 0.2087 - val_loss: 0.4208 - val_acc: 0.2444\n",
      "Epoch 4576/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3710 - acc: 0.2075 - val_loss: 0.4322 - val_acc: 0.2444\n",
      "Epoch 4577/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3675 - acc: 0.2087 - val_loss: 0.4466 - val_acc: 0.2444\n",
      "Epoch 4578/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3691 - acc: 0.2087 - val_loss: 0.4370 - val_acc: 0.2444\n",
      "Epoch 4579/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3929 - acc: 0.2083 - val_loss: 0.6564 - val_acc: 0.2444\n",
      "Epoch 4580/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3702 - acc: 0.2083 - val_loss: 0.4795 - val_acc: 0.2444\n",
      "Epoch 4581/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3584 - acc: 0.2083 - val_loss: 0.4213 - val_acc: 0.2444\n",
      "Epoch 4582/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3614 - acc: 0.2083 - val_loss: 0.4331 - val_acc: 0.2444\n",
      "Epoch 4583/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3873 - acc: 0.2079 - val_loss: 0.4057 - val_acc: 0.2444\n",
      "Epoch 4584/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3518 - acc: 0.2083 - val_loss: 0.4356 - val_acc: 0.2444\n",
      "Epoch 4585/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3523 - acc: 0.2087 - val_loss: 0.4567 - val_acc: 0.2444\n",
      "Epoch 4586/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3706 - acc: 0.2079 - val_loss: 0.4225 - val_acc: 0.2444\n",
      "Epoch 4587/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3658 - acc: 0.2083 - val_loss: 0.4080 - val_acc: 0.2444\n",
      "Epoch 4588/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3483 - acc: 0.2083 - val_loss: 0.4561 - val_acc: 0.2444\n",
      "Epoch 4589/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3777 - acc: 0.2079 - val_loss: 0.4098 - val_acc: 0.2444\n",
      "Epoch 4590/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3679 - acc: 0.2087 - val_loss: 0.5163 - val_acc: 0.2407\n",
      "Epoch 4591/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3665 - acc: 0.2075 - val_loss: 0.4568 - val_acc: 0.2444\n",
      "Epoch 4592/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3592 - acc: 0.2087 - val_loss: 0.4138 - val_acc: 0.2444\n",
      "Epoch 4593/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3903 - acc: 0.2079 - val_loss: 0.5101 - val_acc: 0.2444\n",
      "Epoch 4594/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3817 - acc: 0.2079 - val_loss: 0.4480 - val_acc: 0.2444\n",
      "Epoch 4595/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3872 - acc: 0.2079 - val_loss: 0.4013 - val_acc: 0.2444\n",
      "Epoch 4596/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3727 - acc: 0.2079 - val_loss: 0.4229 - val_acc: 0.2444\n",
      "Epoch 4597/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3556 - acc: 0.2087 - val_loss: 0.4985 - val_acc: 0.2444\n",
      "Epoch 4598/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3473 - acc: 0.2083 - val_loss: 0.4335 - val_acc: 0.2444\n",
      "Epoch 4599/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3563 - acc: 0.2079 - val_loss: 0.4399 - val_acc: 0.2444\n",
      "Epoch 4600/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3597 - acc: 0.2075 - val_loss: 0.4624 - val_acc: 0.2444\n",
      "Epoch 4601/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3866 - acc: 0.2079 - val_loss: 0.4222 - val_acc: 0.2444\n",
      "Epoch 4602/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3511 - acc: 0.2083 - val_loss: 0.4497 - val_acc: 0.2444\n",
      "Epoch 4603/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3491 - acc: 0.2083 - val_loss: 0.4126 - val_acc: 0.2444\n",
      "Epoch 4604/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3715 - acc: 0.2083 - val_loss: 0.5080 - val_acc: 0.2407\n",
      "Epoch 4605/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3740 - acc: 0.2087 - val_loss: 0.4032 - val_acc: 0.2444\n",
      "Epoch 4606/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3724 - acc: 0.2087 - val_loss: 0.4208 - val_acc: 0.2444\n",
      "Epoch 4607/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3555 - acc: 0.2079 - val_loss: 0.4003 - val_acc: 0.2444\n",
      "Epoch 4608/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3652 - acc: 0.2087 - val_loss: 0.4103 - val_acc: 0.2444\n",
      "Epoch 4609/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3646 - acc: 0.2087 - val_loss: 0.4858 - val_acc: 0.2444\n",
      "Epoch 4610/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3577 - acc: 0.2083 - val_loss: 0.4165 - val_acc: 0.2444\n",
      "Epoch 4611/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3550 - acc: 0.2087 - val_loss: 0.4319 - val_acc: 0.2444\n",
      "Epoch 4612/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3651 - acc: 0.2075 - val_loss: 0.4203 - val_acc: 0.2444\n",
      "Epoch 4613/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3838 - acc: 0.2059 - val_loss: 0.4944 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4614/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3863 - acc: 0.2079 - val_loss: 0.5322 - val_acc: 0.2407\n",
      "Epoch 4615/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3772 - acc: 0.2083 - val_loss: 0.7332 - val_acc: 0.2407\n",
      "Epoch 4616/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4277 - acc: 0.2063 - val_loss: 0.5360 - val_acc: 0.2407\n",
      "Epoch 4617/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3687 - acc: 0.2079 - val_loss: 0.4738 - val_acc: 0.2444\n",
      "Epoch 4618/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3550 - acc: 0.2087 - val_loss: 0.4042 - val_acc: 0.2444\n",
      "Epoch 4619/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3551 - acc: 0.2079 - val_loss: 0.4364 - val_acc: 0.2444\n",
      "Epoch 4620/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3493 - acc: 0.2079 - val_loss: 0.4495 - val_acc: 0.2444\n",
      "Epoch 4621/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3703 - acc: 0.2083 - val_loss: 0.4422 - val_acc: 0.2444\n",
      "Epoch 4622/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3846 - acc: 0.2075 - val_loss: 0.4708 - val_acc: 0.2444\n",
      "Epoch 4623/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3739 - acc: 0.2079 - val_loss: 0.4494 - val_acc: 0.2444\n",
      "Epoch 4624/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3546 - acc: 0.2083 - val_loss: 0.4187 - val_acc: 0.2444\n",
      "Epoch 4625/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3813 - acc: 0.2079 - val_loss: 0.4575 - val_acc: 0.2444\n",
      "Epoch 4626/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3536 - acc: 0.2083 - val_loss: 0.4123 - val_acc: 0.2444\n",
      "Epoch 4627/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3554 - acc: 0.2087 - val_loss: 0.4554 - val_acc: 0.2444\n",
      "Epoch 4628/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3789 - acc: 0.2079 - val_loss: 0.5031 - val_acc: 0.2444\n",
      "Epoch 4629/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3876 - acc: 0.2071 - val_loss: 0.4651 - val_acc: 0.2444\n",
      "Epoch 4630/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4172 - acc: 0.2083 - val_loss: 0.6185 - val_acc: 0.2407\n",
      "Epoch 4631/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3684 - acc: 0.2079 - val_loss: 0.4122 - val_acc: 0.2444\n",
      "Epoch 4632/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3883 - acc: 0.2087 - val_loss: 0.4535 - val_acc: 0.2444\n",
      "Epoch 4633/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3692 - acc: 0.2079 - val_loss: 0.4328 - val_acc: 0.2444\n",
      "Epoch 4634/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3565 - acc: 0.2079 - val_loss: 0.4328 - val_acc: 0.2444\n",
      "Epoch 4635/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3720 - acc: 0.2075 - val_loss: 0.4251 - val_acc: 0.2444\n",
      "Epoch 4636/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3731 - acc: 0.2083 - val_loss: 0.4276 - val_acc: 0.2444\n",
      "Epoch 4637/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3715 - acc: 0.2083 - val_loss: 0.4362 - val_acc: 0.2444\n",
      "Epoch 4638/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3611 - acc: 0.2083 - val_loss: 0.4068 - val_acc: 0.2444\n",
      "Epoch 4639/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3467 - acc: 0.2079 - val_loss: 0.4222 - val_acc: 0.2444\n",
      "Epoch 4640/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3898 - acc: 0.2087 - val_loss: 0.4262 - val_acc: 0.2444\n",
      "Epoch 4641/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3545 - acc: 0.2083 - val_loss: 0.4645 - val_acc: 0.2444\n",
      "Epoch 4642/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3833 - acc: 0.2087 - val_loss: 0.4035 - val_acc: 0.2444\n",
      "Epoch 4643/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3789 - acc: 0.2079 - val_loss: 0.4138 - val_acc: 0.2444\n",
      "Epoch 4644/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3531 - acc: 0.2087 - val_loss: 0.5084 - val_acc: 0.2444\n",
      "Epoch 4645/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4008 - acc: 0.2079 - val_loss: 0.4223 - val_acc: 0.2444\n",
      "Epoch 4646/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3595 - acc: 0.2087 - val_loss: 0.4528 - val_acc: 0.2444\n",
      "Epoch 4647/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3580 - acc: 0.2087 - val_loss: 0.4789 - val_acc: 0.2444\n",
      "Epoch 4648/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3627 - acc: 0.2083 - val_loss: 0.4451 - val_acc: 0.2444\n",
      "Epoch 4649/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3536 - acc: 0.2083 - val_loss: 0.4263 - val_acc: 0.2444\n",
      "Epoch 4650/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3525 - acc: 0.2087 - val_loss: 0.4578 - val_acc: 0.2444\n",
      "Epoch 4651/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4083 - acc: 0.2075 - val_loss: 0.4209 - val_acc: 0.2444\n",
      "Epoch 4652/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3735 - acc: 0.2083 - val_loss: 0.5146 - val_acc: 0.2444\n",
      "Epoch 4653/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3645 - acc: 0.2079 - val_loss: 0.4321 - val_acc: 0.2444\n",
      "Epoch 4654/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3504 - acc: 0.2083 - val_loss: 0.4004 - val_acc: 0.2444\n",
      "Epoch 4655/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3670 - acc: 0.2083 - val_loss: 0.4176 - val_acc: 0.2444\n",
      "Epoch 4656/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3591 - acc: 0.2087 - val_loss: 0.4664 - val_acc: 0.2444\n",
      "Epoch 4657/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3669 - acc: 0.2079 - val_loss: 0.4260 - val_acc: 0.2444\n",
      "Epoch 4658/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3644 - acc: 0.2087 - val_loss: 0.4164 - val_acc: 0.2444\n",
      "Epoch 4659/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3544 - acc: 0.2075 - val_loss: 0.4284 - val_acc: 0.2444\n",
      "Epoch 4660/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3703 - acc: 0.2083 - val_loss: 0.4946 - val_acc: 0.2444\n",
      "Epoch 4661/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3901 - acc: 0.2083 - val_loss: 0.4018 - val_acc: 0.2444\n",
      "Epoch 4662/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3553 - acc: 0.2079 - val_loss: 0.4479 - val_acc: 0.2444\n",
      "Epoch 4663/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3493 - acc: 0.2083 - val_loss: 0.4583 - val_acc: 0.2444\n",
      "Epoch 4664/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3715 - acc: 0.2083 - val_loss: 0.5211 - val_acc: 0.2444\n",
      "Epoch 4665/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3532 - acc: 0.2083 - val_loss: 0.4213 - val_acc: 0.2444\n",
      "Epoch 4666/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3563 - acc: 0.2087 - val_loss: 0.5448 - val_acc: 0.2407\n",
      "Epoch 4667/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3695 - acc: 0.2075 - val_loss: 0.4147 - val_acc: 0.2444\n",
      "Epoch 4668/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3484 - acc: 0.2083 - val_loss: 0.5132 - val_acc: 0.2444\n",
      "Epoch 4669/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3588 - acc: 0.2083 - val_loss: 0.4192 - val_acc: 0.2444\n",
      "Epoch 4670/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4054 - acc: 0.2079 - val_loss: 0.6876 - val_acc: 0.2444\n",
      "Epoch 4671/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3983 - acc: 0.2079 - val_loss: 0.4475 - val_acc: 0.2444\n",
      "Epoch 4672/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3816 - acc: 0.2071 - val_loss: 0.4267 - val_acc: 0.2444\n",
      "Epoch 4673/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3624 - acc: 0.2075 - val_loss: 0.4254 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4674/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3478 - acc: 0.2083 - val_loss: 0.4183 - val_acc: 0.2444\n",
      "Epoch 4675/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3739 - acc: 0.2075 - val_loss: 0.4061 - val_acc: 0.2444\n",
      "Epoch 4676/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3491 - acc: 0.2079 - val_loss: 0.4116 - val_acc: 0.2444\n",
      "Epoch 4677/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3488 - acc: 0.2087 - val_loss: 0.4303 - val_acc: 0.2444\n",
      "Epoch 4678/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3607 - acc: 0.2092 - val_loss: 0.4591 - val_acc: 0.2444\n",
      "Epoch 4679/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3747 - acc: 0.2079 - val_loss: 0.4469 - val_acc: 0.2444\n",
      "Epoch 4680/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3690 - acc: 0.2079 - val_loss: 0.4143 - val_acc: 0.2444\n",
      "Epoch 4681/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3553 - acc: 0.2083 - val_loss: 0.4009 - val_acc: 0.2444\n",
      "Epoch 4682/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3575 - acc: 0.2079 - val_loss: 0.4404 - val_acc: 0.2444\n",
      "Epoch 4683/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3464 - acc: 0.2083 - val_loss: 0.4315 - val_acc: 0.2444\n",
      "Epoch 4684/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3664 - acc: 0.2087 - val_loss: 0.4427 - val_acc: 0.2444\n",
      "Epoch 4685/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3547 - acc: 0.2079 - val_loss: 0.4226 - val_acc: 0.2444\n",
      "Epoch 4686/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3742 - acc: 0.2092 - val_loss: 0.4355 - val_acc: 0.2444\n",
      "Epoch 4687/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3544 - acc: 0.2079 - val_loss: 0.4154 - val_acc: 0.2444\n",
      "Epoch 4688/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3515 - acc: 0.2083 - val_loss: 0.4756 - val_acc: 0.2444\n",
      "Epoch 4689/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3459 - acc: 0.2083 - val_loss: 0.4472 - val_acc: 0.2444\n",
      "Epoch 4690/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3768 - acc: 0.2083 - val_loss: 0.4153 - val_acc: 0.2444\n",
      "Epoch 4691/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3599 - acc: 0.2079 - val_loss: 0.4522 - val_acc: 0.2444\n",
      "Epoch 4692/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3877 - acc: 0.2083 - val_loss: 0.4881 - val_acc: 0.2444\n",
      "Epoch 4693/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3638 - acc: 0.2087 - val_loss: 0.4220 - val_acc: 0.2444\n",
      "Epoch 4694/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3660 - acc: 0.2083 - val_loss: 0.4389 - val_acc: 0.2444\n",
      "Epoch 4695/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3676 - acc: 0.2087 - val_loss: 0.4414 - val_acc: 0.2444\n",
      "Epoch 4696/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3807 - acc: 0.2083 - val_loss: 0.7490 - val_acc: 0.2407\n",
      "Epoch 4697/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3722 - acc: 0.2087 - val_loss: 0.4095 - val_acc: 0.2444\n",
      "Epoch 4698/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3605 - acc: 0.2079 - val_loss: 0.4258 - val_acc: 0.2444\n",
      "Epoch 4699/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3605 - acc: 0.2075 - val_loss: 0.4370 - val_acc: 0.2444\n",
      "Epoch 4700/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3509 - acc: 0.2075 - val_loss: 0.4095 - val_acc: 0.2444\n",
      "Epoch 4701/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3534 - acc: 0.2083 - val_loss: 0.4154 - val_acc: 0.2444\n",
      "Epoch 4702/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3611 - acc: 0.2083 - val_loss: 0.4368 - val_acc: 0.2444\n",
      "Epoch 4703/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3790 - acc: 0.2075 - val_loss: 0.4215 - val_acc: 0.2444\n",
      "Epoch 4704/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3453 - acc: 0.2087 - val_loss: 0.4618 - val_acc: 0.2444\n",
      "Epoch 4705/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3533 - acc: 0.2083 - val_loss: 0.4356 - val_acc: 0.2444\n",
      "Epoch 4706/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3504 - acc: 0.2079 - val_loss: 0.4448 - val_acc: 0.2444\n",
      "Epoch 4707/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.8420 - acc: 0.2063 - val_loss: 0.7614 - val_acc: 0.2444\n",
      "Epoch 4708/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.6175 - acc: 0.2067 - val_loss: 0.5587 - val_acc: 0.2444\n",
      "Epoch 4709/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4074 - acc: 0.2079 - val_loss: 0.5190 - val_acc: 0.2444\n",
      "Epoch 4710/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3851 - acc: 0.2092 - val_loss: 0.4769 - val_acc: 0.2444\n",
      "Epoch 4711/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3846 - acc: 0.2079 - val_loss: 0.4535 - val_acc: 0.2444\n",
      "Epoch 4712/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3860 - acc: 0.2083 - val_loss: 0.4267 - val_acc: 0.2444\n",
      "Epoch 4713/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3713 - acc: 0.2079 - val_loss: 0.4368 - val_acc: 0.2444\n",
      "Epoch 4714/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3680 - acc: 0.2083 - val_loss: 0.4249 - val_acc: 0.2444\n",
      "Epoch 4715/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3581 - acc: 0.2083 - val_loss: 0.4131 - val_acc: 0.2444\n",
      "Epoch 4716/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3494 - acc: 0.2083 - val_loss: 0.4126 - val_acc: 0.2444\n",
      "Epoch 4717/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3574 - acc: 0.2087 - val_loss: 0.4386 - val_acc: 0.2444\n",
      "Epoch 4718/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3676 - acc: 0.2087 - val_loss: 0.4189 - val_acc: 0.2444\n",
      "Epoch 4719/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3598 - acc: 0.2083 - val_loss: 0.4388 - val_acc: 0.2444\n",
      "Epoch 4720/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3625 - acc: 0.2079 - val_loss: 0.4214 - val_acc: 0.2444\n",
      "Epoch 4721/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3574 - acc: 0.2083 - val_loss: 0.4165 - val_acc: 0.2444\n",
      "Epoch 4722/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3563 - acc: 0.2087 - val_loss: 0.4713 - val_acc: 0.2444\n",
      "Epoch 4723/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3550 - acc: 0.2079 - val_loss: 0.4572 - val_acc: 0.2444\n",
      "Epoch 4724/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3601 - acc: 0.2087 - val_loss: 0.4298 - val_acc: 0.2444\n",
      "Epoch 4725/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3510 - acc: 0.2087 - val_loss: 0.4343 - val_acc: 0.2444\n",
      "Epoch 4726/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3552 - acc: 0.2087 - val_loss: 0.4168 - val_acc: 0.2444\n",
      "Epoch 4727/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3658 - acc: 0.2083 - val_loss: 0.4465 - val_acc: 0.2444\n",
      "Epoch 4728/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3874 - acc: 0.2079 - val_loss: 0.4504 - val_acc: 0.2444\n",
      "Epoch 4729/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3525 - acc: 0.2083 - val_loss: 0.4154 - val_acc: 0.2444\n",
      "Epoch 4730/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3638 - acc: 0.2083 - val_loss: 0.4204 - val_acc: 0.2444\n",
      "Epoch 4731/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3592 - acc: 0.2083 - val_loss: 0.4138 - val_acc: 0.2444\n",
      "Epoch 4732/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3738 - acc: 0.2075 - val_loss: 0.4135 - val_acc: 0.2444\n",
      "Epoch 4733/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3552 - acc: 0.2083 - val_loss: 0.3996 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4734/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3763 - acc: 0.2087 - val_loss: 0.4546 - val_acc: 0.2444\n",
      "Epoch 4735/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3628 - acc: 0.2083 - val_loss: 0.4132 - val_acc: 0.2444\n",
      "Epoch 4736/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3612 - acc: 0.2079 - val_loss: 0.4396 - val_acc: 0.2444\n",
      "Epoch 4737/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3734 - acc: 0.2079 - val_loss: 0.4227 - val_acc: 0.2444\n",
      "Epoch 4738/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3647 - acc: 0.2083 - val_loss: 0.4132 - val_acc: 0.2444\n",
      "Epoch 4739/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3868 - acc: 0.2087 - val_loss: 0.4914 - val_acc: 0.2444\n",
      "Epoch 4740/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3635 - acc: 0.2087 - val_loss: 0.4438 - val_acc: 0.2444\n",
      "Epoch 4741/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3934 - acc: 0.2083 - val_loss: 0.4724 - val_acc: 0.2444\n",
      "Epoch 4742/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3726 - acc: 0.2083 - val_loss: 0.4228 - val_acc: 0.2444\n",
      "Epoch 4743/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3649 - acc: 0.2087 - val_loss: 0.5247 - val_acc: 0.2444\n",
      "Epoch 4744/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4022 - acc: 0.2083 - val_loss: 0.4733 - val_acc: 0.2444\n",
      "Epoch 4745/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3843 - acc: 0.2083 - val_loss: 0.4030 - val_acc: 0.2444\n",
      "Epoch 4746/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3514 - acc: 0.2083 - val_loss: 0.4193 - val_acc: 0.2444\n",
      "Epoch 4747/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3675 - acc: 0.2079 - val_loss: 0.4991 - val_acc: 0.2444\n",
      "Epoch 4748/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3435 - acc: 0.2083 - val_loss: 0.4166 - val_acc: 0.2444\n",
      "Epoch 4749/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4039 - acc: 0.2075 - val_loss: 0.4109 - val_acc: 0.2444\n",
      "Epoch 4750/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3686 - acc: 0.2071 - val_loss: 0.4157 - val_acc: 0.2444\n",
      "Epoch 4751/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3661 - acc: 0.2083 - val_loss: 0.4495 - val_acc: 0.2444\n",
      "Epoch 4752/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3515 - acc: 0.2087 - val_loss: 0.4453 - val_acc: 0.2444\n",
      "Epoch 4753/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3864 - acc: 0.2083 - val_loss: 0.5557 - val_acc: 0.2444\n",
      "Epoch 4754/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3865 - acc: 0.2071 - val_loss: 0.4383 - val_acc: 0.2444\n",
      "Epoch 4755/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3923 - acc: 0.2083 - val_loss: 0.4349 - val_acc: 0.2444\n",
      "Epoch 4756/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3644 - acc: 0.2075 - val_loss: 0.5835 - val_acc: 0.2407\n",
      "Epoch 4757/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3677 - acc: 0.2079 - val_loss: 0.4204 - val_acc: 0.2444\n",
      "Epoch 4758/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3507 - acc: 0.2083 - val_loss: 0.4128 - val_acc: 0.2444\n",
      "Epoch 4759/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3710 - acc: 0.2083 - val_loss: 0.4217 - val_acc: 0.2444\n",
      "Epoch 4760/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3449 - acc: 0.2087 - val_loss: 0.4253 - val_acc: 0.2444\n",
      "Epoch 4761/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3530 - acc: 0.2079 - val_loss: 0.4062 - val_acc: 0.2444\n",
      "Epoch 4762/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3440 - acc: 0.2087 - val_loss: 0.4041 - val_acc: 0.2444\n",
      "Epoch 4763/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3809 - acc: 0.2075 - val_loss: 0.4693 - val_acc: 0.2444\n",
      "Epoch 4764/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3711 - acc: 0.2083 - val_loss: 0.4125 - val_acc: 0.2444\n",
      "Epoch 4765/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3520 - acc: 0.2079 - val_loss: 0.4014 - val_acc: 0.2444\n",
      "Epoch 4766/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3733 - acc: 0.2079 - val_loss: 0.4077 - val_acc: 0.2444\n",
      "Epoch 4767/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3921 - acc: 0.2075 - val_loss: 0.7003 - val_acc: 0.2407\n",
      "Epoch 4768/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3888 - acc: 0.2087 - val_loss: 0.4153 - val_acc: 0.2444\n",
      "Epoch 4769/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3601 - acc: 0.2087 - val_loss: 0.4229 - val_acc: 0.2444\n",
      "Epoch 4770/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3563 - acc: 0.2087 - val_loss: 0.5839 - val_acc: 0.2407\n",
      "Epoch 4771/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3566 - acc: 0.2083 - val_loss: 0.4070 - val_acc: 0.2444\n",
      "Epoch 4772/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3433 - acc: 0.2083 - val_loss: 0.5051 - val_acc: 0.2444\n",
      "Epoch 4773/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3579 - acc: 0.2087 - val_loss: 0.5807 - val_acc: 0.2407\n",
      "Epoch 4774/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3913 - acc: 0.2071 - val_loss: 0.4245 - val_acc: 0.2444\n",
      "Epoch 4775/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3553 - acc: 0.2083 - val_loss: 0.4173 - val_acc: 0.2444\n",
      "Epoch 4776/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3627 - acc: 0.2083 - val_loss: 0.4169 - val_acc: 0.2444\n",
      "Epoch 4777/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3689 - acc: 0.2083 - val_loss: 0.4067 - val_acc: 0.2444\n",
      "Epoch 4778/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3608 - acc: 0.2079 - val_loss: 0.4265 - val_acc: 0.2444\n",
      "Epoch 4779/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3634 - acc: 0.2075 - val_loss: 0.4226 - val_acc: 0.2444\n",
      "Epoch 4780/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3647 - acc: 0.2079 - val_loss: 0.4283 - val_acc: 0.2444\n",
      "Epoch 4781/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3659 - acc: 0.2083 - val_loss: 0.4174 - val_acc: 0.2444\n",
      "Epoch 4782/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3879 - acc: 0.2067 - val_loss: 0.6180 - val_acc: 0.2444\n",
      "Epoch 4783/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3597 - acc: 0.2075 - val_loss: 0.4916 - val_acc: 0.2444\n",
      "Epoch 4784/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3604 - acc: 0.2079 - val_loss: 0.4411 - val_acc: 0.2444\n",
      "Epoch 4785/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3810 - acc: 0.2083 - val_loss: 0.4175 - val_acc: 0.2444\n",
      "Epoch 4786/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3618 - acc: 0.2079 - val_loss: 0.4217 - val_acc: 0.2444\n",
      "Epoch 4787/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3602 - acc: 0.2083 - val_loss: 0.4433 - val_acc: 0.2444\n",
      "Epoch 4788/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3560 - acc: 0.2079 - val_loss: 0.4263 - val_acc: 0.2444\n",
      "Epoch 4789/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3645 - acc: 0.2075 - val_loss: 0.4105 - val_acc: 0.2444\n",
      "Epoch 4790/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3538 - acc: 0.2079 - val_loss: 0.4102 - val_acc: 0.2444\n",
      "Epoch 4791/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3692 - acc: 0.2079 - val_loss: 0.4136 - val_acc: 0.2444\n",
      "Epoch 4792/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4002 - acc: 0.2083 - val_loss: 0.4975 - val_acc: 0.2444\n",
      "Epoch 4793/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3569 - acc: 0.2079 - val_loss: 0.4519 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4794/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3499 - acc: 0.2079 - val_loss: 0.4245 - val_acc: 0.2444\n",
      "Epoch 4795/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3591 - acc: 0.2083 - val_loss: 0.5173 - val_acc: 0.2444\n",
      "Epoch 4796/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3536 - acc: 0.2079 - val_loss: 0.5505 - val_acc: 0.2407\n",
      "Epoch 4797/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3797 - acc: 0.2087 - val_loss: 0.4180 - val_acc: 0.2444\n",
      "Epoch 4798/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3578 - acc: 0.2083 - val_loss: 0.4289 - val_acc: 0.2444\n",
      "Epoch 4799/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3833 - acc: 0.2087 - val_loss: 0.4241 - val_acc: 0.2444\n",
      "Epoch 4800/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3613 - acc: 0.2079 - val_loss: 0.4478 - val_acc: 0.2444\n",
      "Epoch 4801/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3594 - acc: 0.2083 - val_loss: 0.4084 - val_acc: 0.2444\n",
      "Epoch 4802/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3634 - acc: 0.2087 - val_loss: 0.4168 - val_acc: 0.2444\n",
      "Epoch 4803/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3706 - acc: 0.2079 - val_loss: 0.5068 - val_acc: 0.2444\n",
      "Epoch 4804/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3708 - acc: 0.2083 - val_loss: 0.4100 - val_acc: 0.2444\n",
      "Epoch 4805/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3495 - acc: 0.2079 - val_loss: 0.4170 - val_acc: 0.2444\n",
      "Epoch 4806/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3579 - acc: 0.2087 - val_loss: 0.4093 - val_acc: 0.2444\n",
      "Epoch 4807/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3491 - acc: 0.2079 - val_loss: 0.4252 - val_acc: 0.2444\n",
      "Epoch 4808/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3835 - acc: 0.2079 - val_loss: 0.5561 - val_acc: 0.2407\n",
      "Epoch 4809/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3696 - acc: 0.2087 - val_loss: 0.4346 - val_acc: 0.2444\n",
      "Epoch 4810/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3923 - acc: 0.2096 - val_loss: 0.4617 - val_acc: 0.2444\n",
      "Epoch 4811/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3614 - acc: 0.2087 - val_loss: 0.4365 - val_acc: 0.2444\n",
      "Epoch 4812/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3702 - acc: 0.2083 - val_loss: 0.4064 - val_acc: 0.2444\n",
      "Epoch 4813/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3529 - acc: 0.2083 - val_loss: 0.4850 - val_acc: 0.2444\n",
      "Epoch 4814/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3526 - acc: 0.2087 - val_loss: 0.4363 - val_acc: 0.2444\n",
      "Epoch 4815/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3530 - acc: 0.2087 - val_loss: 0.4089 - val_acc: 0.2444\n",
      "Epoch 4816/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3640 - acc: 0.2083 - val_loss: 0.4199 - val_acc: 0.2444\n",
      "Epoch 4817/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3608 - acc: 0.2087 - val_loss: 0.4276 - val_acc: 0.2444\n",
      "Epoch 4818/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3719 - acc: 0.2075 - val_loss: 0.5458 - val_acc: 0.2407\n",
      "Epoch 4819/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3978 - acc: 0.2092 - val_loss: 0.4201 - val_acc: 0.2444\n",
      "Epoch 4820/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3727 - acc: 0.2083 - val_loss: 0.3998 - val_acc: 0.2444\n",
      "Epoch 4821/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3461 - acc: 0.2083 - val_loss: 0.4046 - val_acc: 0.2444\n",
      "Epoch 4822/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3653 - acc: 0.2083 - val_loss: 0.5610 - val_acc: 0.2444\n",
      "Epoch 4823/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4063 - acc: 0.2087 - val_loss: 0.4196 - val_acc: 0.2444\n",
      "Epoch 4824/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3565 - acc: 0.2083 - val_loss: 0.4430 - val_acc: 0.2444\n",
      "Epoch 4825/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3560 - acc: 0.2087 - val_loss: 0.4984 - val_acc: 0.2444\n",
      "Epoch 4826/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3724 - acc: 0.2079 - val_loss: 0.4207 - val_acc: 0.2444\n",
      "Epoch 4827/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3881 - acc: 0.2083 - val_loss: 0.4112 - val_acc: 0.2444\n",
      "Epoch 4828/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4036 - acc: 0.2079 - val_loss: 0.5503 - val_acc: 0.2407\n",
      "Epoch 4829/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3423 - acc: 0.2079 - val_loss: 0.3995 - val_acc: 0.2444\n",
      "Epoch 4830/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3550 - acc: 0.2087 - val_loss: 0.4285 - val_acc: 0.2444\n",
      "Epoch 4831/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3544 - acc: 0.2075 - val_loss: 0.5243 - val_acc: 0.2444\n",
      "Epoch 4832/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3767 - acc: 0.2079 - val_loss: 0.4477 - val_acc: 0.2444\n",
      "Epoch 4833/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3658 - acc: 0.2083 - val_loss: 0.4075 - val_acc: 0.2444\n",
      "Epoch 4834/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3656 - acc: 0.2096 - val_loss: 0.4222 - val_acc: 0.2444\n",
      "Epoch 4835/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3859 - acc: 0.2075 - val_loss: 0.5771 - val_acc: 0.2444\n",
      "Epoch 4836/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3697 - acc: 0.2083 - val_loss: 0.4654 - val_acc: 0.2444\n",
      "Epoch 4837/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3724 - acc: 0.2079 - val_loss: 0.4349 - val_acc: 0.2444\n",
      "Epoch 4838/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3516 - acc: 0.2083 - val_loss: 0.4461 - val_acc: 0.2444\n",
      "Epoch 4839/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3667 - acc: 0.2079 - val_loss: 0.4065 - val_acc: 0.2444\n",
      "Epoch 4840/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3567 - acc: 0.2071 - val_loss: 0.4126 - val_acc: 0.2444\n",
      "Epoch 4841/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.3538 - acc: 0.2083 - val_loss: 0.4280 - val_acc: 0.2444\n",
      "Epoch 4842/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3719 - acc: 0.2083 - val_loss: 0.4225 - val_acc: 0.2444\n",
      "Epoch 4843/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3516 - acc: 0.2083 - val_loss: 0.4142 - val_acc: 0.2444\n",
      "Epoch 4844/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3713 - acc: 0.2087 - val_loss: 0.5517 - val_acc: 0.2407\n",
      "Epoch 4845/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3560 - acc: 0.2083 - val_loss: 0.4100 - val_acc: 0.2444\n",
      "Epoch 4846/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3706 - acc: 0.2087 - val_loss: 0.5016 - val_acc: 0.2444\n",
      "Epoch 4847/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3510 - acc: 0.2083 - val_loss: 0.4421 - val_acc: 0.2444\n",
      "Epoch 4848/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3603 - acc: 0.2079 - val_loss: 0.5103 - val_acc: 0.2444\n",
      "Epoch 4849/10000\n",
      "76/76 [==============================] - 2s 30ms/step - loss: 0.3770 - acc: 0.2079 - val_loss: 0.4077 - val_acc: 0.2444\n",
      "Epoch 4850/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3447 - acc: 0.2075 - val_loss: 0.4061 - val_acc: 0.2444\n",
      "Epoch 4851/10000\n",
      "76/76 [==============================] - 2s 30ms/step - loss: 0.3603 - acc: 0.2083 - val_loss: 0.5233 - val_acc: 0.2407\n",
      "Epoch 4852/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3846 - acc: 0.2079 - val_loss: 0.4081 - val_acc: 0.2444\n",
      "Epoch 4853/10000\n",
      "76/76 [==============================] - 2s 30ms/step - loss: 0.3996 - acc: 0.2075 - val_loss: 0.4165 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4854/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3616 - acc: 0.2079 - val_loss: 0.4513 - val_acc: 0.2444\n",
      "Epoch 4855/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3751 - acc: 0.2079 - val_loss: 0.4227 - val_acc: 0.2444\n",
      "Epoch 4856/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3537 - acc: 0.2075 - val_loss: 0.4659 - val_acc: 0.2444\n",
      "Epoch 4857/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3496 - acc: 0.2083 - val_loss: 0.4603 - val_acc: 0.2444\n",
      "Epoch 4858/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3688 - acc: 0.2083 - val_loss: 0.4241 - val_acc: 0.2444\n",
      "Epoch 4859/10000\n",
      "76/76 [==============================] - 2s 30ms/step - loss: 0.3664 - acc: 0.2075 - val_loss: 0.4430 - val_acc: 0.2444\n",
      "Epoch 4860/10000\n",
      "76/76 [==============================] - 2s 30ms/step - loss: 0.3439 - acc: 0.2092 - val_loss: 0.3948 - val_acc: 0.2444\n",
      "Epoch 4861/10000\n",
      "76/76 [==============================] - 2s 30ms/step - loss: 0.3601 - acc: 0.2075 - val_loss: 0.4139 - val_acc: 0.2444\n",
      "Epoch 4862/10000\n",
      "76/76 [==============================] - 2s 30ms/step - loss: 0.3729 - acc: 0.2079 - val_loss: 0.4356 - val_acc: 0.2444\n",
      "Epoch 4863/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3629 - acc: 0.2083 - val_loss: 0.4266 - val_acc: 0.2444\n",
      "Epoch 4864/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3572 - acc: 0.2075 - val_loss: 0.4157 - val_acc: 0.2444\n",
      "Epoch 4865/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3499 - acc: 0.2087 - val_loss: 0.4225 - val_acc: 0.2444\n",
      "Epoch 4866/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3749 - acc: 0.2087 - val_loss: 0.4181 - val_acc: 0.2444\n",
      "Epoch 4867/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3544 - acc: 0.2087 - val_loss: 0.3976 - val_acc: 0.2444\n",
      "Epoch 4868/10000\n",
      "76/76 [==============================] - 2s 30ms/step - loss: 0.3539 - acc: 0.2083 - val_loss: 0.4324 - val_acc: 0.2444\n",
      "Epoch 4869/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3670 - acc: 0.2083 - val_loss: 0.4381 - val_acc: 0.2444\n",
      "Epoch 4870/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3467 - acc: 0.2087 - val_loss: 0.4474 - val_acc: 0.2444\n",
      "Epoch 4871/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3464 - acc: 0.2079 - val_loss: 0.4292 - val_acc: 0.2444\n",
      "Epoch 4872/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3679 - acc: 0.2075 - val_loss: 0.4119 - val_acc: 0.2444\n",
      "Epoch 4873/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3747 - acc: 0.2087 - val_loss: 0.5630 - val_acc: 0.2444\n",
      "Epoch 4874/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3951 - acc: 0.2087 - val_loss: 0.4163 - val_acc: 0.2444\n",
      "Epoch 4875/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3845 - acc: 0.2079 - val_loss: 0.4257 - val_acc: 0.2444\n",
      "Epoch 4876/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3567 - acc: 0.2079 - val_loss: 0.4079 - val_acc: 0.2444\n",
      "Epoch 4877/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3458 - acc: 0.2087 - val_loss: 0.4097 - val_acc: 0.2444\n",
      "Epoch 4878/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3838 - acc: 0.2079 - val_loss: 0.4132 - val_acc: 0.2444\n",
      "Epoch 4879/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3657 - acc: 0.2075 - val_loss: 0.4107 - val_acc: 0.2444\n",
      "Epoch 4880/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3547 - acc: 0.2079 - val_loss: 0.4157 - val_acc: 0.2444\n",
      "Epoch 4881/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3533 - acc: 0.2083 - val_loss: 0.4104 - val_acc: 0.2444\n",
      "Epoch 4882/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3674 - acc: 0.2075 - val_loss: 0.4117 - val_acc: 0.2444\n",
      "Epoch 4883/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3817 - acc: 0.2075 - val_loss: 0.4111 - val_acc: 0.2444\n",
      "Epoch 4884/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3607 - acc: 0.2087 - val_loss: 0.4286 - val_acc: 0.2444\n",
      "Epoch 4885/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3557 - acc: 0.2087 - val_loss: 0.4247 - val_acc: 0.2444\n",
      "Epoch 4886/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3539 - acc: 0.2083 - val_loss: 0.4652 - val_acc: 0.2444\n",
      "Epoch 4887/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3540 - acc: 0.2083 - val_loss: 0.4714 - val_acc: 0.2444\n",
      "Epoch 4888/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3561 - acc: 0.2079 - val_loss: 0.4255 - val_acc: 0.2444\n",
      "Epoch 4889/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3486 - acc: 0.2079 - val_loss: 0.5048 - val_acc: 0.2407\n",
      "Epoch 4890/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3547 - acc: 0.2083 - val_loss: 0.4147 - val_acc: 0.2444\n",
      "Epoch 4891/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3476 - acc: 0.2079 - val_loss: 0.4225 - val_acc: 0.2444\n",
      "Epoch 4892/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3702 - acc: 0.2075 - val_loss: 0.4225 - val_acc: 0.2444\n",
      "Epoch 4893/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3598 - acc: 0.2079 - val_loss: 0.4793 - val_acc: 0.2444\n",
      "Epoch 4894/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3691 - acc: 0.2075 - val_loss: 0.5282 - val_acc: 0.2407\n",
      "Epoch 4895/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3646 - acc: 0.2079 - val_loss: 0.4177 - val_acc: 0.2444\n",
      "Epoch 4896/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4037 - acc: 0.2087 - val_loss: 0.7831 - val_acc: 0.2444\n",
      "Epoch 4897/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3680 - acc: 0.2087 - val_loss: 0.4196 - val_acc: 0.2444\n",
      "Epoch 4898/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3665 - acc: 0.2079 - val_loss: 0.4498 - val_acc: 0.2444\n",
      "Epoch 4899/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3526 - acc: 0.2083 - val_loss: 0.4070 - val_acc: 0.2444\n",
      "Epoch 4900/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3559 - acc: 0.2079 - val_loss: 0.4222 - val_acc: 0.2444\n",
      "Epoch 4901/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3572 - acc: 0.2071 - val_loss: 0.4176 - val_acc: 0.2444\n",
      "Epoch 4902/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3491 - acc: 0.2083 - val_loss: 0.4202 - val_acc: 0.2444\n",
      "Epoch 4903/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3438 - acc: 0.2092 - val_loss: 0.4279 - val_acc: 0.2444\n",
      "Epoch 4904/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3639 - acc: 0.2083 - val_loss: 0.4246 - val_acc: 0.2444\n",
      "Epoch 4905/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3758 - acc: 0.2079 - val_loss: 0.5096 - val_acc: 0.2444\n",
      "Epoch 4906/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3817 - acc: 0.2083 - val_loss: 0.4683 - val_acc: 0.2444\n",
      "Epoch 4907/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3527 - acc: 0.2087 - val_loss: 0.4105 - val_acc: 0.2444\n",
      "Epoch 4908/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3684 - acc: 0.2071 - val_loss: 0.4574 - val_acc: 0.2444\n",
      "Epoch 4909/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3769 - acc: 0.2087 - val_loss: 0.4925 - val_acc: 0.2444\n",
      "Epoch 4910/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3688 - acc: 0.2087 - val_loss: 0.4150 - val_acc: 0.2444\n",
      "Epoch 4911/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3585 - acc: 0.2083 - val_loss: 0.4063 - val_acc: 0.2444\n",
      "Epoch 4912/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4091 - acc: 0.2071 - val_loss: 0.5122 - val_acc: 0.2444\n",
      "Epoch 4913/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3565 - acc: 0.2083 - val_loss: 0.4041 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4914/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3720 - acc: 0.2083 - val_loss: 0.4304 - val_acc: 0.2444\n",
      "Epoch 4915/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3481 - acc: 0.2083 - val_loss: 0.4406 - val_acc: 0.2444\n",
      "Epoch 4916/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3660 - acc: 0.2083 - val_loss: 0.4200 - val_acc: 0.2444\n",
      "Epoch 4917/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3570 - acc: 0.2075 - val_loss: 0.4463 - val_acc: 0.2444\n",
      "Epoch 4918/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3594 - acc: 0.2087 - val_loss: 0.4505 - val_acc: 0.2444\n",
      "Epoch 4919/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3655 - acc: 0.2092 - val_loss: 0.4243 - val_acc: 0.2444\n",
      "Epoch 4920/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3596 - acc: 0.2079 - val_loss: 0.4076 - val_acc: 0.2444\n",
      "Epoch 4921/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3498 - acc: 0.2087 - val_loss: 0.4512 - val_acc: 0.2444\n",
      "Epoch 4922/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3478 - acc: 0.2079 - val_loss: 0.5571 - val_acc: 0.2444\n",
      "Epoch 4923/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3640 - acc: 0.2083 - val_loss: 0.5241 - val_acc: 0.2407\n",
      "Epoch 4924/10000\n",
      "76/76 [==============================] - 2s 30ms/step - loss: 0.4013 - acc: 0.2079 - val_loss: 0.4101 - val_acc: 0.2444\n",
      "Epoch 4925/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3923 - acc: 0.2092 - val_loss: 0.4284 - val_acc: 0.2444\n",
      "Epoch 4926/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3544 - acc: 0.2087 - val_loss: 0.5302 - val_acc: 0.2407\n",
      "Epoch 4927/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3901 - acc: 0.2075 - val_loss: 0.4055 - val_acc: 0.2444\n",
      "Epoch 4928/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3799 - acc: 0.2075 - val_loss: 0.4150 - val_acc: 0.2444\n",
      "Epoch 4929/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3888 - acc: 0.2071 - val_loss: 0.4160 - val_acc: 0.2444\n",
      "Epoch 4930/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3650 - acc: 0.2087 - val_loss: 0.4745 - val_acc: 0.2444\n",
      "Epoch 4931/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3585 - acc: 0.2079 - val_loss: 0.4259 - val_acc: 0.2444\n",
      "Epoch 4932/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3952 - acc: 0.2083 - val_loss: 0.4628 - val_acc: 0.2444\n",
      "Epoch 4933/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3602 - acc: 0.2087 - val_loss: 0.4894 - val_acc: 0.2444\n",
      "Epoch 4934/10000\n",
      "76/76 [==============================] - 2s 30ms/step - loss: 0.4386 - acc: 0.2083 - val_loss: 0.4096 - val_acc: 0.2444\n",
      "Epoch 4935/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3612 - acc: 0.2083 - val_loss: 0.4019 - val_acc: 0.2444\n",
      "Epoch 4936/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3608 - acc: 0.2087 - val_loss: 0.4158 - val_acc: 0.2444\n",
      "Epoch 4937/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3449 - acc: 0.2083 - val_loss: 0.4716 - val_acc: 0.2444\n",
      "Epoch 4938/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3468 - acc: 0.2087 - val_loss: 0.4096 - val_acc: 0.2444\n",
      "Epoch 4939/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3671 - acc: 0.2087 - val_loss: 0.4325 - val_acc: 0.2444\n",
      "Epoch 4940/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3656 - acc: 0.2087 - val_loss: 0.4218 - val_acc: 0.2444\n",
      "Epoch 4941/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3626 - acc: 0.2083 - val_loss: 0.4143 - val_acc: 0.2444\n",
      "Epoch 4942/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3895 - acc: 0.2079 - val_loss: 0.4160 - val_acc: 0.2444\n",
      "Epoch 4943/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3606 - acc: 0.2087 - val_loss: 0.4853 - val_acc: 0.2444\n",
      "Epoch 4944/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3823 - acc: 0.2079 - val_loss: 0.4763 - val_acc: 0.2444\n",
      "Epoch 4945/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3823 - acc: 0.2083 - val_loss: 0.4373 - val_acc: 0.2444\n",
      "Epoch 4946/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3830 - acc: 0.2079 - val_loss: 0.4414 - val_acc: 0.2444\n",
      "Epoch 4947/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3491 - acc: 0.2087 - val_loss: 0.4134 - val_acc: 0.2444\n",
      "Epoch 4948/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3554 - acc: 0.2079 - val_loss: 0.4382 - val_acc: 0.2444\n",
      "Epoch 4949/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3739 - acc: 0.2079 - val_loss: 0.4363 - val_acc: 0.2444\n",
      "Epoch 4950/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3750 - acc: 0.2083 - val_loss: 0.4504 - val_acc: 0.2444\n",
      "Epoch 4951/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3531 - acc: 0.2087 - val_loss: 0.4903 - val_acc: 0.2444\n",
      "Epoch 4952/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3649 - acc: 0.2079 - val_loss: 0.5617 - val_acc: 0.2407\n",
      "Epoch 4953/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3586 - acc: 0.2083 - val_loss: 0.4046 - val_acc: 0.2444\n",
      "Epoch 4954/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3819 - acc: 0.2092 - val_loss: 0.4695 - val_acc: 0.2444\n",
      "Epoch 4955/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3682 - acc: 0.2079 - val_loss: 0.4876 - val_acc: 0.2444\n",
      "Epoch 4956/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3585 - acc: 0.2083 - val_loss: 0.4258 - val_acc: 0.2444\n",
      "Epoch 4957/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3513 - acc: 0.2079 - val_loss: 0.4156 - val_acc: 0.2444\n",
      "Epoch 4958/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3707 - acc: 0.2075 - val_loss: 0.4388 - val_acc: 0.2444\n",
      "Epoch 4959/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3486 - acc: 0.2083 - val_loss: 0.5590 - val_acc: 0.2407\n",
      "Epoch 4960/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3904 - acc: 0.2083 - val_loss: 0.4605 - val_acc: 0.2444\n",
      "Epoch 4961/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3649 - acc: 0.2079 - val_loss: 0.5147 - val_acc: 0.2444\n",
      "Epoch 4962/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3705 - acc: 0.2087 - val_loss: 0.3928 - val_acc: 0.2444\n",
      "Epoch 4963/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3553 - acc: 0.2067 - val_loss: 0.4087 - val_acc: 0.2444\n",
      "Epoch 4964/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3645 - acc: 0.2075 - val_loss: 0.4079 - val_acc: 0.2444\n",
      "Epoch 4965/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3462 - acc: 0.2083 - val_loss: 0.4078 - val_acc: 0.2444\n",
      "Epoch 4966/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3608 - acc: 0.2087 - val_loss: 0.4414 - val_acc: 0.2444\n",
      "Epoch 4967/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3773 - acc: 0.2087 - val_loss: 0.4267 - val_acc: 0.2444\n",
      "Epoch 4968/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3687 - acc: 0.2087 - val_loss: 0.4209 - val_acc: 0.2444\n",
      "Epoch 4969/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3699 - acc: 0.2092 - val_loss: 0.3970 - val_acc: 0.2444\n",
      "Epoch 4970/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3468 - acc: 0.2083 - val_loss: 0.4174 - val_acc: 0.2444\n",
      "Epoch 4971/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3454 - acc: 0.2079 - val_loss: 0.4228 - val_acc: 0.2444\n",
      "Epoch 4972/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3770 - acc: 0.2075 - val_loss: 0.4265 - val_acc: 0.2444\n",
      "Epoch 4973/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3475 - acc: 0.2083 - val_loss: 0.4021 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4974/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3629 - acc: 0.2087 - val_loss: 0.4126 - val_acc: 0.2444\n",
      "Epoch 4975/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3455 - acc: 0.2083 - val_loss: 0.4032 - val_acc: 0.2444\n",
      "Epoch 4976/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3744 - acc: 0.2087 - val_loss: 0.4806 - val_acc: 0.2444\n",
      "Epoch 4977/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3509 - acc: 0.2083 - val_loss: 0.4325 - val_acc: 0.2444\n",
      "Epoch 4978/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3746 - acc: 0.2083 - val_loss: 0.4354 - val_acc: 0.2444\n",
      "Epoch 4979/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3526 - acc: 0.2079 - val_loss: 0.4217 - val_acc: 0.2444\n",
      "Epoch 4980/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3504 - acc: 0.2079 - val_loss: 0.4293 - val_acc: 0.2444\n",
      "Epoch 4981/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3511 - acc: 0.2083 - val_loss: 0.4319 - val_acc: 0.2444\n",
      "Epoch 4982/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3648 - acc: 0.2092 - val_loss: 0.3952 - val_acc: 0.2444\n",
      "Epoch 4983/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3679 - acc: 0.2075 - val_loss: 0.4331 - val_acc: 0.2444\n",
      "Epoch 4984/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3575 - acc: 0.2092 - val_loss: 0.4074 - val_acc: 0.2444\n",
      "Epoch 4985/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3515 - acc: 0.2075 - val_loss: 0.4148 - val_acc: 0.2444\n",
      "Epoch 4986/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3505 - acc: 0.2083 - val_loss: 0.4309 - val_acc: 0.2444\n",
      "Epoch 4987/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3517 - acc: 0.2083 - val_loss: 0.4669 - val_acc: 0.2444\n",
      "Epoch 4988/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3888 - acc: 0.2075 - val_loss: 0.4308 - val_acc: 0.2444\n",
      "Epoch 4989/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3617 - acc: 0.2079 - val_loss: 0.4256 - val_acc: 0.2444\n",
      "Epoch 4990/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3694 - acc: 0.2083 - val_loss: 0.4160 - val_acc: 0.2444\n",
      "Epoch 4991/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3482 - acc: 0.2079 - val_loss: 0.4208 - val_acc: 0.2444\n",
      "Epoch 4992/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3477 - acc: 0.2083 - val_loss: 0.4620 - val_acc: 0.2444\n",
      "Epoch 4993/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3474 - acc: 0.2083 - val_loss: 0.4630 - val_acc: 0.2444\n",
      "Epoch 4994/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3624 - acc: 0.2083 - val_loss: 0.4228 - val_acc: 0.2444\n",
      "Epoch 4995/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3672 - acc: 0.2087 - val_loss: 0.4236 - val_acc: 0.2444\n",
      "Epoch 4996/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3518 - acc: 0.2087 - val_loss: 0.4791 - val_acc: 0.2444\n",
      "Epoch 4997/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3626 - acc: 0.2083 - val_loss: 0.4094 - val_acc: 0.2444\n",
      "Epoch 4998/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3701 - acc: 0.2079 - val_loss: 0.5114 - val_acc: 0.2407\n",
      "Epoch 4999/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3740 - acc: 0.2083 - val_loss: 0.6385 - val_acc: 0.2444\n",
      "Epoch 5000/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4075 - acc: 0.2092 - val_loss: 0.5098 - val_acc: 0.2444\n",
      "Epoch 5001/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3582 - acc: 0.2075 - val_loss: 0.4366 - val_acc: 0.2444\n",
      "Epoch 5002/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3643 - acc: 0.2079 - val_loss: 0.4308 - val_acc: 0.2444\n",
      "Epoch 5003/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3529 - acc: 0.2083 - val_loss: 0.4219 - val_acc: 0.2444\n",
      "Epoch 5004/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3488 - acc: 0.2083 - val_loss: 0.6016 - val_acc: 0.2444\n",
      "Epoch 5005/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4007 - acc: 0.2092 - val_loss: 0.4564 - val_acc: 0.2444\n",
      "Epoch 5006/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3524 - acc: 0.2083 - val_loss: 0.4143 - val_acc: 0.2444\n",
      "Epoch 5007/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3538 - acc: 0.2087 - val_loss: 0.4239 - val_acc: 0.2444\n",
      "Epoch 5008/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3627 - acc: 0.2083 - val_loss: 0.4676 - val_acc: 0.2444\n",
      "Epoch 5009/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3731 - acc: 0.2079 - val_loss: 0.3925 - val_acc: 0.2444\n",
      "Epoch 5010/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3541 - acc: 0.2083 - val_loss: 0.4047 - val_acc: 0.2444\n",
      "Epoch 5011/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3512 - acc: 0.2083 - val_loss: 0.4067 - val_acc: 0.2444\n",
      "Epoch 5012/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3510 - acc: 0.2083 - val_loss: 0.4222 - val_acc: 0.2444\n",
      "Epoch 5013/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3668 - acc: 0.2087 - val_loss: 0.4331 - val_acc: 0.2444\n",
      "Epoch 5014/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3556 - acc: 0.2075 - val_loss: 0.4161 - val_acc: 0.2444\n",
      "Epoch 5015/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3632 - acc: 0.2087 - val_loss: 0.4235 - val_acc: 0.2444\n",
      "Epoch 5016/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3603 - acc: 0.2083 - val_loss: 0.4506 - val_acc: 0.2444\n",
      "Epoch 5017/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3642 - acc: 0.2083 - val_loss: 0.6325 - val_acc: 0.2444\n",
      "Epoch 5018/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3950 - acc: 0.2083 - val_loss: 0.4342 - val_acc: 0.2444\n",
      "Epoch 5019/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3470 - acc: 0.2087 - val_loss: 0.4275 - val_acc: 0.2444\n",
      "Epoch 5020/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3502 - acc: 0.2087 - val_loss: 0.4427 - val_acc: 0.2444\n",
      "Epoch 5021/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3625 - acc: 0.2079 - val_loss: 0.4212 - val_acc: 0.2444\n",
      "Epoch 5022/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3615 - acc: 0.2079 - val_loss: 0.4654 - val_acc: 0.2444\n",
      "Epoch 5023/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3445 - acc: 0.2083 - val_loss: 0.5142 - val_acc: 0.2444\n",
      "Epoch 5024/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3776 - acc: 0.2087 - val_loss: 0.4102 - val_acc: 0.2444\n",
      "Epoch 5025/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3573 - acc: 0.2079 - val_loss: 0.4634 - val_acc: 0.2444\n",
      "Epoch 5026/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3466 - acc: 0.2079 - val_loss: 0.4493 - val_acc: 0.2444\n",
      "Epoch 5027/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3642 - acc: 0.2083 - val_loss: 0.4222 - val_acc: 0.2444\n",
      "Epoch 5028/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3791 - acc: 0.2075 - val_loss: 0.4408 - val_acc: 0.2444\n",
      "Epoch 5029/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3543 - acc: 0.2079 - val_loss: 0.4117 - val_acc: 0.2444\n",
      "Epoch 5030/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3703 - acc: 0.2079 - val_loss: 0.4552 - val_acc: 0.2444\n",
      "Epoch 5031/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3729 - acc: 0.2083 - val_loss: 0.4803 - val_acc: 0.2444\n",
      "Epoch 5032/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3474 - acc: 0.2083 - val_loss: 0.4233 - val_acc: 0.2444\n",
      "Epoch 5033/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3704 - acc: 0.2075 - val_loss: 0.4950 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5034/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3657 - acc: 0.2079 - val_loss: 0.4361 - val_acc: 0.2444\n",
      "Epoch 5035/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3631 - acc: 0.2079 - val_loss: 0.4428 - val_acc: 0.2444\n",
      "Epoch 5036/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3649 - acc: 0.2083 - val_loss: 0.4014 - val_acc: 0.2444\n",
      "Epoch 5037/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3447 - acc: 0.2087 - val_loss: 0.4072 - val_acc: 0.2444\n",
      "Epoch 5038/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3547 - acc: 0.2083 - val_loss: 0.4002 - val_acc: 0.2444\n",
      "Epoch 5039/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3451 - acc: 0.2083 - val_loss: 0.4111 - val_acc: 0.2444\n",
      "Epoch 5040/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3557 - acc: 0.2079 - val_loss: 0.4669 - val_acc: 0.2444\n",
      "Epoch 5041/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3565 - acc: 0.2079 - val_loss: 0.4287 - val_acc: 0.2444\n",
      "Epoch 5042/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3691 - acc: 0.2079 - val_loss: 0.4226 - val_acc: 0.2444\n",
      "Epoch 5043/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3957 - acc: 0.2071 - val_loss: 0.4239 - val_acc: 0.2444\n",
      "Epoch 5044/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3840 - acc: 0.2075 - val_loss: 0.4351 - val_acc: 0.2444\n",
      "Epoch 5045/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3606 - acc: 0.2087 - val_loss: 0.4297 - val_acc: 0.2444\n",
      "Epoch 5046/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3502 - acc: 0.2075 - val_loss: 0.4265 - val_acc: 0.2444\n",
      "Epoch 5047/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3541 - acc: 0.2083 - val_loss: 0.4041 - val_acc: 0.2444\n",
      "Epoch 5048/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3589 - acc: 0.2083 - val_loss: 0.4166 - val_acc: 0.2444\n",
      "Epoch 5049/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3530 - acc: 0.2079 - val_loss: 0.5177 - val_acc: 0.2444\n",
      "Epoch 5050/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3949 - acc: 0.2083 - val_loss: 0.4412 - val_acc: 0.2444\n",
      "Epoch 5051/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3491 - acc: 0.2092 - val_loss: 0.4198 - val_acc: 0.2444\n",
      "Epoch 5052/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3603 - acc: 0.2083 - val_loss: 0.3988 - val_acc: 0.2444\n",
      "Epoch 5053/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3490 - acc: 0.2083 - val_loss: 0.4326 - val_acc: 0.2444\n",
      "Epoch 5054/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3715 - acc: 0.2079 - val_loss: 0.4133 - val_acc: 0.2444\n",
      "Epoch 5055/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3598 - acc: 0.2079 - val_loss: 0.4265 - val_acc: 0.2444\n",
      "Epoch 5056/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3463 - acc: 0.2079 - val_loss: 0.4326 - val_acc: 0.2444\n",
      "Epoch 5057/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3544 - acc: 0.2083 - val_loss: 0.4112 - val_acc: 0.2444\n",
      "Epoch 5058/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3576 - acc: 0.2087 - val_loss: 0.4112 - val_acc: 0.2444\n",
      "Epoch 5059/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3550 - acc: 0.2079 - val_loss: 0.4206 - val_acc: 0.2444\n",
      "Epoch 5060/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3443 - acc: 0.2079 - val_loss: 0.4150 - val_acc: 0.2444\n",
      "Epoch 5061/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3435 - acc: 0.2079 - val_loss: 0.4040 - val_acc: 0.2444\n",
      "Epoch 5062/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3700 - acc: 0.2083 - val_loss: 0.4530 - val_acc: 0.2444\n",
      "Epoch 5063/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3947 - acc: 0.2071 - val_loss: 0.4431 - val_acc: 0.2444\n",
      "Epoch 5064/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3568 - acc: 0.2087 - val_loss: 0.4307 - val_acc: 0.2444\n",
      "Epoch 5065/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3448 - acc: 0.2087 - val_loss: 0.4011 - val_acc: 0.2444\n",
      "Epoch 5066/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.3833 - acc: 0.2075 - val_loss: 0.4243 - val_acc: 0.2444\n",
      "Epoch 5067/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3870 - acc: 0.2083 - val_loss: 0.5172 - val_acc: 0.2444\n",
      "Epoch 5068/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3805 - acc: 0.2075 - val_loss: 0.4236 - val_acc: 0.2444\n",
      "Epoch 5069/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3560 - acc: 0.2087 - val_loss: 0.4238 - val_acc: 0.2444\n",
      "Epoch 5070/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3537 - acc: 0.2087 - val_loss: 0.4505 - val_acc: 0.2444\n",
      "Epoch 5071/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3699 - acc: 0.2087 - val_loss: 0.4724 - val_acc: 0.2444\n",
      "Epoch 5072/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3690 - acc: 0.2087 - val_loss: 0.3941 - val_acc: 0.2444\n",
      "Epoch 5073/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3635 - acc: 0.2092 - val_loss: 0.4273 - val_acc: 0.2444\n",
      "Epoch 5074/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3675 - acc: 0.2087 - val_loss: 0.5166 - val_acc: 0.2407\n",
      "Epoch 5075/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3829 - acc: 0.2083 - val_loss: 0.4174 - val_acc: 0.2444\n",
      "Epoch 5076/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3541 - acc: 0.2083 - val_loss: 0.4781 - val_acc: 0.2444\n",
      "Epoch 5077/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3727 - acc: 0.2083 - val_loss: 0.4367 - val_acc: 0.2444\n",
      "Epoch 5078/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3576 - acc: 0.2087 - val_loss: 0.4194 - val_acc: 0.2444\n",
      "Epoch 5079/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3411 - acc: 0.2083 - val_loss: 0.4565 - val_acc: 0.2444\n",
      "Epoch 5080/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3491 - acc: 0.2087 - val_loss: 0.4127 - val_acc: 0.2444\n",
      "Epoch 5081/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3666 - acc: 0.2087 - val_loss: 0.4281 - val_acc: 0.2444\n",
      "Epoch 5082/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3469 - acc: 0.2083 - val_loss: 0.4259 - val_acc: 0.2444\n",
      "Epoch 5083/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3476 - acc: 0.2079 - val_loss: 0.4279 - val_acc: 0.2444\n",
      "Epoch 5084/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3521 - acc: 0.2075 - val_loss: 0.4257 - val_acc: 0.2444\n",
      "Epoch 5085/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3486 - acc: 0.2083 - val_loss: 0.4338 - val_acc: 0.2444\n",
      "Epoch 5086/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4404 - acc: 0.2071 - val_loss: 0.5634 - val_acc: 0.2444\n",
      "Epoch 5087/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3765 - acc: 0.2092 - val_loss: 0.4701 - val_acc: 0.2444\n",
      "Epoch 5088/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3651 - acc: 0.2087 - val_loss: 0.4294 - val_acc: 0.2444\n",
      "Epoch 5089/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3650 - acc: 0.2083 - val_loss: 0.4003 - val_acc: 0.2444\n",
      "Epoch 5090/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3587 - acc: 0.2079 - val_loss: 0.4128 - val_acc: 0.2444\n",
      "Epoch 5091/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3922 - acc: 0.2075 - val_loss: 0.4385 - val_acc: 0.2444\n",
      "Epoch 5092/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3910 - acc: 0.2079 - val_loss: 0.7021 - val_acc: 0.2407\n",
      "Epoch 5093/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3690 - acc: 0.2079 - val_loss: 0.4619 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5094/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3451 - acc: 0.2079 - val_loss: 0.4195 - val_acc: 0.2444\n",
      "Epoch 5095/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3556 - acc: 0.2087 - val_loss: 0.4521 - val_acc: 0.2444\n",
      "Epoch 5096/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3451 - acc: 0.2083 - val_loss: 0.4891 - val_acc: 0.2444\n",
      "Epoch 5097/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3643 - acc: 0.2075 - val_loss: 0.4625 - val_acc: 0.2444\n",
      "Epoch 5098/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.4066 - acc: 0.2083 - val_loss: 0.5022 - val_acc: 0.2407\n",
      "Epoch 5099/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3715 - acc: 0.2083 - val_loss: 0.4413 - val_acc: 0.2444\n",
      "Epoch 5100/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3542 - acc: 0.2079 - val_loss: 0.4993 - val_acc: 0.2444\n",
      "Epoch 5101/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3654 - acc: 0.2079 - val_loss: 0.4370 - val_acc: 0.2444\n",
      "Epoch 5102/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3626 - acc: 0.2087 - val_loss: 0.4331 - val_acc: 0.2444\n",
      "Epoch 5103/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3480 - acc: 0.2083 - val_loss: 0.4064 - val_acc: 0.2444\n",
      "Epoch 5104/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3406 - acc: 0.2083 - val_loss: 0.4448 - val_acc: 0.2444\n",
      "Epoch 5105/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3691 - acc: 0.2083 - val_loss: 0.5711 - val_acc: 0.2407\n",
      "Epoch 5106/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3499 - acc: 0.2079 - val_loss: 0.4198 - val_acc: 0.2444\n",
      "Epoch 5107/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3639 - acc: 0.2083 - val_loss: 0.4212 - val_acc: 0.2444\n",
      "Epoch 5108/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3612 - acc: 0.2087 - val_loss: 0.4202 - val_acc: 0.2444\n",
      "Epoch 5109/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3657 - acc: 0.2079 - val_loss: 0.4169 - val_acc: 0.2444\n",
      "Epoch 5110/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3774 - acc: 0.2087 - val_loss: 0.4188 - val_acc: 0.2444\n",
      "Epoch 5111/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3537 - acc: 0.2083 - val_loss: 0.4911 - val_acc: 0.2444\n",
      "Epoch 5112/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3557 - acc: 0.2083 - val_loss: 0.4208 - val_acc: 0.2444\n",
      "Epoch 5113/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3625 - acc: 0.2083 - val_loss: 0.4223 - val_acc: 0.2444\n",
      "Epoch 5114/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3489 - acc: 0.2087 - val_loss: 0.4065 - val_acc: 0.2444\n",
      "Epoch 5115/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3436 - acc: 0.2087 - val_loss: 0.4177 - val_acc: 0.2444\n",
      "Epoch 5116/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3628 - acc: 0.2079 - val_loss: 0.4690 - val_acc: 0.2444\n",
      "Epoch 5117/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3451 - acc: 0.2079 - val_loss: 0.4136 - val_acc: 0.2444\n",
      "Epoch 5118/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3702 - acc: 0.2083 - val_loss: 0.4249 - val_acc: 0.2444\n",
      "Epoch 5119/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3535 - acc: 0.2092 - val_loss: 0.4272 - val_acc: 0.2444\n",
      "Epoch 5120/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3609 - acc: 0.2083 - val_loss: 0.5633 - val_acc: 0.2444\n",
      "Epoch 5121/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3581 - acc: 0.2075 - val_loss: 0.4633 - val_acc: 0.2444\n",
      "Epoch 5122/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3532 - acc: 0.2083 - val_loss: 0.4689 - val_acc: 0.2444\n",
      "Epoch 5123/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3625 - acc: 0.2075 - val_loss: 0.4090 - val_acc: 0.2444\n",
      "Epoch 5124/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3456 - acc: 0.2083 - val_loss: 0.4254 - val_acc: 0.2444\n",
      "Epoch 5125/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3722 - acc: 0.2075 - val_loss: 0.5147 - val_acc: 0.2407\n",
      "Epoch 5126/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3495 - acc: 0.2087 - val_loss: 0.4412 - val_acc: 0.2444\n",
      "Epoch 5127/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3742 - acc: 0.2083 - val_loss: 0.4122 - val_acc: 0.2444\n",
      "Epoch 5128/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3436 - acc: 0.2083 - val_loss: 0.5069 - val_acc: 0.2444\n",
      "Epoch 5129/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3697 - acc: 0.2079 - val_loss: 0.4359 - val_acc: 0.2444\n",
      "Epoch 5130/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3474 - acc: 0.2079 - val_loss: 0.4144 - val_acc: 0.2444\n",
      "Epoch 5131/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3518 - acc: 0.2079 - val_loss: 0.5808 - val_acc: 0.2444\n",
      "Epoch 5132/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4151 - acc: 0.2083 - val_loss: 0.5028 - val_acc: 0.2407\n",
      "Epoch 5133/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3589 - acc: 0.2083 - val_loss: 0.5642 - val_acc: 0.2407\n",
      "Epoch 5134/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3664 - acc: 0.2075 - val_loss: 0.4267 - val_acc: 0.2444\n",
      "Epoch 5135/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3541 - acc: 0.2083 - val_loss: 0.4111 - val_acc: 0.2444\n",
      "Epoch 5136/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3953 - acc: 0.2075 - val_loss: 0.4133 - val_acc: 0.2444\n",
      "Epoch 5137/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3957 - acc: 0.2083 - val_loss: 0.4145 - val_acc: 0.2444\n",
      "Epoch 5138/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3782 - acc: 0.2087 - val_loss: 0.5057 - val_acc: 0.2444\n",
      "Epoch 5139/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3559 - acc: 0.2087 - val_loss: 0.4051 - val_acc: 0.2444\n",
      "Epoch 5140/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3554 - acc: 0.2087 - val_loss: 0.4436 - val_acc: 0.2444\n",
      "Epoch 5141/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3555 - acc: 0.2087 - val_loss: 0.4292 - val_acc: 0.2444\n",
      "Epoch 5142/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3895 - acc: 0.2096 - val_loss: 0.4655 - val_acc: 0.2444\n",
      "Epoch 5143/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3703 - acc: 0.2071 - val_loss: 0.4091 - val_acc: 0.2444\n",
      "Epoch 5144/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3680 - acc: 0.2079 - val_loss: 0.4203 - val_acc: 0.2444\n",
      "Epoch 5145/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3541 - acc: 0.2092 - val_loss: 0.4239 - val_acc: 0.2444\n",
      "Epoch 5146/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3609 - acc: 0.2083 - val_loss: 0.4126 - val_acc: 0.2444\n",
      "Epoch 5147/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3736 - acc: 0.2092 - val_loss: 0.4539 - val_acc: 0.2444\n",
      "Epoch 5148/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4033 - acc: 0.2083 - val_loss: 0.4755 - val_acc: 0.2444\n",
      "Epoch 5149/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3639 - acc: 0.2092 - val_loss: 0.5406 - val_acc: 0.2444\n",
      "Epoch 5150/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3824 - acc: 0.2075 - val_loss: 0.4248 - val_acc: 0.2444\n",
      "Epoch 5151/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3538 - acc: 0.2087 - val_loss: 0.4446 - val_acc: 0.2444\n",
      "Epoch 5152/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3927 - acc: 0.2083 - val_loss: 0.4924 - val_acc: 0.2444\n",
      "Epoch 5153/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3602 - acc: 0.2079 - val_loss: 0.5200 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5154/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3601 - acc: 0.2083 - val_loss: 0.4317 - val_acc: 0.2444\n",
      "Epoch 5155/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3850 - acc: 0.2075 - val_loss: 0.4227 - val_acc: 0.2444\n",
      "Epoch 5156/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3436 - acc: 0.2083 - val_loss: 0.4135 - val_acc: 0.2444\n",
      "Epoch 5157/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3557 - acc: 0.2083 - val_loss: 0.4380 - val_acc: 0.2444\n",
      "Epoch 5158/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3448 - acc: 0.2083 - val_loss: 0.4412 - val_acc: 0.2444\n",
      "Epoch 5159/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.3723 - acc: 0.2075 - val_loss: 0.5166 - val_acc: 0.2444\n",
      "Epoch 5160/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3668 - acc: 0.2079 - val_loss: 0.4514 - val_acc: 0.2444\n",
      "Epoch 5161/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3592 - acc: 0.2092 - val_loss: 0.4159 - val_acc: 0.2444\n",
      "Epoch 5162/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3500 - acc: 0.2092 - val_loss: 0.4420 - val_acc: 0.2444\n",
      "Epoch 5163/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3440 - acc: 0.2083 - val_loss: 0.4176 - val_acc: 0.2444\n",
      "Epoch 5164/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3431 - acc: 0.2087 - val_loss: 0.4581 - val_acc: 0.2444\n",
      "Epoch 5165/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3557 - acc: 0.2092 - val_loss: 0.4881 - val_acc: 0.2444\n",
      "Epoch 5166/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3624 - acc: 0.2092 - val_loss: 0.4380 - val_acc: 0.2444\n",
      "Epoch 5167/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3522 - acc: 0.2087 - val_loss: 0.4241 - val_acc: 0.2444\n",
      "Epoch 5168/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3489 - acc: 0.2083 - val_loss: 0.4241 - val_acc: 0.2444\n",
      "Epoch 5169/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3796 - acc: 0.2083 - val_loss: 0.5406 - val_acc: 0.2444\n",
      "Epoch 5170/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3770 - acc: 0.2083 - val_loss: 0.4407 - val_acc: 0.2444\n",
      "Epoch 5171/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3470 - acc: 0.2083 - val_loss: 0.4440 - val_acc: 0.2444\n",
      "Epoch 5172/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3763 - acc: 0.2083 - val_loss: 0.4193 - val_acc: 0.2444\n",
      "Epoch 5173/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3534 - acc: 0.2083 - val_loss: 0.4270 - val_acc: 0.2444\n",
      "Epoch 5174/10000\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.3525 - acc: 0.207 - 2s 32ms/step - loss: 0.3534 - acc: 0.2079 - val_loss: 0.4167 - val_acc: 0.2444\n",
      "Epoch 5175/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3539 - acc: 0.2092 - val_loss: 0.4882 - val_acc: 0.2444\n",
      "Epoch 5176/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3459 - acc: 0.2083 - val_loss: 0.4072 - val_acc: 0.2444\n",
      "Epoch 5177/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3664 - acc: 0.2087 - val_loss: 0.4245 - val_acc: 0.2444\n",
      "Epoch 5178/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3658 - acc: 0.2083 - val_loss: 0.4237 - val_acc: 0.2444\n",
      "Epoch 5179/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3480 - acc: 0.2083 - val_loss: 0.4152 - val_acc: 0.2444\n",
      "Epoch 5180/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3661 - acc: 0.2083 - val_loss: 0.4837 - val_acc: 0.2444\n",
      "Epoch 5181/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3526 - acc: 0.2087 - val_loss: 0.4094 - val_acc: 0.2444\n",
      "Epoch 5182/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3727 - acc: 0.2083 - val_loss: 0.4589 - val_acc: 0.2444\n",
      "Epoch 5183/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3583 - acc: 0.2087 - val_loss: 0.5969 - val_acc: 0.2444\n",
      "Epoch 5184/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3600 - acc: 0.2079 - val_loss: 0.3942 - val_acc: 0.2444\n",
      "Epoch 5185/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3598 - acc: 0.2079 - val_loss: 0.4387 - val_acc: 0.2444\n",
      "Epoch 5186/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3613 - acc: 0.2087 - val_loss: 0.4243 - val_acc: 0.2444\n",
      "Epoch 5187/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3504 - acc: 0.2087 - val_loss: 0.4146 - val_acc: 0.2444\n",
      "Epoch 5188/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3540 - acc: 0.2087 - val_loss: 0.4657 - val_acc: 0.2444\n",
      "Epoch 5189/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3639 - acc: 0.2071 - val_loss: 0.4147 - val_acc: 0.2444\n",
      "Epoch 5190/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3441 - acc: 0.2079 - val_loss: 0.4537 - val_acc: 0.2444\n",
      "Epoch 5191/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3488 - acc: 0.2075 - val_loss: 0.5217 - val_acc: 0.2444\n",
      "Epoch 5192/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3688 - acc: 0.2075 - val_loss: 0.4322 - val_acc: 0.2444\n",
      "Epoch 5193/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3742 - acc: 0.2079 - val_loss: 0.4245 - val_acc: 0.2444\n",
      "Epoch 5194/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3647 - acc: 0.2083 - val_loss: 0.4534 - val_acc: 0.2444\n",
      "Epoch 5195/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3619 - acc: 0.2083 - val_loss: 0.4572 - val_acc: 0.2444\n",
      "Epoch 5196/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3548 - acc: 0.2087 - val_loss: 0.6159 - val_acc: 0.2444\n",
      "Epoch 5197/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3692 - acc: 0.2087 - val_loss: 0.4460 - val_acc: 0.2444\n",
      "Epoch 5198/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3472 - acc: 0.2079 - val_loss: 0.4452 - val_acc: 0.2444\n",
      "Epoch 5199/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3601 - acc: 0.2079 - val_loss: 0.4433 - val_acc: 0.2444\n",
      "Epoch 5200/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3661 - acc: 0.2079 - val_loss: 0.4363 - val_acc: 0.2444\n",
      "Epoch 5201/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3612 - acc: 0.2087 - val_loss: 0.4258 - val_acc: 0.2444\n",
      "Epoch 5202/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3444 - acc: 0.2083 - val_loss: 0.4159 - val_acc: 0.2444\n",
      "Epoch 5203/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3456 - acc: 0.2083 - val_loss: 0.4145 - val_acc: 0.2444\n",
      "Epoch 5204/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3645 - acc: 0.2083 - val_loss: 0.4273 - val_acc: 0.2444\n",
      "Epoch 5205/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3530 - acc: 0.2079 - val_loss: 0.4131 - val_acc: 0.2444\n",
      "Epoch 5206/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3671 - acc: 0.2083 - val_loss: 0.5431 - val_acc: 0.2407\n",
      "Epoch 5207/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3615 - acc: 0.2079 - val_loss: 0.4899 - val_acc: 0.2444\n",
      "Epoch 5208/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3776 - acc: 0.2087 - val_loss: 0.4223 - val_acc: 0.2444\n",
      "Epoch 5209/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3444 - acc: 0.2083 - val_loss: 0.4319 - val_acc: 0.2444\n",
      "Epoch 5210/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3517 - acc: 0.2075 - val_loss: 0.4987 - val_acc: 0.2407\n",
      "Epoch 5211/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3474 - acc: 0.2079 - val_loss: 0.4243 - val_acc: 0.2444\n",
      "Epoch 5212/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3401 - acc: 0.2083 - val_loss: 0.4303 - val_acc: 0.2444\n",
      "Epoch 5213/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3607 - acc: 0.2092 - val_loss: 0.4548 - val_acc: 0.2444\n",
      "Epoch 5214/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3590 - acc: 0.2079 - val_loss: 0.4266 - val_acc: 0.2444\n",
      "Epoch 5215/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3645 - acc: 0.2087 - val_loss: 0.4649 - val_acc: 0.2444\n",
      "Epoch 5216/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3784 - acc: 0.2079 - val_loss: 0.4275 - val_acc: 0.2444\n",
      "Epoch 5217/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3522 - acc: 0.2079 - val_loss: 0.4127 - val_acc: 0.2444\n",
      "Epoch 5218/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3647 - acc: 0.2087 - val_loss: 0.4398 - val_acc: 0.2444\n",
      "Epoch 5219/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3439 - acc: 0.2083 - val_loss: 0.4282 - val_acc: 0.2444\n",
      "Epoch 5220/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3437 - acc: 0.2083 - val_loss: 0.4718 - val_acc: 0.2444\n",
      "Epoch 5221/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3666 - acc: 0.2092 - val_loss: 0.4210 - val_acc: 0.2444\n",
      "Epoch 5222/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3552 - acc: 0.2092 - val_loss: 0.4184 - val_acc: 0.2444\n",
      "Epoch 5223/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3519 - acc: 0.2083 - val_loss: 0.4576 - val_acc: 0.2444\n",
      "Epoch 5224/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3639 - acc: 0.2083 - val_loss: 0.4132 - val_acc: 0.2444\n",
      "Epoch 5225/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3511 - acc: 0.2079 - val_loss: 0.5040 - val_acc: 0.2444\n",
      "Epoch 5226/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3653 - acc: 0.2083 - val_loss: 0.3971 - val_acc: 0.2444\n",
      "Epoch 5227/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3441 - acc: 0.2075 - val_loss: 0.4767 - val_acc: 0.2444\n",
      "Epoch 5228/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3529 - acc: 0.2092 - val_loss: 0.4136 - val_acc: 0.2444\n",
      "Epoch 5229/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3474 - acc: 0.2087 - val_loss: 0.4249 - val_acc: 0.2444\n",
      "Epoch 5230/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3475 - acc: 0.2083 - val_loss: 0.4253 - val_acc: 0.2444\n",
      "Epoch 5231/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3587 - acc: 0.2079 - val_loss: 0.4483 - val_acc: 0.2444\n",
      "Epoch 5232/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3489 - acc: 0.2087 - val_loss: 0.4102 - val_acc: 0.2444\n",
      "Epoch 5233/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3557 - acc: 0.2083 - val_loss: 0.4981 - val_acc: 0.2444\n",
      "Epoch 5234/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3859 - acc: 0.2087 - val_loss: 0.5275 - val_acc: 0.2444\n",
      "Epoch 5235/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3688 - acc: 0.2087 - val_loss: 0.4311 - val_acc: 0.2444\n",
      "Epoch 5236/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3503 - acc: 0.2087 - val_loss: 0.3989 - val_acc: 0.2444\n",
      "Epoch 5237/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3415 - acc: 0.2083 - val_loss: 0.4316 - val_acc: 0.2444\n",
      "Epoch 5238/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3797 - acc: 0.2079 - val_loss: 0.5101 - val_acc: 0.2444\n",
      "Epoch 5239/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3513 - acc: 0.2079 - val_loss: 0.4025 - val_acc: 0.2444\n",
      "Epoch 5240/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3455 - acc: 0.2087 - val_loss: 0.4256 - val_acc: 0.2444\n",
      "Epoch 5241/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3470 - acc: 0.2087 - val_loss: 0.4197 - val_acc: 0.2444\n",
      "Epoch 5242/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3673 - acc: 0.2083 - val_loss: 0.4035 - val_acc: 0.2444\n",
      "Epoch 5243/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3478 - acc: 0.2083 - val_loss: 0.4088 - val_acc: 0.2444\n",
      "Epoch 5244/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3526 - acc: 0.2083 - val_loss: 0.4107 - val_acc: 0.2444\n",
      "Epoch 5245/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3644 - acc: 0.2071 - val_loss: 0.4128 - val_acc: 0.2444\n",
      "Epoch 5246/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3515 - acc: 0.2083 - val_loss: 0.4005 - val_acc: 0.2444\n",
      "Epoch 5247/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3622 - acc: 0.2075 - val_loss: 0.4283 - val_acc: 0.2444\n",
      "Epoch 5248/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3735 - acc: 0.2083 - val_loss: 0.4990 - val_acc: 0.2407\n",
      "Epoch 5249/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3732 - acc: 0.2067 - val_loss: 0.4514 - val_acc: 0.2444\n",
      "Epoch 5250/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3703 - acc: 0.2075 - val_loss: 0.4258 - val_acc: 0.2444\n",
      "Epoch 5251/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3541 - acc: 0.2092 - val_loss: 0.4220 - val_acc: 0.2444\n",
      "Epoch 5252/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3464 - acc: 0.2079 - val_loss: 0.4314 - val_acc: 0.2444\n",
      "Epoch 5253/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3451 - acc: 0.2083 - val_loss: 0.3970 - val_acc: 0.2444\n",
      "Epoch 5254/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3550 - acc: 0.2087 - val_loss: 0.4323 - val_acc: 0.2444\n",
      "Epoch 5255/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3458 - acc: 0.2079 - val_loss: 0.4231 - val_acc: 0.2444\n",
      "Epoch 5256/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3498 - acc: 0.2092 - val_loss: 0.4032 - val_acc: 0.2444\n",
      "Epoch 5257/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3570 - acc: 0.2083 - val_loss: 0.4623 - val_acc: 0.2444\n",
      "Epoch 5258/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3619 - acc: 0.2092 - val_loss: 0.4671 - val_acc: 0.2444\n",
      "Epoch 5259/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3579 - acc: 0.2079 - val_loss: 0.4422 - val_acc: 0.2444\n",
      "Epoch 5260/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3647 - acc: 0.2087 - val_loss: 0.4046 - val_acc: 0.2444\n",
      "Epoch 5261/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3489 - acc: 0.2079 - val_loss: 0.4189 - val_acc: 0.2444\n",
      "Epoch 5262/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3594 - acc: 0.2083 - val_loss: 0.4108 - val_acc: 0.2444\n",
      "Epoch 5263/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3472 - acc: 0.2083 - val_loss: 0.4262 - val_acc: 0.2444\n",
      "Epoch 5264/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3475 - acc: 0.2092 - val_loss: 0.5619 - val_acc: 0.2407\n",
      "Epoch 5265/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3756 - acc: 0.2075 - val_loss: 0.5311 - val_acc: 0.2444\n",
      "Epoch 5266/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3748 - acc: 0.2083 - val_loss: 0.4209 - val_acc: 0.2444\n",
      "Epoch 5267/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3823 - acc: 0.2079 - val_loss: 0.4140 - val_acc: 0.2444\n",
      "Epoch 5268/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3572 - acc: 0.2083 - val_loss: 0.4550 - val_acc: 0.2444\n",
      "Epoch 5269/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3443 - acc: 0.2087 - val_loss: 0.5188 - val_acc: 0.2407\n",
      "Epoch 5270/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3646 - acc: 0.2092 - val_loss: 0.4516 - val_acc: 0.2444\n",
      "Epoch 5271/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3699 - acc: 0.2083 - val_loss: 0.4162 - val_acc: 0.2444\n",
      "Epoch 5272/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3500 - acc: 0.2083 - val_loss: 0.5241 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5273/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3675 - acc: 0.2087 - val_loss: 0.4779 - val_acc: 0.2444\n",
      "Epoch 5274/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3598 - acc: 0.2079 - val_loss: 0.4446 - val_acc: 0.2444\n",
      "Epoch 5275/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3594 - acc: 0.2087 - val_loss: 0.3992 - val_acc: 0.2444\n",
      "Epoch 5276/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3429 - acc: 0.2083 - val_loss: 0.4423 - val_acc: 0.2444\n",
      "Epoch 5277/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3771 - acc: 0.2087 - val_loss: 0.6223 - val_acc: 0.2407\n",
      "Epoch 5278/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3498 - acc: 0.2083 - val_loss: 0.4232 - val_acc: 0.2444\n",
      "Epoch 5279/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3393 - acc: 0.2079 - val_loss: 0.3955 - val_acc: 0.2444\n",
      "Epoch 5280/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3445 - acc: 0.2083 - val_loss: 0.3954 - val_acc: 0.2444\n",
      "Epoch 5281/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3429 - acc: 0.2087 - val_loss: 0.4098 - val_acc: 0.2444\n",
      "Epoch 5282/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3805 - acc: 0.2079 - val_loss: 0.4158 - val_acc: 0.2444\n",
      "Epoch 5283/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3500 - acc: 0.2087 - val_loss: 0.4174 - val_acc: 0.2444\n",
      "Epoch 5284/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3498 - acc: 0.2079 - val_loss: 0.4267 - val_acc: 0.2444\n",
      "Epoch 5285/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3473 - acc: 0.2075 - val_loss: 0.4897 - val_acc: 0.2444\n",
      "Epoch 5286/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3443 - acc: 0.2079 - val_loss: 0.4294 - val_acc: 0.2444\n",
      "Epoch 5287/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3586 - acc: 0.2079 - val_loss: 0.4339 - val_acc: 0.2444\n",
      "Epoch 5288/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3546 - acc: 0.2083 - val_loss: 0.4568 - val_acc: 0.2444\n",
      "Epoch 5289/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3564 - acc: 0.2087 - val_loss: 0.4073 - val_acc: 0.2444\n",
      "Epoch 5290/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3410 - acc: 0.2079 - val_loss: 0.4025 - val_acc: 0.2444\n",
      "Epoch 5291/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3526 - acc: 0.2087 - val_loss: 0.4357 - val_acc: 0.2444\n",
      "Epoch 5292/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3656 - acc: 0.2079 - val_loss: 0.4329 - val_acc: 0.2444\n",
      "Epoch 5293/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3771 - acc: 0.2083 - val_loss: 0.4391 - val_acc: 0.2444\n",
      "Epoch 5294/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3701 - acc: 0.2075 - val_loss: 0.5329 - val_acc: 0.2444\n",
      "Epoch 5295/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3740 - acc: 0.2079 - val_loss: 0.4965 - val_acc: 0.2444\n",
      "Epoch 5296/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3981 - acc: 0.2083 - val_loss: 0.4054 - val_acc: 0.2444\n",
      "Epoch 5297/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3524 - acc: 0.2083 - val_loss: 0.4134 - val_acc: 0.2444\n",
      "Epoch 5298/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3441 - acc: 0.2083 - val_loss: 0.4150 - val_acc: 0.2444\n",
      "Epoch 5299/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3519 - acc: 0.2092 - val_loss: 0.4375 - val_acc: 0.2444\n",
      "Epoch 5300/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3736 - acc: 0.2079 - val_loss: 0.5041 - val_acc: 0.2444\n",
      "Epoch 5301/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3442 - acc: 0.2087 - val_loss: 0.5335 - val_acc: 0.2444\n",
      "Epoch 5302/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3599 - acc: 0.2083 - val_loss: 0.4203 - val_acc: 0.2444\n",
      "Epoch 5303/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3678 - acc: 0.2079 - val_loss: 0.4160 - val_acc: 0.2444\n",
      "Epoch 5304/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3442 - acc: 0.2075 - val_loss: 0.4305 - val_acc: 0.2444\n",
      "Epoch 5305/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3783 - acc: 0.2075 - val_loss: 0.4932 - val_acc: 0.2444\n",
      "Epoch 5306/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3440 - acc: 0.2079 - val_loss: 0.4252 - val_acc: 0.2444\n",
      "Epoch 5307/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3505 - acc: 0.2083 - val_loss: 0.4051 - val_acc: 0.2444\n",
      "Epoch 5308/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3543 - acc: 0.2092 - val_loss: 0.4414 - val_acc: 0.2444\n",
      "Epoch 5309/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3588 - acc: 0.2079 - val_loss: 0.4125 - val_acc: 0.2444\n",
      "Epoch 5310/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3572 - acc: 0.2083 - val_loss: 0.4341 - val_acc: 0.2444\n",
      "Epoch 5311/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3460 - acc: 0.2083 - val_loss: 0.4115 - val_acc: 0.2444\n",
      "Epoch 5312/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3532 - acc: 0.2083 - val_loss: 0.4754 - val_acc: 0.2444\n",
      "Epoch 5313/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3468 - acc: 0.2083 - val_loss: 0.3965 - val_acc: 0.2444\n",
      "Epoch 5314/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3556 - acc: 0.2087 - val_loss: 0.5885 - val_acc: 0.2444\n",
      "Epoch 5315/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3935 - acc: 0.2079 - val_loss: 0.4233 - val_acc: 0.2444\n",
      "Epoch 5316/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3530 - acc: 0.2087 - val_loss: 0.4853 - val_acc: 0.2444\n",
      "Epoch 5317/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3642 - acc: 0.2079 - val_loss: 0.4657 - val_acc: 0.2444\n",
      "Epoch 5318/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3540 - acc: 0.2083 - val_loss: 0.4124 - val_acc: 0.2444\n",
      "Epoch 5319/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3456 - acc: 0.2075 - val_loss: 0.3951 - val_acc: 0.2444\n",
      "Epoch 5320/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3864 - acc: 0.2075 - val_loss: 0.4161 - val_acc: 0.2444\n",
      "Epoch 5321/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3533 - acc: 0.2079 - val_loss: 0.3943 - val_acc: 0.2444\n",
      "Epoch 5322/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3736 - acc: 0.2083 - val_loss: 0.4105 - val_acc: 0.2444\n",
      "Epoch 5323/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3476 - acc: 0.2083 - val_loss: 0.4181 - val_acc: 0.2444\n",
      "Epoch 5324/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3605 - acc: 0.2092 - val_loss: 0.4798 - val_acc: 0.2444\n",
      "Epoch 5325/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3824 - acc: 0.2083 - val_loss: 0.4758 - val_acc: 0.2444\n",
      "Epoch 5326/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3531 - acc: 0.2087 - val_loss: 0.4196 - val_acc: 0.2444\n",
      "Epoch 5327/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3567 - acc: 0.2083 - val_loss: 0.4499 - val_acc: 0.2444\n",
      "Epoch 5328/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3416 - acc: 0.2087 - val_loss: 0.4356 - val_acc: 0.2444\n",
      "Epoch 5329/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3569 - acc: 0.2087 - val_loss: 0.4174 - val_acc: 0.2444\n",
      "Epoch 5330/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3741 - acc: 0.2079 - val_loss: 0.4418 - val_acc: 0.2444\n",
      "Epoch 5331/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3702 - acc: 0.2087 - val_loss: 0.4104 - val_acc: 0.2444\n",
      "Epoch 5332/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3695 - acc: 0.2083 - val_loss: 0.5786 - val_acc: 0.2407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5333/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3869 - acc: 0.2079 - val_loss: 0.4061 - val_acc: 0.2444\n",
      "Epoch 5334/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3482 - acc: 0.2087 - val_loss: 0.4183 - val_acc: 0.2444\n",
      "Epoch 5335/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3647 - acc: 0.2079 - val_loss: 0.4274 - val_acc: 0.2444\n",
      "Epoch 5336/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3714 - acc: 0.2083 - val_loss: 0.4157 - val_acc: 0.2444\n",
      "Epoch 5337/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3468 - acc: 0.2083 - val_loss: 0.4022 - val_acc: 0.2444\n",
      "Epoch 5338/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3580 - acc: 0.2087 - val_loss: 0.4106 - val_acc: 0.2444\n",
      "Epoch 5339/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3709 - acc: 0.2087 - val_loss: 0.5628 - val_acc: 0.2407\n",
      "Epoch 5340/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3979 - acc: 0.2092 - val_loss: 0.4373 - val_acc: 0.2444\n",
      "Epoch 5341/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3836 - acc: 0.2079 - val_loss: 0.4500 - val_acc: 0.2444\n",
      "Epoch 5342/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3481 - acc: 0.2083 - val_loss: 0.4163 - val_acc: 0.2444\n",
      "Epoch 5343/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3536 - acc: 0.2087 - val_loss: 0.4161 - val_acc: 0.2444\n",
      "Epoch 5344/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3475 - acc: 0.2087 - val_loss: 0.4397 - val_acc: 0.2444\n",
      "Epoch 5345/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3526 - acc: 0.2087 - val_loss: 0.4221 - val_acc: 0.2444\n",
      "Epoch 5346/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3733 - acc: 0.2083 - val_loss: 0.4108 - val_acc: 0.2444\n",
      "Epoch 5347/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3615 - acc: 0.2092 - val_loss: 0.4006 - val_acc: 0.2444\n",
      "Epoch 5348/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3520 - acc: 0.2087 - val_loss: 0.4082 - val_acc: 0.2444\n",
      "Epoch 5349/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3705 - acc: 0.2092 - val_loss: 0.3961 - val_acc: 0.2444\n",
      "Epoch 5350/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3651 - acc: 0.2087 - val_loss: 0.4661 - val_acc: 0.2444\n",
      "Epoch 5351/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3502 - acc: 0.2092 - val_loss: 0.4091 - val_acc: 0.2444\n",
      "Epoch 5352/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3480 - acc: 0.2083 - val_loss: 0.4208 - val_acc: 0.2444\n",
      "Epoch 5353/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3535 - acc: 0.2083 - val_loss: 0.4309 - val_acc: 0.2444\n",
      "Epoch 5354/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3516 - acc: 0.2087 - val_loss: 0.4791 - val_acc: 0.2444\n",
      "Epoch 5355/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3444 - acc: 0.2087 - val_loss: 0.4172 - val_acc: 0.2444\n",
      "Epoch 5356/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3424 - acc: 0.2087 - val_loss: 0.4033 - val_acc: 0.2444\n",
      "Epoch 5357/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3649 - acc: 0.2092 - val_loss: 0.4115 - val_acc: 0.2444\n",
      "Epoch 5358/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3421 - acc: 0.2083 - val_loss: 0.4815 - val_acc: 0.2444\n",
      "Epoch 5359/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3484 - acc: 0.2083 - val_loss: 0.4181 - val_acc: 0.2444\n",
      "Epoch 5360/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3621 - acc: 0.2087 - val_loss: 0.4578 - val_acc: 0.2444\n",
      "Epoch 5361/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3561 - acc: 0.2079 - val_loss: 0.4099 - val_acc: 0.2444\n",
      "Epoch 5362/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3585 - acc: 0.2087 - val_loss: 0.4025 - val_acc: 0.2444\n",
      "Epoch 5363/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3648 - acc: 0.2071 - val_loss: 0.4508 - val_acc: 0.2444\n",
      "Epoch 5364/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3481 - acc: 0.2083 - val_loss: 0.5193 - val_acc: 0.2444\n",
      "Epoch 5365/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3506 - acc: 0.2087 - val_loss: 0.4129 - val_acc: 0.2444\n",
      "Epoch 5366/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3406 - acc: 0.2087 - val_loss: 0.4314 - val_acc: 0.2444\n",
      "Epoch 5367/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3421 - acc: 0.2087 - val_loss: 0.4450 - val_acc: 0.2444\n",
      "Epoch 5368/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3475 - acc: 0.2087 - val_loss: 0.4226 - val_acc: 0.2444\n",
      "Epoch 5369/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3569 - acc: 0.2087 - val_loss: 0.3997 - val_acc: 0.2444\n",
      "Epoch 5370/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3724 - acc: 0.2092 - val_loss: 0.4257 - val_acc: 0.2444\n",
      "Epoch 5371/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3470 - acc: 0.2083 - val_loss: 0.3921 - val_acc: 0.2444\n",
      "Epoch 5372/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3725 - acc: 0.2096 - val_loss: 0.4617 - val_acc: 0.2444\n",
      "Epoch 5373/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3646 - acc: 0.2087 - val_loss: 0.3935 - val_acc: 0.2444\n",
      "Epoch 5374/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3908 - acc: 0.2087 - val_loss: 0.4337 - val_acc: 0.2444\n",
      "Epoch 5375/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3561 - acc: 0.2087 - val_loss: 0.4017 - val_acc: 0.2444\n",
      "Epoch 5376/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3504 - acc: 0.2096 - val_loss: 0.5193 - val_acc: 0.2444\n",
      "Epoch 5377/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3610 - acc: 0.2092 - val_loss: 0.4363 - val_acc: 0.2444\n",
      "Epoch 5378/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3564 - acc: 0.2087 - val_loss: 0.5519 - val_acc: 0.2407\n",
      "Epoch 5379/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3830 - acc: 0.2083 - val_loss: 0.4491 - val_acc: 0.2444\n",
      "Epoch 5380/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.3500 - acc: 0.2092 - val_loss: 0.4046 - val_acc: 0.2444\n",
      "Epoch 5381/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3667 - acc: 0.2092 - val_loss: 0.4532 - val_acc: 0.2444\n",
      "Epoch 5382/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3439 - acc: 0.2092 - val_loss: 0.4483 - val_acc: 0.2444\n",
      "Epoch 5383/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3761 - acc: 0.2092 - val_loss: 0.4681 - val_acc: 0.2444\n",
      "Epoch 5384/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3484 - acc: 0.2087 - val_loss: 0.4169 - val_acc: 0.2444\n",
      "Epoch 5385/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3486 - acc: 0.2092 - val_loss: 0.4062 - val_acc: 0.2444\n",
      "Epoch 5386/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3641 - acc: 0.2083 - val_loss: 0.4081 - val_acc: 0.2444\n",
      "Epoch 5387/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3730 - acc: 0.2087 - val_loss: 0.4000 - val_acc: 0.2444\n",
      "Epoch 5388/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3689 - acc: 0.2079 - val_loss: 0.4084 - val_acc: 0.2444\n",
      "Epoch 5389/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3564 - acc: 0.2083 - val_loss: 0.4226 - val_acc: 0.2444\n",
      "Epoch 5390/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3514 - acc: 0.2087 - val_loss: 0.3938 - val_acc: 0.2444\n",
      "Epoch 5391/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3411 - acc: 0.2083 - val_loss: 0.4017 - val_acc: 0.2444\n",
      "Epoch 5392/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3853 - acc: 0.2087 - val_loss: 0.4190 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5393/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3721 - acc: 0.2092 - val_loss: 0.6908 - val_acc: 0.2444\n",
      "Epoch 5394/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3630 - acc: 0.2079 - val_loss: 0.4365 - val_acc: 0.2444\n",
      "Epoch 5395/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3432 - acc: 0.2092 - val_loss: 0.3967 - val_acc: 0.2444\n",
      "Epoch 5396/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3449 - acc: 0.2092 - val_loss: 0.4458 - val_acc: 0.2444\n",
      "Epoch 5397/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3628 - acc: 0.2092 - val_loss: 0.5781 - val_acc: 0.2444\n",
      "Epoch 5398/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3566 - acc: 0.2087 - val_loss: 0.4488 - val_acc: 0.2444\n",
      "Epoch 5399/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3912 - acc: 0.2092 - val_loss: 0.4295 - val_acc: 0.2444\n",
      "Epoch 5400/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3786 - acc: 0.2096 - val_loss: 0.3974 - val_acc: 0.2444\n",
      "Epoch 5401/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3396 - acc: 0.2092 - val_loss: 0.4127 - val_acc: 0.2444\n",
      "Epoch 5402/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3387 - acc: 0.2096 - val_loss: 0.3983 - val_acc: 0.2444\n",
      "Epoch 5403/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3657 - acc: 0.2079 - val_loss: 0.4291 - val_acc: 0.2444\n",
      "Epoch 5404/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3491 - acc: 0.2087 - val_loss: 0.3976 - val_acc: 0.2444\n",
      "Epoch 5405/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3688 - acc: 0.2087 - val_loss: 0.4251 - val_acc: 0.2444\n",
      "Epoch 5406/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3487 - acc: 0.2092 - val_loss: 0.4201 - val_acc: 0.2444\n",
      "Epoch 5407/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3517 - acc: 0.2092 - val_loss: 0.4648 - val_acc: 0.2444\n",
      "Epoch 5408/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3485 - acc: 0.2083 - val_loss: 0.4429 - val_acc: 0.2444\n",
      "Epoch 5409/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3810 - acc: 0.2083 - val_loss: 0.4140 - val_acc: 0.2444\n",
      "Epoch 5410/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3540 - acc: 0.2083 - val_loss: 0.4754 - val_acc: 0.2444\n",
      "Epoch 5411/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3512 - acc: 0.2092 - val_loss: 0.4762 - val_acc: 0.2444\n",
      "Epoch 5412/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3624 - acc: 0.2092 - val_loss: 0.4354 - val_acc: 0.2444\n",
      "Epoch 5413/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3452 - acc: 0.2087 - val_loss: 0.4128 - val_acc: 0.2444\n",
      "Epoch 5414/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3468 - acc: 0.2087 - val_loss: 0.4319 - val_acc: 0.2444\n",
      "Epoch 5415/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3415 - acc: 0.2083 - val_loss: 0.4235 - val_acc: 0.2444\n",
      "Epoch 5416/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3843 - acc: 0.2079 - val_loss: 0.5476 - val_acc: 0.2444\n",
      "Epoch 5417/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3368 - acc: 0.2092 - val_loss: 0.4135 - val_acc: 0.2444\n",
      "Epoch 5418/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3465 - acc: 0.2087 - val_loss: 0.4129 - val_acc: 0.2444\n",
      "Epoch 5419/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3650 - acc: 0.2083 - val_loss: 0.4584 - val_acc: 0.2444\n",
      "Epoch 5420/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3649 - acc: 0.2087 - val_loss: 0.4378 - val_acc: 0.2444\n",
      "Epoch 5421/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3411 - acc: 0.2092 - val_loss: 0.4566 - val_acc: 0.2444\n",
      "Epoch 5422/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3528 - acc: 0.2087 - val_loss: 0.4533 - val_acc: 0.2444\n",
      "Epoch 5423/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3730 - acc: 0.2083 - val_loss: 0.5247 - val_acc: 0.2444\n",
      "Epoch 5424/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3531 - acc: 0.2087 - val_loss: 0.4105 - val_acc: 0.2444\n",
      "Epoch 5425/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3549 - acc: 0.2087 - val_loss: 0.4382 - val_acc: 0.2444\n",
      "Epoch 5426/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3728 - acc: 0.2092 - val_loss: 0.5020 - val_acc: 0.2444\n",
      "Epoch 5427/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4453 - acc: 0.2075 - val_loss: 0.4514 - val_acc: 0.2444\n",
      "Epoch 5428/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3504 - acc: 0.2087 - val_loss: 0.4119 - val_acc: 0.2444\n",
      "Epoch 5429/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3774 - acc: 0.2079 - val_loss: 0.4060 - val_acc: 0.2444\n",
      "Epoch 5430/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3542 - acc: 0.2083 - val_loss: 0.4094 - val_acc: 0.2444\n",
      "Epoch 5431/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3549 - acc: 0.2092 - val_loss: 0.4267 - val_acc: 0.2444\n",
      "Epoch 5432/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3508 - acc: 0.2092 - val_loss: 0.4414 - val_acc: 0.2444\n",
      "Epoch 5433/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3826 - acc: 0.2087 - val_loss: 0.4026 - val_acc: 0.2444\n",
      "Epoch 5434/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3544 - acc: 0.2083 - val_loss: 0.4013 - val_acc: 0.2444\n",
      "Epoch 5435/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3537 - acc: 0.2092 - val_loss: 0.4269 - val_acc: 0.2444\n",
      "Epoch 5436/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3546 - acc: 0.2087 - val_loss: 0.4027 - val_acc: 0.2444\n",
      "Epoch 5437/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3598 - acc: 0.2092 - val_loss: 0.4851 - val_acc: 0.2444\n",
      "Epoch 5438/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3755 - acc: 0.2096 - val_loss: 0.4091 - val_acc: 0.2444\n",
      "Epoch 5439/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3775 - acc: 0.2092 - val_loss: 0.4033 - val_acc: 0.2444\n",
      "Epoch 5440/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3592 - acc: 0.2087 - val_loss: 0.4388 - val_acc: 0.2444\n",
      "Epoch 5441/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3518 - acc: 0.2083 - val_loss: 0.4758 - val_acc: 0.2444\n",
      "Epoch 5442/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3723 - acc: 0.2083 - val_loss: 0.4237 - val_acc: 0.2444\n",
      "Epoch 5443/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3374 - acc: 0.2092 - val_loss: 0.4275 - val_acc: 0.2444\n",
      "Epoch 5444/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3647 - acc: 0.2087 - val_loss: 0.3988 - val_acc: 0.2444\n",
      "Epoch 5445/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3435 - acc: 0.2087 - val_loss: 0.4070 - val_acc: 0.2444\n",
      "Epoch 5446/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3571 - acc: 0.2092 - val_loss: 0.7045 - val_acc: 0.2407\n",
      "Epoch 5447/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3524 - acc: 0.2087 - val_loss: 0.4047 - val_acc: 0.2444\n",
      "Epoch 5448/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3456 - acc: 0.2092 - val_loss: 0.4153 - val_acc: 0.2444\n",
      "Epoch 5449/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3389 - acc: 0.2083 - val_loss: 0.4045 - val_acc: 0.2444\n",
      "Epoch 5450/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3544 - acc: 0.2083 - val_loss: 0.4895 - val_acc: 0.2444\n",
      "Epoch 5451/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3439 - acc: 0.2079 - val_loss: 0.4681 - val_acc: 0.2444\n",
      "Epoch 5452/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3519 - acc: 0.2083 - val_loss: 0.4325 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5453/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3509 - acc: 0.2092 - val_loss: 0.4221 - val_acc: 0.2444\n",
      "Epoch 5454/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3388 - acc: 0.2092 - val_loss: 0.4180 - val_acc: 0.2444\n",
      "Epoch 5455/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3581 - acc: 0.2083 - val_loss: 0.4106 - val_acc: 0.2444\n",
      "Epoch 5456/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3534 - acc: 0.2092 - val_loss: 0.4157 - val_acc: 0.2444\n",
      "Epoch 5457/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3772 - acc: 0.2079 - val_loss: 0.4654 - val_acc: 0.2444\n",
      "Epoch 5458/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3779 - acc: 0.2087 - val_loss: 0.4030 - val_acc: 0.2444\n",
      "Epoch 5459/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3606 - acc: 0.2083 - val_loss: 0.4148 - val_acc: 0.2444\n",
      "Epoch 5460/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3512 - acc: 0.2092 - val_loss: 0.4230 - val_acc: 0.2444\n",
      "Epoch 5461/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3509 - acc: 0.2083 - val_loss: 0.4411 - val_acc: 0.2444\n",
      "Epoch 5462/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3460 - acc: 0.2092 - val_loss: 0.4157 - val_acc: 0.2444\n",
      "Epoch 5463/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3450 - acc: 0.2087 - val_loss: 0.3927 - val_acc: 0.2444\n",
      "Epoch 5464/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3993 - acc: 0.2087 - val_loss: 0.4776 - val_acc: 0.2444\n",
      "Epoch 5465/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3461 - acc: 0.2092 - val_loss: 0.4366 - val_acc: 0.2444\n",
      "Epoch 5466/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3430 - acc: 0.2087 - val_loss: 0.4033 - val_acc: 0.2444\n",
      "Epoch 5467/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3486 - acc: 0.2092 - val_loss: 0.4436 - val_acc: 0.2444\n",
      "Epoch 5468/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3771 - acc: 0.2087 - val_loss: 0.4197 - val_acc: 0.2444\n",
      "Epoch 5469/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3546 - acc: 0.2087 - val_loss: 0.4247 - val_acc: 0.2444\n",
      "Epoch 5470/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3668 - acc: 0.2083 - val_loss: 0.4202 - val_acc: 0.2444\n",
      "Epoch 5471/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3492 - acc: 0.2092 - val_loss: 0.4156 - val_acc: 0.2444\n",
      "Epoch 5472/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3637 - acc: 0.2087 - val_loss: 0.4105 - val_acc: 0.2444\n",
      "Epoch 5473/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3522 - acc: 0.2087 - val_loss: 0.4513 - val_acc: 0.2444\n",
      "Epoch 5474/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3904 - acc: 0.2087 - val_loss: 0.4849 - val_acc: 0.2444\n",
      "Epoch 5475/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3756 - acc: 0.2092 - val_loss: 0.4553 - val_acc: 0.2444\n",
      "Epoch 5476/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3458 - acc: 0.2087 - val_loss: 0.4063 - val_acc: 0.2444\n",
      "Epoch 5477/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3471 - acc: 0.2087 - val_loss: 0.4065 - val_acc: 0.2444\n",
      "Epoch 5478/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3632 - acc: 0.2087 - val_loss: 0.4029 - val_acc: 0.2444\n",
      "Epoch 5479/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3688 - acc: 0.2092 - val_loss: 0.3984 - val_acc: 0.2444\n",
      "Epoch 5480/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3509 - acc: 0.2083 - val_loss: 0.3894 - val_acc: 0.2444\n",
      "Epoch 5481/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3405 - acc: 0.2087 - val_loss: 0.4567 - val_acc: 0.2444\n",
      "Epoch 5482/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3657 - acc: 0.2096 - val_loss: 0.4633 - val_acc: 0.2444\n",
      "Epoch 5483/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3670 - acc: 0.2092 - val_loss: 0.4444 - val_acc: 0.2444\n",
      "Epoch 5484/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3521 - acc: 0.2083 - val_loss: 0.4254 - val_acc: 0.2444\n",
      "Epoch 5485/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3406 - acc: 0.2096 - val_loss: 0.4127 - val_acc: 0.2444\n",
      "Epoch 5486/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3497 - acc: 0.2087 - val_loss: 0.3958 - val_acc: 0.2444\n",
      "Epoch 5487/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3832 - acc: 0.2083 - val_loss: 0.4593 - val_acc: 0.2444\n",
      "Epoch 5488/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3614 - acc: 0.2087 - val_loss: 0.4096 - val_acc: 0.2444\n",
      "Epoch 5489/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3408 - acc: 0.2087 - val_loss: 0.4042 - val_acc: 0.2444\n",
      "Epoch 5490/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3518 - acc: 0.2092 - val_loss: 0.4134 - val_acc: 0.2444\n",
      "Epoch 5491/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3498 - acc: 0.2079 - val_loss: 0.3910 - val_acc: 0.2444\n",
      "Epoch 5492/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3618 - acc: 0.2075 - val_loss: 0.4281 - val_acc: 0.2444\n",
      "Epoch 5493/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3625 - acc: 0.2087 - val_loss: 0.4017 - val_acc: 0.2444\n",
      "Epoch 5494/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3369 - acc: 0.2087 - val_loss: 0.4202 - val_acc: 0.2444\n",
      "Epoch 5495/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3557 - acc: 0.2083 - val_loss: 0.3923 - val_acc: 0.2444\n",
      "Epoch 5496/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3644 - acc: 0.2087 - val_loss: 0.3926 - val_acc: 0.2444\n",
      "Epoch 5497/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3613 - acc: 0.2083 - val_loss: 0.4351 - val_acc: 0.2444\n",
      "Epoch 5498/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3700 - acc: 0.2083 - val_loss: 0.5323 - val_acc: 0.2407\n",
      "Epoch 5499/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3797 - acc: 0.2092 - val_loss: 0.4120 - val_acc: 0.2444\n",
      "Epoch 5500/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3790 - acc: 0.2092 - val_loss: 0.5560 - val_acc: 0.2444\n",
      "Epoch 5501/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3613 - acc: 0.2083 - val_loss: 0.4253 - val_acc: 0.2444\n",
      "Epoch 5502/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3535 - acc: 0.2087 - val_loss: 0.4249 - val_acc: 0.2444\n",
      "Epoch 5503/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3434 - acc: 0.2092 - val_loss: 0.4180 - val_acc: 0.2444\n",
      "Epoch 5504/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3323 - acc: 0.2087 - val_loss: 0.4219 - val_acc: 0.2444\n",
      "Epoch 5505/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3411 - acc: 0.2087 - val_loss: 0.4383 - val_acc: 0.2444\n",
      "Epoch 5506/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3560 - acc: 0.2083 - val_loss: 0.4870 - val_acc: 0.2407\n",
      "Epoch 5507/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3382 - acc: 0.2083 - val_loss: 0.4164 - val_acc: 0.2444\n",
      "Epoch 5508/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3654 - acc: 0.2087 - val_loss: 0.4161 - val_acc: 0.2444\n",
      "Epoch 5509/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3472 - acc: 0.2083 - val_loss: 0.4085 - val_acc: 0.2444\n",
      "Epoch 5510/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3590 - acc: 0.2083 - val_loss: 0.5567 - val_acc: 0.2444\n",
      "Epoch 5511/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3621 - acc: 0.2075 - val_loss: 0.4026 - val_acc: 0.2444\n",
      "Epoch 5512/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3454 - acc: 0.2079 - val_loss: 0.4073 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5513/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3506 - acc: 0.2087 - val_loss: 0.5296 - val_acc: 0.2444\n",
      "Epoch 5514/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3503 - acc: 0.2092 - val_loss: 0.4277 - val_acc: 0.2444\n",
      "Epoch 5515/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3478 - acc: 0.2087 - val_loss: 0.4328 - val_acc: 0.2444\n",
      "Epoch 5516/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3533 - acc: 0.2087 - val_loss: 0.4096 - val_acc: 0.2444\n",
      "Epoch 5517/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3602 - acc: 0.2087 - val_loss: 0.3999 - val_acc: 0.2444\n",
      "Epoch 5518/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3504 - acc: 0.2092 - val_loss: 0.3856 - val_acc: 0.2444\n",
      "Epoch 5519/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3450 - acc: 0.2087 - val_loss: 0.4071 - val_acc: 0.2444\n",
      "Epoch 5520/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3817 - acc: 0.2092 - val_loss: 0.5292 - val_acc: 0.2444\n",
      "Epoch 5521/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3519 - acc: 0.2092 - val_loss: 0.4026 - val_acc: 0.2444\n",
      "Epoch 5522/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3386 - acc: 0.2092 - val_loss: 0.4099 - val_acc: 0.2444\n",
      "Epoch 5523/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3286 - acc: 0.2087 - val_loss: 0.4245 - val_acc: 0.2444\n",
      "Epoch 5524/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3546 - acc: 0.2087 - val_loss: 0.4542 - val_acc: 0.2444\n",
      "Epoch 5525/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3663 - acc: 0.2079 - val_loss: 0.4712 - val_acc: 0.2444\n",
      "Epoch 5526/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3606 - acc: 0.2087 - val_loss: 0.4035 - val_acc: 0.2444\n",
      "Epoch 5527/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3415 - acc: 0.2083 - val_loss: 0.4197 - val_acc: 0.2444\n",
      "Epoch 5528/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3486 - acc: 0.2092 - val_loss: 0.4421 - val_acc: 0.2444\n",
      "Epoch 5529/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3515 - acc: 0.2087 - val_loss: 0.4282 - val_acc: 0.2444\n",
      "Epoch 5530/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3576 - acc: 0.2083 - val_loss: 0.4232 - val_acc: 0.2444\n",
      "Epoch 5531/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3519 - acc: 0.2083 - val_loss: 0.4443 - val_acc: 0.2444\n",
      "Epoch 5532/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3510 - acc: 0.2083 - val_loss: 0.4067 - val_acc: 0.2444\n",
      "Epoch 5533/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3627 - acc: 0.2092 - val_loss: 0.4236 - val_acc: 0.2444\n",
      "Epoch 5534/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3573 - acc: 0.2092 - val_loss: 0.4159 - val_acc: 0.2444\n",
      "Epoch 5535/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3587 - acc: 0.2092 - val_loss: 0.3898 - val_acc: 0.2444\n",
      "Epoch 5536/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3566 - acc: 0.2087 - val_loss: 0.3957 - val_acc: 0.2444\n",
      "Epoch 5537/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3610 - acc: 0.2092 - val_loss: 0.5228 - val_acc: 0.2444\n",
      "Epoch 5538/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3458 - acc: 0.2096 - val_loss: 0.4177 - val_acc: 0.2444\n",
      "Epoch 5539/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3450 - acc: 0.2087 - val_loss: 0.4536 - val_acc: 0.2444\n",
      "Epoch 5540/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3676 - acc: 0.2092 - val_loss: 0.4399 - val_acc: 0.2444\n",
      "Epoch 5541/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3660 - acc: 0.2087 - val_loss: 0.4061 - val_acc: 0.2444\n",
      "Epoch 5542/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3666 - acc: 0.2092 - val_loss: 0.4036 - val_acc: 0.2444\n",
      "Epoch 5543/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3413 - acc: 0.2087 - val_loss: 0.3923 - val_acc: 0.2444\n",
      "Epoch 5544/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3551 - acc: 0.2092 - val_loss: 0.4407 - val_acc: 0.2444\n",
      "Epoch 5545/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3418 - acc: 0.2079 - val_loss: 0.4270 - val_acc: 0.2444\n",
      "Epoch 5546/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3408 - acc: 0.2096 - val_loss: 0.4283 - val_acc: 0.2444\n",
      "Epoch 5547/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4145 - acc: 0.2079 - val_loss: 0.4634 - val_acc: 0.2444\n",
      "Epoch 5548/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3478 - acc: 0.2092 - val_loss: 0.4322 - val_acc: 0.2444\n",
      "Epoch 5549/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3357 - acc: 0.2092 - val_loss: 0.4923 - val_acc: 0.2444\n",
      "Epoch 5550/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3677 - acc: 0.2083 - val_loss: 0.4380 - val_acc: 0.2444\n",
      "Epoch 5551/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3438 - acc: 0.2087 - val_loss: 0.4097 - val_acc: 0.2444\n",
      "Epoch 5552/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3385 - acc: 0.2083 - val_loss: 0.5700 - val_acc: 0.2444\n",
      "Epoch 5553/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3687 - acc: 0.2083 - val_loss: 0.4154 - val_acc: 0.2444\n",
      "Epoch 5554/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3388 - acc: 0.2087 - val_loss: 0.3971 - val_acc: 0.2444\n",
      "Epoch 5555/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3555 - acc: 0.2092 - val_loss: 0.4357 - val_acc: 0.2444\n",
      "Epoch 5556/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3418 - acc: 0.2087 - val_loss: 0.4031 - val_acc: 0.2444\n",
      "Epoch 5557/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3523 - acc: 0.2092 - val_loss: 0.4072 - val_acc: 0.2444\n",
      "Epoch 5558/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3696 - acc: 0.2092 - val_loss: 0.3925 - val_acc: 0.2444\n",
      "Epoch 5559/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3561 - acc: 0.2083 - val_loss: 0.4419 - val_acc: 0.2444\n",
      "Epoch 5560/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3438 - acc: 0.2083 - val_loss: 0.4017 - val_acc: 0.2444\n",
      "Epoch 5561/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3375 - acc: 0.2092 - val_loss: 0.4314 - val_acc: 0.2444\n",
      "Epoch 5562/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3546 - acc: 0.2087 - val_loss: 0.4333 - val_acc: 0.2444\n",
      "Epoch 5563/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3493 - acc: 0.2079 - val_loss: 0.4219 - val_acc: 0.2444\n",
      "Epoch 5564/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3515 - acc: 0.2087 - val_loss: 0.4692 - val_acc: 0.2444\n",
      "Epoch 5565/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3575 - acc: 0.2083 - val_loss: 0.4278 - val_acc: 0.2444\n",
      "Epoch 5566/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3692 - acc: 0.2079 - val_loss: 0.3991 - val_acc: 0.2444\n",
      "Epoch 5567/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3864 - acc: 0.2087 - val_loss: 0.4162 - val_acc: 0.2444\n",
      "Epoch 5568/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3677 - acc: 0.2075 - val_loss: 0.5929 - val_acc: 0.2444\n",
      "Epoch 5569/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3618 - acc: 0.2087 - val_loss: 0.4238 - val_acc: 0.2444\n",
      "Epoch 5570/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3447 - acc: 0.2092 - val_loss: 0.4179 - val_acc: 0.2444\n",
      "Epoch 5571/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3662 - acc: 0.2087 - val_loss: 0.5407 - val_acc: 0.2444\n",
      "Epoch 5572/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3459 - acc: 0.2087 - val_loss: 0.4422 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5573/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3667 - acc: 0.2096 - val_loss: 0.4495 - val_acc: 0.2444\n",
      "Epoch 5574/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3548 - acc: 0.2096 - val_loss: 0.4750 - val_acc: 0.2444\n",
      "Epoch 5575/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3738 - acc: 0.2092 - val_loss: 0.5305 - val_acc: 0.2444\n",
      "Epoch 5576/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3790 - acc: 0.2083 - val_loss: 0.4103 - val_acc: 0.2444\n",
      "Epoch 5577/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3598 - acc: 0.2083 - val_loss: 0.4535 - val_acc: 0.2444\n",
      "Epoch 5578/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3326 - acc: 0.2092 - val_loss: 0.5245 - val_acc: 0.2444\n",
      "Epoch 5579/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3497 - acc: 0.2092 - val_loss: 0.4147 - val_acc: 0.2444\n",
      "Epoch 5580/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3469 - acc: 0.2092 - val_loss: 0.3964 - val_acc: 0.2444\n",
      "Epoch 5581/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3532 - acc: 0.2087 - val_loss: 0.4171 - val_acc: 0.2444\n",
      "Epoch 5582/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3446 - acc: 0.2079 - val_loss: 0.4475 - val_acc: 0.2444\n",
      "Epoch 5583/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3446 - acc: 0.2087 - val_loss: 0.4364 - val_acc: 0.2444\n",
      "Epoch 5584/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3677 - acc: 0.2079 - val_loss: 0.4125 - val_acc: 0.2444\n",
      "Epoch 5585/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3665 - acc: 0.2087 - val_loss: 0.4254 - val_acc: 0.2444\n",
      "Epoch 5586/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3495 - acc: 0.2087 - val_loss: 0.5520 - val_acc: 0.2407\n",
      "Epoch 5587/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3527 - acc: 0.2096 - val_loss: 0.4503 - val_acc: 0.2444\n",
      "Epoch 5588/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3494 - acc: 0.2087 - val_loss: 0.4355 - val_acc: 0.2444\n",
      "Epoch 5589/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3515 - acc: 0.2087 - val_loss: 0.4462 - val_acc: 0.2444\n",
      "Epoch 5590/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3498 - acc: 0.2096 - val_loss: 0.4063 - val_acc: 0.2444\n",
      "Epoch 5591/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3540 - acc: 0.2092 - val_loss: 0.4855 - val_acc: 0.2444\n",
      "Epoch 5592/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3510 - acc: 0.2092 - val_loss: 0.4207 - val_acc: 0.2444\n",
      "Epoch 5593/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3522 - acc: 0.2079 - val_loss: 0.4115 - val_acc: 0.2444\n",
      "Epoch 5594/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3403 - acc: 0.2083 - val_loss: 0.5067 - val_acc: 0.2444\n",
      "Epoch 5595/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3670 - acc: 0.2079 - val_loss: 0.4025 - val_acc: 0.2444\n",
      "Epoch 5596/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3532 - acc: 0.2083 - val_loss: 0.5648 - val_acc: 0.2444\n",
      "Epoch 5597/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3574 - acc: 0.2083 - val_loss: 0.4136 - val_acc: 0.2444\n",
      "Epoch 5598/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3449 - acc: 0.2092 - val_loss: 0.4207 - val_acc: 0.2444\n",
      "Epoch 5599/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3684 - acc: 0.2083 - val_loss: 0.4190 - val_acc: 0.2444\n",
      "Epoch 5600/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3528 - acc: 0.2092 - val_loss: 0.4407 - val_acc: 0.2444\n",
      "Epoch 5601/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3543 - acc: 0.2092 - val_loss: 0.4202 - val_acc: 0.2444\n",
      "Epoch 5602/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3561 - acc: 0.2083 - val_loss: 0.4307 - val_acc: 0.2444\n",
      "Epoch 5603/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3424 - acc: 0.2087 - val_loss: 0.4028 - val_acc: 0.2444\n",
      "Epoch 5604/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3425 - acc: 0.2092 - val_loss: 0.3913 - val_acc: 0.2444\n",
      "Epoch 5605/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3444 - acc: 0.2083 - val_loss: 0.4482 - val_acc: 0.2444\n",
      "Epoch 5606/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3514 - acc: 0.2092 - val_loss: 0.4952 - val_acc: 0.2444\n",
      "Epoch 5607/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3533 - acc: 0.2087 - val_loss: 0.4293 - val_acc: 0.2444\n",
      "Epoch 5608/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3404 - acc: 0.2087 - val_loss: 0.4160 - val_acc: 0.2444\n",
      "Epoch 5609/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3365 - acc: 0.2092 - val_loss: 0.4377 - val_acc: 0.2444\n",
      "Epoch 5610/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3591 - acc: 0.2087 - val_loss: 0.4556 - val_acc: 0.2444\n",
      "Epoch 5611/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3426 - acc: 0.2087 - val_loss: 0.4145 - val_acc: 0.2444\n",
      "Epoch 5612/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3480 - acc: 0.2092 - val_loss: 0.5019 - val_acc: 0.2444\n",
      "Epoch 5613/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3711 - acc: 0.2075 - val_loss: 0.8920 - val_acc: 0.2444\n",
      "Epoch 5614/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3848 - acc: 0.2075 - val_loss: 0.5161 - val_acc: 0.2444\n",
      "Epoch 5615/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3414 - acc: 0.2087 - val_loss: 0.4701 - val_acc: 0.2444\n",
      "Epoch 5616/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3355 - acc: 0.2079 - val_loss: 0.4104 - val_acc: 0.2444\n",
      "Epoch 5617/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3409 - acc: 0.2079 - val_loss: 0.3882 - val_acc: 0.2444\n",
      "Epoch 5618/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3408 - acc: 0.2087 - val_loss: 0.4187 - val_acc: 0.2444\n",
      "Epoch 5619/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3485 - acc: 0.2087 - val_loss: 0.3984 - val_acc: 0.2444\n",
      "Epoch 5620/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3708 - acc: 0.2079 - val_loss: 0.4288 - val_acc: 0.2444\n",
      "Epoch 5621/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3452 - acc: 0.2087 - val_loss: 0.3996 - val_acc: 0.2444\n",
      "Epoch 5622/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3451 - acc: 0.2087 - val_loss: 0.4101 - val_acc: 0.2444\n",
      "Epoch 5623/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3602 - acc: 0.2079 - val_loss: 0.4074 - val_acc: 0.2444\n",
      "Epoch 5624/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3835 - acc: 0.2075 - val_loss: 0.4015 - val_acc: 0.2444\n",
      "Epoch 5625/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3653 - acc: 0.2092 - val_loss: 0.4296 - val_acc: 0.2444\n",
      "Epoch 5626/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3702 - acc: 0.2079 - val_loss: 0.3948 - val_acc: 0.2444\n",
      "Epoch 5627/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3737 - acc: 0.2083 - val_loss: 0.4166 - val_acc: 0.2444\n",
      "Epoch 5628/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3418 - acc: 0.2083 - val_loss: 0.4127 - val_acc: 0.2444\n",
      "Epoch 5629/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3335 - acc: 0.2087 - val_loss: 0.4085 - val_acc: 0.2444\n",
      "Epoch 5630/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3410 - acc: 0.2092 - val_loss: 0.4545 - val_acc: 0.2444\n",
      "Epoch 5631/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3690 - acc: 0.2083 - val_loss: 0.6609 - val_acc: 0.2444\n",
      "Epoch 5632/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3594 - acc: 0.2079 - val_loss: 0.4509 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5633/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3424 - acc: 0.2092 - val_loss: 0.4223 - val_acc: 0.2444\n",
      "Epoch 5634/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3561 - acc: 0.2083 - val_loss: 0.4112 - val_acc: 0.2444\n",
      "Epoch 5635/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3453 - acc: 0.2092 - val_loss: 0.4435 - val_acc: 0.2444\n",
      "Epoch 5636/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3599 - acc: 0.2079 - val_loss: 0.4196 - val_acc: 0.2444\n",
      "Epoch 5637/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3452 - acc: 0.2087 - val_loss: 0.4506 - val_acc: 0.2444\n",
      "Epoch 5638/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3622 - acc: 0.2092 - val_loss: 0.4073 - val_acc: 0.2444\n",
      "Epoch 5639/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3577 - acc: 0.2075 - val_loss: 0.4184 - val_acc: 0.2444\n",
      "Epoch 5640/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3683 - acc: 0.2092 - val_loss: 0.3959 - val_acc: 0.2444\n",
      "Epoch 5641/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3345 - acc: 0.2083 - val_loss: 0.4331 - val_acc: 0.2444\n",
      "Epoch 5642/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3716 - acc: 0.2092 - val_loss: 0.4268 - val_acc: 0.2444\n",
      "Epoch 5643/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3738 - acc: 0.2083 - val_loss: 0.4148 - val_acc: 0.2444\n",
      "Epoch 5644/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3681 - acc: 0.2083 - val_loss: 0.4014 - val_acc: 0.2444\n",
      "Epoch 5645/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.3554 - acc: 0.2087 - val_loss: 0.4731 - val_acc: 0.2444\n",
      "Epoch 5646/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3466 - acc: 0.2083 - val_loss: 0.4131 - val_acc: 0.2444\n",
      "Epoch 5647/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3726 - acc: 0.2083 - val_loss: 0.4374 - val_acc: 0.2444\n",
      "Epoch 5648/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3411 - acc: 0.2087 - val_loss: 0.4235 - val_acc: 0.2444\n",
      "Epoch 5649/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3508 - acc: 0.2083 - val_loss: 0.4489 - val_acc: 0.2444\n",
      "Epoch 5650/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3419 - acc: 0.2092 - val_loss: 0.4062 - val_acc: 0.2444\n",
      "Epoch 5651/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3398 - acc: 0.2087 - val_loss: 0.4090 - val_acc: 0.2444\n",
      "Epoch 5652/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3942 - acc: 0.2083 - val_loss: 0.4058 - val_acc: 0.2444\n",
      "Epoch 5653/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3404 - acc: 0.2087 - val_loss: 0.4171 - val_acc: 0.2444\n",
      "Epoch 5654/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3443 - acc: 0.2087 - val_loss: 0.5013 - val_acc: 0.2444\n",
      "Epoch 5655/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3466 - acc: 0.2087 - val_loss: 0.4011 - val_acc: 0.2444\n",
      "Epoch 5656/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3568 - acc: 0.2092 - val_loss: 0.4172 - val_acc: 0.2444\n",
      "Epoch 5657/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3468 - acc: 0.2083 - val_loss: 0.4176 - val_acc: 0.2444\n",
      "Epoch 5658/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3458 - acc: 0.2092 - val_loss: 0.4363 - val_acc: 0.2444\n",
      "Epoch 5659/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3501 - acc: 0.2083 - val_loss: 0.4221 - val_acc: 0.2444\n",
      "Epoch 5660/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3428 - acc: 0.2087 - val_loss: 0.4196 - val_acc: 0.2444\n",
      "Epoch 5661/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3434 - acc: 0.2092 - val_loss: 0.4097 - val_acc: 0.2444\n",
      "Epoch 5662/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3640 - acc: 0.2087 - val_loss: 0.4248 - val_acc: 0.2444\n",
      "Epoch 5663/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3618 - acc: 0.2087 - val_loss: 0.3958 - val_acc: 0.2444\n",
      "Epoch 5664/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3637 - acc: 0.2083 - val_loss: 0.4658 - val_acc: 0.2444\n",
      "Epoch 5665/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3687 - acc: 0.2087 - val_loss: 0.4091 - val_acc: 0.2444\n",
      "Epoch 5666/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3538 - acc: 0.2092 - val_loss: 0.4099 - val_acc: 0.2444\n",
      "Epoch 5667/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3731 - acc: 0.2083 - val_loss: 0.5895 - val_acc: 0.2444\n",
      "Epoch 5668/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3515 - acc: 0.2083 - val_loss: 0.4209 - val_acc: 0.2444\n",
      "Epoch 5669/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3504 - acc: 0.2087 - val_loss: 0.4306 - val_acc: 0.2444\n",
      "Epoch 5670/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3305 - acc: 0.2087 - val_loss: 0.4197 - val_acc: 0.2444\n",
      "Epoch 5671/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3540 - acc: 0.2096 - val_loss: 0.4071 - val_acc: 0.2444\n",
      "Epoch 5672/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3383 - acc: 0.2087 - val_loss: 0.4381 - val_acc: 0.2444\n",
      "Epoch 5673/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3432 - acc: 0.2092 - val_loss: 0.4108 - val_acc: 0.2444\n",
      "Epoch 5674/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3583 - acc: 0.2083 - val_loss: 0.4189 - val_acc: 0.2444\n",
      "Epoch 5675/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3356 - acc: 0.2092 - val_loss: 0.4218 - val_acc: 0.2444\n",
      "Epoch 5676/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3751 - acc: 0.2087 - val_loss: 0.4116 - val_acc: 0.2444\n",
      "Epoch 5677/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3430 - acc: 0.2092 - val_loss: 0.4100 - val_acc: 0.2444\n",
      "Epoch 5678/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3443 - acc: 0.2087 - val_loss: 0.4078 - val_acc: 0.2444\n",
      "Epoch 5679/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3513 - acc: 0.2096 - val_loss: 0.4216 - val_acc: 0.2444\n",
      "Epoch 5680/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3438 - acc: 0.2092 - val_loss: 0.4089 - val_acc: 0.2444\n",
      "Epoch 5681/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3886 - acc: 0.2079 - val_loss: 0.4274 - val_acc: 0.2444\n",
      "Epoch 5682/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3423 - acc: 0.2087 - val_loss: 0.3972 - val_acc: 0.2444\n",
      "Epoch 5683/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3490 - acc: 0.2079 - val_loss: 0.4071 - val_acc: 0.2444\n",
      "Epoch 5684/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3560 - acc: 0.2075 - val_loss: 0.4721 - val_acc: 0.2444\n",
      "Epoch 5685/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3472 - acc: 0.2083 - val_loss: 0.4633 - val_acc: 0.2444\n",
      "Epoch 5686/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3659 - acc: 0.2087 - val_loss: 0.4194 - val_acc: 0.2444\n",
      "Epoch 5687/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3754 - acc: 0.2079 - val_loss: 0.4074 - val_acc: 0.2444\n",
      "Epoch 5688/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3458 - acc: 0.2087 - val_loss: 0.4196 - val_acc: 0.2444\n",
      "Epoch 5689/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3325 - acc: 0.2096 - val_loss: 0.3992 - val_acc: 0.2444\n",
      "Epoch 5690/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3505 - acc: 0.2087 - val_loss: 0.4127 - val_acc: 0.2444\n",
      "Epoch 5691/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3628 - acc: 0.2096 - val_loss: 0.4064 - val_acc: 0.2444\n",
      "Epoch 5692/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3437 - acc: 0.2083 - val_loss: 0.4077 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5693/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3541 - acc: 0.2092 - val_loss: 0.5219 - val_acc: 0.2444\n",
      "Epoch 5694/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3521 - acc: 0.2079 - val_loss: 0.4321 - val_acc: 0.2444\n",
      "Epoch 5695/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3570 - acc: 0.2087 - val_loss: 0.4005 - val_acc: 0.2444\n",
      "Epoch 5696/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3543 - acc: 0.2083 - val_loss: 0.4392 - val_acc: 0.2444\n",
      "Epoch 5697/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3705 - acc: 0.2083 - val_loss: 0.4215 - val_acc: 0.2444\n",
      "Epoch 5698/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3540 - acc: 0.2087 - val_loss: 0.4138 - val_acc: 0.2444\n",
      "Epoch 5699/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3380 - acc: 0.2092 - val_loss: 0.4191 - val_acc: 0.2444\n",
      "Epoch 5700/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3498 - acc: 0.2087 - val_loss: 0.4083 - val_acc: 0.2444\n",
      "Epoch 5701/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3450 - acc: 0.2087 - val_loss: 0.4317 - val_acc: 0.2444\n",
      "Epoch 5702/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3585 - acc: 0.2092 - val_loss: 0.4058 - val_acc: 0.2444\n",
      "Epoch 5703/10000\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.3709 - acc: 0.208 - 2s 32ms/step - loss: 0.3712 - acc: 0.2087 - val_loss: 0.4223 - val_acc: 0.2444\n",
      "Epoch 5704/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3540 - acc: 0.2087 - val_loss: 0.4179 - val_acc: 0.2444\n",
      "Epoch 5705/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3567 - acc: 0.2083 - val_loss: 0.4690 - val_acc: 0.2444\n",
      "Epoch 5706/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3573 - acc: 0.2087 - val_loss: 0.4362 - val_acc: 0.2444\n",
      "Epoch 5707/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3649 - acc: 0.2083 - val_loss: 0.4163 - val_acc: 0.2444\n",
      "Epoch 5708/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3430 - acc: 0.2092 - val_loss: 0.3858 - val_acc: 0.2444\n",
      "Epoch 5709/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3477 - acc: 0.2087 - val_loss: 0.4362 - val_acc: 0.2444\n",
      "Epoch 5710/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3806 - acc: 0.2087 - val_loss: 0.6062 - val_acc: 0.2444\n",
      "Epoch 5711/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3515 - acc: 0.2087 - val_loss: 0.4479 - val_acc: 0.2444\n",
      "Epoch 5712/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3383 - acc: 0.2092 - val_loss: 0.4282 - val_acc: 0.2444\n",
      "Epoch 5713/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3481 - acc: 0.2083 - val_loss: 0.4448 - val_acc: 0.2444\n",
      "Epoch 5714/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3574 - acc: 0.2087 - val_loss: 0.4060 - val_acc: 0.2444\n",
      "Epoch 5715/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3421 - acc: 0.2087 - val_loss: 0.6484 - val_acc: 0.2444\n",
      "Epoch 5716/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3709 - acc: 0.2087 - val_loss: 0.4291 - val_acc: 0.2444\n",
      "Epoch 5717/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3354 - acc: 0.2092 - val_loss: 0.4288 - val_acc: 0.2444\n",
      "Epoch 5718/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3404 - acc: 0.2087 - val_loss: 0.4649 - val_acc: 0.2444\n",
      "Epoch 5719/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3583 - acc: 0.2092 - val_loss: 0.4384 - val_acc: 0.2444\n",
      "Epoch 5720/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3434 - acc: 0.2092 - val_loss: 0.4154 - val_acc: 0.2444\n",
      "Epoch 5721/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.3346 - acc: 0.2092 - val_loss: 0.4250 - val_acc: 0.2444\n",
      "Epoch 5722/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3520 - acc: 0.2092 - val_loss: 0.4166 - val_acc: 0.2444\n",
      "Epoch 5723/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3588 - acc: 0.2092 - val_loss: 0.4946 - val_acc: 0.2444\n",
      "Epoch 5724/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3598 - acc: 0.2083 - val_loss: 0.4366 - val_acc: 0.2444\n",
      "Epoch 5725/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3552 - acc: 0.2096 - val_loss: 0.4911 - val_acc: 0.2444\n",
      "Epoch 5726/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3587 - acc: 0.2087 - val_loss: 0.4230 - val_acc: 0.2444\n",
      "Epoch 5727/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3483 - acc: 0.2087 - val_loss: 0.4044 - val_acc: 0.2444\n",
      "Epoch 5728/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3406 - acc: 0.2092 - val_loss: 0.4992 - val_acc: 0.2444\n",
      "Epoch 5729/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3556 - acc: 0.2087 - val_loss: 0.4999 - val_acc: 0.2444\n",
      "Epoch 5730/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3412 - acc: 0.2087 - val_loss: 0.4865 - val_acc: 0.2444\n",
      "Epoch 5731/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3465 - acc: 0.2087 - val_loss: 0.4001 - val_acc: 0.2444\n",
      "Epoch 5732/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3687 - acc: 0.2083 - val_loss: 0.4640 - val_acc: 0.2444\n",
      "Epoch 5733/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3867 - acc: 0.2083 - val_loss: 0.6523 - val_acc: 0.2407\n",
      "Epoch 5734/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3573 - acc: 0.2092 - val_loss: 0.4771 - val_acc: 0.2444\n",
      "Epoch 5735/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3668 - acc: 0.2087 - val_loss: 0.4250 - val_acc: 0.2444\n",
      "Epoch 5736/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3484 - acc: 0.2100 - val_loss: 0.5167 - val_acc: 0.2444\n",
      "Epoch 5737/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3463 - acc: 0.2087 - val_loss: 0.4034 - val_acc: 0.2444\n",
      "Epoch 5738/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3461 - acc: 0.2092 - val_loss: 0.4463 - val_acc: 0.2444\n",
      "Epoch 5739/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3381 - acc: 0.2087 - val_loss: 0.4503 - val_acc: 0.2444\n",
      "Epoch 5740/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3407 - acc: 0.2092 - val_loss: 0.4089 - val_acc: 0.2444\n",
      "Epoch 5741/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3445 - acc: 0.2087 - val_loss: 0.5065 - val_acc: 0.2444\n",
      "Epoch 5742/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3466 - acc: 0.2096 - val_loss: 0.4660 - val_acc: 0.2444\n",
      "Epoch 5743/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3856 - acc: 0.2092 - val_loss: 0.4169 - val_acc: 0.2444\n",
      "Epoch 5744/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3554 - acc: 0.2083 - val_loss: 0.4269 - val_acc: 0.2444\n",
      "Epoch 5745/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3443 - acc: 0.2087 - val_loss: 0.4062 - val_acc: 0.2444\n",
      "Epoch 5746/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3375 - acc: 0.2087 - val_loss: 0.3912 - val_acc: 0.2444\n",
      "Epoch 5747/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3811 - acc: 0.2092 - val_loss: 0.4957 - val_acc: 0.2444\n",
      "Epoch 5748/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3385 - acc: 0.2087 - val_loss: 0.4000 - val_acc: 0.2444\n",
      "Epoch 5749/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3463 - acc: 0.2092 - val_loss: 0.4223 - val_acc: 0.2444\n",
      "Epoch 5750/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3392 - acc: 0.2083 - val_loss: 0.4060 - val_acc: 0.2444\n",
      "Epoch 5751/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3533 - acc: 0.2087 - val_loss: 0.4608 - val_acc: 0.2444\n",
      "Epoch 5752/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3464 - acc: 0.2087 - val_loss: 0.4085 - val_acc: 0.2444\n",
      "Epoch 5753/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3601 - acc: 0.2079 - val_loss: 0.4165 - val_acc: 0.2444\n",
      "Epoch 5754/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3548 - acc: 0.2087 - val_loss: 0.4150 - val_acc: 0.2444\n",
      "Epoch 5755/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3398 - acc: 0.2083 - val_loss: 0.4237 - val_acc: 0.2444\n",
      "Epoch 5756/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3640 - acc: 0.2087 - val_loss: 0.4140 - val_acc: 0.2444\n",
      "Epoch 5757/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3513 - acc: 0.2087 - val_loss: 0.4126 - val_acc: 0.2444\n",
      "Epoch 5758/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3476 - acc: 0.2092 - val_loss: 0.4051 - val_acc: 0.2444\n",
      "Epoch 5759/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3752 - acc: 0.2096 - val_loss: 0.5464 - val_acc: 0.2407\n",
      "Epoch 5760/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3584 - acc: 0.2087 - val_loss: 0.4414 - val_acc: 0.2444\n",
      "Epoch 5761/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3375 - acc: 0.2087 - val_loss: 0.4651 - val_acc: 0.2444\n",
      "Epoch 5762/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3952 - acc: 0.2083 - val_loss: 0.5594 - val_acc: 0.2444\n",
      "Epoch 5763/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3509 - acc: 0.2083 - val_loss: 0.4755 - val_acc: 0.2444\n",
      "Epoch 5764/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3613 - acc: 0.2087 - val_loss: 0.4790 - val_acc: 0.2444\n",
      "Epoch 5765/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3896 - acc: 0.2096 - val_loss: 0.4302 - val_acc: 0.2444\n",
      "Epoch 5766/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3461 - acc: 0.2087 - val_loss: 0.3995 - val_acc: 0.2444\n",
      "Epoch 5767/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3526 - acc: 0.2092 - val_loss: 0.4387 - val_acc: 0.2444\n",
      "Epoch 5768/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3672 - acc: 0.2087 - val_loss: 0.5153 - val_acc: 0.2444\n",
      "Epoch 5769/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3718 - acc: 0.2087 - val_loss: 0.4305 - val_acc: 0.2444\n",
      "Epoch 5770/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3861 - acc: 0.2092 - val_loss: 0.4073 - val_acc: 0.2444\n",
      "Epoch 5771/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3527 - acc: 0.2092 - val_loss: 0.4081 - val_acc: 0.2444\n",
      "Epoch 5772/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3338 - acc: 0.2087 - val_loss: 0.4148 - val_acc: 0.2444\n",
      "Epoch 5773/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3345 - acc: 0.2087 - val_loss: 0.4013 - val_acc: 0.2444\n",
      "Epoch 5774/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3331 - acc: 0.2087 - val_loss: 0.3971 - val_acc: 0.2444\n",
      "Epoch 5775/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3403 - acc: 0.2092 - val_loss: 0.4486 - val_acc: 0.2444\n",
      "Epoch 5776/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3989 - acc: 0.2083 - val_loss: 0.4219 - val_acc: 0.2444\n",
      "Epoch 5777/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.3467 - acc: 0.2092 - val_loss: 0.4155 - val_acc: 0.2444\n",
      "Epoch 5778/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.3506 - acc: 0.2092 - val_loss: 0.5622 - val_acc: 0.2407\n",
      "Epoch 5779/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3655 - acc: 0.2083 - val_loss: 0.4873 - val_acc: 0.2444\n",
      "Epoch 5780/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3446 - acc: 0.2092 - val_loss: 0.3979 - val_acc: 0.2444\n",
      "Epoch 5781/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3440 - acc: 0.2087 - val_loss: 0.4388 - val_acc: 0.2444\n",
      "Epoch 5782/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3330 - acc: 0.2087 - val_loss: 0.4572 - val_acc: 0.2444\n",
      "Epoch 5783/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3449 - acc: 0.2092 - val_loss: 0.4697 - val_acc: 0.2444\n",
      "Epoch 5784/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3496 - acc: 0.2092 - val_loss: 0.4175 - val_acc: 0.2444\n",
      "Epoch 5785/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3358 - acc: 0.2087 - val_loss: 0.4575 - val_acc: 0.2444\n",
      "Epoch 5786/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3563 - acc: 0.2083 - val_loss: 0.4044 - val_acc: 0.2444\n",
      "Epoch 5787/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3470 - acc: 0.2083 - val_loss: 0.4339 - val_acc: 0.2444\n",
      "Epoch 5788/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3562 - acc: 0.2083 - val_loss: 0.4561 - val_acc: 0.2444\n",
      "Epoch 5789/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3362 - acc: 0.2092 - val_loss: 0.4189 - val_acc: 0.2444\n",
      "Epoch 5790/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3530 - acc: 0.2092 - val_loss: 0.4264 - val_acc: 0.2444\n",
      "Epoch 5791/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3607 - acc: 0.2087 - val_loss: 0.5146 - val_acc: 0.2444\n",
      "Epoch 5792/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3406 - acc: 0.2092 - val_loss: 0.4014 - val_acc: 0.2444\n",
      "Epoch 5793/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3469 - acc: 0.2092 - val_loss: 0.4050 - val_acc: 0.2444\n",
      "Epoch 5794/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3471 - acc: 0.2096 - val_loss: 0.4070 - val_acc: 0.2444\n",
      "Epoch 5795/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3463 - acc: 0.2092 - val_loss: 0.4847 - val_acc: 0.2444\n",
      "Epoch 5796/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3415 - acc: 0.2083 - val_loss: 0.4031 - val_acc: 0.2444\n",
      "Epoch 5797/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3539 - acc: 0.2087 - val_loss: 0.4205 - val_acc: 0.2444\n",
      "Epoch 5798/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3358 - acc: 0.2087 - val_loss: 0.3967 - val_acc: 0.2444\n",
      "Epoch 5799/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3449 - acc: 0.2087 - val_loss: 0.4324 - val_acc: 0.2444\n",
      "Epoch 5800/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3831 - acc: 0.2083 - val_loss: 0.5116 - val_acc: 0.2444\n",
      "Epoch 5801/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3598 - acc: 0.2079 - val_loss: 0.4113 - val_acc: 0.2444\n",
      "Epoch 5802/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3394 - acc: 0.2083 - val_loss: 0.4343 - val_acc: 0.2444\n",
      "Epoch 5803/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3522 - acc: 0.2083 - val_loss: 0.4849 - val_acc: 0.2444\n",
      "Epoch 5804/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3459 - acc: 0.2083 - val_loss: 0.4307 - val_acc: 0.2444\n",
      "Epoch 5805/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3417 - acc: 0.2092 - val_loss: 0.4582 - val_acc: 0.2444\n",
      "Epoch 5806/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3501 - acc: 0.2092 - val_loss: 0.4579 - val_acc: 0.2444\n",
      "Epoch 5807/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3349 - acc: 0.2087 - val_loss: 0.4215 - val_acc: 0.2444\n",
      "Epoch 5808/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3545 - acc: 0.2071 - val_loss: 0.5089 - val_acc: 0.2444\n",
      "Epoch 5809/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3444 - acc: 0.2087 - val_loss: 0.4252 - val_acc: 0.2444\n",
      "Epoch 5810/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3591 - acc: 0.2083 - val_loss: 0.4817 - val_acc: 0.2444\n",
      "Epoch 5811/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3454 - acc: 0.2092 - val_loss: 0.4152 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5812/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3502 - acc: 0.2087 - val_loss: 0.4333 - val_acc: 0.2444\n",
      "Epoch 5813/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3387 - acc: 0.2079 - val_loss: 0.4083 - val_acc: 0.2444\n",
      "Epoch 5814/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3710 - acc: 0.2092 - val_loss: 0.4267 - val_acc: 0.2444\n",
      "Epoch 5815/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3980 - acc: 0.2083 - val_loss: 0.4251 - val_acc: 0.2444\n",
      "Epoch 5816/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3489 - acc: 0.2087 - val_loss: 0.4027 - val_acc: 0.2444\n",
      "Epoch 5817/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3419 - acc: 0.2092 - val_loss: 0.4855 - val_acc: 0.2444\n",
      "Epoch 5818/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3500 - acc: 0.2087 - val_loss: 0.4825 - val_acc: 0.2444\n",
      "Epoch 5819/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3746 - acc: 0.2083 - val_loss: 0.4993 - val_acc: 0.2444\n",
      "Epoch 5820/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3390 - acc: 0.2096 - val_loss: 0.4068 - val_acc: 0.2444\n",
      "Epoch 5821/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3326 - acc: 0.2083 - val_loss: 0.4926 - val_acc: 0.2444\n",
      "Epoch 5822/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3419 - acc: 0.2092 - val_loss: 0.3981 - val_acc: 0.2444\n",
      "Epoch 5823/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3348 - acc: 0.2096 - val_loss: 0.4119 - val_acc: 0.2444\n",
      "Epoch 5824/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3468 - acc: 0.2087 - val_loss: 0.3974 - val_acc: 0.2444\n",
      "Epoch 5825/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3341 - acc: 0.2092 - val_loss: 0.4302 - val_acc: 0.2444\n",
      "Epoch 5826/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3473 - acc: 0.2087 - val_loss: 0.3970 - val_acc: 0.2444\n",
      "Epoch 5827/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3685 - acc: 0.2075 - val_loss: 0.4358 - val_acc: 0.2444\n",
      "Epoch 5828/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3655 - acc: 0.2087 - val_loss: 0.4236 - val_acc: 0.2444\n",
      "Epoch 5829/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3458 - acc: 0.2087 - val_loss: 0.4184 - val_acc: 0.2444\n",
      "Epoch 5830/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3712 - acc: 0.2079 - val_loss: 0.5148 - val_acc: 0.2444\n",
      "Epoch 5831/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3343 - acc: 0.2079 - val_loss: 0.4010 - val_acc: 0.2444\n",
      "Epoch 5832/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3446 - acc: 0.2079 - val_loss: 0.3992 - val_acc: 0.2444\n",
      "Epoch 5833/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3564 - acc: 0.2092 - val_loss: 0.4423 - val_acc: 0.2444\n",
      "Epoch 5834/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3495 - acc: 0.2087 - val_loss: 0.4632 - val_acc: 0.2444\n",
      "Epoch 5835/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3340 - acc: 0.2083 - val_loss: 0.3969 - val_acc: 0.2444\n",
      "Epoch 5836/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3369 - acc: 0.2092 - val_loss: 0.4320 - val_acc: 0.2444\n",
      "Epoch 5837/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3415 - acc: 0.2092 - val_loss: 0.4136 - val_acc: 0.2444\n",
      "Epoch 5838/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3577 - acc: 0.2083 - val_loss: 0.4208 - val_acc: 0.2444\n",
      "Epoch 5839/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3391 - acc: 0.2092 - val_loss: 0.4085 - val_acc: 0.2444\n",
      "Epoch 5840/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3607 - acc: 0.2087 - val_loss: 0.4882 - val_acc: 0.2444\n",
      "Epoch 5841/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3406 - acc: 0.2092 - val_loss: 0.4006 - val_acc: 0.2444\n",
      "Epoch 5842/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3611 - acc: 0.2083 - val_loss: 0.3975 - val_acc: 0.2444\n",
      "Epoch 5843/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3351 - acc: 0.2087 - val_loss: 0.4134 - val_acc: 0.2444\n",
      "Epoch 5844/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3483 - acc: 0.2092 - val_loss: 0.4430 - val_acc: 0.2444\n",
      "Epoch 5845/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3555 - acc: 0.2087 - val_loss: 0.3991 - val_acc: 0.2444\n",
      "Epoch 5846/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3397 - acc: 0.2092 - val_loss: 0.5248 - val_acc: 0.2444\n",
      "Epoch 5847/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3608 - acc: 0.2083 - val_loss: 0.5182 - val_acc: 0.2444\n",
      "Epoch 5848/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3519 - acc: 0.2083 - val_loss: 0.4379 - val_acc: 0.2444\n",
      "Epoch 5849/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3562 - acc: 0.2087 - val_loss: 0.4819 - val_acc: 0.2444\n",
      "Epoch 5850/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3482 - acc: 0.2092 - val_loss: 0.3979 - val_acc: 0.2444\n",
      "Epoch 5851/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3826 - acc: 0.2083 - val_loss: 0.6999 - val_acc: 0.2444\n",
      "Epoch 5852/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3590 - acc: 0.2087 - val_loss: 0.4349 - val_acc: 0.2444\n",
      "Epoch 5853/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3584 - acc: 0.2087 - val_loss: 0.4165 - val_acc: 0.2444\n",
      "Epoch 5854/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3769 - acc: 0.2087 - val_loss: 0.4308 - val_acc: 0.2444\n",
      "Epoch 5855/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3438 - acc: 0.2087 - val_loss: 0.4204 - val_acc: 0.2444\n",
      "Epoch 5856/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3445 - acc: 0.2087 - val_loss: 0.4374 - val_acc: 0.2444\n",
      "Epoch 5857/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3534 - acc: 0.2087 - val_loss: 0.4119 - val_acc: 0.2444\n",
      "Epoch 5858/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3573 - acc: 0.2087 - val_loss: 0.4626 - val_acc: 0.2444\n",
      "Epoch 5859/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3418 - acc: 0.2087 - val_loss: 0.4493 - val_acc: 0.2444\n",
      "Epoch 5860/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3544 - acc: 0.2092 - val_loss: 0.4030 - val_acc: 0.2444\n",
      "Epoch 5861/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3375 - acc: 0.2087 - val_loss: 0.4209 - val_acc: 0.2444\n",
      "Epoch 5862/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3437 - acc: 0.2087 - val_loss: 0.4334 - val_acc: 0.2444\n",
      "Epoch 5863/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3487 - acc: 0.2087 - val_loss: 0.4207 - val_acc: 0.2444\n",
      "Epoch 5864/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3552 - acc: 0.2087 - val_loss: 0.4126 - val_acc: 0.2444\n",
      "Epoch 5865/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3412 - acc: 0.2087 - val_loss: 0.5591 - val_acc: 0.2407\n",
      "Epoch 5866/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3675 - acc: 0.2092 - val_loss: 0.5055 - val_acc: 0.2444\n",
      "Epoch 5867/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3638 - acc: 0.2083 - val_loss: 0.4457 - val_acc: 0.2444\n",
      "Epoch 5868/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3421 - acc: 0.2092 - val_loss: 0.4208 - val_acc: 0.2444\n",
      "Epoch 5869/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3537 - acc: 0.2079 - val_loss: 0.4382 - val_acc: 0.2444\n",
      "Epoch 5870/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3425 - acc: 0.2087 - val_loss: 0.4026 - val_acc: 0.2444\n",
      "Epoch 5871/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3547 - acc: 0.2096 - val_loss: 0.4180 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5872/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3476 - acc: 0.2096 - val_loss: 0.3976 - val_acc: 0.2444\n",
      "Epoch 5873/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3378 - acc: 0.2083 - val_loss: 0.4247 - val_acc: 0.2444\n",
      "Epoch 5874/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3399 - acc: 0.2083 - val_loss: 0.3984 - val_acc: 0.2444\n",
      "Epoch 5875/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3346 - acc: 0.2087 - val_loss: 0.4184 - val_acc: 0.2444\n",
      "Epoch 5876/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3363 - acc: 0.2083 - val_loss: 0.4072 - val_acc: 0.2444\n",
      "Epoch 5877/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3420 - acc: 0.2087 - val_loss: 0.4046 - val_acc: 0.2444\n",
      "Epoch 5878/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3502 - acc: 0.2096 - val_loss: 0.4326 - val_acc: 0.2444\n",
      "Epoch 5879/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3651 - acc: 0.2079 - val_loss: 0.4425 - val_acc: 0.2444\n",
      "Epoch 5880/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3413 - acc: 0.2092 - val_loss: 0.3995 - val_acc: 0.2444\n",
      "Epoch 5881/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3560 - acc: 0.2092 - val_loss: 0.3966 - val_acc: 0.2444\n",
      "Epoch 5882/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3590 - acc: 0.2092 - val_loss: 0.4616 - val_acc: 0.2444\n",
      "Epoch 5883/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3474 - acc: 0.2083 - val_loss: 0.4348 - val_acc: 0.2444\n",
      "Epoch 5884/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3373 - acc: 0.2087 - val_loss: 0.4263 - val_acc: 0.2444\n",
      "Epoch 5885/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3719 - acc: 0.2079 - val_loss: 0.4767 - val_acc: 0.2444\n",
      "Epoch 5886/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3475 - acc: 0.2092 - val_loss: 0.4068 - val_acc: 0.2444\n",
      "Epoch 5887/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3396 - acc: 0.2092 - val_loss: 0.4186 - val_acc: 0.2444\n",
      "Epoch 5888/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3390 - acc: 0.2083 - val_loss: 0.4305 - val_acc: 0.2444\n",
      "Epoch 5889/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3528 - acc: 0.2087 - val_loss: 0.3937 - val_acc: 0.2444\n",
      "Epoch 5890/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3470 - acc: 0.2092 - val_loss: 0.4235 - val_acc: 0.2444\n",
      "Epoch 5891/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3398 - acc: 0.2087 - val_loss: 0.4141 - val_acc: 0.2444\n",
      "Epoch 5892/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3446 - acc: 0.2087 - val_loss: 0.4033 - val_acc: 0.2444\n",
      "Epoch 5893/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3873 - acc: 0.2087 - val_loss: 0.4149 - val_acc: 0.2444\n",
      "Epoch 5894/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3453 - acc: 0.2092 - val_loss: 0.4183 - val_acc: 0.2444\n",
      "Epoch 5895/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3455 - acc: 0.2092 - val_loss: 0.3984 - val_acc: 0.2444\n",
      "Epoch 5896/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3495 - acc: 0.2087 - val_loss: 0.4046 - val_acc: 0.2444\n",
      "Epoch 5897/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3722 - acc: 0.2083 - val_loss: 0.4371 - val_acc: 0.2444\n",
      "Epoch 5898/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3539 - acc: 0.2092 - val_loss: 0.4695 - val_acc: 0.2444\n",
      "Epoch 5899/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3406 - acc: 0.2087 - val_loss: 0.4711 - val_acc: 0.2444\n",
      "Epoch 5900/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3458 - acc: 0.2087 - val_loss: 0.4295 - val_acc: 0.2444\n",
      "Epoch 5901/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3422 - acc: 0.2087 - val_loss: 0.4035 - val_acc: 0.2444\n",
      "Epoch 5902/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3420 - acc: 0.2096 - val_loss: 0.4069 - val_acc: 0.2444\n",
      "Epoch 5903/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3605 - acc: 0.2092 - val_loss: 0.4067 - val_acc: 0.2444\n",
      "Epoch 5904/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3431 - acc: 0.2087 - val_loss: 0.4154 - val_acc: 0.2444\n",
      "Epoch 5905/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3448 - acc: 0.2087 - val_loss: 0.4185 - val_acc: 0.2444\n",
      "Epoch 5906/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3524 - acc: 0.2087 - val_loss: 0.4117 - val_acc: 0.2444\n",
      "Epoch 5907/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3562 - acc: 0.2083 - val_loss: 0.5351 - val_acc: 0.2444\n",
      "Epoch 5908/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.3619 - acc: 0.2092 - val_loss: 0.4521 - val_acc: 0.2444\n",
      "Epoch 5909/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3391 - acc: 0.2092 - val_loss: 0.4661 - val_acc: 0.2444\n",
      "Epoch 5910/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3391 - acc: 0.2092 - val_loss: 0.4175 - val_acc: 0.2444\n",
      "Epoch 5911/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3777 - acc: 0.2083 - val_loss: 0.4064 - val_acc: 0.2444\n",
      "Epoch 5912/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3481 - acc: 0.2092 - val_loss: 0.4156 - val_acc: 0.2444\n",
      "Epoch 5913/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3363 - acc: 0.2092 - val_loss: 0.4180 - val_acc: 0.2444\n",
      "Epoch 5914/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3360 - acc: 0.2083 - val_loss: 0.4119 - val_acc: 0.2444\n",
      "Epoch 5915/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3541 - acc: 0.2083 - val_loss: 0.4046 - val_acc: 0.2444\n",
      "Epoch 5916/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3451 - acc: 0.2083 - val_loss: 0.4208 - val_acc: 0.2444\n",
      "Epoch 5917/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3603 - acc: 0.2075 - val_loss: 0.4583 - val_acc: 0.2444\n",
      "Epoch 5918/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3604 - acc: 0.2079 - val_loss: 0.4385 - val_acc: 0.2444\n",
      "Epoch 5919/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3434 - acc: 0.2087 - val_loss: 0.4098 - val_acc: 0.2444\n",
      "Epoch 5920/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3545 - acc: 0.2083 - val_loss: 0.4389 - val_acc: 0.2444\n",
      "Epoch 5921/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3545 - acc: 0.2075 - val_loss: 0.4814 - val_acc: 0.2444\n",
      "Epoch 5922/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3468 - acc: 0.2092 - val_loss: 0.4655 - val_acc: 0.2444\n",
      "Epoch 5923/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3469 - acc: 0.2083 - val_loss: 0.3987 - val_acc: 0.2444\n",
      "Epoch 5924/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3530 - acc: 0.2083 - val_loss: 0.4141 - val_acc: 0.2444\n",
      "Epoch 5925/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3471 - acc: 0.2092 - val_loss: 0.5252 - val_acc: 0.2407\n",
      "Epoch 5926/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3458 - acc: 0.2087 - val_loss: 0.4187 - val_acc: 0.2444\n",
      "Epoch 5927/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3411 - acc: 0.2083 - val_loss: 0.4005 - val_acc: 0.2444\n",
      "Epoch 5928/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3699 - acc: 0.2087 - val_loss: 0.4145 - val_acc: 0.2444\n",
      "Epoch 5929/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3567 - acc: 0.2087 - val_loss: 0.4444 - val_acc: 0.2444\n",
      "Epoch 5930/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3578 - acc: 0.2083 - val_loss: 0.3905 - val_acc: 0.2444\n",
      "Epoch 5931/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3486 - acc: 0.2087 - val_loss: 0.4106 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5932/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3423 - acc: 0.2092 - val_loss: 0.4194 - val_acc: 0.2444\n",
      "Epoch 5933/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3378 - acc: 0.2087 - val_loss: 0.4058 - val_acc: 0.2444\n",
      "Epoch 5934/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3484 - acc: 0.2083 - val_loss: 0.4650 - val_acc: 0.2444\n",
      "Epoch 5935/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3653 - acc: 0.2087 - val_loss: 0.4028 - val_acc: 0.2444\n",
      "Epoch 5936/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3458 - acc: 0.2092 - val_loss: 0.4380 - val_acc: 0.2444\n",
      "Epoch 5937/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3537 - acc: 0.2083 - val_loss: 0.4266 - val_acc: 0.2444\n",
      "Epoch 5938/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3435 - acc: 0.2087 - val_loss: 0.4086 - val_acc: 0.2444\n",
      "Epoch 5939/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3685 - acc: 0.2083 - val_loss: 0.4797 - val_acc: 0.2444\n",
      "Epoch 5940/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3801 - acc: 0.2079 - val_loss: 0.3994 - val_acc: 0.2444\n",
      "Epoch 5941/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3610 - acc: 0.2087 - val_loss: 0.4640 - val_acc: 0.2444\n",
      "Epoch 5942/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3767 - acc: 0.2092 - val_loss: 0.4744 - val_acc: 0.2444\n",
      "Epoch 5943/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3615 - acc: 0.2079 - val_loss: 0.4362 - val_acc: 0.2444\n",
      "Epoch 5944/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3464 - acc: 0.2092 - val_loss: 0.4206 - val_acc: 0.2444\n",
      "Epoch 5945/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3483 - acc: 0.2083 - val_loss: 0.5135 - val_acc: 0.2444\n",
      "Epoch 5946/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3442 - acc: 0.2092 - val_loss: 0.4216 - val_acc: 0.2444\n",
      "Epoch 5947/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3461 - acc: 0.2087 - val_loss: 0.4946 - val_acc: 0.2444\n",
      "Epoch 5948/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3582 - acc: 0.2092 - val_loss: 0.4871 - val_acc: 0.2444\n",
      "Epoch 5949/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3564 - acc: 0.2087 - val_loss: 0.4813 - val_acc: 0.2444\n",
      "Epoch 5950/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3710 - acc: 0.2083 - val_loss: 0.4334 - val_acc: 0.2444\n",
      "Epoch 5951/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3591 - acc: 0.2075 - val_loss: 0.3973 - val_acc: 0.2444\n",
      "Epoch 5952/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3536 - acc: 0.2083 - val_loss: 0.4136 - val_acc: 0.2444\n",
      "Epoch 5953/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3417 - acc: 0.2096 - val_loss: 0.4182 - val_acc: 0.2444\n",
      "Epoch 5954/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3527 - acc: 0.2087 - val_loss: 0.4015 - val_acc: 0.2444\n",
      "Epoch 5955/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3365 - acc: 0.2083 - val_loss: 0.4030 - val_acc: 0.2444\n",
      "Epoch 5956/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3553 - acc: 0.2079 - val_loss: 0.4341 - val_acc: 0.2444\n",
      "Epoch 5957/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4094 - acc: 0.2087 - val_loss: 0.5265 - val_acc: 0.2444\n",
      "Epoch 5958/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3553 - acc: 0.2083 - val_loss: 0.4137 - val_acc: 0.2444\n",
      "Epoch 5959/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3605 - acc: 0.2087 - val_loss: 0.4122 - val_acc: 0.2444\n",
      "Epoch 5960/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3272 - acc: 0.2087 - val_loss: 0.4809 - val_acc: 0.2444\n",
      "Epoch 5961/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3365 - acc: 0.2083 - val_loss: 0.4287 - val_acc: 0.2444\n",
      "Epoch 5962/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3611 - acc: 0.2087 - val_loss: 0.4723 - val_acc: 0.2444\n",
      "Epoch 5963/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3370 - acc: 0.2083 - val_loss: 0.3990 - val_acc: 0.2444\n",
      "Epoch 5964/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3393 - acc: 0.2087 - val_loss: 0.3949 - val_acc: 0.2444\n",
      "Epoch 5965/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3453 - acc: 0.2083 - val_loss: 0.5158 - val_acc: 0.2444\n",
      "Epoch 5966/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3821 - acc: 0.2083 - val_loss: 0.4824 - val_acc: 0.2444\n",
      "Epoch 5967/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3465 - acc: 0.2083 - val_loss: 0.4145 - val_acc: 0.2444\n",
      "Epoch 5968/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3378 - acc: 0.2087 - val_loss: 0.4091 - val_acc: 0.2444\n",
      "Epoch 5969/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3552 - acc: 0.2092 - val_loss: 0.4716 - val_acc: 0.2444\n",
      "Epoch 5970/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3389 - acc: 0.2087 - val_loss: 0.4905 - val_acc: 0.2444\n",
      "Epoch 5971/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3449 - acc: 0.2087 - val_loss: 0.4257 - val_acc: 0.2444\n",
      "Epoch 5972/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3337 - acc: 0.2087 - val_loss: 0.4182 - val_acc: 0.2444\n",
      "Epoch 5973/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3472 - acc: 0.2087 - val_loss: 0.4424 - val_acc: 0.2444\n",
      "Epoch 5974/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3567 - acc: 0.2092 - val_loss: 0.4457 - val_acc: 0.2444\n",
      "Epoch 5975/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3371 - acc: 0.2092 - val_loss: 0.3946 - val_acc: 0.2444\n",
      "Epoch 5976/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3386 - acc: 0.2096 - val_loss: 0.4021 - val_acc: 0.2444\n",
      "Epoch 5977/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3358 - acc: 0.2087 - val_loss: 0.4086 - val_acc: 0.2444\n",
      "Epoch 5978/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3416 - acc: 0.2092 - val_loss: 0.4135 - val_acc: 0.2444\n",
      "Epoch 5979/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3409 - acc: 0.2092 - val_loss: 0.4466 - val_acc: 0.2444\n",
      "Epoch 5980/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3389 - acc: 0.2083 - val_loss: 0.4129 - val_acc: 0.2444\n",
      "Epoch 5981/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3497 - acc: 0.2087 - val_loss: 0.4360 - val_acc: 0.2444\n",
      "Epoch 5982/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3387 - acc: 0.2087 - val_loss: 0.4120 - val_acc: 0.2444\n",
      "Epoch 5983/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3633 - acc: 0.2079 - val_loss: 0.4365 - val_acc: 0.2444\n",
      "Epoch 5984/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3339 - acc: 0.2083 - val_loss: 0.4160 - val_acc: 0.2444\n",
      "Epoch 5985/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3522 - acc: 0.2087 - val_loss: 0.4234 - val_acc: 0.2444\n",
      "Epoch 5986/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3528 - acc: 0.2079 - val_loss: 0.4267 - val_acc: 0.2444\n",
      "Epoch 5987/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3511 - acc: 0.2096 - val_loss: 0.4651 - val_acc: 0.2444\n",
      "Epoch 5988/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3325 - acc: 0.2092 - val_loss: 0.4132 - val_acc: 0.2444\n",
      "Epoch 5989/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3430 - acc: 0.2096 - val_loss: 0.4468 - val_acc: 0.2444\n",
      "Epoch 5990/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3376 - acc: 0.2096 - val_loss: 0.5151 - val_acc: 0.2444\n",
      "Epoch 5991/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3540 - acc: 0.2087 - val_loss: 0.4617 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5992/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3472 - acc: 0.2079 - val_loss: 0.4174 - val_acc: 0.2444\n",
      "Epoch 5993/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3495 - acc: 0.2092 - val_loss: 0.4071 - val_acc: 0.2444\n",
      "Epoch 5994/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3598 - acc: 0.2083 - val_loss: 0.5667 - val_acc: 0.2444\n",
      "Epoch 5995/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3530 - acc: 0.2092 - val_loss: 0.4198 - val_acc: 0.2444\n",
      "Epoch 5996/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3424 - acc: 0.2087 - val_loss: 0.4254 - val_acc: 0.2444\n",
      "Epoch 5997/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3718 - acc: 0.2083 - val_loss: 0.4905 - val_acc: 0.2444\n",
      "Epoch 5998/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3391 - acc: 0.2087 - val_loss: 0.4197 - val_acc: 0.2444\n",
      "Epoch 5999/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3595 - acc: 0.2087 - val_loss: 0.4272 - val_acc: 0.2444\n",
      "Epoch 6000/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3468 - acc: 0.2092 - val_loss: 0.4005 - val_acc: 0.2444\n",
      "Epoch 6001/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3724 - acc: 0.2083 - val_loss: 0.4014 - val_acc: 0.2444\n",
      "Epoch 6002/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3693 - acc: 0.2087 - val_loss: 0.4614 - val_acc: 0.2444\n",
      "Epoch 6003/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3472 - acc: 0.2100 - val_loss: 0.4652 - val_acc: 0.2444\n",
      "Epoch 6004/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3555 - acc: 0.2087 - val_loss: 0.4156 - val_acc: 0.2444\n",
      "Epoch 6005/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3418 - acc: 0.2087 - val_loss: 0.4029 - val_acc: 0.2444\n",
      "Epoch 6006/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3552 - acc: 0.2087 - val_loss: 0.5486 - val_acc: 0.2407\n",
      "Epoch 6007/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3935 - acc: 0.2083 - val_loss: 0.4446 - val_acc: 0.2444\n",
      "Epoch 6008/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3434 - acc: 0.2092 - val_loss: 0.4634 - val_acc: 0.2444\n",
      "Epoch 6009/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3476 - acc: 0.2083 - val_loss: 0.4041 - val_acc: 0.2444\n",
      "Epoch 6010/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3402 - acc: 0.2092 - val_loss: 0.4135 - val_acc: 0.2444\n",
      "Epoch 6011/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3323 - acc: 0.2092 - val_loss: 0.4086 - val_acc: 0.2444\n",
      "Epoch 6012/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3341 - acc: 0.2092 - val_loss: 0.4077 - val_acc: 0.2444\n",
      "Epoch 6013/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3416 - acc: 0.2083 - val_loss: 0.4933 - val_acc: 0.2444\n",
      "Epoch 6014/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3887 - acc: 0.2087 - val_loss: 0.5242 - val_acc: 0.2444\n",
      "Epoch 6015/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3486 - acc: 0.2092 - val_loss: 0.4334 - val_acc: 0.2444\n",
      "Epoch 6016/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3522 - acc: 0.2083 - val_loss: 0.4505 - val_acc: 0.2444\n",
      "Epoch 6017/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3501 - acc: 0.2092 - val_loss: 0.3956 - val_acc: 0.2444\n",
      "Epoch 6018/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3449 - acc: 0.2092 - val_loss: 0.4734 - val_acc: 0.2444\n",
      "Epoch 6019/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3292 - acc: 0.2083 - val_loss: 0.4311 - val_acc: 0.2444\n",
      "Epoch 6020/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3441 - acc: 0.2087 - val_loss: 0.5060 - val_acc: 0.2407\n",
      "Epoch 6021/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3473 - acc: 0.2079 - val_loss: 0.5127 - val_acc: 0.2444\n",
      "Epoch 6022/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3708 - acc: 0.2087 - val_loss: 0.4657 - val_acc: 0.2444\n",
      "Epoch 6023/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3680 - acc: 0.2087 - val_loss: 0.3915 - val_acc: 0.2444\n",
      "Epoch 6024/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3397 - acc: 0.2087 - val_loss: 0.4006 - val_acc: 0.2444\n",
      "Epoch 6025/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3653 - acc: 0.2087 - val_loss: 0.3901 - val_acc: 0.2444\n",
      "Epoch 6026/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3346 - acc: 0.2083 - val_loss: 0.3974 - val_acc: 0.2444\n",
      "Epoch 6027/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3382 - acc: 0.2092 - val_loss: 0.3998 - val_acc: 0.2444\n",
      "Epoch 6028/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3313 - acc: 0.2083 - val_loss: 0.4010 - val_acc: 0.2444\n",
      "Epoch 6029/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3420 - acc: 0.2096 - val_loss: 0.4005 - val_acc: 0.2444\n",
      "Epoch 6030/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3542 - acc: 0.2092 - val_loss: 0.4726 - val_acc: 0.2444\n",
      "Epoch 6031/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3764 - acc: 0.2079 - val_loss: 0.4012 - val_acc: 0.2444\n",
      "Epoch 6032/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3396 - acc: 0.2087 - val_loss: 0.4019 - val_acc: 0.2444\n",
      "Epoch 6033/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3326 - acc: 0.2087 - val_loss: 0.4357 - val_acc: 0.2444\n",
      "Epoch 6034/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3576 - acc: 0.2092 - val_loss: 0.4228 - val_acc: 0.2444\n",
      "Epoch 6035/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3444 - acc: 0.2079 - val_loss: 0.4855 - val_acc: 0.2444\n",
      "Epoch 6036/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3473 - acc: 0.2083 - val_loss: 0.4180 - val_acc: 0.2444\n",
      "Epoch 6037/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3589 - acc: 0.2083 - val_loss: 0.4376 - val_acc: 0.2444\n",
      "Epoch 6038/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.3485 - acc: 0.2096 - val_loss: 0.5431 - val_acc: 0.2407\n",
      "Epoch 6039/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3696 - acc: 0.2087 - val_loss: 0.4529 - val_acc: 0.2444\n",
      "Epoch 6040/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3429 - acc: 0.2087 - val_loss: 0.4115 - val_acc: 0.2444\n",
      "Epoch 6041/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3324 - acc: 0.2087 - val_loss: 0.4147 - val_acc: 0.2444\n",
      "Epoch 6042/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3448 - acc: 0.2092 - val_loss: 0.4020 - val_acc: 0.2444\n",
      "Epoch 6043/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3433 - acc: 0.2092 - val_loss: 0.4126 - val_acc: 0.2444\n",
      "Epoch 6044/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3469 - acc: 0.2087 - val_loss: 0.5144 - val_acc: 0.2444\n",
      "Epoch 6045/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3513 - acc: 0.2087 - val_loss: 0.3987 - val_acc: 0.2444\n",
      "Epoch 6046/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3484 - acc: 0.2087 - val_loss: 0.4156 - val_acc: 0.2444\n",
      "Epoch 6047/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3423 - acc: 0.2087 - val_loss: 0.4522 - val_acc: 0.2444\n",
      "Epoch 6048/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3693 - acc: 0.2075 - val_loss: 0.4561 - val_acc: 0.2444\n",
      "Epoch 6049/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3399 - acc: 0.2087 - val_loss: 0.4162 - val_acc: 0.2444\n",
      "Epoch 6050/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3388 - acc: 0.2087 - val_loss: 0.4132 - val_acc: 0.2444\n",
      "Epoch 6051/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3707 - acc: 0.2075 - val_loss: 0.4500 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6052/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3402 - acc: 0.2092 - val_loss: 0.4610 - val_acc: 0.2444\n",
      "Epoch 6053/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3380 - acc: 0.2083 - val_loss: 0.4168 - val_acc: 0.2444\n",
      "Epoch 6054/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3563 - acc: 0.2092 - val_loss: 0.4117 - val_acc: 0.2444\n",
      "Epoch 6055/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4015 - acc: 0.2083 - val_loss: 0.4110 - val_acc: 0.2444\n",
      "Epoch 6056/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3588 - acc: 0.2079 - val_loss: 0.4605 - val_acc: 0.2444\n",
      "Epoch 6057/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3825 - acc: 0.2079 - val_loss: 0.4155 - val_acc: 0.2444\n",
      "Epoch 6058/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3633 - acc: 0.2092 - val_loss: 0.5140 - val_acc: 0.2444\n",
      "Epoch 6059/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3454 - acc: 0.2087 - val_loss: 0.4203 - val_acc: 0.2444\n",
      "Epoch 6060/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3422 - acc: 0.2083 - val_loss: 0.4134 - val_acc: 0.2444\n",
      "Epoch 6061/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3511 - acc: 0.2092 - val_loss: 0.4192 - val_acc: 0.2444\n",
      "Epoch 6062/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3563 - acc: 0.2092 - val_loss: 0.4057 - val_acc: 0.2444\n",
      "Epoch 6063/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3414 - acc: 0.2083 - val_loss: 0.4329 - val_acc: 0.2444\n",
      "Epoch 6064/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3538 - acc: 0.2087 - val_loss: 0.4428 - val_acc: 0.2444\n",
      "Epoch 6065/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3605 - acc: 0.2083 - val_loss: 0.4060 - val_acc: 0.2444\n",
      "Epoch 6066/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3361 - acc: 0.2092 - val_loss: 0.4111 - val_acc: 0.2444\n",
      "Epoch 6067/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3524 - acc: 0.2087 - val_loss: 0.4946 - val_acc: 0.2444\n",
      "Epoch 6068/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3454 - acc: 0.2083 - val_loss: 0.4099 - val_acc: 0.2444\n",
      "Epoch 6069/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3518 - acc: 0.2096 - val_loss: 0.3914 - val_acc: 0.2444\n",
      "Epoch 6070/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3475 - acc: 0.2083 - val_loss: 0.4015 - val_acc: 0.2444\n",
      "Epoch 6071/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3392 - acc: 0.2087 - val_loss: 0.4148 - val_acc: 0.2444\n",
      "Epoch 6072/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3356 - acc: 0.2087 - val_loss: 0.4646 - val_acc: 0.2444\n",
      "Epoch 6073/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3640 - acc: 0.2087 - val_loss: 0.4550 - val_acc: 0.2444\n",
      "Epoch 6074/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3560 - acc: 0.2087 - val_loss: 0.4196 - val_acc: 0.2444\n",
      "Epoch 6075/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3582 - acc: 0.2083 - val_loss: 0.5174 - val_acc: 0.2407\n",
      "Epoch 6076/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3527 - acc: 0.2079 - val_loss: 0.4127 - val_acc: 0.2444\n",
      "Epoch 6077/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3508 - acc: 0.2092 - val_loss: 0.4192 - val_acc: 0.2444\n",
      "Epoch 6078/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3425 - acc: 0.2087 - val_loss: 0.4164 - val_acc: 0.2444\n",
      "Epoch 6079/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3511 - acc: 0.2083 - val_loss: 0.4390 - val_acc: 0.2444\n",
      "Epoch 6080/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3483 - acc: 0.2083 - val_loss: 0.4056 - val_acc: 0.2444\n",
      "Epoch 6081/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3390 - acc: 0.2087 - val_loss: 0.4831 - val_acc: 0.2444\n",
      "Epoch 6082/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3461 - acc: 0.2092 - val_loss: 0.4204 - val_acc: 0.2444\n",
      "Epoch 6083/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3788 - acc: 0.2079 - val_loss: 0.5050 - val_acc: 0.2444\n",
      "Epoch 6084/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3363 - acc: 0.2092 - val_loss: 0.4094 - val_acc: 0.2444\n",
      "Epoch 6085/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3486 - acc: 0.2092 - val_loss: 0.4026 - val_acc: 0.2444\n",
      "Epoch 6086/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3378 - acc: 0.2092 - val_loss: 0.4321 - val_acc: 0.2444\n",
      "Epoch 6087/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3526 - acc: 0.2079 - val_loss: 0.5085 - val_acc: 0.2444\n",
      "Epoch 6088/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3513 - acc: 0.2083 - val_loss: 0.5747 - val_acc: 0.2407\n",
      "Epoch 6089/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3438 - acc: 0.2087 - val_loss: 0.4249 - val_acc: 0.2444\n",
      "Epoch 6090/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3361 - acc: 0.2092 - val_loss: 0.4441 - val_acc: 0.2444\n",
      "Epoch 6091/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3352 - acc: 0.2087 - val_loss: 0.4196 - val_acc: 0.2444\n",
      "Epoch 6092/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3289 - acc: 0.2083 - val_loss: 0.3974 - val_acc: 0.2444\n",
      "Epoch 6093/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3434 - acc: 0.2087 - val_loss: 0.4118 - val_acc: 0.2444\n",
      "Epoch 6094/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3570 - acc: 0.2083 - val_loss: 0.4642 - val_acc: 0.2444\n",
      "Epoch 6095/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3346 - acc: 0.2083 - val_loss: 0.4050 - val_acc: 0.2444\n",
      "Epoch 6096/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3730 - acc: 0.2087 - val_loss: 0.4392 - val_acc: 0.2444\n",
      "Epoch 6097/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3772 - acc: 0.2083 - val_loss: 0.4319 - val_acc: 0.2444\n",
      "Epoch 6098/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3382 - acc: 0.2092 - val_loss: 0.4325 - val_acc: 0.2444\n",
      "Epoch 6099/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3663 - acc: 0.2096 - val_loss: 0.3998 - val_acc: 0.2444\n",
      "Epoch 6100/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3368 - acc: 0.2083 - val_loss: 0.4329 - val_acc: 0.2444\n",
      "Epoch 6101/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3425 - acc: 0.2092 - val_loss: 0.4351 - val_acc: 0.2444\n",
      "Epoch 6102/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3412 - acc: 0.2092 - val_loss: 0.4096 - val_acc: 0.2444\n",
      "Epoch 6103/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3410 - acc: 0.2087 - val_loss: 0.4264 - val_acc: 0.2444\n",
      "Epoch 6104/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3536 - acc: 0.2079 - val_loss: 0.4258 - val_acc: 0.2444\n",
      "Epoch 6105/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3456 - acc: 0.2087 - val_loss: 0.4627 - val_acc: 0.2444\n",
      "Epoch 6106/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3440 - acc: 0.2079 - val_loss: 0.3970 - val_acc: 0.2444\n",
      "Epoch 6107/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3498 - acc: 0.2083 - val_loss: 0.4119 - val_acc: 0.2444\n",
      "Epoch 6108/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3682 - acc: 0.2083 - val_loss: 0.5091 - val_acc: 0.2444\n",
      "Epoch 6109/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3430 - acc: 0.2092 - val_loss: 0.4068 - val_acc: 0.2444\n",
      "Epoch 6110/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3755 - acc: 0.2079 - val_loss: 0.4141 - val_acc: 0.2444\n",
      "Epoch 6111/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3351 - acc: 0.2083 - val_loss: 0.4314 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6112/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3472 - acc: 0.2087 - val_loss: 0.5003 - val_acc: 0.2444\n",
      "Epoch 6113/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3780 - acc: 0.2083 - val_loss: 0.4072 - val_acc: 0.2444\n",
      "Epoch 6114/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3603 - acc: 0.2096 - val_loss: 0.4426 - val_acc: 0.2444\n",
      "Epoch 6115/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3479 - acc: 0.2083 - val_loss: 0.4505 - val_acc: 0.2444\n",
      "Epoch 6116/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3423 - acc: 0.2092 - val_loss: 0.4596 - val_acc: 0.2444\n",
      "Epoch 6117/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.3452 - acc: 0.2087 - val_loss: 0.4599 - val_acc: 0.2444\n",
      "Epoch 6118/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.3411 - acc: 0.2087 - val_loss: 0.4407 - val_acc: 0.2444\n",
      "Epoch 6119/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3525 - acc: 0.2092 - val_loss: 0.4330 - val_acc: 0.2444\n",
      "Epoch 6120/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.3467 - acc: 0.2083 - val_loss: 0.4279 - val_acc: 0.2444\n",
      "Epoch 6121/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.3275 - acc: 0.2092 - val_loss: 0.4064 - val_acc: 0.2444\n",
      "Epoch 6122/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3665 - acc: 0.2087 - val_loss: 0.4642 - val_acc: 0.2444\n",
      "Epoch 6123/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3825 - acc: 0.2092 - val_loss: 0.4059 - val_acc: 0.2444\n",
      "Epoch 6124/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.3418 - acc: 0.2092 - val_loss: 0.4070 - val_acc: 0.2444\n",
      "Epoch 6125/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.3420 - acc: 0.2100 - val_loss: 0.4122 - val_acc: 0.2444\n",
      "Epoch 6126/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3449 - acc: 0.2096 - val_loss: 0.4098 - val_acc: 0.2444\n",
      "Epoch 6127/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3531 - acc: 0.2087 - val_loss: 0.4800 - val_acc: 0.2444\n",
      "Epoch 6128/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3462 - acc: 0.2087 - val_loss: 0.4303 - val_acc: 0.2444\n",
      "Epoch 6129/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3478 - acc: 0.2083 - val_loss: 0.4020 - val_acc: 0.2444\n",
      "Epoch 6130/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3304 - acc: 0.2092 - val_loss: 0.4007 - val_acc: 0.2444\n",
      "Epoch 6131/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3364 - acc: 0.2083 - val_loss: 0.4268 - val_acc: 0.2444\n",
      "Epoch 6132/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3514 - acc: 0.2083 - val_loss: 0.5246 - val_acc: 0.2444\n",
      "Epoch 6133/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3702 - acc: 0.2087 - val_loss: 0.4241 - val_acc: 0.2444\n",
      "Epoch 6134/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3724 - acc: 0.2083 - val_loss: 0.4126 - val_acc: 0.2444\n",
      "Epoch 6135/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3642 - acc: 0.2083 - val_loss: 0.4134 - val_acc: 0.2444\n",
      "Epoch 6136/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3699 - acc: 0.2075 - val_loss: 0.4054 - val_acc: 0.2444\n",
      "Epoch 6137/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3414 - acc: 0.2092 - val_loss: 0.4082 - val_acc: 0.2444\n",
      "Epoch 6138/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3404 - acc: 0.2083 - val_loss: 0.5231 - val_acc: 0.2444\n",
      "Epoch 6139/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3483 - acc: 0.2092 - val_loss: 0.4780 - val_acc: 0.2444\n",
      "Epoch 6140/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3348 - acc: 0.2087 - val_loss: 0.4943 - val_acc: 0.2444\n",
      "Epoch 6141/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3499 - acc: 0.2096 - val_loss: 0.4162 - val_acc: 0.2444\n",
      "Epoch 6142/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3661 - acc: 0.2083 - val_loss: 0.4130 - val_acc: 0.2444\n",
      "Epoch 6143/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3560 - acc: 0.2092 - val_loss: 0.4408 - val_acc: 0.2444\n",
      "Epoch 6144/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3398 - acc: 0.2092 - val_loss: 0.4013 - val_acc: 0.2444\n",
      "Epoch 6145/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3436 - acc: 0.2083 - val_loss: 0.5093 - val_acc: 0.2444\n",
      "Epoch 6146/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3648 - acc: 0.2075 - val_loss: 0.4215 - val_acc: 0.2444\n",
      "Epoch 6147/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3348 - acc: 0.2083 - val_loss: 0.4391 - val_acc: 0.2444\n",
      "Epoch 6148/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3352 - acc: 0.2083 - val_loss: 0.4026 - val_acc: 0.2444\n",
      "Epoch 6149/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3315 - acc: 0.2092 - val_loss: 0.4274 - val_acc: 0.2444\n",
      "Epoch 6150/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3589 - acc: 0.2092 - val_loss: 0.4047 - val_acc: 0.2444\n",
      "Epoch 6151/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3349 - acc: 0.2096 - val_loss: 0.4172 - val_acc: 0.2444\n",
      "Epoch 6152/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3689 - acc: 0.2075 - val_loss: 0.4294 - val_acc: 0.2444\n",
      "Epoch 6153/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3433 - acc: 0.2096 - val_loss: 0.4259 - val_acc: 0.2444\n",
      "Epoch 6154/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3490 - acc: 0.2083 - val_loss: 0.4440 - val_acc: 0.2444\n",
      "Epoch 6155/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3914 - acc: 0.2087 - val_loss: 0.4240 - val_acc: 0.2444\n",
      "Epoch 6156/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3567 - acc: 0.2083 - val_loss: 0.4192 - val_acc: 0.2444\n",
      "Epoch 6157/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3343 - acc: 0.2087 - val_loss: 0.3924 - val_acc: 0.2444\n",
      "Epoch 6158/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3498 - acc: 0.2087 - val_loss: 0.4175 - val_acc: 0.2444\n",
      "Epoch 6159/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3499 - acc: 0.2096 - val_loss: 0.4959 - val_acc: 0.2444\n",
      "Epoch 6160/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3493 - acc: 0.2087 - val_loss: 0.4255 - val_acc: 0.2444\n",
      "Epoch 6161/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3394 - acc: 0.2092 - val_loss: 0.4434 - val_acc: 0.2444\n",
      "Epoch 6162/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3454 - acc: 0.2092 - val_loss: 0.4487 - val_acc: 0.2444\n",
      "Epoch 6163/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3541 - acc: 0.2079 - val_loss: 0.4299 - val_acc: 0.2444\n",
      "Epoch 6164/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3478 - acc: 0.2092 - val_loss: 0.4193 - val_acc: 0.2444\n",
      "Epoch 6165/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3283 - acc: 0.2092 - val_loss: 0.3963 - val_acc: 0.2444\n",
      "Epoch 6166/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3452 - acc: 0.2083 - val_loss: 0.4196 - val_acc: 0.2444\n",
      "Epoch 6167/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.3542 - acc: 0.2083 - val_loss: 0.4569 - val_acc: 0.2444\n",
      "Epoch 6168/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.3431 - acc: 0.2092 - val_loss: 0.4220 - val_acc: 0.2444\n",
      "Epoch 6169/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3372 - acc: 0.2092 - val_loss: 0.4133 - val_acc: 0.2444\n",
      "Epoch 6170/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3522 - acc: 0.2087 - val_loss: 0.4124 - val_acc: 0.2444\n",
      "Epoch 6171/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3453 - acc: 0.2087 - val_loss: 0.4237 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6172/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3341 - acc: 0.2083 - val_loss: 0.4748 - val_acc: 0.2444\n",
      "Epoch 6173/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3470 - acc: 0.2096 - val_loss: 0.4732 - val_acc: 0.2444\n",
      "Epoch 6174/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3403 - acc: 0.2096 - val_loss: 0.4079 - val_acc: 0.2444\n",
      "Epoch 6175/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3406 - acc: 0.2087 - val_loss: 0.3919 - val_acc: 0.2444\n",
      "Epoch 6176/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3396 - acc: 0.2083 - val_loss: 0.4148 - val_acc: 0.2444\n",
      "Epoch 6177/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3407 - acc: 0.2087 - val_loss: 0.4062 - val_acc: 0.2444\n",
      "Epoch 6178/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3644 - acc: 0.2096 - val_loss: 0.4320 - val_acc: 0.2444\n",
      "Epoch 6179/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3899 - acc: 0.2075 - val_loss: 0.4985 - val_acc: 0.2444\n",
      "Epoch 6180/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3380 - acc: 0.2096 - val_loss: 0.4129 - val_acc: 0.2444\n",
      "Epoch 6181/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3392 - acc: 0.2087 - val_loss: 0.3994 - val_acc: 0.2444\n",
      "Epoch 6182/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3444 - acc: 0.2092 - val_loss: 0.4009 - val_acc: 0.2444\n",
      "Epoch 6183/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3378 - acc: 0.2092 - val_loss: 0.3978 - val_acc: 0.2444\n",
      "Epoch 6184/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3468 - acc: 0.2087 - val_loss: 0.4617 - val_acc: 0.2444\n",
      "Epoch 6185/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3514 - acc: 0.2087 - val_loss: 0.3985 - val_acc: 0.2444\n",
      "Epoch 6186/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3470 - acc: 0.2087 - val_loss: 0.4020 - val_acc: 0.2444\n",
      "Epoch 6187/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3420 - acc: 0.2087 - val_loss: 0.6890 - val_acc: 0.2444\n",
      "Epoch 6188/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3985 - acc: 0.2087 - val_loss: 0.5388 - val_acc: 0.2444\n",
      "Epoch 6189/10000\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.3656 - acc: 0.208 - 3s 33ms/step - loss: 0.3658 - acc: 0.2092 - val_loss: 0.5225 - val_acc: 0.2444\n",
      "Epoch 6190/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3320 - acc: 0.2083 - val_loss: 0.4074 - val_acc: 0.2444\n",
      "Epoch 6191/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3394 - acc: 0.2087 - val_loss: 0.4569 - val_acc: 0.2444\n",
      "Epoch 6192/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3452 - acc: 0.2092 - val_loss: 0.4135 - val_acc: 0.2444\n",
      "Epoch 6193/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3548 - acc: 0.2087 - val_loss: 0.4167 - val_acc: 0.2444\n",
      "Epoch 6194/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3488 - acc: 0.2079 - val_loss: 0.4035 - val_acc: 0.2444\n",
      "Epoch 6195/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3518 - acc: 0.2092 - val_loss: 0.4082 - val_acc: 0.2444\n",
      "Epoch 6196/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3403 - acc: 0.2083 - val_loss: 0.4150 - val_acc: 0.2444\n",
      "Epoch 6197/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3344 - acc: 0.2087 - val_loss: 0.4205 - val_acc: 0.2444\n",
      "Epoch 6198/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3529 - acc: 0.2096 - val_loss: 0.4485 - val_acc: 0.2444\n",
      "Epoch 6199/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3637 - acc: 0.2087 - val_loss: 0.5247 - val_acc: 0.2407\n",
      "Epoch 6200/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3447 - acc: 0.2083 - val_loss: 0.4264 - val_acc: 0.2444\n",
      "Epoch 6201/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3728 - acc: 0.2075 - val_loss: 0.4295 - val_acc: 0.2444\n",
      "Epoch 6202/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3471 - acc: 0.2083 - val_loss: 0.3957 - val_acc: 0.2444\n",
      "Epoch 6203/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3817 - acc: 0.2079 - val_loss: 0.4016 - val_acc: 0.2444\n",
      "Epoch 6204/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3384 - acc: 0.2083 - val_loss: 0.4329 - val_acc: 0.2444\n",
      "Epoch 6205/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3337 - acc: 0.2083 - val_loss: 0.4140 - val_acc: 0.2444\n",
      "Epoch 6206/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3636 - acc: 0.2087 - val_loss: 0.4015 - val_acc: 0.2444\n",
      "Epoch 6207/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3430 - acc: 0.2083 - val_loss: 0.4108 - val_acc: 0.2444\n",
      "Epoch 6208/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3454 - acc: 0.2087 - val_loss: 0.4070 - val_acc: 0.2444\n",
      "Epoch 6209/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3642 - acc: 0.2096 - val_loss: 0.4220 - val_acc: 0.2444\n",
      "Epoch 6210/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3384 - acc: 0.2083 - val_loss: 0.4126 - val_acc: 0.2444\n",
      "Epoch 6211/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3477 - acc: 0.2092 - val_loss: 0.4444 - val_acc: 0.2444\n",
      "Epoch 6212/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3446 - acc: 0.2096 - val_loss: 0.4290 - val_acc: 0.2444\n",
      "Epoch 6213/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3417 - acc: 0.2092 - val_loss: 0.4227 - val_acc: 0.2444\n",
      "Epoch 6214/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3282 - acc: 0.2087 - val_loss: 0.4431 - val_acc: 0.2444\n",
      "Epoch 6215/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3343 - acc: 0.2087 - val_loss: 0.4075 - val_acc: 0.2444\n",
      "Epoch 6216/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3402 - acc: 0.2096 - val_loss: 0.4073 - val_acc: 0.2444\n",
      "Epoch 6217/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3357 - acc: 0.2083 - val_loss: 0.4196 - val_acc: 0.2444\n",
      "Epoch 6218/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3741 - acc: 0.2083 - val_loss: 0.5228 - val_acc: 0.2444\n",
      "Epoch 6219/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3403 - acc: 0.2092 - val_loss: 0.4116 - val_acc: 0.2444\n",
      "Epoch 6220/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3473 - acc: 0.2087 - val_loss: 0.4153 - val_acc: 0.2444\n",
      "Epoch 6221/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3491 - acc: 0.2083 - val_loss: 0.4071 - val_acc: 0.2444\n",
      "Epoch 6222/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3363 - acc: 0.2087 - val_loss: 0.4335 - val_acc: 0.2444\n",
      "Epoch 6223/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3777 - acc: 0.2079 - val_loss: 0.4824 - val_acc: 0.2444\n",
      "Epoch 6224/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3653 - acc: 0.2087 - val_loss: 0.4733 - val_acc: 0.2444\n",
      "Epoch 6225/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3500 - acc: 0.2083 - val_loss: 0.4228 - val_acc: 0.2444\n",
      "Epoch 6226/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3439 - acc: 0.2083 - val_loss: 0.4067 - val_acc: 0.2444\n",
      "Epoch 6227/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3394 - acc: 0.2100 - val_loss: 0.4141 - val_acc: 0.2444\n",
      "Epoch 6228/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3373 - acc: 0.2092 - val_loss: 0.4914 - val_acc: 0.2444\n",
      "Epoch 6229/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3656 - acc: 0.2087 - val_loss: 0.4071 - val_acc: 0.2444\n",
      "Epoch 6230/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3434 - acc: 0.2087 - val_loss: 0.4494 - val_acc: 0.2444\n",
      "Epoch 6231/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3317 - acc: 0.2092 - val_loss: 0.4145 - val_acc: 0.2444\n",
      "Epoch 6232/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3305 - acc: 0.2092 - val_loss: 0.4055 - val_acc: 0.2444\n",
      "Epoch 6233/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3522 - acc: 0.2087 - val_loss: 0.4187 - val_acc: 0.2444\n",
      "Epoch 6234/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3394 - acc: 0.2083 - val_loss: 0.4213 - val_acc: 0.2444\n",
      "Epoch 6235/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3545 - acc: 0.2092 - val_loss: 0.4125 - val_acc: 0.2444\n",
      "Epoch 6236/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3436 - acc: 0.2092 - val_loss: 0.4064 - val_acc: 0.2444\n",
      "Epoch 6237/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3613 - acc: 0.2083 - val_loss: 0.5224 - val_acc: 0.2444\n",
      "Epoch 6238/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3628 - acc: 0.2092 - val_loss: 0.3978 - val_acc: 0.2444\n",
      "Epoch 6239/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3349 - acc: 0.2087 - val_loss: 0.4090 - val_acc: 0.2444\n",
      "Epoch 6240/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3308 - acc: 0.2092 - val_loss: 0.5164 - val_acc: 0.2407\n",
      "Epoch 6241/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3863 - acc: 0.2083 - val_loss: 0.3937 - val_acc: 0.2444\n",
      "Epoch 6242/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3398 - acc: 0.2087 - val_loss: 0.4371 - val_acc: 0.2444\n",
      "Epoch 6243/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3459 - acc: 0.2087 - val_loss: 0.5342 - val_acc: 0.2444\n",
      "Epoch 6244/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3563 - acc: 0.2083 - val_loss: 0.4160 - val_acc: 0.2444\n",
      "Epoch 6245/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3327 - acc: 0.2083 - val_loss: 0.3948 - val_acc: 0.2444\n",
      "Epoch 6246/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3397 - acc: 0.2087 - val_loss: 0.5260 - val_acc: 0.2444\n",
      "Epoch 6247/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3442 - acc: 0.2083 - val_loss: 0.4120 - val_acc: 0.2444\n",
      "Epoch 6248/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3342 - acc: 0.2092 - val_loss: 0.4332 - val_acc: 0.2444\n",
      "Epoch 6249/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3527 - acc: 0.2087 - val_loss: 0.4565 - val_acc: 0.2444\n",
      "Epoch 6250/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3305 - acc: 0.2087 - val_loss: 0.4785 - val_acc: 0.2444\n",
      "Epoch 6251/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3345 - acc: 0.2092 - val_loss: 0.4107 - val_acc: 0.2444\n",
      "Epoch 6252/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3376 - acc: 0.2087 - val_loss: 0.4886 - val_acc: 0.2444\n",
      "Epoch 6253/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3583 - acc: 0.2092 - val_loss: 0.4817 - val_acc: 0.2444\n",
      "Epoch 6254/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3483 - acc: 0.2087 - val_loss: 0.4232 - val_acc: 0.2444\n",
      "Epoch 6255/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3400 - acc: 0.2092 - val_loss: 0.4022 - val_acc: 0.2444\n",
      "Epoch 6256/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3458 - acc: 0.2083 - val_loss: 0.3989 - val_acc: 0.2444\n",
      "Epoch 6257/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3508 - acc: 0.2087 - val_loss: 0.5049 - val_acc: 0.2444\n",
      "Epoch 6258/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4175 - acc: 0.2071 - val_loss: 0.4764 - val_acc: 0.2444\n",
      "Epoch 6259/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3381 - acc: 0.2079 - val_loss: 0.4124 - val_acc: 0.2444\n",
      "Epoch 6260/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3300 - acc: 0.2087 - val_loss: 0.4191 - val_acc: 0.2444\n",
      "Epoch 6261/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3700 - acc: 0.2087 - val_loss: 0.4123 - val_acc: 0.2444\n",
      "Epoch 6262/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3546 - acc: 0.2087 - val_loss: 0.3996 - val_acc: 0.2444\n",
      "Epoch 6263/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3450 - acc: 0.2092 - val_loss: 0.4489 - val_acc: 0.2444\n",
      "Epoch 6264/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3422 - acc: 0.2083 - val_loss: 0.4572 - val_acc: 0.2444\n",
      "Epoch 6265/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3495 - acc: 0.2087 - val_loss: 0.4015 - val_acc: 0.2444\n",
      "Epoch 6266/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3502 - acc: 0.2087 - val_loss: 0.5036 - val_acc: 0.2444\n",
      "Epoch 6267/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3373 - acc: 0.2087 - val_loss: 0.4382 - val_acc: 0.2444\n",
      "Epoch 6268/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3582 - acc: 0.2079 - val_loss: 0.4003 - val_acc: 0.2444\n",
      "Epoch 6269/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3363 - acc: 0.2083 - val_loss: 0.3946 - val_acc: 0.2444\n",
      "Epoch 6270/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3707 - acc: 0.2092 - val_loss: 0.3959 - val_acc: 0.2444\n",
      "Epoch 6271/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3467 - acc: 0.2087 - val_loss: 0.4176 - val_acc: 0.2444\n",
      "Epoch 6272/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3477 - acc: 0.2079 - val_loss: 0.4006 - val_acc: 0.2444\n",
      "Epoch 6273/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3326 - acc: 0.2096 - val_loss: 0.4094 - val_acc: 0.2444\n",
      "Epoch 6274/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3364 - acc: 0.2092 - val_loss: 0.4001 - val_acc: 0.2444\n",
      "Epoch 6275/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3482 - acc: 0.2092 - val_loss: 0.4188 - val_acc: 0.2444\n",
      "Epoch 6276/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3556 - acc: 0.2096 - val_loss: 0.4113 - val_acc: 0.2444\n",
      "Epoch 6277/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3634 - acc: 0.2079 - val_loss: 0.4029 - val_acc: 0.2444\n",
      "Epoch 6278/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3340 - acc: 0.2087 - val_loss: 0.4021 - val_acc: 0.2444\n",
      "Epoch 6279/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3311 - acc: 0.2087 - val_loss: 0.4232 - val_acc: 0.2444\n",
      "Epoch 6280/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3475 - acc: 0.2087 - val_loss: 0.4259 - val_acc: 0.2444\n",
      "Epoch 6281/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3394 - acc: 0.2087 - val_loss: 0.4312 - val_acc: 0.2444\n",
      "Epoch 6282/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3536 - acc: 0.2087 - val_loss: 0.4197 - val_acc: 0.2444\n",
      "Epoch 6283/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3627 - acc: 0.2079 - val_loss: 0.4007 - val_acc: 0.2444\n",
      "Epoch 6284/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3396 - acc: 0.2083 - val_loss: 0.4547 - val_acc: 0.2444\n",
      "Epoch 6285/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3446 - acc: 0.2096 - val_loss: 0.4136 - val_acc: 0.2444\n",
      "Epoch 6286/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3368 - acc: 0.2092 - val_loss: 0.4267 - val_acc: 0.2444\n",
      "Epoch 6287/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3383 - acc: 0.2087 - val_loss: 0.4031 - val_acc: 0.2444\n",
      "Epoch 6288/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3435 - acc: 0.2087 - val_loss: 0.5159 - val_acc: 0.2444\n",
      "Epoch 6289/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3597 - acc: 0.2092 - val_loss: 0.4917 - val_acc: 0.2444\n",
      "Epoch 6290/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3569 - acc: 0.2083 - val_loss: 0.4683 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6291/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3477 - acc: 0.2096 - val_loss: 0.4078 - val_acc: 0.2444\n",
      "Epoch 6292/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3395 - acc: 0.2092 - val_loss: 0.4364 - val_acc: 0.2444\n",
      "Epoch 6293/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3484 - acc: 0.2092 - val_loss: 0.3984 - val_acc: 0.2444\n",
      "Epoch 6294/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3586 - acc: 0.2087 - val_loss: 0.4425 - val_acc: 0.2444\n",
      "Epoch 6295/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3501 - acc: 0.2096 - val_loss: 0.4270 - val_acc: 0.2444\n",
      "Epoch 6296/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.3454 - acc: 0.2083 - val_loss: 0.4711 - val_acc: 0.2444\n",
      "Epoch 6297/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.3504 - acc: 0.2083 - val_loss: 0.4712 - val_acc: 0.2444\n",
      "Epoch 6298/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3852 - acc: 0.2075 - val_loss: 0.5710 - val_acc: 0.2444\n",
      "Epoch 6299/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3576 - acc: 0.2087 - val_loss: 0.4086 - val_acc: 0.2444\n",
      "Epoch 6300/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3460 - acc: 0.2083 - val_loss: 0.4060 - val_acc: 0.2444\n",
      "Epoch 6301/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3445 - acc: 0.2083 - val_loss: 0.4320 - val_acc: 0.2444\n",
      "Epoch 6302/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3538 - acc: 0.2079 - val_loss: 0.4053 - val_acc: 0.2444\n",
      "Epoch 6303/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3305 - acc: 0.2087 - val_loss: 0.4061 - val_acc: 0.2444\n",
      "Epoch 6304/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3333 - acc: 0.2092 - val_loss: 0.3968 - val_acc: 0.2444\n",
      "Epoch 6305/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3316 - acc: 0.2087 - val_loss: 0.4196 - val_acc: 0.2444\n",
      "Epoch 6306/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3421 - acc: 0.2083 - val_loss: 0.3969 - val_acc: 0.2444\n",
      "Epoch 6307/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3327 - acc: 0.2092 - val_loss: 0.4076 - val_acc: 0.2444\n",
      "Epoch 6308/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3422 - acc: 0.2087 - val_loss: 0.3989 - val_acc: 0.2444\n",
      "Epoch 6309/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3718 - acc: 0.2092 - val_loss: 0.4263 - val_acc: 0.2444\n",
      "Epoch 6310/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3532 - acc: 0.2083 - val_loss: 0.4546 - val_acc: 0.2444\n",
      "Epoch 6311/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3992 - acc: 0.2071 - val_loss: 0.4588 - val_acc: 0.2444\n",
      "Epoch 6312/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3331 - acc: 0.2083 - val_loss: 0.4281 - val_acc: 0.2444\n",
      "Epoch 6313/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3355 - acc: 0.2092 - val_loss: 0.4374 - val_acc: 0.2444\n",
      "Epoch 6314/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3467 - acc: 0.2092 - val_loss: 0.4570 - val_acc: 0.2444\n",
      "Epoch 6315/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3345 - acc: 0.2087 - val_loss: 0.4572 - val_acc: 0.2444\n",
      "Epoch 6316/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3392 - acc: 0.2083 - val_loss: 0.4425 - val_acc: 0.2444\n",
      "Epoch 6317/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3607 - acc: 0.2087 - val_loss: 0.3932 - val_acc: 0.2444\n",
      "Epoch 6318/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3356 - acc: 0.2087 - val_loss: 0.3942 - val_acc: 0.2444\n",
      "Epoch 6319/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3598 - acc: 0.2087 - val_loss: 0.4082 - val_acc: 0.2444\n",
      "Epoch 6320/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3396 - acc: 0.2087 - val_loss: 0.4301 - val_acc: 0.2444\n",
      "Epoch 6321/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3469 - acc: 0.2087 - val_loss: 0.4349 - val_acc: 0.2444\n",
      "Epoch 6322/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3516 - acc: 0.2087 - val_loss: 0.3986 - val_acc: 0.2444\n",
      "Epoch 6323/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3298 - acc: 0.2092 - val_loss: 0.4014 - val_acc: 0.2444\n",
      "Epoch 6324/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3391 - acc: 0.2087 - val_loss: 0.4741 - val_acc: 0.2444\n",
      "Epoch 6325/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3444 - acc: 0.2071 - val_loss: 0.4757 - val_acc: 0.2444\n",
      "Epoch 6326/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3468 - acc: 0.2087 - val_loss: 0.3923 - val_acc: 0.2444\n",
      "Epoch 6327/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3460 - acc: 0.2087 - val_loss: 0.4500 - val_acc: 0.2444\n",
      "Epoch 6328/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3406 - acc: 0.2087 - val_loss: 0.4076 - val_acc: 0.2444\n",
      "Epoch 6329/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3411 - acc: 0.2092 - val_loss: 0.3992 - val_acc: 0.2444\n",
      "Epoch 6330/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3484 - acc: 0.2083 - val_loss: 0.4029 - val_acc: 0.2444\n",
      "Epoch 6331/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3427 - acc: 0.2087 - val_loss: 0.4227 - val_acc: 0.2444\n",
      "Epoch 6332/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3286 - acc: 0.2092 - val_loss: 0.4075 - val_acc: 0.2444\n",
      "Epoch 6333/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3380 - acc: 0.2092 - val_loss: 0.4393 - val_acc: 0.2444\n",
      "Epoch 6334/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3356 - acc: 0.2092 - val_loss: 0.4069 - val_acc: 0.2444\n",
      "Epoch 6335/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3342 - acc: 0.2083 - val_loss: 0.4728 - val_acc: 0.2444\n",
      "Epoch 6336/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3710 - acc: 0.2083 - val_loss: 0.3983 - val_acc: 0.2444\n",
      "Epoch 6337/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3348 - acc: 0.2092 - val_loss: 0.5065 - val_acc: 0.2444\n",
      "Epoch 6338/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3626 - acc: 0.2083 - val_loss: 0.4186 - val_acc: 0.2444\n",
      "Epoch 6339/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3468 - acc: 0.2087 - val_loss: 0.5384 - val_acc: 0.2407\n",
      "Epoch 6340/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3702 - acc: 0.2079 - val_loss: 0.4355 - val_acc: 0.2444\n",
      "Epoch 6341/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3575 - acc: 0.2092 - val_loss: 0.4086 - val_acc: 0.2444\n",
      "Epoch 6342/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3469 - acc: 0.2092 - val_loss: 0.4325 - val_acc: 0.2444\n",
      "Epoch 6343/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3305 - acc: 0.2092 - val_loss: 0.4653 - val_acc: 0.2444\n",
      "Epoch 6344/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3575 - acc: 0.2087 - val_loss: 0.4687 - val_acc: 0.2444\n",
      "Epoch 6345/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3348 - acc: 0.2083 - val_loss: 0.4044 - val_acc: 0.2444\n",
      "Epoch 6346/10000\n",
      "76/76 [==============================] - 4s 46ms/step - loss: 0.3576 - acc: 0.2096 - val_loss: 0.4082 - val_acc: 0.2444\n",
      "Epoch 6347/10000\n",
      "76/76 [==============================] - 4s 46ms/step - loss: 0.3392 - acc: 0.2092 - val_loss: 0.4166 - val_acc: 0.2444\n",
      "Epoch 6348/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3519 - acc: 0.2075 - val_loss: 0.5106 - val_acc: 0.2444\n",
      "Epoch 6349/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3286 - acc: 0.2083 - val_loss: 0.4075 - val_acc: 0.2444\n",
      "Epoch 6350/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3318 - acc: 0.2092 - val_loss: 0.4135 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6351/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3356 - acc: 0.2092 - val_loss: 0.4222 - val_acc: 0.2444\n",
      "Epoch 6352/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3866 - acc: 0.2087 - val_loss: 0.6590 - val_acc: 0.2444\n",
      "Epoch 6353/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.9828 - acc: 0.2059 - val_loss: 0.7685 - val_acc: 0.2444\n",
      "Epoch 6354/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.5864 - acc: 0.2083 - val_loss: 0.6238 - val_acc: 0.2444\n",
      "Epoch 6355/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4243 - acc: 0.2083 - val_loss: 0.5326 - val_acc: 0.2444\n",
      "Epoch 6356/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3716 - acc: 0.2092 - val_loss: 0.4472 - val_acc: 0.2444\n",
      "Epoch 6357/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3523 - acc: 0.2092 - val_loss: 0.4118 - val_acc: 0.2444\n",
      "Epoch 6358/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3425 - acc: 0.2092 - val_loss: 0.4071 - val_acc: 0.2444\n",
      "Epoch 6359/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3329 - acc: 0.2092 - val_loss: 0.3970 - val_acc: 0.2444\n",
      "Epoch 6360/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3315 - acc: 0.2087 - val_loss: 0.4022 - val_acc: 0.2444\n",
      "Epoch 6361/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3422 - acc: 0.2092 - val_loss: 0.4225 - val_acc: 0.2444\n",
      "Epoch 6362/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3438 - acc: 0.2092 - val_loss: 0.4298 - val_acc: 0.2444\n",
      "Epoch 6363/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3446 - acc: 0.2087 - val_loss: 0.4138 - val_acc: 0.2444\n",
      "Epoch 6364/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3567 - acc: 0.2083 - val_loss: 0.4098 - val_acc: 0.2444\n",
      "Epoch 6365/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3612 - acc: 0.2092 - val_loss: 0.4141 - val_acc: 0.2444\n",
      "Epoch 6366/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3807 - acc: 0.2079 - val_loss: 0.4094 - val_acc: 0.2444\n",
      "Epoch 6367/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3372 - acc: 0.2087 - val_loss: 0.4192 - val_acc: 0.2444\n",
      "Epoch 6368/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3286 - acc: 0.2096 - val_loss: 0.4240 - val_acc: 0.2444\n",
      "Epoch 6369/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3401 - acc: 0.2096 - val_loss: 0.5036 - val_acc: 0.2444\n",
      "Epoch 6370/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3442 - acc: 0.2092 - val_loss: 0.4608 - val_acc: 0.2444\n",
      "Epoch 6371/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3507 - acc: 0.2100 - val_loss: 0.4466 - val_acc: 0.2444\n",
      "Epoch 6372/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3412 - acc: 0.2087 - val_loss: 0.4490 - val_acc: 0.2444\n",
      "Epoch 6373/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3391 - acc: 0.2087 - val_loss: 0.4041 - val_acc: 0.2444\n",
      "Epoch 6374/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3525 - acc: 0.2087 - val_loss: 0.4089 - val_acc: 0.2444\n",
      "Epoch 6375/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3417 - acc: 0.2087 - val_loss: 0.4034 - val_acc: 0.2444\n",
      "Epoch 6376/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3367 - acc: 0.2083 - val_loss: 0.4133 - val_acc: 0.2444\n",
      "Epoch 6377/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3390 - acc: 0.2087 - val_loss: 0.4925 - val_acc: 0.2444\n",
      "Epoch 6378/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3496 - acc: 0.2100 - val_loss: 0.4150 - val_acc: 0.2444\n",
      "Epoch 6379/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3354 - acc: 0.2087 - val_loss: 0.4478 - val_acc: 0.2444\n",
      "Epoch 6380/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3444 - acc: 0.2087 - val_loss: 0.4067 - val_acc: 0.2444\n",
      "Epoch 6381/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3328 - acc: 0.2087 - val_loss: 0.4566 - val_acc: 0.2444\n",
      "Epoch 6382/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3365 - acc: 0.2087 - val_loss: 0.4257 - val_acc: 0.2444\n",
      "Epoch 6383/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3547 - acc: 0.2087 - val_loss: 0.4004 - val_acc: 0.2444\n",
      "Epoch 6384/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3507 - acc: 0.2083 - val_loss: 0.4035 - val_acc: 0.2444\n",
      "Epoch 6385/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3398 - acc: 0.2092 - val_loss: 0.4408 - val_acc: 0.2444\n",
      "Epoch 6386/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3503 - acc: 0.2087 - val_loss: 0.4120 - val_acc: 0.2444\n",
      "Epoch 6387/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3515 - acc: 0.2092 - val_loss: 0.4153 - val_acc: 0.2444\n",
      "Epoch 6388/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3372 - acc: 0.2096 - val_loss: 0.4038 - val_acc: 0.2444\n",
      "Epoch 6389/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3329 - acc: 0.2083 - val_loss: 0.4772 - val_acc: 0.2444\n",
      "Epoch 6390/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3626 - acc: 0.2096 - val_loss: 0.4590 - val_acc: 0.2444\n",
      "Epoch 6391/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3733 - acc: 0.2092 - val_loss: 0.4108 - val_acc: 0.2444\n",
      "Epoch 6392/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3506 - acc: 0.2096 - val_loss: 0.4056 - val_acc: 0.2444\n",
      "Epoch 6393/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3449 - acc: 0.2092 - val_loss: 0.4119 - val_acc: 0.2444\n",
      "Epoch 6394/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3434 - acc: 0.2079 - val_loss: 0.4471 - val_acc: 0.2444\n",
      "Epoch 6395/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3568 - acc: 0.2071 - val_loss: 0.4625 - val_acc: 0.2444\n",
      "Epoch 6396/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3372 - acc: 0.2092 - val_loss: 0.4144 - val_acc: 0.2444\n",
      "Epoch 6397/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3778 - acc: 0.2075 - val_loss: 0.4071 - val_acc: 0.2444\n",
      "Epoch 6398/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3472 - acc: 0.2087 - val_loss: 0.5883 - val_acc: 0.2444\n",
      "Epoch 6399/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3711 - acc: 0.2079 - val_loss: 0.4682 - val_acc: 0.2444\n",
      "Epoch 6400/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3618 - acc: 0.2096 - val_loss: 0.4579 - val_acc: 0.2444\n",
      "Epoch 6401/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3400 - acc: 0.2083 - val_loss: 0.4142 - val_acc: 0.2444\n",
      "Epoch 6402/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3359 - acc: 0.2096 - val_loss: 0.4248 - val_acc: 0.2444\n",
      "Epoch 6403/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3397 - acc: 0.2087 - val_loss: 0.3986 - val_acc: 0.2444\n",
      "Epoch 6404/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3314 - acc: 0.2087 - val_loss: 0.5631 - val_acc: 0.2407\n",
      "Epoch 6405/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3433 - acc: 0.2092 - val_loss: 0.4432 - val_acc: 0.2444\n",
      "Epoch 6406/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3463 - acc: 0.2092 - val_loss: 0.4546 - val_acc: 0.2444\n",
      "Epoch 6407/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3330 - acc: 0.2087 - val_loss: 0.4869 - val_acc: 0.2444\n",
      "Epoch 6408/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3419 - acc: 0.2096 - val_loss: 0.4321 - val_acc: 0.2444\n",
      "Epoch 6409/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.3403 - acc: 0.2087 - val_loss: 0.4612 - val_acc: 0.2444\n",
      "Epoch 6410/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3571 - acc: 0.2087 - val_loss: 0.4452 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6411/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3360 - acc: 0.2083 - val_loss: 0.4239 - val_acc: 0.2444\n",
      "Epoch 6412/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3364 - acc: 0.2092 - val_loss: 0.4232 - val_acc: 0.2444\n",
      "Epoch 6413/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3501 - acc: 0.2083 - val_loss: 0.3960 - val_acc: 0.2444\n",
      "Epoch 6414/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3256 - acc: 0.2087 - val_loss: 0.4606 - val_acc: 0.2444\n",
      "Epoch 6415/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3370 - acc: 0.2087 - val_loss: 0.4947 - val_acc: 0.2444\n",
      "Epoch 6416/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3693 - acc: 0.2087 - val_loss: 0.4281 - val_acc: 0.2444\n",
      "Epoch 6417/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3387 - acc: 0.2087 - val_loss: 0.4041 - val_acc: 0.2444\n",
      "Epoch 6418/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3594 - acc: 0.2083 - val_loss: 0.5209 - val_acc: 0.2444\n",
      "Epoch 6419/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3398 - acc: 0.2087 - val_loss: 0.4262 - val_acc: 0.2444\n",
      "Epoch 6420/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3282 - acc: 0.2087 - val_loss: 0.3985 - val_acc: 0.2444\n",
      "Epoch 6421/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3415 - acc: 0.2092 - val_loss: 0.4090 - val_acc: 0.2444\n",
      "Epoch 6422/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3671 - acc: 0.2092 - val_loss: 0.5633 - val_acc: 0.2407\n",
      "Epoch 6423/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3366 - acc: 0.2083 - val_loss: 0.4458 - val_acc: 0.2444\n",
      "Epoch 6424/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3786 - acc: 0.2092 - val_loss: 0.4713 - val_acc: 0.2444\n",
      "Epoch 6425/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.3389 - acc: 0.2096 - val_loss: 0.4532 - val_acc: 0.2444\n",
      "Epoch 6426/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3456 - acc: 0.2092 - val_loss: 0.4064 - val_acc: 0.2444\n",
      "Epoch 6427/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3436 - acc: 0.2092 - val_loss: 0.4324 - val_acc: 0.2444\n",
      "Epoch 6428/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3376 - acc: 0.2092 - val_loss: 0.4008 - val_acc: 0.2444\n",
      "Epoch 6429/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3542 - acc: 0.2087 - val_loss: 0.4271 - val_acc: 0.2444\n",
      "Epoch 6430/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3321 - acc: 0.2087 - val_loss: 0.4140 - val_acc: 0.2444\n",
      "Epoch 6431/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3694 - acc: 0.2087 - val_loss: 0.4092 - val_acc: 0.2444\n",
      "Epoch 6432/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3334 - acc: 0.2092 - val_loss: 0.4148 - val_acc: 0.2444\n",
      "Epoch 6433/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3377 - acc: 0.2092 - val_loss: 0.4175 - val_acc: 0.2444\n",
      "Epoch 6434/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3472 - acc: 0.2092 - val_loss: 0.4130 - val_acc: 0.2444\n",
      "Epoch 6435/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3547 - acc: 0.2083 - val_loss: 0.3881 - val_acc: 0.2444\n",
      "Epoch 6436/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3438 - acc: 0.2092 - val_loss: 0.3954 - val_acc: 0.2444\n",
      "Epoch 6437/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3550 - acc: 0.2092 - val_loss: 0.4040 - val_acc: 0.2444\n",
      "Epoch 6438/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3601 - acc: 0.2083 - val_loss: 0.4409 - val_acc: 0.2444\n",
      "Epoch 6439/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3621 - acc: 0.2092 - val_loss: 0.4675 - val_acc: 0.2444\n",
      "Epoch 6440/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3572 - acc: 0.2087 - val_loss: 0.4015 - val_acc: 0.2444\n",
      "Epoch 6441/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3499 - acc: 0.2096 - val_loss: 0.4172 - val_acc: 0.2444\n",
      "Epoch 6442/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3634 - acc: 0.2083 - val_loss: 0.4808 - val_acc: 0.2444\n",
      "Epoch 6443/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3486 - acc: 0.2092 - val_loss: 0.5492 - val_acc: 0.2444\n",
      "Epoch 6444/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3435 - acc: 0.2083 - val_loss: 0.3841 - val_acc: 0.2444\n",
      "Epoch 6445/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3340 - acc: 0.2092 - val_loss: 0.4072 - val_acc: 0.2444\n",
      "Epoch 6446/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3377 - acc: 0.2087 - val_loss: 0.4862 - val_acc: 0.2444\n",
      "Epoch 6447/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3708 - acc: 0.2087 - val_loss: 0.4163 - val_acc: 0.2444\n",
      "Epoch 6448/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3640 - acc: 0.2087 - val_loss: 0.4860 - val_acc: 0.2444\n",
      "Epoch 6449/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3571 - acc: 0.2092 - val_loss: 0.4004 - val_acc: 0.2444\n",
      "Epoch 6450/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3598 - acc: 0.2083 - val_loss: 0.4584 - val_acc: 0.2444\n",
      "Epoch 6451/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3359 - acc: 0.2092 - val_loss: 0.4179 - val_acc: 0.2444\n",
      "Epoch 6452/10000\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.3424 - acc: 0.209 - 3s 33ms/step - loss: 0.3420 - acc: 0.2096 - val_loss: 0.4319 - val_acc: 0.2444\n",
      "Epoch 6453/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3451 - acc: 0.2087 - val_loss: 0.5798 - val_acc: 0.2444\n",
      "Epoch 6454/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3498 - acc: 0.2100 - val_loss: 0.4645 - val_acc: 0.2444\n",
      "Epoch 6455/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3318 - acc: 0.2083 - val_loss: 0.4089 - val_acc: 0.2444\n",
      "Epoch 6456/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3397 - acc: 0.2087 - val_loss: 0.4029 - val_acc: 0.2444\n",
      "Epoch 6457/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3522 - acc: 0.2096 - val_loss: 0.4507 - val_acc: 0.2444\n",
      "Epoch 6458/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3404 - acc: 0.2096 - val_loss: 0.4222 - val_acc: 0.2444\n",
      "Epoch 6459/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3437 - acc: 0.2079 - val_loss: 0.4591 - val_acc: 0.2444\n",
      "Epoch 6460/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3648 - acc: 0.2087 - val_loss: 0.5080 - val_acc: 0.2407\n",
      "Epoch 6461/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3477 - acc: 0.2083 - val_loss: 0.4122 - val_acc: 0.2444\n",
      "Epoch 6462/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3361 - acc: 0.2092 - val_loss: 0.4012 - val_acc: 0.2444\n",
      "Epoch 6463/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3392 - acc: 0.2083 - val_loss: 0.4082 - val_acc: 0.2444\n",
      "Epoch 6464/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3473 - acc: 0.2087 - val_loss: 0.4028 - val_acc: 0.2444\n",
      "Epoch 6465/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3460 - acc: 0.2092 - val_loss: 0.4059 - val_acc: 0.2444\n",
      "Epoch 6466/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3552 - acc: 0.2087 - val_loss: 0.4002 - val_acc: 0.2444\n",
      "Epoch 6467/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3444 - acc: 0.2092 - val_loss: 0.4018 - val_acc: 0.2444\n",
      "Epoch 6468/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3461 - acc: 0.2092 - val_loss: 0.4082 - val_acc: 0.2444\n",
      "Epoch 6469/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3496 - acc: 0.2087 - val_loss: 0.6070 - val_acc: 0.2407\n",
      "Epoch 6470/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3779 - acc: 0.2083 - val_loss: 0.4053 - val_acc: 0.2444\n",
      "Epoch 6471/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3266 - acc: 0.2087 - val_loss: 0.4162 - val_acc: 0.2444\n",
      "Epoch 6472/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3551 - acc: 0.2087 - val_loss: 0.4790 - val_acc: 0.2444\n",
      "Epoch 6473/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3502 - acc: 0.2087 - val_loss: 0.5414 - val_acc: 0.2407\n",
      "Epoch 6474/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3476 - acc: 0.2087 - val_loss: 0.4145 - val_acc: 0.2444\n",
      "Epoch 6475/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3378 - acc: 0.2087 - val_loss: 0.4028 - val_acc: 0.2444\n",
      "Epoch 6476/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3497 - acc: 0.2096 - val_loss: 0.4022 - val_acc: 0.2444\n",
      "Epoch 6477/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3322 - acc: 0.2092 - val_loss: 0.4091 - val_acc: 0.2444\n",
      "Epoch 6478/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3636 - acc: 0.2087 - val_loss: 0.6427 - val_acc: 0.2407\n",
      "Epoch 6479/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3499 - acc: 0.2092 - val_loss: 0.4103 - val_acc: 0.2444\n",
      "Epoch 6480/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3579 - acc: 0.2079 - val_loss: 0.4004 - val_acc: 0.2444\n",
      "Epoch 6481/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3541 - acc: 0.2096 - val_loss: 0.4309 - val_acc: 0.2444\n",
      "Epoch 6482/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3383 - acc: 0.2092 - val_loss: 0.4032 - val_acc: 0.2444\n",
      "Epoch 6483/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3355 - acc: 0.2092 - val_loss: 0.4311 - val_acc: 0.2444\n",
      "Epoch 6484/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3505 - acc: 0.2083 - val_loss: 0.5218 - val_acc: 0.2444\n",
      "Epoch 6485/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3680 - acc: 0.2075 - val_loss: 0.4393 - val_acc: 0.2444\n",
      "Epoch 6486/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3369 - acc: 0.2096 - val_loss: 0.3953 - val_acc: 0.2444\n",
      "Epoch 6487/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3432 - acc: 0.2083 - val_loss: 0.4310 - val_acc: 0.2444\n",
      "Epoch 6488/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3337 - acc: 0.2092 - val_loss: 0.4042 - val_acc: 0.2444\n",
      "Epoch 6489/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3362 - acc: 0.2083 - val_loss: 0.4049 - val_acc: 0.2444\n",
      "Epoch 6490/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3413 - acc: 0.2092 - val_loss: 0.4655 - val_acc: 0.2444\n",
      "Epoch 6491/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3640 - acc: 0.2087 - val_loss: 0.4273 - val_acc: 0.2444\n",
      "Epoch 6492/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3467 - acc: 0.2083 - val_loss: 0.4612 - val_acc: 0.2444\n",
      "Epoch 6493/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3437 - acc: 0.2083 - val_loss: 0.4059 - val_acc: 0.2444\n",
      "Epoch 6494/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3316 - acc: 0.2083 - val_loss: 0.4349 - val_acc: 0.2444\n",
      "Epoch 6495/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3594 - acc: 0.2083 - val_loss: 0.4092 - val_acc: 0.2444\n",
      "Epoch 6496/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3443 - acc: 0.2092 - val_loss: 0.3934 - val_acc: 0.2444\n",
      "Epoch 6497/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3699 - acc: 0.2092 - val_loss: 0.4090 - val_acc: 0.2444\n",
      "Epoch 6498/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3430 - acc: 0.2087 - val_loss: 0.4044 - val_acc: 0.2444\n",
      "Epoch 6499/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3421 - acc: 0.2079 - val_loss: 0.4087 - val_acc: 0.2444\n",
      "Epoch 6500/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3456 - acc: 0.2087 - val_loss: 0.4174 - val_acc: 0.2444\n",
      "Epoch 6501/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3293 - acc: 0.2092 - val_loss: 0.4086 - val_acc: 0.2444\n",
      "Epoch 6502/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3351 - acc: 0.2083 - val_loss: 0.4078 - val_acc: 0.2444\n",
      "Epoch 6503/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3397 - acc: 0.2087 - val_loss: 0.4335 - val_acc: 0.2444\n",
      "Epoch 6504/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3625 - acc: 0.2096 - val_loss: 0.4641 - val_acc: 0.2444\n",
      "Epoch 6505/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3389 - acc: 0.2096 - val_loss: 0.3973 - val_acc: 0.2444\n",
      "Epoch 6506/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3556 - acc: 0.2092 - val_loss: 0.4310 - val_acc: 0.2444\n",
      "Epoch 6507/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3738 - acc: 0.2079 - val_loss: 0.4323 - val_acc: 0.2444\n",
      "Epoch 6508/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3455 - acc: 0.2087 - val_loss: 0.4064 - val_acc: 0.2444\n",
      "Epoch 6509/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3326 - acc: 0.2087 - val_loss: 0.4123 - val_acc: 0.2444\n",
      "Epoch 6510/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3404 - acc: 0.2096 - val_loss: 0.4025 - val_acc: 0.2444\n",
      "Epoch 6511/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3362 - acc: 0.2092 - val_loss: 0.4051 - val_acc: 0.2444\n",
      "Epoch 6512/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3381 - acc: 0.2087 - val_loss: 0.4535 - val_acc: 0.2444\n",
      "Epoch 6513/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3395 - acc: 0.2079 - val_loss: 0.4019 - val_acc: 0.2444\n",
      "Epoch 6514/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3409 - acc: 0.2079 - val_loss: 0.3931 - val_acc: 0.2444\n",
      "Epoch 6515/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3326 - acc: 0.2092 - val_loss: 0.4026 - val_acc: 0.2444\n",
      "Epoch 6516/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3335 - acc: 0.2096 - val_loss: 0.4055 - val_acc: 0.2444\n",
      "Epoch 6517/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3308 - acc: 0.2087 - val_loss: 0.5589 - val_acc: 0.2444\n",
      "Epoch 6518/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3388 - acc: 0.2092 - val_loss: 0.4337 - val_acc: 0.2444\n",
      "Epoch 6519/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3430 - acc: 0.2092 - val_loss: 0.4070 - val_acc: 0.2444\n",
      "Epoch 6520/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3396 - acc: 0.2087 - val_loss: 0.4273 - val_acc: 0.2444\n",
      "Epoch 6521/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3295 - acc: 0.2087 - val_loss: 0.4242 - val_acc: 0.2444\n",
      "Epoch 6522/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3323 - acc: 0.2092 - val_loss: 0.4048 - val_acc: 0.2444\n",
      "Epoch 6523/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3495 - acc: 0.2092 - val_loss: 0.4034 - val_acc: 0.2444\n",
      "Epoch 6524/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3651 - acc: 0.2075 - val_loss: 0.4181 - val_acc: 0.2444\n",
      "Epoch 6525/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3590 - acc: 0.2092 - val_loss: 0.4418 - val_acc: 0.2444\n",
      "Epoch 6526/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3304 - acc: 0.2087 - val_loss: 0.3954 - val_acc: 0.2444\n",
      "Epoch 6527/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3395 - acc: 0.2096 - val_loss: 0.4023 - val_acc: 0.2444\n",
      "Epoch 6528/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3432 - acc: 0.2092 - val_loss: 0.4123 - val_acc: 0.2444\n",
      "Epoch 6529/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.3357 - acc: 0.2092 - val_loss: 0.3952 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6530/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3271 - acc: 0.2092 - val_loss: 0.4289 - val_acc: 0.2444\n",
      "Epoch 6531/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3407 - acc: 0.2096 - val_loss: 0.4137 - val_acc: 0.2444\n",
      "Epoch 6532/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3335 - acc: 0.2092 - val_loss: 0.4082 - val_acc: 0.2444\n",
      "Epoch 6533/10000\n",
      "76/76 [==============================] - 2s 30ms/step - loss: 0.3378 - acc: 0.2092 - val_loss: 0.5267 - val_acc: 0.2407\n",
      "Epoch 6534/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3412 - acc: 0.2092 - val_loss: 0.4464 - val_acc: 0.2444\n",
      "Epoch 6535/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3450 - acc: 0.2087 - val_loss: 0.4505 - val_acc: 0.2444\n",
      "Epoch 6536/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3396 - acc: 0.2083 - val_loss: 0.4165 - val_acc: 0.2444\n",
      "Epoch 6537/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3409 - acc: 0.2092 - val_loss: 0.4048 - val_acc: 0.2444\n",
      "Epoch 6538/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3313 - acc: 0.2083 - val_loss: 0.4021 - val_acc: 0.2444\n",
      "Epoch 6539/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3320 - acc: 0.2092 - val_loss: 0.4548 - val_acc: 0.2444\n",
      "Epoch 6540/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3478 - acc: 0.2096 - val_loss: 0.5906 - val_acc: 0.2444\n",
      "Epoch 6541/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3426 - acc: 0.2083 - val_loss: 0.3939 - val_acc: 0.2444\n",
      "Epoch 6542/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3420 - acc: 0.2092 - val_loss: 0.4238 - val_acc: 0.2444\n",
      "Epoch 6543/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3635 - acc: 0.2083 - val_loss: 0.5359 - val_acc: 0.2444\n",
      "Epoch 6544/10000\n",
      "76/76 [==============================] - 2s 30ms/step - loss: 0.3906 - acc: 0.2096 - val_loss: 0.4046 - val_acc: 0.2444\n",
      "Epoch 6545/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3369 - acc: 0.2096 - val_loss: 0.4076 - val_acc: 0.2444\n",
      "Epoch 6546/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3344 - acc: 0.2087 - val_loss: 0.3861 - val_acc: 0.2444\n",
      "Epoch 6547/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3348 - acc: 0.2092 - val_loss: 0.3934 - val_acc: 0.2444\n",
      "Epoch 6548/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3351 - acc: 0.2092 - val_loss: 0.4056 - val_acc: 0.2444\n",
      "Epoch 6549/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3390 - acc: 0.2092 - val_loss: 0.4322 - val_acc: 0.2444\n",
      "Epoch 6550/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3350 - acc: 0.2083 - val_loss: 0.3978 - val_acc: 0.2444\n",
      "Epoch 6551/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3367 - acc: 0.2087 - val_loss: 0.4978 - val_acc: 0.2444\n",
      "Epoch 6552/10000\n",
      "76/76 [==============================] - 2s 30ms/step - loss: 0.3395 - acc: 0.2092 - val_loss: 0.4774 - val_acc: 0.2407\n",
      "Epoch 6553/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3351 - acc: 0.2087 - val_loss: 0.4627 - val_acc: 0.2444\n",
      "Epoch 6554/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.3344 - acc: 0.2087 - val_loss: 0.5018 - val_acc: 0.2407\n",
      "Epoch 6555/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.3508 - acc: 0.2087 - val_loss: 0.3947 - val_acc: 0.2444\n",
      "Epoch 6556/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3276 - acc: 0.2087 - val_loss: 0.4675 - val_acc: 0.2407\n",
      "Epoch 6557/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3368 - acc: 0.2092 - val_loss: 0.4008 - val_acc: 0.2444\n",
      "Epoch 6558/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3615 - acc: 0.2083 - val_loss: 0.4126 - val_acc: 0.2444\n",
      "Epoch 6559/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3293 - acc: 0.2096 - val_loss: 0.4156 - val_acc: 0.2444\n",
      "Epoch 6560/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3616 - acc: 0.2079 - val_loss: 0.4796 - val_acc: 0.2407\n",
      "Epoch 6561/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3477 - acc: 0.2092 - val_loss: 0.4126 - val_acc: 0.2444\n",
      "Epoch 6562/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3408 - acc: 0.2096 - val_loss: 0.4137 - val_acc: 0.2444\n",
      "Epoch 6563/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3323 - acc: 0.2083 - val_loss: 0.4420 - val_acc: 0.2444\n",
      "Epoch 6564/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3761 - acc: 0.2092 - val_loss: 0.4525 - val_acc: 0.2444\n",
      "Epoch 6565/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3583 - acc: 0.2087 - val_loss: 0.4588 - val_acc: 0.2444\n",
      "Epoch 6566/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3380 - acc: 0.2092 - val_loss: 0.3947 - val_acc: 0.2444\n",
      "Epoch 6567/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3555 - acc: 0.2087 - val_loss: 0.4126 - val_acc: 0.2444\n",
      "Epoch 6568/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3275 - acc: 0.2096 - val_loss: 0.4139 - val_acc: 0.2444\n",
      "Epoch 6569/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3576 - acc: 0.2083 - val_loss: 0.4625 - val_acc: 0.2444\n",
      "Epoch 6570/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3457 - acc: 0.2087 - val_loss: 0.4044 - val_acc: 0.2444\n",
      "Epoch 6571/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3768 - acc: 0.2092 - val_loss: 0.4110 - val_acc: 0.2444\n",
      "Epoch 6572/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3336 - acc: 0.2092 - val_loss: 0.4113 - val_acc: 0.2444\n",
      "Epoch 6573/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3428 - acc: 0.2087 - val_loss: 0.4120 - val_acc: 0.2444\n",
      "Epoch 6574/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3823 - acc: 0.2087 - val_loss: 0.4901 - val_acc: 0.2444\n",
      "Epoch 6575/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3428 - acc: 0.2087 - val_loss: 0.4166 - val_acc: 0.2444\n",
      "Epoch 6576/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3396 - acc: 0.2083 - val_loss: 0.4168 - val_acc: 0.2444\n",
      "Epoch 6577/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3412 - acc: 0.2092 - val_loss: 0.4268 - val_acc: 0.2444\n",
      "Epoch 6578/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3389 - acc: 0.2083 - val_loss: 0.4128 - val_acc: 0.2444\n",
      "Epoch 6579/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3512 - acc: 0.2092 - val_loss: 0.4155 - val_acc: 0.2444\n",
      "Epoch 6580/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3343 - acc: 0.2092 - val_loss: 0.4075 - val_acc: 0.2444\n",
      "Epoch 6581/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3409 - acc: 0.2092 - val_loss: 0.4077 - val_acc: 0.2444\n",
      "Epoch 6582/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3316 - acc: 0.2087 - val_loss: 0.4063 - val_acc: 0.2444\n",
      "Epoch 6583/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3374 - acc: 0.2096 - val_loss: 0.3989 - val_acc: 0.2444\n",
      "Epoch 6584/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3404 - acc: 0.2087 - val_loss: 0.4310 - val_acc: 0.2444\n",
      "Epoch 6585/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3373 - acc: 0.2092 - val_loss: 0.5410 - val_acc: 0.2444\n",
      "Epoch 6586/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3524 - acc: 0.2083 - val_loss: 0.4253 - val_acc: 0.2444\n",
      "Epoch 6587/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3696 - acc: 0.2092 - val_loss: 0.5570 - val_acc: 0.2407\n",
      "Epoch 6588/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3672 - acc: 0.2083 - val_loss: 0.4587 - val_acc: 0.2444\n",
      "Epoch 6589/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3595 - acc: 0.2083 - val_loss: 0.3967 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6590/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3340 - acc: 0.2092 - val_loss: 0.3976 - val_acc: 0.2444\n",
      "Epoch 6591/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3650 - acc: 0.2092 - val_loss: 0.4591 - val_acc: 0.2444\n",
      "Epoch 6592/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3659 - acc: 0.2087 - val_loss: 0.4202 - val_acc: 0.2444\n",
      "Epoch 6593/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3332 - acc: 0.2092 - val_loss: 0.4211 - val_acc: 0.2444\n",
      "Epoch 6594/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3476 - acc: 0.2092 - val_loss: 0.4187 - val_acc: 0.2444\n",
      "Epoch 6595/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3438 - acc: 0.2096 - val_loss: 0.4220 - val_acc: 0.2444\n",
      "Epoch 6596/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3326 - acc: 0.2083 - val_loss: 0.4076 - val_acc: 0.2444\n",
      "Epoch 6597/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3251 - acc: 0.2092 - val_loss: 0.4217 - val_acc: 0.2444\n",
      "Epoch 6598/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3307 - acc: 0.2083 - val_loss: 0.4089 - val_acc: 0.2444\n",
      "Epoch 6599/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3330 - acc: 0.2087 - val_loss: 0.4143 - val_acc: 0.2444\n",
      "Epoch 6600/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3531 - acc: 0.2087 - val_loss: 0.4244 - val_acc: 0.2444\n",
      "Epoch 6601/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3386 - acc: 0.2092 - val_loss: 0.3951 - val_acc: 0.2444\n",
      "Epoch 6602/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3791 - acc: 0.2096 - val_loss: 0.4230 - val_acc: 0.2444\n",
      "Epoch 6603/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3409 - acc: 0.2092 - val_loss: 0.4309 - val_acc: 0.2444\n",
      "Epoch 6604/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3511 - acc: 0.2079 - val_loss: 0.5797 - val_acc: 0.2407\n",
      "Epoch 6605/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3695 - acc: 0.2079 - val_loss: 0.4457 - val_acc: 0.2444\n",
      "Epoch 6606/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3420 - acc: 0.2083 - val_loss: 0.4007 - val_acc: 0.2444\n",
      "Epoch 6607/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3395 - acc: 0.2096 - val_loss: 0.3956 - val_acc: 0.2444\n",
      "Epoch 6608/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3390 - acc: 0.2096 - val_loss: 0.4101 - val_acc: 0.2444\n",
      "Epoch 6609/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3300 - acc: 0.2092 - val_loss: 0.4946 - val_acc: 0.2444\n",
      "Epoch 6610/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3338 - acc: 0.2087 - val_loss: 0.4166 - val_acc: 0.2444\n",
      "Epoch 6611/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3487 - acc: 0.2087 - val_loss: 0.4197 - val_acc: 0.2444\n",
      "Epoch 6612/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3623 - acc: 0.2083 - val_loss: 0.4349 - val_acc: 0.2444\n",
      "Epoch 6613/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3491 - acc: 0.2092 - val_loss: 0.4198 - val_acc: 0.2444\n",
      "Epoch 6614/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3428 - acc: 0.2092 - val_loss: 0.4105 - val_acc: 0.2444\n",
      "Epoch 6615/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3427 - acc: 0.2087 - val_loss: 0.4166 - val_acc: 0.2444\n",
      "Epoch 6616/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3305 - acc: 0.2092 - val_loss: 0.4193 - val_acc: 0.2444\n",
      "Epoch 6617/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3427 - acc: 0.2092 - val_loss: 0.3974 - val_acc: 0.2444\n",
      "Epoch 6618/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3486 - acc: 0.2083 - val_loss: 0.4341 - val_acc: 0.2444\n",
      "Epoch 6619/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3538 - acc: 0.2083 - val_loss: 0.4501 - val_acc: 0.2407\n",
      "Epoch 6620/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3364 - acc: 0.2087 - val_loss: 0.4111 - val_acc: 0.2444\n",
      "Epoch 6621/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3420 - acc: 0.2092 - val_loss: 0.4436 - val_acc: 0.2444\n",
      "Epoch 6622/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3551 - acc: 0.2100 - val_loss: 0.4215 - val_acc: 0.2444\n",
      "Epoch 6623/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3669 - acc: 0.2092 - val_loss: 0.3929 - val_acc: 0.2444\n",
      "Epoch 6624/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3276 - acc: 0.2087 - val_loss: 0.4024 - val_acc: 0.2444\n",
      "Epoch 6625/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3617 - acc: 0.2092 - val_loss: 0.3966 - val_acc: 0.2444\n",
      "Epoch 6626/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3467 - acc: 0.2087 - val_loss: 0.4152 - val_acc: 0.2444\n",
      "Epoch 6627/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3700 - acc: 0.2079 - val_loss: 0.4438 - val_acc: 0.2444\n",
      "Epoch 6628/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3511 - acc: 0.2092 - val_loss: 0.4089 - val_acc: 0.2444\n",
      "Epoch 6629/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3298 - acc: 0.2083 - val_loss: 0.4031 - val_acc: 0.2444\n",
      "Epoch 6630/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3252 - acc: 0.2092 - val_loss: 0.3991 - val_acc: 0.2444\n",
      "Epoch 6631/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3438 - acc: 0.2092 - val_loss: 0.4813 - val_acc: 0.2407\n",
      "Epoch 6632/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3550 - acc: 0.2075 - val_loss: 0.4589 - val_acc: 0.2444\n",
      "Epoch 6633/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3430 - acc: 0.2087 - val_loss: 0.4247 - val_acc: 0.2444\n",
      "Epoch 6634/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3386 - acc: 0.2092 - val_loss: 0.4277 - val_acc: 0.2444\n",
      "Epoch 6635/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3433 - acc: 0.2092 - val_loss: 0.4207 - val_acc: 0.2444\n",
      "Epoch 6636/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3450 - acc: 0.2092 - val_loss: 0.4509 - val_acc: 0.2444\n",
      "Epoch 6637/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3355 - acc: 0.2083 - val_loss: 0.3966 - val_acc: 0.2444\n",
      "Epoch 6638/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3499 - acc: 0.2096 - val_loss: 0.3914 - val_acc: 0.2444\n",
      "Epoch 6639/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3243 - acc: 0.2092 - val_loss: 0.4207 - val_acc: 0.2444\n",
      "Epoch 6640/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3446 - acc: 0.2092 - val_loss: 0.4112 - val_acc: 0.2444\n",
      "Epoch 6641/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3516 - acc: 0.2087 - val_loss: 0.4954 - val_acc: 0.2407\n",
      "Epoch 6642/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3423 - acc: 0.2092 - val_loss: 0.4099 - val_acc: 0.2444\n",
      "Epoch 6643/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3266 - acc: 0.2087 - val_loss: 0.4048 - val_acc: 0.2444\n",
      "Epoch 6644/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3455 - acc: 0.2092 - val_loss: 0.5038 - val_acc: 0.2407\n",
      "Epoch 6645/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3298 - acc: 0.2087 - val_loss: 0.4288 - val_acc: 0.2444\n",
      "Epoch 6646/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3452 - acc: 0.2087 - val_loss: 0.4325 - val_acc: 0.2444\n",
      "Epoch 6647/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3463 - acc: 0.2096 - val_loss: 0.4096 - val_acc: 0.2444\n",
      "Epoch 6648/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3378 - acc: 0.2092 - val_loss: 0.3897 - val_acc: 0.2444\n",
      "Epoch 6649/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3831 - acc: 0.2092 - val_loss: 0.5940 - val_acc: 0.2407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6650/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3655 - acc: 0.2087 - val_loss: 0.4202 - val_acc: 0.2444\n",
      "Epoch 6651/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3338 - acc: 0.2083 - val_loss: 0.4165 - val_acc: 0.2444\n",
      "Epoch 6652/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3320 - acc: 0.2087 - val_loss: 0.3976 - val_acc: 0.2444\n",
      "Epoch 6653/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3526 - acc: 0.2087 - val_loss: 0.4042 - val_acc: 0.2444\n",
      "Epoch 6654/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3321 - acc: 0.2092 - val_loss: 0.4015 - val_acc: 0.2444\n",
      "Epoch 6655/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3406 - acc: 0.2092 - val_loss: 0.4077 - val_acc: 0.2444\n",
      "Epoch 6656/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3396 - acc: 0.2087 - val_loss: 0.4051 - val_acc: 0.2444\n",
      "Epoch 6657/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3321 - acc: 0.2092 - val_loss: 0.4704 - val_acc: 0.2444\n",
      "Epoch 6658/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3444 - acc: 0.2083 - val_loss: 0.4332 - val_acc: 0.2444\n",
      "Epoch 6659/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3514 - acc: 0.2087 - val_loss: 0.4286 - val_acc: 0.2444\n",
      "Epoch 6660/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3503 - acc: 0.2092 - val_loss: 0.4389 - val_acc: 0.2444\n",
      "Epoch 6661/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3508 - acc: 0.2092 - val_loss: 0.4397 - val_acc: 0.2444\n",
      "Epoch 6662/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3333 - acc: 0.2096 - val_loss: 0.4051 - val_acc: 0.2444\n",
      "Epoch 6663/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3428 - acc: 0.2096 - val_loss: 0.4000 - val_acc: 0.2444\n",
      "Epoch 6664/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3462 - acc: 0.2087 - val_loss: 0.4421 - val_acc: 0.2444\n",
      "Epoch 6665/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3337 - acc: 0.2092 - val_loss: 0.4348 - val_acc: 0.2444\n",
      "Epoch 6666/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3318 - acc: 0.2092 - val_loss: 0.4066 - val_acc: 0.2444\n",
      "Epoch 6667/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3362 - acc: 0.2092 - val_loss: 0.4058 - val_acc: 0.2444\n",
      "Epoch 6668/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3405 - acc: 0.2092 - val_loss: 0.4211 - val_acc: 0.2444\n",
      "Epoch 6669/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3686 - acc: 0.2087 - val_loss: 0.4510 - val_acc: 0.2444\n",
      "Epoch 6670/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3587 - acc: 0.2092 - val_loss: 0.4602 - val_acc: 0.2444\n",
      "Epoch 6671/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3558 - acc: 0.2092 - val_loss: 0.4871 - val_acc: 0.2407\n",
      "Epoch 6672/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3411 - acc: 0.2087 - val_loss: 0.4459 - val_acc: 0.2444\n",
      "Epoch 6673/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3471 - acc: 0.2096 - val_loss: 0.4122 - val_acc: 0.2444\n",
      "Epoch 6674/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3415 - acc: 0.2087 - val_loss: 0.3946 - val_acc: 0.2444\n",
      "Epoch 6675/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3368 - acc: 0.2092 - val_loss: 0.4316 - val_acc: 0.2444\n",
      "Epoch 6676/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3455 - acc: 0.2083 - val_loss: 0.4177 - val_acc: 0.2444\n",
      "Epoch 6677/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3527 - acc: 0.2092 - val_loss: 0.4265 - val_acc: 0.2444\n",
      "Epoch 6678/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3414 - acc: 0.2092 - val_loss: 0.4112 - val_acc: 0.2444\n",
      "Epoch 6679/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3299 - acc: 0.2087 - val_loss: 0.4531 - val_acc: 0.2444\n",
      "Epoch 6680/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3458 - acc: 0.2083 - val_loss: 0.4161 - val_acc: 0.2444\n",
      "Epoch 6681/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3307 - acc: 0.2092 - val_loss: 0.5363 - val_acc: 0.2407\n",
      "Epoch 6682/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3558 - acc: 0.2083 - val_loss: 0.4181 - val_acc: 0.2444\n",
      "Epoch 6683/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3450 - acc: 0.2092 - val_loss: 0.4100 - val_acc: 0.2444\n",
      "Epoch 6684/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3385 - acc: 0.2087 - val_loss: 0.3874 - val_acc: 0.2444\n",
      "Epoch 6685/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3229 - acc: 0.2092 - val_loss: 0.4103 - val_acc: 0.2444\n",
      "Epoch 6686/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3338 - acc: 0.2087 - val_loss: 0.4226 - val_acc: 0.2444\n",
      "Epoch 6687/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3409 - acc: 0.2092 - val_loss: 0.3969 - val_acc: 0.2444\n",
      "Epoch 6688/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3355 - acc: 0.2087 - val_loss: 0.4196 - val_acc: 0.2444\n",
      "Epoch 6689/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3341 - acc: 0.2083 - val_loss: 0.4085 - val_acc: 0.2444\n",
      "Epoch 6690/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3413 - acc: 0.2087 - val_loss: 0.4067 - val_acc: 0.2444\n",
      "Epoch 6691/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3350 - acc: 0.2100 - val_loss: 0.4268 - val_acc: 0.2444\n",
      "Epoch 6692/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3462 - acc: 0.2087 - val_loss: 0.4252 - val_acc: 0.2444\n",
      "Epoch 6693/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3834 - acc: 0.2087 - val_loss: 0.4060 - val_acc: 0.2444\n",
      "Epoch 6694/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3334 - acc: 0.2083 - val_loss: 0.4165 - val_acc: 0.2444\n",
      "Epoch 6695/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3380 - acc: 0.2092 - val_loss: 0.4172 - val_acc: 0.2444\n",
      "Epoch 6696/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3486 - acc: 0.2096 - val_loss: 0.4744 - val_acc: 0.2407\n",
      "Epoch 6697/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3388 - acc: 0.2096 - val_loss: 0.4967 - val_acc: 0.2407\n",
      "Epoch 6698/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3322 - acc: 0.2092 - val_loss: 0.4353 - val_acc: 0.2444\n",
      "Epoch 6699/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3455 - acc: 0.2083 - val_loss: 0.3999 - val_acc: 0.2444\n",
      "Epoch 6700/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3400 - acc: 0.2083 - val_loss: 0.4139 - val_acc: 0.2444\n",
      "Epoch 6701/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3545 - acc: 0.2087 - val_loss: 0.4212 - val_acc: 0.2444\n",
      "Epoch 6702/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3365 - acc: 0.2092 - val_loss: 0.4388 - val_acc: 0.2444\n",
      "Epoch 6703/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3805 - acc: 0.2092 - val_loss: 0.4145 - val_acc: 0.2444\n",
      "Epoch 6704/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3408 - acc: 0.2087 - val_loss: 0.4123 - val_acc: 0.2444\n",
      "Epoch 6705/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3265 - acc: 0.2092 - val_loss: 0.4173 - val_acc: 0.2444\n",
      "Epoch 6706/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3280 - acc: 0.2092 - val_loss: 0.4308 - val_acc: 0.2444\n",
      "Epoch 6707/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3337 - acc: 0.2092 - val_loss: 0.4099 - val_acc: 0.2444\n",
      "Epoch 6708/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3238 - acc: 0.2087 - val_loss: 0.4007 - val_acc: 0.2444\n",
      "Epoch 6709/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3469 - acc: 0.2092 - val_loss: 0.4356 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6710/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3389 - acc: 0.2092 - val_loss: 0.4353 - val_acc: 0.2444\n",
      "Epoch 6711/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3515 - acc: 0.2087 - val_loss: 0.4841 - val_acc: 0.2444\n",
      "Epoch 6712/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3457 - acc: 0.2087 - val_loss: 0.4343 - val_acc: 0.2444\n",
      "Epoch 6713/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3498 - acc: 0.2092 - val_loss: 0.3988 - val_acc: 0.2444\n",
      "Epoch 6714/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3555 - acc: 0.2083 - val_loss: 0.4260 - val_acc: 0.2444\n",
      "Epoch 6715/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3376 - acc: 0.2087 - val_loss: 0.4089 - val_acc: 0.2444\n",
      "Epoch 6716/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3495 - acc: 0.2083 - val_loss: 0.3917 - val_acc: 0.2444\n",
      "Epoch 6717/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3423 - acc: 0.2087 - val_loss: 0.6133 - val_acc: 0.2444\n",
      "Epoch 6718/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3675 - acc: 0.2092 - val_loss: 0.4188 - val_acc: 0.2444\n",
      "Epoch 6719/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3386 - acc: 0.2096 - val_loss: 0.4222 - val_acc: 0.2444\n",
      "Epoch 6720/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3454 - acc: 0.2092 - val_loss: 0.4090 - val_acc: 0.2444\n",
      "Epoch 6721/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3383 - acc: 0.2083 - val_loss: 0.4117 - val_acc: 0.2444\n",
      "Epoch 6722/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3522 - acc: 0.2092 - val_loss: 0.4404 - val_acc: 0.2444\n",
      "Epoch 6723/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3635 - acc: 0.2087 - val_loss: 0.6098 - val_acc: 0.2407\n",
      "Epoch 6724/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3624 - acc: 0.2092 - val_loss: 0.4792 - val_acc: 0.2407\n",
      "Epoch 6725/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3362 - acc: 0.2092 - val_loss: 0.4695 - val_acc: 0.2444\n",
      "Epoch 6726/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3545 - acc: 0.2083 - val_loss: 0.3957 - val_acc: 0.2444\n",
      "Epoch 6727/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3441 - acc: 0.2087 - val_loss: 0.3995 - val_acc: 0.2444\n",
      "Epoch 6728/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3314 - acc: 0.2092 - val_loss: 0.4016 - val_acc: 0.2444\n",
      "Epoch 6729/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3364 - acc: 0.2096 - val_loss: 0.3925 - val_acc: 0.2444\n",
      "Epoch 6730/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3830 - acc: 0.2092 - val_loss: 0.4521 - val_acc: 0.2444\n",
      "Epoch 6731/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3471 - acc: 0.2092 - val_loss: 0.4323 - val_acc: 0.2444\n",
      "Epoch 6732/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3456 - acc: 0.2092 - val_loss: 0.4171 - val_acc: 0.2444\n",
      "Epoch 6733/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3512 - acc: 0.2096 - val_loss: 0.4315 - val_acc: 0.2444\n",
      "Epoch 6734/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3408 - acc: 0.2087 - val_loss: 0.4692 - val_acc: 0.2407\n",
      "Epoch 6735/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3280 - acc: 0.2092 - val_loss: 0.3924 - val_acc: 0.2444\n",
      "Epoch 6736/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3463 - acc: 0.2079 - val_loss: 0.4199 - val_acc: 0.2444\n",
      "Epoch 6737/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3287 - acc: 0.2096 - val_loss: 0.4062 - val_acc: 0.2444\n",
      "Epoch 6738/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3367 - acc: 0.2096 - val_loss: 0.4117 - val_acc: 0.2444\n",
      "Epoch 6739/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3340 - acc: 0.2087 - val_loss: 0.4077 - val_acc: 0.2444\n",
      "Epoch 6740/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3431 - acc: 0.2092 - val_loss: 0.4125 - val_acc: 0.2444\n",
      "Epoch 6741/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3381 - acc: 0.2092 - val_loss: 0.4099 - val_acc: 0.2444\n",
      "Epoch 6742/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3475 - acc: 0.2092 - val_loss: 0.4123 - val_acc: 0.2444\n",
      "Epoch 6743/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3346 - acc: 0.2096 - val_loss: 0.4447 - val_acc: 0.2444\n",
      "Epoch 6744/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3560 - acc: 0.2083 - val_loss: 0.3973 - val_acc: 0.2444\n",
      "Epoch 6745/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3362 - acc: 0.2096 - val_loss: 0.5232 - val_acc: 0.2407\n",
      "Epoch 6746/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3383 - acc: 0.2096 - val_loss: 0.4312 - val_acc: 0.2444\n",
      "Epoch 6747/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3618 - acc: 0.2083 - val_loss: 0.4873 - val_acc: 0.2407\n",
      "Epoch 6748/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3381 - acc: 0.2087 - val_loss: 0.4526 - val_acc: 0.2444\n",
      "Epoch 6749/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3558 - acc: 0.2087 - val_loss: 0.4159 - val_acc: 0.2444\n",
      "Epoch 6750/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3315 - acc: 0.2092 - val_loss: 0.4190 - val_acc: 0.2444\n",
      "Epoch 6751/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3576 - acc: 0.2075 - val_loss: 0.4088 - val_acc: 0.2444\n",
      "Epoch 6752/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3332 - acc: 0.2087 - val_loss: 0.4296 - val_acc: 0.2444\n",
      "Epoch 6753/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3342 - acc: 0.2083 - val_loss: 0.4977 - val_acc: 0.2407\n",
      "Epoch 6754/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3483 - acc: 0.2092 - val_loss: 0.5455 - val_acc: 0.2407\n",
      "Epoch 6755/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3442 - acc: 0.2083 - val_loss: 0.4041 - val_acc: 0.2444\n",
      "Epoch 6756/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3273 - acc: 0.2100 - val_loss: 0.4138 - val_acc: 0.2444\n",
      "Epoch 6757/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3405 - acc: 0.2083 - val_loss: 0.3905 - val_acc: 0.2444\n",
      "Epoch 6758/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3502 - acc: 0.2096 - val_loss: 0.3950 - val_acc: 0.2444\n",
      "Epoch 6759/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3337 - acc: 0.2096 - val_loss: 0.4561 - val_acc: 0.2444\n",
      "Epoch 6760/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3652 - acc: 0.2087 - val_loss: 0.4122 - val_acc: 0.2444\n",
      "Epoch 6761/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3450 - acc: 0.2096 - val_loss: 0.4357 - val_acc: 0.2444\n",
      "Epoch 6762/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3309 - acc: 0.2087 - val_loss: 0.4077 - val_acc: 0.2444\n",
      "Epoch 6763/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3453 - acc: 0.2083 - val_loss: 0.4012 - val_acc: 0.2444\n",
      "Epoch 6764/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3461 - acc: 0.2092 - val_loss: 0.4018 - val_acc: 0.2444\n",
      "Epoch 6765/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3483 - acc: 0.2092 - val_loss: 0.4102 - val_acc: 0.2444\n",
      "Epoch 6766/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3405 - acc: 0.2092 - val_loss: 0.4179 - val_acc: 0.2444\n",
      "Epoch 6767/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3521 - acc: 0.2083 - val_loss: 0.4328 - val_acc: 0.2444\n",
      "Epoch 6768/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3347 - acc: 0.2092 - val_loss: 0.3999 - val_acc: 0.2444\n",
      "Epoch 6769/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3493 - acc: 0.2096 - val_loss: 0.4061 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6770/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3356 - acc: 0.2092 - val_loss: 0.4097 - val_acc: 0.2444\n",
      "Epoch 6771/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3254 - acc: 0.2092 - val_loss: 0.4063 - val_acc: 0.2444\n",
      "Epoch 6772/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3361 - acc: 0.2092 - val_loss: 0.4298 - val_acc: 0.2444\n",
      "Epoch 6773/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3670 - acc: 0.2087 - val_loss: 0.4462 - val_acc: 0.2444\n",
      "Epoch 6774/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3402 - acc: 0.2092 - val_loss: 0.4173 - val_acc: 0.2444\n",
      "Epoch 6775/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3355 - acc: 0.2096 - val_loss: 0.5230 - val_acc: 0.2444\n",
      "Epoch 6776/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3583 - acc: 0.2092 - val_loss: 0.4001 - val_acc: 0.2444\n",
      "Epoch 6777/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3417 - acc: 0.2096 - val_loss: 0.3979 - val_acc: 0.2444\n",
      "Epoch 6778/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3310 - acc: 0.2092 - val_loss: 0.4910 - val_acc: 0.2407\n",
      "Epoch 6779/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3482 - acc: 0.2092 - val_loss: 0.5248 - val_acc: 0.2407\n",
      "Epoch 6780/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3654 - acc: 0.2083 - val_loss: 0.4121 - val_acc: 0.2444\n",
      "Epoch 6781/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3465 - acc: 0.2092 - val_loss: 0.4188 - val_acc: 0.2444\n",
      "Epoch 6782/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3290 - acc: 0.2092 - val_loss: 0.4037 - val_acc: 0.2444\n",
      "Epoch 6783/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3373 - acc: 0.2096 - val_loss: 0.5662 - val_acc: 0.2444\n",
      "Epoch 6784/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3409 - acc: 0.2092 - val_loss: 0.4127 - val_acc: 0.2444\n",
      "Epoch 6785/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3636 - acc: 0.2087 - val_loss: 0.4559 - val_acc: 0.2444\n",
      "Epoch 6786/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3317 - acc: 0.2100 - val_loss: 0.4062 - val_acc: 0.2444\n",
      "Epoch 6787/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3390 - acc: 0.2096 - val_loss: 0.4062 - val_acc: 0.2444\n",
      "Epoch 6788/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3429 - acc: 0.2083 - val_loss: 0.5328 - val_acc: 0.2444\n",
      "Epoch 6789/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3397 - acc: 0.2096 - val_loss: 0.4302 - val_acc: 0.2444\n",
      "Epoch 6790/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3417 - acc: 0.2079 - val_loss: 0.4133 - val_acc: 0.2444\n",
      "Epoch 6791/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3534 - acc: 0.2096 - val_loss: 0.4086 - val_acc: 0.2444\n",
      "Epoch 6792/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3309 - acc: 0.2096 - val_loss: 0.3977 - val_acc: 0.2444\n",
      "Epoch 6793/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3365 - acc: 0.2087 - val_loss: 0.4477 - val_acc: 0.2444\n",
      "Epoch 6794/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3491 - acc: 0.2096 - val_loss: 0.4259 - val_acc: 0.2444\n",
      "Epoch 6795/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3707 - acc: 0.2083 - val_loss: 0.4139 - val_acc: 0.2444\n",
      "Epoch 6796/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3268 - acc: 0.2092 - val_loss: 0.5612 - val_acc: 0.2444\n",
      "Epoch 6797/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3461 - acc: 0.2087 - val_loss: 0.4471 - val_acc: 0.2444\n",
      "Epoch 6798/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3599 - acc: 0.2087 - val_loss: 0.4845 - val_acc: 0.2444\n",
      "Epoch 6799/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3274 - acc: 0.2087 - val_loss: 0.3960 - val_acc: 0.2444\n",
      "Epoch 6800/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3419 - acc: 0.2083 - val_loss: 0.4203 - val_acc: 0.2444\n",
      "Epoch 6801/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3384 - acc: 0.2083 - val_loss: 0.5590 - val_acc: 0.2444\n",
      "Epoch 6802/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3841 - acc: 0.2083 - val_loss: 0.4396 - val_acc: 0.2444\n",
      "Epoch 6803/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3450 - acc: 0.2096 - val_loss: 0.4050 - val_acc: 0.2444\n",
      "Epoch 6804/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3482 - acc: 0.2087 - val_loss: 0.4438 - val_acc: 0.2444\n",
      "Epoch 6805/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3508 - acc: 0.2092 - val_loss: 0.4164 - val_acc: 0.2444\n",
      "Epoch 6806/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3258 - acc: 0.2096 - val_loss: 0.3928 - val_acc: 0.2444\n",
      "Epoch 6807/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3412 - acc: 0.2083 - val_loss: 0.4117 - val_acc: 0.2444\n",
      "Epoch 6808/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3311 - acc: 0.2087 - val_loss: 0.4151 - val_acc: 0.2444\n",
      "Epoch 6809/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3535 - acc: 0.2087 - val_loss: 0.4260 - val_acc: 0.2444\n",
      "Epoch 6810/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3397 - acc: 0.2087 - val_loss: 0.4064 - val_acc: 0.2444\n",
      "Epoch 6811/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3617 - acc: 0.2096 - val_loss: 0.3998 - val_acc: 0.2444\n",
      "Epoch 6812/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3293 - acc: 0.2087 - val_loss: 0.4080 - val_acc: 0.2444\n",
      "Epoch 6813/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3334 - acc: 0.2092 - val_loss: 0.4190 - val_acc: 0.2444\n",
      "Epoch 6814/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3534 - acc: 0.2087 - val_loss: 0.4016 - val_acc: 0.2444\n",
      "Epoch 6815/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3275 - acc: 0.2087 - val_loss: 0.4057 - val_acc: 0.2444\n",
      "Epoch 6816/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3286 - acc: 0.2087 - val_loss: 0.3996 - val_acc: 0.2444\n",
      "Epoch 6817/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3298 - acc: 0.2083 - val_loss: 0.4001 - val_acc: 0.2444\n",
      "Epoch 6818/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3661 - acc: 0.2092 - val_loss: 0.4436 - val_acc: 0.2444\n",
      "Epoch 6819/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3405 - acc: 0.2096 - val_loss: 0.3996 - val_acc: 0.2444\n",
      "Epoch 6820/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3419 - acc: 0.2087 - val_loss: 0.4855 - val_acc: 0.2444\n",
      "Epoch 6821/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3487 - acc: 0.2096 - val_loss: 0.5050 - val_acc: 0.2407\n",
      "Epoch 6822/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3344 - acc: 0.2096 - val_loss: 0.4465 - val_acc: 0.2444\n",
      "Epoch 6823/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3405 - acc: 0.2087 - val_loss: 0.3927 - val_acc: 0.2444\n",
      "Epoch 6824/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3330 - acc: 0.2087 - val_loss: 0.4482 - val_acc: 0.2444\n",
      "Epoch 6825/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3422 - acc: 0.2096 - val_loss: 0.4060 - val_acc: 0.2444\n",
      "Epoch 6826/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3346 - acc: 0.2092 - val_loss: 0.4039 - val_acc: 0.2444\n",
      "Epoch 6827/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3332 - acc: 0.2100 - val_loss: 0.4400 - val_acc: 0.2444\n",
      "Epoch 6828/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3584 - acc: 0.2087 - val_loss: 0.3896 - val_acc: 0.2444\n",
      "Epoch 6829/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3430 - acc: 0.2087 - val_loss: 0.4127 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6830/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3261 - acc: 0.2083 - val_loss: 0.4043 - val_acc: 0.2444\n",
      "Epoch 6831/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3371 - acc: 0.2092 - val_loss: 0.5699 - val_acc: 0.2444\n",
      "Epoch 6832/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3429 - acc: 0.2087 - val_loss: 0.3879 - val_acc: 0.2444\n",
      "Epoch 6833/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3505 - acc: 0.2087 - val_loss: 0.4060 - val_acc: 0.2444\n",
      "Epoch 6834/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3309 - acc: 0.2087 - val_loss: 0.4243 - val_acc: 0.2444\n",
      "Epoch 6835/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3578 - acc: 0.2083 - val_loss: 0.4340 - val_acc: 0.2444\n",
      "Epoch 6836/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3401 - acc: 0.2087 - val_loss: 0.4251 - val_acc: 0.2444\n",
      "Epoch 6837/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3459 - acc: 0.2087 - val_loss: 0.4036 - val_acc: 0.2444\n",
      "Epoch 6838/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3438 - acc: 0.2096 - val_loss: 0.4005 - val_acc: 0.2444\n",
      "Epoch 6839/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3412 - acc: 0.2083 - val_loss: 0.4326 - val_acc: 0.2444\n",
      "Epoch 6840/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3574 - acc: 0.2092 - val_loss: 0.4024 - val_acc: 0.2444\n",
      "Epoch 6841/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3408 - acc: 0.2092 - val_loss: 0.4373 - val_acc: 0.2444\n",
      "Epoch 6842/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3488 - acc: 0.2083 - val_loss: 0.4240 - val_acc: 0.2444\n",
      "Epoch 6843/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3553 - acc: 0.2092 - val_loss: 0.4051 - val_acc: 0.2444\n",
      "Epoch 6844/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3305 - acc: 0.2083 - val_loss: 0.3916 - val_acc: 0.2444\n",
      "Epoch 6845/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3358 - acc: 0.2092 - val_loss: 0.4253 - val_acc: 0.2444\n",
      "Epoch 6846/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3349 - acc: 0.2092 - val_loss: 0.4405 - val_acc: 0.2444\n",
      "Epoch 6847/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3672 - acc: 0.2079 - val_loss: 0.4062 - val_acc: 0.2444\n",
      "Epoch 6848/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3234 - acc: 0.2087 - val_loss: 0.4014 - val_acc: 0.2444\n",
      "Epoch 6849/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3399 - acc: 0.2092 - val_loss: 0.4378 - val_acc: 0.2444\n",
      "Epoch 6850/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3294 - acc: 0.2087 - val_loss: 0.3968 - val_acc: 0.2444\n",
      "Epoch 6851/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3239 - acc: 0.2087 - val_loss: 0.3868 - val_acc: 0.2444\n",
      "Epoch 6852/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3369 - acc: 0.2087 - val_loss: 0.4113 - val_acc: 0.2444\n",
      "Epoch 6853/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3295 - acc: 0.2087 - val_loss: 0.3914 - val_acc: 0.2444\n",
      "Epoch 6854/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3294 - acc: 0.2087 - val_loss: 0.3941 - val_acc: 0.2444\n",
      "Epoch 6855/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3590 - acc: 0.2087 - val_loss: 0.4115 - val_acc: 0.2444\n",
      "Epoch 6856/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3716 - acc: 0.2087 - val_loss: 0.4169 - val_acc: 0.2444\n",
      "Epoch 6857/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3349 - acc: 0.2087 - val_loss: 0.3950 - val_acc: 0.2444\n",
      "Epoch 6858/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3506 - acc: 0.2096 - val_loss: 0.3875 - val_acc: 0.2444\n",
      "Epoch 6859/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3428 - acc: 0.2087 - val_loss: 0.4765 - val_acc: 0.2444\n",
      "Epoch 6860/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3465 - acc: 0.2087 - val_loss: 0.4149 - val_acc: 0.2444\n",
      "Epoch 6861/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3561 - acc: 0.2083 - val_loss: 0.3905 - val_acc: 0.2444\n",
      "Epoch 6862/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3381 - acc: 0.2087 - val_loss: 0.4753 - val_acc: 0.2444\n",
      "Epoch 6863/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3343 - acc: 0.2092 - val_loss: 0.4027 - val_acc: 0.2444\n",
      "Epoch 6864/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3327 - acc: 0.2092 - val_loss: 0.4339 - val_acc: 0.2444\n",
      "Epoch 6865/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3460 - acc: 0.2092 - val_loss: 0.3958 - val_acc: 0.2444\n",
      "Epoch 6866/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3418 - acc: 0.2092 - val_loss: 0.3951 - val_acc: 0.2444\n",
      "Epoch 6867/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3397 - acc: 0.2087 - val_loss: 0.4095 - val_acc: 0.2444\n",
      "Epoch 6868/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3402 - acc: 0.2087 - val_loss: 0.3900 - val_acc: 0.2444\n",
      "Epoch 6869/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3274 - acc: 0.2087 - val_loss: 0.4014 - val_acc: 0.2444\n",
      "Epoch 6870/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3292 - acc: 0.2096 - val_loss: 0.4083 - val_acc: 0.2444\n",
      "Epoch 6871/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3315 - acc: 0.2096 - val_loss: 0.3905 - val_acc: 0.2444\n",
      "Epoch 6872/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3520 - acc: 0.2087 - val_loss: 0.4715 - val_acc: 0.2444\n",
      "Epoch 6873/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3415 - acc: 0.2092 - val_loss: 0.4109 - val_acc: 0.2444\n",
      "Epoch 6874/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3249 - acc: 0.2096 - val_loss: 0.4123 - val_acc: 0.2444\n",
      "Epoch 6875/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3648 - acc: 0.2087 - val_loss: 0.4191 - val_acc: 0.2444\n",
      "Epoch 6876/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3327 - acc: 0.2092 - val_loss: 0.4026 - val_acc: 0.2444\n",
      "Epoch 6877/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3484 - acc: 0.2083 - val_loss: 0.4135 - val_acc: 0.2444\n",
      "Epoch 6878/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3435 - acc: 0.2087 - val_loss: 0.3916 - val_acc: 0.2444\n",
      "Epoch 6879/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3317 - acc: 0.2083 - val_loss: 0.4118 - val_acc: 0.2444\n",
      "Epoch 6880/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3553 - acc: 0.2092 - val_loss: 0.4291 - val_acc: 0.2444\n",
      "Epoch 6881/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3444 - acc: 0.2083 - val_loss: 0.3960 - val_acc: 0.2444\n",
      "Epoch 6882/10000\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.3448 - acc: 0.207 - 3s 33ms/step - loss: 0.3442 - acc: 0.2096 - val_loss: 0.4309 - val_acc: 0.2444\n",
      "Epoch 6883/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3307 - acc: 0.2083 - val_loss: 0.4326 - val_acc: 0.2444\n",
      "Epoch 6884/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3420 - acc: 0.2087 - val_loss: 0.4015 - val_acc: 0.2444\n",
      "Epoch 6885/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3453 - acc: 0.2083 - val_loss: 0.4033 - val_acc: 0.2444\n",
      "Epoch 6886/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3290 - acc: 0.2087 - val_loss: 0.4295 - val_acc: 0.2444\n",
      "Epoch 6887/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3352 - acc: 0.2092 - val_loss: 0.4378 - val_acc: 0.2444\n",
      "Epoch 6888/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3408 - acc: 0.2092 - val_loss: 0.4074 - val_acc: 0.2444\n",
      "Epoch 6889/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3423 - acc: 0.2092 - val_loss: 0.4180 - val_acc: 0.2444\n",
      "Epoch 6890/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3617 - acc: 0.2083 - val_loss: 0.4137 - val_acc: 0.2444\n",
      "Epoch 6891/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3391 - acc: 0.2092 - val_loss: 0.4079 - val_acc: 0.2444\n",
      "Epoch 6892/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3232 - acc: 0.2087 - val_loss: 0.4238 - val_acc: 0.2444\n",
      "Epoch 6893/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3560 - acc: 0.2087 - val_loss: 0.4115 - val_acc: 0.2444\n",
      "Epoch 6894/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3389 - acc: 0.2096 - val_loss: 0.4295 - val_acc: 0.2444\n",
      "Epoch 6895/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3355 - acc: 0.2079 - val_loss: 0.5039 - val_acc: 0.2407\n",
      "Epoch 6896/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3713 - acc: 0.2087 - val_loss: 0.4239 - val_acc: 0.2444\n",
      "Epoch 6897/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3365 - acc: 0.2092 - val_loss: 0.5024 - val_acc: 0.2407\n",
      "Epoch 6898/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3531 - acc: 0.2087 - val_loss: 0.3974 - val_acc: 0.2444\n",
      "Epoch 6899/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3318 - acc: 0.2096 - val_loss: 0.4016 - val_acc: 0.2444\n",
      "Epoch 6900/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3565 - acc: 0.2087 - val_loss: 0.4472 - val_acc: 0.2444\n",
      "Epoch 6901/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3463 - acc: 0.2083 - val_loss: 0.4427 - val_acc: 0.2444\n",
      "Epoch 6902/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3521 - acc: 0.2092 - val_loss: 0.4077 - val_acc: 0.2444\n",
      "Epoch 6903/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3570 - acc: 0.2092 - val_loss: 0.4122 - val_acc: 0.2444\n",
      "Epoch 6904/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3312 - acc: 0.2096 - val_loss: 0.5237 - val_acc: 0.2444\n",
      "Epoch 6905/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3396 - acc: 0.2083 - val_loss: 0.3963 - val_acc: 0.2444\n",
      "Epoch 6906/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3487 - acc: 0.2092 - val_loss: 0.4227 - val_acc: 0.2444\n",
      "Epoch 6907/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3274 - acc: 0.2092 - val_loss: 0.3985 - val_acc: 0.2444\n",
      "Epoch 6908/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3229 - acc: 0.2083 - val_loss: 0.3942 - val_acc: 0.2444\n",
      "Epoch 6909/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3367 - acc: 0.2087 - val_loss: 0.4136 - val_acc: 0.2444\n",
      "Epoch 6910/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3372 - acc: 0.2092 - val_loss: 0.3955 - val_acc: 0.2444\n",
      "Epoch 6911/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3359 - acc: 0.2087 - val_loss: 0.4523 - val_acc: 0.2407\n",
      "Epoch 6912/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3474 - acc: 0.2087 - val_loss: 0.4109 - val_acc: 0.2444\n",
      "Epoch 6913/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3220 - acc: 0.2092 - val_loss: 0.5760 - val_acc: 0.2407\n",
      "Epoch 6914/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3406 - acc: 0.2092 - val_loss: 0.4697 - val_acc: 0.2444\n",
      "Epoch 6915/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3322 - acc: 0.2092 - val_loss: 0.4221 - val_acc: 0.2444\n",
      "Epoch 6916/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3495 - acc: 0.2092 - val_loss: 0.4275 - val_acc: 0.2444\n",
      "Epoch 6917/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3455 - acc: 0.2092 - val_loss: 0.4149 - val_acc: 0.2444\n",
      "Epoch 6918/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3749 - acc: 0.2092 - val_loss: 0.3933 - val_acc: 0.2444\n",
      "Epoch 6919/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3467 - acc: 0.2087 - val_loss: 0.4142 - val_acc: 0.2444\n",
      "Epoch 6920/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3366 - acc: 0.2087 - val_loss: 0.4122 - val_acc: 0.2444\n",
      "Epoch 6921/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3384 - acc: 0.2096 - val_loss: 0.4479 - val_acc: 0.2407\n",
      "Epoch 6922/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3590 - acc: 0.2092 - val_loss: 0.4224 - val_acc: 0.2444\n",
      "Epoch 6923/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3457 - acc: 0.2092 - val_loss: 0.4319 - val_acc: 0.2444\n",
      "Epoch 6924/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3430 - acc: 0.2096 - val_loss: 0.4104 - val_acc: 0.2444\n",
      "Epoch 6925/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3371 - acc: 0.2092 - val_loss: 0.4123 - val_acc: 0.2444\n",
      "Epoch 6926/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3426 - acc: 0.2083 - val_loss: 0.4165 - val_acc: 0.2444\n",
      "Epoch 6927/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3353 - acc: 0.2096 - val_loss: 0.4009 - val_acc: 0.2444\n",
      "Epoch 6928/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3408 - acc: 0.2092 - val_loss: 0.4220 - val_acc: 0.2444\n",
      "Epoch 6929/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3322 - acc: 0.2087 - val_loss: 0.4533 - val_acc: 0.2444\n",
      "Epoch 6930/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3301 - acc: 0.2096 - val_loss: 0.4745 - val_acc: 0.2444\n",
      "Epoch 6931/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3373 - acc: 0.2092 - val_loss: 0.4701 - val_acc: 0.2407\n",
      "Epoch 6932/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3280 - acc: 0.2092 - val_loss: 0.4427 - val_acc: 0.2444\n",
      "Epoch 6933/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3319 - acc: 0.2092 - val_loss: 0.3997 - val_acc: 0.2444\n",
      "Epoch 6934/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3301 - acc: 0.2092 - val_loss: 0.4276 - val_acc: 0.2444\n",
      "Epoch 6935/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3561 - acc: 0.2096 - val_loss: 0.5699 - val_acc: 0.2407\n",
      "Epoch 6936/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3446 - acc: 0.2092 - val_loss: 0.3958 - val_acc: 0.2444\n",
      "Epoch 6937/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3652 - acc: 0.2092 - val_loss: 0.5430 - val_acc: 0.2444\n",
      "Epoch 6938/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3464 - acc: 0.2092 - val_loss: 0.4025 - val_acc: 0.2444\n",
      "Epoch 6939/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3329 - acc: 0.2092 - val_loss: 0.4144 - val_acc: 0.2444\n",
      "Epoch 6940/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3182 - acc: 0.2087 - val_loss: 0.4453 - val_acc: 0.2444\n",
      "Epoch 6941/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3387 - acc: 0.2096 - val_loss: 0.4212 - val_acc: 0.2444\n",
      "Epoch 6942/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3429 - acc: 0.2092 - val_loss: 0.3966 - val_acc: 0.2444\n",
      "Epoch 6943/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3703 - acc: 0.2096 - val_loss: 0.4278 - val_acc: 0.2444\n",
      "Epoch 6944/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3465 - acc: 0.2087 - val_loss: 0.4058 - val_acc: 0.2444\n",
      "Epoch 6945/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3261 - acc: 0.2083 - val_loss: 0.4043 - val_acc: 0.2444\n",
      "Epoch 6946/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3502 - acc: 0.2100 - val_loss: 0.3859 - val_acc: 0.2444\n",
      "Epoch 6947/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3351 - acc: 0.2087 - val_loss: 0.4228 - val_acc: 0.2444\n",
      "Epoch 6948/10000\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.3450 - acc: 0.210 - 2s 33ms/step - loss: 0.3436 - acc: 0.2092 - val_loss: 0.3860 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6949/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3362 - acc: 0.2096 - val_loss: 0.4033 - val_acc: 0.2444\n",
      "Epoch 6950/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3353 - acc: 0.2092 - val_loss: 0.5368 - val_acc: 0.2444\n",
      "Epoch 6951/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3488 - acc: 0.2092 - val_loss: 0.4949 - val_acc: 0.2407\n",
      "Epoch 6952/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3408 - acc: 0.2083 - val_loss: 0.4662 - val_acc: 0.2407\n",
      "Epoch 6953/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.3665 - acc: 0.2092 - val_loss: 0.4127 - val_acc: 0.2444\n",
      "Epoch 6954/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.3372 - acc: 0.2096 - val_loss: 0.5533 - val_acc: 0.2444\n",
      "Epoch 6955/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3570 - acc: 0.2087 - val_loss: 0.4564 - val_acc: 0.2407\n",
      "Epoch 6956/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3354 - acc: 0.2092 - val_loss: 0.4022 - val_acc: 0.2444\n",
      "Epoch 6957/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3338 - acc: 0.2096 - val_loss: 0.4353 - val_acc: 0.2444\n",
      "Epoch 6958/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3528 - acc: 0.2100 - val_loss: 0.4235 - val_acc: 0.2444\n",
      "Epoch 6959/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3507 - acc: 0.2092 - val_loss: 0.5112 - val_acc: 0.2444\n",
      "Epoch 6960/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3279 - acc: 0.2096 - val_loss: 0.4082 - val_acc: 0.2444\n",
      "Epoch 6961/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3392 - acc: 0.2092 - val_loss: 0.4853 - val_acc: 0.2444\n",
      "Epoch 6962/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3518 - acc: 0.2092 - val_loss: 0.4326 - val_acc: 0.2444\n",
      "Epoch 6963/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3487 - acc: 0.2083 - val_loss: 0.3983 - val_acc: 0.2444\n",
      "Epoch 6964/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3270 - acc: 0.2100 - val_loss: 0.4123 - val_acc: 0.2444\n",
      "Epoch 6965/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3294 - acc: 0.2087 - val_loss: 0.3937 - val_acc: 0.2444\n",
      "Epoch 6966/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3560 - acc: 0.2083 - val_loss: 0.4794 - val_acc: 0.2444\n",
      "Epoch 6967/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3388 - acc: 0.2096 - val_loss: 0.4004 - val_acc: 0.2444\n",
      "Epoch 6968/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3334 - acc: 0.2092 - val_loss: 0.4026 - val_acc: 0.2444\n",
      "Epoch 6969/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3433 - acc: 0.2087 - val_loss: 0.4352 - val_acc: 0.2444\n",
      "Epoch 6970/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3568 - acc: 0.2092 - val_loss: 0.4684 - val_acc: 0.2407\n",
      "Epoch 6971/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3290 - acc: 0.2092 - val_loss: 0.4925 - val_acc: 0.2444\n",
      "Epoch 6972/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3337 - acc: 0.2087 - val_loss: 0.4063 - val_acc: 0.2444\n",
      "Epoch 6973/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3494 - acc: 0.2087 - val_loss: 0.4535 - val_acc: 0.2444\n",
      "Epoch 6974/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3381 - acc: 0.2087 - val_loss: 0.4238 - val_acc: 0.2444\n",
      "Epoch 6975/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3558 - acc: 0.2092 - val_loss: 0.4200 - val_acc: 0.2444\n",
      "Epoch 6976/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3307 - acc: 0.2092 - val_loss: 0.4213 - val_acc: 0.2444\n",
      "Epoch 6977/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3319 - acc: 0.2087 - val_loss: 0.4123 - val_acc: 0.2444\n",
      "Epoch 6978/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3471 - acc: 0.2087 - val_loss: 0.4108 - val_acc: 0.2444\n",
      "Epoch 6979/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3309 - acc: 0.2087 - val_loss: 0.4198 - val_acc: 0.2444\n",
      "Epoch 6980/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3358 - acc: 0.2087 - val_loss: 0.4178 - val_acc: 0.2444\n",
      "Epoch 6981/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3353 - acc: 0.2083 - val_loss: 0.4088 - val_acc: 0.2444\n",
      "Epoch 6982/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3419 - acc: 0.2096 - val_loss: 0.4226 - val_acc: 0.2444\n",
      "Epoch 6983/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3357 - acc: 0.2096 - val_loss: 0.3936 - val_acc: 0.2444\n",
      "Epoch 6984/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3329 - acc: 0.2092 - val_loss: 0.4872 - val_acc: 0.2407\n",
      "Epoch 6985/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3669 - acc: 0.2087 - val_loss: 0.3958 - val_acc: 0.2444\n",
      "Epoch 6986/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3355 - acc: 0.2092 - val_loss: 0.3857 - val_acc: 0.2444\n",
      "Epoch 6987/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3371 - acc: 0.2092 - val_loss: 0.4667 - val_acc: 0.2444\n",
      "Epoch 6988/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3329 - acc: 0.2083 - val_loss: 0.4662 - val_acc: 0.2444\n",
      "Epoch 6989/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3535 - acc: 0.2087 - val_loss: 0.4261 - val_acc: 0.2444\n",
      "Epoch 6990/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3440 - acc: 0.2096 - val_loss: 0.4292 - val_acc: 0.2444\n",
      "Epoch 6991/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3251 - acc: 0.2096 - val_loss: 0.3938 - val_acc: 0.2444\n",
      "Epoch 6992/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3492 - acc: 0.2092 - val_loss: 0.3982 - val_acc: 0.2444\n",
      "Epoch 6993/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3335 - acc: 0.2096 - val_loss: 0.6015 - val_acc: 0.2444\n",
      "Epoch 6994/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3727 - acc: 0.2079 - val_loss: 0.4976 - val_acc: 0.2444\n",
      "Epoch 6995/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3397 - acc: 0.2092 - val_loss: 0.3931 - val_acc: 0.2444\n",
      "Epoch 6996/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3429 - acc: 0.2087 - val_loss: 0.4057 - val_acc: 0.2444\n",
      "Epoch 6997/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3397 - acc: 0.2092 - val_loss: 0.5290 - val_acc: 0.2407\n",
      "Epoch 6998/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3229 - acc: 0.2096 - val_loss: 0.4298 - val_acc: 0.2444\n",
      "Epoch 6999/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3332 - acc: 0.2092 - val_loss: 0.4773 - val_acc: 0.2444\n",
      "Epoch 7000/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3386 - acc: 0.2087 - val_loss: 0.4071 - val_acc: 0.2444\n",
      "Epoch 7001/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3286 - acc: 0.2092 - val_loss: 0.3892 - val_acc: 0.2444\n",
      "Epoch 7002/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3484 - acc: 0.2100 - val_loss: 0.3923 - val_acc: 0.2444\n",
      "Epoch 7003/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3323 - acc: 0.2092 - val_loss: 0.5165 - val_acc: 0.2444\n",
      "Epoch 7004/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3472 - acc: 0.2083 - val_loss: 0.4446 - val_acc: 0.2444\n",
      "Epoch 7005/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3459 - acc: 0.2096 - val_loss: 0.3959 - val_acc: 0.2444\n",
      "Epoch 7006/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3416 - acc: 0.2087 - val_loss: 0.3918 - val_acc: 0.2444\n",
      "Epoch 7007/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3434 - acc: 0.2087 - val_loss: 0.4066 - val_acc: 0.2444\n",
      "Epoch 7008/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3733 - acc: 0.2092 - val_loss: 0.3993 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7009/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3414 - acc: 0.2100 - val_loss: 0.4025 - val_acc: 0.2444\n",
      "Epoch 7010/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3270 - acc: 0.2096 - val_loss: 0.3884 - val_acc: 0.2444\n",
      "Epoch 7011/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3584 - acc: 0.2092 - val_loss: 0.7435 - val_acc: 0.2444\n",
      "Epoch 7012/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3481 - acc: 0.2092 - val_loss: 0.4333 - val_acc: 0.2444\n",
      "Epoch 7013/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3303 - acc: 0.2092 - val_loss: 0.4751 - val_acc: 0.2444\n",
      "Epoch 7014/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3317 - acc: 0.2096 - val_loss: 0.3875 - val_acc: 0.2444\n",
      "Epoch 7015/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3348 - acc: 0.2087 - val_loss: 0.5629 - val_acc: 0.2444\n",
      "Epoch 7016/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3432 - acc: 0.2096 - val_loss: 0.4868 - val_acc: 0.2444\n",
      "Epoch 7017/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3348 - acc: 0.2096 - val_loss: 0.4512 - val_acc: 0.2444\n",
      "Epoch 7018/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3355 - acc: 0.2100 - val_loss: 0.4430 - val_acc: 0.2444\n",
      "Epoch 7019/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3378 - acc: 0.2092 - val_loss: 0.4193 - val_acc: 0.2444\n",
      "Epoch 7020/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3380 - acc: 0.2092 - val_loss: 0.3973 - val_acc: 0.2444\n",
      "Epoch 7021/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3213 - acc: 0.2083 - val_loss: 0.4199 - val_acc: 0.2444\n",
      "Epoch 7022/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3359 - acc: 0.2087 - val_loss: 0.3949 - val_acc: 0.2444\n",
      "Epoch 7023/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3505 - acc: 0.2087 - val_loss: 0.4111 - val_acc: 0.2444\n",
      "Epoch 7024/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3393 - acc: 0.2087 - val_loss: 0.4161 - val_acc: 0.2444\n",
      "Epoch 7025/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3350 - acc: 0.2092 - val_loss: 0.4016 - val_acc: 0.2444\n",
      "Epoch 7026/10000\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.3470 - acc: 0.208 - 2s 32ms/step - loss: 0.3466 - acc: 0.2087 - val_loss: 0.5213 - val_acc: 0.2444\n",
      "Epoch 7027/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3328 - acc: 0.2092 - val_loss: 0.3976 - val_acc: 0.2444\n",
      "Epoch 7028/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3265 - acc: 0.2092 - val_loss: 0.3871 - val_acc: 0.2444\n",
      "Epoch 7029/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3354 - acc: 0.2083 - val_loss: 0.3844 - val_acc: 0.2444\n",
      "Epoch 7030/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3414 - acc: 0.2083 - val_loss: 0.4241 - val_acc: 0.2444\n",
      "Epoch 7031/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3403 - acc: 0.2087 - val_loss: 0.4207 - val_acc: 0.2444\n",
      "Epoch 7032/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3343 - acc: 0.2087 - val_loss: 0.5483 - val_acc: 0.2444\n",
      "Epoch 7033/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3548 - acc: 0.2092 - val_loss: 0.3944 - val_acc: 0.2444\n",
      "Epoch 7034/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3433 - acc: 0.2092 - val_loss: 0.4289 - val_acc: 0.2444\n",
      "Epoch 7035/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3374 - acc: 0.2083 - val_loss: 0.4287 - val_acc: 0.2444\n",
      "Epoch 7036/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3246 - acc: 0.2096 - val_loss: 0.4953 - val_acc: 0.2444\n",
      "Epoch 7037/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3417 - acc: 0.2092 - val_loss: 0.4983 - val_acc: 0.2444\n",
      "Epoch 7038/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3539 - acc: 0.2092 - val_loss: 0.4619 - val_acc: 0.2407\n",
      "Epoch 7039/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3464 - acc: 0.2096 - val_loss: 0.4310 - val_acc: 0.2444\n",
      "Epoch 7040/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3287 - acc: 0.2096 - val_loss: 0.4013 - val_acc: 0.2444\n",
      "Epoch 7041/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3282 - acc: 0.2092 - val_loss: 0.4907 - val_acc: 0.2444\n",
      "Epoch 7042/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3483 - acc: 0.2092 - val_loss: 0.3968 - val_acc: 0.2444\n",
      "Epoch 7043/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3349 - acc: 0.2100 - val_loss: 0.3946 - val_acc: 0.2444\n",
      "Epoch 7044/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3212 - acc: 0.2096 - val_loss: 0.4353 - val_acc: 0.2407\n",
      "Epoch 7045/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3744 - acc: 0.2083 - val_loss: 0.4873 - val_acc: 0.2407\n",
      "Epoch 7046/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3408 - acc: 0.2083 - val_loss: 0.4096 - val_acc: 0.2444\n",
      "Epoch 7047/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3376 - acc: 0.2100 - val_loss: 0.3930 - val_acc: 0.2444\n",
      "Epoch 7048/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3283 - acc: 0.2100 - val_loss: 0.4095 - val_acc: 0.2444\n",
      "Epoch 7049/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3427 - acc: 0.2092 - val_loss: 0.4063 - val_acc: 0.2444\n",
      "Epoch 7050/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3416 - acc: 0.2092 - val_loss: 0.5018 - val_acc: 0.2444\n",
      "Epoch 7051/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3338 - acc: 0.2083 - val_loss: 0.4066 - val_acc: 0.2444\n",
      "Epoch 7052/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3304 - acc: 0.2092 - val_loss: 0.4094 - val_acc: 0.2444\n",
      "Epoch 7053/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.3367 - acc: 0.2087 - val_loss: 0.4812 - val_acc: 0.2444\n",
      "Epoch 7054/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3300 - acc: 0.2092 - val_loss: 0.4081 - val_acc: 0.2444\n",
      "Epoch 7055/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.3447 - acc: 0.2083 - val_loss: 0.3959 - val_acc: 0.2444\n",
      "Epoch 7056/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3587 - acc: 0.2092 - val_loss: 0.4781 - val_acc: 0.2444\n",
      "Epoch 7057/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.3315 - acc: 0.2092 - val_loss: 0.3927 - val_acc: 0.2444\n",
      "Epoch 7058/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3416 - acc: 0.2096 - val_loss: 0.4109 - val_acc: 0.2444\n",
      "Epoch 7059/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3317 - acc: 0.2092 - val_loss: 0.4860 - val_acc: 0.2407\n",
      "Epoch 7060/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.3373 - acc: 0.2092 - val_loss: 0.4164 - val_acc: 0.2444\n",
      "Epoch 7061/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3284 - acc: 0.2087 - val_loss: 0.4094 - val_acc: 0.2444\n",
      "Epoch 7062/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.3370 - acc: 0.2092 - val_loss: 0.4252 - val_acc: 0.2444\n",
      "Epoch 7063/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3484 - acc: 0.2079 - val_loss: 0.4134 - val_acc: 0.2444\n",
      "Epoch 7064/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3347 - acc: 0.2092 - val_loss: 0.4375 - val_acc: 0.2444\n",
      "Epoch 7065/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3574 - acc: 0.2087 - val_loss: 0.3843 - val_acc: 0.2444\n",
      "Epoch 7066/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3431 - acc: 0.2092 - val_loss: 0.3977 - val_acc: 0.2444\n",
      "Epoch 7067/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3556 - acc: 0.2092 - val_loss: 0.5518 - val_acc: 0.2444\n",
      "Epoch 7068/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3343 - acc: 0.2087 - val_loss: 0.4014 - val_acc: 0.2444\n",
      "Epoch 7069/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3456 - acc: 0.2096 - val_loss: 0.4023 - val_acc: 0.2444\n",
      "Epoch 7070/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3283 - acc: 0.2092 - val_loss: 0.4058 - val_acc: 0.2444\n",
      "Epoch 7071/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3485 - acc: 0.2096 - val_loss: 0.4410 - val_acc: 0.2444\n",
      "Epoch 7072/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3287 - acc: 0.2087 - val_loss: 0.4035 - val_acc: 0.2444\n",
      "Epoch 7073/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3356 - acc: 0.2092 - val_loss: 0.4074 - val_acc: 0.2444\n",
      "Epoch 7074/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3379 - acc: 0.2092 - val_loss: 0.4332 - val_acc: 0.2407\n",
      "Epoch 7075/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3346 - acc: 0.2096 - val_loss: 0.3885 - val_acc: 0.2444\n",
      "Epoch 7076/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3401 - acc: 0.2083 - val_loss: 0.4721 - val_acc: 0.2444\n",
      "Epoch 7077/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3285 - acc: 0.2087 - val_loss: 0.4106 - val_acc: 0.2444\n",
      "Epoch 7078/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3248 - acc: 0.2092 - val_loss: 0.4203 - val_acc: 0.2444\n",
      "Epoch 7079/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3518 - acc: 0.2096 - val_loss: 0.4139 - val_acc: 0.2444\n",
      "Epoch 7080/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3393 - acc: 0.2092 - val_loss: 0.3966 - val_acc: 0.2444\n",
      "Epoch 7081/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3606 - acc: 0.2087 - val_loss: 0.5506 - val_acc: 0.2444\n",
      "Epoch 7082/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3441 - acc: 0.2092 - val_loss: 0.4137 - val_acc: 0.2444\n",
      "Epoch 7083/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.3257 - acc: 0.2096 - val_loss: 0.3900 - val_acc: 0.2444\n",
      "Epoch 7084/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.3325 - acc: 0.2087 - val_loss: 0.3970 - val_acc: 0.2444\n",
      "Epoch 7085/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3280 - acc: 0.2092 - val_loss: 0.3866 - val_acc: 0.2444\n",
      "Epoch 7086/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3512 - acc: 0.2083 - val_loss: 0.5146 - val_acc: 0.2444\n",
      "Epoch 7087/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3309 - acc: 0.2092 - val_loss: 0.3888 - val_acc: 0.2444\n",
      "Epoch 7088/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3307 - acc: 0.2087 - val_loss: 0.4193 - val_acc: 0.2444\n",
      "Epoch 7089/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3408 - acc: 0.2092 - val_loss: 0.4309 - val_acc: 0.2444\n",
      "Epoch 7090/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3246 - acc: 0.2087 - val_loss: 0.3900 - val_acc: 0.2444\n",
      "Epoch 7091/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3384 - acc: 0.2079 - val_loss: 0.3960 - val_acc: 0.2444\n",
      "Epoch 7092/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3349 - acc: 0.2083 - val_loss: 0.3971 - val_acc: 0.2444\n",
      "Epoch 7093/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3416 - acc: 0.2083 - val_loss: 0.4732 - val_acc: 0.2407\n",
      "Epoch 7094/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3325 - acc: 0.2092 - val_loss: 0.4073 - val_acc: 0.2444\n",
      "Epoch 7095/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3247 - acc: 0.2096 - val_loss: 0.4098 - val_acc: 0.2444\n",
      "Epoch 7096/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3302 - acc: 0.2096 - val_loss: 0.4390 - val_acc: 0.2444\n",
      "Epoch 7097/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3533 - acc: 0.2092 - val_loss: 0.4007 - val_acc: 0.2444\n",
      "Epoch 7098/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3393 - acc: 0.2092 - val_loss: 0.3953 - val_acc: 0.2444\n",
      "Epoch 7099/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3478 - acc: 0.2087 - val_loss: 0.4158 - val_acc: 0.2444\n",
      "Epoch 7100/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3618 - acc: 0.2092 - val_loss: 0.4352 - val_acc: 0.2444\n",
      "Epoch 7101/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3500 - acc: 0.2083 - val_loss: 0.4176 - val_acc: 0.2444\n",
      "Epoch 7102/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3325 - acc: 0.2092 - val_loss: 0.4068 - val_acc: 0.2444\n",
      "Epoch 7103/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3272 - acc: 0.2087 - val_loss: 0.4568 - val_acc: 0.2407\n",
      "Epoch 7104/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3262 - acc: 0.2087 - val_loss: 0.5716 - val_acc: 0.2444\n",
      "Epoch 7105/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3343 - acc: 0.2079 - val_loss: 0.4342 - val_acc: 0.2444\n",
      "Epoch 7106/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3448 - acc: 0.2096 - val_loss: 0.3928 - val_acc: 0.2444\n",
      "Epoch 7107/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3347 - acc: 0.2096 - val_loss: 0.4730 - val_acc: 0.2444\n",
      "Epoch 7108/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3325 - acc: 0.2096 - val_loss: 0.4053 - val_acc: 0.2444\n",
      "Epoch 7109/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3574 - acc: 0.2096 - val_loss: 0.5147 - val_acc: 0.2444\n",
      "Epoch 7110/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3654 - acc: 0.2092 - val_loss: 0.4060 - val_acc: 0.2444\n",
      "Epoch 7111/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3287 - acc: 0.2087 - val_loss: 0.4070 - val_acc: 0.2444\n",
      "Epoch 7112/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3527 - acc: 0.2096 - val_loss: 0.4046 - val_acc: 0.2444\n",
      "Epoch 7113/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3546 - acc: 0.2096 - val_loss: 0.4076 - val_acc: 0.2444\n",
      "Epoch 7114/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3377 - acc: 0.2092 - val_loss: 0.4104 - val_acc: 0.2444\n",
      "Epoch 7115/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3639 - acc: 0.2092 - val_loss: 0.4080 - val_acc: 0.2444\n",
      "Epoch 7116/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3297 - acc: 0.2087 - val_loss: 0.4309 - val_acc: 0.2444\n",
      "Epoch 7117/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3590 - acc: 0.2092 - val_loss: 0.3877 - val_acc: 0.2444\n",
      "Epoch 7118/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3607 - acc: 0.2096 - val_loss: 0.4374 - val_acc: 0.2444\n",
      "Epoch 7119/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3402 - acc: 0.2092 - val_loss: 0.4345 - val_acc: 0.2444\n",
      "Epoch 7120/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3514 - acc: 0.2087 - val_loss: 0.3922 - val_acc: 0.2444\n",
      "Epoch 7121/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3325 - acc: 0.2083 - val_loss: 0.4158 - val_acc: 0.2444\n",
      "Epoch 7122/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3374 - acc: 0.2092 - val_loss: 0.5355 - val_acc: 0.2444\n",
      "Epoch 7123/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3389 - acc: 0.2096 - val_loss: 0.4163 - val_acc: 0.2444\n",
      "Epoch 7124/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3423 - acc: 0.2096 - val_loss: 0.4174 - val_acc: 0.2444\n",
      "Epoch 7125/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3456 - acc: 0.2087 - val_loss: 0.4388 - val_acc: 0.2444\n",
      "Epoch 7126/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3264 - acc: 0.2083 - val_loss: 0.4034 - val_acc: 0.2444\n",
      "Epoch 7127/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3285 - acc: 0.2096 - val_loss: 0.4249 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7128/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3331 - acc: 0.2083 - val_loss: 0.4298 - val_acc: 0.2444\n",
      "Epoch 7129/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3442 - acc: 0.2083 - val_loss: 0.4425 - val_acc: 0.2444\n",
      "Epoch 7130/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3343 - acc: 0.2087 - val_loss: 0.4060 - val_acc: 0.2444\n",
      "Epoch 7131/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3469 - acc: 0.2096 - val_loss: 0.4024 - val_acc: 0.2444\n",
      "Epoch 7132/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3363 - acc: 0.2092 - val_loss: 0.3926 - val_acc: 0.2444\n",
      "Epoch 7133/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3359 - acc: 0.2096 - val_loss: 0.4110 - val_acc: 0.2444\n",
      "Epoch 7134/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3374 - acc: 0.2092 - val_loss: 0.3999 - val_acc: 0.2444\n",
      "Epoch 7135/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3308 - acc: 0.2087 - val_loss: 0.3961 - val_acc: 0.2444\n",
      "Epoch 7136/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3307 - acc: 0.2087 - val_loss: 0.5924 - val_acc: 0.2444\n",
      "Epoch 7137/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3455 - acc: 0.2092 - val_loss: 0.3823 - val_acc: 0.2444\n",
      "Epoch 7138/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3358 - acc: 0.2096 - val_loss: 0.4103 - val_acc: 0.2444\n",
      "Epoch 7139/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3202 - acc: 0.2092 - val_loss: 0.4082 - val_acc: 0.2444\n",
      "Epoch 7140/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3557 - acc: 0.2083 - val_loss: 0.3921 - val_acc: 0.2444\n",
      "Epoch 7141/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3539 - acc: 0.2087 - val_loss: 0.3915 - val_acc: 0.2444\n",
      "Epoch 7142/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3326 - acc: 0.2096 - val_loss: 0.3867 - val_acc: 0.2444\n",
      "Epoch 7143/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3281 - acc: 0.2092 - val_loss: 0.4153 - val_acc: 0.2444\n",
      "Epoch 7144/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3489 - acc: 0.2083 - val_loss: 0.4080 - val_acc: 0.2444\n",
      "Epoch 7145/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3292 - acc: 0.2087 - val_loss: 0.4411 - val_acc: 0.2444\n",
      "Epoch 7146/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3279 - acc: 0.2096 - val_loss: 0.4442 - val_acc: 0.2407\n",
      "Epoch 7147/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3310 - acc: 0.2096 - val_loss: 0.4028 - val_acc: 0.2444\n",
      "Epoch 7148/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3213 - acc: 0.2092 - val_loss: 0.4120 - val_acc: 0.2444\n",
      "Epoch 7149/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3404 - acc: 0.2087 - val_loss: 0.4335 - val_acc: 0.2444\n",
      "Epoch 7150/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3624 - acc: 0.2087 - val_loss: 0.4009 - val_acc: 0.2444\n",
      "Epoch 7151/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3322 - acc: 0.2083 - val_loss: 0.4240 - val_acc: 0.2444\n",
      "Epoch 7152/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3384 - acc: 0.2092 - val_loss: 0.4178 - val_acc: 0.2444\n",
      "Epoch 7153/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3277 - acc: 0.2096 - val_loss: 0.4251 - val_acc: 0.2444\n",
      "Epoch 7154/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3296 - acc: 0.2096 - val_loss: 0.3961 - val_acc: 0.2444\n",
      "Epoch 7155/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3322 - acc: 0.2092 - val_loss: 0.4144 - val_acc: 0.2444\n",
      "Epoch 7156/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3883 - acc: 0.2087 - val_loss: 0.4057 - val_acc: 0.2444\n",
      "Epoch 7157/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3313 - acc: 0.2087 - val_loss: 0.3967 - val_acc: 0.2444\n",
      "Epoch 7158/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3314 - acc: 0.2096 - val_loss: 0.4265 - val_acc: 0.2444\n",
      "Epoch 7159/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3304 - acc: 0.2092 - val_loss: 0.4174 - val_acc: 0.2444\n",
      "Epoch 7160/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3374 - acc: 0.2096 - val_loss: 0.4293 - val_acc: 0.2444\n",
      "Epoch 7161/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3342 - acc: 0.2096 - val_loss: 0.4200 - val_acc: 0.2444\n",
      "Epoch 7162/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3305 - acc: 0.2100 - val_loss: 0.3940 - val_acc: 0.2444\n",
      "Epoch 7163/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3460 - acc: 0.2096 - val_loss: 0.4312 - val_acc: 0.2444\n",
      "Epoch 7164/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3450 - acc: 0.2100 - val_loss: 0.4820 - val_acc: 0.2407\n",
      "Epoch 7165/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3627 - acc: 0.2096 - val_loss: 0.4841 - val_acc: 0.2444\n",
      "Epoch 7166/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3318 - acc: 0.2092 - val_loss: 0.3947 - val_acc: 0.2444\n",
      "Epoch 7167/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3288 - acc: 0.2092 - val_loss: 0.4247 - val_acc: 0.2444\n",
      "Epoch 7168/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3378 - acc: 0.2092 - val_loss: 0.3981 - val_acc: 0.2444\n",
      "Epoch 7169/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3356 - acc: 0.2087 - val_loss: 0.4514 - val_acc: 0.2407\n",
      "Epoch 7170/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3352 - acc: 0.2092 - val_loss: 0.3989 - val_acc: 0.2444\n",
      "Epoch 7171/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3361 - acc: 0.2092 - val_loss: 0.4047 - val_acc: 0.2444\n",
      "Epoch 7172/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3702 - acc: 0.2083 - val_loss: 0.3926 - val_acc: 0.2444\n",
      "Epoch 7173/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3436 - acc: 0.2087 - val_loss: 0.4494 - val_acc: 0.2444\n",
      "Epoch 7174/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3382 - acc: 0.2092 - val_loss: 0.4005 - val_acc: 0.2444\n",
      "Epoch 7175/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3290 - acc: 0.2087 - val_loss: 0.5143 - val_acc: 0.2407\n",
      "Epoch 7176/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3479 - acc: 0.2100 - val_loss: 0.3894 - val_acc: 0.2444\n",
      "Epoch 7177/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3319 - acc: 0.2092 - val_loss: 0.4644 - val_acc: 0.2444\n",
      "Epoch 7178/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3335 - acc: 0.2092 - val_loss: 0.4243 - val_acc: 0.2444\n",
      "Epoch 7179/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3283 - acc: 0.2083 - val_loss: 0.5184 - val_acc: 0.2444\n",
      "Epoch 7180/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3306 - acc: 0.2087 - val_loss: 0.4308 - val_acc: 0.2444\n",
      "Epoch 7181/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3243 - acc: 0.2092 - val_loss: 0.4132 - val_acc: 0.2444\n",
      "Epoch 7182/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3383 - acc: 0.2087 - val_loss: 0.4028 - val_acc: 0.2444\n",
      "Epoch 7183/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3345 - acc: 0.2096 - val_loss: 0.4004 - val_acc: 0.2444\n",
      "Epoch 7184/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3365 - acc: 0.2087 - val_loss: 0.4286 - val_acc: 0.2407\n",
      "Epoch 7185/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3480 - acc: 0.2083 - val_loss: 0.4065 - val_acc: 0.2444\n",
      "Epoch 7186/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3340 - acc: 0.2096 - val_loss: 0.4790 - val_acc: 0.2444\n",
      "Epoch 7187/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.3524 - acc: 0.2092 - val_loss: 0.4099 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7188/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3480 - acc: 0.2100 - val_loss: 0.4789 - val_acc: 0.2444\n",
      "Epoch 7189/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3468 - acc: 0.2092 - val_loss: 0.4964 - val_acc: 0.2444\n",
      "Epoch 7190/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3329 - acc: 0.2096 - val_loss: 0.5112 - val_acc: 0.2444\n",
      "Epoch 7191/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3436 - acc: 0.2092 - val_loss: 0.3918 - val_acc: 0.2444\n",
      "Epoch 7192/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3490 - acc: 0.2083 - val_loss: 0.4076 - val_acc: 0.2444\n",
      "Epoch 7193/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3357 - acc: 0.2087 - val_loss: 0.4062 - val_acc: 0.2444\n",
      "Epoch 7194/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3622 - acc: 0.2083 - val_loss: 0.4042 - val_acc: 0.2444\n",
      "Epoch 7195/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3265 - acc: 0.2092 - val_loss: 0.3882 - val_acc: 0.2444\n",
      "Epoch 7196/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3537 - acc: 0.2096 - val_loss: 0.4026 - val_acc: 0.2444\n",
      "Epoch 7197/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3294 - acc: 0.2087 - val_loss: 0.4116 - val_acc: 0.2444\n",
      "Epoch 7198/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3407 - acc: 0.2092 - val_loss: 0.4405 - val_acc: 0.2407\n",
      "Epoch 7199/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3359 - acc: 0.2092 - val_loss: 0.5164 - val_acc: 0.2407\n",
      "Epoch 7200/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3378 - acc: 0.2092 - val_loss: 0.4076 - val_acc: 0.2444\n",
      "Epoch 7201/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3301 - acc: 0.2092 - val_loss: 0.4625 - val_acc: 0.2444\n",
      "Epoch 7202/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3494 - acc: 0.2087 - val_loss: 0.4414 - val_acc: 0.2407\n",
      "Epoch 7203/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3246 - acc: 0.2087 - val_loss: 0.4795 - val_acc: 0.2444\n",
      "Epoch 7204/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3501 - acc: 0.2087 - val_loss: 0.4080 - val_acc: 0.2444\n",
      "Epoch 7205/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3309 - acc: 0.2096 - val_loss: 0.4720 - val_acc: 0.2444\n",
      "Epoch 7206/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3338 - acc: 0.2087 - val_loss: 0.4488 - val_acc: 0.2407\n",
      "Epoch 7207/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3441 - acc: 0.2096 - val_loss: 0.4211 - val_acc: 0.2444\n",
      "Epoch 7208/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3252 - acc: 0.2092 - val_loss: 0.3967 - val_acc: 0.2444\n",
      "Epoch 7209/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3604 - acc: 0.2079 - val_loss: 0.4134 - val_acc: 0.2444\n",
      "Epoch 7210/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3379 - acc: 0.2096 - val_loss: 0.4167 - val_acc: 0.2444\n",
      "Epoch 7211/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3266 - acc: 0.2096 - val_loss: 0.4056 - val_acc: 0.2444\n",
      "Epoch 7212/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3248 - acc: 0.2087 - val_loss: 0.4384 - val_acc: 0.2444\n",
      "Epoch 7213/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3272 - acc: 0.2087 - val_loss: 0.4063 - val_acc: 0.2444\n",
      "Epoch 7214/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.3632 - acc: 0.2083 - val_loss: 0.4142 - val_acc: 0.2444\n",
      "Epoch 7215/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3377 - acc: 0.2087 - val_loss: 0.4019 - val_acc: 0.2444\n",
      "Epoch 7216/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3381 - acc: 0.2087 - val_loss: 0.3959 - val_acc: 0.2444\n",
      "Epoch 7217/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3512 - acc: 0.2096 - val_loss: 0.3938 - val_acc: 0.2444\n",
      "Epoch 7218/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.3326 - acc: 0.2096 - val_loss: 0.4193 - val_acc: 0.2444\n",
      "Epoch 7219/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.3278 - acc: 0.2087 - val_loss: 0.4201 - val_acc: 0.2444\n",
      "Epoch 7220/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3401 - acc: 0.2087 - val_loss: 0.5411 - val_acc: 0.2407\n",
      "Epoch 7221/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3378 - acc: 0.2083 - val_loss: 0.4511 - val_acc: 0.2444\n",
      "Epoch 7222/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3392 - acc: 0.2083 - val_loss: 0.3908 - val_acc: 0.2444\n",
      "Epoch 7223/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3213 - acc: 0.2096 - val_loss: 0.4082 - val_acc: 0.2444\n",
      "Epoch 7224/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3344 - acc: 0.2100 - val_loss: 0.4083 - val_acc: 0.2444\n",
      "Epoch 7225/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3335 - acc: 0.2092 - val_loss: 0.4125 - val_acc: 0.2444\n",
      "Epoch 7226/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3231 - acc: 0.2092 - val_loss: 0.3949 - val_acc: 0.2444\n",
      "Epoch 7227/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3314 - acc: 0.2096 - val_loss: 0.3832 - val_acc: 0.2444\n",
      "Epoch 7228/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3276 - acc: 0.2100 - val_loss: 0.4430 - val_acc: 0.2444\n",
      "Epoch 7229/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3667 - acc: 0.2092 - val_loss: 0.4025 - val_acc: 0.2444\n",
      "Epoch 7230/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3425 - acc: 0.2087 - val_loss: 0.3917 - val_acc: 0.2444\n",
      "Epoch 7231/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3336 - acc: 0.2096 - val_loss: 0.4614 - val_acc: 0.2407\n",
      "Epoch 7232/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3363 - acc: 0.2087 - val_loss: 0.3968 - val_acc: 0.2444\n",
      "Epoch 7233/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3411 - acc: 0.2096 - val_loss: 0.4013 - val_acc: 0.2444\n",
      "Epoch 7234/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3376 - acc: 0.2087 - val_loss: 0.4332 - val_acc: 0.2407\n",
      "Epoch 7235/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3274 - acc: 0.2092 - val_loss: 0.3968 - val_acc: 0.2444\n",
      "Epoch 7236/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3250 - acc: 0.2092 - val_loss: 0.5347 - val_acc: 0.2444\n",
      "Epoch 7237/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3472 - acc: 0.2087 - val_loss: 0.4311 - val_acc: 0.2444\n",
      "Epoch 7238/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3631 - acc: 0.2096 - val_loss: 0.5577 - val_acc: 0.2444\n",
      "Epoch 7239/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3549 - acc: 0.2096 - val_loss: 0.3917 - val_acc: 0.2444\n",
      "Epoch 7240/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3460 - acc: 0.2096 - val_loss: 0.4073 - val_acc: 0.2444\n",
      "Epoch 7241/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3320 - acc: 0.2087 - val_loss: 0.4022 - val_acc: 0.2444\n",
      "Epoch 7242/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3231 - acc: 0.2092 - val_loss: 0.3941 - val_acc: 0.2444\n",
      "Epoch 7243/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3249 - acc: 0.2087 - val_loss: 0.4831 - val_acc: 0.2444\n",
      "Epoch 7244/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3530 - acc: 0.2083 - val_loss: 0.4254 - val_acc: 0.2444\n",
      "Epoch 7245/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3406 - acc: 0.2083 - val_loss: 0.4064 - val_acc: 0.2444\n",
      "Epoch 7246/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3338 - acc: 0.2087 - val_loss: 0.3947 - val_acc: 0.2444\n",
      "Epoch 7247/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3570 - acc: 0.2096 - val_loss: 0.4379 - val_acc: 0.2407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7248/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3483 - acc: 0.2087 - val_loss: 0.4010 - val_acc: 0.2444\n",
      "Epoch 7249/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3306 - acc: 0.2096 - val_loss: 0.4062 - val_acc: 0.2444\n",
      "Epoch 7250/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3215 - acc: 0.2087 - val_loss: 0.4145 - val_acc: 0.2444\n",
      "Epoch 7251/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4832 - acc: 0.2087 - val_loss: 0.5301 - val_acc: 0.2444\n",
      "Epoch 7252/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4636 - acc: 0.2096 - val_loss: 0.5088 - val_acc: 0.2444\n",
      "Epoch 7253/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3511 - acc: 0.2096 - val_loss: 0.4068 - val_acc: 0.2444\n",
      "Epoch 7254/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3409 - acc: 0.2096 - val_loss: 0.4039 - val_acc: 0.2444\n",
      "Epoch 7255/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3380 - acc: 0.2096 - val_loss: 0.4143 - val_acc: 0.2444\n",
      "Epoch 7256/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3440 - acc: 0.2087 - val_loss: 0.5597 - val_acc: 0.2444\n",
      "Epoch 7257/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3578 - acc: 0.2092 - val_loss: 0.4300 - val_acc: 0.2444\n",
      "Epoch 7258/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3442 - acc: 0.2092 - val_loss: 0.4165 - val_acc: 0.2444\n",
      "Epoch 7259/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3204 - acc: 0.2092 - val_loss: 0.4164 - val_acc: 0.2444\n",
      "Epoch 7260/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3298 - acc: 0.2083 - val_loss: 0.4808 - val_acc: 0.2407\n",
      "Epoch 7261/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3464 - acc: 0.2092 - val_loss: 0.4268 - val_acc: 0.2444\n",
      "Epoch 7262/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3213 - acc: 0.2092 - val_loss: 0.4052 - val_acc: 0.2444\n",
      "Epoch 7263/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3244 - acc: 0.2087 - val_loss: 0.4372 - val_acc: 0.2407\n",
      "Epoch 7264/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3239 - acc: 0.2096 - val_loss: 0.4921 - val_acc: 0.2444\n",
      "Epoch 7265/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3343 - acc: 0.2096 - val_loss: 0.4382 - val_acc: 0.2444\n",
      "Epoch 7266/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3233 - acc: 0.2087 - val_loss: 0.4521 - val_acc: 0.2444\n",
      "Epoch 7267/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3272 - acc: 0.2092 - val_loss: 0.5028 - val_acc: 0.2407\n",
      "Epoch 7268/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3292 - acc: 0.2083 - val_loss: 0.4058 - val_acc: 0.2444\n",
      "Epoch 7269/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3397 - acc: 0.2100 - val_loss: 0.5455 - val_acc: 0.2407\n",
      "Epoch 7270/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3497 - acc: 0.2083 - val_loss: 0.3905 - val_acc: 0.2444\n",
      "Epoch 7271/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3218 - acc: 0.2096 - val_loss: 0.4058 - val_acc: 0.2444\n",
      "Epoch 7272/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3334 - acc: 0.2092 - val_loss: 0.4098 - val_acc: 0.2444\n",
      "Epoch 7273/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3298 - acc: 0.2092 - val_loss: 0.4140 - val_acc: 0.2444\n",
      "Epoch 7274/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3438 - acc: 0.2092 - val_loss: 0.4176 - val_acc: 0.2444\n",
      "Epoch 7275/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3311 - acc: 0.2087 - val_loss: 0.4456 - val_acc: 0.2444\n",
      "Epoch 7276/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3421 - acc: 0.2079 - val_loss: 0.3927 - val_acc: 0.2444\n",
      "Epoch 7277/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3226 - acc: 0.2092 - val_loss: 0.4000 - val_acc: 0.2444\n",
      "Epoch 7278/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3333 - acc: 0.2087 - val_loss: 0.4243 - val_acc: 0.2444\n",
      "Epoch 7279/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3285 - acc: 0.2092 - val_loss: 0.4758 - val_acc: 0.2444\n",
      "Epoch 7280/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3331 - acc: 0.2087 - val_loss: 0.4114 - val_acc: 0.2444\n",
      "Epoch 7281/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3238 - acc: 0.2087 - val_loss: 0.4223 - val_acc: 0.2444\n",
      "Epoch 7282/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3315 - acc: 0.2096 - val_loss: 0.4015 - val_acc: 0.2444\n",
      "Epoch 7283/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3251 - acc: 0.2092 - val_loss: 0.4180 - val_acc: 0.2444\n",
      "Epoch 7284/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3214 - acc: 0.2096 - val_loss: 0.4164 - val_acc: 0.2444\n",
      "Epoch 7285/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3329 - acc: 0.2083 - val_loss: 0.3904 - val_acc: 0.2444\n",
      "Epoch 7286/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3300 - acc: 0.2092 - val_loss: 0.3915 - val_acc: 0.2444\n",
      "Epoch 7287/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3227 - acc: 0.2083 - val_loss: 0.3972 - val_acc: 0.2444\n",
      "Epoch 7288/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3291 - acc: 0.2092 - val_loss: 0.4133 - val_acc: 0.2444\n",
      "Epoch 7289/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3350 - acc: 0.2083 - val_loss: 0.4130 - val_acc: 0.2444\n",
      "Epoch 7290/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3497 - acc: 0.2100 - val_loss: 0.5714 - val_acc: 0.2444\n",
      "Epoch 7291/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3353 - acc: 0.2087 - val_loss: 0.4180 - val_acc: 0.2444\n",
      "Epoch 7292/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3260 - acc: 0.2096 - val_loss: 0.4296 - val_acc: 0.2444\n",
      "Epoch 7293/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3272 - acc: 0.2087 - val_loss: 0.4006 - val_acc: 0.2444\n",
      "Epoch 7294/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3471 - acc: 0.2096 - val_loss: 0.4704 - val_acc: 0.2407\n",
      "Epoch 7295/10000\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.3647 - acc: 0.208 - 2s 32ms/step - loss: 0.3644 - acc: 0.2083 - val_loss: 0.3826 - val_acc: 0.2444\n",
      "Epoch 7296/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3368 - acc: 0.2092 - val_loss: 0.3827 - val_acc: 0.2444\n",
      "Epoch 7297/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3302 - acc: 0.2087 - val_loss: 0.4127 - val_acc: 0.2444\n",
      "Epoch 7298/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3347 - acc: 0.2083 - val_loss: 0.4491 - val_acc: 0.2407\n",
      "Epoch 7299/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3299 - acc: 0.2087 - val_loss: 0.3966 - val_acc: 0.2444\n",
      "Epoch 7300/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3234 - acc: 0.2092 - val_loss: 0.4173 - val_acc: 0.2444\n",
      "Epoch 7301/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3413 - acc: 0.2092 - val_loss: 0.4008 - val_acc: 0.2444\n",
      "Epoch 7302/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3375 - acc: 0.2096 - val_loss: 0.5019 - val_acc: 0.2444\n",
      "Epoch 7303/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3289 - acc: 0.2096 - val_loss: 0.4506 - val_acc: 0.2444\n",
      "Epoch 7304/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3328 - acc: 0.2092 - val_loss: 0.4287 - val_acc: 0.2444\n",
      "Epoch 7305/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3447 - acc: 0.2096 - val_loss: 0.4141 - val_acc: 0.2444\n",
      "Epoch 7306/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.4388 - acc: 0.2087 - val_loss: 0.5519 - val_acc: 0.2444\n",
      "Epoch 7307/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3531 - acc: 0.2096 - val_loss: 0.4106 - val_acc: 0.2444\n",
      "Epoch 7308/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3311 - acc: 0.2079 - val_loss: 0.3997 - val_acc: 0.2444\n",
      "Epoch 7309/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3574 - acc: 0.2087 - val_loss: 0.5562 - val_acc: 0.2444\n",
      "Epoch 7310/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4345 - acc: 0.2096 - val_loss: 0.4958 - val_acc: 0.2407\n",
      "Epoch 7311/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4299 - acc: 0.2092 - val_loss: 0.4287 - val_acc: 0.2444\n",
      "Epoch 7312/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3368 - acc: 0.2087 - val_loss: 0.4007 - val_acc: 0.2444\n",
      "Epoch 7313/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3446 - acc: 0.2092 - val_loss: 0.3947 - val_acc: 0.2444\n",
      "Epoch 7314/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3336 - acc: 0.2092 - val_loss: 0.3915 - val_acc: 0.2444\n",
      "Epoch 7315/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3412 - acc: 0.2100 - val_loss: 0.5766 - val_acc: 0.2444\n",
      "Epoch 7316/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3295 - acc: 0.2096 - val_loss: 0.4524 - val_acc: 0.2407\n",
      "Epoch 7317/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3372 - acc: 0.2087 - val_loss: 0.4933 - val_acc: 0.2407\n",
      "Epoch 7318/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3435 - acc: 0.2092 - val_loss: 0.3902 - val_acc: 0.2444\n",
      "Epoch 7319/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3935 - acc: 0.2096 - val_loss: 0.4768 - val_acc: 0.2444\n",
      "Epoch 7320/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3553 - acc: 0.2092 - val_loss: 0.4746 - val_acc: 0.2444\n",
      "Epoch 7321/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4294 - acc: 0.2092 - val_loss: 0.6567 - val_acc: 0.2407\n",
      "Epoch 7322/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.4243 - acc: 0.2087 - val_loss: 0.4791 - val_acc: 0.2407\n",
      "Epoch 7323/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3578 - acc: 0.2096 - val_loss: 0.3921 - val_acc: 0.2444\n",
      "Epoch 7324/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3347 - acc: 0.2092 - val_loss: 0.3901 - val_acc: 0.2444\n",
      "Epoch 7325/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3402 - acc: 0.2096 - val_loss: 0.3972 - val_acc: 0.2444\n",
      "Epoch 7326/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3326 - acc: 0.2087 - val_loss: 0.3985 - val_acc: 0.2444\n",
      "Epoch 7327/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3326 - acc: 0.2100 - val_loss: 0.4113 - val_acc: 0.2444\n",
      "Epoch 7328/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3449 - acc: 0.2087 - val_loss: 0.4345 - val_acc: 0.2444\n",
      "Epoch 7329/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3602 - acc: 0.2096 - val_loss: 0.5518 - val_acc: 0.2444\n",
      "Epoch 7330/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3466 - acc: 0.2100 - val_loss: 0.4161 - val_acc: 0.2444\n",
      "Epoch 7331/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3210 - acc: 0.2096 - val_loss: 0.3936 - val_acc: 0.2444\n",
      "Epoch 7332/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3483 - acc: 0.2092 - val_loss: 0.4314 - val_acc: 0.2444\n",
      "Epoch 7333/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3382 - acc: 0.2092 - val_loss: 0.4406 - val_acc: 0.2407\n",
      "Epoch 7334/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3516 - acc: 0.2092 - val_loss: 0.4247 - val_acc: 0.2444\n",
      "Epoch 7335/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3468 - acc: 0.2092 - val_loss: 0.4310 - val_acc: 0.2444\n",
      "Epoch 7336/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3546 - acc: 0.2083 - val_loss: 0.4921 - val_acc: 0.2444\n",
      "Epoch 7337/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3384 - acc: 0.2083 - val_loss: 0.5393 - val_acc: 0.2444\n",
      "Epoch 7338/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3415 - acc: 0.2092 - val_loss: 0.4309 - val_acc: 0.2444\n",
      "Epoch 7339/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3211 - acc: 0.2092 - val_loss: 0.4080 - val_acc: 0.2444\n",
      "Epoch 7340/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3372 - acc: 0.2096 - val_loss: 0.4004 - val_acc: 0.2444\n",
      "Epoch 7341/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3360 - acc: 0.2092 - val_loss: 0.4700 - val_acc: 0.2444\n",
      "Epoch 7342/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3338 - acc: 0.2096 - val_loss: 0.3942 - val_acc: 0.2444\n",
      "Epoch 7343/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.3297 - acc: 0.2096 - val_loss: 0.4170 - val_acc: 0.2444\n",
      "Epoch 7344/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.3305 - acc: 0.2092 - val_loss: 0.4050 - val_acc: 0.2444\n",
      "Epoch 7345/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3202 - acc: 0.2096 - val_loss: 0.4273 - val_acc: 0.2407\n",
      "Epoch 7346/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3549 - acc: 0.2087 - val_loss: 0.5042 - val_acc: 0.2444\n",
      "Epoch 7347/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3393 - acc: 0.2083 - val_loss: 0.4172 - val_acc: 0.2444\n",
      "Epoch 7348/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3342 - acc: 0.2092 - val_loss: 0.3928 - val_acc: 0.2444\n",
      "Epoch 7349/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3467 - acc: 0.2096 - val_loss: 0.3876 - val_acc: 0.2444\n",
      "Epoch 7350/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3180 - acc: 0.2096 - val_loss: 0.4580 - val_acc: 0.2407\n",
      "Epoch 7351/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3426 - acc: 0.2087 - val_loss: 0.4157 - val_acc: 0.2444\n",
      "Epoch 7352/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3665 - acc: 0.2083 - val_loss: 0.4215 - val_acc: 0.2444\n",
      "Epoch 7353/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3263 - acc: 0.2087 - val_loss: 0.4015 - val_acc: 0.2444\n",
      "Epoch 7354/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3309 - acc: 0.2096 - val_loss: 0.4023 - val_acc: 0.2444\n",
      "Epoch 7355/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3190 - acc: 0.2096 - val_loss: 0.4089 - val_acc: 0.2444\n",
      "Epoch 7356/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3439 - acc: 0.2096 - val_loss: 0.4612 - val_acc: 0.2407\n",
      "Epoch 7357/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3301 - acc: 0.2087 - val_loss: 0.3980 - val_acc: 0.2444\n",
      "Epoch 7358/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3311 - acc: 0.2096 - val_loss: 0.4989 - val_acc: 0.2444\n",
      "Epoch 7359/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3314 - acc: 0.2087 - val_loss: 0.4001 - val_acc: 0.2444\n",
      "Epoch 7360/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3470 - acc: 0.2096 - val_loss: 0.3959 - val_acc: 0.2444\n",
      "Epoch 7361/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3363 - acc: 0.2087 - val_loss: 0.4198 - val_acc: 0.2444\n",
      "Epoch 7362/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3395 - acc: 0.2096 - val_loss: 0.4079 - val_acc: 0.2444\n",
      "Epoch 7363/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3266 - acc: 0.2096 - val_loss: 0.3941 - val_acc: 0.2444\n",
      "Epoch 7364/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3323 - acc: 0.2087 - val_loss: 0.4609 - val_acc: 0.2444\n",
      "Epoch 7365/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3381 - acc: 0.2092 - val_loss: 0.3974 - val_acc: 0.2444\n",
      "Epoch 7366/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3365 - acc: 0.2096 - val_loss: 0.4157 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7367/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3391 - acc: 0.2096 - val_loss: 0.3965 - val_acc: 0.2444\n",
      "Epoch 7368/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3392 - acc: 0.2087 - val_loss: 0.4589 - val_acc: 0.2444\n",
      "Epoch 7369/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3856 - acc: 0.2087 - val_loss: 0.3949 - val_acc: 0.2444\n",
      "Epoch 7370/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3377 - acc: 0.2092 - val_loss: 0.3927 - val_acc: 0.2444\n",
      "Epoch 7371/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3314 - acc: 0.2092 - val_loss: 0.4020 - val_acc: 0.2444\n",
      "Epoch 7372/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3494 - acc: 0.2092 - val_loss: 0.4401 - val_acc: 0.2444\n",
      "Epoch 7373/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3276 - acc: 0.2087 - val_loss: 0.3959 - val_acc: 0.2444\n",
      "Epoch 7374/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3299 - acc: 0.2100 - val_loss: 0.4078 - val_acc: 0.2444\n",
      "Epoch 7375/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3194 - acc: 0.2092 - val_loss: 0.4657 - val_acc: 0.2407\n",
      "Epoch 7376/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3337 - acc: 0.2092 - val_loss: 0.4555 - val_acc: 0.2407\n",
      "Epoch 7377/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3503 - acc: 0.2087 - val_loss: 0.6288 - val_acc: 0.2444\n",
      "Epoch 7378/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3533 - acc: 0.2100 - val_loss: 0.4020 - val_acc: 0.2444\n",
      "Epoch 7379/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3318 - acc: 0.2087 - val_loss: 0.4032 - val_acc: 0.2444\n",
      "Epoch 7380/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3357 - acc: 0.2100 - val_loss: 0.3850 - val_acc: 0.2444\n",
      "Epoch 7381/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3309 - acc: 0.2087 - val_loss: 0.4191 - val_acc: 0.2444\n",
      "Epoch 7382/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3244 - acc: 0.2100 - val_loss: 0.4197 - val_acc: 0.2444\n",
      "Epoch 7383/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3247 - acc: 0.2096 - val_loss: 0.4482 - val_acc: 0.2444\n",
      "Epoch 7384/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3394 - acc: 0.2096 - val_loss: 0.3926 - val_acc: 0.2444\n",
      "Epoch 7385/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3504 - acc: 0.2096 - val_loss: 0.3985 - val_acc: 0.2444\n",
      "Epoch 7386/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3423 - acc: 0.2083 - val_loss: 0.4023 - val_acc: 0.2444\n",
      "Epoch 7387/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3530 - acc: 0.2079 - val_loss: 0.4082 - val_acc: 0.2444\n",
      "Epoch 7388/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3270 - acc: 0.2096 - val_loss: 0.4231 - val_acc: 0.2444\n",
      "Epoch 7389/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3293 - acc: 0.2087 - val_loss: 0.4247 - val_acc: 0.2444\n",
      "Epoch 7390/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3456 - acc: 0.2083 - val_loss: 0.4619 - val_acc: 0.2407\n",
      "Epoch 7391/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3400 - acc: 0.2087 - val_loss: 0.3975 - val_acc: 0.2444\n",
      "Epoch 7392/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3365 - acc: 0.2096 - val_loss: 0.4200 - val_acc: 0.2407\n",
      "Epoch 7393/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3539 - acc: 0.2092 - val_loss: 0.4118 - val_acc: 0.2444\n",
      "Epoch 7394/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3261 - acc: 0.2092 - val_loss: 0.4163 - val_acc: 0.2444\n",
      "Epoch 7395/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3291 - acc: 0.2092 - val_loss: 0.5795 - val_acc: 0.2407\n",
      "Epoch 7396/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3990 - acc: 0.2092 - val_loss: 0.4378 - val_acc: 0.2407\n",
      "Epoch 7397/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3353 - acc: 0.2087 - val_loss: 0.4022 - val_acc: 0.2444\n",
      "Epoch 7398/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3302 - acc: 0.2092 - val_loss: 0.4030 - val_acc: 0.2444\n",
      "Epoch 7399/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3228 - acc: 0.2092 - val_loss: 0.4279 - val_acc: 0.2407\n",
      "Epoch 7400/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3387 - acc: 0.2087 - val_loss: 0.3995 - val_acc: 0.2444\n",
      "Epoch 7401/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3357 - acc: 0.2092 - val_loss: 0.5292 - val_acc: 0.2407\n",
      "Epoch 7402/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3573 - acc: 0.2092 - val_loss: 0.5020 - val_acc: 0.2407\n",
      "Epoch 7403/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3828 - acc: 0.2092 - val_loss: 0.3867 - val_acc: 0.2444\n",
      "Epoch 7404/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3551 - acc: 0.2092 - val_loss: 0.3936 - val_acc: 0.2444\n",
      "Epoch 7405/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3378 - acc: 0.2083 - val_loss: 0.4557 - val_acc: 0.2444\n",
      "Epoch 7406/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3329 - acc: 0.2092 - val_loss: 0.3981 - val_acc: 0.2444\n",
      "Epoch 7407/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3489 - acc: 0.2083 - val_loss: 0.3972 - val_acc: 0.2444\n",
      "Epoch 7408/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3343 - acc: 0.2087 - val_loss: 0.4850 - val_acc: 0.2407\n",
      "Epoch 7409/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3327 - acc: 0.2092 - val_loss: 0.4059 - val_acc: 0.2444\n",
      "Epoch 7410/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3352 - acc: 0.2087 - val_loss: 0.4160 - val_acc: 0.2444\n",
      "Epoch 7411/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3293 - acc: 0.2092 - val_loss: 0.5056 - val_acc: 0.2444\n",
      "Epoch 7412/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3394 - acc: 0.2087 - val_loss: 0.3947 - val_acc: 0.2444\n",
      "Epoch 7413/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3509 - acc: 0.2092 - val_loss: 0.4843 - val_acc: 0.2444\n",
      "Epoch 7414/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3364 - acc: 0.2092 - val_loss: 0.3939 - val_acc: 0.2444\n",
      "Epoch 7415/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3466 - acc: 0.2092 - val_loss: 0.4265 - val_acc: 0.2444\n",
      "Epoch 7416/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.3488 - acc: 0.2087 - val_loss: 0.4021 - val_acc: 0.2444\n",
      "Epoch 7417/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3289 - acc: 0.2100 - val_loss: 0.4004 - val_acc: 0.2444\n",
      "Epoch 7418/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3217 - acc: 0.2096 - val_loss: 0.4195 - val_acc: 0.2407\n",
      "Epoch 7419/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3298 - acc: 0.2092 - val_loss: 0.4329 - val_acc: 0.2444\n",
      "Epoch 7420/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 1.1560 - acc: 0.2071 - val_loss: 0.6761 - val_acc: 0.2407\n",
      "Epoch 7421/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.4657 - acc: 0.2096 - val_loss: 0.5716 - val_acc: 0.2407\n",
      "Epoch 7422/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3814 - acc: 0.2087 - val_loss: 0.4772 - val_acc: 0.2444\n",
      "Epoch 7423/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3704 - acc: 0.2092 - val_loss: 0.4157 - val_acc: 0.2444\n",
      "Epoch 7424/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3378 - acc: 0.2087 - val_loss: 0.3912 - val_acc: 0.2444\n",
      "Epoch 7425/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3663 - acc: 0.2092 - val_loss: 0.3920 - val_acc: 0.2444\n",
      "Epoch 7426/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3434 - acc: 0.2087 - val_loss: 0.4984 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7427/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3277 - acc: 0.2087 - val_loss: 0.4041 - val_acc: 0.2444\n",
      "Epoch 7428/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3149 - acc: 0.2096 - val_loss: 0.3947 - val_acc: 0.2444\n",
      "Epoch 7429/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3437 - acc: 0.2092 - val_loss: 0.4193 - val_acc: 0.2444\n",
      "Epoch 7430/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3327 - acc: 0.2096 - val_loss: 0.3997 - val_acc: 0.2444\n",
      "Epoch 7431/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3273 - acc: 0.2092 - val_loss: 0.3965 - val_acc: 0.2444\n",
      "Epoch 7432/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3291 - acc: 0.2096 - val_loss: 0.4653 - val_acc: 0.2444\n",
      "Epoch 7433/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3533 - acc: 0.2096 - val_loss: 0.4438 - val_acc: 0.2444\n",
      "Epoch 7434/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3385 - acc: 0.2092 - val_loss: 0.4053 - val_acc: 0.2444\n",
      "Epoch 7435/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3388 - acc: 0.2092 - val_loss: 0.4452 - val_acc: 0.2444\n",
      "Epoch 7436/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3343 - acc: 0.2092 - val_loss: 0.4002 - val_acc: 0.2444\n",
      "Epoch 7437/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3442 - acc: 0.2096 - val_loss: 0.5862 - val_acc: 0.2444\n",
      "Epoch 7438/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3243 - acc: 0.2096 - val_loss: 0.4542 - val_acc: 0.2407\n",
      "Epoch 7439/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3312 - acc: 0.2092 - val_loss: 0.3996 - val_acc: 0.2444\n",
      "Epoch 7440/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3239 - acc: 0.2092 - val_loss: 0.3979 - val_acc: 0.2444\n",
      "Epoch 7441/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3218 - acc: 0.2092 - val_loss: 0.3937 - val_acc: 0.2444\n",
      "Epoch 7442/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3259 - acc: 0.2096 - val_loss: 0.4471 - val_acc: 0.2444\n",
      "Epoch 7443/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3339 - acc: 0.2100 - val_loss: 0.4067 - val_acc: 0.2444\n",
      "Epoch 7444/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3479 - acc: 0.2096 - val_loss: 0.4085 - val_acc: 0.2444\n",
      "Epoch 7445/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3208 - acc: 0.2096 - val_loss: 0.4330 - val_acc: 0.2444\n",
      "Epoch 7446/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3425 - acc: 0.2087 - val_loss: 0.3929 - val_acc: 0.2444\n",
      "Epoch 7447/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3342 - acc: 0.2092 - val_loss: 0.5217 - val_acc: 0.2444\n",
      "Epoch 7448/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3302 - acc: 0.2087 - val_loss: 0.3982 - val_acc: 0.2444\n",
      "Epoch 7449/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3207 - acc: 0.2096 - val_loss: 0.4258 - val_acc: 0.2444\n",
      "Epoch 7450/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3279 - acc: 0.2096 - val_loss: 0.4176 - val_acc: 0.2444\n",
      "Epoch 7451/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3370 - acc: 0.2092 - val_loss: 0.3998 - val_acc: 0.2444\n",
      "Epoch 7452/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3338 - acc: 0.2087 - val_loss: 0.4004 - val_acc: 0.2444\n",
      "Epoch 7453/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3484 - acc: 0.2087 - val_loss: 0.4394 - val_acc: 0.2407\n",
      "Epoch 7454/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3458 - acc: 0.2092 - val_loss: 0.4258 - val_acc: 0.2444\n",
      "Epoch 7455/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3632 - acc: 0.2083 - val_loss: 0.4195 - val_acc: 0.2444\n",
      "Epoch 7456/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3530 - acc: 0.2092 - val_loss: 0.4058 - val_acc: 0.2444\n",
      "Epoch 7457/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3248 - acc: 0.2100 - val_loss: 0.4008 - val_acc: 0.2444\n",
      "Epoch 7458/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3393 - acc: 0.2087 - val_loss: 0.5019 - val_acc: 0.2444\n",
      "Epoch 7459/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3387 - acc: 0.2092 - val_loss: 0.4275 - val_acc: 0.2444\n",
      "Epoch 7460/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3186 - acc: 0.2096 - val_loss: 0.4328 - val_acc: 0.2444\n",
      "Epoch 7461/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3339 - acc: 0.2092 - val_loss: 0.4077 - val_acc: 0.2444\n",
      "Epoch 7462/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3261 - acc: 0.2092 - val_loss: 0.5699 - val_acc: 0.2444\n",
      "Epoch 7463/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3341 - acc: 0.2096 - val_loss: 0.4452 - val_acc: 0.2444\n",
      "Epoch 7464/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3231 - acc: 0.2096 - val_loss: 0.4067 - val_acc: 0.2444\n",
      "Epoch 7465/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3387 - acc: 0.2096 - val_loss: 0.4317 - val_acc: 0.2444\n",
      "Epoch 7466/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3371 - acc: 0.2083 - val_loss: 0.4182 - val_acc: 0.2444\n",
      "Epoch 7467/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3616 - acc: 0.2092 - val_loss: 0.4077 - val_acc: 0.2444\n",
      "Epoch 7468/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3279 - acc: 0.2087 - val_loss: 0.4000 - val_acc: 0.2444\n",
      "Epoch 7469/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3253 - acc: 0.2096 - val_loss: 0.4340 - val_acc: 0.2444\n",
      "Epoch 7470/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3320 - acc: 0.2096 - val_loss: 0.4000 - val_acc: 0.2444\n",
      "Epoch 7471/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3228 - acc: 0.2092 - val_loss: 0.4069 - val_acc: 0.2444\n",
      "Epoch 7472/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3407 - acc: 0.2096 - val_loss: 0.4132 - val_acc: 0.2444\n",
      "Epoch 7473/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.3759 - acc: 0.2100 - val_loss: 0.4537 - val_acc: 0.2444\n",
      "Epoch 7474/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.3260 - acc: 0.2096 - val_loss: 0.3909 - val_acc: 0.2444\n",
      "Epoch 7475/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3401 - acc: 0.2096 - val_loss: 0.4316 - val_acc: 0.2444\n",
      "Epoch 7476/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3466 - acc: 0.2096 - val_loss: 0.3844 - val_acc: 0.2444\n",
      "Epoch 7477/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3261 - acc: 0.2092 - val_loss: 0.4664 - val_acc: 0.2444\n",
      "Epoch 7478/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3388 - acc: 0.2092 - val_loss: 0.4081 - val_acc: 0.2444\n",
      "Epoch 7479/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3245 - acc: 0.2087 - val_loss: 0.4173 - val_acc: 0.2444\n",
      "Epoch 7480/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3217 - acc: 0.2100 - val_loss: 0.3860 - val_acc: 0.2444\n",
      "Epoch 7481/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3229 - acc: 0.2087 - val_loss: 0.4521 - val_acc: 0.2444\n",
      "Epoch 7482/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3317 - acc: 0.2096 - val_loss: 0.3932 - val_acc: 0.2444\n",
      "Epoch 7483/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3331 - acc: 0.2083 - val_loss: 0.4032 - val_acc: 0.2444\n",
      "Epoch 7484/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3415 - acc: 0.2092 - val_loss: 0.3905 - val_acc: 0.2444\n",
      "Epoch 7485/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3312 - acc: 0.2083 - val_loss: 0.4004 - val_acc: 0.2444\n",
      "Epoch 7486/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3279 - acc: 0.2092 - val_loss: 0.3971 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7487/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3323 - acc: 0.2087 - val_loss: 0.4004 - val_acc: 0.2444\n",
      "Epoch 7488/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3446 - acc: 0.2096 - val_loss: 0.4256 - val_acc: 0.2444\n",
      "Epoch 7489/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3329 - acc: 0.2083 - val_loss: 0.3986 - val_acc: 0.2444\n",
      "Epoch 7490/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3278 - acc: 0.2092 - val_loss: 0.4364 - val_acc: 0.2407\n",
      "Epoch 7491/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3322 - acc: 0.2096 - val_loss: 0.4361 - val_acc: 0.2444\n",
      "Epoch 7492/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.3202 - acc: 0.2092 - val_loss: 0.3996 - val_acc: 0.2444\n",
      "Epoch 7493/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3335 - acc: 0.2092 - val_loss: 0.4290 - val_acc: 0.2444\n",
      "Epoch 7494/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3839 - acc: 0.2087 - val_loss: 0.4260 - val_acc: 0.2444\n",
      "Epoch 7495/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3454 - acc: 0.2092 - val_loss: 0.4003 - val_acc: 0.2444\n",
      "Epoch 7496/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3376 - acc: 0.2096 - val_loss: 0.4915 - val_acc: 0.2407\n",
      "Epoch 7497/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3288 - acc: 0.2087 - val_loss: 0.4129 - val_acc: 0.2444\n",
      "Epoch 7498/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3355 - acc: 0.2087 - val_loss: 0.4664 - val_acc: 0.2407\n",
      "Epoch 7499/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3524 - acc: 0.2092 - val_loss: 0.4112 - val_acc: 0.2444\n",
      "Epoch 7500/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3192 - acc: 0.2092 - val_loss: 0.4658 - val_acc: 0.2444\n",
      "Epoch 7501/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3474 - acc: 0.2087 - val_loss: 0.4102 - val_acc: 0.2444\n",
      "Epoch 7502/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3326 - acc: 0.2100 - val_loss: 0.4206 - val_acc: 0.2444\n",
      "Epoch 7503/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3233 - acc: 0.2092 - val_loss: 0.4107 - val_acc: 0.2444\n",
      "Epoch 7504/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3278 - acc: 0.2092 - val_loss: 0.4682 - val_acc: 0.2407\n",
      "Epoch 7505/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3635 - acc: 0.2092 - val_loss: 0.4730 - val_acc: 0.2444\n",
      "Epoch 7506/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3324 - acc: 0.2087 - val_loss: 0.3985 - val_acc: 0.2444\n",
      "Epoch 7507/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3492 - acc: 0.2092 - val_loss: 0.3928 - val_acc: 0.2444\n",
      "Epoch 7508/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3191 - acc: 0.2096 - val_loss: 0.3957 - val_acc: 0.2444\n",
      "Epoch 7509/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3310 - acc: 0.2092 - val_loss: 0.3887 - val_acc: 0.2444\n",
      "Epoch 7510/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3381 - acc: 0.2087 - val_loss: 0.4090 - val_acc: 0.2444\n",
      "Epoch 7511/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3536 - acc: 0.2092 - val_loss: 0.3918 - val_acc: 0.2444\n",
      "Epoch 7512/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3343 - acc: 0.2100 - val_loss: 0.4602 - val_acc: 0.2407\n",
      "Epoch 7513/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3410 - acc: 0.2092 - val_loss: 0.5592 - val_acc: 0.2444\n",
      "Epoch 7514/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3369 - acc: 0.2092 - val_loss: 0.4762 - val_acc: 0.2444\n",
      "Epoch 7515/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3451 - acc: 0.2079 - val_loss: 0.4483 - val_acc: 0.2444\n",
      "Epoch 7516/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3216 - acc: 0.2092 - val_loss: 0.4170 - val_acc: 0.2444\n",
      "Epoch 7517/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3303 - acc: 0.2092 - val_loss: 0.5330 - val_acc: 0.2444\n",
      "Epoch 7518/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3772 - acc: 0.2092 - val_loss: 0.3977 - val_acc: 0.2444\n",
      "Epoch 7519/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3268 - acc: 0.2092 - val_loss: 0.4662 - val_acc: 0.2407\n",
      "Epoch 7520/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3444 - acc: 0.2092 - val_loss: 0.4037 - val_acc: 0.2444\n",
      "Epoch 7521/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3359 - acc: 0.2092 - val_loss: 0.3948 - val_acc: 0.2444\n",
      "Epoch 7522/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3419 - acc: 0.2092 - val_loss: 0.4642 - val_acc: 0.2407\n",
      "Epoch 7523/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3531 - acc: 0.2092 - val_loss: 0.4013 - val_acc: 0.2444\n",
      "Epoch 7524/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3297 - acc: 0.2096 - val_loss: 0.3931 - val_acc: 0.2444\n",
      "Epoch 7525/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3275 - acc: 0.2087 - val_loss: 0.3971 - val_acc: 0.2444\n",
      "Epoch 7526/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3222 - acc: 0.2092 - val_loss: 0.4045 - val_acc: 0.2444\n",
      "Epoch 7527/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3338 - acc: 0.2096 - val_loss: 0.4086 - val_acc: 0.2444\n",
      "Epoch 7528/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3242 - acc: 0.2092 - val_loss: 0.3887 - val_acc: 0.2444\n",
      "Epoch 7529/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3313 - acc: 0.2092 - val_loss: 0.4524 - val_acc: 0.2407\n",
      "Epoch 7530/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3445 - acc: 0.2092 - val_loss: 0.4122 - val_acc: 0.2444\n",
      "Epoch 7531/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3328 - acc: 0.2096 - val_loss: 0.4342 - val_acc: 0.2407\n",
      "Epoch 7532/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3526 - acc: 0.2087 - val_loss: 0.5715 - val_acc: 0.2444\n",
      "Epoch 7533/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3491 - acc: 0.2083 - val_loss: 0.3933 - val_acc: 0.2444\n",
      "Epoch 7534/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3284 - acc: 0.2096 - val_loss: 0.4092 - val_acc: 0.2444\n",
      "Epoch 7535/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3266 - acc: 0.2100 - val_loss: 0.3860 - val_acc: 0.2444\n",
      "Epoch 7536/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3237 - acc: 0.2096 - val_loss: 0.4381 - val_acc: 0.2444\n",
      "Epoch 7537/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3548 - acc: 0.2083 - val_loss: 0.4135 - val_acc: 0.2444\n",
      "Epoch 7538/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3531 - acc: 0.2087 - val_loss: 0.4370 - val_acc: 0.2444\n",
      "Epoch 7539/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3326 - acc: 0.2092 - val_loss: 0.4834 - val_acc: 0.2407\n",
      "Epoch 7540/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3392 - acc: 0.2079 - val_loss: 0.4083 - val_acc: 0.2444\n",
      "Epoch 7541/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3295 - acc: 0.2087 - val_loss: 0.4391 - val_acc: 0.2444\n",
      "Epoch 7542/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3470 - acc: 0.2092 - val_loss: 0.3977 - val_acc: 0.2444\n",
      "Epoch 7543/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3357 - acc: 0.2083 - val_loss: 0.4332 - val_acc: 0.2444\n",
      "Epoch 7544/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3240 - acc: 0.2083 - val_loss: 0.3942 - val_acc: 0.2444\n",
      "Epoch 7545/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3287 - acc: 0.2092 - val_loss: 0.4104 - val_acc: 0.2444\n",
      "Epoch 7546/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3237 - acc: 0.2096 - val_loss: 0.4194 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7547/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3420 - acc: 0.2087 - val_loss: 0.4055 - val_acc: 0.2444\n",
      "Epoch 7548/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3666 - acc: 0.2092 - val_loss: 0.7302 - val_acc: 0.2444\n",
      "Epoch 7549/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3333 - acc: 0.2096 - val_loss: 0.4544 - val_acc: 0.2444\n",
      "Epoch 7550/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3292 - acc: 0.2092 - val_loss: 0.4515 - val_acc: 0.2407\n",
      "Epoch 7551/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3471 - acc: 0.2087 - val_loss: 0.4072 - val_acc: 0.2444\n",
      "Epoch 7552/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3246 - acc: 0.2092 - val_loss: 0.4608 - val_acc: 0.2444\n",
      "Epoch 7553/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3304 - acc: 0.2096 - val_loss: 0.3966 - val_acc: 0.2444\n",
      "Epoch 7554/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3270 - acc: 0.2092 - val_loss: 0.4140 - val_acc: 0.2444\n",
      "Epoch 7555/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3246 - acc: 0.2096 - val_loss: 0.4598 - val_acc: 0.2444\n",
      "Epoch 7556/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3299 - acc: 0.2092 - val_loss: 0.4295 - val_acc: 0.2407\n",
      "Epoch 7557/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3679 - acc: 0.2092 - val_loss: 0.3981 - val_acc: 0.2444\n",
      "Epoch 7558/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3510 - acc: 0.2079 - val_loss: 0.4182 - val_acc: 0.2407\n",
      "Epoch 7559/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3341 - acc: 0.2092 - val_loss: 0.3923 - val_acc: 0.2444\n",
      "Epoch 7560/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3278 - acc: 0.2096 - val_loss: 0.4069 - val_acc: 0.2444\n",
      "Epoch 7561/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3273 - acc: 0.2092 - val_loss: 0.4384 - val_acc: 0.2444\n",
      "Epoch 7562/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3261 - acc: 0.2083 - val_loss: 0.4111 - val_acc: 0.2444\n",
      "Epoch 7563/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3562 - acc: 0.2092 - val_loss: 0.3901 - val_acc: 0.2444\n",
      "Epoch 7564/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3444 - acc: 0.2087 - val_loss: 0.4000 - val_acc: 0.2444\n",
      "Epoch 7565/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3487 - acc: 0.2096 - val_loss: 0.4147 - val_acc: 0.2444\n",
      "Epoch 7566/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3207 - acc: 0.2096 - val_loss: 0.4073 - val_acc: 0.2444\n",
      "Epoch 7567/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3323 - acc: 0.2087 - val_loss: 0.3797 - val_acc: 0.2444\n",
      "Epoch 7568/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3377 - acc: 0.2087 - val_loss: 0.4917 - val_acc: 0.2407\n",
      "Epoch 7569/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3451 - acc: 0.2087 - val_loss: 0.4063 - val_acc: 0.2444\n",
      "Epoch 7570/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3229 - acc: 0.2092 - val_loss: 0.4043 - val_acc: 0.2444\n",
      "Epoch 7571/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3185 - acc: 0.2092 - val_loss: 0.3832 - val_acc: 0.2444\n",
      "Epoch 7572/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3328 - acc: 0.2092 - val_loss: 0.4018 - val_acc: 0.2444\n",
      "Epoch 7573/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3418 - acc: 0.2087 - val_loss: 0.4206 - val_acc: 0.2444\n",
      "Epoch 7574/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3390 - acc: 0.2096 - val_loss: 0.3984 - val_acc: 0.2444\n",
      "Epoch 7575/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3212 - acc: 0.2083 - val_loss: 0.3883 - val_acc: 0.2444\n",
      "Epoch 7576/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3431 - acc: 0.2096 - val_loss: 0.4397 - val_acc: 0.2407\n",
      "Epoch 7577/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3583 - acc: 0.2092 - val_loss: 0.3875 - val_acc: 0.2444\n",
      "Epoch 7578/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3496 - acc: 0.2092 - val_loss: 0.3876 - val_acc: 0.2444\n",
      "Epoch 7579/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3180 - acc: 0.2100 - val_loss: 0.4076 - val_acc: 0.2444\n",
      "Epoch 7580/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3280 - acc: 0.2092 - val_loss: 0.3983 - val_acc: 0.2444\n",
      "Epoch 7581/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3344 - acc: 0.2083 - val_loss: 0.5174 - val_acc: 0.2444\n",
      "Epoch 7582/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3563 - acc: 0.2075 - val_loss: 0.3932 - val_acc: 0.2444\n",
      "Epoch 7583/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3293 - acc: 0.2087 - val_loss: 0.3937 - val_acc: 0.2444\n",
      "Epoch 7584/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3181 - acc: 0.2100 - val_loss: 0.4224 - val_acc: 0.2444\n",
      "Epoch 7585/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3528 - acc: 0.2087 - val_loss: 0.4455 - val_acc: 0.2444\n",
      "Epoch 7586/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3554 - acc: 0.2092 - val_loss: 0.4129 - val_acc: 0.2444\n",
      "Epoch 7587/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3234 - acc: 0.2092 - val_loss: 0.4454 - val_acc: 0.2444\n",
      "Epoch 7588/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3258 - acc: 0.2092 - val_loss: 0.3809 - val_acc: 0.2444\n",
      "Epoch 7589/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3251 - acc: 0.2100 - val_loss: 0.3983 - val_acc: 0.2444\n",
      "Epoch 7590/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3263 - acc: 0.2096 - val_loss: 0.3974 - val_acc: 0.2444\n",
      "Epoch 7591/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3409 - acc: 0.2087 - val_loss: 0.3830 - val_acc: 0.2444\n",
      "Epoch 7592/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3322 - acc: 0.2092 - val_loss: 0.4167 - val_acc: 0.2407\n",
      "Epoch 7593/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3357 - acc: 0.2083 - val_loss: 0.4532 - val_acc: 0.2444\n",
      "Epoch 7594/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3305 - acc: 0.2096 - val_loss: 0.4347 - val_acc: 0.2444\n",
      "Epoch 7595/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3334 - acc: 0.2096 - val_loss: 0.4200 - val_acc: 0.2444\n",
      "Epoch 7596/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3323 - acc: 0.2087 - val_loss: 0.3994 - val_acc: 0.2444\n",
      "Epoch 7597/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3291 - acc: 0.2087 - val_loss: 0.4026 - val_acc: 0.2444\n",
      "Epoch 7598/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3542 - acc: 0.2092 - val_loss: 0.4220 - val_acc: 0.2444\n",
      "Epoch 7599/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3195 - acc: 0.2096 - val_loss: 0.4174 - val_acc: 0.2444\n",
      "Epoch 7600/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3280 - acc: 0.2092 - val_loss: 0.3811 - val_acc: 0.2444\n",
      "Epoch 7601/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3317 - acc: 0.2092 - val_loss: 0.4029 - val_acc: 0.2444\n",
      "Epoch 7602/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.3357 - acc: 0.2087 - val_loss: 0.4118 - val_acc: 0.2444\n",
      "Epoch 7603/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.3409 - acc: 0.2100 - val_loss: 0.3976 - val_acc: 0.2444\n",
      "Epoch 7604/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3587 - acc: 0.2075 - val_loss: 0.3851 - val_acc: 0.2444\n",
      "Epoch 7605/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3283 - acc: 0.2100 - val_loss: 0.4022 - val_acc: 0.2444\n",
      "Epoch 7606/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3342 - acc: 0.2100 - val_loss: 0.4002 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7607/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3286 - acc: 0.2100 - val_loss: 0.4096 - val_acc: 0.2444\n",
      "Epoch 7608/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3246 - acc: 0.2096 - val_loss: 0.3900 - val_acc: 0.2444\n",
      "Epoch 7609/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3364 - acc: 0.2092 - val_loss: 0.4832 - val_acc: 0.2444\n",
      "Epoch 7610/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3412 - acc: 0.2083 - val_loss: 0.4684 - val_acc: 0.2444\n",
      "Epoch 7611/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3373 - acc: 0.2096 - val_loss: 0.3957 - val_acc: 0.2444\n",
      "Epoch 7612/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3538 - acc: 0.2096 - val_loss: 0.4014 - val_acc: 0.2444\n",
      "Epoch 7613/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3500 - acc: 0.2087 - val_loss: 0.3896 - val_acc: 0.2444\n",
      "Epoch 7614/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3468 - acc: 0.2096 - val_loss: 0.4035 - val_acc: 0.2444\n",
      "Epoch 7615/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3288 - acc: 0.2092 - val_loss: 0.3979 - val_acc: 0.2444\n",
      "Epoch 7616/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3267 - acc: 0.2096 - val_loss: 0.4056 - val_acc: 0.2444\n",
      "Epoch 7617/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3223 - acc: 0.2092 - val_loss: 0.4005 - val_acc: 0.2444\n",
      "Epoch 7618/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3571 - acc: 0.2092 - val_loss: 0.4949 - val_acc: 0.2444\n",
      "Epoch 7619/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3262 - acc: 0.2092 - val_loss: 0.4415 - val_acc: 0.2444\n",
      "Epoch 7620/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3311 - acc: 0.2096 - val_loss: 0.3987 - val_acc: 0.2444\n",
      "Epoch 7621/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3445 - acc: 0.2092 - val_loss: 0.4444 - val_acc: 0.2444\n",
      "Epoch 7622/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3357 - acc: 0.2100 - val_loss: 0.4113 - val_acc: 0.2444\n",
      "Epoch 7623/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3280 - acc: 0.2087 - val_loss: 0.4492 - val_acc: 0.2444\n",
      "Epoch 7624/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3233 - acc: 0.2096 - val_loss: 0.4059 - val_acc: 0.2444\n",
      "Epoch 7625/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3382 - acc: 0.2096 - val_loss: 0.4379 - val_acc: 0.2407\n",
      "Epoch 7626/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3311 - acc: 0.2092 - val_loss: 0.4040 - val_acc: 0.2444\n",
      "Epoch 7627/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3513 - acc: 0.2087 - val_loss: 0.4015 - val_acc: 0.2444\n",
      "Epoch 7628/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3422 - acc: 0.2096 - val_loss: 0.4365 - val_acc: 0.2444\n",
      "Epoch 7629/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3513 - acc: 0.2087 - val_loss: 0.3958 - val_acc: 0.2444\n",
      "Epoch 7630/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3235 - acc: 0.2096 - val_loss: 0.4564 - val_acc: 0.2407\n",
      "Epoch 7631/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3233 - acc: 0.2096 - val_loss: 0.3959 - val_acc: 0.2444\n",
      "Epoch 7632/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3561 - acc: 0.2087 - val_loss: 0.5741 - val_acc: 0.2444\n",
      "Epoch 7633/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3388 - acc: 0.2096 - val_loss: 0.4020 - val_acc: 0.2444\n",
      "Epoch 7634/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3258 - acc: 0.2100 - val_loss: 0.3866 - val_acc: 0.2444\n",
      "Epoch 7635/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3394 - acc: 0.2096 - val_loss: 0.3875 - val_acc: 0.2444\n",
      "Epoch 7636/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3240 - acc: 0.2096 - val_loss: 0.4086 - val_acc: 0.2444\n",
      "Epoch 7637/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3291 - acc: 0.2087 - val_loss: 0.3876 - val_acc: 0.2444\n",
      "Epoch 7638/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3432 - acc: 0.2096 - val_loss: 0.3937 - val_acc: 0.2444\n",
      "Epoch 7639/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3320 - acc: 0.2096 - val_loss: 0.4375 - val_acc: 0.2444\n",
      "Epoch 7640/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3486 - acc: 0.2087 - val_loss: 0.4288 - val_acc: 0.2444\n",
      "Epoch 7641/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3346 - acc: 0.2096 - val_loss: 0.3942 - val_acc: 0.2444\n",
      "Epoch 7642/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3271 - acc: 0.2100 - val_loss: 0.4279 - val_acc: 0.2444\n",
      "Epoch 7643/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3512 - acc: 0.2092 - val_loss: 0.3877 - val_acc: 0.2444\n",
      "Epoch 7644/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3245 - acc: 0.2096 - val_loss: 0.4500 - val_acc: 0.2407\n",
      "Epoch 7645/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3361 - acc: 0.2092 - val_loss: 0.3993 - val_acc: 0.2444\n",
      "Epoch 7646/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3482 - acc: 0.2096 - val_loss: 0.4052 - val_acc: 0.2444\n",
      "Epoch 7647/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3298 - acc: 0.2092 - val_loss: 0.5040 - val_acc: 0.2444\n",
      "Epoch 7648/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3429 - acc: 0.2092 - val_loss: 0.4257 - val_acc: 0.2407\n",
      "Epoch 7649/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3334 - acc: 0.2087 - val_loss: 0.4042 - val_acc: 0.2444\n",
      "Epoch 7650/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3348 - acc: 0.2092 - val_loss: 0.4119 - val_acc: 0.2444\n",
      "Epoch 7651/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3332 - acc: 0.2096 - val_loss: 0.4242 - val_acc: 0.2444\n",
      "Epoch 7652/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3357 - acc: 0.2092 - val_loss: 0.4468 - val_acc: 0.2444\n",
      "Epoch 7653/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3531 - acc: 0.2092 - val_loss: 0.4080 - val_acc: 0.2444\n",
      "Epoch 7654/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3421 - acc: 0.2092 - val_loss: 0.3978 - val_acc: 0.2444\n",
      "Epoch 7655/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3295 - acc: 0.2100 - val_loss: 0.4403 - val_acc: 0.2444\n",
      "Epoch 7656/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3303 - acc: 0.2096 - val_loss: 0.4083 - val_acc: 0.2444\n",
      "Epoch 7657/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3358 - acc: 0.2092 - val_loss: 0.4231 - val_acc: 0.2444\n",
      "Epoch 7658/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3314 - acc: 0.2092 - val_loss: 0.4553 - val_acc: 0.2444\n",
      "Epoch 7659/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3244 - acc: 0.2096 - val_loss: 0.4138 - val_acc: 0.2444\n",
      "Epoch 7660/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3222 - acc: 0.2092 - val_loss: 0.4327 - val_acc: 0.2407\n",
      "Epoch 7661/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3392 - acc: 0.2096 - val_loss: 0.3929 - val_acc: 0.2444\n",
      "Epoch 7662/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3344 - acc: 0.2092 - val_loss: 0.3965 - val_acc: 0.2444\n",
      "Epoch 7663/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3199 - acc: 0.2096 - val_loss: 0.4354 - val_acc: 0.2407\n",
      "Epoch 7664/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3626 - acc: 0.2087 - val_loss: 0.3965 - val_acc: 0.2444\n",
      "Epoch 7665/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3337 - acc: 0.2096 - val_loss: 0.4362 - val_acc: 0.2407\n",
      "Epoch 7666/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3272 - acc: 0.2087 - val_loss: 0.3934 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7667/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3643 - acc: 0.2092 - val_loss: 0.3967 - val_acc: 0.2444\n",
      "Epoch 7668/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3257 - acc: 0.2092 - val_loss: 0.4013 - val_acc: 0.2444\n",
      "Epoch 7669/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3386 - acc: 0.2096 - val_loss: 0.4409 - val_acc: 0.2407\n",
      "Epoch 7670/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3271 - acc: 0.2087 - val_loss: 0.3901 - val_acc: 0.2444\n",
      "Epoch 7671/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3367 - acc: 0.2092 - val_loss: 0.4212 - val_acc: 0.2444\n",
      "Epoch 7672/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3219 - acc: 0.2087 - val_loss: 0.4880 - val_acc: 0.2444\n",
      "Epoch 7673/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3236 - acc: 0.2092 - val_loss: 0.3948 - val_acc: 0.2444\n",
      "Epoch 7674/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3221 - acc: 0.2100 - val_loss: 0.3919 - val_acc: 0.2444\n",
      "Epoch 7675/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3443 - acc: 0.2100 - val_loss: 0.3960 - val_acc: 0.2444\n",
      "Epoch 7676/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3370 - acc: 0.2096 - val_loss: 0.3981 - val_acc: 0.2444\n",
      "Epoch 7677/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3377 - acc: 0.2096 - val_loss: 0.4737 - val_acc: 0.2407\n",
      "Epoch 7678/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3336 - acc: 0.2096 - val_loss: 0.3951 - val_acc: 0.2444\n",
      "Epoch 7679/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3265 - acc: 0.2092 - val_loss: 0.3895 - val_acc: 0.2444\n",
      "Epoch 7680/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3578 - acc: 0.2092 - val_loss: 0.3946 - val_acc: 0.2444\n",
      "Epoch 7681/10000\n",
      "76/76 [==============================] - 3s 46ms/step - loss: 0.3212 - acc: 0.2096 - val_loss: 0.4030 - val_acc: 0.2444\n",
      "Epoch 7682/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3524 - acc: 0.2092 - val_loss: 0.5098 - val_acc: 0.2444\n",
      "Epoch 7683/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.3502 - acc: 0.2083 - val_loss: 0.4057 - val_acc: 0.2444\n",
      "Epoch 7684/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3393 - acc: 0.2096 - val_loss: 0.4427 - val_acc: 0.2444\n",
      "Epoch 7685/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3256 - acc: 0.2100 - val_loss: 0.3893 - val_acc: 0.2444\n",
      "Epoch 7686/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3366 - acc: 0.2092 - val_loss: 0.3933 - val_acc: 0.2444\n",
      "Epoch 7687/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3284 - acc: 0.2092 - val_loss: 0.4034 - val_acc: 0.2444\n",
      "Epoch 7688/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3285 - acc: 0.2100 - val_loss: 0.3919 - val_acc: 0.2444\n",
      "Epoch 7689/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3277 - acc: 0.2083 - val_loss: 0.3957 - val_acc: 0.2444\n",
      "Epoch 7690/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3253 - acc: 0.2087 - val_loss: 0.4944 - val_acc: 0.2444\n",
      "Epoch 7691/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3425 - acc: 0.2096 - val_loss: 0.4002 - val_acc: 0.2444\n",
      "Epoch 7692/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3605 - acc: 0.2092 - val_loss: 0.4193 - val_acc: 0.2407\n",
      "Epoch 7693/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3299 - acc: 0.2096 - val_loss: 0.4015 - val_acc: 0.2444\n",
      "Epoch 7694/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3518 - acc: 0.2092 - val_loss: 0.4035 - val_acc: 0.2444\n",
      "Epoch 7695/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3630 - acc: 0.2087 - val_loss: 0.5870 - val_acc: 0.2444\n",
      "Epoch 7696/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3524 - acc: 0.2092 - val_loss: 0.4092 - val_acc: 0.2444\n",
      "Epoch 7697/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3166 - acc: 0.2092 - val_loss: 0.4130 - val_acc: 0.2444\n",
      "Epoch 7698/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3321 - acc: 0.2087 - val_loss: 0.3855 - val_acc: 0.2444\n",
      "Epoch 7699/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3227 - acc: 0.2096 - val_loss: 0.4603 - val_acc: 0.2444\n",
      "Epoch 7700/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3312 - acc: 0.2092 - val_loss: 0.4329 - val_acc: 0.2444\n",
      "Epoch 7701/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3424 - acc: 0.2096 - val_loss: 0.3993 - val_acc: 0.2444\n",
      "Epoch 7702/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3333 - acc: 0.2092 - val_loss: 0.3975 - val_acc: 0.2444\n",
      "Epoch 7703/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3269 - acc: 0.2087 - val_loss: 0.4246 - val_acc: 0.2444\n",
      "Epoch 7704/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3382 - acc: 0.2096 - val_loss: 0.3965 - val_acc: 0.2444\n",
      "Epoch 7705/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3365 - acc: 0.2087 - val_loss: 0.3968 - val_acc: 0.2444\n",
      "Epoch 7706/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3355 - acc: 0.2092 - val_loss: 0.4341 - val_acc: 0.2444\n",
      "Epoch 7707/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3185 - acc: 0.2096 - val_loss: 0.4328 - val_acc: 0.2444\n",
      "Epoch 7708/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3439 - acc: 0.2100 - val_loss: 0.4035 - val_acc: 0.2444\n",
      "Epoch 7709/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3207 - acc: 0.2096 - val_loss: 0.4178 - val_acc: 0.2444\n",
      "Epoch 7710/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3311 - acc: 0.2087 - val_loss: 0.3912 - val_acc: 0.2444\n",
      "Epoch 7711/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3334 - acc: 0.2096 - val_loss: 0.3874 - val_acc: 0.2444\n",
      "Epoch 7712/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3240 - acc: 0.2087 - val_loss: 0.4051 - val_acc: 0.2444\n",
      "Epoch 7713/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3475 - acc: 0.2083 - val_loss: 0.4314 - val_acc: 0.2444\n",
      "Epoch 7714/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3265 - acc: 0.2100 - val_loss: 0.3983 - val_acc: 0.2444\n",
      "Epoch 7715/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3241 - acc: 0.2087 - val_loss: 0.4253 - val_acc: 0.2444\n",
      "Epoch 7716/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3310 - acc: 0.2092 - val_loss: 0.4213 - val_acc: 0.2407\n",
      "Epoch 7717/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3256 - acc: 0.2087 - val_loss: 0.4112 - val_acc: 0.2444\n",
      "Epoch 7718/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3418 - acc: 0.2092 - val_loss: 0.3916 - val_acc: 0.2444\n",
      "Epoch 7719/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3385 - acc: 0.2087 - val_loss: 0.5112 - val_acc: 0.2444\n",
      "Epoch 7720/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3365 - acc: 0.2087 - val_loss: 0.3981 - val_acc: 0.2444\n",
      "Epoch 7721/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3310 - acc: 0.2092 - val_loss: 0.3926 - val_acc: 0.2444\n",
      "Epoch 7722/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3400 - acc: 0.2092 - val_loss: 0.3893 - val_acc: 0.2444\n",
      "Epoch 7723/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3248 - acc: 0.2092 - val_loss: 0.4018 - val_acc: 0.2444\n",
      "Epoch 7724/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3304 - acc: 0.2096 - val_loss: 0.4026 - val_acc: 0.2444\n",
      "Epoch 7725/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3231 - acc: 0.2092 - val_loss: 0.3779 - val_acc: 0.2444\n",
      "Epoch 7726/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3472 - acc: 0.2092 - val_loss: 0.3974 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7727/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3246 - acc: 0.2092 - val_loss: 0.5355 - val_acc: 0.2444\n",
      "Epoch 7728/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3544 - acc: 0.2092 - val_loss: 0.3782 - val_acc: 0.2444\n",
      "Epoch 7729/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3296 - acc: 0.2083 - val_loss: 0.3887 - val_acc: 0.2444\n",
      "Epoch 7730/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3322 - acc: 0.2092 - val_loss: 0.4127 - val_acc: 0.2444\n",
      "Epoch 7731/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3355 - acc: 0.2087 - val_loss: 0.3906 - val_acc: 0.2444\n",
      "Epoch 7732/10000\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.3334 - acc: 0.2087 - val_loss: 0.3915 - val_acc: 0.2444\n",
      "Epoch 7733/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3270 - acc: 0.2096 - val_loss: 0.3995 - val_acc: 0.2444\n",
      "Epoch 7734/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3283 - acc: 0.2087 - val_loss: 0.4492 - val_acc: 0.2407\n",
      "Epoch 7735/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3267 - acc: 0.2096 - val_loss: 0.3953 - val_acc: 0.2444\n",
      "Epoch 7736/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3195 - acc: 0.2096 - val_loss: 0.4029 - val_acc: 0.2444\n",
      "Epoch 7737/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3178 - acc: 0.2092 - val_loss: 0.3831 - val_acc: 0.2444\n",
      "Epoch 7738/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3515 - acc: 0.2087 - val_loss: 0.3971 - val_acc: 0.2444\n",
      "Epoch 7739/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3310 - acc: 0.2083 - val_loss: 0.4065 - val_acc: 0.2444\n",
      "Epoch 7740/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3304 - acc: 0.2087 - val_loss: 0.3972 - val_acc: 0.2444\n",
      "Epoch 7741/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3368 - acc: 0.2096 - val_loss: 0.3926 - val_acc: 0.2444\n",
      "Epoch 7742/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3438 - acc: 0.2092 - val_loss: 0.4951 - val_acc: 0.2444\n",
      "Epoch 7743/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3271 - acc: 0.2083 - val_loss: 0.4401 - val_acc: 0.2444\n",
      "Epoch 7744/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3333 - acc: 0.2087 - val_loss: 0.4429 - val_acc: 0.2444\n",
      "Epoch 7745/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3373 - acc: 0.2096 - val_loss: 0.5060 - val_acc: 0.2444\n",
      "Epoch 7746/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3634 - acc: 0.2096 - val_loss: 0.4735 - val_acc: 0.2444\n",
      "Epoch 7747/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3266 - acc: 0.2096 - val_loss: 0.3924 - val_acc: 0.2444\n",
      "Epoch 7748/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3389 - acc: 0.2092 - val_loss: 0.4882 - val_acc: 0.2407\n",
      "Epoch 7749/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3799 - acc: 0.2092 - val_loss: 0.4245 - val_acc: 0.2407\n",
      "Epoch 7750/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3486 - acc: 0.2087 - val_loss: 0.3884 - val_acc: 0.2444\n",
      "Epoch 7751/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3485 - acc: 0.2083 - val_loss: 0.4155 - val_acc: 0.2407\n",
      "Epoch 7752/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3333 - acc: 0.2087 - val_loss: 0.4115 - val_acc: 0.2444\n",
      "Epoch 7753/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3346 - acc: 0.2083 - val_loss: 0.4301 - val_acc: 0.2407\n",
      "Epoch 7754/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3521 - acc: 0.2079 - val_loss: 0.4578 - val_acc: 0.2444\n",
      "Epoch 7755/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3866 - acc: 0.2092 - val_loss: 0.5308 - val_acc: 0.2407\n",
      "Epoch 7756/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3354 - acc: 0.2092 - val_loss: 0.4349 - val_acc: 0.2407\n",
      "Epoch 7757/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3271 - acc: 0.2087 - val_loss: 0.3857 - val_acc: 0.2444\n",
      "Epoch 7758/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3459 - acc: 0.2083 - val_loss: 0.6293 - val_acc: 0.2407\n",
      "Epoch 7759/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3439 - acc: 0.2096 - val_loss: 0.4056 - val_acc: 0.2444\n",
      "Epoch 7760/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3262 - acc: 0.2100 - val_loss: 0.3858 - val_acc: 0.2444\n",
      "Epoch 7761/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3437 - acc: 0.2100 - val_loss: 0.4867 - val_acc: 0.2444\n",
      "Epoch 7762/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3207 - acc: 0.2092 - val_loss: 0.4111 - val_acc: 0.2444\n",
      "Epoch 7763/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3598 - acc: 0.2096 - val_loss: 0.4165 - val_acc: 0.2444\n",
      "Epoch 7764/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3214 - acc: 0.2096 - val_loss: 0.4397 - val_acc: 0.2407\n",
      "Epoch 7765/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3225 - acc: 0.2087 - val_loss: 0.3838 - val_acc: 0.2444\n",
      "Epoch 7766/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3357 - acc: 0.2092 - val_loss: 0.4370 - val_acc: 0.2444\n",
      "Epoch 7767/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3206 - acc: 0.2096 - val_loss: 0.3896 - val_acc: 0.2444\n",
      "Epoch 7768/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3215 - acc: 0.2096 - val_loss: 0.3949 - val_acc: 0.2444\n",
      "Epoch 7769/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3535 - acc: 0.2096 - val_loss: 0.3858 - val_acc: 0.2444\n",
      "Epoch 7770/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3252 - acc: 0.2096 - val_loss: 0.4184 - val_acc: 0.2444\n",
      "Epoch 7771/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3274 - acc: 0.2087 - val_loss: 0.3911 - val_acc: 0.2444\n",
      "Epoch 7772/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3228 - acc: 0.2092 - val_loss: 0.3975 - val_acc: 0.2444\n",
      "Epoch 7773/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3361 - acc: 0.2087 - val_loss: 0.4732 - val_acc: 0.2407\n",
      "Epoch 7774/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3581 - acc: 0.2100 - val_loss: 0.5116 - val_acc: 0.2407\n",
      "Epoch 7775/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3299 - acc: 0.2096 - val_loss: 0.3907 - val_acc: 0.2444\n",
      "Epoch 7776/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3281 - acc: 0.2096 - val_loss: 0.3908 - val_acc: 0.2444\n",
      "Epoch 7777/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3269 - acc: 0.2092 - val_loss: 0.4149 - val_acc: 0.2407\n",
      "Epoch 7778/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3324 - acc: 0.2092 - val_loss: 0.4134 - val_acc: 0.2444\n",
      "Epoch 7779/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3305 - acc: 0.2087 - val_loss: 0.4699 - val_acc: 0.2444\n",
      "Epoch 7780/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3385 - acc: 0.2092 - val_loss: 0.4635 - val_acc: 0.2444\n",
      "Epoch 7781/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3466 - acc: 0.2100 - val_loss: 0.4008 - val_acc: 0.2444\n",
      "Epoch 7782/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3336 - acc: 0.2096 - val_loss: 0.4527 - val_acc: 0.2444\n",
      "Epoch 7783/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3327 - acc: 0.2096 - val_loss: 0.4005 - val_acc: 0.2444\n",
      "Epoch 7784/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3305 - acc: 0.2087 - val_loss: 0.3958 - val_acc: 0.2444\n",
      "Epoch 7785/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3439 - acc: 0.2092 - val_loss: 0.4311 - val_acc: 0.2444\n",
      "Epoch 7786/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3296 - acc: 0.2096 - val_loss: 0.3928 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7787/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3303 - acc: 0.2096 - val_loss: 0.4161 - val_acc: 0.2444\n",
      "Epoch 7788/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3576 - acc: 0.2087 - val_loss: 0.5618 - val_acc: 0.2407\n",
      "Epoch 7789/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3730 - acc: 0.2096 - val_loss: 0.3833 - val_acc: 0.2444\n",
      "Epoch 7790/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3454 - acc: 0.2096 - val_loss: 0.3879 - val_acc: 0.2444\n",
      "Epoch 7791/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3513 - acc: 0.2096 - val_loss: 0.4118 - val_acc: 0.2444\n",
      "Epoch 7792/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3365 - acc: 0.2092 - val_loss: 0.4177 - val_acc: 0.2407\n",
      "Epoch 7793/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3370 - acc: 0.2083 - val_loss: 0.3951 - val_acc: 0.2444\n",
      "Epoch 7794/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3262 - acc: 0.2092 - val_loss: 0.4225 - val_acc: 0.2444\n",
      "Epoch 7795/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3344 - acc: 0.2087 - val_loss: 0.4195 - val_acc: 0.2444\n",
      "Epoch 7796/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3439 - acc: 0.2096 - val_loss: 0.3785 - val_acc: 0.2444\n",
      "Epoch 7797/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3269 - acc: 0.2083 - val_loss: 0.3844 - val_acc: 0.2444\n",
      "Epoch 7798/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3153 - acc: 0.2092 - val_loss: 0.4326 - val_acc: 0.2407\n",
      "Epoch 7799/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3340 - acc: 0.2092 - val_loss: 0.3969 - val_acc: 0.2444\n",
      "Epoch 7800/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3517 - acc: 0.2092 - val_loss: 0.3869 - val_acc: 0.2444\n",
      "Epoch 7801/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3418 - acc: 0.2092 - val_loss: 0.4064 - val_acc: 0.2444\n",
      "Epoch 7802/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3449 - acc: 0.2083 - val_loss: 0.4636 - val_acc: 0.2407\n",
      "Epoch 7803/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3603 - acc: 0.2087 - val_loss: 0.4421 - val_acc: 0.2407\n",
      "Epoch 7804/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3536 - acc: 0.2092 - val_loss: 0.4454 - val_acc: 0.2407\n",
      "Epoch 7805/10000\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.3226 - acc: 0.209 - 2s 32ms/step - loss: 0.3318 - acc: 0.2096 - val_loss: 0.3948 - val_acc: 0.2444\n",
      "Epoch 7806/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3233 - acc: 0.2092 - val_loss: 0.3933 - val_acc: 0.2444\n",
      "Epoch 7807/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3565 - acc: 0.2092 - val_loss: 0.4653 - val_acc: 0.2407\n",
      "Epoch 7808/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3321 - acc: 0.2100 - val_loss: 0.4176 - val_acc: 0.2444\n",
      "Epoch 7809/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3547 - acc: 0.2087 - val_loss: 0.4284 - val_acc: 0.2407\n",
      "Epoch 7810/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3276 - acc: 0.2096 - val_loss: 0.3885 - val_acc: 0.2444\n",
      "Epoch 7811/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3329 - acc: 0.2096 - val_loss: 0.4126 - val_acc: 0.2444\n",
      "Epoch 7812/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3236 - acc: 0.2096 - val_loss: 0.3908 - val_acc: 0.2444\n",
      "Epoch 7813/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3199 - acc: 0.2092 - val_loss: 0.3901 - val_acc: 0.2444\n",
      "Epoch 7814/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3358 - acc: 0.2092 - val_loss: 0.3852 - val_acc: 0.2444\n",
      "Epoch 7815/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3294 - acc: 0.2096 - val_loss: 0.4826 - val_acc: 0.2444\n",
      "Epoch 7816/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3297 - acc: 0.2087 - val_loss: 0.4437 - val_acc: 0.2407\n",
      "Epoch 7817/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3250 - acc: 0.2087 - val_loss: 0.3841 - val_acc: 0.2444\n",
      "Epoch 7818/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3235 - acc: 0.2092 - val_loss: 0.4180 - val_acc: 0.2444\n",
      "Epoch 7819/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3313 - acc: 0.2100 - val_loss: 0.4041 - val_acc: 0.2444\n",
      "Epoch 7820/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3415 - acc: 0.2096 - val_loss: 0.4041 - val_acc: 0.2444\n",
      "Epoch 7821/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3409 - acc: 0.2092 - val_loss: 0.4007 - val_acc: 0.2444\n",
      "Epoch 7822/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3219 - acc: 0.2087 - val_loss: 0.3876 - val_acc: 0.2444\n",
      "Epoch 7823/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3496 - acc: 0.2087 - val_loss: 0.3959 - val_acc: 0.2444\n",
      "Epoch 7824/10000\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.3312 - acc: 0.208 - 2s 32ms/step - loss: 0.3300 - acc: 0.2100 - val_loss: 0.4788 - val_acc: 0.2444\n",
      "Epoch 7825/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3772 - acc: 0.2100 - val_loss: 0.4324 - val_acc: 0.2444\n",
      "Epoch 7826/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3376 - acc: 0.2096 - val_loss: 0.4321 - val_acc: 0.2444\n",
      "Epoch 7827/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3506 - acc: 0.2096 - val_loss: 0.4157 - val_acc: 0.2444\n",
      "Epoch 7828/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3162 - acc: 0.2092 - val_loss: 0.4095 - val_acc: 0.2444\n",
      "Epoch 7829/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3281 - acc: 0.2092 - val_loss: 0.3885 - val_acc: 0.2444\n",
      "Epoch 7830/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3357 - acc: 0.2083 - val_loss: 0.4768 - val_acc: 0.2444\n",
      "Epoch 7831/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3237 - acc: 0.2092 - val_loss: 0.3923 - val_acc: 0.2444\n",
      "Epoch 7832/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3176 - acc: 0.2087 - val_loss: 0.3891 - val_acc: 0.2444\n",
      "Epoch 7833/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3401 - acc: 0.2096 - val_loss: 0.4067 - val_acc: 0.2444\n",
      "Epoch 7834/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3347 - acc: 0.2096 - val_loss: 0.4202 - val_acc: 0.2444\n",
      "Epoch 7835/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3239 - acc: 0.2096 - val_loss: 0.4848 - val_acc: 0.2407\n",
      "Epoch 7836/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3186 - acc: 0.2087 - val_loss: 0.3990 - val_acc: 0.2444\n",
      "Epoch 7837/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3481 - acc: 0.2087 - val_loss: 0.4069 - val_acc: 0.2444\n",
      "Epoch 7838/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3555 - acc: 0.2096 - val_loss: 0.3870 - val_acc: 0.2444\n",
      "Epoch 7839/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3519 - acc: 0.2096 - val_loss: 0.5013 - val_acc: 0.2407\n",
      "Epoch 7840/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3552 - acc: 0.2096 - val_loss: 0.4022 - val_acc: 0.2444\n",
      "Epoch 7841/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3342 - acc: 0.2092 - val_loss: 0.4420 - val_acc: 0.2444\n",
      "Epoch 7842/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3317 - acc: 0.2096 - val_loss: 0.4367 - val_acc: 0.2444\n",
      "Epoch 7843/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3248 - acc: 0.2092 - val_loss: 0.4010 - val_acc: 0.2444\n",
      "Epoch 7844/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3237 - acc: 0.2092 - val_loss: 0.3978 - val_acc: 0.2444\n",
      "Epoch 7845/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3245 - acc: 0.2092 - val_loss: 0.4254 - val_acc: 0.2444\n",
      "Epoch 7846/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3244 - acc: 0.2096 - val_loss: 0.4365 - val_acc: 0.2444\n",
      "Epoch 7847/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3457 - acc: 0.2096 - val_loss: 0.4343 - val_acc: 0.2444\n",
      "Epoch 7848/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3182 - acc: 0.2087 - val_loss: 0.3959 - val_acc: 0.2444\n",
      "Epoch 7849/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3352 - acc: 0.2096 - val_loss: 0.3874 - val_acc: 0.2444\n",
      "Epoch 7850/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3539 - acc: 0.2096 - val_loss: 0.4811 - val_acc: 0.2444\n",
      "Epoch 7851/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3254 - acc: 0.2092 - val_loss: 0.3982 - val_acc: 0.2444\n",
      "Epoch 7852/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3343 - acc: 0.2092 - val_loss: 0.3861 - val_acc: 0.2444\n",
      "Epoch 7853/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3347 - acc: 0.2092 - val_loss: 0.3789 - val_acc: 0.2444\n",
      "Epoch 7854/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3216 - acc: 0.2092 - val_loss: 0.4620 - val_acc: 0.2407\n",
      "Epoch 7855/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3341 - acc: 0.2083 - val_loss: 0.3764 - val_acc: 0.2444\n",
      "Epoch 7856/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.3297 - acc: 0.2092 - val_loss: 0.4260 - val_acc: 0.2444\n",
      "Epoch 7857/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3236 - acc: 0.2096 - val_loss: 0.3851 - val_acc: 0.2444\n",
      "Epoch 7858/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3391 - acc: 0.2096 - val_loss: 0.3984 - val_acc: 0.2444\n",
      "Epoch 7859/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3306 - acc: 0.2096 - val_loss: 0.4002 - val_acc: 0.2444\n",
      "Epoch 7860/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3204 - acc: 0.2092 - val_loss: 0.4317 - val_acc: 0.2444\n",
      "Epoch 7861/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3471 - acc: 0.2096 - val_loss: 0.3964 - val_acc: 0.2444\n",
      "Epoch 7862/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3317 - acc: 0.2100 - val_loss: 0.3994 - val_acc: 0.2444\n",
      "Epoch 7863/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3329 - acc: 0.2092 - val_loss: 0.3959 - val_acc: 0.2444\n",
      "Epoch 7864/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3246 - acc: 0.2096 - val_loss: 0.3919 - val_acc: 0.2444\n",
      "Epoch 7865/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.3560 - acc: 0.2096 - val_loss: 0.3944 - val_acc: 0.2444\n",
      "Epoch 7866/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.3161 - acc: 0.2087 - val_loss: 0.5591 - val_acc: 0.2444\n",
      "Epoch 7867/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3328 - acc: 0.2092 - val_loss: 0.4330 - val_acc: 0.2444\n",
      "Epoch 7868/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3362 - acc: 0.2096 - val_loss: 0.4134 - val_acc: 0.2444\n",
      "Epoch 7869/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3284 - acc: 0.2096 - val_loss: 0.4237 - val_acc: 0.2444\n",
      "Epoch 7870/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3287 - acc: 0.2100 - val_loss: 0.3913 - val_acc: 0.2444\n",
      "Epoch 7871/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3216 - acc: 0.2087 - val_loss: 0.5357 - val_acc: 0.2407\n",
      "Epoch 7872/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3341 - acc: 0.2092 - val_loss: 0.4435 - val_acc: 0.2444\n",
      "Epoch 7873/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3357 - acc: 0.2096 - val_loss: 0.4718 - val_acc: 0.2444\n",
      "Epoch 7874/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3357 - acc: 0.2092 - val_loss: 0.3959 - val_acc: 0.2444\n",
      "Epoch 7875/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3267 - acc: 0.2087 - val_loss: 0.3770 - val_acc: 0.2444\n",
      "Epoch 7876/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3168 - acc: 0.2092 - val_loss: 0.4037 - val_acc: 0.2444\n",
      "Epoch 7877/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3223 - acc: 0.2092 - val_loss: 0.4015 - val_acc: 0.2444\n",
      "Epoch 7878/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3344 - acc: 0.2092 - val_loss: 0.4094 - val_acc: 0.2444\n",
      "Epoch 7879/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3381 - acc: 0.2092 - val_loss: 0.4226 - val_acc: 0.2407\n",
      "Epoch 7880/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3633 - acc: 0.2096 - val_loss: 0.4144 - val_acc: 0.2407\n",
      "Epoch 7881/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3213 - acc: 0.2092 - val_loss: 0.5186 - val_acc: 0.2444\n",
      "Epoch 7882/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3247 - acc: 0.2096 - val_loss: 0.3962 - val_acc: 0.2444\n",
      "Epoch 7883/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3583 - acc: 0.2092 - val_loss: 0.4068 - val_acc: 0.2444\n",
      "Epoch 7884/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3340 - acc: 0.2092 - val_loss: 0.5201 - val_acc: 0.2407\n",
      "Epoch 7885/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3193 - acc: 0.2096 - val_loss: 0.3949 - val_acc: 0.2444\n",
      "Epoch 7886/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3309 - acc: 0.2087 - val_loss: 0.4070 - val_acc: 0.2444\n",
      "Epoch 7887/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3212 - acc: 0.2096 - val_loss: 0.4168 - val_acc: 0.2444\n",
      "Epoch 7888/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3214 - acc: 0.2100 - val_loss: 0.4806 - val_acc: 0.2444\n",
      "Epoch 7889/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3400 - acc: 0.2100 - val_loss: 0.4149 - val_acc: 0.2444\n",
      "Epoch 7890/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3171 - acc: 0.2092 - val_loss: 0.3873 - val_acc: 0.2444\n",
      "Epoch 7891/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3397 - acc: 0.2100 - val_loss: 0.3993 - val_acc: 0.2444\n",
      "Epoch 7892/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3622 - acc: 0.2092 - val_loss: 0.4559 - val_acc: 0.2444\n",
      "Epoch 7893/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3517 - acc: 0.2096 - val_loss: 0.4054 - val_acc: 0.2444\n",
      "Epoch 7894/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3256 - acc: 0.2092 - val_loss: 0.4431 - val_acc: 0.2444\n",
      "Epoch 7895/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3384 - acc: 0.2100 - val_loss: 0.4000 - val_acc: 0.2444\n",
      "Epoch 7896/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3354 - acc: 0.2096 - val_loss: 0.4040 - val_acc: 0.2444\n",
      "Epoch 7897/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3319 - acc: 0.2092 - val_loss: 0.3937 - val_acc: 0.2444\n",
      "Epoch 7898/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3239 - acc: 0.2096 - val_loss: 0.4005 - val_acc: 0.2444\n",
      "Epoch 7899/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3278 - acc: 0.2087 - val_loss: 0.4250 - val_acc: 0.2407\n",
      "Epoch 7900/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3463 - acc: 0.2087 - val_loss: 0.3819 - val_acc: 0.2444\n",
      "Epoch 7901/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3277 - acc: 0.2100 - val_loss: 0.4042 - val_acc: 0.2444\n",
      "Epoch 7902/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3471 - acc: 0.2092 - val_loss: 0.3916 - val_acc: 0.2444\n",
      "Epoch 7903/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3323 - acc: 0.2096 - val_loss: 0.3921 - val_acc: 0.2444\n",
      "Epoch 7904/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3338 - acc: 0.2092 - val_loss: 0.4419 - val_acc: 0.2407\n",
      "Epoch 7905/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3748 - acc: 0.2092 - val_loss: 0.5390 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7906/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3455 - acc: 0.2087 - val_loss: 0.3954 - val_acc: 0.2444\n",
      "Epoch 7907/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3377 - acc: 0.2096 - val_loss: 0.3870 - val_acc: 0.2444\n",
      "Epoch 7908/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3304 - acc: 0.2092 - val_loss: 0.3966 - val_acc: 0.2444\n",
      "Epoch 7909/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3272 - acc: 0.2087 - val_loss: 0.3973 - val_acc: 0.2444\n",
      "Epoch 7910/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3205 - acc: 0.2083 - val_loss: 0.4834 - val_acc: 0.2444\n",
      "Epoch 7911/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3444 - acc: 0.2092 - val_loss: 0.3873 - val_acc: 0.2444\n",
      "Epoch 7912/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3256 - acc: 0.2087 - val_loss: 0.4050 - val_acc: 0.2444\n",
      "Epoch 7913/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3293 - acc: 0.2087 - val_loss: 0.4213 - val_acc: 0.2444\n",
      "Epoch 7914/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3286 - acc: 0.2100 - val_loss: 0.4015 - val_acc: 0.2444\n",
      "Epoch 7915/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3353 - acc: 0.2087 - val_loss: 0.3843 - val_acc: 0.2444\n",
      "Epoch 7916/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3289 - acc: 0.2100 - val_loss: 0.5107 - val_acc: 0.2444\n",
      "Epoch 7917/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3351 - acc: 0.2096 - val_loss: 0.3803 - val_acc: 0.2444\n",
      "Epoch 7918/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3340 - acc: 0.2096 - val_loss: 0.3923 - val_acc: 0.2444\n",
      "Epoch 7919/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3233 - acc: 0.2100 - val_loss: 0.4315 - val_acc: 0.2444\n",
      "Epoch 7920/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3605 - acc: 0.2087 - val_loss: 0.3943 - val_acc: 0.2444\n",
      "Epoch 7921/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3260 - acc: 0.2096 - val_loss: 0.3982 - val_acc: 0.2444\n",
      "Epoch 7922/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3529 - acc: 0.2092 - val_loss: 0.3970 - val_acc: 0.2444\n",
      "Epoch 7923/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3634 - acc: 0.2096 - val_loss: 0.4873 - val_acc: 0.2444\n",
      "Epoch 7924/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3330 - acc: 0.2096 - val_loss: 0.4208 - val_acc: 0.2444\n",
      "Epoch 7925/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3197 - acc: 0.2100 - val_loss: 0.3826 - val_acc: 0.2444\n",
      "Epoch 7926/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3332 - acc: 0.2087 - val_loss: 0.3974 - val_acc: 0.2444\n",
      "Epoch 7927/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3184 - acc: 0.2092 - val_loss: 0.3994 - val_acc: 0.2444\n",
      "Epoch 7928/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3194 - acc: 0.2092 - val_loss: 0.4582 - val_acc: 0.2444\n",
      "Epoch 7929/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3224 - acc: 0.2092 - val_loss: 0.4099 - val_acc: 0.2444\n",
      "Epoch 7930/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3253 - acc: 0.2096 - val_loss: 0.4152 - val_acc: 0.2407\n",
      "Epoch 7931/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3321 - acc: 0.2092 - val_loss: 0.4018 - val_acc: 0.2444\n",
      "Epoch 7932/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3367 - acc: 0.2096 - val_loss: 0.4078 - val_acc: 0.2444\n",
      "Epoch 7933/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3187 - acc: 0.2096 - val_loss: 0.4383 - val_acc: 0.2444\n",
      "Epoch 7934/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3180 - acc: 0.2092 - val_loss: 0.3858 - val_acc: 0.2444\n",
      "Epoch 7935/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3184 - acc: 0.2092 - val_loss: 0.3974 - val_acc: 0.2444\n",
      "Epoch 7936/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3322 - acc: 0.2100 - val_loss: 0.4857 - val_acc: 0.2444\n",
      "Epoch 7937/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3344 - acc: 0.2092 - val_loss: 0.3861 - val_acc: 0.2444\n",
      "Epoch 7938/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3566 - acc: 0.2087 - val_loss: 0.3891 - val_acc: 0.2444\n",
      "Epoch 7939/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3291 - acc: 0.2096 - val_loss: 0.3922 - val_acc: 0.2444\n",
      "Epoch 7940/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3452 - acc: 0.2096 - val_loss: 0.4000 - val_acc: 0.2444\n",
      "Epoch 7941/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3450 - acc: 0.2079 - val_loss: 0.4020 - val_acc: 0.2444\n",
      "Epoch 7942/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3287 - acc: 0.2092 - val_loss: 0.4181 - val_acc: 0.2444\n",
      "Epoch 7943/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3282 - acc: 0.2087 - val_loss: 0.3890 - val_acc: 0.2444\n",
      "Epoch 7944/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3415 - acc: 0.2096 - val_loss: 0.3869 - val_acc: 0.2444\n",
      "Epoch 7945/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3236 - acc: 0.2096 - val_loss: 0.4022 - val_acc: 0.2444\n",
      "Epoch 7946/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3477 - acc: 0.2092 - val_loss: 0.4975 - val_acc: 0.2444\n",
      "Epoch 7947/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3409 - acc: 0.2087 - val_loss: 0.4170 - val_acc: 0.2444\n",
      "Epoch 7948/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3240 - acc: 0.2092 - val_loss: 0.3876 - val_acc: 0.2444\n",
      "Epoch 7949/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3310 - acc: 0.2092 - val_loss: 0.4923 - val_acc: 0.2407\n",
      "Epoch 7950/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3199 - acc: 0.2100 - val_loss: 0.4308 - val_acc: 0.2407\n",
      "Epoch 7951/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3271 - acc: 0.2096 - val_loss: 0.4000 - val_acc: 0.2444\n",
      "Epoch 7952/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3335 - acc: 0.2092 - val_loss: 0.4361 - val_acc: 0.2444\n",
      "Epoch 7953/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3248 - acc: 0.2083 - val_loss: 0.3912 - val_acc: 0.2444\n",
      "Epoch 7954/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3438 - acc: 0.2083 - val_loss: 0.5507 - val_acc: 0.2407\n",
      "Epoch 7955/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3466 - acc: 0.2079 - val_loss: 0.4441 - val_acc: 0.2407\n",
      "Epoch 7956/10000\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.3401 - acc: 0.208 - 2s 32ms/step - loss: 0.3396 - acc: 0.2087 - val_loss: 0.4057 - val_acc: 0.2444\n",
      "Epoch 7957/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3271 - acc: 0.2092 - val_loss: 0.3895 - val_acc: 0.2444\n",
      "Epoch 7958/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3264 - acc: 0.2100 - val_loss: 0.4051 - val_acc: 0.2444\n",
      "Epoch 7959/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.3308 - acc: 0.2092 - val_loss: 0.4916 - val_acc: 0.2444\n",
      "Epoch 7960/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3297 - acc: 0.2100 - val_loss: 0.4022 - val_acc: 0.2444\n",
      "Epoch 7961/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3215 - acc: 0.2096 - val_loss: 0.4025 - val_acc: 0.2444\n",
      "Epoch 7962/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3340 - acc: 0.2096 - val_loss: 0.3958 - val_acc: 0.2444\n",
      "Epoch 7963/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3345 - acc: 0.2096 - val_loss: 0.3812 - val_acc: 0.2444\n",
      "Epoch 7964/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3346 - acc: 0.2087 - val_loss: 0.3963 - val_acc: 0.2444\n",
      "Epoch 7965/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3294 - acc: 0.2100 - val_loss: 0.4250 - val_acc: 0.2444\n",
      "Epoch 7966/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3680 - acc: 0.2083 - val_loss: 0.3995 - val_acc: 0.2444\n",
      "Epoch 7967/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3369 - acc: 0.2092 - val_loss: 0.3922 - val_acc: 0.2444\n",
      "Epoch 7968/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3404 - acc: 0.2100 - val_loss: 0.4417 - val_acc: 0.2407\n",
      "Epoch 7969/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3201 - acc: 0.2096 - val_loss: 0.3877 - val_acc: 0.2444\n",
      "Epoch 7970/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3176 - acc: 0.2092 - val_loss: 0.3894 - val_acc: 0.2444\n",
      "Epoch 7971/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3573 - acc: 0.2092 - val_loss: 0.4392 - val_acc: 0.2444\n",
      "Epoch 7972/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3369 - acc: 0.2096 - val_loss: 0.4228 - val_acc: 0.2444\n",
      "Epoch 7973/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3539 - acc: 0.2092 - val_loss: 0.3879 - val_acc: 0.2444\n",
      "Epoch 7974/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3930 - acc: 0.2079 - val_loss: 0.4909 - val_acc: 0.2444\n",
      "Epoch 7975/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3273 - acc: 0.2096 - val_loss: 0.4357 - val_acc: 0.2444\n",
      "Epoch 7976/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3288 - acc: 0.2096 - val_loss: 0.4550 - val_acc: 0.2444\n",
      "Epoch 7977/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3222 - acc: 0.2096 - val_loss: 0.4077 - val_acc: 0.2444\n",
      "Epoch 7978/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3228 - acc: 0.2087 - val_loss: 0.4626 - val_acc: 0.2444\n",
      "Epoch 7979/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3368 - acc: 0.2096 - val_loss: 0.3890 - val_acc: 0.2444\n",
      "Epoch 7980/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3457 - acc: 0.2092 - val_loss: 0.3871 - val_acc: 0.2444\n",
      "Epoch 7981/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3236 - acc: 0.2100 - val_loss: 0.3836 - val_acc: 0.2444\n",
      "Epoch 7982/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3236 - acc: 0.2092 - val_loss: 0.3913 - val_acc: 0.2444\n",
      "Epoch 7983/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3391 - acc: 0.2092 - val_loss: 0.3864 - val_acc: 0.2444\n",
      "Epoch 7984/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3217 - acc: 0.2092 - val_loss: 0.4433 - val_acc: 0.2444\n",
      "Epoch 7985/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3398 - acc: 0.2092 - val_loss: 0.4043 - val_acc: 0.2444\n",
      "Epoch 7986/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3725 - acc: 0.2087 - val_loss: 0.4602 - val_acc: 0.2407\n",
      "Epoch 7987/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3270 - acc: 0.2100 - val_loss: 0.4420 - val_acc: 0.2444\n",
      "Epoch 7988/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3198 - acc: 0.2092 - val_loss: 0.4316 - val_acc: 0.2444\n",
      "Epoch 7989/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3353 - acc: 0.2096 - val_loss: 0.3848 - val_acc: 0.2444\n",
      "Epoch 7990/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3336 - acc: 0.2100 - val_loss: 0.4107 - val_acc: 0.2444\n",
      "Epoch 7991/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3232 - acc: 0.2096 - val_loss: 0.3910 - val_acc: 0.2444\n",
      "Epoch 7992/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.3385 - acc: 0.2092 - val_loss: 0.3878 - val_acc: 0.2444\n",
      "Epoch 7993/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3172 - acc: 0.2092 - val_loss: 0.5173 - val_acc: 0.2444\n",
      "Epoch 7994/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.3431 - acc: 0.2083 - val_loss: 0.3836 - val_acc: 0.2444\n",
      "Epoch 7995/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.3223 - acc: 0.2087 - val_loss: 0.4214 - val_acc: 0.2407\n",
      "Epoch 7996/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3302 - acc: 0.2096 - val_loss: 0.4011 - val_acc: 0.2444\n",
      "Epoch 7997/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3267 - acc: 0.2096 - val_loss: 0.4027 - val_acc: 0.2444\n",
      "Epoch 7998/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3181 - acc: 0.2092 - val_loss: 0.3883 - val_acc: 0.2444\n",
      "Epoch 7999/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3276 - acc: 0.2096 - val_loss: 0.4949 - val_acc: 0.2444\n",
      "Epoch 8000/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3462 - acc: 0.2100 - val_loss: 0.4003 - val_acc: 0.2444\n",
      "Epoch 8001/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3579 - acc: 0.2083 - val_loss: 0.3949 - val_acc: 0.2444\n",
      "Epoch 8002/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3280 - acc: 0.2087 - val_loss: 0.4020 - val_acc: 0.2444\n",
      "Epoch 8003/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3275 - acc: 0.2096 - val_loss: 0.3940 - val_acc: 0.2444\n",
      "Epoch 8004/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3313 - acc: 0.2087 - val_loss: 0.4559 - val_acc: 0.2444\n",
      "Epoch 8005/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3734 - acc: 0.2087 - val_loss: 0.3840 - val_acc: 0.2444\n",
      "Epoch 8006/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3199 - acc: 0.2092 - val_loss: 0.3880 - val_acc: 0.2444\n",
      "Epoch 8007/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3165 - acc: 0.2096 - val_loss: 0.4060 - val_acc: 0.2444\n",
      "Epoch 8008/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3224 - acc: 0.2096 - val_loss: 0.3963 - val_acc: 0.2444\n",
      "Epoch 8009/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3529 - acc: 0.2087 - val_loss: 0.4141 - val_acc: 0.2444\n",
      "Epoch 8010/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3504 - acc: 0.2092 - val_loss: 0.4094 - val_acc: 0.2444\n",
      "Epoch 8011/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3342 - acc: 0.2096 - val_loss: 0.3837 - val_acc: 0.2444\n",
      "Epoch 8012/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3308 - acc: 0.2096 - val_loss: 0.3885 - val_acc: 0.2444\n",
      "Epoch 8013/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3393 - acc: 0.2092 - val_loss: 0.4238 - val_acc: 0.2444\n",
      "Epoch 8014/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3313 - acc: 0.2092 - val_loss: 0.4244 - val_acc: 0.2444\n",
      "Epoch 8015/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3483 - acc: 0.2087 - val_loss: 0.3849 - val_acc: 0.2444\n",
      "Epoch 8016/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3438 - acc: 0.2092 - val_loss: 0.4728 - val_acc: 0.2407\n",
      "Epoch 8017/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3298 - acc: 0.2092 - val_loss: 0.4017 - val_acc: 0.2444\n",
      "Epoch 8018/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3166 - acc: 0.2096 - val_loss: 0.4065 - val_acc: 0.2444\n",
      "Epoch 8019/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3267 - acc: 0.2096 - val_loss: 0.3877 - val_acc: 0.2444\n",
      "Epoch 8020/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3177 - acc: 0.2092 - val_loss: 0.4134 - val_acc: 0.2444\n",
      "Epoch 8021/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3233 - acc: 0.2096 - val_loss: 0.4781 - val_acc: 0.2444\n",
      "Epoch 8022/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3254 - acc: 0.2096 - val_loss: 0.3899 - val_acc: 0.2444\n",
      "Epoch 8023/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3216 - acc: 0.2096 - val_loss: 0.4102 - val_acc: 0.2444\n",
      "Epoch 8024/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3244 - acc: 0.2100 - val_loss: 0.4302 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8025/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3591 - acc: 0.2092 - val_loss: 0.3835 - val_acc: 0.2444\n",
      "Epoch 8026/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3473 - acc: 0.2087 - val_loss: 0.3914 - val_acc: 0.2444\n",
      "Epoch 8027/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3465 - acc: 0.2087 - val_loss: 0.3982 - val_acc: 0.2444\n",
      "Epoch 8028/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3345 - acc: 0.2092 - val_loss: 0.4004 - val_acc: 0.2444\n",
      "Epoch 8029/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3461 - acc: 0.2092 - val_loss: 0.4107 - val_acc: 0.2444\n",
      "Epoch 8030/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3335 - acc: 0.2087 - val_loss: 0.4574 - val_acc: 0.2444\n",
      "Epoch 8031/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3596 - acc: 0.2087 - val_loss: 0.4143 - val_acc: 0.2444\n",
      "Epoch 8032/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3230 - acc: 0.2092 - val_loss: 0.3919 - val_acc: 0.2444\n",
      "Epoch 8033/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3210 - acc: 0.2096 - val_loss: 0.4498 - val_acc: 0.2407\n",
      "Epoch 8034/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3424 - acc: 0.2092 - val_loss: 0.3918 - val_acc: 0.2444\n",
      "Epoch 8035/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3249 - acc: 0.2092 - val_loss: 0.3948 - val_acc: 0.2444\n",
      "Epoch 8036/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3269 - acc: 0.2100 - val_loss: 0.4258 - val_acc: 0.2444\n",
      "Epoch 8037/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3328 - acc: 0.2100 - val_loss: 0.4606 - val_acc: 0.2444\n",
      "Epoch 8038/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3447 - acc: 0.2092 - val_loss: 0.4325 - val_acc: 0.2444\n",
      "Epoch 8039/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3316 - acc: 0.2096 - val_loss: 0.4190 - val_acc: 0.2407\n",
      "Epoch 8040/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3260 - acc: 0.2092 - val_loss: 0.4160 - val_acc: 0.2407\n",
      "Epoch 8041/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3376 - acc: 0.2092 - val_loss: 0.4053 - val_acc: 0.2444\n",
      "Epoch 8042/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3163 - acc: 0.2096 - val_loss: 0.4306 - val_acc: 0.2444\n",
      "Epoch 8043/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3336 - acc: 0.2096 - val_loss: 0.4083 - val_acc: 0.2444\n",
      "Epoch 8044/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3245 - acc: 0.2092 - val_loss: 0.3837 - val_acc: 0.2444\n",
      "Epoch 8045/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3325 - acc: 0.2092 - val_loss: 0.3807 - val_acc: 0.2444\n",
      "Epoch 8046/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3247 - acc: 0.2096 - val_loss: 0.4036 - val_acc: 0.2444\n",
      "Epoch 8047/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3274 - acc: 0.2092 - val_loss: 0.4192 - val_acc: 0.2407\n",
      "Epoch 8048/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3243 - acc: 0.2092 - val_loss: 0.3929 - val_acc: 0.2444\n",
      "Epoch 8049/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3265 - acc: 0.2092 - val_loss: 0.4297 - val_acc: 0.2444\n",
      "Epoch 8050/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3285 - acc: 0.2100 - val_loss: 0.3844 - val_acc: 0.2444\n",
      "Epoch 8051/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3202 - acc: 0.2100 - val_loss: 0.4852 - val_acc: 0.2407\n",
      "Epoch 8052/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3356 - acc: 0.2096 - val_loss: 0.4191 - val_acc: 0.2444\n",
      "Epoch 8053/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3662 - acc: 0.2096 - val_loss: 0.4505 - val_acc: 0.2407\n",
      "Epoch 8054/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3440 - acc: 0.2087 - val_loss: 0.3929 - val_acc: 0.2444\n",
      "Epoch 8055/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3252 - acc: 0.2096 - val_loss: 0.3934 - val_acc: 0.2444\n",
      "Epoch 8056/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3277 - acc: 0.2087 - val_loss: 0.3787 - val_acc: 0.2444\n",
      "Epoch 8057/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3236 - acc: 0.2096 - val_loss: 0.3846 - val_acc: 0.2444\n",
      "Epoch 8058/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3257 - acc: 0.2087 - val_loss: 0.4345 - val_acc: 0.2407\n",
      "Epoch 8059/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3226 - acc: 0.2092 - val_loss: 0.3941 - val_acc: 0.2444\n",
      "Epoch 8060/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3208 - acc: 0.2092 - val_loss: 0.4171 - val_acc: 0.2444\n",
      "Epoch 8061/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3220 - acc: 0.2092 - val_loss: 0.3959 - val_acc: 0.2444\n",
      "Epoch 8062/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3823 - acc: 0.2083 - val_loss: 0.4353 - val_acc: 0.2444\n",
      "Epoch 8063/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3508 - acc: 0.2083 - val_loss: 0.3966 - val_acc: 0.2444\n",
      "Epoch 8064/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3345 - acc: 0.2096 - val_loss: 0.3870 - val_acc: 0.2444\n",
      "Epoch 8065/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3155 - acc: 0.2096 - val_loss: 0.4169 - val_acc: 0.2407\n",
      "Epoch 8066/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3212 - acc: 0.2096 - val_loss: 0.4423 - val_acc: 0.2407\n",
      "Epoch 8067/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3340 - acc: 0.2096 - val_loss: 0.3986 - val_acc: 0.2444\n",
      "Epoch 8068/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3271 - acc: 0.2096 - val_loss: 0.3895 - val_acc: 0.2444\n",
      "Epoch 8069/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3207 - acc: 0.2096 - val_loss: 0.3889 - val_acc: 0.2444\n",
      "Epoch 8070/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3306 - acc: 0.2096 - val_loss: 0.3911 - val_acc: 0.2444\n",
      "Epoch 8071/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3173 - acc: 0.2100 - val_loss: 0.3848 - val_acc: 0.2444\n",
      "Epoch 8072/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3294 - acc: 0.2092 - val_loss: 0.5317 - val_acc: 0.2407\n",
      "Epoch 8073/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3264 - acc: 0.2087 - val_loss: 0.4006 - val_acc: 0.2444\n",
      "Epoch 8074/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3232 - acc: 0.2100 - val_loss: 0.3873 - val_acc: 0.2444\n",
      "Epoch 8075/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3198 - acc: 0.2092 - val_loss: 0.4622 - val_acc: 0.2407\n",
      "Epoch 8076/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3908 - acc: 0.2083 - val_loss: 0.4399 - val_acc: 0.2444\n",
      "Epoch 8077/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3267 - acc: 0.2087 - val_loss: 0.4739 - val_acc: 0.2444\n",
      "Epoch 8078/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3492 - acc: 0.2092 - val_loss: 0.4673 - val_acc: 0.2444\n",
      "Epoch 8079/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3397 - acc: 0.2100 - val_loss: 0.4131 - val_acc: 0.2444\n",
      "Epoch 8080/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3483 - acc: 0.2092 - val_loss: 0.3950 - val_acc: 0.2444\n",
      "Epoch 8081/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3251 - acc: 0.2092 - val_loss: 0.4011 - val_acc: 0.2407\n",
      "Epoch 8082/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3406 - acc: 0.2087 - val_loss: 0.3954 - val_acc: 0.2444\n",
      "Epoch 8083/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3293 - acc: 0.2087 - val_loss: 0.4754 - val_acc: 0.2444\n",
      "Epoch 8084/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3261 - acc: 0.2096 - val_loss: 0.4290 - val_acc: 0.2407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8085/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3664 - acc: 0.2083 - val_loss: 0.4055 - val_acc: 0.2407\n",
      "Epoch 8086/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3176 - acc: 0.2100 - val_loss: 0.3971 - val_acc: 0.2444\n",
      "Epoch 8087/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.3324 - acc: 0.2096 - val_loss: 0.3965 - val_acc: 0.2444\n",
      "Epoch 8088/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3196 - acc: 0.2100 - val_loss: 0.4019 - val_acc: 0.2444\n",
      "Epoch 8089/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3359 - acc: 0.2100 - val_loss: 0.3847 - val_acc: 0.2444\n",
      "Epoch 8090/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3281 - acc: 0.2096 - val_loss: 0.3908 - val_acc: 0.2444\n",
      "Epoch 8091/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3388 - acc: 0.2087 - val_loss: 0.3948 - val_acc: 0.2444\n",
      "Epoch 8092/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3411 - acc: 0.2096 - val_loss: 0.3848 - val_acc: 0.2444\n",
      "Epoch 8093/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3266 - acc: 0.2096 - val_loss: 0.4822 - val_acc: 0.2407\n",
      "Epoch 8094/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3172 - acc: 0.2087 - val_loss: 0.3883 - val_acc: 0.2444\n",
      "Epoch 8095/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3413 - acc: 0.2087 - val_loss: 0.4317 - val_acc: 0.2444\n",
      "Epoch 8096/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3426 - acc: 0.2092 - val_loss: 0.3862 - val_acc: 0.2444\n",
      "Epoch 8097/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3184 - acc: 0.2092 - val_loss: 0.4330 - val_acc: 0.2444\n",
      "Epoch 8098/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3475 - acc: 0.2096 - val_loss: 0.3839 - val_acc: 0.2444\n",
      "Epoch 8099/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3296 - acc: 0.2092 - val_loss: 0.3845 - val_acc: 0.2444\n",
      "Epoch 8100/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3309 - acc: 0.2092 - val_loss: 0.4653 - val_acc: 0.2444\n",
      "Epoch 8101/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3282 - acc: 0.2092 - val_loss: 0.3926 - val_acc: 0.2444\n",
      "Epoch 8102/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3370 - acc: 0.2087 - val_loss: 0.4000 - val_acc: 0.2444\n",
      "Epoch 8103/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3504 - acc: 0.2079 - val_loss: 0.5006 - val_acc: 0.2407\n",
      "Epoch 8104/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3527 - acc: 0.2092 - val_loss: 0.3802 - val_acc: 0.2444\n",
      "Epoch 8105/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3339 - acc: 0.2096 - val_loss: 0.5396 - val_acc: 0.2444\n",
      "Epoch 8106/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3582 - acc: 0.2096 - val_loss: 0.3999 - val_acc: 0.2444\n",
      "Epoch 8107/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3224 - acc: 0.2096 - val_loss: 0.3821 - val_acc: 0.2444\n",
      "Epoch 8108/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3321 - acc: 0.2096 - val_loss: 0.3963 - val_acc: 0.2444\n",
      "Epoch 8109/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3283 - acc: 0.2096 - val_loss: 0.4316 - val_acc: 0.2444\n",
      "Epoch 8110/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3167 - acc: 0.2096 - val_loss: 0.4051 - val_acc: 0.2444\n",
      "Epoch 8111/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3169 - acc: 0.2096 - val_loss: 0.4072 - val_acc: 0.2444\n",
      "Epoch 8112/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3161 - acc: 0.2096 - val_loss: 0.4120 - val_acc: 0.2407\n",
      "Epoch 8113/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3323 - acc: 0.2092 - val_loss: 0.3947 - val_acc: 0.2444\n",
      "Epoch 8114/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3213 - acc: 0.2100 - val_loss: 0.3942 - val_acc: 0.2444\n",
      "Epoch 8115/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3372 - acc: 0.2096 - val_loss: 0.3996 - val_acc: 0.2444\n",
      "Epoch 8116/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3375 - acc: 0.2087 - val_loss: 0.4045 - val_acc: 0.2444\n",
      "Epoch 8117/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3267 - acc: 0.2096 - val_loss: 0.3824 - val_acc: 0.2444\n",
      "Epoch 8118/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3202 - acc: 0.2092 - val_loss: 0.3972 - val_acc: 0.2444\n",
      "Epoch 8119/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3447 - acc: 0.2096 - val_loss: 0.4197 - val_acc: 0.2407\n",
      "Epoch 8120/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3168 - acc: 0.2092 - val_loss: 0.3984 - val_acc: 0.2444\n",
      "Epoch 8121/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3788 - acc: 0.2087 - val_loss: 0.4446 - val_acc: 0.2407\n",
      "Epoch 8122/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3268 - acc: 0.2092 - val_loss: 0.3938 - val_acc: 0.2444\n",
      "Epoch 8123/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3471 - acc: 0.2092 - val_loss: 0.5490 - val_acc: 0.2407\n",
      "Epoch 8124/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3589 - acc: 0.2083 - val_loss: 0.3849 - val_acc: 0.2444\n",
      "Epoch 8125/10000\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 0.3248 - acc: 0.2087 - val_loss: 0.3907 - val_acc: 0.2444\n",
      "Epoch 8126/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3345 - acc: 0.2087 - val_loss: 0.3918 - val_acc: 0.2444\n",
      "Epoch 8127/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3280 - acc: 0.2092 - val_loss: 0.5513 - val_acc: 0.2407\n",
      "Epoch 8128/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3376 - acc: 0.2083 - val_loss: 0.3947 - val_acc: 0.2444\n",
      "Epoch 8129/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3145 - acc: 0.2096 - val_loss: 0.4629 - val_acc: 0.2444\n",
      "Epoch 8130/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3346 - acc: 0.2100 - val_loss: 0.4367 - val_acc: 0.2444\n",
      "Epoch 8131/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3396 - acc: 0.2096 - val_loss: 0.3937 - val_acc: 0.2444\n",
      "Epoch 8132/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3184 - acc: 0.2092 - val_loss: 0.4108 - val_acc: 0.2444\n",
      "Epoch 8133/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3221 - acc: 0.2100 - val_loss: 0.4406 - val_acc: 0.2444\n",
      "Epoch 8134/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3171 - acc: 0.2096 - val_loss: 0.4090 - val_acc: 0.2444\n",
      "Epoch 8135/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3337 - acc: 0.2092 - val_loss: 0.3900 - val_acc: 0.2444\n",
      "Epoch 8136/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3304 - acc: 0.2096 - val_loss: 0.4390 - val_acc: 0.2444\n",
      "Epoch 8137/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3340 - acc: 0.2087 - val_loss: 0.3927 - val_acc: 0.2444\n",
      "Epoch 8138/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3301 - acc: 0.2092 - val_loss: 0.3924 - val_acc: 0.2444\n",
      "Epoch 8139/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3258 - acc: 0.2096 - val_loss: 0.3969 - val_acc: 0.2444\n",
      "Epoch 8140/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3191 - acc: 0.2092 - val_loss: 0.3863 - val_acc: 0.2444\n",
      "Epoch 8141/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3184 - acc: 0.2092 - val_loss: 0.4104 - val_acc: 0.2444\n",
      "Epoch 8142/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3479 - acc: 0.2083 - val_loss: 0.4031 - val_acc: 0.2444\n",
      "Epoch 8143/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3466 - acc: 0.2092 - val_loss: 0.3916 - val_acc: 0.2444\n",
      "Epoch 8144/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3243 - acc: 0.2087 - val_loss: 0.3860 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8145/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3427 - acc: 0.2096 - val_loss: 0.4148 - val_acc: 0.2444\n",
      "Epoch 8146/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3232 - acc: 0.2096 - val_loss: 0.4111 - val_acc: 0.2407\n",
      "Epoch 8147/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3294 - acc: 0.2096 - val_loss: 0.3881 - val_acc: 0.2444\n",
      "Epoch 8148/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3216 - acc: 0.2096 - val_loss: 0.4013 - val_acc: 0.2444\n",
      "Epoch 8149/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3442 - acc: 0.2092 - val_loss: 0.4310 - val_acc: 0.2444\n",
      "Epoch 8150/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3332 - acc: 0.2096 - val_loss: 0.3935 - val_acc: 0.2444\n",
      "Epoch 8151/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3252 - acc: 0.2087 - val_loss: 0.3926 - val_acc: 0.2444\n",
      "Epoch 8152/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3597 - acc: 0.2087 - val_loss: 0.3974 - val_acc: 0.2444\n",
      "Epoch 8153/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3297 - acc: 0.2092 - val_loss: 0.4180 - val_acc: 0.2444\n",
      "Epoch 8154/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3297 - acc: 0.2092 - val_loss: 0.3909 - val_acc: 0.2444\n",
      "Epoch 8155/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3297 - acc: 0.2096 - val_loss: 0.3942 - val_acc: 0.2444\n",
      "Epoch 8156/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3473 - acc: 0.2092 - val_loss: 0.4013 - val_acc: 0.2407\n",
      "Epoch 8157/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3333 - acc: 0.2100 - val_loss: 0.4160 - val_acc: 0.2407\n",
      "Epoch 8158/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3232 - acc: 0.2092 - val_loss: 0.3949 - val_acc: 0.2444\n",
      "Epoch 8159/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3455 - acc: 0.2083 - val_loss: 0.3867 - val_acc: 0.2444\n",
      "Epoch 8160/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3262 - acc: 0.2087 - val_loss: 0.3859 - val_acc: 0.2444\n",
      "Epoch 8161/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3154 - acc: 0.2092 - val_loss: 0.4024 - val_acc: 0.2407\n",
      "Epoch 8162/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3594 - acc: 0.2092 - val_loss: 0.3948 - val_acc: 0.2444\n",
      "Epoch 8163/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3249 - acc: 0.2092 - val_loss: 0.4212 - val_acc: 0.2444\n",
      "Epoch 8164/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3631 - acc: 0.2096 - val_loss: 0.4131 - val_acc: 0.2444\n",
      "Epoch 8165/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3211 - acc: 0.2100 - val_loss: 0.3861 - val_acc: 0.2444\n",
      "Epoch 8166/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3335 - acc: 0.2100 - val_loss: 0.4674 - val_acc: 0.2444\n",
      "Epoch 8167/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3177 - acc: 0.2100 - val_loss: 0.3913 - val_acc: 0.2444\n",
      "Epoch 8168/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3131 - acc: 0.2096 - val_loss: 0.3753 - val_acc: 0.2444\n",
      "Epoch 8169/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3283 - acc: 0.2083 - val_loss: 0.3885 - val_acc: 0.2444\n",
      "Epoch 8170/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3255 - acc: 0.2096 - val_loss: 0.3904 - val_acc: 0.2444\n",
      "Epoch 8171/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3212 - acc: 0.2092 - val_loss: 0.3902 - val_acc: 0.2444\n",
      "Epoch 8172/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3214 - acc: 0.2096 - val_loss: 0.4750 - val_acc: 0.2407\n",
      "Epoch 8173/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3651 - acc: 0.2087 - val_loss: 0.4586 - val_acc: 0.2444\n",
      "Epoch 8174/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3297 - acc: 0.2096 - val_loss: 0.4015 - val_acc: 0.2444\n",
      "Epoch 8175/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3263 - acc: 0.2096 - val_loss: 0.3906 - val_acc: 0.2444\n",
      "Epoch 8176/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3315 - acc: 0.2096 - val_loss: 0.3930 - val_acc: 0.2444\n",
      "Epoch 8177/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3433 - acc: 0.2087 - val_loss: 0.3827 - val_acc: 0.2444\n",
      "Epoch 8178/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3439 - acc: 0.2100 - val_loss: 0.4754 - val_acc: 0.2444\n",
      "Epoch 8179/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3362 - acc: 0.2096 - val_loss: 0.4200 - val_acc: 0.2444\n",
      "Epoch 8180/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3461 - acc: 0.2096 - val_loss: 0.3989 - val_acc: 0.2444\n",
      "Epoch 8181/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3217 - acc: 0.2087 - val_loss: 0.4017 - val_acc: 0.2444\n",
      "Epoch 8182/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3264 - acc: 0.2092 - val_loss: 0.3860 - val_acc: 0.2444\n",
      "Epoch 8183/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3540 - acc: 0.2092 - val_loss: 0.4049 - val_acc: 0.2444\n",
      "Epoch 8184/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3432 - acc: 0.2100 - val_loss: 0.4545 - val_acc: 0.2444\n",
      "Epoch 8185/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3451 - acc: 0.2087 - val_loss: 0.4046 - val_acc: 0.2444\n",
      "Epoch 8186/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3234 - acc: 0.2100 - val_loss: 0.3948 - val_acc: 0.2444\n",
      "Epoch 8187/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3495 - acc: 0.2087 - val_loss: 0.4945 - val_acc: 0.2407\n",
      "Epoch 8188/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3612 - acc: 0.2087 - val_loss: 0.3833 - val_acc: 0.2444\n",
      "Epoch 8189/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3222 - acc: 0.2096 - val_loss: 0.3952 - val_acc: 0.2444\n",
      "Epoch 8190/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3228 - acc: 0.2096 - val_loss: 0.3825 - val_acc: 0.2444\n",
      "Epoch 8191/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3369 - acc: 0.2087 - val_loss: 0.3792 - val_acc: 0.2444\n",
      "Epoch 8192/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3278 - acc: 0.2087 - val_loss: 0.5644 - val_acc: 0.2407\n",
      "Epoch 8193/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3508 - acc: 0.2087 - val_loss: 0.5388 - val_acc: 0.2444\n",
      "Epoch 8194/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3357 - acc: 0.2100 - val_loss: 0.4164 - val_acc: 0.2444\n",
      "Epoch 8195/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3188 - acc: 0.2096 - val_loss: 0.4208 - val_acc: 0.2407\n",
      "Epoch 8196/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3161 - acc: 0.2096 - val_loss: 0.5110 - val_acc: 0.2444\n",
      "Epoch 8197/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3204 - acc: 0.2100 - val_loss: 0.4276 - val_acc: 0.2444\n",
      "Epoch 8198/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3432 - acc: 0.2092 - val_loss: 0.5406 - val_acc: 0.2444\n",
      "Epoch 8199/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3235 - acc: 0.2096 - val_loss: 0.4238 - val_acc: 0.2407\n",
      "Epoch 8200/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3221 - acc: 0.2087 - val_loss: 0.3874 - val_acc: 0.2444\n",
      "Epoch 8201/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3229 - acc: 0.2087 - val_loss: 0.4093 - val_acc: 0.2444\n",
      "Epoch 8202/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3336 - acc: 0.2092 - val_loss: 0.3910 - val_acc: 0.2444\n",
      "Epoch 8203/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3254 - acc: 0.2096 - val_loss: 0.3979 - val_acc: 0.2444\n",
      "Epoch 8204/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3295 - acc: 0.2096 - val_loss: 0.4290 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8205/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3236 - acc: 0.2092 - val_loss: 0.4397 - val_acc: 0.2444\n",
      "Epoch 8206/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3163 - acc: 0.2092 - val_loss: 0.3992 - val_acc: 0.2444\n",
      "Epoch 8207/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3446 - acc: 0.2092 - val_loss: 0.3831 - val_acc: 0.2444\n",
      "Epoch 8208/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3175 - acc: 0.2096 - val_loss: 0.3964 - val_acc: 0.2444\n",
      "Epoch 8209/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3216 - acc: 0.2092 - val_loss: 0.4894 - val_acc: 0.2444\n",
      "Epoch 8210/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3304 - acc: 0.2092 - val_loss: 0.4344 - val_acc: 0.2407\n",
      "Epoch 8211/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3466 - acc: 0.2092 - val_loss: 0.3941 - val_acc: 0.2444\n",
      "Epoch 8212/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3555 - acc: 0.2100 - val_loss: 0.3740 - val_acc: 0.2444\n",
      "Epoch 8213/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3439 - acc: 0.2087 - val_loss: 0.4006 - val_acc: 0.2444\n",
      "Epoch 8214/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3241 - acc: 0.2096 - val_loss: 0.3898 - val_acc: 0.2444\n",
      "Epoch 8215/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3214 - acc: 0.2100 - val_loss: 0.5242 - val_acc: 0.2444\n",
      "Epoch 8216/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3264 - acc: 0.2100 - val_loss: 0.3949 - val_acc: 0.2444\n",
      "Epoch 8217/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3241 - acc: 0.2092 - val_loss: 0.3863 - val_acc: 0.2444\n",
      "Epoch 8218/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3119 - acc: 0.2092 - val_loss: 0.3809 - val_acc: 0.2444\n",
      "Epoch 8219/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3323 - acc: 0.2096 - val_loss: 0.3847 - val_acc: 0.2444\n",
      "Epoch 8220/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3147 - acc: 0.2100 - val_loss: 0.3791 - val_acc: 0.2444\n",
      "Epoch 8221/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3192 - acc: 0.2096 - val_loss: 0.3905 - val_acc: 0.2444\n",
      "Epoch 8222/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3467 - acc: 0.2092 - val_loss: 0.4324 - val_acc: 0.2444\n",
      "Epoch 8223/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3158 - acc: 0.2096 - val_loss: 0.3901 - val_acc: 0.2444\n",
      "Epoch 8224/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3517 - acc: 0.2092 - val_loss: 0.3887 - val_acc: 0.2444\n",
      "Epoch 8225/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3213 - acc: 0.2100 - val_loss: 0.3844 - val_acc: 0.2444\n",
      "Epoch 8226/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3278 - acc: 0.2096 - val_loss: 0.5060 - val_acc: 0.2444\n",
      "Epoch 8227/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3318 - acc: 0.2092 - val_loss: 0.3893 - val_acc: 0.2444\n",
      "Epoch 8228/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3323 - acc: 0.2092 - val_loss: 0.4559 - val_acc: 0.2407\n",
      "Epoch 8229/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3193 - acc: 0.2087 - val_loss: 0.4465 - val_acc: 0.2407\n",
      "Epoch 8230/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3597 - acc: 0.2092 - val_loss: 0.3888 - val_acc: 0.2444\n",
      "Epoch 8231/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3158 - acc: 0.2092 - val_loss: 0.3893 - val_acc: 0.2444\n",
      "Epoch 8232/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3343 - acc: 0.2092 - val_loss: 0.3866 - val_acc: 0.2444\n",
      "Epoch 8233/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3236 - acc: 0.2092 - val_loss: 0.3908 - val_acc: 0.2444\n",
      "Epoch 8234/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3230 - acc: 0.2087 - val_loss: 0.4037 - val_acc: 0.2444\n",
      "Epoch 8235/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3480 - acc: 0.2100 - val_loss: 0.5207 - val_acc: 0.2407\n",
      "Epoch 8236/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3412 - acc: 0.2092 - val_loss: 0.3958 - val_acc: 0.2444\n",
      "Epoch 8237/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3582 - acc: 0.2096 - val_loss: 0.5065 - val_acc: 0.2444\n",
      "Epoch 8238/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3431 - acc: 0.2083 - val_loss: 0.4140 - val_acc: 0.2444\n",
      "Epoch 8239/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3139 - acc: 0.2100 - val_loss: 0.3893 - val_acc: 0.2444\n",
      "Epoch 8240/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3317 - acc: 0.2092 - val_loss: 0.3961 - val_acc: 0.2444\n",
      "Epoch 8241/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3580 - acc: 0.2083 - val_loss: 0.4750 - val_acc: 0.2407\n",
      "Epoch 8242/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3296 - acc: 0.2087 - val_loss: 0.3825 - val_acc: 0.2444\n",
      "Epoch 8243/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3197 - acc: 0.2096 - val_loss: 0.3860 - val_acc: 0.2444\n",
      "Epoch 8244/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3223 - acc: 0.2092 - val_loss: 0.3746 - val_acc: 0.2444\n",
      "Epoch 8245/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3240 - acc: 0.2100 - val_loss: 0.4843 - val_acc: 0.2407\n",
      "Epoch 8246/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3197 - acc: 0.2092 - val_loss: 0.4638 - val_acc: 0.2444\n",
      "Epoch 8247/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3339 - acc: 0.2087 - val_loss: 0.5292 - val_acc: 0.2407\n",
      "Epoch 8248/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3332 - acc: 0.2096 - val_loss: 0.4176 - val_acc: 0.2444\n",
      "Epoch 8249/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3263 - acc: 0.2100 - val_loss: 0.4615 - val_acc: 0.2444\n",
      "Epoch 8250/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3206 - acc: 0.2100 - val_loss: 0.3833 - val_acc: 0.2444\n",
      "Epoch 8251/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3242 - acc: 0.2092 - val_loss: 0.3857 - val_acc: 0.2444\n",
      "Epoch 8252/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3223 - acc: 0.2096 - val_loss: 0.3953 - val_acc: 0.2444\n",
      "Epoch 8253/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3366 - acc: 0.2092 - val_loss: 0.4003 - val_acc: 0.2444\n",
      "Epoch 8254/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3573 - acc: 0.2096 - val_loss: 0.4528 - val_acc: 0.2444\n",
      "Epoch 8255/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3599 - acc: 0.2096 - val_loss: 0.3856 - val_acc: 0.2444\n",
      "Epoch 8256/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3163 - acc: 0.2092 - val_loss: 0.3830 - val_acc: 0.2444\n",
      "Epoch 8257/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3306 - acc: 0.2100 - val_loss: 0.3981 - val_acc: 0.2444\n",
      "Epoch 8258/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.3283 - acc: 0.2096 - val_loss: 0.4168 - val_acc: 0.2444\n",
      "Epoch 8259/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3213 - acc: 0.2096 - val_loss: 0.3906 - val_acc: 0.2444\n",
      "Epoch 8260/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3251 - acc: 0.2092 - val_loss: 0.3821 - val_acc: 0.2444\n",
      "Epoch 8261/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3263 - acc: 0.2096 - val_loss: 0.4415 - val_acc: 0.2407\n",
      "Epoch 8262/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3428 - acc: 0.2092 - val_loss: 0.4584 - val_acc: 0.2407\n",
      "Epoch 8263/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3401 - acc: 0.2096 - val_loss: 0.4703 - val_acc: 0.2444\n",
      "Epoch 8264/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3166 - acc: 0.2092 - val_loss: 0.3990 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8265/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3434 - acc: 0.2092 - val_loss: 0.3787 - val_acc: 0.2444\n",
      "Epoch 8266/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3205 - acc: 0.2092 - val_loss: 0.4054 - val_acc: 0.2444\n",
      "Epoch 8267/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3253 - acc: 0.2092 - val_loss: 0.3900 - val_acc: 0.2444\n",
      "Epoch 8268/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3443 - acc: 0.2096 - val_loss: 0.3802 - val_acc: 0.2444\n",
      "Epoch 8269/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3303 - acc: 0.2087 - val_loss: 0.5007 - val_acc: 0.2407\n",
      "Epoch 8270/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3360 - acc: 0.2096 - val_loss: 0.3840 - val_acc: 0.2444\n",
      "Epoch 8271/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3235 - acc: 0.2092 - val_loss: 0.3929 - val_acc: 0.2444\n",
      "Epoch 8272/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3191 - acc: 0.2087 - val_loss: 0.3869 - val_acc: 0.2444\n",
      "Epoch 8273/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3341 - acc: 0.2092 - val_loss: 0.3899 - val_acc: 0.2444\n",
      "Epoch 8274/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3271 - acc: 0.2096 - val_loss: 0.3870 - val_acc: 0.2444\n",
      "Epoch 8275/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3478 - acc: 0.2100 - val_loss: 0.3990 - val_acc: 0.2407\n",
      "Epoch 8276/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3404 - acc: 0.2100 - val_loss: 0.5099 - val_acc: 0.2407\n",
      "Epoch 8277/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3473 - acc: 0.2096 - val_loss: 0.3782 - val_acc: 0.2444\n",
      "Epoch 8278/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3179 - acc: 0.2096 - val_loss: 0.4254 - val_acc: 0.2444\n",
      "Epoch 8279/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3200 - acc: 0.2096 - val_loss: 0.3858 - val_acc: 0.2444\n",
      "Epoch 8280/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3179 - acc: 0.2096 - val_loss: 0.4518 - val_acc: 0.2407\n",
      "Epoch 8281/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3643 - acc: 0.2096 - val_loss: 0.3789 - val_acc: 0.2444\n",
      "Epoch 8282/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3324 - acc: 0.2096 - val_loss: 0.4016 - val_acc: 0.2444\n",
      "Epoch 8283/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3301 - acc: 0.2092 - val_loss: 0.4016 - val_acc: 0.2444\n",
      "Epoch 8284/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3387 - acc: 0.2096 - val_loss: 0.4285 - val_acc: 0.2407\n",
      "Epoch 8285/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3203 - acc: 0.2096 - val_loss: 0.3841 - val_acc: 0.2444\n",
      "Epoch 8286/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3224 - acc: 0.2087 - val_loss: 0.3836 - val_acc: 0.2444\n",
      "Epoch 8287/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3250 - acc: 0.2096 - val_loss: 0.3842 - val_acc: 0.2444\n",
      "Epoch 8288/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3237 - acc: 0.2092 - val_loss: 0.3925 - val_acc: 0.2444\n",
      "Epoch 8289/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3168 - acc: 0.2092 - val_loss: 0.4090 - val_acc: 0.2444\n",
      "Epoch 8290/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3324 - acc: 0.2100 - val_loss: 0.5132 - val_acc: 0.2444\n",
      "Epoch 8291/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3309 - acc: 0.2092 - val_loss: 0.3786 - val_acc: 0.2444\n",
      "Epoch 8292/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3253 - acc: 0.2096 - val_loss: 0.4202 - val_acc: 0.2444\n",
      "Epoch 8293/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3228 - acc: 0.2096 - val_loss: 0.3752 - val_acc: 0.2444\n",
      "Epoch 8294/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3397 - acc: 0.2092 - val_loss: 0.4188 - val_acc: 0.2444\n",
      "Epoch 8295/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3163 - acc: 0.2092 - val_loss: 0.4169 - val_acc: 0.2444\n",
      "Epoch 8296/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3370 - acc: 0.2092 - val_loss: 0.4455 - val_acc: 0.2444\n",
      "Epoch 8297/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3268 - acc: 0.2092 - val_loss: 0.3792 - val_acc: 0.2444\n",
      "Epoch 8298/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3338 - acc: 0.2096 - val_loss: 0.3869 - val_acc: 0.2444\n",
      "Epoch 8299/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3242 - acc: 0.2096 - val_loss: 0.3934 - val_acc: 0.2444\n",
      "Epoch 8300/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3152 - acc: 0.2096 - val_loss: 0.3916 - val_acc: 0.2444\n",
      "Epoch 8301/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3264 - acc: 0.2087 - val_loss: 0.4151 - val_acc: 0.2444\n",
      "Epoch 8302/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3193 - acc: 0.2083 - val_loss: 0.3869 - val_acc: 0.2444\n",
      "Epoch 8303/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3374 - acc: 0.2087 - val_loss: 0.3822 - val_acc: 0.2444\n",
      "Epoch 8304/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3506 - acc: 0.2092 - val_loss: 0.4076 - val_acc: 0.2444\n",
      "Epoch 8305/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3174 - acc: 0.2100 - val_loss: 0.3915 - val_acc: 0.2444\n",
      "Epoch 8306/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3325 - acc: 0.2096 - val_loss: 0.4045 - val_acc: 0.2444\n",
      "Epoch 8307/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3160 - acc: 0.2092 - val_loss: 0.3797 - val_acc: 0.2444\n",
      "Epoch 8308/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3231 - acc: 0.2083 - val_loss: 0.3873 - val_acc: 0.2444\n",
      "Epoch 8309/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3436 - acc: 0.2096 - val_loss: 0.3844 - val_acc: 0.2444\n",
      "Epoch 8310/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3278 - acc: 0.2079 - val_loss: 0.3952 - val_acc: 0.2444\n",
      "Epoch 8311/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3447 - acc: 0.2083 - val_loss: 0.3907 - val_acc: 0.2444\n",
      "Epoch 8312/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3452 - acc: 0.2087 - val_loss: 0.4461 - val_acc: 0.2444\n",
      "Epoch 8313/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3471 - acc: 0.2100 - val_loss: 0.4292 - val_acc: 0.2444\n",
      "Epoch 8314/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3320 - acc: 0.2092 - val_loss: 0.4210 - val_acc: 0.2444\n",
      "Epoch 8315/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3319 - acc: 0.2092 - val_loss: 0.3991 - val_acc: 0.2444\n",
      "Epoch 8316/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3262 - acc: 0.2092 - val_loss: 0.3864 - val_acc: 0.2444\n",
      "Epoch 8317/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3269 - acc: 0.2087 - val_loss: 0.3870 - val_acc: 0.2444\n",
      "Epoch 8318/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3319 - acc: 0.2083 - val_loss: 0.6726 - val_acc: 0.2444\n",
      "Epoch 8319/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3608 - acc: 0.2092 - val_loss: 0.4097 - val_acc: 0.2444\n",
      "Epoch 8320/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3237 - acc: 0.2100 - val_loss: 0.3797 - val_acc: 0.2444\n",
      "Epoch 8321/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3257 - acc: 0.2092 - val_loss: 0.3790 - val_acc: 0.2444\n",
      "Epoch 8322/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3143 - acc: 0.2096 - val_loss: 0.5185 - val_acc: 0.2444\n",
      "Epoch 8323/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3402 - acc: 0.2087 - val_loss: 0.3832 - val_acc: 0.2444\n",
      "Epoch 8324/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3261 - acc: 0.2087 - val_loss: 0.3909 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8325/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3147 - acc: 0.2100 - val_loss: 0.4335 - val_acc: 0.2444\n",
      "Epoch 8326/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3643 - acc: 0.2083 - val_loss: 0.3878 - val_acc: 0.2444\n",
      "Epoch 8327/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3325 - acc: 0.2087 - val_loss: 0.4064 - val_acc: 0.2444\n",
      "Epoch 8328/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3255 - acc: 0.2096 - val_loss: 0.4179 - val_acc: 0.2444\n",
      "Epoch 8329/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3165 - acc: 0.2092 - val_loss: 0.3966 - val_acc: 0.2444\n",
      "Epoch 8330/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3261 - acc: 0.2087 - val_loss: 0.3710 - val_acc: 0.2444\n",
      "Epoch 8331/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3508 - acc: 0.2087 - val_loss: 0.4527 - val_acc: 0.2444\n",
      "Epoch 8332/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3648 - acc: 0.2087 - val_loss: 0.4019 - val_acc: 0.2444\n",
      "Epoch 8333/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3232 - acc: 0.2100 - val_loss: 0.3858 - val_acc: 0.2444\n",
      "Epoch 8334/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3280 - acc: 0.2096 - val_loss: 0.4416 - val_acc: 0.2407\n",
      "Epoch 8335/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3211 - acc: 0.2087 - val_loss: 0.3841 - val_acc: 0.2444\n",
      "Epoch 8336/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3131 - acc: 0.2096 - val_loss: 0.3872 - val_acc: 0.2444\n",
      "Epoch 8337/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3216 - acc: 0.2096 - val_loss: 0.3793 - val_acc: 0.2444\n",
      "Epoch 8338/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3326 - acc: 0.2083 - val_loss: 0.3880 - val_acc: 0.2444\n",
      "Epoch 8339/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3215 - acc: 0.2092 - val_loss: 0.4642 - val_acc: 0.2444\n",
      "Epoch 8340/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3374 - acc: 0.2092 - val_loss: 0.3995 - val_acc: 0.2444\n",
      "Epoch 8341/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3295 - acc: 0.2087 - val_loss: 0.4137 - val_acc: 0.2444\n",
      "Epoch 8342/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3314 - acc: 0.2096 - val_loss: 0.3977 - val_acc: 0.2444\n",
      "Epoch 8343/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3542 - acc: 0.2083 - val_loss: 0.4210 - val_acc: 0.2444\n",
      "Epoch 8344/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3555 - acc: 0.2092 - val_loss: 0.3851 - val_acc: 0.2444\n",
      "Epoch 8345/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3289 - acc: 0.2087 - val_loss: 0.4061 - val_acc: 0.2444\n",
      "Epoch 8346/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3348 - acc: 0.2100 - val_loss: 0.3841 - val_acc: 0.2444\n",
      "Epoch 8347/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3112 - acc: 0.2087 - val_loss: 0.4131 - val_acc: 0.2444\n",
      "Epoch 8348/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3343 - acc: 0.2096 - val_loss: 0.3957 - val_acc: 0.2444\n",
      "Epoch 8349/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3335 - acc: 0.2096 - val_loss: 0.4250 - val_acc: 0.2444\n",
      "Epoch 8350/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3422 - acc: 0.2096 - val_loss: 0.3887 - val_acc: 0.2444\n",
      "Epoch 8351/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3124 - acc: 0.2087 - val_loss: 0.4254 - val_acc: 0.2444\n",
      "Epoch 8352/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3168 - acc: 0.2087 - val_loss: 0.3859 - val_acc: 0.2444\n",
      "Epoch 8353/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3352 - acc: 0.2096 - val_loss: 0.4618 - val_acc: 0.2407\n",
      "Epoch 8354/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3420 - acc: 0.2087 - val_loss: 0.4510 - val_acc: 0.2407\n",
      "Epoch 8355/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3384 - acc: 0.2092 - val_loss: 0.4112 - val_acc: 0.2444\n",
      "Epoch 8356/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3327 - acc: 0.2092 - val_loss: 0.4139 - val_acc: 0.2444\n",
      "Epoch 8357/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3506 - acc: 0.2100 - val_loss: 0.3791 - val_acc: 0.2444\n",
      "Epoch 8358/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3265 - acc: 0.2087 - val_loss: 0.4017 - val_acc: 0.2407\n",
      "Epoch 8359/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3368 - acc: 0.2083 - val_loss: 0.4133 - val_acc: 0.2444\n",
      "Epoch 8360/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3232 - acc: 0.2087 - val_loss: 0.3970 - val_acc: 0.2444\n",
      "Epoch 8361/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3695 - acc: 0.2087 - val_loss: 0.4023 - val_acc: 0.2444\n",
      "Epoch 8362/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3323 - acc: 0.2100 - val_loss: 0.4267 - val_acc: 0.2444\n",
      "Epoch 8363/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3259 - acc: 0.2096 - val_loss: 0.3997 - val_acc: 0.2444\n",
      "Epoch 8364/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3330 - acc: 0.2096 - val_loss: 0.4405 - val_acc: 0.2407\n",
      "Epoch 8365/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3557 - acc: 0.2087 - val_loss: 0.4016 - val_acc: 0.2444\n",
      "Epoch 8366/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3504 - acc: 0.2087 - val_loss: 0.4569 - val_acc: 0.2407\n",
      "Epoch 8367/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3196 - acc: 0.2087 - val_loss: 0.3931 - val_acc: 0.2444\n",
      "Epoch 8368/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3380 - acc: 0.2087 - val_loss: 0.4064 - val_acc: 0.2444\n",
      "Epoch 8369/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3350 - acc: 0.2092 - val_loss: 0.3829 - val_acc: 0.2444\n",
      "Epoch 8370/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3371 - acc: 0.2087 - val_loss: 0.3849 - val_acc: 0.2444\n",
      "Epoch 8371/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3124 - acc: 0.2092 - val_loss: 0.4053 - val_acc: 0.2444\n",
      "Epoch 8372/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3355 - acc: 0.2087 - val_loss: 0.4287 - val_acc: 0.2444\n",
      "Epoch 8373/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3135 - acc: 0.2096 - val_loss: 0.4071 - val_acc: 0.2444\n",
      "Epoch 8374/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3355 - acc: 0.2096 - val_loss: 0.3825 - val_acc: 0.2444\n",
      "Epoch 8375/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3704 - acc: 0.2083 - val_loss: 0.4904 - val_acc: 0.2444\n",
      "Epoch 8376/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3348 - acc: 0.2092 - val_loss: 0.3947 - val_acc: 0.2444\n",
      "Epoch 8377/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3298 - acc: 0.2096 - val_loss: 0.3916 - val_acc: 0.2444\n",
      "Epoch 8378/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3251 - acc: 0.2096 - val_loss: 0.4362 - val_acc: 0.2444\n",
      "Epoch 8379/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3459 - acc: 0.2092 - val_loss: 0.4067 - val_acc: 0.2444\n",
      "Epoch 8380/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3611 - acc: 0.2087 - val_loss: 0.4146 - val_acc: 0.2444\n",
      "Epoch 8381/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3344 - acc: 0.2092 - val_loss: 0.3742 - val_acc: 0.2444\n",
      "Epoch 8382/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3401 - acc: 0.2087 - val_loss: 0.3869 - val_acc: 0.2444\n",
      "Epoch 8383/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3497 - acc: 0.2092 - val_loss: 0.3909 - val_acc: 0.2444\n",
      "Epoch 8384/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3094 - acc: 0.2100 - val_loss: 0.4032 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8385/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3344 - acc: 0.2092 - val_loss: 0.4128 - val_acc: 0.2444\n",
      "Epoch 8386/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3251 - acc: 0.2100 - val_loss: 0.4007 - val_acc: 0.2444\n",
      "Epoch 8387/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3153 - acc: 0.2092 - val_loss: 0.4148 - val_acc: 0.2444\n",
      "Epoch 8388/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3195 - acc: 0.2096 - val_loss: 0.3803 - val_acc: 0.2444\n",
      "Epoch 8389/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3329 - acc: 0.2087 - val_loss: 0.3868 - val_acc: 0.2444\n",
      "Epoch 8390/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3226 - acc: 0.2100 - val_loss: 0.4413 - val_acc: 0.2407\n",
      "Epoch 8391/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.3325 - acc: 0.2087 - val_loss: 0.4347 - val_acc: 0.2407\n",
      "Epoch 8392/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3143 - acc: 0.2096 - val_loss: 0.4244 - val_acc: 0.2444\n",
      "Epoch 8393/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3177 - acc: 0.2100 - val_loss: 0.3867 - val_acc: 0.2444\n",
      "Epoch 8394/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3279 - acc: 0.2087 - val_loss: 0.5471 - val_acc: 0.2407\n",
      "Epoch 8395/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3379 - acc: 0.2096 - val_loss: 0.4061 - val_acc: 0.2444\n",
      "Epoch 8396/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3600 - acc: 0.2087 - val_loss: 0.3971 - val_acc: 0.2444\n",
      "Epoch 8397/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3218 - acc: 0.2100 - val_loss: 0.4053 - val_acc: 0.2444\n",
      "Epoch 8398/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3200 - acc: 0.2096 - val_loss: 0.4114 - val_acc: 0.2444\n",
      "Epoch 8399/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.3266 - acc: 0.2083 - val_loss: 0.4693 - val_acc: 0.2444\n",
      "Epoch 8400/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3244 - acc: 0.2092 - val_loss: 0.4418 - val_acc: 0.2407\n",
      "Epoch 8401/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3553 - acc: 0.2087 - val_loss: 0.4861 - val_acc: 0.2444\n",
      "Epoch 8402/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3268 - acc: 0.2100 - val_loss: 0.3881 - val_acc: 0.2444\n",
      "Epoch 8403/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3219 - acc: 0.2092 - val_loss: 0.3847 - val_acc: 0.2444\n",
      "Epoch 8404/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3112 - acc: 0.2087 - val_loss: 0.4436 - val_acc: 0.2444\n",
      "Epoch 8405/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3246 - acc: 0.2087 - val_loss: 0.4759 - val_acc: 0.2444\n",
      "Epoch 8406/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3187 - acc: 0.2096 - val_loss: 0.4231 - val_acc: 0.2444\n",
      "Epoch 8407/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3261 - acc: 0.2100 - val_loss: 0.3951 - val_acc: 0.2444\n",
      "Epoch 8408/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3451 - acc: 0.2092 - val_loss: 0.4103 - val_acc: 0.2444\n",
      "Epoch 8409/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3511 - acc: 0.2096 - val_loss: 0.3704 - val_acc: 0.2444\n",
      "Epoch 8410/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3212 - acc: 0.2096 - val_loss: 0.3895 - val_acc: 0.2444\n",
      "Epoch 8411/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3216 - acc: 0.2092 - val_loss: 0.3866 - val_acc: 0.2444\n",
      "Epoch 8412/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3350 - acc: 0.2079 - val_loss: 0.3906 - val_acc: 0.2444\n",
      "Epoch 8413/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3253 - acc: 0.2083 - val_loss: 0.4197 - val_acc: 0.2444\n",
      "Epoch 8414/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3410 - acc: 0.2096 - val_loss: 0.4015 - val_acc: 0.2444\n",
      "Epoch 8415/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3261 - acc: 0.2096 - val_loss: 0.4828 - val_acc: 0.2444\n",
      "Epoch 8416/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3317 - acc: 0.2100 - val_loss: 0.3867 - val_acc: 0.2444\n",
      "Epoch 8417/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3347 - acc: 0.2100 - val_loss: 0.3823 - val_acc: 0.2444\n",
      "Epoch 8418/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3287 - acc: 0.2092 - val_loss: 0.4010 - val_acc: 0.2407\n",
      "Epoch 8419/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3410 - acc: 0.2083 - val_loss: 0.4081 - val_acc: 0.2444\n",
      "Epoch 8420/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3150 - acc: 0.2100 - val_loss: 0.4565 - val_acc: 0.2444\n",
      "Epoch 8421/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3191 - acc: 0.2100 - val_loss: 0.3878 - val_acc: 0.2444\n",
      "Epoch 8422/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3139 - acc: 0.2096 - val_loss: 0.4653 - val_acc: 0.2444\n",
      "Epoch 8423/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3469 - acc: 0.2096 - val_loss: 0.4374 - val_acc: 0.2444\n",
      "Epoch 8424/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3317 - acc: 0.2087 - val_loss: 0.3793 - val_acc: 0.2444\n",
      "Epoch 8425/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3317 - acc: 0.2092 - val_loss: 0.3934 - val_acc: 0.2444\n",
      "Epoch 8426/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3256 - acc: 0.2092 - val_loss: 0.4123 - val_acc: 0.2444\n",
      "Epoch 8427/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3295 - acc: 0.2096 - val_loss: 0.3793 - val_acc: 0.2444\n",
      "Epoch 8428/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3305 - acc: 0.2096 - val_loss: 0.3992 - val_acc: 0.2444\n",
      "Epoch 8429/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3251 - acc: 0.2092 - val_loss: 0.4907 - val_acc: 0.2407\n",
      "Epoch 8430/10000\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.3348 - acc: 0.208 - 2s 32ms/step - loss: 0.3443 - acc: 0.2087 - val_loss: 0.4014 - val_acc: 0.2444\n",
      "Epoch 8431/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3240 - acc: 0.2096 - val_loss: 0.4915 - val_acc: 0.2444\n",
      "Epoch 8432/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3623 - acc: 0.2087 - val_loss: 0.3829 - val_acc: 0.2444\n",
      "Epoch 8433/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3194 - acc: 0.2092 - val_loss: 0.3946 - val_acc: 0.2444\n",
      "Epoch 8434/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3150 - acc: 0.2096 - val_loss: 0.3943 - val_acc: 0.2444\n",
      "Epoch 8435/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3361 - acc: 0.2092 - val_loss: 0.4305 - val_acc: 0.2407\n",
      "Epoch 8436/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3343 - acc: 0.2092 - val_loss: 0.4346 - val_acc: 0.2407\n",
      "Epoch 8437/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3304 - acc: 0.2096 - val_loss: 0.3903 - val_acc: 0.2444\n",
      "Epoch 8438/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.3362 - acc: 0.2087 - val_loss: 0.4040 - val_acc: 0.2444\n",
      "Epoch 8439/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3167 - acc: 0.2092 - val_loss: 0.3755 - val_acc: 0.2444\n",
      "Epoch 8440/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3277 - acc: 0.2087 - val_loss: 0.4030 - val_acc: 0.2444\n",
      "Epoch 8441/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3250 - acc: 0.2087 - val_loss: 0.4119 - val_acc: 0.2444\n",
      "Epoch 8442/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3390 - acc: 0.2092 - val_loss: 0.4853 - val_acc: 0.2444\n",
      "Epoch 8443/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3369 - acc: 0.2087 - val_loss: 0.3782 - val_acc: 0.2444\n",
      "Epoch 8444/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3154 - acc: 0.2092 - val_loss: 0.3900 - val_acc: 0.2444\n",
      "Epoch 8445/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3222 - acc: 0.2100 - val_loss: 0.3845 - val_acc: 0.2444\n",
      "Epoch 8446/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3397 - acc: 0.2083 - val_loss: 0.3909 - val_acc: 0.2444\n",
      "Epoch 8447/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3152 - acc: 0.2092 - val_loss: 0.3797 - val_acc: 0.2444\n",
      "Epoch 8448/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3530 - acc: 0.2092 - val_loss: 0.3824 - val_acc: 0.2444\n",
      "Epoch 8449/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3261 - acc: 0.2092 - val_loss: 0.3938 - val_acc: 0.2444\n",
      "Epoch 8450/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3408 - acc: 0.2087 - val_loss: 0.4000 - val_acc: 0.2444\n",
      "Epoch 8451/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3139 - acc: 0.2092 - val_loss: 0.3805 - val_acc: 0.2444\n",
      "Epoch 8452/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3187 - acc: 0.2092 - val_loss: 0.4381 - val_acc: 0.2407\n",
      "Epoch 8453/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3221 - acc: 0.2092 - val_loss: 0.4157 - val_acc: 0.2444\n",
      "Epoch 8454/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3312 - acc: 0.2096 - val_loss: 0.3852 - val_acc: 0.2444\n",
      "Epoch 8455/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3293 - acc: 0.2092 - val_loss: 0.3910 - val_acc: 0.2444\n",
      "Epoch 8456/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3354 - acc: 0.2096 - val_loss: 0.3772 - val_acc: 0.2444\n",
      "Epoch 8457/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3123 - acc: 0.2096 - val_loss: 0.3850 - val_acc: 0.2444\n",
      "Epoch 8458/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3193 - acc: 0.2096 - val_loss: 0.3866 - val_acc: 0.2444\n",
      "Epoch 8459/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3206 - acc: 0.2087 - val_loss: 0.4033 - val_acc: 0.2444\n",
      "Epoch 8460/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3555 - acc: 0.2092 - val_loss: 0.3920 - val_acc: 0.2444\n",
      "Epoch 8461/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3227 - acc: 0.2100 - val_loss: 0.4175 - val_acc: 0.2444\n",
      "Epoch 8462/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3233 - acc: 0.2087 - val_loss: 0.3938 - val_acc: 0.2444\n",
      "Epoch 8463/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3214 - acc: 0.2100 - val_loss: 0.5134 - val_acc: 0.2444\n",
      "Epoch 8464/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3266 - acc: 0.2092 - val_loss: 0.3839 - val_acc: 0.2444\n",
      "Epoch 8465/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3407 - acc: 0.2092 - val_loss: 0.4038 - val_acc: 0.2444\n",
      "Epoch 8466/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3260 - acc: 0.2096 - val_loss: 0.3980 - val_acc: 0.2444\n",
      "Epoch 8467/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3279 - acc: 0.2096 - val_loss: 0.3717 - val_acc: 0.2444\n",
      "Epoch 8468/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3226 - acc: 0.2100 - val_loss: 0.3842 - val_acc: 0.2444\n",
      "Epoch 8469/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3176 - acc: 0.2096 - val_loss: 0.4244 - val_acc: 0.2407\n",
      "Epoch 8470/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3356 - acc: 0.2096 - val_loss: 0.3807 - val_acc: 0.2444\n",
      "Epoch 8471/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3297 - acc: 0.2100 - val_loss: 0.4008 - val_acc: 0.2444\n",
      "Epoch 8472/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3282 - acc: 0.2087 - val_loss: 0.3894 - val_acc: 0.2444\n",
      "Epoch 8473/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3231 - acc: 0.2096 - val_loss: 0.3832 - val_acc: 0.2444\n",
      "Epoch 8474/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3330 - acc: 0.2092 - val_loss: 0.4674 - val_acc: 0.2444\n",
      "Epoch 8475/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3474 - acc: 0.2096 - val_loss: 0.3837 - val_acc: 0.2444\n",
      "Epoch 8476/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3296 - acc: 0.2092 - val_loss: 0.4028 - val_acc: 0.2444\n",
      "Epoch 8477/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3263 - acc: 0.2100 - val_loss: 0.3773 - val_acc: 0.2444\n",
      "Epoch 8478/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3156 - acc: 0.2096 - val_loss: 0.3975 - val_acc: 0.2444\n",
      "Epoch 8479/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3190 - acc: 0.2096 - val_loss: 0.3886 - val_acc: 0.2444\n",
      "Epoch 8480/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3336 - acc: 0.2092 - val_loss: 0.4031 - val_acc: 0.2444\n",
      "Epoch 8481/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3285 - acc: 0.2096 - val_loss: 0.3881 - val_acc: 0.2444\n",
      "Epoch 8482/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3136 - acc: 0.2092 - val_loss: 0.3898 - val_acc: 0.2444\n",
      "Epoch 8483/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3488 - acc: 0.2092 - val_loss: 0.3878 - val_acc: 0.2444\n",
      "Epoch 8484/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3251 - acc: 0.2096 - val_loss: 0.4323 - val_acc: 0.2444\n",
      "Epoch 8485/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3269 - acc: 0.2100 - val_loss: 0.4448 - val_acc: 0.2407\n",
      "Epoch 8486/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3480 - acc: 0.2096 - val_loss: 0.6095 - val_acc: 0.2444\n",
      "Epoch 8487/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3573 - acc: 0.2092 - val_loss: 0.3906 - val_acc: 0.2444\n",
      "Epoch 8488/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3247 - acc: 0.2092 - val_loss: 0.4692 - val_acc: 0.2407\n",
      "Epoch 8489/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3243 - acc: 0.2083 - val_loss: 0.3829 - val_acc: 0.2444\n",
      "Epoch 8490/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3412 - acc: 0.2087 - val_loss: 0.4260 - val_acc: 0.2444\n",
      "Epoch 8491/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3213 - acc: 0.2096 - val_loss: 0.4649 - val_acc: 0.2444\n",
      "Epoch 8492/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3333 - acc: 0.2092 - val_loss: 0.4097 - val_acc: 0.2444\n",
      "Epoch 8493/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3241 - acc: 0.2087 - val_loss: 0.3912 - val_acc: 0.2444\n",
      "Epoch 8494/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3178 - acc: 0.2087 - val_loss: 0.3834 - val_acc: 0.2444\n",
      "Epoch 8495/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3379 - acc: 0.2092 - val_loss: 0.3853 - val_acc: 0.2444\n",
      "Epoch 8496/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3209 - acc: 0.2100 - val_loss: 0.3819 - val_acc: 0.2444\n",
      "Epoch 8497/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3255 - acc: 0.2096 - val_loss: 0.4483 - val_acc: 0.2407\n",
      "Epoch 8498/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3256 - acc: 0.2092 - val_loss: 0.3958 - val_acc: 0.2444\n",
      "Epoch 8499/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3459 - acc: 0.2092 - val_loss: 0.3748 - val_acc: 0.2444\n",
      "Epoch 8500/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3419 - acc: 0.2087 - val_loss: 0.4057 - val_acc: 0.2444\n",
      "Epoch 8501/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3758 - acc: 0.2087 - val_loss: 0.4245 - val_acc: 0.2407\n",
      "Epoch 8502/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3438 - acc: 0.2096 - val_loss: 0.4338 - val_acc: 0.2407\n",
      "Epoch 8503/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3239 - acc: 0.2100 - val_loss: 0.3974 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8504/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3343 - acc: 0.2096 - val_loss: 0.4042 - val_acc: 0.2444\n",
      "Epoch 8505/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3160 - acc: 0.2096 - val_loss: 0.4198 - val_acc: 0.2444\n",
      "Epoch 8506/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3207 - acc: 0.2092 - val_loss: 0.3842 - val_acc: 0.2444\n",
      "Epoch 8507/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3227 - acc: 0.2087 - val_loss: 0.4629 - val_acc: 0.2407\n",
      "Epoch 8508/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3399 - acc: 0.2100 - val_loss: 0.4411 - val_acc: 0.2407\n",
      "Epoch 8509/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3164 - acc: 0.2087 - val_loss: 0.3921 - val_acc: 0.2444\n",
      "Epoch 8510/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3273 - acc: 0.2087 - val_loss: 0.4001 - val_acc: 0.2444\n",
      "Epoch 8511/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3162 - acc: 0.2087 - val_loss: 0.3962 - val_acc: 0.2444\n",
      "Epoch 8512/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3161 - acc: 0.2096 - val_loss: 0.4194 - val_acc: 0.2444\n",
      "Epoch 8513/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3331 - acc: 0.2096 - val_loss: 0.3878 - val_acc: 0.2444\n",
      "Epoch 8514/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3166 - acc: 0.2100 - val_loss: 0.4082 - val_acc: 0.2444\n",
      "Epoch 8515/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3213 - acc: 0.2096 - val_loss: 0.3916 - val_acc: 0.2444\n",
      "Epoch 8516/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3310 - acc: 0.2096 - val_loss: 0.3951 - val_acc: 0.2444\n",
      "Epoch 8517/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3454 - acc: 0.2096 - val_loss: 0.5224 - val_acc: 0.2444\n",
      "Epoch 8518/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3307 - acc: 0.2087 - val_loss: 0.3927 - val_acc: 0.2444\n",
      "Epoch 8519/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3355 - acc: 0.2100 - val_loss: 0.4323 - val_acc: 0.2407\n",
      "Epoch 8520/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3361 - acc: 0.2092 - val_loss: 0.3986 - val_acc: 0.2444\n",
      "Epoch 8521/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3397 - acc: 0.2096 - val_loss: 0.3835 - val_acc: 0.2444\n",
      "Epoch 8522/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.3214 - acc: 0.2096 - val_loss: 0.3815 - val_acc: 0.2444\n",
      "Epoch 8523/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.3394 - acc: 0.2083 - val_loss: 0.3959 - val_acc: 0.2444\n",
      "Epoch 8524/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3240 - acc: 0.2100 - val_loss: 0.4085 - val_acc: 0.2444\n",
      "Epoch 8525/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3227 - acc: 0.2100 - val_loss: 0.4399 - val_acc: 0.2444\n",
      "Epoch 8526/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3322 - acc: 0.2096 - val_loss: 0.4238 - val_acc: 0.2407\n",
      "Epoch 8527/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3244 - acc: 0.2092 - val_loss: 0.4238 - val_acc: 0.2407\n",
      "Epoch 8528/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3571 - acc: 0.2092 - val_loss: 0.4546 - val_acc: 0.2444\n",
      "Epoch 8529/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3165 - acc: 0.2096 - val_loss: 0.3872 - val_acc: 0.2444\n",
      "Epoch 8530/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3123 - acc: 0.2092 - val_loss: 0.3879 - val_acc: 0.2444\n",
      "Epoch 8531/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3211 - acc: 0.2100 - val_loss: 0.3906 - val_acc: 0.2444\n",
      "Epoch 8532/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3196 - acc: 0.2087 - val_loss: 0.4072 - val_acc: 0.2407\n",
      "Epoch 8533/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3171 - acc: 0.2096 - val_loss: 0.3825 - val_acc: 0.2444\n",
      "Epoch 8534/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3278 - acc: 0.2096 - val_loss: 0.4257 - val_acc: 0.2444\n",
      "Epoch 8535/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3236 - acc: 0.2092 - val_loss: 0.3906 - val_acc: 0.2444\n",
      "Epoch 8536/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3232 - acc: 0.2096 - val_loss: 0.3935 - val_acc: 0.2444\n",
      "Epoch 8537/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3129 - acc: 0.2092 - val_loss: 0.4003 - val_acc: 0.2444\n",
      "Epoch 8538/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3183 - acc: 0.2100 - val_loss: 0.4364 - val_acc: 0.2407\n",
      "Epoch 8539/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3168 - acc: 0.2092 - val_loss: 0.3822 - val_acc: 0.2444\n",
      "Epoch 8540/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3172 - acc: 0.2092 - val_loss: 0.3776 - val_acc: 0.2444\n",
      "Epoch 8541/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3379 - acc: 0.2096 - val_loss: 0.4328 - val_acc: 0.2407\n",
      "Epoch 8542/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3240 - acc: 0.2096 - val_loss: 0.3858 - val_acc: 0.2444\n",
      "Epoch 8543/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3328 - acc: 0.2096 - val_loss: 0.3834 - val_acc: 0.2444\n",
      "Epoch 8544/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3761 - acc: 0.2087 - val_loss: 0.5014 - val_acc: 0.2407\n",
      "Epoch 8545/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3812 - acc: 0.2092 - val_loss: 0.4217 - val_acc: 0.2407\n",
      "Epoch 8546/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3129 - acc: 0.2092 - val_loss: 0.3840 - val_acc: 0.2444\n",
      "Epoch 8547/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3182 - acc: 0.2092 - val_loss: 0.3877 - val_acc: 0.2444\n",
      "Epoch 8548/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3201 - acc: 0.2100 - val_loss: 0.4035 - val_acc: 0.2444\n",
      "Epoch 8549/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3297 - acc: 0.2083 - val_loss: 0.4069 - val_acc: 0.2444\n",
      "Epoch 8550/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3265 - acc: 0.2083 - val_loss: 0.3884 - val_acc: 0.2444\n",
      "Epoch 8551/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3232 - acc: 0.2100 - val_loss: 0.4088 - val_acc: 0.2444\n",
      "Epoch 8552/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3223 - acc: 0.2096 - val_loss: 0.3884 - val_acc: 0.2444\n",
      "Epoch 8553/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3241 - acc: 0.2096 - val_loss: 0.4405 - val_acc: 0.2407\n",
      "Epoch 8554/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3435 - acc: 0.2096 - val_loss: 0.4095 - val_acc: 0.2444\n",
      "Epoch 8555/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3382 - acc: 0.2092 - val_loss: 0.3848 - val_acc: 0.2444\n",
      "Epoch 8556/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3284 - acc: 0.2092 - val_loss: 0.4770 - val_acc: 0.2407\n",
      "Epoch 8557/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3262 - acc: 0.2100 - val_loss: 0.3822 - val_acc: 0.2444\n",
      "Epoch 8558/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3155 - acc: 0.2087 - val_loss: 0.3888 - val_acc: 0.2444\n",
      "Epoch 8559/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3205 - acc: 0.2092 - val_loss: 0.3922 - val_acc: 0.2444\n",
      "Epoch 8560/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3220 - acc: 0.2092 - val_loss: 0.3896 - val_acc: 0.2444\n",
      "Epoch 8561/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3202 - acc: 0.2096 - val_loss: 0.3989 - val_acc: 0.2444\n",
      "Epoch 8562/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3299 - acc: 0.2092 - val_loss: 0.3895 - val_acc: 0.2444\n",
      "Epoch 8563/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3317 - acc: 0.2096 - val_loss: 0.4270 - val_acc: 0.2407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8564/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3327 - acc: 0.2096 - val_loss: 0.4097 - val_acc: 0.2407\n",
      "Epoch 8565/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3393 - acc: 0.2096 - val_loss: 0.3928 - val_acc: 0.2444\n",
      "Epoch 8566/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3383 - acc: 0.2092 - val_loss: 0.3785 - val_acc: 0.2444\n",
      "Epoch 8567/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3240 - acc: 0.2096 - val_loss: 0.3902 - val_acc: 0.2444\n",
      "Epoch 8568/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3260 - acc: 0.2087 - val_loss: 0.3871 - val_acc: 0.2444\n",
      "Epoch 8569/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3161 - acc: 0.2096 - val_loss: 0.3921 - val_acc: 0.2444\n",
      "Epoch 8570/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3477 - acc: 0.2100 - val_loss: 0.3794 - val_acc: 0.2444\n",
      "Epoch 8571/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3200 - acc: 0.2096 - val_loss: 0.4314 - val_acc: 0.2444\n",
      "Epoch 8572/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3338 - acc: 0.2092 - val_loss: 0.3934 - val_acc: 0.2444\n",
      "Epoch 8573/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3244 - acc: 0.2092 - val_loss: 0.3794 - val_acc: 0.2444\n",
      "Epoch 8574/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3333 - acc: 0.2092 - val_loss: 0.3986 - val_acc: 0.2444\n",
      "Epoch 8575/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3237 - acc: 0.2092 - val_loss: 0.4986 - val_acc: 0.2407\n",
      "Epoch 8576/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3494 - acc: 0.2092 - val_loss: 0.5476 - val_acc: 0.2444\n",
      "Epoch 8577/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3421 - acc: 0.2100 - val_loss: 0.3943 - val_acc: 0.2444\n",
      "Epoch 8578/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3401 - acc: 0.2096 - val_loss: 0.3910 - val_acc: 0.2444\n",
      "Epoch 8579/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3335 - acc: 0.2100 - val_loss: 0.4019 - val_acc: 0.2444\n",
      "Epoch 8580/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3312 - acc: 0.2096 - val_loss: 0.3724 - val_acc: 0.2444\n",
      "Epoch 8581/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3475 - acc: 0.2100 - val_loss: 0.3870 - val_acc: 0.2444\n",
      "Epoch 8582/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3291 - acc: 0.2096 - val_loss: 0.3803 - val_acc: 0.2444\n",
      "Epoch 8583/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3405 - acc: 0.2083 - val_loss: 0.4761 - val_acc: 0.2444\n",
      "Epoch 8584/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3389 - acc: 0.2087 - val_loss: 0.4609 - val_acc: 0.2444\n",
      "Epoch 8585/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3176 - acc: 0.2092 - val_loss: 0.4223 - val_acc: 0.2444\n",
      "Epoch 8586/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3625 - acc: 0.2087 - val_loss: 0.3901 - val_acc: 0.2444\n",
      "Epoch 8587/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3287 - acc: 0.2087 - val_loss: 0.3887 - val_acc: 0.2444\n",
      "Epoch 8588/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3360 - acc: 0.2092 - val_loss: 0.5071 - val_acc: 0.2444\n",
      "Epoch 8589/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3240 - acc: 0.2092 - val_loss: 0.3827 - val_acc: 0.2444\n",
      "Epoch 8590/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3568 - acc: 0.2087 - val_loss: 0.4552 - val_acc: 0.2407\n",
      "Epoch 8591/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3276 - acc: 0.2092 - val_loss: 0.3929 - val_acc: 0.2444\n",
      "Epoch 8592/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3119 - acc: 0.2096 - val_loss: 0.4061 - val_acc: 0.2444\n",
      "Epoch 8593/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3406 - acc: 0.2079 - val_loss: 0.3961 - val_acc: 0.2444\n",
      "Epoch 8594/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3232 - acc: 0.2096 - val_loss: 0.3857 - val_acc: 0.2444\n",
      "Epoch 8595/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3378 - acc: 0.2087 - val_loss: 0.3838 - val_acc: 0.2444\n",
      "Epoch 8596/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3366 - acc: 0.2096 - val_loss: 0.3821 - val_acc: 0.2444\n",
      "Epoch 8597/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3320 - acc: 0.2096 - val_loss: 0.4425 - val_acc: 0.2407\n",
      "Epoch 8598/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3193 - acc: 0.2096 - val_loss: 0.3871 - val_acc: 0.2444\n",
      "Epoch 8599/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3236 - acc: 0.2092 - val_loss: 0.4061 - val_acc: 0.2407\n",
      "Epoch 8600/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3184 - acc: 0.2092 - val_loss: 0.4029 - val_acc: 0.2444\n",
      "Epoch 8601/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3168 - acc: 0.2100 - val_loss: 0.3891 - val_acc: 0.2444\n",
      "Epoch 8602/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3311 - acc: 0.2092 - val_loss: 0.4389 - val_acc: 0.2444\n",
      "Epoch 8603/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3135 - acc: 0.2100 - val_loss: 0.3933 - val_acc: 0.2444\n",
      "Epoch 8604/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3215 - acc: 0.2096 - val_loss: 0.3866 - val_acc: 0.2444\n",
      "Epoch 8605/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3550 - acc: 0.2096 - val_loss: 0.4890 - val_acc: 0.2407\n",
      "Epoch 8606/10000\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.3285 - acc: 0.208 - 3s 34ms/step - loss: 0.3293 - acc: 0.2096 - val_loss: 0.3869 - val_acc: 0.2444\n",
      "Epoch 8607/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3269 - acc: 0.2092 - val_loss: 0.4159 - val_acc: 0.2407\n",
      "Epoch 8608/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3198 - acc: 0.2096 - val_loss: 0.4464 - val_acc: 0.2444\n",
      "Epoch 8609/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3451 - acc: 0.2092 - val_loss: 0.4793 - val_acc: 0.2444\n",
      "Epoch 8610/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3348 - acc: 0.2096 - val_loss: 0.3831 - val_acc: 0.2444\n",
      "Epoch 8611/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3303 - acc: 0.2100 - val_loss: 0.3883 - val_acc: 0.2444\n",
      "Epoch 8612/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3166 - acc: 0.2092 - val_loss: 0.3829 - val_acc: 0.2444\n",
      "Epoch 8613/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3179 - acc: 0.2092 - val_loss: 0.3884 - val_acc: 0.2444\n",
      "Epoch 8614/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3156 - acc: 0.2100 - val_loss: 0.3833 - val_acc: 0.2444\n",
      "Epoch 8615/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3355 - acc: 0.2096 - val_loss: 0.4598 - val_acc: 0.2444\n",
      "Epoch 8616/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3305 - acc: 0.2087 - val_loss: 0.3933 - val_acc: 0.2444\n",
      "Epoch 8617/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3326 - acc: 0.2092 - val_loss: 0.3855 - val_acc: 0.2444\n",
      "Epoch 8618/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3405 - acc: 0.2092 - val_loss: 0.3796 - val_acc: 0.2444\n",
      "Epoch 8619/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3137 - acc: 0.2096 - val_loss: 0.3946 - val_acc: 0.2444\n",
      "Epoch 8620/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3156 - acc: 0.2096 - val_loss: 0.3805 - val_acc: 0.2444\n",
      "Epoch 8621/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3177 - acc: 0.2092 - val_loss: 0.3868 - val_acc: 0.2444\n",
      "Epoch 8622/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3103 - acc: 0.2096 - val_loss: 0.3892 - val_acc: 0.2444\n",
      "Epoch 8623/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3305 - acc: 0.2092 - val_loss: 0.3993 - val_acc: 0.2444\n",
      "Epoch 8624/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3186 - acc: 0.2096 - val_loss: 0.4030 - val_acc: 0.2444\n",
      "Epoch 8625/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3265 - acc: 0.2092 - val_loss: 0.4058 - val_acc: 0.2444\n",
      "Epoch 8626/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3146 - acc: 0.2092 - val_loss: 0.4623 - val_acc: 0.2444\n",
      "Epoch 8627/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3380 - acc: 0.2092 - val_loss: 0.3938 - val_acc: 0.2444\n",
      "Epoch 8628/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3219 - acc: 0.2092 - val_loss: 0.4306 - val_acc: 0.2444\n",
      "Epoch 8629/10000\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.3288 - acc: 0.208 - 2s 33ms/step - loss: 0.3364 - acc: 0.2092 - val_loss: 0.4095 - val_acc: 0.2407\n",
      "Epoch 8630/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3435 - acc: 0.2092 - val_loss: 0.3948 - val_acc: 0.2444\n",
      "Epoch 8631/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3216 - acc: 0.2096 - val_loss: 0.3818 - val_acc: 0.2444\n",
      "Epoch 8632/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3203 - acc: 0.2096 - val_loss: 0.3895 - val_acc: 0.2444\n",
      "Epoch 8633/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3226 - acc: 0.2100 - val_loss: 0.4052 - val_acc: 0.2444\n",
      "Epoch 8634/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3222 - acc: 0.2100 - val_loss: 0.4054 - val_acc: 0.2444\n",
      "Epoch 8635/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3154 - acc: 0.2096 - val_loss: 0.4122 - val_acc: 0.2444\n",
      "Epoch 8636/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3150 - acc: 0.2092 - val_loss: 0.4129 - val_acc: 0.2444\n",
      "Epoch 8637/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3301 - acc: 0.2096 - val_loss: 0.4059 - val_acc: 0.2444\n",
      "Epoch 8638/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3188 - acc: 0.2092 - val_loss: 0.5096 - val_acc: 0.2444\n",
      "Epoch 8639/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3356 - acc: 0.2087 - val_loss: 0.3937 - val_acc: 0.2444\n",
      "Epoch 8640/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3261 - acc: 0.2096 - val_loss: 0.4283 - val_acc: 0.2444\n",
      "Epoch 8641/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3283 - acc: 0.2096 - val_loss: 0.3805 - val_acc: 0.2444\n",
      "Epoch 8642/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3214 - acc: 0.2096 - val_loss: 0.3975 - val_acc: 0.2444\n",
      "Epoch 8643/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3165 - acc: 0.2100 - val_loss: 0.3831 - val_acc: 0.2444\n",
      "Epoch 8644/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3178 - acc: 0.2100 - val_loss: 0.4087 - val_acc: 0.2407\n",
      "Epoch 8645/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3222 - acc: 0.2092 - val_loss: 0.4319 - val_acc: 0.2407\n",
      "Epoch 8646/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3373 - acc: 0.2092 - val_loss: 0.5025 - val_acc: 0.2444\n",
      "Epoch 8647/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3567 - acc: 0.2096 - val_loss: 0.3794 - val_acc: 0.2444\n",
      "Epoch 8648/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3169 - acc: 0.2096 - val_loss: 0.3909 - val_acc: 0.2444\n",
      "Epoch 8649/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3393 - acc: 0.2092 - val_loss: 0.5641 - val_acc: 0.2407\n",
      "Epoch 8650/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3248 - acc: 0.2096 - val_loss: 0.4020 - val_acc: 0.2444\n",
      "Epoch 8651/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3217 - acc: 0.2096 - val_loss: 0.3894 - val_acc: 0.2444\n",
      "Epoch 8652/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3271 - acc: 0.2100 - val_loss: 0.3868 - val_acc: 0.2444\n",
      "Epoch 8653/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3766 - acc: 0.2087 - val_loss: 0.4850 - val_acc: 0.2444\n",
      "Epoch 8654/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.3308 - acc: 0.2092 - val_loss: 0.3812 - val_acc: 0.2444\n",
      "Epoch 8655/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3236 - acc: 0.2087 - val_loss: 0.3826 - val_acc: 0.2444\n",
      "Epoch 8656/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3150 - acc: 0.2100 - val_loss: 0.4001 - val_acc: 0.2444\n",
      "Epoch 8657/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3116 - acc: 0.2096 - val_loss: 0.3870 - val_acc: 0.2444\n",
      "Epoch 8658/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3375 - acc: 0.2096 - val_loss: 0.3897 - val_acc: 0.2444\n",
      "Epoch 8659/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3364 - acc: 0.2087 - val_loss: 0.3855 - val_acc: 0.2444\n",
      "Epoch 8660/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3188 - acc: 0.2092 - val_loss: 0.3942 - val_acc: 0.2444\n",
      "Epoch 8661/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3146 - acc: 0.2092 - val_loss: 0.4293 - val_acc: 0.2407\n",
      "Epoch 8662/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3223 - acc: 0.2092 - val_loss: 0.3855 - val_acc: 0.2444\n",
      "Epoch 8663/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3289 - acc: 0.2092 - val_loss: 0.3876 - val_acc: 0.2444\n",
      "Epoch 8664/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3354 - acc: 0.2092 - val_loss: 0.4298 - val_acc: 0.2407\n",
      "Epoch 8665/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3195 - acc: 0.2087 - val_loss: 0.4050 - val_acc: 0.2444\n",
      "Epoch 8666/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3342 - acc: 0.2096 - val_loss: 0.4871 - val_acc: 0.2407\n",
      "Epoch 8667/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3302 - acc: 0.2096 - val_loss: 0.4581 - val_acc: 0.2444\n",
      "Epoch 8668/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3196 - acc: 0.2092 - val_loss: 0.4126 - val_acc: 0.2407\n",
      "Epoch 8669/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3309 - acc: 0.2087 - val_loss: 0.3959 - val_acc: 0.2444\n",
      "Epoch 8670/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3322 - acc: 0.2100 - val_loss: 0.3819 - val_acc: 0.2444\n",
      "Epoch 8671/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3220 - acc: 0.2092 - val_loss: 0.3754 - val_acc: 0.2444\n",
      "Epoch 8672/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3165 - acc: 0.2092 - val_loss: 0.3925 - val_acc: 0.2444\n",
      "Epoch 8673/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3219 - acc: 0.2092 - val_loss: 0.3942 - val_acc: 0.2444\n",
      "Epoch 8674/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3210 - acc: 0.2096 - val_loss: 0.3802 - val_acc: 0.2444\n",
      "Epoch 8675/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3182 - acc: 0.2096 - val_loss: 0.3828 - val_acc: 0.2444\n",
      "Epoch 8676/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3336 - acc: 0.2096 - val_loss: 0.6178 - val_acc: 0.2444\n",
      "Epoch 8677/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3467 - acc: 0.2092 - val_loss: 0.5348 - val_acc: 0.2407\n",
      "Epoch 8678/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3343 - acc: 0.2092 - val_loss: 0.4257 - val_acc: 0.2407\n",
      "Epoch 8679/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3173 - acc: 0.2096 - val_loss: 0.3845 - val_acc: 0.2444\n",
      "Epoch 8680/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3109 - acc: 0.2096 - val_loss: 0.4062 - val_acc: 0.2444\n",
      "Epoch 8681/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3109 - acc: 0.2096 - val_loss: 0.3773 - val_acc: 0.2444\n",
      "Epoch 8682/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3266 - acc: 0.2092 - val_loss: 0.3932 - val_acc: 0.2444\n",
      "Epoch 8683/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3267 - acc: 0.2092 - val_loss: 0.3883 - val_acc: 0.2444\n",
      "Epoch 8684/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3351 - acc: 0.2087 - val_loss: 0.3866 - val_acc: 0.2444\n",
      "Epoch 8685/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3389 - acc: 0.2092 - val_loss: 0.3893 - val_acc: 0.2444\n",
      "Epoch 8686/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3123 - acc: 0.2096 - val_loss: 0.3924 - val_acc: 0.2444\n",
      "Epoch 8687/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3175 - acc: 0.2092 - val_loss: 0.4164 - val_acc: 0.2444\n",
      "Epoch 8688/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3410 - acc: 0.2083 - val_loss: 0.4374 - val_acc: 0.2444\n",
      "Epoch 8689/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3262 - acc: 0.2096 - val_loss: 0.4486 - val_acc: 0.2444\n",
      "Epoch 8690/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3410 - acc: 0.2092 - val_loss: 0.3904 - val_acc: 0.2444\n",
      "Epoch 8691/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3253 - acc: 0.2092 - val_loss: 0.3765 - val_acc: 0.2444\n",
      "Epoch 8692/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3270 - acc: 0.2092 - val_loss: 0.3810 - val_acc: 0.2444\n",
      "Epoch 8693/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3271 - acc: 0.2092 - val_loss: 0.4793 - val_acc: 0.2407\n",
      "Epoch 8694/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3467 - acc: 0.2100 - val_loss: 0.3828 - val_acc: 0.2444\n",
      "Epoch 8695/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3085 - acc: 0.2096 - val_loss: 0.4119 - val_acc: 0.2407\n",
      "Epoch 8696/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3180 - acc: 0.2092 - val_loss: 0.3898 - val_acc: 0.2444\n",
      "Epoch 8697/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3361 - acc: 0.2096 - val_loss: 0.3971 - val_acc: 0.2444\n",
      "Epoch 8698/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3290 - acc: 0.2100 - val_loss: 0.4735 - val_acc: 0.2444\n",
      "Epoch 8699/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3371 - acc: 0.2092 - val_loss: 0.3811 - val_acc: 0.2444\n",
      "Epoch 8700/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3183 - acc: 0.2096 - val_loss: 0.3971 - val_acc: 0.2444\n",
      "Epoch 8701/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3524 - acc: 0.2092 - val_loss: 0.3799 - val_acc: 0.2444\n",
      "Epoch 8702/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3574 - acc: 0.2087 - val_loss: 0.3781 - val_acc: 0.2444\n",
      "Epoch 8703/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3625 - acc: 0.2092 - val_loss: 0.3997 - val_acc: 0.2444\n",
      "Epoch 8704/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3146 - acc: 0.2100 - val_loss: 0.3877 - val_acc: 0.2444\n",
      "Epoch 8705/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3218 - acc: 0.2092 - val_loss: 0.3927 - val_acc: 0.2444\n",
      "Epoch 8706/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3357 - acc: 0.2092 - val_loss: 0.4017 - val_acc: 0.2444\n",
      "Epoch 8707/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3215 - acc: 0.2096 - val_loss: 0.3836 - val_acc: 0.2444\n",
      "Epoch 8708/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3286 - acc: 0.2092 - val_loss: 0.3859 - val_acc: 0.2444\n",
      "Epoch 8709/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3303 - acc: 0.2092 - val_loss: 0.5029 - val_acc: 0.2444\n",
      "Epoch 8710/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3269 - acc: 0.2087 - val_loss: 0.4036 - val_acc: 0.2444\n",
      "Epoch 8711/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3161 - acc: 0.2092 - val_loss: 0.3874 - val_acc: 0.2444\n",
      "Epoch 8712/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3355 - acc: 0.2087 - val_loss: 0.5734 - val_acc: 0.2444\n",
      "Epoch 8713/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3445 - acc: 0.2100 - val_loss: 0.4066 - val_acc: 0.2444\n",
      "Epoch 8714/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3238 - acc: 0.2092 - val_loss: 0.4740 - val_acc: 0.2444\n",
      "Epoch 8715/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3287 - acc: 0.2087 - val_loss: 0.3828 - val_acc: 0.2444\n",
      "Epoch 8716/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3225 - acc: 0.2092 - val_loss: 0.3744 - val_acc: 0.2444\n",
      "Epoch 8717/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3531 - acc: 0.2100 - val_loss: 0.5556 - val_acc: 0.2407\n",
      "Epoch 8718/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3300 - acc: 0.2096 - val_loss: 0.4317 - val_acc: 0.2444\n",
      "Epoch 8719/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3226 - acc: 0.2092 - val_loss: 0.4461 - val_acc: 0.2407\n",
      "Epoch 8720/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3248 - acc: 0.2092 - val_loss: 0.3946 - val_acc: 0.2444\n",
      "Epoch 8721/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3204 - acc: 0.2096 - val_loss: 0.3867 - val_acc: 0.2444\n",
      "Epoch 8722/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3169 - acc: 0.2092 - val_loss: 0.3853 - val_acc: 0.2444\n",
      "Epoch 8723/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3236 - acc: 0.2100 - val_loss: 0.4434 - val_acc: 0.2407\n",
      "Epoch 8724/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3263 - acc: 0.2096 - val_loss: 0.3743 - val_acc: 0.2444\n",
      "Epoch 8725/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3151 - acc: 0.2096 - val_loss: 0.3916 - val_acc: 0.2444\n",
      "Epoch 8726/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3271 - acc: 0.2100 - val_loss: 0.4023 - val_acc: 0.2444\n",
      "Epoch 8727/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3225 - acc: 0.2087 - val_loss: 0.4114 - val_acc: 0.2444\n",
      "Epoch 8728/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3668 - acc: 0.2087 - val_loss: 0.4611 - val_acc: 0.2407\n",
      "Epoch 8729/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3260 - acc: 0.2100 - val_loss: 0.3836 - val_acc: 0.2444\n",
      "Epoch 8730/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3138 - acc: 0.2096 - val_loss: 0.3877 - val_acc: 0.2444\n",
      "Epoch 8731/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3114 - acc: 0.2087 - val_loss: 0.3944 - val_acc: 0.2444\n",
      "Epoch 8732/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3147 - acc: 0.2092 - val_loss: 0.3816 - val_acc: 0.2444\n",
      "Epoch 8733/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3275 - acc: 0.2087 - val_loss: 0.4501 - val_acc: 0.2407\n",
      "Epoch 8734/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3303 - acc: 0.2092 - val_loss: 0.4217 - val_acc: 0.2444\n",
      "Epoch 8735/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3167 - acc: 0.2100 - val_loss: 0.3896 - val_acc: 0.2444\n",
      "Epoch 8736/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3201 - acc: 0.2100 - val_loss: 0.3773 - val_acc: 0.2444\n",
      "Epoch 8737/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3118 - acc: 0.2100 - val_loss: 0.3907 - val_acc: 0.2444\n",
      "Epoch 8738/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3176 - acc: 0.2092 - val_loss: 0.4035 - val_acc: 0.2444\n",
      "Epoch 8739/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3154 - acc: 0.2096 - val_loss: 0.3928 - val_acc: 0.2444\n",
      "Epoch 8740/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3189 - acc: 0.2096 - val_loss: 0.4591 - val_acc: 0.2407\n",
      "Epoch 8741/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3588 - acc: 0.2083 - val_loss: 0.3955 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8742/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3309 - acc: 0.2092 - val_loss: 0.4199 - val_acc: 0.2444\n",
      "Epoch 8743/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3569 - acc: 0.2083 - val_loss: 0.3865 - val_acc: 0.2444\n",
      "Epoch 8744/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3317 - acc: 0.2096 - val_loss: 0.3888 - val_acc: 0.2444\n",
      "Epoch 8745/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3352 - acc: 0.2092 - val_loss: 0.3936 - val_acc: 0.2444\n",
      "Epoch 8746/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3142 - acc: 0.2092 - val_loss: 0.4165 - val_acc: 0.2444\n",
      "Epoch 8747/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3387 - acc: 0.2100 - val_loss: 0.3919 - val_acc: 0.2444\n",
      "Epoch 8748/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3256 - acc: 0.2087 - val_loss: 0.3936 - val_acc: 0.2444\n",
      "Epoch 8749/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3178 - acc: 0.2092 - val_loss: 0.3749 - val_acc: 0.2444\n",
      "Epoch 8750/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3174 - acc: 0.2087 - val_loss: 0.4671 - val_acc: 0.2407\n",
      "Epoch 8751/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3450 - acc: 0.2087 - val_loss: 0.3884 - val_acc: 0.2444\n",
      "Epoch 8752/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3212 - acc: 0.2096 - val_loss: 0.4521 - val_acc: 0.2444\n",
      "Epoch 8753/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3242 - acc: 0.2096 - val_loss: 0.3925 - val_acc: 0.2444\n",
      "Epoch 8754/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3442 - acc: 0.2092 - val_loss: 0.4195 - val_acc: 0.2444\n",
      "Epoch 8755/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3253 - acc: 0.2096 - val_loss: 0.4073 - val_acc: 0.2444\n",
      "Epoch 8756/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3184 - acc: 0.2100 - val_loss: 0.3990 - val_acc: 0.2444\n",
      "Epoch 8757/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3317 - acc: 0.2083 - val_loss: 0.4567 - val_acc: 0.2444\n",
      "Epoch 8758/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3202 - acc: 0.2096 - val_loss: 0.4095 - val_acc: 0.2444\n",
      "Epoch 8759/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3438 - acc: 0.2096 - val_loss: 0.4198 - val_acc: 0.2444\n",
      "Epoch 8760/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3261 - acc: 0.2092 - val_loss: 0.3704 - val_acc: 0.2444\n",
      "Epoch 8761/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3280 - acc: 0.2100 - val_loss: 0.4564 - val_acc: 0.2407\n",
      "Epoch 8762/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3223 - acc: 0.2083 - val_loss: 0.4174 - val_acc: 0.2444\n",
      "Epoch 8763/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3343 - acc: 0.2092 - val_loss: 0.6615 - val_acc: 0.2407\n",
      "Epoch 8764/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3481 - acc: 0.2083 - val_loss: 0.4108 - val_acc: 0.2444\n",
      "Epoch 8765/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3605 - acc: 0.2100 - val_loss: 0.3892 - val_acc: 0.2444\n",
      "Epoch 8766/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3304 - acc: 0.2096 - val_loss: 0.3860 - val_acc: 0.2444\n",
      "Epoch 8767/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3362 - acc: 0.2087 - val_loss: 0.3817 - val_acc: 0.2444\n",
      "Epoch 8768/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3183 - acc: 0.2096 - val_loss: 0.3854 - val_acc: 0.2444\n",
      "Epoch 8769/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3220 - acc: 0.2092 - val_loss: 0.3803 - val_acc: 0.2444\n",
      "Epoch 8770/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3289 - acc: 0.2100 - val_loss: 0.3928 - val_acc: 0.2444\n",
      "Epoch 8771/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3158 - acc: 0.2096 - val_loss: 0.5124 - val_acc: 0.2407\n",
      "Epoch 8772/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3500 - acc: 0.2096 - val_loss: 0.3861 - val_acc: 0.2444\n",
      "Epoch 8773/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3198 - acc: 0.2096 - val_loss: 0.3802 - val_acc: 0.2444\n",
      "Epoch 8774/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3324 - acc: 0.2096 - val_loss: 0.3907 - val_acc: 0.2444\n",
      "Epoch 8775/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3265 - acc: 0.2100 - val_loss: 0.4227 - val_acc: 0.2444\n",
      "Epoch 8776/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3229 - acc: 0.2096 - val_loss: 0.3833 - val_acc: 0.2444\n",
      "Epoch 8777/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3185 - acc: 0.2092 - val_loss: 0.4318 - val_acc: 0.2407\n",
      "Epoch 8778/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3505 - acc: 0.2083 - val_loss: 0.3925 - val_acc: 0.2444\n",
      "Epoch 8779/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3384 - acc: 0.2087 - val_loss: 0.4203 - val_acc: 0.2444\n",
      "Epoch 8780/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3269 - acc: 0.2092 - val_loss: 0.3821 - val_acc: 0.2444\n",
      "Epoch 8781/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3149 - acc: 0.2092 - val_loss: 0.4137 - val_acc: 0.2407\n",
      "Epoch 8782/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3171 - acc: 0.2092 - val_loss: 0.4145 - val_acc: 0.2407\n",
      "Epoch 8783/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3270 - acc: 0.2096 - val_loss: 0.3868 - val_acc: 0.2444\n",
      "Epoch 8784/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.3210 - acc: 0.2100 - val_loss: 0.4112 - val_acc: 0.2444\n",
      "Epoch 8785/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3214 - acc: 0.2092 - val_loss: 0.4394 - val_acc: 0.2444\n",
      "Epoch 8786/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3132 - acc: 0.2100 - val_loss: 0.3716 - val_acc: 0.2444\n",
      "Epoch 8787/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3129 - acc: 0.2100 - val_loss: 0.4798 - val_acc: 0.2444\n",
      "Epoch 8788/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3379 - acc: 0.2092 - val_loss: 0.4178 - val_acc: 0.2407\n",
      "Epoch 8789/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3158 - acc: 0.2087 - val_loss: 0.3842 - val_acc: 0.2444\n",
      "Epoch 8790/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3091 - acc: 0.2100 - val_loss: 0.3712 - val_acc: 0.2444\n",
      "Epoch 8791/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3224 - acc: 0.2092 - val_loss: 0.3799 - val_acc: 0.2444\n",
      "Epoch 8792/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3116 - acc: 0.2096 - val_loss: 0.4344 - val_acc: 0.2444\n",
      "Epoch 8793/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3323 - acc: 0.2100 - val_loss: 0.3885 - val_acc: 0.2444\n",
      "Epoch 8794/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3141 - acc: 0.2092 - val_loss: 0.3798 - val_acc: 0.2444\n",
      "Epoch 8795/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3203 - acc: 0.2100 - val_loss: 0.4486 - val_acc: 0.2407\n",
      "Epoch 8796/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3358 - acc: 0.2096 - val_loss: 0.4379 - val_acc: 0.2444\n",
      "Epoch 8797/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3199 - acc: 0.2100 - val_loss: 0.3895 - val_acc: 0.2444\n",
      "Epoch 8798/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3167 - acc: 0.2096 - val_loss: 0.3771 - val_acc: 0.2444\n",
      "Epoch 8799/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3201 - acc: 0.2096 - val_loss: 0.4059 - val_acc: 0.2444\n",
      "Epoch 8800/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3174 - acc: 0.2100 - val_loss: 0.3987 - val_acc: 0.2444\n",
      "Epoch 8801/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3165 - acc: 0.2096 - val_loss: 0.3997 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8802/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3115 - acc: 0.2096 - val_loss: 0.4023 - val_acc: 0.2444\n",
      "Epoch 8803/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3120 - acc: 0.2096 - val_loss: 0.4471 - val_acc: 0.2444\n",
      "Epoch 8804/10000\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.3394 - acc: 0.209 - 3s 33ms/step - loss: 0.3403 - acc: 0.2096 - val_loss: 0.3895 - val_acc: 0.2444\n",
      "Epoch 8805/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3226 - acc: 0.2092 - val_loss: 0.3965 - val_acc: 0.2444\n",
      "Epoch 8806/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3234 - acc: 0.2092 - val_loss: 0.3870 - val_acc: 0.2444\n",
      "Epoch 8807/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3151 - acc: 0.2096 - val_loss: 0.3925 - val_acc: 0.2444\n",
      "Epoch 8808/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3148 - acc: 0.2087 - val_loss: 0.3799 - val_acc: 0.2444\n",
      "Epoch 8809/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3191 - acc: 0.2096 - val_loss: 0.3824 - val_acc: 0.2444\n",
      "Epoch 8810/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3419 - acc: 0.2096 - val_loss: 0.5126 - val_acc: 0.2407\n",
      "Epoch 8811/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3429 - acc: 0.2079 - val_loss: 0.3820 - val_acc: 0.2444\n",
      "Epoch 8812/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3516 - acc: 0.2096 - val_loss: 0.4113 - val_acc: 0.2444\n",
      "Epoch 8813/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3123 - acc: 0.2100 - val_loss: 0.3846 - val_acc: 0.2444\n",
      "Epoch 8814/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3281 - acc: 0.2096 - val_loss: 0.5597 - val_acc: 0.2407\n",
      "Epoch 8815/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3380 - acc: 0.2087 - val_loss: 0.4025 - val_acc: 0.2444\n",
      "Epoch 8816/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3269 - acc: 0.2092 - val_loss: 0.3997 - val_acc: 0.2444\n",
      "Epoch 8817/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3324 - acc: 0.2092 - val_loss: 0.3889 - val_acc: 0.2444\n",
      "Epoch 8818/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3192 - acc: 0.2096 - val_loss: 0.4339 - val_acc: 0.2444\n",
      "Epoch 8819/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3122 - acc: 0.2100 - val_loss: 0.3923 - val_acc: 0.2444\n",
      "Epoch 8820/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3249 - acc: 0.2092 - val_loss: 0.3994 - val_acc: 0.2444\n",
      "Epoch 8821/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3166 - acc: 0.2096 - val_loss: 0.4952 - val_acc: 0.2444\n",
      "Epoch 8822/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3439 - acc: 0.2087 - val_loss: 0.5060 - val_acc: 0.2407\n",
      "Epoch 8823/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3528 - acc: 0.2096 - val_loss: 0.4160 - val_acc: 0.2444\n",
      "Epoch 8824/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3155 - acc: 0.2100 - val_loss: 0.3889 - val_acc: 0.2444\n",
      "Epoch 8825/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3314 - acc: 0.2092 - val_loss: 0.4541 - val_acc: 0.2444\n",
      "Epoch 8826/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3326 - acc: 0.2083 - val_loss: 0.3725 - val_acc: 0.2444\n",
      "Epoch 8827/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3183 - acc: 0.2096 - val_loss: 0.5803 - val_acc: 0.2444\n",
      "Epoch 8828/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3346 - acc: 0.2096 - val_loss: 0.4348 - val_acc: 0.2444\n",
      "Epoch 8829/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3141 - acc: 0.2096 - val_loss: 0.4507 - val_acc: 0.2407\n",
      "Epoch 8830/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3365 - acc: 0.2092 - val_loss: 0.3774 - val_acc: 0.2444\n",
      "Epoch 8831/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3272 - acc: 0.2092 - val_loss: 0.4360 - val_acc: 0.2444\n",
      "Epoch 8832/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3313 - acc: 0.2092 - val_loss: 0.3815 - val_acc: 0.2444\n",
      "Epoch 8833/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3168 - acc: 0.2092 - val_loss: 0.3800 - val_acc: 0.2444\n",
      "Epoch 8834/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3153 - acc: 0.2100 - val_loss: 0.3860 - val_acc: 0.2444\n",
      "Epoch 8835/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3264 - acc: 0.2087 - val_loss: 0.3858 - val_acc: 0.2444\n",
      "Epoch 8836/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3298 - acc: 0.2096 - val_loss: 0.3879 - val_acc: 0.2444\n",
      "Epoch 8837/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3152 - acc: 0.2100 - val_loss: 0.4259 - val_acc: 0.2407\n",
      "Epoch 8838/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3298 - acc: 0.2100 - val_loss: 0.4019 - val_acc: 0.2444\n",
      "Epoch 8839/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3287 - acc: 0.2096 - val_loss: 0.3886 - val_acc: 0.2444\n",
      "Epoch 8840/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3161 - acc: 0.2096 - val_loss: 0.5257 - val_acc: 0.2444\n",
      "Epoch 8841/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3645 - acc: 0.2096 - val_loss: 0.3823 - val_acc: 0.2444\n",
      "Epoch 8842/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3395 - acc: 0.2096 - val_loss: 0.4550 - val_acc: 0.2407\n",
      "Epoch 8843/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3196 - acc: 0.2092 - val_loss: 0.3901 - val_acc: 0.2444\n",
      "Epoch 8844/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3149 - acc: 0.2096 - val_loss: 0.3909 - val_acc: 0.2444\n",
      "Epoch 8845/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.3188 - acc: 0.2092 - val_loss: 0.3756 - val_acc: 0.2444\n",
      "Epoch 8846/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.3313 - acc: 0.2096 - val_loss: 0.3949 - val_acc: 0.2444\n",
      "Epoch 8847/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3200 - acc: 0.2096 - val_loss: 0.4061 - val_acc: 0.2407\n",
      "Epoch 8848/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3214 - acc: 0.2096 - val_loss: 0.4411 - val_acc: 0.2444\n",
      "Epoch 8849/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3255 - acc: 0.2087 - val_loss: 0.4000 - val_acc: 0.2444\n",
      "Epoch 8850/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3232 - acc: 0.2092 - val_loss: 0.3974 - val_acc: 0.2444\n",
      "Epoch 8851/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3311 - acc: 0.2092 - val_loss: 0.4986 - val_acc: 0.2407\n",
      "Epoch 8852/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3293 - acc: 0.2087 - val_loss: 0.3733 - val_acc: 0.2444\n",
      "Epoch 8853/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3134 - acc: 0.2096 - val_loss: 0.4230 - val_acc: 0.2407\n",
      "Epoch 8854/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3508 - acc: 0.2092 - val_loss: 0.5919 - val_acc: 0.2444\n",
      "Epoch 8855/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3288 - acc: 0.2087 - val_loss: 0.4009 - val_acc: 0.2444\n",
      "Epoch 8856/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3357 - acc: 0.2092 - val_loss: 0.3784 - val_acc: 0.2444\n",
      "Epoch 8857/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3112 - acc: 0.2100 - val_loss: 0.3926 - val_acc: 0.2444\n",
      "Epoch 8858/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3207 - acc: 0.2092 - val_loss: 0.4283 - val_acc: 0.2407\n",
      "Epoch 8859/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3461 - acc: 0.2096 - val_loss: 0.4238 - val_acc: 0.2407\n",
      "Epoch 8860/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3568 - acc: 0.2100 - val_loss: 0.4508 - val_acc: 0.2407\n",
      "Epoch 8861/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3287 - acc: 0.2096 - val_loss: 0.3855 - val_acc: 0.2444\n",
      "Epoch 8862/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3247 - acc: 0.2087 - val_loss: 0.3994 - val_acc: 0.2444\n",
      "Epoch 8863/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3175 - acc: 0.2100 - val_loss: 0.3842 - val_acc: 0.2444\n",
      "Epoch 8864/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3223 - acc: 0.2092 - val_loss: 0.4055 - val_acc: 0.2444\n",
      "Epoch 8865/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3129 - acc: 0.2096 - val_loss: 0.3869 - val_acc: 0.2444\n",
      "Epoch 8866/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3339 - acc: 0.2092 - val_loss: 0.3789 - val_acc: 0.2444\n",
      "Epoch 8867/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3266 - acc: 0.2096 - val_loss: 0.4514 - val_acc: 0.2407\n",
      "Epoch 8868/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3368 - acc: 0.2096 - val_loss: 0.3752 - val_acc: 0.2444\n",
      "Epoch 8869/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3504 - acc: 0.2087 - val_loss: 0.4484 - val_acc: 0.2444\n",
      "Epoch 8870/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3099 - acc: 0.2092 - val_loss: 0.3820 - val_acc: 0.2444\n",
      "Epoch 8871/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3250 - acc: 0.2092 - val_loss: 0.3891 - val_acc: 0.2444\n",
      "Epoch 8872/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3069 - acc: 0.2092 - val_loss: 0.4008 - val_acc: 0.2407\n",
      "Epoch 8873/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3303 - acc: 0.2096 - val_loss: 0.5489 - val_acc: 0.2444\n",
      "Epoch 8874/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3310 - acc: 0.2087 - val_loss: 0.4056 - val_acc: 0.2444\n",
      "Epoch 8875/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3299 - acc: 0.2096 - val_loss: 0.3881 - val_acc: 0.2444\n",
      "Epoch 8876/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3226 - acc: 0.2096 - val_loss: 0.4206 - val_acc: 0.2407\n",
      "Epoch 8877/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3147 - acc: 0.2096 - val_loss: 0.4094 - val_acc: 0.2444\n",
      "Epoch 8878/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3202 - acc: 0.2100 - val_loss: 0.4070 - val_acc: 0.2444\n",
      "Epoch 8879/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3262 - acc: 0.2092 - val_loss: 0.3798 - val_acc: 0.2444\n",
      "Epoch 8880/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3173 - acc: 0.2096 - val_loss: 0.4208 - val_acc: 0.2407\n",
      "Epoch 8881/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3588 - acc: 0.2087 - val_loss: 0.4660 - val_acc: 0.2407\n",
      "Epoch 8882/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3339 - acc: 0.2092 - val_loss: 0.3753 - val_acc: 0.2444\n",
      "Epoch 8883/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3127 - acc: 0.2092 - val_loss: 0.3758 - val_acc: 0.2444\n",
      "Epoch 8884/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3447 - acc: 0.2087 - val_loss: 0.4010 - val_acc: 0.2444\n",
      "Epoch 8885/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3210 - acc: 0.2100 - val_loss: 0.3951 - val_acc: 0.2444\n",
      "Epoch 8886/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3277 - acc: 0.2092 - val_loss: 0.3879 - val_acc: 0.2444\n",
      "Epoch 8887/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3262 - acc: 0.2092 - val_loss: 0.3727 - val_acc: 0.2444\n",
      "Epoch 8888/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3206 - acc: 0.2092 - val_loss: 0.3851 - val_acc: 0.2444\n",
      "Epoch 8889/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3467 - acc: 0.2087 - val_loss: 0.4418 - val_acc: 0.2407\n",
      "Epoch 8890/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3219 - acc: 0.2092 - val_loss: 0.4001 - val_acc: 0.2444\n",
      "Epoch 8891/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3201 - acc: 0.2100 - val_loss: 0.3816 - val_acc: 0.2444\n",
      "Epoch 8892/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3281 - acc: 0.2096 - val_loss: 0.4131 - val_acc: 0.2407\n",
      "Epoch 8893/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3141 - acc: 0.2096 - val_loss: 0.3923 - val_acc: 0.2444\n",
      "Epoch 8894/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3151 - acc: 0.2096 - val_loss: 0.4145 - val_acc: 0.2444\n",
      "Epoch 8895/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3193 - acc: 0.2100 - val_loss: 0.4190 - val_acc: 0.2444\n",
      "Epoch 8896/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3224 - acc: 0.2096 - val_loss: 0.3962 - val_acc: 0.2444\n",
      "Epoch 8897/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3358 - acc: 0.2092 - val_loss: 0.4384 - val_acc: 0.2444\n",
      "Epoch 8898/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3337 - acc: 0.2096 - val_loss: 0.4507 - val_acc: 0.2407\n",
      "Epoch 8899/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3194 - acc: 0.2092 - val_loss: 0.3828 - val_acc: 0.2444\n",
      "Epoch 8900/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3332 - acc: 0.2087 - val_loss: 0.3881 - val_acc: 0.2444\n",
      "Epoch 8901/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3124 - acc: 0.2092 - val_loss: 0.3953 - val_acc: 0.2444\n",
      "Epoch 8902/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3161 - acc: 0.2096 - val_loss: 0.4101 - val_acc: 0.2407\n",
      "Epoch 8903/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3183 - acc: 0.2092 - val_loss: 0.4321 - val_acc: 0.2407\n",
      "Epoch 8904/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3419 - acc: 0.2092 - val_loss: 0.3893 - val_acc: 0.2444\n",
      "Epoch 8905/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3272 - acc: 0.2092 - val_loss: 0.4087 - val_acc: 0.2444\n",
      "Epoch 8906/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3281 - acc: 0.2092 - val_loss: 0.4922 - val_acc: 0.2407\n",
      "Epoch 8907/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3506 - acc: 0.2100 - val_loss: 0.3866 - val_acc: 0.2444\n",
      "Epoch 8908/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3167 - acc: 0.2100 - val_loss: 0.3931 - val_acc: 0.2444\n",
      "Epoch 8909/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3249 - acc: 0.2092 - val_loss: 0.4278 - val_acc: 0.2444\n",
      "Epoch 8910/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3357 - acc: 0.2087 - val_loss: 0.4789 - val_acc: 0.2444\n",
      "Epoch 8911/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3117 - acc: 0.2100 - val_loss: 0.3785 - val_acc: 0.2444\n",
      "Epoch 8912/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3117 - acc: 0.2087 - val_loss: 0.4128 - val_acc: 0.2444\n",
      "Epoch 8913/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3701 - acc: 0.2087 - val_loss: 0.3872 - val_acc: 0.2444\n",
      "Epoch 8914/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.3317 - acc: 0.2087 - val_loss: 0.3925 - val_acc: 0.2444\n",
      "Epoch 8915/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.3646 - acc: 0.2087 - val_loss: 0.4462 - val_acc: 0.2444\n",
      "Epoch 8916/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3344 - acc: 0.2096 - val_loss: 0.3776 - val_acc: 0.2444\n",
      "Epoch 8917/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3071 - acc: 0.2100 - val_loss: 0.4811 - val_acc: 0.2407\n",
      "Epoch 8918/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3268 - acc: 0.2092 - val_loss: 0.4127 - val_acc: 0.2407\n",
      "Epoch 8919/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3273 - acc: 0.2092 - val_loss: 0.4216 - val_acc: 0.2444\n",
      "Epoch 8920/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3298 - acc: 0.2083 - val_loss: 0.3801 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8921/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3277 - acc: 0.2096 - val_loss: 0.3801 - val_acc: 0.2444\n",
      "Epoch 8922/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3248 - acc: 0.2100 - val_loss: 0.3763 - val_acc: 0.2444\n",
      "Epoch 8923/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3538 - acc: 0.2083 - val_loss: 0.4993 - val_acc: 0.2444\n",
      "Epoch 8924/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3438 - acc: 0.2100 - val_loss: 0.3814 - val_acc: 0.2444\n",
      "Epoch 8925/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3141 - acc: 0.2096 - val_loss: 0.4097 - val_acc: 0.2407\n",
      "Epoch 8926/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3290 - acc: 0.2096 - val_loss: 0.3970 - val_acc: 0.2444\n",
      "Epoch 8927/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3362 - acc: 0.2092 - val_loss: 0.3776 - val_acc: 0.2444\n",
      "Epoch 8928/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3192 - acc: 0.2096 - val_loss: 0.3782 - val_acc: 0.2444\n",
      "Epoch 8929/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3210 - acc: 0.2092 - val_loss: 0.4010 - val_acc: 0.2444\n",
      "Epoch 8930/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3158 - acc: 0.2096 - val_loss: 0.4005 - val_acc: 0.2407\n",
      "Epoch 8931/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3129 - acc: 0.2092 - val_loss: 0.3827 - val_acc: 0.2444\n",
      "Epoch 8932/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3161 - acc: 0.2096 - val_loss: 0.3858 - val_acc: 0.2444\n",
      "Epoch 8933/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3337 - acc: 0.2092 - val_loss: 0.3816 - val_acc: 0.2444\n",
      "Epoch 8934/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3697 - acc: 0.2092 - val_loss: 0.3909 - val_acc: 0.2444\n",
      "Epoch 8935/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3209 - acc: 0.2096 - val_loss: 0.3794 - val_acc: 0.2444\n",
      "Epoch 8936/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3160 - acc: 0.2096 - val_loss: 0.3794 - val_acc: 0.2444\n",
      "Epoch 8937/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3198 - acc: 0.2092 - val_loss: 0.3815 - val_acc: 0.2444\n",
      "Epoch 8938/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3169 - acc: 0.2100 - val_loss: 0.3793 - val_acc: 0.2444\n",
      "Epoch 8939/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3207 - acc: 0.2096 - val_loss: 0.3851 - val_acc: 0.2444\n",
      "Epoch 8940/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3185 - acc: 0.2096 - val_loss: 0.3810 - val_acc: 0.2444\n",
      "Epoch 8941/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3182 - acc: 0.2100 - val_loss: 0.3929 - val_acc: 0.2444\n",
      "Epoch 8942/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3210 - acc: 0.2100 - val_loss: 0.3745 - val_acc: 0.2444\n",
      "Epoch 8943/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3274 - acc: 0.2096 - val_loss: 0.3806 - val_acc: 0.2444\n",
      "Epoch 8944/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3076 - acc: 0.2092 - val_loss: 0.3832 - val_acc: 0.2444\n",
      "Epoch 8945/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3265 - acc: 0.2100 - val_loss: 0.4137 - val_acc: 0.2407\n",
      "Epoch 8946/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3409 - acc: 0.2092 - val_loss: 0.3897 - val_acc: 0.2444\n",
      "Epoch 8947/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3188 - acc: 0.2096 - val_loss: 0.4374 - val_acc: 0.2444\n",
      "Epoch 8948/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3158 - acc: 0.2096 - val_loss: 0.3804 - val_acc: 0.2444\n",
      "Epoch 8949/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3256 - acc: 0.2092 - val_loss: 0.5007 - val_acc: 0.2444\n",
      "Epoch 8950/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3651 - acc: 0.2087 - val_loss: 0.3866 - val_acc: 0.2444\n",
      "Epoch 8951/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3507 - acc: 0.2083 - val_loss: 0.4233 - val_acc: 0.2444\n",
      "Epoch 8952/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3136 - acc: 0.2096 - val_loss: 0.4270 - val_acc: 0.2407\n",
      "Epoch 8953/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3276 - acc: 0.2092 - val_loss: 0.3878 - val_acc: 0.2444\n",
      "Epoch 8954/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3169 - acc: 0.2096 - val_loss: 0.3858 - val_acc: 0.2444\n",
      "Epoch 8955/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3428 - acc: 0.2083 - val_loss: 0.4180 - val_acc: 0.2444\n",
      "Epoch 8956/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3491 - acc: 0.2100 - val_loss: 0.3967 - val_acc: 0.2444\n",
      "Epoch 8957/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3445 - acc: 0.2100 - val_loss: 0.4112 - val_acc: 0.2444\n",
      "Epoch 8958/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3192 - acc: 0.2100 - val_loss: 0.3925 - val_acc: 0.2444\n",
      "Epoch 8959/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3224 - acc: 0.2092 - val_loss: 0.3914 - val_acc: 0.2444\n",
      "Epoch 8960/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3178 - acc: 0.2100 - val_loss: 0.3786 - val_acc: 0.2444\n",
      "Epoch 8961/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3308 - acc: 0.2100 - val_loss: 0.3848 - val_acc: 0.2444\n",
      "Epoch 8962/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3211 - acc: 0.2087 - val_loss: 0.3925 - val_acc: 0.2444\n",
      "Epoch 8963/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3156 - acc: 0.2087 - val_loss: 0.3957 - val_acc: 0.2444\n",
      "Epoch 8964/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3287 - acc: 0.2096 - val_loss: 0.3925 - val_acc: 0.2444\n",
      "Epoch 8965/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3308 - acc: 0.2100 - val_loss: 0.3922 - val_acc: 0.2444\n",
      "Epoch 8966/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3065 - acc: 0.2096 - val_loss: 0.4025 - val_acc: 0.2444\n",
      "Epoch 8967/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3395 - acc: 0.2100 - val_loss: 0.4029 - val_acc: 0.2444\n",
      "Epoch 8968/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3403 - acc: 0.2096 - val_loss: 0.3822 - val_acc: 0.2444\n",
      "Epoch 8969/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3129 - acc: 0.2096 - val_loss: 0.3855 - val_acc: 0.2444\n",
      "Epoch 8970/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3344 - acc: 0.2083 - val_loss: 0.3881 - val_acc: 0.2444\n",
      "Epoch 8971/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3310 - acc: 0.2096 - val_loss: 0.3903 - val_acc: 0.2444\n",
      "Epoch 8972/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3204 - acc: 0.2100 - val_loss: 0.3837 - val_acc: 0.2444\n",
      "Epoch 8973/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3155 - acc: 0.2092 - val_loss: 0.3733 - val_acc: 0.2444\n",
      "Epoch 8974/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3338 - acc: 0.2087 - val_loss: 0.3863 - val_acc: 0.2444\n",
      "Epoch 8975/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3086 - acc: 0.2100 - val_loss: 0.4097 - val_acc: 0.2444\n",
      "Epoch 8976/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3160 - acc: 0.2100 - val_loss: 0.3802 - val_acc: 0.2444\n",
      "Epoch 8977/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3256 - acc: 0.2100 - val_loss: 0.3875 - val_acc: 0.2444\n",
      "Epoch 8978/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3506 - acc: 0.2096 - val_loss: 0.3753 - val_acc: 0.2444\n",
      "Epoch 8979/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3264 - acc: 0.2092 - val_loss: 0.3848 - val_acc: 0.2444\n",
      "Epoch 8980/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3119 - acc: 0.2100 - val_loss: 0.3772 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8981/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3173 - acc: 0.2096 - val_loss: 0.3762 - val_acc: 0.2444\n",
      "Epoch 8982/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3210 - acc: 0.2087 - val_loss: 0.3740 - val_acc: 0.2444\n",
      "Epoch 8983/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3298 - acc: 0.2096 - val_loss: 0.3958 - val_acc: 0.2444\n",
      "Epoch 8984/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3166 - acc: 0.2096 - val_loss: 0.3978 - val_acc: 0.2444\n",
      "Epoch 8985/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3154 - acc: 0.2087 - val_loss: 0.4040 - val_acc: 0.2444\n",
      "Epoch 8986/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3391 - acc: 0.2087 - val_loss: 0.3805 - val_acc: 0.2444\n",
      "Epoch 8987/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3302 - acc: 0.2092 - val_loss: 0.3723 - val_acc: 0.2444\n",
      "Epoch 8988/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3450 - acc: 0.2087 - val_loss: 0.3939 - val_acc: 0.2444\n",
      "Epoch 8989/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3362 - acc: 0.2092 - val_loss: 0.4188 - val_acc: 0.2444\n",
      "Epoch 8990/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3232 - acc: 0.2100 - val_loss: 0.3905 - val_acc: 0.2444\n",
      "Epoch 8991/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3535 - acc: 0.2087 - val_loss: 0.3894 - val_acc: 0.2444\n",
      "Epoch 8992/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3151 - acc: 0.2096 - val_loss: 0.3801 - val_acc: 0.2444\n",
      "Epoch 8993/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3078 - acc: 0.2100 - val_loss: 0.4132 - val_acc: 0.2444\n",
      "Epoch 8994/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3296 - acc: 0.2100 - val_loss: 0.4117 - val_acc: 0.2444\n",
      "Epoch 8995/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3313 - acc: 0.2096 - val_loss: 0.3995 - val_acc: 0.2444\n",
      "Epoch 8996/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3247 - acc: 0.2096 - val_loss: 0.4345 - val_acc: 0.2444\n",
      "Epoch 8997/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3124 - acc: 0.2092 - val_loss: 0.4466 - val_acc: 0.2444\n",
      "Epoch 8998/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3231 - acc: 0.2096 - val_loss: 0.3756 - val_acc: 0.2444\n",
      "Epoch 8999/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3176 - acc: 0.2096 - val_loss: 0.4103 - val_acc: 0.2444\n",
      "Epoch 9000/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3133 - acc: 0.2096 - val_loss: 0.3831 - val_acc: 0.2444\n",
      "Epoch 9001/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3597 - acc: 0.2092 - val_loss: 0.4474 - val_acc: 0.2407\n",
      "Epoch 9002/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3398 - acc: 0.2087 - val_loss: 0.3932 - val_acc: 0.2444\n",
      "Epoch 9003/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3310 - acc: 0.2096 - val_loss: 0.3858 - val_acc: 0.2444\n",
      "Epoch 9004/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3177 - acc: 0.2100 - val_loss: 0.3772 - val_acc: 0.2444\n",
      "Epoch 9005/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3397 - acc: 0.2092 - val_loss: 0.4515 - val_acc: 0.2444\n",
      "Epoch 9006/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3307 - acc: 0.2092 - val_loss: 0.5016 - val_acc: 0.2444\n",
      "Epoch 9007/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3182 - acc: 0.2100 - val_loss: 0.3903 - val_acc: 0.2444\n",
      "Epoch 9008/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3146 - acc: 0.2096 - val_loss: 0.3869 - val_acc: 0.2444\n",
      "Epoch 9009/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3201 - acc: 0.2100 - val_loss: 0.4484 - val_acc: 0.2444\n",
      "Epoch 9010/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3138 - acc: 0.2092 - val_loss: 0.3863 - val_acc: 0.2444\n",
      "Epoch 9011/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3330 - acc: 0.2100 - val_loss: 0.4073 - val_acc: 0.2444\n",
      "Epoch 9012/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3265 - acc: 0.2096 - val_loss: 0.5283 - val_acc: 0.2407\n",
      "Epoch 9013/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3744 - acc: 0.2079 - val_loss: 0.3951 - val_acc: 0.2444\n",
      "Epoch 9014/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3207 - acc: 0.2100 - val_loss: 0.3778 - val_acc: 0.2444\n",
      "Epoch 9015/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3309 - acc: 0.2087 - val_loss: 0.3843 - val_acc: 0.2444\n",
      "Epoch 9016/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3326 - acc: 0.2100 - val_loss: 0.5386 - val_acc: 0.2444\n",
      "Epoch 9017/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3332 - acc: 0.2079 - val_loss: 0.3798 - val_acc: 0.2444\n",
      "Epoch 9018/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3181 - acc: 0.2100 - val_loss: 0.3800 - val_acc: 0.2444\n",
      "Epoch 9019/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3178 - acc: 0.2096 - val_loss: 0.4087 - val_acc: 0.2444\n",
      "Epoch 9020/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3156 - acc: 0.2100 - val_loss: 0.3847 - val_acc: 0.2444\n",
      "Epoch 9021/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3268 - acc: 0.2100 - val_loss: 0.3959 - val_acc: 0.2444\n",
      "Epoch 9022/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3304 - acc: 0.2096 - val_loss: 0.4525 - val_acc: 0.2444\n",
      "Epoch 9023/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3207 - acc: 0.2087 - val_loss: 0.4025 - val_acc: 0.2444\n",
      "Epoch 9024/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3198 - acc: 0.2100 - val_loss: 0.4043 - val_acc: 0.2407\n",
      "Epoch 9025/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3241 - acc: 0.2096 - val_loss: 0.4504 - val_acc: 0.2407\n",
      "Epoch 9026/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3349 - acc: 0.2092 - val_loss: 0.4034 - val_acc: 0.2444\n",
      "Epoch 9027/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3291 - acc: 0.2092 - val_loss: 0.3745 - val_acc: 0.2444\n",
      "Epoch 9028/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3164 - acc: 0.2092 - val_loss: 0.4041 - val_acc: 0.2407\n",
      "Epoch 9029/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3239 - acc: 0.2092 - val_loss: 0.3705 - val_acc: 0.2444\n",
      "Epoch 9030/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3283 - acc: 0.2092 - val_loss: 0.3983 - val_acc: 0.2444\n",
      "Epoch 9031/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3261 - acc: 0.2100 - val_loss: 0.3881 - val_acc: 0.2444\n",
      "Epoch 9032/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3198 - acc: 0.2096 - val_loss: 0.3777 - val_acc: 0.2444\n",
      "Epoch 9033/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3209 - acc: 0.2087 - val_loss: 0.3725 - val_acc: 0.2444\n",
      "Epoch 9034/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3249 - acc: 0.2100 - val_loss: 0.3993 - val_acc: 0.2444\n",
      "Epoch 9035/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3207 - acc: 0.2096 - val_loss: 0.3951 - val_acc: 0.2444\n",
      "Epoch 9036/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3366 - acc: 0.2100 - val_loss: 0.4386 - val_acc: 0.2407\n",
      "Epoch 9037/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3270 - acc: 0.2092 - val_loss: 0.4117 - val_acc: 0.2444\n",
      "Epoch 9038/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3258 - acc: 0.2096 - val_loss: 0.3896 - val_acc: 0.2444\n",
      "Epoch 9039/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3332 - acc: 0.2092 - val_loss: 0.3749 - val_acc: 0.2444\n",
      "Epoch 9040/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3272 - acc: 0.2092 - val_loss: 0.3780 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9041/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3179 - acc: 0.2096 - val_loss: 0.3861 - val_acc: 0.2444\n",
      "Epoch 9042/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3123 - acc: 0.2096 - val_loss: 0.4243 - val_acc: 0.2444\n",
      "Epoch 9043/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3187 - acc: 0.2100 - val_loss: 0.3779 - val_acc: 0.2444\n",
      "Epoch 9044/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.3371 - acc: 0.2100 - val_loss: 0.4643 - val_acc: 0.2444\n",
      "Epoch 9045/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3288 - acc: 0.2092 - val_loss: 0.3904 - val_acc: 0.2444\n",
      "Epoch 9046/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3327 - acc: 0.2096 - val_loss: 0.4077 - val_acc: 0.2407\n",
      "Epoch 9047/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3149 - acc: 0.2100 - val_loss: 0.3998 - val_acc: 0.2444\n",
      "Epoch 9048/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3278 - acc: 0.2096 - val_loss: 0.3813 - val_acc: 0.2444\n",
      "Epoch 9049/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3166 - acc: 0.2087 - val_loss: 0.5380 - val_acc: 0.2407\n",
      "Epoch 9050/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3532 - acc: 0.2096 - val_loss: 0.3802 - val_acc: 0.2444\n",
      "Epoch 9051/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3255 - acc: 0.2096 - val_loss: 0.4084 - val_acc: 0.2444\n",
      "Epoch 9052/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3102 - acc: 0.2100 - val_loss: 0.3822 - val_acc: 0.2444\n",
      "Epoch 9053/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3235 - acc: 0.2096 - val_loss: 0.3816 - val_acc: 0.2444\n",
      "Epoch 9054/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3114 - acc: 0.2092 - val_loss: 0.3714 - val_acc: 0.2444\n",
      "Epoch 9055/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3234 - acc: 0.2092 - val_loss: 0.4565 - val_acc: 0.2444\n",
      "Epoch 9056/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3290 - acc: 0.2096 - val_loss: 0.4292 - val_acc: 0.2444\n",
      "Epoch 9057/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3290 - acc: 0.2096 - val_loss: 0.4016 - val_acc: 0.2444\n",
      "Epoch 9058/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3170 - acc: 0.2100 - val_loss: 0.3870 - val_acc: 0.2444\n",
      "Epoch 9059/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3410 - acc: 0.2096 - val_loss: 0.4280 - val_acc: 0.2444\n",
      "Epoch 9060/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3129 - acc: 0.2096 - val_loss: 0.3989 - val_acc: 0.2444\n",
      "Epoch 9061/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3259 - acc: 0.2096 - val_loss: 0.3859 - val_acc: 0.2444\n",
      "Epoch 9062/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3309 - acc: 0.2092 - val_loss: 0.4955 - val_acc: 0.2407\n",
      "Epoch 9063/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3222 - acc: 0.2096 - val_loss: 0.5432 - val_acc: 0.2444\n",
      "Epoch 9064/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3418 - acc: 0.2100 - val_loss: 0.4042 - val_acc: 0.2444\n",
      "Epoch 9065/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3260 - acc: 0.2100 - val_loss: 0.3996 - val_acc: 0.2444\n",
      "Epoch 9066/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3405 - acc: 0.2079 - val_loss: 0.3747 - val_acc: 0.2444\n",
      "Epoch 9067/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3137 - acc: 0.2100 - val_loss: 0.3949 - val_acc: 0.2444\n",
      "Epoch 9068/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3289 - acc: 0.2087 - val_loss: 0.4078 - val_acc: 0.2444\n",
      "Epoch 9069/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3140 - acc: 0.2096 - val_loss: 0.3865 - val_acc: 0.2444\n",
      "Epoch 9070/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3151 - acc: 0.2100 - val_loss: 0.3961 - val_acc: 0.2444\n",
      "Epoch 9071/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3088 - acc: 0.2092 - val_loss: 0.3939 - val_acc: 0.2444\n",
      "Epoch 9072/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3181 - acc: 0.2092 - val_loss: 0.3935 - val_acc: 0.2444\n",
      "Epoch 9073/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3458 - acc: 0.2087 - val_loss: 0.3943 - val_acc: 0.2444\n",
      "Epoch 9074/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3334 - acc: 0.2083 - val_loss: 0.4015 - val_acc: 0.2444\n",
      "Epoch 9075/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3132 - acc: 0.2092 - val_loss: 0.3940 - val_acc: 0.2444\n",
      "Epoch 9076/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3256 - acc: 0.2092 - val_loss: 0.3770 - val_acc: 0.2444\n",
      "Epoch 9077/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3207 - acc: 0.2100 - val_loss: 0.4282 - val_acc: 0.2407\n",
      "Epoch 9078/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3359 - acc: 0.2096 - val_loss: 0.5828 - val_acc: 0.2444\n",
      "Epoch 9079/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3317 - acc: 0.2092 - val_loss: 0.3997 - val_acc: 0.2444\n",
      "Epoch 9080/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3065 - acc: 0.2100 - val_loss: 0.3903 - val_acc: 0.2444\n",
      "Epoch 9081/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3173 - acc: 0.2096 - val_loss: 0.4213 - val_acc: 0.2407\n",
      "Epoch 9082/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3361 - acc: 0.2096 - val_loss: 0.3777 - val_acc: 0.2444\n",
      "Epoch 9083/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3307 - acc: 0.2092 - val_loss: 0.3905 - val_acc: 0.2444\n",
      "Epoch 9084/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3183 - acc: 0.2100 - val_loss: 0.3860 - val_acc: 0.2444\n",
      "Epoch 9085/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3539 - acc: 0.2096 - val_loss: 0.4584 - val_acc: 0.2444\n",
      "Epoch 9086/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3181 - acc: 0.2100 - val_loss: 0.3992 - val_acc: 0.2444\n",
      "Epoch 9087/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3294 - acc: 0.2096 - val_loss: 0.5077 - val_acc: 0.2444\n",
      "Epoch 9088/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3233 - acc: 0.2092 - val_loss: 0.3842 - val_acc: 0.2444\n",
      "Epoch 9089/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3070 - acc: 0.2096 - val_loss: 0.5152 - val_acc: 0.2407\n",
      "Epoch 9090/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3208 - acc: 0.2092 - val_loss: 0.4019 - val_acc: 0.2444\n",
      "Epoch 9091/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3304 - acc: 0.2096 - val_loss: 0.3958 - val_acc: 0.2444\n",
      "Epoch 9092/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3261 - acc: 0.2100 - val_loss: 0.4029 - val_acc: 0.2444\n",
      "Epoch 9093/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3582 - acc: 0.2087 - val_loss: 0.3906 - val_acc: 0.2444\n",
      "Epoch 9094/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3093 - acc: 0.2092 - val_loss: 0.3920 - val_acc: 0.2444\n",
      "Epoch 9095/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3282 - acc: 0.2092 - val_loss: 0.3696 - val_acc: 0.2444\n",
      "Epoch 9096/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3276 - acc: 0.2096 - val_loss: 0.3952 - val_acc: 0.2444\n",
      "Epoch 9097/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3373 - acc: 0.2096 - val_loss: 0.3799 - val_acc: 0.2444\n",
      "Epoch 9098/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3396 - acc: 0.2096 - val_loss: 0.3814 - val_acc: 0.2444\n",
      "Epoch 9099/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3375 - acc: 0.2083 - val_loss: 0.3863 - val_acc: 0.2444\n",
      "Epoch 9100/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3217 - acc: 0.2096 - val_loss: 0.3858 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9101/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3092 - acc: 0.2100 - val_loss: 0.5572 - val_acc: 0.2407\n",
      "Epoch 9102/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3158 - acc: 0.2100 - val_loss: 0.3998 - val_acc: 0.2444\n",
      "Epoch 9103/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3221 - acc: 0.2096 - val_loss: 0.3699 - val_acc: 0.2444\n",
      "Epoch 9104/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3299 - acc: 0.2087 - val_loss: 0.3796 - val_acc: 0.2444\n",
      "Epoch 9105/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3485 - acc: 0.2087 - val_loss: 0.4294 - val_acc: 0.2407\n",
      "Epoch 9106/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3135 - acc: 0.2096 - val_loss: 0.3913 - val_acc: 0.2444\n",
      "Epoch 9107/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3240 - acc: 0.2096 - val_loss: 0.3990 - val_acc: 0.2444\n",
      "Epoch 9108/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3361 - acc: 0.2092 - val_loss: 0.4141 - val_acc: 0.2444\n",
      "Epoch 9109/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3132 - acc: 0.2096 - val_loss: 0.3936 - val_acc: 0.2444\n",
      "Epoch 9110/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3215 - acc: 0.2087 - val_loss: 0.3849 - val_acc: 0.2444\n",
      "Epoch 9111/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3350 - acc: 0.2092 - val_loss: 0.4217 - val_acc: 0.2444\n",
      "Epoch 9112/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3407 - acc: 0.2100 - val_loss: 0.4079 - val_acc: 0.2444\n",
      "Epoch 9113/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3367 - acc: 0.2096 - val_loss: 0.3868 - val_acc: 0.2444\n",
      "Epoch 9114/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3263 - acc: 0.2092 - val_loss: 0.4924 - val_acc: 0.2407\n",
      "Epoch 9115/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3184 - acc: 0.2096 - val_loss: 0.4140 - val_acc: 0.2444\n",
      "Epoch 9116/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3219 - acc: 0.2092 - val_loss: 0.3859 - val_acc: 0.2444\n",
      "Epoch 9117/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3239 - acc: 0.2087 - val_loss: 0.3750 - val_acc: 0.2444\n",
      "Epoch 9118/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3385 - acc: 0.2087 - val_loss: 0.4237 - val_acc: 0.2407\n",
      "Epoch 9119/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3190 - acc: 0.2096 - val_loss: 0.3781 - val_acc: 0.2444\n",
      "Epoch 9120/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3374 - acc: 0.2087 - val_loss: 0.4638 - val_acc: 0.2444\n",
      "Epoch 9121/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3146 - acc: 0.2092 - val_loss: 0.3770 - val_acc: 0.2444\n",
      "Epoch 9122/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3212 - acc: 0.2087 - val_loss: 0.3769 - val_acc: 0.2444\n",
      "Epoch 9123/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3261 - acc: 0.2092 - val_loss: 0.3817 - val_acc: 0.2444\n",
      "Epoch 9124/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3067 - acc: 0.2100 - val_loss: 0.3852 - val_acc: 0.2444\n",
      "Epoch 9125/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3109 - acc: 0.2096 - val_loss: 0.3789 - val_acc: 0.2444\n",
      "Epoch 9126/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3101 - acc: 0.2092 - val_loss: 0.4704 - val_acc: 0.2444\n",
      "Epoch 9127/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3174 - acc: 0.2092 - val_loss: 0.4114 - val_acc: 0.2407\n",
      "Epoch 9128/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3161 - acc: 0.2092 - val_loss: 0.5081 - val_acc: 0.2407\n",
      "Epoch 9129/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3145 - acc: 0.2100 - val_loss: 0.3970 - val_acc: 0.2444\n",
      "Epoch 9130/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3136 - acc: 0.2100 - val_loss: 0.4112 - val_acc: 0.2444\n",
      "Epoch 9131/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3291 - acc: 0.2096 - val_loss: 0.3982 - val_acc: 0.2444\n",
      "Epoch 9132/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3144 - acc: 0.2092 - val_loss: 0.4366 - val_acc: 0.2444\n",
      "Epoch 9133/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3240 - acc: 0.2100 - val_loss: 0.3848 - val_acc: 0.2444\n",
      "Epoch 9134/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3149 - acc: 0.2096 - val_loss: 0.3873 - val_acc: 0.2444\n",
      "Epoch 9135/10000\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.5393 - acc: 0.211 - 2s 32ms/step - loss: 0.5459 - acc: 0.2096 - val_loss: 0.4923 - val_acc: 0.2444\n",
      "Epoch 9136/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3574 - acc: 0.2096 - val_loss: 0.3853 - val_acc: 0.2444\n",
      "Epoch 9137/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3363 - acc: 0.2092 - val_loss: 0.3908 - val_acc: 0.2444\n",
      "Epoch 9138/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3138 - acc: 0.2096 - val_loss: 0.3867 - val_acc: 0.2444\n",
      "Epoch 9139/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3172 - acc: 0.2096 - val_loss: 0.4362 - val_acc: 0.2444\n",
      "Epoch 9140/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3096 - acc: 0.2100 - val_loss: 0.4065 - val_acc: 0.2444\n",
      "Epoch 9141/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3215 - acc: 0.2096 - val_loss: 0.3945 - val_acc: 0.2444\n",
      "Epoch 9142/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4550 - acc: 0.2092 - val_loss: 0.4281 - val_acc: 0.2407\n",
      "Epoch 9143/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4615 - acc: 0.2100 - val_loss: 0.4403 - val_acc: 0.2444\n",
      "Epoch 9144/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3626 - acc: 0.2087 - val_loss: 0.3863 - val_acc: 0.2444\n",
      "Epoch 9145/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3228 - acc: 0.2092 - val_loss: 0.4683 - val_acc: 0.2444\n",
      "Epoch 9146/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3529 - acc: 0.2087 - val_loss: 0.3785 - val_acc: 0.2444\n",
      "Epoch 9147/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3146 - acc: 0.2096 - val_loss: 0.3874 - val_acc: 0.2444\n",
      "Epoch 9148/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3153 - acc: 0.2100 - val_loss: 0.4098 - val_acc: 0.2444\n",
      "Epoch 9149/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3091 - acc: 0.2096 - val_loss: 0.3898 - val_acc: 0.2444\n",
      "Epoch 9150/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3132 - acc: 0.2096 - val_loss: 0.3842 - val_acc: 0.2444\n",
      "Epoch 9151/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3233 - acc: 0.2096 - val_loss: 0.4030 - val_acc: 0.2444\n",
      "Epoch 9152/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3259 - acc: 0.2096 - val_loss: 0.5197 - val_acc: 0.2444\n",
      "Epoch 9153/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3130 - acc: 0.2096 - val_loss: 0.3854 - val_acc: 0.2444\n",
      "Epoch 9154/10000\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.3153 - acc: 0.209 - 2s 33ms/step - loss: 0.3153 - acc: 0.2100 - val_loss: 0.4503 - val_acc: 0.2444\n",
      "Epoch 9155/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3135 - acc: 0.2100 - val_loss: 0.4218 - val_acc: 0.2407\n",
      "Epoch 9156/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3058 - acc: 0.2100 - val_loss: 0.3796 - val_acc: 0.2444\n",
      "Epoch 9157/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3310 - acc: 0.2096 - val_loss: 0.3914 - val_acc: 0.2444\n",
      "Epoch 9158/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3358 - acc: 0.2096 - val_loss: 0.3875 - val_acc: 0.2444\n",
      "Epoch 9159/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3222 - acc: 0.2096 - val_loss: 0.3857 - val_acc: 0.2444\n",
      "Epoch 9160/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3066 - acc: 0.2096 - val_loss: 0.3926 - val_acc: 0.2444\n",
      "Epoch 9161/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3147 - acc: 0.2096 - val_loss: 0.4163 - val_acc: 0.2444\n",
      "Epoch 9162/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3100 - acc: 0.2096 - val_loss: 0.3792 - val_acc: 0.2444\n",
      "Epoch 9163/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3123 - acc: 0.2096 - val_loss: 0.3849 - val_acc: 0.2444\n",
      "Epoch 9164/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3363 - acc: 0.2092 - val_loss: 0.3938 - val_acc: 0.2444\n",
      "Epoch 9165/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3211 - acc: 0.2092 - val_loss: 0.4085 - val_acc: 0.2407\n",
      "Epoch 9166/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3299 - acc: 0.2100 - val_loss: 0.3836 - val_acc: 0.2444\n",
      "Epoch 9167/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3485 - acc: 0.2096 - val_loss: 0.3813 - val_acc: 0.2444\n",
      "Epoch 9168/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3366 - acc: 0.2092 - val_loss: 0.4139 - val_acc: 0.2444\n",
      "Epoch 9169/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3185 - acc: 0.2096 - val_loss: 0.3942 - val_acc: 0.2444\n",
      "Epoch 9170/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3089 - acc: 0.2100 - val_loss: 0.4003 - val_acc: 0.2407\n",
      "Epoch 9171/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3252 - acc: 0.2096 - val_loss: 0.3966 - val_acc: 0.2444\n",
      "Epoch 9172/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3185 - acc: 0.2100 - val_loss: 0.4186 - val_acc: 0.2407\n",
      "Epoch 9173/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3120 - acc: 0.2096 - val_loss: 0.3837 - val_acc: 0.2444\n",
      "Epoch 9174/10000\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 0.3149 - acc: 0.2096 - val_loss: 0.3811 - val_acc: 0.2444\n",
      "Epoch 9175/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.3337 - acc: 0.2087 - val_loss: 0.3975 - val_acc: 0.2444\n",
      "Epoch 9176/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3062 - acc: 0.2096 - val_loss: 0.3978 - val_acc: 0.2444\n",
      "Epoch 9177/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3156 - acc: 0.2092 - val_loss: 0.3870 - val_acc: 0.2444\n",
      "Epoch 9178/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3223 - acc: 0.2096 - val_loss: 0.3830 - val_acc: 0.2444\n",
      "Epoch 9179/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3268 - acc: 0.2096 - val_loss: 0.4810 - val_acc: 0.2444\n",
      "Epoch 9180/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3169 - acc: 0.2096 - val_loss: 0.3807 - val_acc: 0.2444\n",
      "Epoch 9181/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3359 - acc: 0.2087 - val_loss: 0.4085 - val_acc: 0.2407\n",
      "Epoch 9182/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3267 - acc: 0.2092 - val_loss: 0.3863 - val_acc: 0.2444\n",
      "Epoch 9183/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3195 - acc: 0.2100 - val_loss: 0.3839 - val_acc: 0.2444\n",
      "Epoch 9184/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3198 - acc: 0.2087 - val_loss: 0.3762 - val_acc: 0.2444\n",
      "Epoch 9185/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3359 - acc: 0.2092 - val_loss: 0.3806 - val_acc: 0.2444\n",
      "Epoch 9186/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3155 - acc: 0.2092 - val_loss: 0.3779 - val_acc: 0.2444\n",
      "Epoch 9187/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3147 - acc: 0.2096 - val_loss: 0.3772 - val_acc: 0.2444\n",
      "Epoch 9188/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3365 - acc: 0.2083 - val_loss: 0.4628 - val_acc: 0.2407\n",
      "Epoch 9189/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3203 - acc: 0.2092 - val_loss: 0.3805 - val_acc: 0.2444\n",
      "Epoch 9190/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3084 - acc: 0.2096 - val_loss: 0.3890 - val_acc: 0.2444\n",
      "Epoch 9191/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3253 - acc: 0.2092 - val_loss: 0.3867 - val_acc: 0.2444\n",
      "Epoch 9192/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3421 - acc: 0.2087 - val_loss: 0.3952 - val_acc: 0.2444\n",
      "Epoch 9193/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3147 - acc: 0.2092 - val_loss: 0.3936 - val_acc: 0.2444\n",
      "Epoch 9194/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3113 - acc: 0.2092 - val_loss: 0.3883 - val_acc: 0.2444\n",
      "Epoch 9195/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3200 - acc: 0.2092 - val_loss: 0.4421 - val_acc: 0.2444\n",
      "Epoch 9196/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3233 - acc: 0.2100 - val_loss: 0.4440 - val_acc: 0.2444\n",
      "Epoch 9197/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3189 - acc: 0.2083 - val_loss: 0.3776 - val_acc: 0.2444\n",
      "Epoch 9198/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3190 - acc: 0.2100 - val_loss: 0.4217 - val_acc: 0.2444\n",
      "Epoch 9199/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3182 - acc: 0.2096 - val_loss: 0.4456 - val_acc: 0.2407\n",
      "Epoch 9200/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3280 - acc: 0.2100 - val_loss: 0.3802 - val_acc: 0.2444\n",
      "Epoch 9201/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3138 - acc: 0.2096 - val_loss: 0.4040 - val_acc: 0.2444\n",
      "Epoch 9202/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3347 - acc: 0.2092 - val_loss: 0.3969 - val_acc: 0.2444\n",
      "Epoch 9203/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3312 - acc: 0.2092 - val_loss: 0.3882 - val_acc: 0.2444\n",
      "Epoch 9204/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3303 - acc: 0.2100 - val_loss: 0.4082 - val_acc: 0.2444\n",
      "Epoch 9205/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3206 - acc: 0.2096 - val_loss: 0.4110 - val_acc: 0.2444\n",
      "Epoch 9206/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3257 - acc: 0.2096 - val_loss: 0.3804 - val_acc: 0.2444\n",
      "Epoch 9207/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3199 - acc: 0.2092 - val_loss: 0.3923 - val_acc: 0.2444\n",
      "Epoch 9208/10000\n",
      "76/76 [==============================] - 4s 46ms/step - loss: 0.3158 - acc: 0.2100 - val_loss: 0.4495 - val_acc: 0.2407\n",
      "Epoch 9209/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.3264 - acc: 0.2096 - val_loss: 0.3844 - val_acc: 0.2444\n",
      "Epoch 9210/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3159 - acc: 0.2083 - val_loss: 0.4620 - val_acc: 0.2444\n",
      "Epoch 9211/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3225 - acc: 0.2087 - val_loss: 0.3813 - val_acc: 0.2444\n",
      "Epoch 9212/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3104 - acc: 0.2096 - val_loss: 0.3973 - val_acc: 0.2444\n",
      "Epoch 9213/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3429 - acc: 0.2092 - val_loss: 0.3795 - val_acc: 0.2444\n",
      "Epoch 9214/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3097 - acc: 0.2096 - val_loss: 0.3868 - val_acc: 0.2444\n",
      "Epoch 9215/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3545 - acc: 0.2096 - val_loss: 0.4024 - val_acc: 0.2444\n",
      "Epoch 9216/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3174 - acc: 0.2096 - val_loss: 0.4148 - val_acc: 0.2444\n",
      "Epoch 9217/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3378 - acc: 0.2096 - val_loss: 0.5253 - val_acc: 0.2407\n",
      "Epoch 9218/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3144 - acc: 0.2096 - val_loss: 0.3813 - val_acc: 0.2444\n",
      "Epoch 9219/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3269 - acc: 0.2092 - val_loss: 0.3876 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9220/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3345 - acc: 0.2092 - val_loss: 0.4261 - val_acc: 0.2444\n",
      "Epoch 9221/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3200 - acc: 0.2092 - val_loss: 0.3845 - val_acc: 0.2444\n",
      "Epoch 9222/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3335 - acc: 0.2096 - val_loss: 0.4370 - val_acc: 0.2444\n",
      "Epoch 9223/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3133 - acc: 0.2092 - val_loss: 0.3844 - val_acc: 0.2444\n",
      "Epoch 9224/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3170 - acc: 0.2096 - val_loss: 0.3930 - val_acc: 0.2444\n",
      "Epoch 9225/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3195 - acc: 0.2092 - val_loss: 0.4216 - val_acc: 0.2444\n",
      "Epoch 9226/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3301 - acc: 0.2096 - val_loss: 0.5078 - val_acc: 0.2407\n",
      "Epoch 9227/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3317 - acc: 0.2096 - val_loss: 0.4083 - val_acc: 0.2444\n",
      "Epoch 9228/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3402 - acc: 0.2092 - val_loss: 0.5358 - val_acc: 0.2444\n",
      "Epoch 9229/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3180 - acc: 0.2096 - val_loss: 0.3915 - val_acc: 0.2444\n",
      "Epoch 9230/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3354 - acc: 0.2092 - val_loss: 0.5161 - val_acc: 0.2407\n",
      "Epoch 9231/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3158 - acc: 0.2096 - val_loss: 0.3952 - val_acc: 0.2444\n",
      "Epoch 9232/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3235 - acc: 0.2092 - val_loss: 0.3864 - val_acc: 0.2444\n",
      "Epoch 9233/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3198 - acc: 0.2100 - val_loss: 0.3865 - val_acc: 0.2444\n",
      "Epoch 9234/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3127 - acc: 0.2087 - val_loss: 0.3809 - val_acc: 0.2444\n",
      "Epoch 9235/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3237 - acc: 0.2092 - val_loss: 0.3848 - val_acc: 0.2444\n",
      "Epoch 9236/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3369 - acc: 0.2092 - val_loss: 0.4106 - val_acc: 0.2444\n",
      "Epoch 9237/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3373 - acc: 0.2100 - val_loss: 0.3997 - val_acc: 0.2444\n",
      "Epoch 9238/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3149 - acc: 0.2100 - val_loss: 0.3803 - val_acc: 0.2444\n",
      "Epoch 9239/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3070 - acc: 0.2100 - val_loss: 0.3788 - val_acc: 0.2444\n",
      "Epoch 9240/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3326 - acc: 0.2092 - val_loss: 0.4010 - val_acc: 0.2444\n",
      "Epoch 9241/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3207 - acc: 0.2096 - val_loss: 0.3897 - val_acc: 0.2444\n",
      "Epoch 9242/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3059 - acc: 0.2096 - val_loss: 0.3698 - val_acc: 0.2444\n",
      "Epoch 9243/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3197 - acc: 0.2092 - val_loss: 0.3780 - val_acc: 0.2444\n",
      "Epoch 9244/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3230 - acc: 0.2100 - val_loss: 0.3783 - val_acc: 0.2444\n",
      "Epoch 9245/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3042 - acc: 0.2096 - val_loss: 0.3866 - val_acc: 0.2444\n",
      "Epoch 9246/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3140 - acc: 0.2096 - val_loss: 0.4877 - val_acc: 0.2444\n",
      "Epoch 9247/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3490 - acc: 0.2092 - val_loss: 0.3908 - val_acc: 0.2444\n",
      "Epoch 9248/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3176 - acc: 0.2100 - val_loss: 0.3852 - val_acc: 0.2444\n",
      "Epoch 9249/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3171 - acc: 0.2096 - val_loss: 0.3821 - val_acc: 0.2444\n",
      "Epoch 9250/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3292 - acc: 0.2092 - val_loss: 0.3856 - val_acc: 0.2444\n",
      "Epoch 9251/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3681 - acc: 0.2096 - val_loss: 0.3833 - val_acc: 0.2444\n",
      "Epoch 9252/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3293 - acc: 0.2087 - val_loss: 0.3731 - val_acc: 0.2444\n",
      "Epoch 9253/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3399 - acc: 0.2087 - val_loss: 0.3872 - val_acc: 0.2444\n",
      "Epoch 9254/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3174 - acc: 0.2096 - val_loss: 0.3879 - val_acc: 0.2444\n",
      "Epoch 9255/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3590 - acc: 0.2092 - val_loss: 0.6225 - val_acc: 0.2407\n",
      "Epoch 9256/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3303 - acc: 0.2096 - val_loss: 0.3843 - val_acc: 0.2444\n",
      "Epoch 9257/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3242 - acc: 0.2096 - val_loss: 0.5937 - val_acc: 0.2444\n",
      "Epoch 9258/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3479 - acc: 0.2087 - val_loss: 0.3929 - val_acc: 0.2407\n",
      "Epoch 9259/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3198 - acc: 0.2096 - val_loss: 0.4442 - val_acc: 0.2444\n",
      "Epoch 9260/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3242 - acc: 0.2100 - val_loss: 0.3907 - val_acc: 0.2407\n",
      "Epoch 9261/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3190 - acc: 0.2087 - val_loss: 0.4074 - val_acc: 0.2407\n",
      "Epoch 9262/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3084 - acc: 0.2096 - val_loss: 0.4821 - val_acc: 0.2444\n",
      "Epoch 9263/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3197 - acc: 0.2083 - val_loss: 0.3751 - val_acc: 0.2444\n",
      "Epoch 9264/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3222 - acc: 0.2096 - val_loss: 0.3751 - val_acc: 0.2444\n",
      "Epoch 9265/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3146 - acc: 0.2100 - val_loss: 0.3887 - val_acc: 0.2444\n",
      "Epoch 9266/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3150 - acc: 0.2092 - val_loss: 0.3962 - val_acc: 0.2444\n",
      "Epoch 9267/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3225 - acc: 0.2096 - val_loss: 0.3866 - val_acc: 0.2444\n",
      "Epoch 9268/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3099 - acc: 0.2096 - val_loss: 0.3813 - val_acc: 0.2444\n",
      "Epoch 9269/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3210 - acc: 0.2096 - val_loss: 0.3915 - val_acc: 0.2444\n",
      "Epoch 9270/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3199 - acc: 0.2096 - val_loss: 0.3964 - val_acc: 0.2444\n",
      "Epoch 9271/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3122 - acc: 0.2087 - val_loss: 0.4452 - val_acc: 0.2444\n",
      "Epoch 9272/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3560 - acc: 0.2087 - val_loss: 0.4058 - val_acc: 0.2407\n",
      "Epoch 9273/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3179 - acc: 0.2096 - val_loss: 0.3942 - val_acc: 0.2444\n",
      "Epoch 9274/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3175 - acc: 0.2096 - val_loss: 0.4048 - val_acc: 0.2444\n",
      "Epoch 9275/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3435 - acc: 0.2096 - val_loss: 0.4131 - val_acc: 0.2444\n",
      "Epoch 9276/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3294 - acc: 0.2092 - val_loss: 0.4752 - val_acc: 0.2407\n",
      "Epoch 9277/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3213 - acc: 0.2100 - val_loss: 0.3897 - val_acc: 0.2444\n",
      "Epoch 9278/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3128 - acc: 0.2100 - val_loss: 0.3778 - val_acc: 0.2444\n",
      "Epoch 9279/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3225 - acc: 0.2100 - val_loss: 0.4355 - val_acc: 0.2407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9280/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3216 - acc: 0.2087 - val_loss: 0.3950 - val_acc: 0.2444\n",
      "Epoch 9281/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3129 - acc: 0.2092 - val_loss: 0.3818 - val_acc: 0.2444\n",
      "Epoch 9282/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3181 - acc: 0.2092 - val_loss: 0.3837 - val_acc: 0.2444\n",
      "Epoch 9283/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3307 - acc: 0.2096 - val_loss: 0.3922 - val_acc: 0.2444\n",
      "Epoch 9284/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3198 - acc: 0.2096 - val_loss: 0.3823 - val_acc: 0.2444\n",
      "Epoch 9285/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3099 - acc: 0.2096 - val_loss: 0.3809 - val_acc: 0.2444\n",
      "Epoch 9286/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3101 - acc: 0.2100 - val_loss: 0.3848 - val_acc: 0.2444\n",
      "Epoch 9287/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3529 - acc: 0.2096 - val_loss: 0.4161 - val_acc: 0.2444\n",
      "Epoch 9288/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3299 - acc: 0.2087 - val_loss: 0.3911 - val_acc: 0.2444\n",
      "Epoch 9289/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3566 - acc: 0.2092 - val_loss: 0.4138 - val_acc: 0.2444\n",
      "Epoch 9290/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3364 - acc: 0.2096 - val_loss: 0.3927 - val_acc: 0.2444\n",
      "Epoch 9291/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3184 - acc: 0.2087 - val_loss: 0.4183 - val_acc: 0.2444\n",
      "Epoch 9292/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3429 - acc: 0.2100 - val_loss: 0.5574 - val_acc: 0.2444\n",
      "Epoch 9293/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3232 - acc: 0.2092 - val_loss: 0.4052 - val_acc: 0.2444\n",
      "Epoch 9294/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3121 - acc: 0.2096 - val_loss: 0.3932 - val_acc: 0.2444\n",
      "Epoch 9295/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3263 - acc: 0.2087 - val_loss: 0.4085 - val_acc: 0.2444\n",
      "Epoch 9296/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3053 - acc: 0.2096 - val_loss: 0.4456 - val_acc: 0.2444\n",
      "Epoch 9297/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3212 - acc: 0.2087 - val_loss: 0.3831 - val_acc: 0.2444\n",
      "Epoch 9298/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3120 - acc: 0.2100 - val_loss: 0.4377 - val_acc: 0.2444\n",
      "Epoch 9299/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3296 - acc: 0.2096 - val_loss: 0.4179 - val_acc: 0.2407\n",
      "Epoch 9300/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3145 - acc: 0.2096 - val_loss: 0.4131 - val_acc: 0.2444\n",
      "Epoch 9301/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3194 - acc: 0.2092 - val_loss: 0.3959 - val_acc: 0.2444\n",
      "Epoch 9302/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3134 - acc: 0.2100 - val_loss: 0.4704 - val_acc: 0.2407\n",
      "Epoch 9303/10000\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.3180 - acc: 0.2096 - val_loss: 0.4397 - val_acc: 0.2444\n",
      "Epoch 9304/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3243 - acc: 0.2096 - val_loss: 0.4160 - val_acc: 0.2407\n",
      "Epoch 9305/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3112 - acc: 0.2100 - val_loss: 0.4069 - val_acc: 0.2444\n",
      "Epoch 9306/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3188 - acc: 0.2096 - val_loss: 0.4040 - val_acc: 0.2444\n",
      "Epoch 9307/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3120 - acc: 0.2096 - val_loss: 0.3936 - val_acc: 0.2444\n",
      "Epoch 9308/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3247 - acc: 0.2096 - val_loss: 0.5082 - val_acc: 0.2407\n",
      "Epoch 9309/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3355 - acc: 0.2092 - val_loss: 0.4389 - val_acc: 0.2444\n",
      "Epoch 9310/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3305 - acc: 0.2092 - val_loss: 0.3747 - val_acc: 0.2444\n",
      "Epoch 9311/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3097 - acc: 0.2100 - val_loss: 0.4498 - val_acc: 0.2407\n",
      "Epoch 9312/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3523 - acc: 0.2092 - val_loss: 0.4067 - val_acc: 0.2444\n",
      "Epoch 9313/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3343 - acc: 0.2092 - val_loss: 0.3831 - val_acc: 0.2444\n",
      "Epoch 9314/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3100 - acc: 0.2096 - val_loss: 0.4388 - val_acc: 0.2407\n",
      "Epoch 9315/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3170 - acc: 0.2100 - val_loss: 0.3796 - val_acc: 0.2444\n",
      "Epoch 9316/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3190 - acc: 0.2096 - val_loss: 0.3812 - val_acc: 0.2444\n",
      "Epoch 9317/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3313 - acc: 0.2092 - val_loss: 0.3939 - val_acc: 0.2444\n",
      "Epoch 9318/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3412 - acc: 0.2087 - val_loss: 0.4255 - val_acc: 0.2407\n",
      "Epoch 9319/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3370 - acc: 0.2096 - val_loss: 0.3794 - val_acc: 0.2444\n",
      "Epoch 9320/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3213 - acc: 0.2100 - val_loss: 0.4036 - val_acc: 0.2407\n",
      "Epoch 9321/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3138 - acc: 0.2092 - val_loss: 0.3815 - val_acc: 0.2444\n",
      "Epoch 9322/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3222 - acc: 0.2092 - val_loss: 0.3965 - val_acc: 0.2444\n",
      "Epoch 9323/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3308 - acc: 0.2092 - val_loss: 0.3826 - val_acc: 0.2444\n",
      "Epoch 9324/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3275 - acc: 0.2096 - val_loss: 0.3929 - val_acc: 0.2444\n",
      "Epoch 9325/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3197 - acc: 0.2096 - val_loss: 0.3882 - val_acc: 0.2444\n",
      "Epoch 9326/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3203 - acc: 0.2100 - val_loss: 0.3964 - val_acc: 0.2444\n",
      "Epoch 9327/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3189 - acc: 0.2096 - val_loss: 0.3744 - val_acc: 0.2444\n",
      "Epoch 9328/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3136 - acc: 0.2100 - val_loss: 0.3944 - val_acc: 0.2444\n",
      "Epoch 9329/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3371 - acc: 0.2100 - val_loss: 0.5517 - val_acc: 0.2444\n",
      "Epoch 9330/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3489 - acc: 0.2087 - val_loss: 0.3857 - val_acc: 0.2444\n",
      "Epoch 9331/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3478 - acc: 0.2083 - val_loss: 0.3831 - val_acc: 0.2444\n",
      "Epoch 9332/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3249 - acc: 0.2096 - val_loss: 0.4280 - val_acc: 0.2444\n",
      "Epoch 9333/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3325 - acc: 0.2096 - val_loss: 0.4044 - val_acc: 0.2444\n",
      "Epoch 9334/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3298 - acc: 0.2096 - val_loss: 0.3792 - val_acc: 0.2444\n",
      "Epoch 9335/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3203 - acc: 0.2092 - val_loss: 0.3973 - val_acc: 0.2444\n",
      "Epoch 9336/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3157 - acc: 0.2096 - val_loss: 0.3803 - val_acc: 0.2444\n",
      "Epoch 9337/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3211 - acc: 0.2096 - val_loss: 0.3812 - val_acc: 0.2444\n",
      "Epoch 9338/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3246 - acc: 0.2087 - val_loss: 0.3907 - val_acc: 0.2444\n",
      "Epoch 9339/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3086 - acc: 0.2100 - val_loss: 0.4530 - val_acc: 0.2407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9340/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3253 - acc: 0.2096 - val_loss: 0.3715 - val_acc: 0.2444\n",
      "Epoch 9341/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3135 - acc: 0.2096 - val_loss: 0.3870 - val_acc: 0.2444\n",
      "Epoch 9342/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3262 - acc: 0.2100 - val_loss: 0.3880 - val_acc: 0.2444\n",
      "Epoch 9343/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3249 - acc: 0.2100 - val_loss: 0.4255 - val_acc: 0.2407\n",
      "Epoch 9344/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3245 - acc: 0.2083 - val_loss: 0.3961 - val_acc: 0.2444\n",
      "Epoch 9345/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3299 - acc: 0.2092 - val_loss: 0.3946 - val_acc: 0.2444\n",
      "Epoch 9346/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3228 - acc: 0.2100 - val_loss: 0.4126 - val_acc: 0.2444\n",
      "Epoch 9347/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3132 - acc: 0.2096 - val_loss: 0.3811 - val_acc: 0.2444\n",
      "Epoch 9348/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3235 - acc: 0.2092 - val_loss: 0.3815 - val_acc: 0.2444\n",
      "Epoch 9349/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3091 - acc: 0.2096 - val_loss: 0.3764 - val_acc: 0.2444\n",
      "Epoch 9350/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.3207 - acc: 0.2092 - val_loss: 0.4196 - val_acc: 0.2444\n",
      "Epoch 9351/10000\n",
      "76/76 [==============================] - 2s 30ms/step - loss: 0.3318 - acc: 0.2092 - val_loss: 0.3810 - val_acc: 0.2444\n",
      "Epoch 9352/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3231 - acc: 0.2096 - val_loss: 0.3851 - val_acc: 0.2444\n",
      "Epoch 9353/10000\n",
      "76/76 [==============================] - 2s 30ms/step - loss: 0.3164 - acc: 0.2096 - val_loss: 0.3981 - val_acc: 0.2444\n",
      "Epoch 9354/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3173 - acc: 0.2100 - val_loss: 0.4689 - val_acc: 0.2444\n",
      "Epoch 9355/10000\n",
      "76/76 [==============================] - 2s 30ms/step - loss: 0.3321 - acc: 0.2096 - val_loss: 0.3780 - val_acc: 0.2444\n",
      "Epoch 9356/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3226 - acc: 0.2092 - val_loss: 0.3863 - val_acc: 0.2444\n",
      "Epoch 9357/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3359 - acc: 0.2092 - val_loss: 0.3810 - val_acc: 0.2444\n",
      "Epoch 9358/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3224 - acc: 0.2100 - val_loss: 0.4233 - val_acc: 0.2407\n",
      "Epoch 9359/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3190 - acc: 0.2096 - val_loss: 0.3838 - val_acc: 0.2444\n",
      "Epoch 9360/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3127 - acc: 0.2096 - val_loss: 0.3771 - val_acc: 0.2444\n",
      "Epoch 9361/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3242 - acc: 0.2100 - val_loss: 0.4120 - val_acc: 0.2444\n",
      "Epoch 9362/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3183 - acc: 0.2100 - val_loss: 0.3974 - val_acc: 0.2444\n",
      "Epoch 9363/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3173 - acc: 0.2100 - val_loss: 0.4067 - val_acc: 0.2444\n",
      "Epoch 9364/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3171 - acc: 0.2100 - val_loss: 0.3845 - val_acc: 0.2444\n",
      "Epoch 9365/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3179 - acc: 0.2096 - val_loss: 0.4766 - val_acc: 0.2407\n",
      "Epoch 9366/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3391 - acc: 0.2087 - val_loss: 0.3902 - val_acc: 0.2444\n",
      "Epoch 9367/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3128 - acc: 0.2092 - val_loss: 0.4329 - val_acc: 0.2407\n",
      "Epoch 9368/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3184 - acc: 0.2100 - val_loss: 0.4251 - val_acc: 0.2444\n",
      "Epoch 9369/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3180 - acc: 0.2096 - val_loss: 0.3817 - val_acc: 0.2444\n",
      "Epoch 9370/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3361 - acc: 0.2087 - val_loss: 0.4414 - val_acc: 0.2407\n",
      "Epoch 9371/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3233 - acc: 0.2092 - val_loss: 0.4428 - val_acc: 0.2444\n",
      "Epoch 9372/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3163 - acc: 0.2100 - val_loss: 0.3799 - val_acc: 0.2444\n",
      "Epoch 9373/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3281 - acc: 0.2087 - val_loss: 0.3710 - val_acc: 0.2444\n",
      "Epoch 9374/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3138 - acc: 0.2096 - val_loss: 0.4493 - val_acc: 0.2444\n",
      "Epoch 9375/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3321 - acc: 0.2100 - val_loss: 0.3867 - val_acc: 0.2444\n",
      "Epoch 9376/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3099 - acc: 0.2100 - val_loss: 0.4211 - val_acc: 0.2444\n",
      "Epoch 9377/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3240 - acc: 0.2096 - val_loss: 0.3833 - val_acc: 0.2444\n",
      "Epoch 9378/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3084 - acc: 0.2100 - val_loss: 0.3811 - val_acc: 0.2444\n",
      "Epoch 9379/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3298 - acc: 0.2096 - val_loss: 0.4049 - val_acc: 0.2407\n",
      "Epoch 9380/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3340 - acc: 0.2096 - val_loss: 0.3952 - val_acc: 0.2444\n",
      "Epoch 9381/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3139 - acc: 0.2096 - val_loss: 0.3840 - val_acc: 0.2444\n",
      "Epoch 9382/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3192 - acc: 0.2096 - val_loss: 0.4879 - val_acc: 0.2444\n",
      "Epoch 9383/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3223 - acc: 0.2100 - val_loss: 0.3934 - val_acc: 0.2444\n",
      "Epoch 9384/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3214 - acc: 0.2092 - val_loss: 0.4522 - val_acc: 0.2444\n",
      "Epoch 9385/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3402 - acc: 0.2100 - val_loss: 0.4627 - val_acc: 0.2444\n",
      "Epoch 9386/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.3285 - acc: 0.2092 - val_loss: 0.3815 - val_acc: 0.2444\n",
      "Epoch 9387/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3352 - acc: 0.2087 - val_loss: 0.3887 - val_acc: 0.2444\n",
      "Epoch 9388/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3167 - acc: 0.2096 - val_loss: 0.4039 - val_acc: 0.2407\n",
      "Epoch 9389/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3297 - acc: 0.2100 - val_loss: 0.3829 - val_acc: 0.2444\n",
      "Epoch 9390/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3371 - acc: 0.2096 - val_loss: 0.4250 - val_acc: 0.2407\n",
      "Epoch 9391/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3255 - acc: 0.2092 - val_loss: 0.3982 - val_acc: 0.2444\n",
      "Epoch 9392/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3221 - acc: 0.2096 - val_loss: 0.3885 - val_acc: 0.2444\n",
      "Epoch 9393/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3091 - acc: 0.2096 - val_loss: 0.3884 - val_acc: 0.2444\n",
      "Epoch 9394/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3143 - acc: 0.2096 - val_loss: 0.3881 - val_acc: 0.2444\n",
      "Epoch 9395/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3243 - acc: 0.2096 - val_loss: 0.3733 - val_acc: 0.2444\n",
      "Epoch 9396/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3286 - acc: 0.2087 - val_loss: 0.3799 - val_acc: 0.2444\n",
      "Epoch 9397/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3232 - acc: 0.2100 - val_loss: 0.4085 - val_acc: 0.2407\n",
      "Epoch 9398/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3389 - acc: 0.2096 - val_loss: 0.3940 - val_acc: 0.2444\n",
      "Epoch 9399/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3433 - acc: 0.2087 - val_loss: 0.3772 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9400/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3183 - acc: 0.2100 - val_loss: 0.3855 - val_acc: 0.2444\n",
      "Epoch 9401/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3366 - acc: 0.2092 - val_loss: 0.5467 - val_acc: 0.2444\n",
      "Epoch 9402/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3569 - acc: 0.2096 - val_loss: 0.4423 - val_acc: 0.2444\n",
      "Epoch 9403/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3101 - acc: 0.2096 - val_loss: 0.4063 - val_acc: 0.2407\n",
      "Epoch 9404/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3171 - acc: 0.2092 - val_loss: 0.4000 - val_acc: 0.2407\n",
      "Epoch 9405/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3412 - acc: 0.2092 - val_loss: 0.5793 - val_acc: 0.2407\n",
      "Epoch 9406/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3202 - acc: 0.2092 - val_loss: 0.3680 - val_acc: 0.2444\n",
      "Epoch 9407/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3145 - acc: 0.2096 - val_loss: 0.4402 - val_acc: 0.2444\n",
      "Epoch 9408/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3464 - acc: 0.2087 - val_loss: 0.4110 - val_acc: 0.2444\n",
      "Epoch 9409/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3261 - acc: 0.2096 - val_loss: 0.3791 - val_acc: 0.2444\n",
      "Epoch 9410/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3501 - acc: 0.2092 - val_loss: 0.3994 - val_acc: 0.2444\n",
      "Epoch 9411/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3080 - acc: 0.2096 - val_loss: 0.3914 - val_acc: 0.2444\n",
      "Epoch 9412/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3253 - acc: 0.2092 - val_loss: 0.3824 - val_acc: 0.2444\n",
      "Epoch 9413/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3163 - acc: 0.2096 - val_loss: 0.3750 - val_acc: 0.2444\n",
      "Epoch 9414/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3189 - acc: 0.2092 - val_loss: 0.4069 - val_acc: 0.2444\n",
      "Epoch 9415/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3378 - acc: 0.2100 - val_loss: 0.5092 - val_acc: 0.2444\n",
      "Epoch 9416/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3338 - acc: 0.2100 - val_loss: 0.4092 - val_acc: 0.2444\n",
      "Epoch 9417/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3158 - acc: 0.2096 - val_loss: 0.3840 - val_acc: 0.2444\n",
      "Epoch 9418/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3305 - acc: 0.2096 - val_loss: 0.4434 - val_acc: 0.2444\n",
      "Epoch 9419/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3188 - acc: 0.2100 - val_loss: 0.3999 - val_acc: 0.2444\n",
      "Epoch 9420/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3262 - acc: 0.2100 - val_loss: 0.3952 - val_acc: 0.2444\n",
      "Epoch 9421/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3413 - acc: 0.2096 - val_loss: 0.3697 - val_acc: 0.2444\n",
      "Epoch 9422/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3123 - acc: 0.2096 - val_loss: 0.3768 - val_acc: 0.2444\n",
      "Epoch 9423/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3241 - acc: 0.2100 - val_loss: 0.3743 - val_acc: 0.2444\n",
      "Epoch 9424/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3096 - acc: 0.2100 - val_loss: 0.3717 - val_acc: 0.2444\n",
      "Epoch 9425/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3242 - acc: 0.2096 - val_loss: 0.3835 - val_acc: 0.2444\n",
      "Epoch 9426/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3234 - acc: 0.2092 - val_loss: 0.3663 - val_acc: 0.2444\n",
      "Epoch 9427/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3145 - acc: 0.2096 - val_loss: 0.4023 - val_acc: 0.2407\n",
      "Epoch 9428/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3261 - acc: 0.2092 - val_loss: 0.4079 - val_acc: 0.2407\n",
      "Epoch 9429/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3433 - acc: 0.2087 - val_loss: 0.3787 - val_acc: 0.2444\n",
      "Epoch 9430/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3132 - acc: 0.2096 - val_loss: 0.4011 - val_acc: 0.2444\n",
      "Epoch 9431/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3385 - acc: 0.2096 - val_loss: 0.4063 - val_acc: 0.2444\n",
      "Epoch 9432/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3079 - acc: 0.2096 - val_loss: 0.3818 - val_acc: 0.2444\n",
      "Epoch 9433/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3087 - acc: 0.2096 - val_loss: 0.4372 - val_acc: 0.2444\n",
      "Epoch 9434/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.3206 - acc: 0.2096 - val_loss: 0.4066 - val_acc: 0.2444\n",
      "Epoch 9435/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3166 - acc: 0.2100 - val_loss: 0.3995 - val_acc: 0.2444\n",
      "Epoch 9436/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3298 - acc: 0.2100 - val_loss: 0.3949 - val_acc: 0.2444\n",
      "Epoch 9437/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3290 - acc: 0.2096 - val_loss: 0.4341 - val_acc: 0.2407\n",
      "Epoch 9438/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3240 - acc: 0.2100 - val_loss: 0.4326 - val_acc: 0.2444\n",
      "Epoch 9439/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3371 - acc: 0.2096 - val_loss: 0.3865 - val_acc: 0.2444\n",
      "Epoch 9440/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3759 - acc: 0.2087 - val_loss: 0.3987 - val_acc: 0.2444\n",
      "Epoch 9441/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3204 - acc: 0.2092 - val_loss: 0.3915 - val_acc: 0.2444\n",
      "Epoch 9442/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3135 - acc: 0.2092 - val_loss: 0.4530 - val_acc: 0.2444\n",
      "Epoch 9443/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3304 - acc: 0.2092 - val_loss: 0.4256 - val_acc: 0.2444\n",
      "Epoch 9444/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3215 - acc: 0.2092 - val_loss: 0.4049 - val_acc: 0.2444\n",
      "Epoch 9445/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3098 - acc: 0.2096 - val_loss: 0.4104 - val_acc: 0.2444\n",
      "Epoch 9446/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3184 - acc: 0.2100 - val_loss: 0.4363 - val_acc: 0.2407\n",
      "Epoch 9447/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3220 - acc: 0.2096 - val_loss: 0.3890 - val_acc: 0.2444\n",
      "Epoch 9448/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3242 - acc: 0.2092 - val_loss: 0.4970 - val_acc: 0.2407\n",
      "Epoch 9449/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3127 - acc: 0.2096 - val_loss: 0.3931 - val_acc: 0.2444\n",
      "Epoch 9450/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3161 - acc: 0.2096 - val_loss: 0.4084 - val_acc: 0.2407\n",
      "Epoch 9451/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3431 - acc: 0.2087 - val_loss: 0.3837 - val_acc: 0.2444\n",
      "Epoch 9452/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3128 - acc: 0.2096 - val_loss: 0.3769 - val_acc: 0.2444\n",
      "Epoch 9453/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3158 - acc: 0.2096 - val_loss: 0.3881 - val_acc: 0.2407\n",
      "Epoch 9454/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3172 - acc: 0.2083 - val_loss: 0.3853 - val_acc: 0.2444\n",
      "Epoch 9455/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3259 - acc: 0.2087 - val_loss: 0.3867 - val_acc: 0.2444\n",
      "Epoch 9456/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3264 - acc: 0.2096 - val_loss: 0.3836 - val_acc: 0.2444\n",
      "Epoch 9457/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3278 - acc: 0.2100 - val_loss: 0.3799 - val_acc: 0.2444\n",
      "Epoch 9458/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3471 - acc: 0.2096 - val_loss: 0.3934 - val_acc: 0.2444\n",
      "Epoch 9459/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3164 - acc: 0.2096 - val_loss: 0.4244 - val_acc: 0.2407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9460/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3142 - acc: 0.2096 - val_loss: 0.3706 - val_acc: 0.2444\n",
      "Epoch 9461/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3313 - acc: 0.2092 - val_loss: 0.4564 - val_acc: 0.2407\n",
      "Epoch 9462/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3136 - acc: 0.2096 - val_loss: 0.3844 - val_acc: 0.2444\n",
      "Epoch 9463/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3279 - acc: 0.2096 - val_loss: 0.3796 - val_acc: 0.2444\n",
      "Epoch 9464/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3323 - acc: 0.2092 - val_loss: 0.4345 - val_acc: 0.2444\n",
      "Epoch 9465/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3264 - acc: 0.2087 - val_loss: 0.3920 - val_acc: 0.2444\n",
      "Epoch 9466/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3159 - acc: 0.2092 - val_loss: 0.3962 - val_acc: 0.2444\n",
      "Epoch 9467/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3195 - acc: 0.2096 - val_loss: 0.4019 - val_acc: 0.2444\n",
      "Epoch 9468/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3155 - acc: 0.2096 - val_loss: 0.3632 - val_acc: 0.2444\n",
      "Epoch 9469/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3125 - acc: 0.2100 - val_loss: 0.3842 - val_acc: 0.2444\n",
      "Epoch 9470/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3360 - acc: 0.2092 - val_loss: 0.4928 - val_acc: 0.2407\n",
      "Epoch 9471/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3124 - acc: 0.2100 - val_loss: 0.3804 - val_acc: 0.2444\n",
      "Epoch 9472/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3189 - acc: 0.2092 - val_loss: 0.3958 - val_acc: 0.2444\n",
      "Epoch 9473/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3155 - acc: 0.2100 - val_loss: 0.5423 - val_acc: 0.2444\n",
      "Epoch 9474/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3210 - acc: 0.2092 - val_loss: 0.4110 - val_acc: 0.2407\n",
      "Epoch 9475/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3242 - acc: 0.2087 - val_loss: 0.4311 - val_acc: 0.2444\n",
      "Epoch 9476/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3171 - acc: 0.2092 - val_loss: 0.3868 - val_acc: 0.2444\n",
      "Epoch 9477/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3069 - acc: 0.2100 - val_loss: 0.4012 - val_acc: 0.2444\n",
      "Epoch 9478/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3312 - acc: 0.2100 - val_loss: 0.3858 - val_acc: 0.2444\n",
      "Epoch 9479/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3496 - acc: 0.2092 - val_loss: 0.3727 - val_acc: 0.2444\n",
      "Epoch 9480/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4402 - acc: 0.2092 - val_loss: 0.5875 - val_acc: 0.2407\n",
      "Epoch 9481/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3665 - acc: 0.2092 - val_loss: 0.3619 - val_acc: 0.2444\n",
      "Epoch 9482/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3151 - acc: 0.2096 - val_loss: 0.3900 - val_acc: 0.2444\n",
      "Epoch 9483/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3191 - acc: 0.2092 - val_loss: 0.3853 - val_acc: 0.2444\n",
      "Epoch 9484/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3130 - acc: 0.2100 - val_loss: 0.3818 - val_acc: 0.2444\n",
      "Epoch 9485/10000\n",
      "76/76 [==============================] - 4s 49ms/step - loss: 0.3070 - acc: 0.2100 - val_loss: 0.3750 - val_acc: 0.2444\n",
      "Epoch 9486/10000\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.3234 - acc: 0.2100 - val_loss: 0.3738 - val_acc: 0.2444\n",
      "Epoch 9487/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3152 - acc: 0.2100 - val_loss: 0.3763 - val_acc: 0.2444\n",
      "Epoch 9488/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3192 - acc: 0.2100 - val_loss: 0.4361 - val_acc: 0.2407\n",
      "Epoch 9489/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3468 - acc: 0.2096 - val_loss: 0.3841 - val_acc: 0.2444\n",
      "Epoch 9490/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.3114 - acc: 0.2096 - val_loss: 0.3884 - val_acc: 0.2444\n",
      "Epoch 9491/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3133 - acc: 0.2087 - val_loss: 0.3870 - val_acc: 0.2444\n",
      "Epoch 9492/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3203 - acc: 0.2092 - val_loss: 0.3874 - val_acc: 0.2444\n",
      "Epoch 9493/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3298 - acc: 0.2087 - val_loss: 0.4489 - val_acc: 0.2407\n",
      "Epoch 9494/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3379 - acc: 0.2087 - val_loss: 0.4209 - val_acc: 0.2444\n",
      "Epoch 9495/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.7932 - acc: 0.2087 - val_loss: 0.6423 - val_acc: 0.2407\n",
      "Epoch 9496/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4049 - acc: 0.2100 - val_loss: 0.4429 - val_acc: 0.2444\n",
      "Epoch 9497/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3495 - acc: 0.2092 - val_loss: 0.3851 - val_acc: 0.2444\n",
      "Epoch 9498/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3465 - acc: 0.2096 - val_loss: 0.3614 - val_acc: 0.2444\n",
      "Epoch 9499/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3188 - acc: 0.2096 - val_loss: 0.3847 - val_acc: 0.2444\n",
      "Epoch 9500/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3149 - acc: 0.2096 - val_loss: 0.4047 - val_acc: 0.2444\n",
      "Epoch 9501/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3224 - acc: 0.2096 - val_loss: 0.3931 - val_acc: 0.2444\n",
      "Epoch 9502/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3204 - acc: 0.2100 - val_loss: 0.3702 - val_acc: 0.2444\n",
      "Epoch 9503/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3168 - acc: 0.2096 - val_loss: 0.3792 - val_acc: 0.2444\n",
      "Epoch 9504/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3124 - acc: 0.2096 - val_loss: 0.3714 - val_acc: 0.2444\n",
      "Epoch 9505/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3145 - acc: 0.2100 - val_loss: 0.3752 - val_acc: 0.2444\n",
      "Epoch 9506/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3107 - acc: 0.2096 - val_loss: 0.3816 - val_acc: 0.2444\n",
      "Epoch 9507/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3222 - acc: 0.2100 - val_loss: 0.3992 - val_acc: 0.2444\n",
      "Epoch 9508/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3170 - acc: 0.2096 - val_loss: 0.4078 - val_acc: 0.2444\n",
      "Epoch 9509/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3135 - acc: 0.2096 - val_loss: 0.4004 - val_acc: 0.2444\n",
      "Epoch 9510/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3158 - acc: 0.2096 - val_loss: 0.3857 - val_acc: 0.2444\n",
      "Epoch 9511/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3229 - acc: 0.2100 - val_loss: 0.4074 - val_acc: 0.2444\n",
      "Epoch 9512/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3181 - acc: 0.2096 - val_loss: 0.3865 - val_acc: 0.2444\n",
      "Epoch 9513/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3181 - acc: 0.2092 - val_loss: 0.3819 - val_acc: 0.2444\n",
      "Epoch 9514/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3126 - acc: 0.2087 - val_loss: 0.3758 - val_acc: 0.2444\n",
      "Epoch 9515/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3252 - acc: 0.2100 - val_loss: 0.4214 - val_acc: 0.2407\n",
      "Epoch 9516/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3123 - acc: 0.2096 - val_loss: 0.3935 - val_acc: 0.2444\n",
      "Epoch 9517/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3202 - acc: 0.2096 - val_loss: 0.3825 - val_acc: 0.2444\n",
      "Epoch 9518/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3248 - acc: 0.2100 - val_loss: 0.4901 - val_acc: 0.2407\n",
      "Epoch 9519/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3335 - acc: 0.2100 - val_loss: 0.4045 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9520/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3290 - acc: 0.2096 - val_loss: 0.3936 - val_acc: 0.2444\n",
      "Epoch 9521/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3322 - acc: 0.2092 - val_loss: 0.4577 - val_acc: 0.2444\n",
      "Epoch 9522/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3201 - acc: 0.2096 - val_loss: 0.3990 - val_acc: 0.2444\n",
      "Epoch 9523/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3344 - acc: 0.2100 - val_loss: 0.4752 - val_acc: 0.2444\n",
      "Epoch 9524/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3121 - acc: 0.2096 - val_loss: 0.3981 - val_acc: 0.2444\n",
      "Epoch 9525/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3164 - acc: 0.2096 - val_loss: 0.4158 - val_acc: 0.2407\n",
      "Epoch 9526/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3134 - acc: 0.2096 - val_loss: 0.3864 - val_acc: 0.2444\n",
      "Epoch 9527/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3213 - acc: 0.2096 - val_loss: 0.3806 - val_acc: 0.2444\n",
      "Epoch 9528/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3276 - acc: 0.2100 - val_loss: 0.3890 - val_acc: 0.2444\n",
      "Epoch 9529/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3373 - acc: 0.2100 - val_loss: 0.4096 - val_acc: 0.2407\n",
      "Epoch 9530/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3341 - acc: 0.2092 - val_loss: 0.3856 - val_acc: 0.2444\n",
      "Epoch 9531/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3163 - acc: 0.2092 - val_loss: 0.3796 - val_acc: 0.2444\n",
      "Epoch 9532/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3066 - acc: 0.2100 - val_loss: 0.4002 - val_acc: 0.2444\n",
      "Epoch 9533/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3247 - acc: 0.2100 - val_loss: 0.3945 - val_acc: 0.2444\n",
      "Epoch 9534/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3165 - acc: 0.2087 - val_loss: 0.4898 - val_acc: 0.2444\n",
      "Epoch 9535/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3358 - acc: 0.2092 - val_loss: 0.3775 - val_acc: 0.2444\n",
      "Epoch 9536/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3297 - acc: 0.2096 - val_loss: 0.3766 - val_acc: 0.2444\n",
      "Epoch 9537/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3186 - acc: 0.2096 - val_loss: 0.3929 - val_acc: 0.2444\n",
      "Epoch 9538/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3039 - acc: 0.2100 - val_loss: 0.3812 - val_acc: 0.2444\n",
      "Epoch 9539/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3241 - acc: 0.2087 - val_loss: 0.3791 - val_acc: 0.2444\n",
      "Epoch 9540/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3100 - acc: 0.2100 - val_loss: 0.4046 - val_acc: 0.2444\n",
      "Epoch 9541/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3266 - acc: 0.2092 - val_loss: 0.4074 - val_acc: 0.2444\n",
      "Epoch 9542/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3077 - acc: 0.2096 - val_loss: 0.3879 - val_acc: 0.2444\n",
      "Epoch 9543/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3285 - acc: 0.2100 - val_loss: 0.3945 - val_acc: 0.2444\n",
      "Epoch 9544/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3142 - acc: 0.2092 - val_loss: 0.5358 - val_acc: 0.2444\n",
      "Epoch 9545/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3335 - acc: 0.2096 - val_loss: 0.4111 - val_acc: 0.2444\n",
      "Epoch 9546/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3113 - acc: 0.2096 - val_loss: 0.4572 - val_acc: 0.2407\n",
      "Epoch 9547/10000\n",
      "76/76 [==============================] - 2s 31ms/step - loss: 0.3272 - acc: 0.2087 - val_loss: 0.4492 - val_acc: 0.2407\n",
      "Epoch 9548/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3202 - acc: 0.2096 - val_loss: 0.4011 - val_acc: 0.2444\n",
      "Epoch 9549/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3231 - acc: 0.2092 - val_loss: 0.3733 - val_acc: 0.2444\n",
      "Epoch 9550/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3211 - acc: 0.2096 - val_loss: 0.4207 - val_acc: 0.2444\n",
      "Epoch 9551/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3227 - acc: 0.2096 - val_loss: 0.4091 - val_acc: 0.2444\n",
      "Epoch 9552/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3268 - acc: 0.2096 - val_loss: 0.3932 - val_acc: 0.2444\n",
      "Epoch 9553/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3143 - acc: 0.2096 - val_loss: 0.3923 - val_acc: 0.2444\n",
      "Epoch 9554/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3163 - acc: 0.2096 - val_loss: 0.3774 - val_acc: 0.2444\n",
      "Epoch 9555/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3091 - acc: 0.2100 - val_loss: 0.3729 - val_acc: 0.2444\n",
      "Epoch 9556/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3187 - acc: 0.2092 - val_loss: 0.3858 - val_acc: 0.2444\n",
      "Epoch 9557/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3219 - acc: 0.2100 - val_loss: 0.3916 - val_acc: 0.2444\n",
      "Epoch 9558/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3242 - acc: 0.2092 - val_loss: 0.4527 - val_acc: 0.2444\n",
      "Epoch 9559/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3181 - acc: 0.2100 - val_loss: 0.3880 - val_acc: 0.2444\n",
      "Epoch 9560/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3103 - acc: 0.2100 - val_loss: 0.3879 - val_acc: 0.2444\n",
      "Epoch 9561/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3352 - acc: 0.2096 - val_loss: 0.5498 - val_acc: 0.2444\n",
      "Epoch 9562/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3313 - acc: 0.2100 - val_loss: 0.4051 - val_acc: 0.2444\n",
      "Epoch 9563/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3240 - acc: 0.2096 - val_loss: 0.4557 - val_acc: 0.2407\n",
      "Epoch 9564/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3144 - acc: 0.2100 - val_loss: 0.3750 - val_acc: 0.2444\n",
      "Epoch 9565/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.3187 - acc: 0.2092 - val_loss: 0.4055 - val_acc: 0.2444\n",
      "Epoch 9566/10000\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 0.3156 - acc: 0.2100 - val_loss: 0.3867 - val_acc: 0.2444\n",
      "Epoch 9567/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3336 - acc: 0.2096 - val_loss: 0.3835 - val_acc: 0.2444\n",
      "Epoch 9568/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3345 - acc: 0.2096 - val_loss: 0.4475 - val_acc: 0.2407\n",
      "Epoch 9569/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3416 - acc: 0.2096 - val_loss: 0.4316 - val_acc: 0.2444\n",
      "Epoch 9570/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3127 - acc: 0.2096 - val_loss: 0.3846 - val_acc: 0.2444\n",
      "Epoch 9571/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3301 - acc: 0.2092 - val_loss: 0.3716 - val_acc: 0.2444\n",
      "Epoch 9572/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3289 - acc: 0.2096 - val_loss: 0.4003 - val_acc: 0.2444\n",
      "Epoch 9573/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3215 - acc: 0.2092 - val_loss: 0.5748 - val_acc: 0.2444\n",
      "Epoch 9574/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3218 - acc: 0.2096 - val_loss: 0.3823 - val_acc: 0.2444\n",
      "Epoch 9575/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3409 - acc: 0.2083 - val_loss: 0.4045 - val_acc: 0.2444\n",
      "Epoch 9576/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3285 - acc: 0.2096 - val_loss: 0.3748 - val_acc: 0.2444\n",
      "Epoch 9577/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3111 - acc: 0.2087 - val_loss: 0.3798 - val_acc: 0.2444\n",
      "Epoch 9578/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3141 - acc: 0.2096 - val_loss: 0.3906 - val_acc: 0.2444\n",
      "Epoch 9579/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3091 - acc: 0.2100 - val_loss: 0.3762 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9580/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3472 - acc: 0.2096 - val_loss: 0.3765 - val_acc: 0.2444\n",
      "Epoch 9581/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3122 - acc: 0.2092 - val_loss: 0.3805 - val_acc: 0.2444\n",
      "Epoch 9582/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3049 - acc: 0.2096 - val_loss: 0.4246 - val_acc: 0.2444\n",
      "Epoch 9583/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3157 - acc: 0.2087 - val_loss: 0.3883 - val_acc: 0.2444\n",
      "Epoch 9584/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3087 - acc: 0.2100 - val_loss: 0.4655 - val_acc: 0.2407\n",
      "Epoch 9585/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3234 - acc: 0.2096 - val_loss: 0.3828 - val_acc: 0.2444\n",
      "Epoch 9586/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3269 - acc: 0.2096 - val_loss: 0.3920 - val_acc: 0.2444\n",
      "Epoch 9587/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3148 - acc: 0.2092 - val_loss: 0.4280 - val_acc: 0.2407\n",
      "Epoch 9588/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3321 - acc: 0.2087 - val_loss: 0.3867 - val_acc: 0.2444\n",
      "Epoch 9589/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3262 - acc: 0.2100 - val_loss: 0.4098 - val_acc: 0.2444\n",
      "Epoch 9590/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3345 - acc: 0.2100 - val_loss: 0.4126 - val_acc: 0.2444\n",
      "Epoch 9591/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3234 - acc: 0.2096 - val_loss: 0.4022 - val_acc: 0.2444\n",
      "Epoch 9592/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3324 - acc: 0.2096 - val_loss: 0.3796 - val_acc: 0.2444\n",
      "Epoch 9593/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3310 - acc: 0.2100 - val_loss: 0.4076 - val_acc: 0.2444\n",
      "Epoch 9594/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3210 - acc: 0.2096 - val_loss: 0.3910 - val_acc: 0.2444\n",
      "Epoch 9595/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3216 - acc: 0.2096 - val_loss: 0.4026 - val_acc: 0.2444\n",
      "Epoch 9596/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3106 - acc: 0.2096 - val_loss: 0.3903 - val_acc: 0.2444\n",
      "Epoch 9597/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3219 - acc: 0.2100 - val_loss: 0.4090 - val_acc: 0.2444\n",
      "Epoch 9598/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3206 - acc: 0.2096 - val_loss: 0.3733 - val_acc: 0.2444\n",
      "Epoch 9599/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3325 - acc: 0.2096 - val_loss: 0.3765 - val_acc: 0.2444\n",
      "Epoch 9600/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3067 - acc: 0.2100 - val_loss: 0.4039 - val_acc: 0.2444\n",
      "Epoch 9601/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3234 - acc: 0.2092 - val_loss: 0.3736 - val_acc: 0.2444\n",
      "Epoch 9602/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3157 - acc: 0.2100 - val_loss: 0.4299 - val_acc: 0.2407\n",
      "Epoch 9603/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3163 - acc: 0.2096 - val_loss: 0.4210 - val_acc: 0.2444\n",
      "Epoch 9604/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3138 - acc: 0.2100 - val_loss: 0.3694 - val_acc: 0.2444\n",
      "Epoch 9605/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3208 - acc: 0.2100 - val_loss: 0.3847 - val_acc: 0.2444\n",
      "Epoch 9606/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3178 - acc: 0.2096 - val_loss: 0.4279 - val_acc: 0.2444\n",
      "Epoch 9607/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3144 - acc: 0.2092 - val_loss: 0.3876 - val_acc: 0.2444\n",
      "Epoch 9608/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3055 - acc: 0.2096 - val_loss: 0.3758 - val_acc: 0.2444\n",
      "Epoch 9609/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3402 - acc: 0.2079 - val_loss: 0.4015 - val_acc: 0.2444\n",
      "Epoch 9610/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3240 - acc: 0.2096 - val_loss: 0.4211 - val_acc: 0.2444\n",
      "Epoch 9611/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3446 - acc: 0.2100 - val_loss: 0.4904 - val_acc: 0.2444\n",
      "Epoch 9612/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3185 - acc: 0.2092 - val_loss: 0.3829 - val_acc: 0.2444\n",
      "Epoch 9613/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3179 - acc: 0.2100 - val_loss: 0.3999 - val_acc: 0.2444\n",
      "Epoch 9614/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3332 - acc: 0.2092 - val_loss: 0.3921 - val_acc: 0.2444\n",
      "Epoch 9615/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3317 - acc: 0.2079 - val_loss: 0.3825 - val_acc: 0.2444\n",
      "Epoch 9616/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3201 - acc: 0.2092 - val_loss: 0.3997 - val_acc: 0.2444\n",
      "Epoch 9617/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3241 - acc: 0.2096 - val_loss: 0.5311 - val_acc: 0.2407\n",
      "Epoch 9618/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3128 - acc: 0.2092 - val_loss: 0.4154 - val_acc: 0.2407\n",
      "Epoch 9619/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3206 - acc: 0.2092 - val_loss: 0.4816 - val_acc: 0.2444\n",
      "Epoch 9620/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3288 - acc: 0.2096 - val_loss: 0.5766 - val_acc: 0.2444\n",
      "Epoch 9621/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3524 - acc: 0.2096 - val_loss: 0.3769 - val_acc: 0.2444\n",
      "Epoch 9622/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3132 - acc: 0.2096 - val_loss: 0.3864 - val_acc: 0.2444\n",
      "Epoch 9623/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3150 - acc: 0.2100 - val_loss: 0.3847 - val_acc: 0.2444\n",
      "Epoch 9624/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3264 - acc: 0.2100 - val_loss: 0.3791 - val_acc: 0.2444\n",
      "Epoch 9625/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3233 - acc: 0.2096 - val_loss: 0.3967 - val_acc: 0.2444\n",
      "Epoch 9626/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3266 - acc: 0.2096 - val_loss: 0.3710 - val_acc: 0.2444\n",
      "Epoch 9627/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3089 - acc: 0.2096 - val_loss: 0.3747 - val_acc: 0.2444\n",
      "Epoch 9628/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3070 - acc: 0.2096 - val_loss: 0.4105 - val_acc: 0.2444\n",
      "Epoch 9629/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3150 - acc: 0.2100 - val_loss: 0.3873 - val_acc: 0.2444\n",
      "Epoch 9630/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3141 - acc: 0.2092 - val_loss: 0.4079 - val_acc: 0.2444\n",
      "Epoch 9631/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3263 - acc: 0.2096 - val_loss: 0.4292 - val_acc: 0.2444\n",
      "Epoch 9632/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3120 - acc: 0.2100 - val_loss: 0.3866 - val_acc: 0.2444\n",
      "Epoch 9633/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3166 - acc: 0.2100 - val_loss: 0.4792 - val_acc: 0.2407\n",
      "Epoch 9634/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3383 - acc: 0.2096 - val_loss: 0.4438 - val_acc: 0.2407\n",
      "Epoch 9635/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3181 - acc: 0.2096 - val_loss: 0.5805 - val_acc: 0.2444\n",
      "Epoch 9636/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3347 - acc: 0.2087 - val_loss: 0.3871 - val_acc: 0.2444\n",
      "Epoch 9637/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3220 - acc: 0.2096 - val_loss: 0.5934 - val_acc: 0.2444\n",
      "Epoch 9638/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3121 - acc: 0.2096 - val_loss: 0.3913 - val_acc: 0.2444\n",
      "Epoch 9639/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3294 - acc: 0.2092 - val_loss: 0.4872 - val_acc: 0.2407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9640/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3112 - acc: 0.2092 - val_loss: 0.3954 - val_acc: 0.2444\n",
      "Epoch 9641/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3163 - acc: 0.2092 - val_loss: 0.3731 - val_acc: 0.2444\n",
      "Epoch 9642/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3259 - acc: 0.2087 - val_loss: 0.3837 - val_acc: 0.2444\n",
      "Epoch 9643/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3219 - acc: 0.2092 - val_loss: 0.3884 - val_acc: 0.2444\n",
      "Epoch 9644/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3270 - acc: 0.2096 - val_loss: 0.3894 - val_acc: 0.2444\n",
      "Epoch 9645/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3322 - acc: 0.2096 - val_loss: 0.3937 - val_acc: 0.2444\n",
      "Epoch 9646/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3266 - acc: 0.2087 - val_loss: 0.4479 - val_acc: 0.2444\n",
      "Epoch 9647/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3292 - acc: 0.2096 - val_loss: 0.3849 - val_acc: 0.2444\n",
      "Epoch 9648/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3382 - acc: 0.2096 - val_loss: 0.4067 - val_acc: 0.2444\n",
      "Epoch 9649/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3097 - acc: 0.2100 - val_loss: 0.3858 - val_acc: 0.2444\n",
      "Epoch 9650/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3062 - acc: 0.2092 - val_loss: 0.4532 - val_acc: 0.2444\n",
      "Epoch 9651/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3087 - acc: 0.2100 - val_loss: 0.3888 - val_acc: 0.2444\n",
      "Epoch 9652/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3071 - acc: 0.2096 - val_loss: 0.4280 - val_acc: 0.2444\n",
      "Epoch 9653/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3099 - acc: 0.2100 - val_loss: 0.3889 - val_acc: 0.2444\n",
      "Epoch 9654/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3394 - acc: 0.2092 - val_loss: 0.3761 - val_acc: 0.2444\n",
      "Epoch 9655/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3093 - acc: 0.2096 - val_loss: 0.3938 - val_acc: 0.2444\n",
      "Epoch 9656/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3582 - acc: 0.2092 - val_loss: 0.3979 - val_acc: 0.2444\n",
      "Epoch 9657/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3112 - acc: 0.2096 - val_loss: 0.4197 - val_acc: 0.2407\n",
      "Epoch 9658/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3239 - acc: 0.2087 - val_loss: 0.3742 - val_acc: 0.2444\n",
      "Epoch 9659/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3432 - acc: 0.2092 - val_loss: 0.4343 - val_acc: 0.2407\n",
      "Epoch 9660/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3381 - acc: 0.2092 - val_loss: 0.3941 - val_acc: 0.2444\n",
      "Epoch 9661/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3277 - acc: 0.2100 - val_loss: 0.3987 - val_acc: 0.2407\n",
      "Epoch 9662/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3156 - acc: 0.2092 - val_loss: 0.3698 - val_acc: 0.2444\n",
      "Epoch 9663/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3398 - acc: 0.2092 - val_loss: 0.4005 - val_acc: 0.2444\n",
      "Epoch 9664/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3274 - acc: 0.2092 - val_loss: 0.4276 - val_acc: 0.2444\n",
      "Epoch 9665/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3598 - acc: 0.2100 - val_loss: 0.3787 - val_acc: 0.2444\n",
      "Epoch 9666/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3283 - acc: 0.2100 - val_loss: 0.4112 - val_acc: 0.2407\n",
      "Epoch 9667/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3132 - acc: 0.2100 - val_loss: 0.3763 - val_acc: 0.2444\n",
      "Epoch 9668/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3348 - acc: 0.2096 - val_loss: 0.3911 - val_acc: 0.2444\n",
      "Epoch 9669/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3271 - acc: 0.2092 - val_loss: 0.4711 - val_acc: 0.2444\n",
      "Epoch 9670/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3198 - acc: 0.2092 - val_loss: 0.3876 - val_acc: 0.2444\n",
      "Epoch 9671/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3135 - acc: 0.2096 - val_loss: 0.3716 - val_acc: 0.2444\n",
      "Epoch 9672/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3075 - acc: 0.2100 - val_loss: 0.3775 - val_acc: 0.2444\n",
      "Epoch 9673/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3275 - acc: 0.2096 - val_loss: 0.3982 - val_acc: 0.2444\n",
      "Epoch 9674/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3246 - acc: 0.2096 - val_loss: 0.4035 - val_acc: 0.2444\n",
      "Epoch 9675/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3187 - acc: 0.2096 - val_loss: 0.3993 - val_acc: 0.2444\n",
      "Epoch 9676/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3170 - acc: 0.2096 - val_loss: 0.4492 - val_acc: 0.2407\n",
      "Epoch 9677/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3297 - acc: 0.2096 - val_loss: 0.4110 - val_acc: 0.2444\n",
      "Epoch 9678/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3144 - acc: 0.2092 - val_loss: 0.3781 - val_acc: 0.2444\n",
      "Epoch 9679/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3215 - acc: 0.2092 - val_loss: 0.5423 - val_acc: 0.2444\n",
      "Epoch 9680/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3239 - acc: 0.2096 - val_loss: 0.3945 - val_acc: 0.2444\n",
      "Epoch 9681/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3180 - acc: 0.2092 - val_loss: 0.3866 - val_acc: 0.2444\n",
      "Epoch 9682/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3181 - acc: 0.2100 - val_loss: 0.4084 - val_acc: 0.2407\n",
      "Epoch 9683/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3316 - acc: 0.2100 - val_loss: 0.3927 - val_acc: 0.2444\n",
      "Epoch 9684/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3365 - acc: 0.2100 - val_loss: 0.3915 - val_acc: 0.2444\n",
      "Epoch 9685/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3180 - acc: 0.2096 - val_loss: 0.3976 - val_acc: 0.2407\n",
      "Epoch 9686/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3095 - acc: 0.2100 - val_loss: 0.4971 - val_acc: 0.2444\n",
      "Epoch 9687/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3476 - acc: 0.2096 - val_loss: 0.5553 - val_acc: 0.2444\n",
      "Epoch 9688/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3306 - acc: 0.2096 - val_loss: 0.4155 - val_acc: 0.2407\n",
      "Epoch 9689/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3274 - acc: 0.2096 - val_loss: 0.3849 - val_acc: 0.2444\n",
      "Epoch 9690/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3082 - acc: 0.2092 - val_loss: 0.5591 - val_acc: 0.2444\n",
      "Epoch 9691/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3455 - acc: 0.2096 - val_loss: 0.4427 - val_acc: 0.2444\n",
      "Epoch 9692/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3195 - acc: 0.2096 - val_loss: 0.3746 - val_acc: 0.2444\n",
      "Epoch 9693/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3423 - acc: 0.2087 - val_loss: 0.4113 - val_acc: 0.2444\n",
      "Epoch 9694/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3229 - acc: 0.2096 - val_loss: 0.4107 - val_acc: 0.2444\n",
      "Epoch 9695/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3139 - acc: 0.2100 - val_loss: 0.3881 - val_acc: 0.2444\n",
      "Epoch 9696/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3179 - acc: 0.2092 - val_loss: 0.3889 - val_acc: 0.2444\n",
      "Epoch 9697/10000\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 0.3131 - acc: 0.2100 - val_loss: 0.3950 - val_acc: 0.2444\n",
      "Epoch 9698/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.3161 - acc: 0.2087 - val_loss: 0.3813 - val_acc: 0.2444\n",
      "Epoch 9699/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3254 - acc: 0.2092 - val_loss: 0.4448 - val_acc: 0.2407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9700/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3413 - acc: 0.2096 - val_loss: 0.3753 - val_acc: 0.2444\n",
      "Epoch 9701/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3159 - acc: 0.2096 - val_loss: 0.3818 - val_acc: 0.2444\n",
      "Epoch 9702/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3170 - acc: 0.2096 - val_loss: 0.3844 - val_acc: 0.2444\n",
      "Epoch 9703/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3114 - acc: 0.2096 - val_loss: 0.3792 - val_acc: 0.2444\n",
      "Epoch 9704/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3374 - acc: 0.2100 - val_loss: 0.3800 - val_acc: 0.2444\n",
      "Epoch 9705/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3168 - acc: 0.2096 - val_loss: 0.3708 - val_acc: 0.2444\n",
      "Epoch 9706/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3189 - acc: 0.2100 - val_loss: 0.4005 - val_acc: 0.2407\n",
      "Epoch 9707/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3133 - acc: 0.2100 - val_loss: 0.4353 - val_acc: 0.2407\n",
      "Epoch 9708/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3175 - acc: 0.2092 - val_loss: 0.3805 - val_acc: 0.2444\n",
      "Epoch 9709/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3124 - acc: 0.2092 - val_loss: 0.4213 - val_acc: 0.2407\n",
      "Epoch 9710/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3117 - acc: 0.2096 - val_loss: 0.3954 - val_acc: 0.2444\n",
      "Epoch 9711/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3372 - acc: 0.2096 - val_loss: 0.3989 - val_acc: 0.2444\n",
      "Epoch 9712/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3239 - acc: 0.2096 - val_loss: 0.3793 - val_acc: 0.2444\n",
      "Epoch 9713/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3306 - acc: 0.2092 - val_loss: 0.4429 - val_acc: 0.2444\n",
      "Epoch 9714/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3451 - acc: 0.2096 - val_loss: 0.4119 - val_acc: 0.2407\n",
      "Epoch 9715/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3291 - acc: 0.2092 - val_loss: 0.3781 - val_acc: 0.2444\n",
      "Epoch 9716/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3137 - acc: 0.2100 - val_loss: 0.4074 - val_acc: 0.2444\n",
      "Epoch 9717/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3331 - acc: 0.2096 - val_loss: 0.3872 - val_acc: 0.2444\n",
      "Epoch 9718/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3228 - acc: 0.2096 - val_loss: 0.4173 - val_acc: 0.2444\n",
      "Epoch 9719/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3173 - acc: 0.2100 - val_loss: 0.4046 - val_acc: 0.2444\n",
      "Epoch 9720/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3116 - acc: 0.2096 - val_loss: 0.4142 - val_acc: 0.2407\n",
      "Epoch 9721/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3292 - acc: 0.2096 - val_loss: 0.3767 - val_acc: 0.2444\n",
      "Epoch 9722/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3157 - acc: 0.2096 - val_loss: 0.4804 - val_acc: 0.2407\n",
      "Epoch 9723/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3368 - acc: 0.2096 - val_loss: 0.4139 - val_acc: 0.2444\n",
      "Epoch 9724/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3284 - acc: 0.2100 - val_loss: 0.3797 - val_acc: 0.2444\n",
      "Epoch 9725/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3105 - acc: 0.2096 - val_loss: 0.3969 - val_acc: 0.2444\n",
      "Epoch 9726/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3602 - acc: 0.2096 - val_loss: 0.4013 - val_acc: 0.2444\n",
      "Epoch 9727/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3180 - acc: 0.2096 - val_loss: 0.4126 - val_acc: 0.2444\n",
      "Epoch 9728/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3386 - acc: 0.2096 - val_loss: 0.4210 - val_acc: 0.2444\n",
      "Epoch 9729/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3244 - acc: 0.2092 - val_loss: 0.3764 - val_acc: 0.2444\n",
      "Epoch 9730/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3078 - acc: 0.2096 - val_loss: 0.3739 - val_acc: 0.2444\n",
      "Epoch 9731/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3131 - acc: 0.2092 - val_loss: 0.3788 - val_acc: 0.2444\n",
      "Epoch 9732/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3111 - acc: 0.2092 - val_loss: 0.3857 - val_acc: 0.2444\n",
      "Epoch 9733/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3210 - acc: 0.2096 - val_loss: 0.4474 - val_acc: 0.2444\n",
      "Epoch 9734/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3155 - acc: 0.2096 - val_loss: 0.4276 - val_acc: 0.2444\n",
      "Epoch 9735/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3283 - acc: 0.2096 - val_loss: 0.4371 - val_acc: 0.2444\n",
      "Epoch 9736/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3170 - acc: 0.2100 - val_loss: 0.3979 - val_acc: 0.2444\n",
      "Epoch 9737/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3322 - acc: 0.2087 - val_loss: 0.3973 - val_acc: 0.2444\n",
      "Epoch 9738/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3152 - acc: 0.2100 - val_loss: 0.4149 - val_acc: 0.2407\n",
      "Epoch 9739/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3096 - acc: 0.2096 - val_loss: 0.4043 - val_acc: 0.2444\n",
      "Epoch 9740/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3246 - acc: 0.2092 - val_loss: 0.3808 - val_acc: 0.2444\n",
      "Epoch 9741/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3167 - acc: 0.2100 - val_loss: 0.4076 - val_acc: 0.2407\n",
      "Epoch 9742/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3202 - acc: 0.2100 - val_loss: 0.3904 - val_acc: 0.2444\n",
      "Epoch 9743/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3128 - acc: 0.2100 - val_loss: 0.3996 - val_acc: 0.2407\n",
      "Epoch 9744/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3149 - acc: 0.2092 - val_loss: 0.3830 - val_acc: 0.2444\n",
      "Epoch 9745/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3138 - acc: 0.2100 - val_loss: 0.4101 - val_acc: 0.2444\n",
      "Epoch 9746/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3185 - acc: 0.2096 - val_loss: 0.3811 - val_acc: 0.2444\n",
      "Epoch 9747/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3489 - acc: 0.2100 - val_loss: 0.3823 - val_acc: 0.2444\n",
      "Epoch 9748/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3184 - acc: 0.2092 - val_loss: 0.3885 - val_acc: 0.2444\n",
      "Epoch 9749/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3206 - acc: 0.2100 - val_loss: 0.4112 - val_acc: 0.2444\n",
      "Epoch 9750/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3127 - acc: 0.2100 - val_loss: 0.3736 - val_acc: 0.2444\n",
      "Epoch 9751/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3146 - acc: 0.2100 - val_loss: 0.4930 - val_acc: 0.2407\n",
      "Epoch 9752/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3165 - acc: 0.2092 - val_loss: 0.3793 - val_acc: 0.2444\n",
      "Epoch 9753/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3038 - acc: 0.2096 - val_loss: 0.3858 - val_acc: 0.2444\n",
      "Epoch 9754/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3157 - acc: 0.2100 - val_loss: 0.3768 - val_acc: 0.2444\n",
      "Epoch 9755/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3188 - acc: 0.2100 - val_loss: 0.3940 - val_acc: 0.2444\n",
      "Epoch 9756/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3331 - acc: 0.2096 - val_loss: 0.3950 - val_acc: 0.2444\n",
      "Epoch 9757/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3244 - acc: 0.2087 - val_loss: 0.6459 - val_acc: 0.2444\n",
      "Epoch 9758/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3339 - acc: 0.2092 - val_loss: 0.3717 - val_acc: 0.2444\n",
      "Epoch 9759/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3432 - acc: 0.2096 - val_loss: 0.3792 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9760/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3292 - acc: 0.2083 - val_loss: 0.4166 - val_acc: 0.2444\n",
      "Epoch 9761/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3118 - acc: 0.2100 - val_loss: 0.3847 - val_acc: 0.2444\n",
      "Epoch 9762/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3137 - acc: 0.2096 - val_loss: 0.4016 - val_acc: 0.2444\n",
      "Epoch 9763/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3243 - acc: 0.2092 - val_loss: 0.3843 - val_acc: 0.2444\n",
      "Epoch 9764/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3242 - acc: 0.2096 - val_loss: 0.3893 - val_acc: 0.2444\n",
      "Epoch 9765/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3119 - acc: 0.2096 - val_loss: 0.3756 - val_acc: 0.2444\n",
      "Epoch 9766/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3157 - acc: 0.2100 - val_loss: 0.4288 - val_acc: 0.2444\n",
      "Epoch 9767/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3049 - acc: 0.2096 - val_loss: 0.3814 - val_acc: 0.2444\n",
      "Epoch 9768/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3166 - acc: 0.2100 - val_loss: 0.3916 - val_acc: 0.2444\n",
      "Epoch 9769/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3117 - acc: 0.2100 - val_loss: 0.3751 - val_acc: 0.2444\n",
      "Epoch 9770/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3360 - acc: 0.2087 - val_loss: 0.3951 - val_acc: 0.2407\n",
      "Epoch 9771/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3223 - acc: 0.2100 - val_loss: 0.3725 - val_acc: 0.2444\n",
      "Epoch 9772/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3112 - acc: 0.2100 - val_loss: 0.3773 - val_acc: 0.2444\n",
      "Epoch 9773/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3365 - acc: 0.2087 - val_loss: 0.4343 - val_acc: 0.2444\n",
      "Epoch 9774/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3213 - acc: 0.2100 - val_loss: 0.4003 - val_acc: 0.2444\n",
      "Epoch 9775/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3090 - acc: 0.2092 - val_loss: 0.4086 - val_acc: 0.2444\n",
      "Epoch 9776/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3157 - acc: 0.2096 - val_loss: 0.3768 - val_acc: 0.2444\n",
      "Epoch 9777/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3050 - acc: 0.2096 - val_loss: 0.3938 - val_acc: 0.2444\n",
      "Epoch 9778/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3053 - acc: 0.2092 - val_loss: 0.3851 - val_acc: 0.2444\n",
      "Epoch 9779/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3177 - acc: 0.2100 - val_loss: 0.3761 - val_acc: 0.2444\n",
      "Epoch 9780/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3122 - acc: 0.2096 - val_loss: 0.3760 - val_acc: 0.2444\n",
      "Epoch 9781/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3133 - acc: 0.2100 - val_loss: 0.3871 - val_acc: 0.2444\n",
      "Epoch 9782/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3110 - acc: 0.2096 - val_loss: 0.5119 - val_acc: 0.2444\n",
      "Epoch 9783/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3554 - acc: 0.2087 - val_loss: 0.3896 - val_acc: 0.2444\n",
      "Epoch 9784/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3172 - acc: 0.2096 - val_loss: 0.4172 - val_acc: 0.2407\n",
      "Epoch 9785/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3169 - acc: 0.2096 - val_loss: 0.3916 - val_acc: 0.2407\n",
      "Epoch 9786/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3175 - acc: 0.2100 - val_loss: 0.3993 - val_acc: 0.2444\n",
      "Epoch 9787/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3182 - acc: 0.2092 - val_loss: 0.4029 - val_acc: 0.2407\n",
      "Epoch 9788/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3369 - acc: 0.2096 - val_loss: 0.3918 - val_acc: 0.2407\n",
      "Epoch 9789/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3203 - acc: 0.2087 - val_loss: 0.4525 - val_acc: 0.2444\n",
      "Epoch 9790/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3453 - acc: 0.2092 - val_loss: 0.3941 - val_acc: 0.2444\n",
      "Epoch 9791/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3115 - acc: 0.2096 - val_loss: 0.3852 - val_acc: 0.2444\n",
      "Epoch 9792/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3316 - acc: 0.2092 - val_loss: 0.4554 - val_acc: 0.2444\n",
      "Epoch 9793/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3199 - acc: 0.2092 - val_loss: 0.3811 - val_acc: 0.2444\n",
      "Epoch 9794/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3168 - acc: 0.2092 - val_loss: 0.3949 - val_acc: 0.2444\n",
      "Epoch 9795/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3227 - acc: 0.2096 - val_loss: 0.4430 - val_acc: 0.2444\n",
      "Epoch 9796/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3186 - acc: 0.2096 - val_loss: 0.4467 - val_acc: 0.2407\n",
      "Epoch 9797/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3288 - acc: 0.2087 - val_loss: 0.3817 - val_acc: 0.2444\n",
      "Epoch 9798/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3355 - acc: 0.2096 - val_loss: 0.3735 - val_acc: 0.2444\n",
      "Epoch 9799/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3519 - acc: 0.2092 - val_loss: 0.3895 - val_acc: 0.2444\n",
      "Epoch 9800/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3142 - acc: 0.2096 - val_loss: 0.5117 - val_acc: 0.2444\n",
      "Epoch 9801/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3214 - acc: 0.2096 - val_loss: 0.4036 - val_acc: 0.2407\n",
      "Epoch 9802/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3234 - acc: 0.2096 - val_loss: 0.3985 - val_acc: 0.2407\n",
      "Epoch 9803/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3032 - acc: 0.2100 - val_loss: 0.3733 - val_acc: 0.2444\n",
      "Epoch 9804/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3128 - acc: 0.2100 - val_loss: 0.3857 - val_acc: 0.2444\n",
      "Epoch 9805/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3244 - acc: 0.2100 - val_loss: 0.4525 - val_acc: 0.2407\n",
      "Epoch 9806/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3166 - acc: 0.2092 - val_loss: 0.4036 - val_acc: 0.2407\n",
      "Epoch 9807/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3086 - acc: 0.2096 - val_loss: 0.3894 - val_acc: 0.2444\n",
      "Epoch 9808/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3293 - acc: 0.2096 - val_loss: 0.6036 - val_acc: 0.2407\n",
      "Epoch 9809/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3219 - acc: 0.2092 - val_loss: 0.3992 - val_acc: 0.2444\n",
      "Epoch 9810/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3088 - acc: 0.2096 - val_loss: 0.3747 - val_acc: 0.2444\n",
      "Epoch 9811/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3133 - acc: 0.2100 - val_loss: 0.4021 - val_acc: 0.2444\n",
      "Epoch 9812/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3229 - acc: 0.2100 - val_loss: 0.4006 - val_acc: 0.2444\n",
      "Epoch 9813/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3126 - acc: 0.2100 - val_loss: 0.3937 - val_acc: 0.2444\n",
      "Epoch 9814/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3357 - acc: 0.2096 - val_loss: 0.4214 - val_acc: 0.2407\n",
      "Epoch 9815/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3071 - acc: 0.2092 - val_loss: 0.3842 - val_acc: 0.2444\n",
      "Epoch 9816/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3162 - acc: 0.2092 - val_loss: 0.3809 - val_acc: 0.2444\n",
      "Epoch 9817/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3337 - acc: 0.2092 - val_loss: 0.3934 - val_acc: 0.2444\n",
      "Epoch 9818/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3129 - acc: 0.2092 - val_loss: 0.3777 - val_acc: 0.2444\n",
      "Epoch 9819/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3163 - acc: 0.2100 - val_loss: 0.4117 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9820/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3357 - acc: 0.2092 - val_loss: 0.3843 - val_acc: 0.2444\n",
      "Epoch 9821/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3225 - acc: 0.2096 - val_loss: 0.4037 - val_acc: 0.2444\n",
      "Epoch 9822/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3461 - acc: 0.2087 - val_loss: 0.4021 - val_acc: 0.2444\n",
      "Epoch 9823/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3073 - acc: 0.2100 - val_loss: 0.3705 - val_acc: 0.2444\n",
      "Epoch 9824/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3192 - acc: 0.2100 - val_loss: 0.3815 - val_acc: 0.2444\n",
      "Epoch 9825/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3303 - acc: 0.2100 - val_loss: 0.4523 - val_acc: 0.2407\n",
      "Epoch 9826/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3124 - acc: 0.2096 - val_loss: 0.3738 - val_acc: 0.2444\n",
      "Epoch 9827/10000\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.3168 - acc: 0.209 - 3s 42ms/step - loss: 0.3168 - acc: 0.2092 - val_loss: 0.4266 - val_acc: 0.2407\n",
      "Epoch 9828/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.3082 - acc: 0.2092 - val_loss: 0.3757 - val_acc: 0.2444\n",
      "Epoch 9829/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3097 - acc: 0.2096 - val_loss: 0.3792 - val_acc: 0.2444\n",
      "Epoch 9830/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3164 - acc: 0.2096 - val_loss: 0.4350 - val_acc: 0.2444\n",
      "Epoch 9831/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3288 - acc: 0.2096 - val_loss: 0.4403 - val_acc: 0.2444\n",
      "Epoch 9832/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3129 - acc: 0.2096 - val_loss: 0.4177 - val_acc: 0.2444\n",
      "Epoch 9833/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3082 - acc: 0.2100 - val_loss: 0.3976 - val_acc: 0.2444\n",
      "Epoch 9834/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3159 - acc: 0.2096 - val_loss: 0.3929 - val_acc: 0.2444\n",
      "Epoch 9835/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3446 - acc: 0.2083 - val_loss: 0.3692 - val_acc: 0.2444\n",
      "Epoch 9836/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3264 - acc: 0.2100 - val_loss: 0.3892 - val_acc: 0.2444\n",
      "Epoch 9837/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3190 - acc: 0.2100 - val_loss: 0.3904 - val_acc: 0.2444\n",
      "Epoch 9838/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3200 - acc: 0.2092 - val_loss: 0.3820 - val_acc: 0.2444\n",
      "Epoch 9839/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3063 - acc: 0.2092 - val_loss: 0.4052 - val_acc: 0.2444\n",
      "Epoch 9840/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3048 - acc: 0.2096 - val_loss: 0.3815 - val_acc: 0.2444\n",
      "Epoch 9841/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3214 - acc: 0.2096 - val_loss: 0.4002 - val_acc: 0.2444\n",
      "Epoch 9842/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3119 - acc: 0.2100 - val_loss: 0.3849 - val_acc: 0.2444\n",
      "Epoch 9843/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3035 - acc: 0.2100 - val_loss: 0.3983 - val_acc: 0.2444\n",
      "Epoch 9844/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3085 - acc: 0.2096 - val_loss: 0.3839 - val_acc: 0.2444\n",
      "Epoch 9845/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3080 - acc: 0.2100 - val_loss: 0.3732 - val_acc: 0.2444\n",
      "Epoch 9846/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3220 - acc: 0.2100 - val_loss: 0.3697 - val_acc: 0.2444\n",
      "Epoch 9847/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3102 - acc: 0.2100 - val_loss: 0.4117 - val_acc: 0.2407\n",
      "Epoch 9848/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3240 - acc: 0.2092 - val_loss: 0.3912 - val_acc: 0.2444\n",
      "Epoch 9849/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3175 - acc: 0.2092 - val_loss: 0.4295 - val_acc: 0.2407\n",
      "Epoch 9850/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3119 - acc: 0.2096 - val_loss: 0.4366 - val_acc: 0.2407\n",
      "Epoch 9851/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3343 - acc: 0.2096 - val_loss: 0.3842 - val_acc: 0.2444\n",
      "Epoch 9852/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3129 - acc: 0.2087 - val_loss: 0.4029 - val_acc: 0.2407\n",
      "Epoch 9853/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3383 - acc: 0.2092 - val_loss: 0.3929 - val_acc: 0.2444\n",
      "Epoch 9854/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3098 - acc: 0.2092 - val_loss: 0.3778 - val_acc: 0.2444\n",
      "Epoch 9855/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3192 - acc: 0.2096 - val_loss: 0.3932 - val_acc: 0.2407\n",
      "Epoch 9856/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3112 - acc: 0.2096 - val_loss: 0.4623 - val_acc: 0.2407\n",
      "Epoch 9857/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3330 - acc: 0.2096 - val_loss: 0.3953 - val_acc: 0.2407\n",
      "Epoch 9858/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3157 - acc: 0.2087 - val_loss: 0.3827 - val_acc: 0.2444\n",
      "Epoch 9859/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3224 - acc: 0.2100 - val_loss: 0.3701 - val_acc: 0.2444\n",
      "Epoch 9860/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3223 - acc: 0.2087 - val_loss: 0.3857 - val_acc: 0.2444\n",
      "Epoch 9861/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3300 - acc: 0.2096 - val_loss: 0.3807 - val_acc: 0.2444\n",
      "Epoch 9862/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3031 - acc: 0.2092 - val_loss: 0.4144 - val_acc: 0.2444\n",
      "Epoch 9863/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3073 - acc: 0.2096 - val_loss: 0.3946 - val_acc: 0.2444\n",
      "Epoch 9864/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3132 - acc: 0.2087 - val_loss: 0.4471 - val_acc: 0.2407\n",
      "Epoch 9865/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3115 - acc: 0.2096 - val_loss: 0.3829 - val_acc: 0.2444\n",
      "Epoch 9866/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3119 - acc: 0.2092 - val_loss: 0.4049 - val_acc: 0.2407\n",
      "Epoch 9867/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3188 - acc: 0.2096 - val_loss: 0.3997 - val_acc: 0.2444\n",
      "Epoch 9868/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3086 - acc: 0.2096 - val_loss: 0.4060 - val_acc: 0.2444\n",
      "Epoch 9869/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3431 - acc: 0.2096 - val_loss: 0.4029 - val_acc: 0.2444\n",
      "Epoch 9870/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3339 - acc: 0.2092 - val_loss: 0.4696 - val_acc: 0.2407\n",
      "Epoch 9871/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3217 - acc: 0.2096 - val_loss: 0.3896 - val_acc: 0.2444\n",
      "Epoch 9872/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3120 - acc: 0.2092 - val_loss: 0.3968 - val_acc: 0.2444\n",
      "Epoch 9873/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3249 - acc: 0.2096 - val_loss: 0.3936 - val_acc: 0.2444\n",
      "Epoch 9874/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3303 - acc: 0.2096 - val_loss: 0.4571 - val_acc: 0.2407\n",
      "Epoch 9875/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3197 - acc: 0.2096 - val_loss: 0.3875 - val_acc: 0.2444\n",
      "Epoch 9876/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3323 - acc: 0.2100 - val_loss: 0.4552 - val_acc: 0.2444\n",
      "Epoch 9877/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3358 - acc: 0.2096 - val_loss: 0.3835 - val_acc: 0.2444\n",
      "Epoch 9878/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3185 - acc: 0.2096 - val_loss: 0.3782 - val_acc: 0.2444\n",
      "Epoch 9879/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3160 - acc: 0.2096 - val_loss: 0.3968 - val_acc: 0.2444\n",
      "Epoch 9880/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3208 - acc: 0.2092 - val_loss: 0.4035 - val_acc: 0.2444\n",
      "Epoch 9881/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3165 - acc: 0.2100 - val_loss: 0.3851 - val_acc: 0.2444\n",
      "Epoch 9882/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3105 - acc: 0.2096 - val_loss: 0.3950 - val_acc: 0.2444\n",
      "Epoch 9883/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3157 - acc: 0.2092 - val_loss: 0.3803 - val_acc: 0.2444\n",
      "Epoch 9884/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3109 - acc: 0.2100 - val_loss: 0.3747 - val_acc: 0.2444\n",
      "Epoch 9885/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3195 - acc: 0.2100 - val_loss: 0.4267 - val_acc: 0.2407\n",
      "Epoch 9886/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3234 - acc: 0.2096 - val_loss: 0.3804 - val_acc: 0.2444\n",
      "Epoch 9887/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3239 - acc: 0.2092 - val_loss: 0.3666 - val_acc: 0.2444\n",
      "Epoch 9888/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3108 - acc: 0.2096 - val_loss: 0.4120 - val_acc: 0.2444\n",
      "Epoch 9889/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3378 - acc: 0.2092 - val_loss: 0.3772 - val_acc: 0.2444\n",
      "Epoch 9890/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3481 - acc: 0.2100 - val_loss: 0.3794 - val_acc: 0.2444\n",
      "Epoch 9891/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3100 - acc: 0.2092 - val_loss: 0.4209 - val_acc: 0.2407\n",
      "Epoch 9892/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3258 - acc: 0.2092 - val_loss: 0.4773 - val_acc: 0.2444\n",
      "Epoch 9893/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.4024 - acc: 0.2096 - val_loss: 0.4543 - val_acc: 0.2444\n",
      "Epoch 9894/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3209 - acc: 0.2100 - val_loss: 0.3903 - val_acc: 0.2444\n",
      "Epoch 9895/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3166 - acc: 0.2100 - val_loss: 0.3769 - val_acc: 0.2444\n",
      "Epoch 9896/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3212 - acc: 0.2092 - val_loss: 0.3849 - val_acc: 0.2444\n",
      "Epoch 9897/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3371 - acc: 0.2100 - val_loss: 0.4146 - val_acc: 0.2444\n",
      "Epoch 9898/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3397 - acc: 0.2096 - val_loss: 0.3858 - val_acc: 0.2444\n",
      "Epoch 9899/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3180 - acc: 0.2092 - val_loss: 0.3740 - val_acc: 0.2444\n",
      "Epoch 9900/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3135 - acc: 0.2092 - val_loss: 0.4098 - val_acc: 0.2407\n",
      "Epoch 9901/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3358 - acc: 0.2100 - val_loss: 0.3761 - val_acc: 0.2444\n",
      "Epoch 9902/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3196 - acc: 0.2087 - val_loss: 0.4650 - val_acc: 0.2444\n",
      "Epoch 9903/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3181 - acc: 0.2092 - val_loss: 0.3691 - val_acc: 0.2444\n",
      "Epoch 9904/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3081 - acc: 0.2100 - val_loss: 0.3848 - val_acc: 0.2444\n",
      "Epoch 9905/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3074 - acc: 0.2096 - val_loss: 0.3844 - val_acc: 0.2444\n",
      "Epoch 9906/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3086 - acc: 0.2100 - val_loss: 0.4093 - val_acc: 0.2444\n",
      "Epoch 9907/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3184 - acc: 0.2092 - val_loss: 0.4073 - val_acc: 0.2444\n",
      "Epoch 9908/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3189 - acc: 0.2092 - val_loss: 0.3992 - val_acc: 0.2444\n",
      "Epoch 9909/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3215 - acc: 0.2100 - val_loss: 0.3706 - val_acc: 0.2444\n",
      "Epoch 9910/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3068 - acc: 0.2096 - val_loss: 0.3815 - val_acc: 0.2444\n",
      "Epoch 9911/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3044 - acc: 0.2096 - val_loss: 0.3841 - val_acc: 0.2444\n",
      "Epoch 9912/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3246 - acc: 0.2092 - val_loss: 0.4860 - val_acc: 0.2444\n",
      "Epoch 9913/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3172 - acc: 0.2096 - val_loss: 0.3981 - val_acc: 0.2444\n",
      "Epoch 9914/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3262 - acc: 0.2096 - val_loss: 0.4617 - val_acc: 0.2407\n",
      "Epoch 9915/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3060 - acc: 0.2100 - val_loss: 0.4598 - val_acc: 0.2444\n",
      "Epoch 9916/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3129 - acc: 0.2096 - val_loss: 0.3822 - val_acc: 0.2444\n",
      "Epoch 9917/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3063 - acc: 0.2100 - val_loss: 0.3905 - val_acc: 0.2444\n",
      "Epoch 9918/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3274 - acc: 0.2096 - val_loss: 0.3803 - val_acc: 0.2444\n",
      "Epoch 9919/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3250 - acc: 0.2096 - val_loss: 0.3888 - val_acc: 0.2444\n",
      "Epoch 9920/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3321 - acc: 0.2092 - val_loss: 0.3828 - val_acc: 0.2444\n",
      "Epoch 9921/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3397 - acc: 0.2096 - val_loss: 0.5028 - val_acc: 0.2444\n",
      "Epoch 9922/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3418 - acc: 0.2096 - val_loss: 0.3762 - val_acc: 0.2444\n",
      "Epoch 9923/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3080 - acc: 0.2100 - val_loss: 0.3865 - val_acc: 0.2444\n",
      "Epoch 9924/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3045 - acc: 0.2100 - val_loss: 0.3738 - val_acc: 0.2444\n",
      "Epoch 9925/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3133 - acc: 0.2096 - val_loss: 0.3768 - val_acc: 0.2444\n",
      "Epoch 9926/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3145 - acc: 0.2092 - val_loss: 0.4102 - val_acc: 0.2407\n",
      "Epoch 9927/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3067 - acc: 0.2100 - val_loss: 0.4087 - val_acc: 0.2407\n",
      "Epoch 9928/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3321 - acc: 0.2092 - val_loss: 0.3967 - val_acc: 0.2407\n",
      "Epoch 9929/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3107 - acc: 0.2100 - val_loss: 0.3922 - val_acc: 0.2444\n",
      "Epoch 9930/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3145 - acc: 0.2100 - val_loss: 0.3811 - val_acc: 0.2444\n",
      "Epoch 9931/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3325 - acc: 0.2100 - val_loss: 0.3844 - val_acc: 0.2444\n",
      "Epoch 9932/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3380 - acc: 0.2087 - val_loss: 0.3960 - val_acc: 0.2444\n",
      "Epoch 9933/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3167 - acc: 0.2092 - val_loss: 0.4011 - val_acc: 0.2444\n",
      "Epoch 9934/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3202 - acc: 0.2092 - val_loss: 0.3955 - val_acc: 0.2444\n",
      "Epoch 9935/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3215 - acc: 0.2087 - val_loss: 0.4064 - val_acc: 0.2407\n",
      "Epoch 9936/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3146 - acc: 0.2096 - val_loss: 0.4131 - val_acc: 0.2407\n",
      "Epoch 9937/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3089 - acc: 0.2096 - val_loss: 0.4084 - val_acc: 0.2444\n",
      "Epoch 9938/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3214 - acc: 0.2096 - val_loss: 0.3892 - val_acc: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9939/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3389 - acc: 0.2096 - val_loss: 0.4020 - val_acc: 0.2444\n",
      "Epoch 9940/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3382 - acc: 0.2087 - val_loss: 0.3740 - val_acc: 0.2444\n",
      "Epoch 9941/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3077 - acc: 0.2100 - val_loss: 0.3849 - val_acc: 0.2444\n",
      "Epoch 9942/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3318 - acc: 0.2092 - val_loss: 0.3766 - val_acc: 0.2444\n",
      "Epoch 9943/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3114 - acc: 0.2092 - val_loss: 0.4006 - val_acc: 0.2444\n",
      "Epoch 9944/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3082 - acc: 0.2100 - val_loss: 0.3879 - val_acc: 0.2444\n",
      "Epoch 9945/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3278 - acc: 0.2096 - val_loss: 0.3719 - val_acc: 0.2444\n",
      "Epoch 9946/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3268 - acc: 0.2092 - val_loss: 0.4031 - val_acc: 0.2444\n",
      "Epoch 9947/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3170 - acc: 0.2096 - val_loss: 0.3935 - val_acc: 0.2444\n",
      "Epoch 9948/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3040 - acc: 0.2100 - val_loss: 0.3702 - val_acc: 0.2444\n",
      "Epoch 9949/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3124 - acc: 0.2096 - val_loss: 0.3716 - val_acc: 0.2444\n",
      "Epoch 9950/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3216 - acc: 0.2096 - val_loss: 0.3905 - val_acc: 0.2444\n",
      "Epoch 9951/10000\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.3340 - acc: 0.207 - 2s 33ms/step - loss: 0.3330 - acc: 0.2087 - val_loss: 0.4502 - val_acc: 0.2444\n",
      "Epoch 9952/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3206 - acc: 0.2096 - val_loss: 0.3727 - val_acc: 0.2444\n",
      "Epoch 9953/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3100 - acc: 0.2100 - val_loss: 0.3931 - val_acc: 0.2444\n",
      "Epoch 9954/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3180 - acc: 0.2092 - val_loss: 0.3834 - val_acc: 0.2444\n",
      "Epoch 9955/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3419 - acc: 0.2096 - val_loss: 0.3701 - val_acc: 0.2444\n",
      "Epoch 9956/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3541 - acc: 0.2075 - val_loss: 0.4265 - val_acc: 0.2407\n",
      "Epoch 9957/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3266 - acc: 0.2100 - val_loss: 0.3796 - val_acc: 0.2444\n",
      "Epoch 9958/10000\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 0.3226 - acc: 0.2100 - val_loss: 0.3791 - val_acc: 0.2444\n",
      "Epoch 9959/10000\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 0.3300 - acc: 0.2096 - val_loss: 0.4681 - val_acc: 0.2444\n",
      "Epoch 9960/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3343 - acc: 0.2096 - val_loss: 0.4536 - val_acc: 0.2444\n",
      "Epoch 9961/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3290 - acc: 0.2100 - val_loss: 0.4233 - val_acc: 0.2407\n",
      "Epoch 9962/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3142 - acc: 0.2096 - val_loss: 0.3883 - val_acc: 0.2444\n",
      "Epoch 9963/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3224 - acc: 0.2092 - val_loss: 0.4546 - val_acc: 0.2444\n",
      "Epoch 9964/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3171 - acc: 0.2100 - val_loss: 0.4212 - val_acc: 0.2444\n",
      "Epoch 9965/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3025 - acc: 0.2092 - val_loss: 0.3901 - val_acc: 0.2444\n",
      "Epoch 9966/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3275 - acc: 0.2092 - val_loss: 0.3810 - val_acc: 0.2444\n",
      "Epoch 9967/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3092 - acc: 0.2096 - val_loss: 0.4003 - val_acc: 0.2444\n",
      "Epoch 9968/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3305 - acc: 0.2092 - val_loss: 0.4152 - val_acc: 0.2444\n",
      "Epoch 9969/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3098 - acc: 0.2092 - val_loss: 0.3775 - val_acc: 0.2444\n",
      "Epoch 9970/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3042 - acc: 0.2096 - val_loss: 0.3953 - val_acc: 0.2444\n",
      "Epoch 9971/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3115 - acc: 0.2096 - val_loss: 0.3906 - val_acc: 0.2444\n",
      "Epoch 9972/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3109 - acc: 0.2096 - val_loss: 0.3759 - val_acc: 0.2444\n",
      "Epoch 9973/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3142 - acc: 0.2100 - val_loss: 0.3847 - val_acc: 0.2444\n",
      "Epoch 9974/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3088 - acc: 0.2096 - val_loss: 0.3854 - val_acc: 0.2444\n",
      "Epoch 9975/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3146 - acc: 0.2092 - val_loss: 0.3750 - val_acc: 0.2444\n",
      "Epoch 9976/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3228 - acc: 0.2100 - val_loss: 0.4375 - val_acc: 0.2407\n",
      "Epoch 9977/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3152 - acc: 0.2096 - val_loss: 0.4052 - val_acc: 0.2407\n",
      "Epoch 9978/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3274 - acc: 0.2087 - val_loss: 0.3802 - val_acc: 0.2444\n",
      "Epoch 9979/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3090 - acc: 0.2100 - val_loss: 0.4102 - val_acc: 0.2444\n",
      "Epoch 9980/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3124 - acc: 0.2100 - val_loss: 0.4015 - val_acc: 0.2444\n",
      "Epoch 9981/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3122 - acc: 0.2100 - val_loss: 0.4514 - val_acc: 0.2444\n",
      "Epoch 9982/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3244 - acc: 0.2096 - val_loss: 0.3855 - val_acc: 0.2444\n",
      "Epoch 9983/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3219 - acc: 0.2096 - val_loss: 0.4380 - val_acc: 0.2407\n",
      "Epoch 9984/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3174 - acc: 0.2092 - val_loss: 0.3957 - val_acc: 0.2407\n",
      "Epoch 9985/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3277 - acc: 0.2096 - val_loss: 0.5814 - val_acc: 0.2444\n",
      "Epoch 9986/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3213 - acc: 0.2096 - val_loss: 0.3912 - val_acc: 0.2444\n",
      "Epoch 9987/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3324 - acc: 0.2087 - val_loss: 0.4169 - val_acc: 0.2444\n",
      "Epoch 9988/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3109 - acc: 0.2087 - val_loss: 0.3730 - val_acc: 0.2444\n",
      "Epoch 9989/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3222 - acc: 0.2100 - val_loss: 0.3962 - val_acc: 0.2444\n",
      "Epoch 9990/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3145 - acc: 0.2100 - val_loss: 0.3962 - val_acc: 0.2444\n",
      "Epoch 9991/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3242 - acc: 0.2100 - val_loss: 0.4397 - val_acc: 0.2444\n",
      "Epoch 9992/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3054 - acc: 0.2100 - val_loss: 0.3806 - val_acc: 0.2444\n",
      "Epoch 9993/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3023 - acc: 0.2100 - val_loss: 0.4400 - val_acc: 0.2444\n",
      "Epoch 9994/10000\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 0.3131 - acc: 0.2100 - val_loss: 0.4231 - val_acc: 0.2444\n",
      "Epoch 9995/10000\n",
      "76/76 [==============================] - 3s 35ms/step - loss: 0.3218 - acc: 0.2096 - val_loss: 0.4335 - val_acc: 0.2407\n",
      "Epoch 9996/10000\n",
      "76/76 [==============================] - 3s 33ms/step - loss: 0.3136 - acc: 0.2096 - val_loss: 0.3825 - val_acc: 0.2444\n",
      "Epoch 9997/10000\n",
      "76/76 [==============================] - 3s 34ms/step - loss: 0.3348 - acc: 0.2100 - val_loss: 0.3917 - val_acc: 0.2444\n",
      "Epoch 9998/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3132 - acc: 0.2096 - val_loss: 0.3759 - val_acc: 0.2444\n",
      "Epoch 9999/10000\n",
      "76/76 [==============================] - 2s 32ms/step - loss: 0.3169 - acc: 0.2092 - val_loss: 0.4375 - val_acc: 0.2407\n",
      "Epoch 10000/10000\n",
      "76/76 [==============================] - 2s 33ms/step - loss: 0.3180 - acc: 0.2096 - val_loss: 0.3830 - val_acc: 0.2444\n"
     ]
    }
   ],
   "source": [
    "size_history = cnn_size_model.fit([size_x_train1, size_x_train2, size_x_train3], size_y_train, epochs=10000, validation_data=([size_x_test1,size_x_test2,size_x_test3], size_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3830 - acc: 0.2444\n",
      "Test loss: 0.38304874300956726\n",
      "Test accuracy: 0.24444444477558136\n"
     ]
    }
   ],
   "source": [
    "# モデルの評価(大きさ)\n",
    "score = cnn_size_model.evaluate([size_x_test1, size_x_test2, size_x_test3], size_y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 学習経過の可視化(大きさ)\n",
    "loss     = size_history.history['loss']\n",
    "val_loss = size_history.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss,     marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff971f64410>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 散布図表示\n",
    "size_predict = cnn_size_model.predict([size_x_test1,size_x_test2,size_x_test3])\n",
    "size_answer = size_y_test\n",
    "\n",
    "plt.scatter(size_answer, size_predict)\n",
    "plt.xlabel(\"size\")\n",
    "plt.ylabel(\"prediction\")\n",
    "plt.grid(True)\n",
    "## y=xの直線をひく\n",
    "x = []\n",
    "for i in range(60):\n",
    "    x.append(i*0.1)\n",
    "y = []\n",
    "for i in range(60):\n",
    "    y.append(i*0.1)\n",
    "plt.plot(x, y, color='black')\n",
    "## 誤差-30%の直線を引く\n",
    "y = []\n",
    "for i in range(60):\n",
    "    y.append(i*0.1*0.7)\n",
    "plt.plot(x, y, color='red')\n",
    "## 誤差+30%の直線を引く\n",
    "y = []\n",
    "for i in range(60):\n",
    "    y.append(i*0.1*1.3)\n",
    "plt.plot(x, y, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大きさ1の正答率：0.058333333333333334\n",
      "大きさ2の正答率：0.45614035087719296\n",
      "大きさ3の正答率：0.6568627450980392\n",
      "大きさ4の正答率：0.9230769230769231\n",
      "大きさ5の正答率：0.6868686868686869\n"
     ]
    }
   ],
   "source": [
    "#大きさごとの推定精度の確認：20%以下\n",
    "size_predict = cnn_size_model.predict([size_x_test1,size_x_test2,size_x_test3])\n",
    "size_answer = size_y_test\n",
    "one_total = 0\n",
    "one_ok = 0\n",
    "two_total = 0\n",
    "two_ok = 0\n",
    "three_total = 0\n",
    "three_ok = 0\n",
    "four_total = 0\n",
    "four_ok = 0\n",
    "five_total = 0\n",
    "five_ok = 0\n",
    "for i in range(len(size_predict)):\n",
    "    if size_answer[i] == 1:\n",
    "        one_total = one_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.2):\n",
    "            one_ok = one_ok + 1\n",
    "    if size_answer[i] == 2:\n",
    "        two_total = two_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.4):\n",
    "            two_ok = two_ok + 1\n",
    "    if size_answer[i] == 3:\n",
    "        three_total = three_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.6):\n",
    "            three_ok = three_ok + 1\n",
    "    if size_answer[i] == 4:\n",
    "        four_total = four_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.8):\n",
    "            four_ok = four_ok + 1\n",
    "    if size_answer[i] == 5:\n",
    "        five_total = five_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 1):\n",
    "            five_ok = five_ok + 1\n",
    "print(\"大きさ1の正答率：\"+str(one_ok/one_total))\n",
    "print(\"大きさ2の正答率：\"+str(two_ok/two_total))\n",
    "print(\"大きさ3の正答率：\"+str(three_ok/three_total))\n",
    "print(\"大きさ4の正答率：\"+str(four_ok/four_total))\n",
    "print(\"大きさ5の正答率：\"+str(five_ok/five_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "left = np.array([1,2,3,4,5])\n",
    "height = np.array([one_ok/one_total,two_ok/two_total,three_ok/three_total,four_ok/four_total,five_ok/five_total])\n",
    "plt.bar(left, height)\n",
    "plt.xlabel(\"size\")\n",
    "plt.ylabel(\"size acc\")\n",
    "plt.ylim(top=1, bottom=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大きさ1の正答率：0.8083333333333333\n",
      "大きさ2の正答率：0.7017543859649122\n",
      "大きさ3の正答率：0.5098039215686274\n",
      "大きさ4の正答率：0.75\n",
      "大きさ5の正答率：0.37373737373737376\n"
     ]
    }
   ],
   "source": [
    "#大きさごとの推定精度の確認：最も近く予測\n",
    "size_predict = cnn_size_model.predict([size_x_test1,size_x_test2,size_x_test3])\n",
    "size_answer = size_y_test\n",
    "one_total = 0\n",
    "one_ok = 0\n",
    "two_total = 0\n",
    "two_ok = 0\n",
    "three_total = 0\n",
    "three_ok = 0\n",
    "four_total = 0\n",
    "four_ok = 0\n",
    "five_total = 0\n",
    "five_ok = 0\n",
    "for i in range(len(size_predict)):\n",
    "    if size_answer[i] == 1:\n",
    "        one_total = one_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.5):\n",
    "            one_ok = one_ok + 1\n",
    "    if size_answer[i] == 2:\n",
    "        two_total = two_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.5):\n",
    "            two_ok = two_ok + 1\n",
    "    if size_answer[i] == 3:\n",
    "        three_total = three_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.5):\n",
    "            three_ok = three_ok + 1\n",
    "    if size_answer[i] == 4:\n",
    "        four_total = four_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.5):\n",
    "            four_ok = four_ok + 1\n",
    "    if size_answer[i] == 5:\n",
    "        five_total = five_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.5):\n",
    "            five_ok = five_ok + 1\n",
    "print(\"大きさ1の正答率：\"+str(one_ok/one_total))\n",
    "print(\"大きさ2の正答率：\"+str(two_ok/two_total))\n",
    "print(\"大きさ3の正答率：\"+str(three_ok/three_total))\n",
    "print(\"大きさ4の正答率：\"+str(four_ok/four_total))\n",
    "print(\"大きさ5の正答率：\"+str(five_ok/five_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "left = np.array([1,2,3,4,5])\n",
    "height = np.array([one_ok/one_total,two_ok/two_total,three_ok/three_total,four_ok/four_total,five_ok/five_total])\n",
    "plt.bar(left, height)\n",
    "plt.xlabel(\"size\")\n",
    "plt.ylabel(\"size acc\")\n",
    "plt.ylim(top=1, bottom=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.44252, 1.1473302, 1.4547509, 1.1462659, 1.279724, 1.4187611, 2.2494783, 1.4151858, 1.5425566, 1.3619479, 1.5114468, 1.3730124, 1.5752915, 1.4545077, 1.3821934, 1.5695113, 1.2814149, 1.4333647, 1.567007, 0.73064697, 1.4592646, 1.4466609, 1.4385337, 1.4378985, 1.4328555, 1.4320906, 0.7976588, 1.4148434, 1.4687041, 1.396653, 1.4211091, 1.3610276, 1.4213666, 1.3046511, 1.4013566, 1.1810225, 1.3877333, 1.4635714, 1.4398497, 1.4356498, 1.4115142, 1.435707, 1.3438138, 1.2059973, 1.4960641, 1.4183291, 1.4417571, 1.4593323, 1.3119601, 1.3960971, 1.4772471, 1.5889014, 1.4211463, 1.4654015, 1.5327939, 1.4758557, 1.3323001, 1.4968585, 1.5920066, 1.5640067, 1.3928717, 1.4473618, 1.6459101, 1.461213, 1.4432524, 0.48839843, 1.4031609, 1.4343623, 1.4961585, 1.5364636, 1.4618129, 1.2368821, 1.4010838, 1.2895831, 1.4371518, 1.4584311, 1.4902104, 1.60155, 1.2386817, 1.3893145, 1.4438361, 1.4162654, 1.4688128, 1.4389266, 1.501458, 1.0119036, 1.5519599, 1.4248704, 1.4687833, 1.4215535, 1.7420453, 1.4437693, 1.4343117, 1.5139579, 0.9973773, 1.4538172, 1.5159482, -0.11382401, 1.4308633, 1.4684209, 0.8307208, 1.4089888, 1.4299, 1.4102553, 1.4873255, 1.2943581, 1.3691577, 1.4503945, 1.392393, 1.3947467, 1.502941, 1.4222916, 1.49028, 1.4303769, 0.86862934, 1.3616542, 1.9995621, 1.4444684, 1.4969891, 1.5039643]\n"
     ]
    }
   ],
   "source": [
    "one_predict = []\n",
    "size_predict = cnn_size_model.predict([size_x_test1,size_x_test2,size_x_test3])\n",
    "size_answer = size_y_test\n",
    "for i in range(len(size_y_test)):\n",
    "    if size_answer[i] == 1:\n",
    "        one_predict.append(size_predict[i][0])\n",
    "print(one_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1251, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1251, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 1251, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 1251, 32)     128         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1251, 32)     128         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1251, 32)     128         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 626, 32)      0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 626, 32)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 626, 32)      0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 626, 32)      3104        max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 626, 32)      3104        max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 626, 32)      3104        max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 313, 32)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 313, 32)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 313, 32)      0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 313, 96)      0           max_pooling1d_1[0][0]            \n",
      "                                                                 max_pooling1d_3[0][0]            \n",
      "                                                                 max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 30048)        0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            30049       flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 39,745\n",
      "Trainable params: 39,745\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNNモデルで大きさ推定(層を増やす)\n",
    "# import\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, concatenate, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
    "\n",
    "# 入力を定義\n",
    "input1 = Input(shape=(1251,1))\n",
    "input2 = Input(shape=(1251,1))\n",
    "input3 = Input(shape=(1251,1))\n",
    "\n",
    "# 入力1から結合前まで\n",
    "x = Conv1D(32, 3, padding='same', activation='tanh')(input1)\n",
    "x = MaxPooling1D(2, padding='same')(x)\n",
    "x = Conv1D(32, 3, padding='same', activation='tanh')(x)\n",
    "x = MaxPooling1D(2, padding='same')(x)\n",
    "x = Model(inputs=input1, outputs=x)\n",
    "# 入力2から結合前まで\n",
    "y = Conv1D(32, 3, padding='same', activation='tanh')(input2)\n",
    "y = MaxPooling1D(2, padding='same')(y)\n",
    "y = Conv1D(32, 3, padding='same', activation='tanh')(y)\n",
    "y = MaxPooling1D(2, padding='same')(y)\n",
    "y = Model(inputs=input2, outputs=y)\n",
    "# 入力3から結合前まで\n",
    "z = Conv1D(32, 3, padding='same', activation='tanh')(input3)\n",
    "z = MaxPooling1D(2, padding='same')(z)\n",
    "z = Conv1D(32, 3, padding='same', activation='tanh')(z)\n",
    "z = MaxPooling1D(2, padding='same')(z)\n",
    "z = Model(inputs=input3, outputs=z)\n",
    "\n",
    "# 結合\n",
    "combined = concatenate([x.output, y.output, z.output])\n",
    "\n",
    "# 密結合\n",
    "cnn = Flatten()(combined)\n",
    "cnn = Dense(1, activation=\"linear\")(cnn)\n",
    "\n",
    "# モデル定義とコンパイル\n",
    "cnn_size_model = Model(inputs=[x.input, y.input, z.input], outputs=cnn)\n",
    "cnn_size_model.compile(loss='mse', optimizer='adam', metrics=['acc'])\n",
    "cnn_size_model.summary()\n",
    "plot_model(cnn_size_model, show_shapes=True, show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 1.9712 - acc: 0.2172 - val_loss: 1.9494 - val_acc: 0.2004\n",
      "Epoch 2/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 1.9611 - acc: 0.2172 - val_loss: 1.9221 - val_acc: 0.2004\n",
      "Epoch 3/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 1.9368 - acc: 0.2172 - val_loss: 1.8511 - val_acc: 0.2004\n",
      "Epoch 4/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 1.8238 - acc: 0.2172 - val_loss: 1.7745 - val_acc: 0.2004\n",
      "Epoch 5/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 1.7258 - acc: 0.2172 - val_loss: 1.7579 - val_acc: 0.2004\n",
      "Epoch 6/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 1.7605 - acc: 0.2172 - val_loss: 1.9649 - val_acc: 0.2004\n",
      "Epoch 7/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 1.7141 - acc: 0.2172 - val_loss: 1.7147 - val_acc: 0.2004\n",
      "Epoch 8/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 1.5905 - acc: 0.2172 - val_loss: 1.7092 - val_acc: 0.2004\n",
      "Epoch 9/4000\n",
      "68/68 [==============================] - 5s 77ms/step - loss: 1.5608 - acc: 0.2172 - val_loss: 1.8368 - val_acc: 0.2004\n",
      "Epoch 10/4000\n",
      "68/68 [==============================] - 5s 78ms/step - loss: 1.5561 - acc: 0.2172 - val_loss: 1.6648 - val_acc: 0.2004\n",
      "Epoch 11/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 1.4753 - acc: 0.2172 - val_loss: 1.6022 - val_acc: 0.2004\n",
      "Epoch 12/4000\n",
      "68/68 [==============================] - 5s 71ms/step - loss: 1.4900 - acc: 0.2172 - val_loss: 1.4933 - val_acc: 0.2004\n",
      "Epoch 13/4000\n",
      "68/68 [==============================] - 5s 69ms/step - loss: 1.4808 - acc: 0.2172 - val_loss: 1.5167 - val_acc: 0.2004\n",
      "Epoch 14/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 1.4853 - acc: 0.2172 - val_loss: 1.5366 - val_acc: 0.2004\n",
      "Epoch 15/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 1.4260 - acc: 0.2172 - val_loss: 1.4179 - val_acc: 0.2004\n",
      "Epoch 16/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 1.3228 - acc: 0.2172 - val_loss: 1.3881 - val_acc: 0.2004\n",
      "Epoch 17/4000\n",
      "68/68 [==============================] - 5s 70ms/step - loss: 1.3273 - acc: 0.2172 - val_loss: 1.3492 - val_acc: 0.2004\n",
      "Epoch 18/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 1.3382 - acc: 0.2172 - val_loss: 1.4073 - val_acc: 0.2004\n",
      "Epoch 19/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 1.2649 - acc: 0.2172 - val_loss: 1.3512 - val_acc: 0.2004\n",
      "Epoch 20/4000\n",
      "68/68 [==============================] - 5s 69ms/step - loss: 1.3223 - acc: 0.2172 - val_loss: 1.3309 - val_acc: 0.2004\n",
      "Epoch 21/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 1.2582 - acc: 0.2172 - val_loss: 1.2883 - val_acc: 0.2004\n",
      "Epoch 22/4000\n",
      "68/68 [==============================] - 5s 70ms/step - loss: 1.1972 - acc: 0.2172 - val_loss: 1.3119 - val_acc: 0.2004\n",
      "Epoch 23/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 1.2029 - acc: 0.2172 - val_loss: 1.2765 - val_acc: 0.2004\n",
      "Epoch 24/4000\n",
      "68/68 [==============================] - 5s 71ms/step - loss: 1.1924 - acc: 0.2172 - val_loss: 1.3055 - val_acc: 0.2004\n",
      "Epoch 25/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 1.1981 - acc: 0.2172 - val_loss: 1.2328 - val_acc: 0.2004\n",
      "Epoch 26/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 1.1524 - acc: 0.2172 - val_loss: 1.2684 - val_acc: 0.2004\n",
      "Epoch 27/4000\n",
      "68/68 [==============================] - 5s 72ms/step - loss: 1.1580 - acc: 0.2172 - val_loss: 1.2389 - val_acc: 0.2004\n",
      "Epoch 28/4000\n",
      "68/68 [==============================] - 5s 74ms/step - loss: 1.2464 - acc: 0.2172 - val_loss: 1.3214 - val_acc: 0.2004\n",
      "Epoch 29/4000\n",
      "68/68 [==============================] - 5s 76ms/step - loss: 1.1837 - acc: 0.2172 - val_loss: 1.2955 - val_acc: 0.2004\n",
      "Epoch 30/4000\n",
      "68/68 [==============================] - 5s 72ms/step - loss: 1.1226 - acc: 0.2172 - val_loss: 1.1708 - val_acc: 0.2004\n",
      "Epoch 31/4000\n",
      "68/68 [==============================] - 5s 71ms/step - loss: 1.1583 - acc: 0.2172 - val_loss: 1.3401 - val_acc: 0.2004\n",
      "Epoch 32/4000\n",
      "68/68 [==============================] - 5s 70ms/step - loss: 1.1018 - acc: 0.2172 - val_loss: 1.1687 - val_acc: 0.2004\n",
      "Epoch 33/4000\n",
      "68/68 [==============================] - 5s 70ms/step - loss: 1.0694 - acc: 0.2172 - val_loss: 1.1291 - val_acc: 0.2004\n",
      "Epoch 34/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 1.0464 - acc: 0.2172 - val_loss: 1.1685 - val_acc: 0.2004\n",
      "Epoch 35/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 1.0659 - acc: 0.2172 - val_loss: 1.1199 - val_acc: 0.2004\n",
      "Epoch 36/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 1.0448 - acc: 0.2172 - val_loss: 1.1119 - val_acc: 0.2004\n",
      "Epoch 37/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 1.0429 - acc: 0.2172 - val_loss: 1.0936 - val_acc: 0.2004\n",
      "Epoch 38/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 1.0455 - acc: 0.2172 - val_loss: 1.2553 - val_acc: 0.2004\n",
      "Epoch 39/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.9913 - acc: 0.2172 - val_loss: 1.0885 - val_acc: 0.2004\n",
      "Epoch 40/4000\n",
      "68/68 [==============================] - 5s 70ms/step - loss: 1.0083 - acc: 0.2172 - val_loss: 1.1777 - val_acc: 0.2004\n",
      "Epoch 41/4000\n",
      "68/68 [==============================] - 5s 66ms/step - loss: 1.0252 - acc: 0.2172 - val_loss: 1.0614 - val_acc: 0.2004\n",
      "Epoch 42/4000\n",
      "68/68 [==============================] - 5s 77ms/step - loss: 1.0005 - acc: 0.2172 - val_loss: 1.0543 - val_acc: 0.2004\n",
      "Epoch 43/4000\n",
      "68/68 [==============================] - 5s 71ms/step - loss: 0.9657 - acc: 0.2172 - val_loss: 1.0521 - val_acc: 0.2004\n",
      "Epoch 44/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 0.9828 - acc: 0.2172 - val_loss: 1.1759 - val_acc: 0.2004\n",
      "Epoch 45/4000\n",
      "68/68 [==============================] - 5s 66ms/step - loss: 1.0702 - acc: 0.2172 - val_loss: 1.0335 - val_acc: 0.2004\n",
      "Epoch 46/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 1.1234 - acc: 0.2172 - val_loss: 1.2539 - val_acc: 0.2004\n",
      "Epoch 47/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 1.0371 - acc: 0.2172 - val_loss: 1.0621 - val_acc: 0.2004\n",
      "Epoch 48/4000\n",
      "68/68 [==============================] - 5s 78ms/step - loss: 0.9600 - acc: 0.2172 - val_loss: 1.0419 - val_acc: 0.2004\n",
      "Epoch 49/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.9398 - acc: 0.2172 - val_loss: 1.0454 - val_acc: 0.2004\n",
      "Epoch 50/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.9510 - acc: 0.2172 - val_loss: 0.9947 - val_acc: 0.2004\n",
      "Epoch 51/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.9448 - acc: 0.2172 - val_loss: 0.9888 - val_acc: 0.2004\n",
      "Epoch 52/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.9132 - acc: 0.2172 - val_loss: 1.3331 - val_acc: 0.2004\n",
      "Epoch 53/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 0.9122 - acc: 0.2167 - val_loss: 1.0442 - val_acc: 0.2004\n",
      "Epoch 54/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.9069 - acc: 0.2167 - val_loss: 1.1170 - val_acc: 0.2004\n",
      "Epoch 55/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.9790 - acc: 0.2172 - val_loss: 1.2856 - val_acc: 0.2004\n",
      "Epoch 56/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.9325 - acc: 0.2172 - val_loss: 1.1629 - val_acc: 0.2004\n",
      "Epoch 57/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.9188 - acc: 0.2172 - val_loss: 1.0862 - val_acc: 0.2004\n",
      "Epoch 58/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.8881 - acc: 0.2172 - val_loss: 0.9607 - val_acc: 0.2004\n",
      "Epoch 59/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.8392 - acc: 0.2172 - val_loss: 0.9899 - val_acc: 0.2004\n",
      "Epoch 60/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.8762 - acc: 0.2172 - val_loss: 0.9635 - val_acc: 0.2004\n",
      "Epoch 61/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 1.2175 - acc: 0.2162 - val_loss: 0.9649 - val_acc: 0.2004\n",
      "Epoch 62/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.9783 - acc: 0.2167 - val_loss: 0.9632 - val_acc: 0.2004\n",
      "Epoch 63/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.9294 - acc: 0.2167 - val_loss: 1.0599 - val_acc: 0.2004\n",
      "Epoch 64/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.8540 - acc: 0.2172 - val_loss: 0.9815 - val_acc: 0.2004\n",
      "Epoch 65/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.9309 - acc: 0.2167 - val_loss: 0.9586 - val_acc: 0.2004\n",
      "Epoch 66/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.9202 - acc: 0.2172 - val_loss: 0.9457 - val_acc: 0.2004\n",
      "Epoch 67/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.8350 - acc: 0.2172 - val_loss: 0.9333 - val_acc: 0.2004\n",
      "Epoch 68/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.8135 - acc: 0.2167 - val_loss: 0.9235 - val_acc: 0.2004\n",
      "Epoch 69/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.8740 - acc: 0.2172 - val_loss: 0.9598 - val_acc: 0.2004\n",
      "Epoch 70/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.8399 - acc: 0.2167 - val_loss: 1.0878 - val_acc: 0.2004\n",
      "Epoch 71/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.8498 - acc: 0.2167 - val_loss: 0.9357 - val_acc: 0.2004\n",
      "Epoch 72/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.8592 - acc: 0.2167 - val_loss: 0.9295 - val_acc: 0.2004\n",
      "Epoch 73/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.8245 - acc: 0.2167 - val_loss: 1.0579 - val_acc: 0.2004\n",
      "Epoch 74/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.8461 - acc: 0.2167 - val_loss: 0.9380 - val_acc: 0.2004\n",
      "Epoch 75/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.7934 - acc: 0.2162 - val_loss: 0.9033 - val_acc: 0.2004\n",
      "Epoch 76/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.8511 - acc: 0.2158 - val_loss: 0.9031 - val_acc: 0.2004\n",
      "Epoch 77/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.8537 - acc: 0.2162 - val_loss: 0.9195 - val_acc: 0.2004\n",
      "Epoch 78/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 1.1414 - acc: 0.2167 - val_loss: 0.9366 - val_acc: 0.2004\n",
      "Epoch 79/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 1.0126 - acc: 0.2172 - val_loss: 0.9733 - val_acc: 0.2004\n",
      "Epoch 80/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.8238 - acc: 0.2167 - val_loss: 0.9339 - val_acc: 0.2004\n",
      "Epoch 81/4000\n",
      "68/68 [==============================] - 5s 78ms/step - loss: 0.8228 - acc: 0.2167 - val_loss: 0.9277 - val_acc: 0.2004\n",
      "Epoch 82/4000\n",
      "68/68 [==============================] - 5s 66ms/step - loss: 0.7927 - acc: 0.2167 - val_loss: 0.9023 - val_acc: 0.2004\n",
      "Epoch 83/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.7820 - acc: 0.2167 - val_loss: 0.9136 - val_acc: 0.2004\n",
      "Epoch 84/4000\n",
      "68/68 [==============================] - 5s 66ms/step - loss: 0.8068 - acc: 0.2167 - val_loss: 1.0332 - val_acc: 0.2004\n",
      "Epoch 85/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.8219 - acc: 0.2167 - val_loss: 0.9544 - val_acc: 0.2004\n",
      "Epoch 86/4000\n",
      "68/68 [==============================] - 5s 66ms/step - loss: 0.7828 - acc: 0.2167 - val_loss: 0.9921 - val_acc: 0.2004\n",
      "Epoch 87/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.7894 - acc: 0.2167 - val_loss: 0.8896 - val_acc: 0.2004\n",
      "Epoch 88/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.7711 - acc: 0.2162 - val_loss: 0.8916 - val_acc: 0.2004\n",
      "Epoch 89/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.8046 - acc: 0.2162 - val_loss: 0.8643 - val_acc: 0.2004\n",
      "Epoch 90/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.7685 - acc: 0.2167 - val_loss: 0.8937 - val_acc: 0.2004\n",
      "Epoch 91/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.7562 - acc: 0.2162 - val_loss: 0.8883 - val_acc: 0.2004\n",
      "Epoch 92/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.7343 - acc: 0.2162 - val_loss: 0.9603 - val_acc: 0.2004\n",
      "Epoch 93/4000\n",
      "68/68 [==============================] - 5s 66ms/step - loss: 0.7459 - acc: 0.2162 - val_loss: 0.9039 - val_acc: 0.2004\n",
      "Epoch 94/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.7342 - acc: 0.2162 - val_loss: 0.9116 - val_acc: 0.2004\n",
      "Epoch 95/4000\n",
      "68/68 [==============================] - 5s 66ms/step - loss: 0.7482 - acc: 0.2162 - val_loss: 0.9391 - val_acc: 0.2004\n",
      "Epoch 96/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.7745 - acc: 0.2158 - val_loss: 1.1234 - val_acc: 0.2004\n",
      "Epoch 97/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.7776 - acc: 0.2162 - val_loss: 1.2125 - val_acc: 0.2004\n",
      "Epoch 98/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.7682 - acc: 0.2162 - val_loss: 0.8884 - val_acc: 0.2004\n",
      "Epoch 99/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.7744 - acc: 0.2153 - val_loss: 0.9976 - val_acc: 0.2004\n",
      "Epoch 100/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 0.7314 - acc: 0.2162 - val_loss: 0.8552 - val_acc: 0.2004\n",
      "Epoch 101/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.7044 - acc: 0.2167 - val_loss: 1.2564 - val_acc: 0.2004\n",
      "Epoch 102/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.7444 - acc: 0.2162 - val_loss: 0.8620 - val_acc: 0.2004\n",
      "Epoch 103/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.7429 - acc: 0.2162 - val_loss: 1.0057 - val_acc: 0.2004\n",
      "Epoch 104/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.7743 - acc: 0.2158 - val_loss: 0.8712 - val_acc: 0.2004\n",
      "Epoch 105/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.7588 - acc: 0.2162 - val_loss: 0.9959 - val_acc: 0.2004\n",
      "Epoch 106/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.7795 - acc: 0.2158 - val_loss: 0.8945 - val_acc: 0.2004\n",
      "Epoch 107/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.7249 - acc: 0.2162 - val_loss: 0.8443 - val_acc: 0.2004\n",
      "Epoch 108/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.6906 - acc: 0.2167 - val_loss: 0.8183 - val_acc: 0.2004\n",
      "Epoch 109/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.6860 - acc: 0.2162 - val_loss: 0.9264 - val_acc: 0.2004\n",
      "Epoch 110/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.7000 - acc: 0.2162 - val_loss: 0.8489 - val_acc: 0.2004\n",
      "Epoch 111/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.7156 - acc: 0.2162 - val_loss: 0.8118 - val_acc: 0.2004\n",
      "Epoch 112/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.6759 - acc: 0.2162 - val_loss: 0.8580 - val_acc: 0.2004\n",
      "Epoch 113/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.7291 - acc: 0.2158 - val_loss: 0.7962 - val_acc: 0.2004\n",
      "Epoch 114/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.7036 - acc: 0.2167 - val_loss: 0.8123 - val_acc: 0.2004\n",
      "Epoch 115/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.7299 - acc: 0.2148 - val_loss: 0.9262 - val_acc: 0.2004\n",
      "Epoch 116/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.6941 - acc: 0.2162 - val_loss: 0.9152 - val_acc: 0.2004\n",
      "Epoch 117/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.7159 - acc: 0.2158 - val_loss: 0.8224 - val_acc: 0.2004\n",
      "Epoch 118/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.6474 - acc: 0.2162 - val_loss: 0.7896 - val_acc: 0.2004\n",
      "Epoch 119/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.6703 - acc: 0.2158 - val_loss: 0.9250 - val_acc: 0.2004\n",
      "Epoch 120/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.7002 - acc: 0.2162 - val_loss: 0.9457 - val_acc: 0.2004\n",
      "Epoch 121/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 0.7157 - acc: 0.2162 - val_loss: 1.1106 - val_acc: 0.2004\n",
      "Epoch 122/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.7901 - acc: 0.2158 - val_loss: 0.9104 - val_acc: 0.2004\n",
      "Epoch 123/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 63ms/step - loss: 0.9350 - acc: 0.2162 - val_loss: 0.9978 - val_acc: 0.2004\n",
      "Epoch 124/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.8806 - acc: 0.2162 - val_loss: 0.8940 - val_acc: 0.2004\n",
      "Epoch 125/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 1.1510 - acc: 0.2167 - val_loss: 0.8955 - val_acc: 0.2004\n",
      "Epoch 126/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.7568 - acc: 0.2167 - val_loss: 0.9166 - val_acc: 0.2004\n",
      "Epoch 127/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.7135 - acc: 0.2167 - val_loss: 0.8179 - val_acc: 0.2004\n",
      "Epoch 128/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.6569 - acc: 0.2162 - val_loss: 0.9375 - val_acc: 0.2004\n",
      "Epoch 129/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.6703 - acc: 0.2162 - val_loss: 0.8611 - val_acc: 0.2004\n",
      "Epoch 130/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.6437 - acc: 0.2162 - val_loss: 0.8667 - val_acc: 0.2004\n",
      "Epoch 131/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.6766 - acc: 0.2162 - val_loss: 0.8408 - val_acc: 0.2004\n",
      "Epoch 132/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.6376 - acc: 0.2162 - val_loss: 0.8030 - val_acc: 0.2004\n",
      "Epoch 133/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.6502 - acc: 0.2158 - val_loss: 0.8582 - val_acc: 0.2004\n",
      "Epoch 134/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.7253 - acc: 0.2158 - val_loss: 0.7874 - val_acc: 0.2004\n",
      "Epoch 135/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.7112 - acc: 0.2158 - val_loss: 0.7948 - val_acc: 0.2004\n",
      "Epoch 136/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.7485 - acc: 0.2158 - val_loss: 0.8355 - val_acc: 0.2004\n",
      "Epoch 137/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.6394 - acc: 0.2158 - val_loss: 0.9959 - val_acc: 0.2004\n",
      "Epoch 138/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.7029 - acc: 0.2162 - val_loss: 0.8160 - val_acc: 0.2004\n",
      "Epoch 139/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.6086 - acc: 0.2162 - val_loss: 0.8284 - val_acc: 0.2004\n",
      "Epoch 140/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.6146 - acc: 0.2162 - val_loss: 0.8652 - val_acc: 0.2004\n",
      "Epoch 141/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.6425 - acc: 0.2158 - val_loss: 1.0283 - val_acc: 0.2004\n",
      "Epoch 142/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.6990 - acc: 0.2162 - val_loss: 1.0548 - val_acc: 0.2004\n",
      "Epoch 143/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.6651 - acc: 0.2162 - val_loss: 0.7560 - val_acc: 0.2004\n",
      "Epoch 144/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.6382 - acc: 0.2162 - val_loss: 1.0780 - val_acc: 0.1985\n",
      "Epoch 145/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.6084 - acc: 0.2148 - val_loss: 0.7800 - val_acc: 0.2004\n",
      "Epoch 146/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5898 - acc: 0.2162 - val_loss: 0.7935 - val_acc: 0.2004\n",
      "Epoch 147/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.6389 - acc: 0.2153 - val_loss: 0.8685 - val_acc: 0.2004\n",
      "Epoch 148/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.6278 - acc: 0.2158 - val_loss: 0.8409 - val_acc: 0.2004\n",
      "Epoch 149/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.6245 - acc: 0.2153 - val_loss: 0.7799 - val_acc: 0.2004\n",
      "Epoch 150/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.6151 - acc: 0.2153 - val_loss: 0.8246 - val_acc: 0.2004\n",
      "Epoch 151/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5858 - acc: 0.2148 - val_loss: 0.8103 - val_acc: 0.2004\n",
      "Epoch 152/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5939 - acc: 0.2158 - val_loss: 0.7955 - val_acc: 0.2004\n",
      "Epoch 153/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.5895 - acc: 0.2158 - val_loss: 0.8092 - val_acc: 0.2004\n",
      "Epoch 154/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.6454 - acc: 0.2144 - val_loss: 0.7853 - val_acc: 0.2004\n",
      "Epoch 155/4000\n",
      "68/68 [==============================] - 5s 77ms/step - loss: 0.6172 - acc: 0.2158 - val_loss: 1.2081 - val_acc: 0.2004\n",
      "Epoch 156/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.6462 - acc: 0.2158 - val_loss: 0.7554 - val_acc: 0.2004\n",
      "Epoch 157/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.6211 - acc: 0.2158 - val_loss: 0.8813 - val_acc: 0.2004\n",
      "Epoch 158/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5996 - acc: 0.2162 - val_loss: 0.7742 - val_acc: 0.2004\n",
      "Epoch 159/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5680 - acc: 0.2162 - val_loss: 0.7701 - val_acc: 0.2004\n",
      "Epoch 160/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5912 - acc: 0.2153 - val_loss: 0.7667 - val_acc: 0.2004\n",
      "Epoch 161/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5844 - acc: 0.2153 - val_loss: 0.7643 - val_acc: 0.2004\n",
      "Epoch 162/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.6007 - acc: 0.2158 - val_loss: 0.7736 - val_acc: 0.2004\n",
      "Epoch 163/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.6316 - acc: 0.2153 - val_loss: 0.8166 - val_acc: 0.2004\n",
      "Epoch 164/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.6220 - acc: 0.2158 - val_loss: 0.9451 - val_acc: 0.2004\n",
      "Epoch 165/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.6478 - acc: 0.2144 - val_loss: 0.7710 - val_acc: 0.2004\n",
      "Epoch 166/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.5850 - acc: 0.2162 - val_loss: 0.8106 - val_acc: 0.2004\n",
      "Epoch 167/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.6770 - acc: 0.2148 - val_loss: 0.8027 - val_acc: 0.2004\n",
      "Epoch 168/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.5632 - acc: 0.2158 - val_loss: 0.8354 - val_acc: 0.2004\n",
      "Epoch 169/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5741 - acc: 0.2158 - val_loss: 0.7589 - val_acc: 0.2004\n",
      "Epoch 170/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.6202 - acc: 0.2153 - val_loss: 1.0920 - val_acc: 0.2004\n",
      "Epoch 171/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.6166 - acc: 0.2153 - val_loss: 1.0254 - val_acc: 0.1985\n",
      "Epoch 172/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5990 - acc: 0.2158 - val_loss: 0.9630 - val_acc: 0.2004\n",
      "Epoch 173/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.5975 - acc: 0.2148 - val_loss: 0.7465 - val_acc: 0.2004\n",
      "Epoch 174/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5505 - acc: 0.2158 - val_loss: 0.7236 - val_acc: 0.2004\n",
      "Epoch 175/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.5779 - acc: 0.2153 - val_loss: 0.7736 - val_acc: 0.2004\n",
      "Epoch 176/4000\n",
      "68/68 [==============================] - 5s 66ms/step - loss: 0.5934 - acc: 0.2148 - val_loss: 0.9123 - val_acc: 0.2004\n",
      "Epoch 177/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.6224 - acc: 0.2148 - val_loss: 1.1728 - val_acc: 0.2004\n",
      "Epoch 178/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5681 - acc: 0.2158 - val_loss: 0.8319 - val_acc: 0.2004\n",
      "Epoch 179/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5770 - acc: 0.2148 - val_loss: 0.7463 - val_acc: 0.2004\n",
      "Epoch 180/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.5371 - acc: 0.2139 - val_loss: 0.9101 - val_acc: 0.2004\n",
      "Epoch 181/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.5767 - acc: 0.2153 - val_loss: 0.7688 - val_acc: 0.2004\n",
      "Epoch 182/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5643 - acc: 0.2144 - val_loss: 0.8088 - val_acc: 0.2004\n",
      "Epoch 183/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5708 - acc: 0.2153 - val_loss: 0.8710 - val_acc: 0.2004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5378 - acc: 0.2148 - val_loss: 0.8351 - val_acc: 0.2004\n",
      "Epoch 185/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.5264 - acc: 0.2153 - val_loss: 0.7978 - val_acc: 0.2004\n",
      "Epoch 186/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5612 - acc: 0.2153 - val_loss: 0.7622 - val_acc: 0.2004\n",
      "Epoch 187/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5767 - acc: 0.2153 - val_loss: 1.0635 - val_acc: 0.1985\n",
      "Epoch 188/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5889 - acc: 0.2144 - val_loss: 0.7787 - val_acc: 0.2004\n",
      "Epoch 189/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.5276 - acc: 0.2158 - val_loss: 0.7650 - val_acc: 0.2004\n",
      "Epoch 190/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5279 - acc: 0.2148 - val_loss: 0.8949 - val_acc: 0.2004\n",
      "Epoch 191/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.6038 - acc: 0.2153 - val_loss: 0.9055 - val_acc: 0.2004\n",
      "Epoch 192/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5951 - acc: 0.2153 - val_loss: 0.7630 - val_acc: 0.2004\n",
      "Epoch 193/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5460 - acc: 0.2153 - val_loss: 0.8811 - val_acc: 0.2004\n",
      "Epoch 194/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.5548 - acc: 0.2153 - val_loss: 0.7865 - val_acc: 0.2004\n",
      "Epoch 195/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5577 - acc: 0.2139 - val_loss: 0.9052 - val_acc: 0.2004\n",
      "Epoch 196/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5964 - acc: 0.2135 - val_loss: 0.7582 - val_acc: 0.2004\n",
      "Epoch 197/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5233 - acc: 0.2144 - val_loss: 0.8042 - val_acc: 0.2004\n",
      "Epoch 198/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.5431 - acc: 0.2144 - val_loss: 0.8197 - val_acc: 0.2004\n",
      "Epoch 199/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 0.5438 - acc: 0.2148 - val_loss: 0.8090 - val_acc: 0.2004\n",
      "Epoch 200/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5443 - acc: 0.2148 - val_loss: 0.8162 - val_acc: 0.2004\n",
      "Epoch 201/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5361 - acc: 0.2148 - val_loss: 0.8218 - val_acc: 0.2004\n",
      "Epoch 202/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5092 - acc: 0.2148 - val_loss: 1.1894 - val_acc: 0.2004\n",
      "Epoch 203/4000\n",
      "68/68 [==============================] - 5s 70ms/step - loss: 0.5476 - acc: 0.2148 - val_loss: 0.7924 - val_acc: 0.2004\n",
      "Epoch 204/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5397 - acc: 0.2139 - val_loss: 0.7858 - val_acc: 0.2004\n",
      "Epoch 205/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5078 - acc: 0.2148 - val_loss: 0.7508 - val_acc: 0.2004\n",
      "Epoch 206/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4982 - acc: 0.2148 - val_loss: 0.8413 - val_acc: 0.2004\n",
      "Epoch 207/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5949 - acc: 0.2144 - val_loss: 0.8995 - val_acc: 0.2004\n",
      "Epoch 208/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4982 - acc: 0.2148 - val_loss: 0.8570 - val_acc: 0.2004\n",
      "Epoch 209/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5470 - acc: 0.2148 - val_loss: 0.7476 - val_acc: 0.2004\n",
      "Epoch 210/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5551 - acc: 0.2139 - val_loss: 0.8003 - val_acc: 0.2004\n",
      "Epoch 211/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.5053 - acc: 0.2148 - val_loss: 0.8459 - val_acc: 0.2004\n",
      "Epoch 212/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.5201 - acc: 0.2148 - val_loss: 0.7509 - val_acc: 0.2004\n",
      "Epoch 213/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5237 - acc: 0.2158 - val_loss: 0.7748 - val_acc: 0.2004\n",
      "Epoch 214/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5225 - acc: 0.2148 - val_loss: 0.7684 - val_acc: 0.2004\n",
      "Epoch 215/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5022 - acc: 0.2153 - val_loss: 0.7619 - val_acc: 0.2004\n",
      "Epoch 216/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4936 - acc: 0.2148 - val_loss: 0.7886 - val_acc: 0.2004\n",
      "Epoch 217/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.5338 - acc: 0.2148 - val_loss: 0.7476 - val_acc: 0.2004\n",
      "Epoch 218/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5235 - acc: 0.2144 - val_loss: 0.8776 - val_acc: 0.2004\n",
      "Epoch 219/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.4993 - acc: 0.2148 - val_loss: 0.9372 - val_acc: 0.2004\n",
      "Epoch 220/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5261 - acc: 0.2144 - val_loss: 0.8186 - val_acc: 0.2004\n",
      "Epoch 221/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.5123 - acc: 0.2148 - val_loss: 0.8434 - val_acc: 0.2004\n",
      "Epoch 222/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4845 - acc: 0.2153 - val_loss: 0.7580 - val_acc: 0.2004\n",
      "Epoch 223/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5311 - acc: 0.2144 - val_loss: 1.2977 - val_acc: 0.1967\n",
      "Epoch 224/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5503 - acc: 0.2144 - val_loss: 0.8754 - val_acc: 0.2004\n",
      "Epoch 225/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4734 - acc: 0.2144 - val_loss: 0.7870 - val_acc: 0.2004\n",
      "Epoch 226/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4930 - acc: 0.2148 - val_loss: 0.8595 - val_acc: 0.2004\n",
      "Epoch 227/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4770 - acc: 0.2148 - val_loss: 0.8655 - val_acc: 0.2004\n",
      "Epoch 228/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.5031 - acc: 0.2148 - val_loss: 0.7729 - val_acc: 0.2004\n",
      "Epoch 229/4000\n",
      "68/68 [==============================] - 5s 79ms/step - loss: 0.4922 - acc: 0.2144 - val_loss: 0.7848 - val_acc: 0.2004\n",
      "Epoch 230/4000\n",
      "68/68 [==============================] - 5s 71ms/step - loss: 0.5023 - acc: 0.2144 - val_loss: 0.8405 - val_acc: 0.2004\n",
      "Epoch 231/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4898 - acc: 0.2153 - val_loss: 0.8451 - val_acc: 0.2004\n",
      "Epoch 232/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5346 - acc: 0.2135 - val_loss: 0.9273 - val_acc: 0.1985\n",
      "Epoch 233/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5380 - acc: 0.2148 - val_loss: 0.7039 - val_acc: 0.2004\n",
      "Epoch 234/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.7163 - acc: 0.2144 - val_loss: 0.8638 - val_acc: 0.2004\n",
      "Epoch 235/4000\n",
      "68/68 [==============================] - 5s 66ms/step - loss: 0.6956 - acc: 0.2153 - val_loss: 1.1272 - val_acc: 0.1967\n",
      "Epoch 236/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.6499 - acc: 0.2135 - val_loss: 0.9566 - val_acc: 0.2004\n",
      "Epoch 237/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4758 - acc: 0.2148 - val_loss: 0.7444 - val_acc: 0.2004\n",
      "Epoch 238/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4995 - acc: 0.2158 - val_loss: 0.7565 - val_acc: 0.2004\n",
      "Epoch 239/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4712 - acc: 0.2153 - val_loss: 0.8725 - val_acc: 0.2004\n",
      "Epoch 240/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.6083 - acc: 0.2139 - val_loss: 0.9223 - val_acc: 0.2004\n",
      "Epoch 241/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4886 - acc: 0.2144 - val_loss: 0.9002 - val_acc: 0.2004\n",
      "Epoch 242/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.5095 - acc: 0.2153 - val_loss: 0.8604 - val_acc: 0.2004\n",
      "Epoch 243/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4659 - acc: 0.2148 - val_loss: 0.7666 - val_acc: 0.2004\n",
      "Epoch 244/4000\n",
      "68/68 [==============================] - 5s 66ms/step - loss: 0.4774 - acc: 0.2144 - val_loss: 0.7664 - val_acc: 0.2004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4798 - acc: 0.2153 - val_loss: 0.7586 - val_acc: 0.2004\n",
      "Epoch 246/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4772 - acc: 0.2148 - val_loss: 0.8943 - val_acc: 0.2004\n",
      "Epoch 247/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.4892 - acc: 0.2144 - val_loss: 0.7604 - val_acc: 0.2004\n",
      "Epoch 248/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4726 - acc: 0.2148 - val_loss: 0.8495 - val_acc: 0.2004\n",
      "Epoch 249/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4654 - acc: 0.2148 - val_loss: 0.7805 - val_acc: 0.2004\n",
      "Epoch 250/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4567 - acc: 0.2148 - val_loss: 0.9075 - val_acc: 0.2004\n",
      "Epoch 251/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5014 - acc: 0.2148 - val_loss: 0.8294 - val_acc: 0.2004\n",
      "Epoch 252/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.4947 - acc: 0.2148 - val_loss: 0.7611 - val_acc: 0.2004\n",
      "Epoch 253/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.4481 - acc: 0.2148 - val_loss: 0.8223 - val_acc: 0.2004\n",
      "Epoch 254/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4539 - acc: 0.2144 - val_loss: 0.9092 - val_acc: 0.2004\n",
      "Epoch 255/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4876 - acc: 0.2153 - val_loss: 0.7588 - val_acc: 0.2004\n",
      "Epoch 256/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.4816 - acc: 0.2148 - val_loss: 0.7789 - val_acc: 0.2004\n",
      "Epoch 257/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4703 - acc: 0.2144 - val_loss: 0.7814 - val_acc: 0.2004\n",
      "Epoch 258/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.5226 - acc: 0.2144 - val_loss: 0.8256 - val_acc: 0.2004\n",
      "Epoch 259/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.4796 - acc: 0.2153 - val_loss: 0.8073 - val_acc: 0.2004\n",
      "Epoch 260/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4857 - acc: 0.2148 - val_loss: 0.7426 - val_acc: 0.2004\n",
      "Epoch 261/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4467 - acc: 0.2153 - val_loss: 0.8369 - val_acc: 0.2004\n",
      "Epoch 262/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4613 - acc: 0.2139 - val_loss: 0.7797 - val_acc: 0.2004\n",
      "Epoch 263/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.5244 - acc: 0.2153 - val_loss: 0.7984 - val_acc: 0.2004\n",
      "Epoch 264/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4549 - acc: 0.2148 - val_loss: 0.8991 - val_acc: 0.1985\n",
      "Epoch 265/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4876 - acc: 0.2144 - val_loss: 0.7707 - val_acc: 0.2004\n",
      "Epoch 266/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4590 - acc: 0.2148 - val_loss: 1.0707 - val_acc: 0.2004\n",
      "Epoch 267/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4984 - acc: 0.2139 - val_loss: 0.7819 - val_acc: 0.2004\n",
      "Epoch 268/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4752 - acc: 0.2144 - val_loss: 0.7937 - val_acc: 0.2004\n",
      "Epoch 269/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4790 - acc: 0.2144 - val_loss: 0.7987 - val_acc: 0.2004\n",
      "Epoch 270/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.4972 - acc: 0.2148 - val_loss: 0.7838 - val_acc: 0.2004\n",
      "Epoch 271/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4758 - acc: 0.2144 - val_loss: 0.8305 - val_acc: 0.2004\n",
      "Epoch 272/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4805 - acc: 0.2158 - val_loss: 0.7619 - val_acc: 0.2004\n",
      "Epoch 273/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5122 - acc: 0.2139 - val_loss: 0.8422 - val_acc: 0.2004\n",
      "Epoch 274/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4741 - acc: 0.2153 - val_loss: 0.7732 - val_acc: 0.2004\n",
      "Epoch 275/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4799 - acc: 0.2144 - val_loss: 0.8914 - val_acc: 0.2004\n",
      "Epoch 276/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.5017 - acc: 0.2148 - val_loss: 0.7717 - val_acc: 0.2004\n",
      "Epoch 277/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4633 - acc: 0.2153 - val_loss: 0.8773 - val_acc: 0.2004\n",
      "Epoch 278/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4533 - acc: 0.2148 - val_loss: 0.8559 - val_acc: 0.2004\n",
      "Epoch 279/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4293 - acc: 0.2158 - val_loss: 0.8099 - val_acc: 0.2004\n",
      "Epoch 280/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4389 - acc: 0.2148 - val_loss: 0.7808 - val_acc: 0.2004\n",
      "Epoch 281/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4284 - acc: 0.2139 - val_loss: 0.9277 - val_acc: 0.1985\n",
      "Epoch 282/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4660 - acc: 0.2148 - val_loss: 0.9714 - val_acc: 0.1985\n",
      "Epoch 283/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4516 - acc: 0.2158 - val_loss: 0.9016 - val_acc: 0.2004\n",
      "Epoch 284/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.4698 - acc: 0.2139 - val_loss: 0.9756 - val_acc: 0.1985\n",
      "Epoch 285/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4728 - acc: 0.2144 - val_loss: 0.8337 - val_acc: 0.2004\n",
      "Epoch 286/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4711 - acc: 0.2148 - val_loss: 0.8053 - val_acc: 0.2004\n",
      "Epoch 287/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4943 - acc: 0.2135 - val_loss: 1.1919 - val_acc: 0.2004\n",
      "Epoch 288/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5283 - acc: 0.2139 - val_loss: 0.7492 - val_acc: 0.2004\n",
      "Epoch 289/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4092 - acc: 0.2144 - val_loss: 0.7677 - val_acc: 0.2004\n",
      "Epoch 290/4000\n",
      "68/68 [==============================] - 5s 66ms/step - loss: 0.4588 - acc: 0.2148 - val_loss: 0.7978 - val_acc: 0.2004\n",
      "Epoch 291/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4480 - acc: 0.2144 - val_loss: 0.7882 - val_acc: 0.2004\n",
      "Epoch 292/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4167 - acc: 0.2148 - val_loss: 0.8445 - val_acc: 0.2004\n",
      "Epoch 293/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4227 - acc: 0.2144 - val_loss: 0.7708 - val_acc: 0.2004\n",
      "Epoch 294/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.5127 - acc: 0.2135 - val_loss: 0.8343 - val_acc: 0.2004\n",
      "Epoch 295/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4303 - acc: 0.2148 - val_loss: 0.8291 - val_acc: 0.2004\n",
      "Epoch 296/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4390 - acc: 0.2144 - val_loss: 0.9712 - val_acc: 0.1985\n",
      "Epoch 297/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4963 - acc: 0.2139 - val_loss: 0.7996 - val_acc: 0.2004\n",
      "Epoch 298/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4394 - acc: 0.2148 - val_loss: 0.8519 - val_acc: 0.1985\n",
      "Epoch 299/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4714 - acc: 0.2144 - val_loss: 0.8488 - val_acc: 0.2004\n",
      "Epoch 300/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4288 - acc: 0.2148 - val_loss: 0.8151 - val_acc: 0.2004\n",
      "Epoch 301/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4301 - acc: 0.2144 - val_loss: 0.8735 - val_acc: 0.1985\n",
      "Epoch 302/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.5030 - acc: 0.2139 - val_loss: 0.8284 - val_acc: 0.2004\n",
      "Epoch 303/4000\n",
      "68/68 [==============================] - 5s 72ms/step - loss: 0.4251 - acc: 0.2144 - val_loss: 0.9909 - val_acc: 0.2004\n",
      "Epoch 304/4000\n",
      "68/68 [==============================] - 5s 72ms/step - loss: 0.4639 - acc: 0.2153 - val_loss: 0.8435 - val_acc: 0.2004\n",
      "Epoch 305/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4484 - acc: 0.2139 - val_loss: 0.9529 - val_acc: 0.1985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 306/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4309 - acc: 0.2144 - val_loss: 0.7286 - val_acc: 0.2004\n",
      "Epoch 307/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4953 - acc: 0.2144 - val_loss: 0.8158 - val_acc: 0.2004\n",
      "Epoch 308/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4859 - acc: 0.2139 - val_loss: 0.8647 - val_acc: 0.1985\n",
      "Epoch 309/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4352 - acc: 0.2144 - val_loss: 0.8145 - val_acc: 0.2004\n",
      "Epoch 310/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4316 - acc: 0.2144 - val_loss: 0.8731 - val_acc: 0.2004\n",
      "Epoch 311/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4249 - acc: 0.2148 - val_loss: 0.8800 - val_acc: 0.2004\n",
      "Epoch 312/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.4374 - acc: 0.2153 - val_loss: 0.8427 - val_acc: 0.2004\n",
      "Epoch 313/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4441 - acc: 0.2144 - val_loss: 0.9221 - val_acc: 0.2004\n",
      "Epoch 314/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4135 - acc: 0.2153 - val_loss: 1.1124 - val_acc: 0.2004\n",
      "Epoch 315/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4281 - acc: 0.2148 - val_loss: 0.8290 - val_acc: 0.2004\n",
      "Epoch 316/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4223 - acc: 0.2144 - val_loss: 0.7664 - val_acc: 0.2004\n",
      "Epoch 317/4000\n",
      "68/68 [==============================] - 6s 91ms/step - loss: 0.4017 - acc: 0.2144 - val_loss: 0.9269 - val_acc: 0.2004\n",
      "Epoch 318/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4333 - acc: 0.2139 - val_loss: 0.8864 - val_acc: 0.2004\n",
      "Epoch 319/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4478 - acc: 0.2158 - val_loss: 0.8354 - val_acc: 0.2004\n",
      "Epoch 320/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4348 - acc: 0.2135 - val_loss: 0.8528 - val_acc: 0.2004\n",
      "Epoch 321/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.5124 - acc: 0.2130 - val_loss: 0.8630 - val_acc: 0.2004\n",
      "Epoch 322/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.5416 - acc: 0.2153 - val_loss: 0.8200 - val_acc: 0.2004\n",
      "Epoch 323/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.4985 - acc: 0.2148 - val_loss: 0.8295 - val_acc: 0.2004\n",
      "Epoch 324/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4143 - acc: 0.2148 - val_loss: 0.7616 - val_acc: 0.2004\n",
      "Epoch 325/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4120 - acc: 0.2144 - val_loss: 0.8899 - val_acc: 0.2004\n",
      "Epoch 326/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.4623 - acc: 0.2139 - val_loss: 0.9085 - val_acc: 0.1985\n",
      "Epoch 327/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4068 - acc: 0.2144 - val_loss: 0.7983 - val_acc: 0.2004\n",
      "Epoch 328/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3895 - acc: 0.2144 - val_loss: 0.7477 - val_acc: 0.2004\n",
      "Epoch 329/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4162 - acc: 0.2148 - val_loss: 0.7903 - val_acc: 0.2004\n",
      "Epoch 330/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4297 - acc: 0.2144 - val_loss: 0.7589 - val_acc: 0.2004\n",
      "Epoch 331/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4181 - acc: 0.2144 - val_loss: 0.8019 - val_acc: 0.2004\n",
      "Epoch 332/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3910 - acc: 0.2153 - val_loss: 0.8004 - val_acc: 0.2004\n",
      "Epoch 333/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4062 - acc: 0.2130 - val_loss: 0.8033 - val_acc: 0.2004\n",
      "Epoch 334/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.4094 - acc: 0.2139 - val_loss: 0.8459 - val_acc: 0.1985\n",
      "Epoch 335/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4121 - acc: 0.2148 - val_loss: 0.8612 - val_acc: 0.2004\n",
      "Epoch 336/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4091 - acc: 0.2144 - val_loss: 0.7701 - val_acc: 0.2004\n",
      "Epoch 337/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.4477 - acc: 0.2148 - val_loss: 1.0159 - val_acc: 0.2004\n",
      "Epoch 338/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4340 - acc: 0.2148 - val_loss: 0.8199 - val_acc: 0.1985\n",
      "Epoch 339/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.4089 - acc: 0.2148 - val_loss: 0.8189 - val_acc: 0.2004\n",
      "Epoch 340/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4309 - acc: 0.2144 - val_loss: 0.7414 - val_acc: 0.2004\n",
      "Epoch 341/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4675 - acc: 0.2148 - val_loss: 0.9900 - val_acc: 0.2004\n",
      "Epoch 342/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.6735 - acc: 0.2144 - val_loss: 1.5813 - val_acc: 0.2004\n",
      "Epoch 343/4000\n",
      "68/68 [==============================] - 6s 86ms/step - loss: 1.7624 - acc: 0.2125 - val_loss: 1.6051 - val_acc: 0.2004\n",
      "Epoch 344/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 0.7796 - acc: 0.2148 - val_loss: 0.8392 - val_acc: 0.2004\n",
      "Epoch 345/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.6803 - acc: 0.2158 - val_loss: 0.8741 - val_acc: 0.2004\n",
      "Epoch 346/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4554 - acc: 0.2153 - val_loss: 0.9792 - val_acc: 0.1985\n",
      "Epoch 347/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4229 - acc: 0.2153 - val_loss: 0.7647 - val_acc: 0.2004\n",
      "Epoch 348/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3957 - acc: 0.2158 - val_loss: 0.8431 - val_acc: 0.1985\n",
      "Epoch 349/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4091 - acc: 0.2153 - val_loss: 0.7712 - val_acc: 0.2004\n",
      "Epoch 350/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4112 - acc: 0.2148 - val_loss: 0.7761 - val_acc: 0.2004\n",
      "Epoch 351/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3805 - acc: 0.2148 - val_loss: 0.7873 - val_acc: 0.2004\n",
      "Epoch 352/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3951 - acc: 0.2148 - val_loss: 0.7888 - val_acc: 0.2004\n",
      "Epoch 353/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3999 - acc: 0.2144 - val_loss: 0.7780 - val_acc: 0.2004\n",
      "Epoch 354/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3931 - acc: 0.2158 - val_loss: 0.7856 - val_acc: 0.2004\n",
      "Epoch 355/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3999 - acc: 0.2139 - val_loss: 0.7787 - val_acc: 0.2004\n",
      "Epoch 356/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3942 - acc: 0.2144 - val_loss: 0.7958 - val_acc: 0.2004\n",
      "Epoch 357/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3833 - acc: 0.2144 - val_loss: 0.8051 - val_acc: 0.1985\n",
      "Epoch 358/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3782 - acc: 0.2153 - val_loss: 0.7968 - val_acc: 0.2004\n",
      "Epoch 359/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4336 - acc: 0.2148 - val_loss: 1.0936 - val_acc: 0.1985\n",
      "Epoch 360/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.4604 - acc: 0.2148 - val_loss: 0.8225 - val_acc: 0.2004\n",
      "Epoch 361/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3797 - acc: 0.2144 - val_loss: 0.8291 - val_acc: 0.2004\n",
      "Epoch 362/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3990 - acc: 0.2153 - val_loss: 0.8060 - val_acc: 0.2004\n",
      "Epoch 363/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4111 - acc: 0.2148 - val_loss: 0.7983 - val_acc: 0.2004\n",
      "Epoch 364/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3907 - acc: 0.2153 - val_loss: 0.9189 - val_acc: 0.1985\n",
      "Epoch 365/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3949 - acc: 0.2144 - val_loss: 0.8338 - val_acc: 0.2004\n",
      "Epoch 366/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3838 - acc: 0.2148 - val_loss: 0.8332 - val_acc: 0.1985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4217 - acc: 0.2139 - val_loss: 0.7729 - val_acc: 0.2004\n",
      "Epoch 368/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3804 - acc: 0.2144 - val_loss: 0.7984 - val_acc: 0.2004\n",
      "Epoch 369/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.4038 - acc: 0.2148 - val_loss: 0.7856 - val_acc: 0.2004\n",
      "Epoch 370/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3857 - acc: 0.2153 - val_loss: 0.8648 - val_acc: 0.2004\n",
      "Epoch 371/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4260 - acc: 0.2148 - val_loss: 0.9972 - val_acc: 0.2004\n",
      "Epoch 372/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4525 - acc: 0.2135 - val_loss: 0.8863 - val_acc: 0.2004\n",
      "Epoch 373/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4089 - acc: 0.2144 - val_loss: 0.8392 - val_acc: 0.2004\n",
      "Epoch 374/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4267 - acc: 0.2148 - val_loss: 0.8598 - val_acc: 0.2004\n",
      "Epoch 375/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4061 - acc: 0.2144 - val_loss: 0.8288 - val_acc: 0.2004\n",
      "Epoch 376/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4347 - acc: 0.2144 - val_loss: 0.7566 - val_acc: 0.2004\n",
      "Epoch 377/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.4229 - acc: 0.2153 - val_loss: 0.8205 - val_acc: 0.2004\n",
      "Epoch 378/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4026 - acc: 0.2130 - val_loss: 0.8723 - val_acc: 0.2004\n",
      "Epoch 379/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3739 - acc: 0.2139 - val_loss: 0.8064 - val_acc: 0.2004\n",
      "Epoch 380/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3932 - acc: 0.2148 - val_loss: 1.0040 - val_acc: 0.2004\n",
      "Epoch 381/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 0.3794 - acc: 0.2144 - val_loss: 0.8528 - val_acc: 0.2004\n",
      "Epoch 382/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4088 - acc: 0.2148 - val_loss: 0.8450 - val_acc: 0.2004\n",
      "Epoch 383/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4045 - acc: 0.2148 - val_loss: 1.0113 - val_acc: 0.2004\n",
      "Epoch 384/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3798 - acc: 0.2144 - val_loss: 0.7754 - val_acc: 0.2004\n",
      "Epoch 385/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.4093 - acc: 0.2153 - val_loss: 1.0413 - val_acc: 0.1985\n",
      "Epoch 386/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.4340 - acc: 0.2139 - val_loss: 0.7782 - val_acc: 0.2004\n",
      "Epoch 387/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3817 - acc: 0.2148 - val_loss: 0.8470 - val_acc: 0.1985\n",
      "Epoch 388/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4062 - acc: 0.2148 - val_loss: 0.8696 - val_acc: 0.2004\n",
      "Epoch 389/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4113 - acc: 0.2139 - val_loss: 0.8124 - val_acc: 0.2004\n",
      "Epoch 390/4000\n",
      "68/68 [==============================] - 6s 83ms/step - loss: 0.3724 - acc: 0.2144 - val_loss: 0.7756 - val_acc: 0.2004\n",
      "Epoch 391/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.4313 - acc: 0.2148 - val_loss: 0.8731 - val_acc: 0.1985\n",
      "Epoch 392/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3887 - acc: 0.2148 - val_loss: 0.7739 - val_acc: 0.2004\n",
      "Epoch 393/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3886 - acc: 0.2139 - val_loss: 0.7930 - val_acc: 0.1985\n",
      "Epoch 394/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4394 - acc: 0.2148 - val_loss: 0.9903 - val_acc: 0.2004\n",
      "Epoch 395/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3974 - acc: 0.2148 - val_loss: 0.7674 - val_acc: 0.2004\n",
      "Epoch 396/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.4182 - acc: 0.2144 - val_loss: 0.7931 - val_acc: 0.2004\n",
      "Epoch 397/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3650 - acc: 0.2144 - val_loss: 0.8054 - val_acc: 0.1985\n",
      "Epoch 398/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3988 - acc: 0.2144 - val_loss: 0.8315 - val_acc: 0.1985\n",
      "Epoch 399/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3939 - acc: 0.2144 - val_loss: 0.8025 - val_acc: 0.2004\n",
      "Epoch 400/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3668 - acc: 0.2153 - val_loss: 0.8528 - val_acc: 0.2004\n",
      "Epoch 401/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3925 - acc: 0.2153 - val_loss: 0.7793 - val_acc: 0.2004\n",
      "Epoch 402/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3728 - acc: 0.2153 - val_loss: 0.8422 - val_acc: 0.2004\n",
      "Epoch 403/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3861 - acc: 0.2148 - val_loss: 1.0959 - val_acc: 0.2004\n",
      "Epoch 404/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4831 - acc: 0.2130 - val_loss: 0.8438 - val_acc: 0.2004\n",
      "Epoch 405/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3975 - acc: 0.2148 - val_loss: 0.8123 - val_acc: 0.2004\n",
      "Epoch 406/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3707 - acc: 0.2153 - val_loss: 0.7981 - val_acc: 0.2004\n",
      "Epoch 407/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3692 - acc: 0.2139 - val_loss: 0.7964 - val_acc: 0.2004\n",
      "Epoch 408/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3775 - acc: 0.2148 - val_loss: 0.7928 - val_acc: 0.2004\n",
      "Epoch 409/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4090 - acc: 0.2139 - val_loss: 0.8246 - val_acc: 0.2004\n",
      "Epoch 410/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3706 - acc: 0.2153 - val_loss: 0.9030 - val_acc: 0.2004\n",
      "Epoch 411/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3942 - acc: 0.2148 - val_loss: 0.8335 - val_acc: 0.2004\n",
      "Epoch 412/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3728 - acc: 0.2144 - val_loss: 0.7731 - val_acc: 0.2004\n",
      "Epoch 413/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3782 - acc: 0.2144 - val_loss: 0.9492 - val_acc: 0.1985\n",
      "Epoch 414/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.4706 - acc: 0.2148 - val_loss: 0.8581 - val_acc: 0.1985\n",
      "Epoch 415/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.4142 - acc: 0.2148 - val_loss: 0.7939 - val_acc: 0.2004\n",
      "Epoch 416/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3821 - acc: 0.2148 - val_loss: 0.8276 - val_acc: 0.2004\n",
      "Epoch 417/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4259 - acc: 0.2144 - val_loss: 1.0374 - val_acc: 0.2004\n",
      "Epoch 418/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4260 - acc: 0.2144 - val_loss: 0.8409 - val_acc: 0.1985\n",
      "Epoch 419/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3990 - acc: 0.2153 - val_loss: 0.9790 - val_acc: 0.1985\n",
      "Epoch 420/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3988 - acc: 0.2139 - val_loss: 0.8577 - val_acc: 0.2004\n",
      "Epoch 421/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3703 - acc: 0.2139 - val_loss: 0.8147 - val_acc: 0.2004\n",
      "Epoch 422/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3739 - acc: 0.2153 - val_loss: 0.8014 - val_acc: 0.1985\n",
      "Epoch 423/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3775 - acc: 0.2139 - val_loss: 0.9510 - val_acc: 0.2004\n",
      "Epoch 424/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3680 - acc: 0.2144 - val_loss: 0.8259 - val_acc: 0.1985\n",
      "Epoch 425/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3717 - acc: 0.2148 - val_loss: 0.7825 - val_acc: 0.2004\n",
      "Epoch 426/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.3611 - acc: 0.2135 - val_loss: 0.8429 - val_acc: 0.2004\n",
      "Epoch 427/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3657 - acc: 0.2162 - val_loss: 0.7941 - val_acc: 0.2004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 428/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3606 - acc: 0.2139 - val_loss: 0.9401 - val_acc: 0.1985\n",
      "Epoch 429/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4619 - acc: 0.2144 - val_loss: 0.8976 - val_acc: 0.2004\n",
      "Epoch 430/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.6286 - acc: 0.2144 - val_loss: 0.8928 - val_acc: 0.1985\n",
      "Epoch 431/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.9151 - acc: 0.2139 - val_loss: 1.3437 - val_acc: 0.2004\n",
      "Epoch 432/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 1.1105 - acc: 0.2107 - val_loss: 0.8755 - val_acc: 0.2004\n",
      "Epoch 433/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.5649 - acc: 0.2162 - val_loss: 0.9790 - val_acc: 0.2004\n",
      "Epoch 434/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.6566 - acc: 0.2144 - val_loss: 1.0227 - val_acc: 0.2004\n",
      "Epoch 435/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4451 - acc: 0.2153 - val_loss: 0.6989 - val_acc: 0.2004\n",
      "Epoch 436/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3711 - acc: 0.2153 - val_loss: 0.7782 - val_acc: 0.2004\n",
      "Epoch 437/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3651 - acc: 0.2144 - val_loss: 0.9653 - val_acc: 0.2004\n",
      "Epoch 438/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3955 - acc: 0.2153 - val_loss: 0.7565 - val_acc: 0.2004\n",
      "Epoch 439/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3603 - acc: 0.2139 - val_loss: 0.7901 - val_acc: 0.2004\n",
      "Epoch 440/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3705 - acc: 0.2144 - val_loss: 0.7623 - val_acc: 0.2004\n",
      "Epoch 441/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4604 - acc: 0.2148 - val_loss: 1.0095 - val_acc: 0.1985\n",
      "Epoch 442/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3634 - acc: 0.2148 - val_loss: 0.7760 - val_acc: 0.2004\n",
      "Epoch 443/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3637 - acc: 0.2144 - val_loss: 0.8290 - val_acc: 0.2004\n",
      "Epoch 444/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3547 - acc: 0.2158 - val_loss: 0.7588 - val_acc: 0.2004\n",
      "Epoch 445/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3483 - acc: 0.2153 - val_loss: 0.7738 - val_acc: 0.2004\n",
      "Epoch 446/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3670 - acc: 0.2144 - val_loss: 0.7602 - val_acc: 0.2004\n",
      "Epoch 447/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3714 - acc: 0.2139 - val_loss: 0.8218 - val_acc: 0.1985\n",
      "Epoch 448/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3795 - acc: 0.2144 - val_loss: 0.7777 - val_acc: 0.2004\n",
      "Epoch 449/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3585 - acc: 0.2153 - val_loss: 0.7463 - val_acc: 0.2004\n",
      "Epoch 450/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4076 - acc: 0.2148 - val_loss: 0.9391 - val_acc: 0.1985\n",
      "Epoch 451/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4171 - acc: 0.2148 - val_loss: 0.8282 - val_acc: 0.2004\n",
      "Epoch 452/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3607 - acc: 0.2153 - val_loss: 0.7692 - val_acc: 0.2004\n",
      "Epoch 453/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3874 - acc: 0.2162 - val_loss: 0.7900 - val_acc: 0.2004\n",
      "Epoch 454/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3753 - acc: 0.2144 - val_loss: 0.8902 - val_acc: 0.1985\n",
      "Epoch 455/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3539 - acc: 0.2148 - val_loss: 0.7598 - val_acc: 0.2004\n",
      "Epoch 456/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3642 - acc: 0.2139 - val_loss: 0.8105 - val_acc: 0.2004\n",
      "Epoch 457/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3592 - acc: 0.2153 - val_loss: 0.7797 - val_acc: 0.2004\n",
      "Epoch 458/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3568 - acc: 0.2148 - val_loss: 0.7615 - val_acc: 0.2004\n",
      "Epoch 459/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3517 - acc: 0.2153 - val_loss: 0.7962 - val_acc: 0.2004\n",
      "Epoch 460/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3429 - acc: 0.2139 - val_loss: 0.7736 - val_acc: 0.1985\n",
      "Epoch 461/4000\n",
      "68/68 [==============================] - 5s 74ms/step - loss: 0.3506 - acc: 0.2148 - val_loss: 0.7871 - val_acc: 0.2004\n",
      "Epoch 462/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3640 - acc: 0.2148 - val_loss: 0.7809 - val_acc: 0.2004\n",
      "Epoch 463/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3629 - acc: 0.2148 - val_loss: 0.8064 - val_acc: 0.1985\n",
      "Epoch 464/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3767 - acc: 0.2144 - val_loss: 0.7857 - val_acc: 0.2004\n",
      "Epoch 465/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3431 - acc: 0.2139 - val_loss: 0.7812 - val_acc: 0.2004\n",
      "Epoch 466/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3545 - acc: 0.2148 - val_loss: 0.8374 - val_acc: 0.1985\n",
      "Epoch 467/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3741 - acc: 0.2148 - val_loss: 0.8684 - val_acc: 0.1985\n",
      "Epoch 468/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3733 - acc: 0.2148 - val_loss: 0.8263 - val_acc: 0.2004\n",
      "Epoch 469/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3987 - acc: 0.2148 - val_loss: 0.8173 - val_acc: 0.1985\n",
      "Epoch 470/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3681 - acc: 0.2139 - val_loss: 0.9278 - val_acc: 0.2004\n",
      "Epoch 471/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3651 - acc: 0.2144 - val_loss: 0.8920 - val_acc: 0.1985\n",
      "Epoch 472/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3978 - acc: 0.2162 - val_loss: 0.8120 - val_acc: 0.1985\n",
      "Epoch 473/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3396 - acc: 0.2144 - val_loss: 0.8128 - val_acc: 0.1985\n",
      "Epoch 474/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3688 - acc: 0.2153 - val_loss: 0.9304 - val_acc: 0.1985\n",
      "Epoch 475/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.4054 - acc: 0.2158 - val_loss: 0.8348 - val_acc: 0.1985\n",
      "Epoch 476/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3707 - acc: 0.2148 - val_loss: 0.8082 - val_acc: 0.2004\n",
      "Epoch 477/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3743 - acc: 0.2148 - val_loss: 0.8198 - val_acc: 0.1985\n",
      "Epoch 478/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3552 - acc: 0.2135 - val_loss: 0.8108 - val_acc: 0.2004\n",
      "Epoch 479/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3467 - acc: 0.2144 - val_loss: 0.9007 - val_acc: 0.1985\n",
      "Epoch 480/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3441 - acc: 0.2153 - val_loss: 0.8877 - val_acc: 0.1985\n",
      "Epoch 481/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3646 - acc: 0.2148 - val_loss: 0.7604 - val_acc: 0.2004\n",
      "Epoch 482/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3479 - acc: 0.2148 - val_loss: 0.8299 - val_acc: 0.2004\n",
      "Epoch 483/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3870 - acc: 0.2148 - val_loss: 0.7788 - val_acc: 0.2004\n",
      "Epoch 484/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3564 - acc: 0.2148 - val_loss: 0.9076 - val_acc: 0.2004\n",
      "Epoch 485/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3440 - acc: 0.2148 - val_loss: 0.7815 - val_acc: 0.1985\n",
      "Epoch 486/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3555 - acc: 0.2148 - val_loss: 0.8075 - val_acc: 0.1985\n",
      "Epoch 487/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3346 - acc: 0.2148 - val_loss: 0.7955 - val_acc: 0.2004\n",
      "Epoch 488/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3919 - acc: 0.2135 - val_loss: 0.7970 - val_acc: 0.2004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 489/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3539 - acc: 0.2148 - val_loss: 0.7684 - val_acc: 0.1985\n",
      "Epoch 490/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3750 - acc: 0.2148 - val_loss: 0.8512 - val_acc: 0.1985\n",
      "Epoch 491/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3476 - acc: 0.2153 - val_loss: 0.7866 - val_acc: 0.1985\n",
      "Epoch 492/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4326 - acc: 0.2135 - val_loss: 0.8629 - val_acc: 0.1985\n",
      "Epoch 493/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3611 - acc: 0.2153 - val_loss: 0.7509 - val_acc: 0.2004\n",
      "Epoch 494/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3377 - acc: 0.2148 - val_loss: 0.8514 - val_acc: 0.2004\n",
      "Epoch 495/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3370 - acc: 0.2139 - val_loss: 0.8107 - val_acc: 0.1985\n",
      "Epoch 496/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3305 - acc: 0.2144 - val_loss: 0.7740 - val_acc: 0.2004\n",
      "Epoch 497/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3330 - acc: 0.2148 - val_loss: 0.7875 - val_acc: 0.2004\n",
      "Epoch 498/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3280 - acc: 0.2144 - val_loss: 1.0575 - val_acc: 0.1985\n",
      "Epoch 499/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3686 - acc: 0.2148 - val_loss: 0.8444 - val_acc: 0.2004\n",
      "Epoch 500/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3587 - acc: 0.2148 - val_loss: 0.7512 - val_acc: 0.2004\n",
      "Epoch 501/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3524 - acc: 0.2144 - val_loss: 0.7640 - val_acc: 0.2004\n",
      "Epoch 502/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3532 - acc: 0.2144 - val_loss: 0.7821 - val_acc: 0.1985\n",
      "Epoch 503/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3633 - acc: 0.2148 - val_loss: 0.7860 - val_acc: 0.1985\n",
      "Epoch 504/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3934 - acc: 0.2158 - val_loss: 0.9422 - val_acc: 0.1985\n",
      "Epoch 505/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3843 - acc: 0.2153 - val_loss: 0.7734 - val_acc: 0.1985\n",
      "Epoch 506/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3400 - acc: 0.2139 - val_loss: 0.8575 - val_acc: 0.2004\n",
      "Epoch 507/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3859 - acc: 0.2148 - val_loss: 0.7182 - val_acc: 0.2004\n",
      "Epoch 508/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3590 - acc: 0.2148 - val_loss: 0.8715 - val_acc: 0.1985\n",
      "Epoch 509/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3456 - acc: 0.2144 - val_loss: 0.7898 - val_acc: 0.2004\n",
      "Epoch 510/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3432 - acc: 0.2153 - val_loss: 0.7821 - val_acc: 0.1985\n",
      "Epoch 511/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3213 - acc: 0.2144 - val_loss: 0.8222 - val_acc: 0.1985\n",
      "Epoch 512/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3411 - acc: 0.2148 - val_loss: 0.8069 - val_acc: 0.1985\n",
      "Epoch 513/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3564 - acc: 0.2158 - val_loss: 0.7929 - val_acc: 0.2004\n",
      "Epoch 514/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3666 - acc: 0.2144 - val_loss: 0.7804 - val_acc: 0.1985\n",
      "Epoch 515/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3456 - acc: 0.2148 - val_loss: 0.7849 - val_acc: 0.2004\n",
      "Epoch 516/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3705 - acc: 0.2153 - val_loss: 0.8811 - val_acc: 0.2004\n",
      "Epoch 517/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3469 - acc: 0.2139 - val_loss: 0.8149 - val_acc: 0.2004\n",
      "Epoch 518/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3566 - acc: 0.2148 - val_loss: 1.0245 - val_acc: 0.1985\n",
      "Epoch 519/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3492 - acc: 0.2139 - val_loss: 0.7774 - val_acc: 0.2004\n",
      "Epoch 520/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.4042 - acc: 0.2148 - val_loss: 1.2033 - val_acc: 0.2004\n",
      "Epoch 521/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4402 - acc: 0.2139 - val_loss: 0.8402 - val_acc: 0.1985\n",
      "Epoch 522/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3748 - acc: 0.2144 - val_loss: 0.7586 - val_acc: 0.2004\n",
      "Epoch 523/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3926 - acc: 0.2148 - val_loss: 0.8236 - val_acc: 0.2004\n",
      "Epoch 524/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3569 - acc: 0.2144 - val_loss: 0.9119 - val_acc: 0.1985\n",
      "Epoch 525/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3591 - acc: 0.2148 - val_loss: 0.7409 - val_acc: 0.2004\n",
      "Epoch 526/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3607 - acc: 0.2153 - val_loss: 0.7877 - val_acc: 0.2004\n",
      "Epoch 527/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3343 - acc: 0.2148 - val_loss: 0.8167 - val_acc: 0.1985\n",
      "Epoch 528/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3622 - acc: 0.2148 - val_loss: 0.7375 - val_acc: 0.2004\n",
      "Epoch 529/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3468 - acc: 0.2153 - val_loss: 0.8081 - val_acc: 0.2004\n",
      "Epoch 530/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3195 - acc: 0.2148 - val_loss: 0.7697 - val_acc: 0.2004\n",
      "Epoch 531/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3745 - acc: 0.2153 - val_loss: 0.8420 - val_acc: 0.2004\n",
      "Epoch 532/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3320 - acc: 0.2153 - val_loss: 0.7919 - val_acc: 0.2004\n",
      "Epoch 533/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3336 - acc: 0.2148 - val_loss: 0.8168 - val_acc: 0.2004\n",
      "Epoch 534/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4285 - acc: 0.2144 - val_loss: 1.4562 - val_acc: 0.2004\n",
      "Epoch 535/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3754 - acc: 0.2144 - val_loss: 0.8003 - val_acc: 0.1985\n",
      "Epoch 536/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3615 - acc: 0.2153 - val_loss: 0.7932 - val_acc: 0.2004\n",
      "Epoch 537/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3785 - acc: 0.2148 - val_loss: 0.7437 - val_acc: 0.2004\n",
      "Epoch 538/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4375 - acc: 0.2130 - val_loss: 0.9007 - val_acc: 0.1985\n",
      "Epoch 539/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3423 - acc: 0.2139 - val_loss: 0.8521 - val_acc: 0.2004\n",
      "Epoch 540/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3862 - acc: 0.2148 - val_loss: 0.9743 - val_acc: 0.2004\n",
      "Epoch 541/4000\n",
      "68/68 [==============================] - 5s 69ms/step - loss: 0.3404 - acc: 0.2153 - val_loss: 0.8006 - val_acc: 0.1985\n",
      "Epoch 542/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.3439 - acc: 0.2135 - val_loss: 1.1208 - val_acc: 0.1985\n",
      "Epoch 543/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3705 - acc: 0.2135 - val_loss: 0.7401 - val_acc: 0.1985\n",
      "Epoch 544/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3292 - acc: 0.2144 - val_loss: 0.7908 - val_acc: 0.1985\n",
      "Epoch 545/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3493 - acc: 0.2144 - val_loss: 0.7711 - val_acc: 0.1985\n",
      "Epoch 546/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3216 - acc: 0.2139 - val_loss: 0.7682 - val_acc: 0.2004\n",
      "Epoch 547/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3447 - acc: 0.2158 - val_loss: 0.7487 - val_acc: 0.2004\n",
      "Epoch 548/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3309 - acc: 0.2158 - val_loss: 0.8265 - val_acc: 0.2004\n",
      "Epoch 549/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3282 - acc: 0.2158 - val_loss: 0.8484 - val_acc: 0.2004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 550/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3313 - acc: 0.2153 - val_loss: 0.7517 - val_acc: 0.2004\n",
      "Epoch 551/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3240 - acc: 0.2139 - val_loss: 0.7899 - val_acc: 0.2004\n",
      "Epoch 552/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3576 - acc: 0.2148 - val_loss: 0.9727 - val_acc: 0.1985\n",
      "Epoch 553/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3194 - acc: 0.2158 - val_loss: 0.7633 - val_acc: 0.1985\n",
      "Epoch 554/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3238 - acc: 0.2148 - val_loss: 0.7573 - val_acc: 0.2004\n",
      "Epoch 555/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3322 - acc: 0.2153 - val_loss: 0.7606 - val_acc: 0.2004\n",
      "Epoch 556/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3450 - acc: 0.2158 - val_loss: 0.9342 - val_acc: 0.1985\n",
      "Epoch 557/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3626 - acc: 0.2139 - val_loss: 0.7154 - val_acc: 0.2004\n",
      "Epoch 558/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.7276 - acc: 0.2144 - val_loss: 1.3270 - val_acc: 0.2004\n",
      "Epoch 559/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.7287 - acc: 0.2153 - val_loss: 0.8311 - val_acc: 0.1985\n",
      "Epoch 560/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.9804 - acc: 0.2097 - val_loss: 0.7930 - val_acc: 0.2004\n",
      "Epoch 561/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4815 - acc: 0.2162 - val_loss: 0.9697 - val_acc: 0.2004\n",
      "Epoch 562/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4203 - acc: 0.2148 - val_loss: 0.7198 - val_acc: 0.2004\n",
      "Epoch 563/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3474 - acc: 0.2153 - val_loss: 0.7486 - val_acc: 0.2004\n",
      "Epoch 564/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3251 - acc: 0.2144 - val_loss: 0.7211 - val_acc: 0.2004\n",
      "Epoch 565/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3340 - acc: 0.2144 - val_loss: 1.0753 - val_acc: 0.2004\n",
      "Epoch 566/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3593 - acc: 0.2153 - val_loss: 0.7883 - val_acc: 0.1985\n",
      "Epoch 567/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3317 - acc: 0.2153 - val_loss: 0.8136 - val_acc: 0.2004\n",
      "Epoch 568/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3339 - acc: 0.2148 - val_loss: 0.8497 - val_acc: 0.1985\n",
      "Epoch 569/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3646 - acc: 0.2153 - val_loss: 0.7341 - val_acc: 0.2004\n",
      "Epoch 570/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3391 - acc: 0.2153 - val_loss: 0.7447 - val_acc: 0.2004\n",
      "Epoch 571/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3477 - acc: 0.2144 - val_loss: 0.7568 - val_acc: 0.2004\n",
      "Epoch 572/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3465 - acc: 0.2153 - val_loss: 0.8763 - val_acc: 0.2004\n",
      "Epoch 573/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3378 - acc: 0.2158 - val_loss: 0.7727 - val_acc: 0.1985\n",
      "Epoch 574/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3271 - acc: 0.2158 - val_loss: 0.8405 - val_acc: 0.2004\n",
      "Epoch 575/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3224 - acc: 0.2158 - val_loss: 0.7802 - val_acc: 0.1985\n",
      "Epoch 576/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3453 - acc: 0.2144 - val_loss: 0.7818 - val_acc: 0.2004\n",
      "Epoch 577/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3828 - acc: 0.2144 - val_loss: 0.7850 - val_acc: 0.1985\n",
      "Epoch 578/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3206 - acc: 0.2153 - val_loss: 0.7643 - val_acc: 0.1985\n",
      "Epoch 579/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3689 - acc: 0.2144 - val_loss: 0.8623 - val_acc: 0.1985\n",
      "Epoch 580/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3701 - acc: 0.2144 - val_loss: 0.7828 - val_acc: 0.2004\n",
      "Epoch 581/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3334 - acc: 0.2153 - val_loss: 0.7603 - val_acc: 0.2004\n",
      "Epoch 582/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3377 - acc: 0.2139 - val_loss: 0.7657 - val_acc: 0.2004\n",
      "Epoch 583/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3256 - acc: 0.2153 - val_loss: 0.7491 - val_acc: 0.2004\n",
      "Epoch 584/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3113 - acc: 0.2158 - val_loss: 0.7308 - val_acc: 0.2004\n",
      "Epoch 585/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3148 - acc: 0.2158 - val_loss: 0.7827 - val_acc: 0.1985\n",
      "Epoch 586/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3121 - acc: 0.2148 - val_loss: 0.7487 - val_acc: 0.2004\n",
      "Epoch 587/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3215 - acc: 0.2153 - val_loss: 0.8560 - val_acc: 0.1985\n",
      "Epoch 588/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3412 - acc: 0.2158 - val_loss: 0.7527 - val_acc: 0.2004\n",
      "Epoch 589/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3256 - acc: 0.2153 - val_loss: 0.7849 - val_acc: 0.2004\n",
      "Epoch 590/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.3213 - acc: 0.2144 - val_loss: 0.7852 - val_acc: 0.2004\n",
      "Epoch 591/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3200 - acc: 0.2148 - val_loss: 0.7917 - val_acc: 0.2004\n",
      "Epoch 592/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4658 - acc: 0.2135 - val_loss: 0.9539 - val_acc: 0.2004\n",
      "Epoch 593/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3555 - acc: 0.2144 - val_loss: 0.7576 - val_acc: 0.2004\n",
      "Epoch 594/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3340 - acc: 0.2148 - val_loss: 0.9621 - val_acc: 0.1985\n",
      "Epoch 595/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3219 - acc: 0.2158 - val_loss: 0.7733 - val_acc: 0.2004\n",
      "Epoch 596/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3054 - acc: 0.2158 - val_loss: 0.8199 - val_acc: 0.1985\n",
      "Epoch 597/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3090 - acc: 0.2158 - val_loss: 0.8013 - val_acc: 0.2004\n",
      "Epoch 598/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3115 - acc: 0.2148 - val_loss: 0.7546 - val_acc: 0.2004\n",
      "Epoch 599/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3003 - acc: 0.2153 - val_loss: 0.8521 - val_acc: 0.1985\n",
      "Epoch 600/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.3614 - acc: 0.2144 - val_loss: 0.9254 - val_acc: 0.1985\n",
      "Epoch 601/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3336 - acc: 0.2144 - val_loss: 0.7808 - val_acc: 0.2004\n",
      "Epoch 602/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3136 - acc: 0.2158 - val_loss: 0.7364 - val_acc: 0.2004\n",
      "Epoch 603/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3237 - acc: 0.2148 - val_loss: 0.7407 - val_acc: 0.2004\n",
      "Epoch 604/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3415 - acc: 0.2153 - val_loss: 0.9593 - val_acc: 0.2004\n",
      "Epoch 605/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.4279 - acc: 0.2139 - val_loss: 0.7969 - val_acc: 0.2004\n",
      "Epoch 606/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3733 - acc: 0.2148 - val_loss: 0.7827 - val_acc: 0.2004\n",
      "Epoch 607/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3414 - acc: 0.2158 - val_loss: 0.7298 - val_acc: 0.2004\n",
      "Epoch 608/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3905 - acc: 0.2139 - val_loss: 0.7325 - val_acc: 0.2004\n",
      "Epoch 609/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3462 - acc: 0.2148 - val_loss: 0.7404 - val_acc: 0.2004\n",
      "Epoch 610/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3345 - acc: 0.2158 - val_loss: 0.7663 - val_acc: 0.2004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 611/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3410 - acc: 0.2158 - val_loss: 0.7547 - val_acc: 0.1985\n",
      "Epoch 612/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3092 - acc: 0.2153 - val_loss: 0.7789 - val_acc: 0.2004\n",
      "Epoch 613/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3257 - acc: 0.2148 - val_loss: 0.7028 - val_acc: 0.2004\n",
      "Epoch 614/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3228 - acc: 0.2158 - val_loss: 0.8936 - val_acc: 0.1985\n",
      "Epoch 615/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3650 - acc: 0.2153 - val_loss: 0.8534 - val_acc: 0.2004\n",
      "Epoch 616/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3546 - acc: 0.2153 - val_loss: 0.7420 - val_acc: 0.1985\n",
      "Epoch 617/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3253 - acc: 0.2153 - val_loss: 0.8569 - val_acc: 0.1985\n",
      "Epoch 618/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3129 - acc: 0.2148 - val_loss: 0.8192 - val_acc: 0.1985\n",
      "Epoch 619/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3604 - acc: 0.2139 - val_loss: 0.7768 - val_acc: 0.1985\n",
      "Epoch 620/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3362 - acc: 0.2153 - val_loss: 0.8935 - val_acc: 0.2004\n",
      "Epoch 621/4000\n",
      "68/68 [==============================] - 5s 73ms/step - loss: 0.3613 - acc: 0.2144 - val_loss: 0.7547 - val_acc: 0.2004\n",
      "Epoch 622/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.2973 - acc: 0.2153 - val_loss: 0.7669 - val_acc: 0.2004\n",
      "Epoch 623/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3286 - acc: 0.2144 - val_loss: 0.8183 - val_acc: 0.1985\n",
      "Epoch 624/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3826 - acc: 0.2144 - val_loss: 0.7598 - val_acc: 0.2004\n",
      "Epoch 625/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3079 - acc: 0.2153 - val_loss: 0.8463 - val_acc: 0.1985\n",
      "Epoch 626/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3307 - acc: 0.2153 - val_loss: 0.7764 - val_acc: 0.2004\n",
      "Epoch 627/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3309 - acc: 0.2153 - val_loss: 0.7736 - val_acc: 0.1985\n",
      "Epoch 628/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.3390 - acc: 0.2144 - val_loss: 0.7654 - val_acc: 0.2004\n",
      "Epoch 629/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.3334 - acc: 0.2158 - val_loss: 0.7945 - val_acc: 0.1985\n",
      "Epoch 630/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3117 - acc: 0.2144 - val_loss: 0.7731 - val_acc: 0.2004\n",
      "Epoch 631/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3155 - acc: 0.2144 - val_loss: 0.7818 - val_acc: 0.2004\n",
      "Epoch 632/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3298 - acc: 0.2148 - val_loss: 0.8803 - val_acc: 0.1985\n",
      "Epoch 633/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3454 - acc: 0.2162 - val_loss: 0.7266 - val_acc: 0.2004\n",
      "Epoch 634/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3146 - acc: 0.2153 - val_loss: 0.7937 - val_acc: 0.2004\n",
      "Epoch 635/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3227 - acc: 0.2158 - val_loss: 0.9742 - val_acc: 0.2004\n",
      "Epoch 636/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3730 - acc: 0.2148 - val_loss: 0.8179 - val_acc: 0.1985\n",
      "Epoch 637/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3061 - acc: 0.2153 - val_loss: 0.7445 - val_acc: 0.2004\n",
      "Epoch 638/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3138 - acc: 0.2153 - val_loss: 0.7497 - val_acc: 0.1985\n",
      "Epoch 639/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3324 - acc: 0.2153 - val_loss: 0.7445 - val_acc: 0.1985\n",
      "Epoch 640/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3065 - acc: 0.2148 - val_loss: 0.7413 - val_acc: 0.2004\n",
      "Epoch 641/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3420 - acc: 0.2144 - val_loss: 0.7804 - val_acc: 0.1985\n",
      "Epoch 642/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3469 - acc: 0.2153 - val_loss: 1.3167 - val_acc: 0.1911\n",
      "Epoch 643/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3434 - acc: 0.2158 - val_loss: 0.7515 - val_acc: 0.1985\n",
      "Epoch 644/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3340 - acc: 0.2153 - val_loss: 0.7609 - val_acc: 0.2004\n",
      "Epoch 645/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2975 - acc: 0.2153 - val_loss: 0.7740 - val_acc: 0.1985\n",
      "Epoch 646/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3314 - acc: 0.2158 - val_loss: 0.7310 - val_acc: 0.2004\n",
      "Epoch 647/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3593 - acc: 0.2144 - val_loss: 0.7297 - val_acc: 0.2004\n",
      "Epoch 648/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3067 - acc: 0.2148 - val_loss: 0.8152 - val_acc: 0.2004\n",
      "Epoch 649/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3193 - acc: 0.2153 - val_loss: 0.7532 - val_acc: 0.2004\n",
      "Epoch 650/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3216 - acc: 0.2158 - val_loss: 0.8007 - val_acc: 0.1985\n",
      "Epoch 651/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3429 - acc: 0.2158 - val_loss: 0.7889 - val_acc: 0.2004\n",
      "Epoch 652/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3073 - acc: 0.2144 - val_loss: 0.7774 - val_acc: 0.1985\n",
      "Epoch 653/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3268 - acc: 0.2144 - val_loss: 0.7958 - val_acc: 0.1985\n",
      "Epoch 654/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3438 - acc: 0.2139 - val_loss: 0.7333 - val_acc: 0.2004\n",
      "Epoch 655/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3777 - acc: 0.2135 - val_loss: 0.7510 - val_acc: 0.1985\n",
      "Epoch 656/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3932 - acc: 0.2144 - val_loss: 0.6922 - val_acc: 0.2004\n",
      "Epoch 657/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3436 - acc: 0.2167 - val_loss: 0.8601 - val_acc: 0.2004\n",
      "Epoch 658/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3208 - acc: 0.2153 - val_loss: 0.8459 - val_acc: 0.2004\n",
      "Epoch 659/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3491 - acc: 0.2158 - val_loss: 0.8983 - val_acc: 0.1985\n",
      "Epoch 660/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3230 - acc: 0.2153 - val_loss: 0.8199 - val_acc: 0.1985\n",
      "Epoch 661/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3084 - acc: 0.2162 - val_loss: 0.7666 - val_acc: 0.1985\n",
      "Epoch 662/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3480 - acc: 0.2148 - val_loss: 0.7888 - val_acc: 0.2004\n",
      "Epoch 663/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3313 - acc: 0.2153 - val_loss: 0.7729 - val_acc: 0.1985\n",
      "Epoch 664/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3036 - acc: 0.2148 - val_loss: 0.8223 - val_acc: 0.2004\n",
      "Epoch 665/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3760 - acc: 0.2153 - val_loss: 0.9035 - val_acc: 0.2004\n",
      "Epoch 666/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3350 - acc: 0.2144 - val_loss: 0.7827 - val_acc: 0.2004\n",
      "Epoch 667/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3480 - acc: 0.2158 - val_loss: 0.7346 - val_acc: 0.2004\n",
      "Epoch 668/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3466 - acc: 0.2172 - val_loss: 0.9680 - val_acc: 0.2004\n",
      "Epoch 669/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4225 - acc: 0.2158 - val_loss: 0.8665 - val_acc: 0.2004\n",
      "Epoch 670/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3758 - acc: 0.2144 - val_loss: 1.1557 - val_acc: 0.2004\n",
      "Epoch 671/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4696 - acc: 0.2158 - val_loss: 0.7043 - val_acc: 0.2004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 672/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3705 - acc: 0.2162 - val_loss: 0.6732 - val_acc: 0.2004\n",
      "Epoch 673/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3189 - acc: 0.2148 - val_loss: 0.7796 - val_acc: 0.2004\n",
      "Epoch 674/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3402 - acc: 0.2158 - val_loss: 0.7041 - val_acc: 0.2004\n",
      "Epoch 675/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3258 - acc: 0.2153 - val_loss: 0.7779 - val_acc: 0.2004\n",
      "Epoch 676/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3193 - acc: 0.2153 - val_loss: 0.7088 - val_acc: 0.1985\n",
      "Epoch 677/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3143 - acc: 0.2153 - val_loss: 0.7358 - val_acc: 0.2004\n",
      "Epoch 678/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3069 - acc: 0.2158 - val_loss: 0.7660 - val_acc: 0.1985\n",
      "Epoch 679/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3375 - acc: 0.2153 - val_loss: 1.0107 - val_acc: 0.2004\n",
      "Epoch 680/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3306 - acc: 0.2162 - val_loss: 0.7398 - val_acc: 0.2004\n",
      "Epoch 681/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3215 - acc: 0.2162 - val_loss: 0.7095 - val_acc: 0.2004\n",
      "Epoch 682/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3065 - acc: 0.2148 - val_loss: 0.7514 - val_acc: 0.1985\n",
      "Epoch 683/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3236 - acc: 0.2153 - val_loss: 0.6919 - val_acc: 0.1985\n",
      "Epoch 684/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3203 - acc: 0.2153 - val_loss: 0.7656 - val_acc: 0.1985\n",
      "Epoch 685/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2924 - acc: 0.2158 - val_loss: 0.7345 - val_acc: 0.1985\n",
      "Epoch 686/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2954 - acc: 0.2153 - val_loss: 0.7544 - val_acc: 0.2004\n",
      "Epoch 687/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3249 - acc: 0.2153 - val_loss: 0.7267 - val_acc: 0.1985\n",
      "Epoch 688/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3174 - acc: 0.2148 - val_loss: 0.7288 - val_acc: 0.1985\n",
      "Epoch 689/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3222 - acc: 0.2144 - val_loss: 0.7988 - val_acc: 0.1985\n",
      "Epoch 690/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2953 - acc: 0.2153 - val_loss: 0.7757 - val_acc: 0.2004\n",
      "Epoch 691/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3141 - acc: 0.2153 - val_loss: 0.7371 - val_acc: 0.1985\n",
      "Epoch 692/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3001 - acc: 0.2162 - val_loss: 0.7463 - val_acc: 0.2004\n",
      "Epoch 693/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.3010 - acc: 0.2153 - val_loss: 0.7527 - val_acc: 0.1985\n",
      "Epoch 694/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3600 - acc: 0.2144 - val_loss: 1.0074 - val_acc: 0.2004\n",
      "Epoch 695/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3165 - acc: 0.2162 - val_loss: 0.7061 - val_acc: 0.1985\n",
      "Epoch 696/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3163 - acc: 0.2148 - val_loss: 0.7838 - val_acc: 0.2004\n",
      "Epoch 697/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3032 - acc: 0.2148 - val_loss: 0.8167 - val_acc: 0.2004\n",
      "Epoch 698/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3764 - acc: 0.2158 - val_loss: 0.8270 - val_acc: 0.1985\n",
      "Epoch 699/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3138 - acc: 0.2158 - val_loss: 0.7273 - val_acc: 0.2004\n",
      "Epoch 700/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3062 - acc: 0.2144 - val_loss: 0.7203 - val_acc: 0.2004\n",
      "Epoch 701/4000\n",
      "68/68 [==============================] - 5s 74ms/step - loss: 0.3108 - acc: 0.2148 - val_loss: 0.8147 - val_acc: 0.2004\n",
      "Epoch 702/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3125 - acc: 0.2158 - val_loss: 0.6694 - val_acc: 0.1985\n",
      "Epoch 703/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3205 - acc: 0.2148 - val_loss: 0.8973 - val_acc: 0.2004\n",
      "Epoch 704/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3469 - acc: 0.2148 - val_loss: 0.6927 - val_acc: 0.2004\n",
      "Epoch 705/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2957 - acc: 0.2153 - val_loss: 0.7881 - val_acc: 0.2004\n",
      "Epoch 706/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2996 - acc: 0.2158 - val_loss: 0.7807 - val_acc: 0.2004\n",
      "Epoch 707/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3024 - acc: 0.2153 - val_loss: 0.7556 - val_acc: 0.2004\n",
      "Epoch 708/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2877 - acc: 0.2153 - val_loss: 0.7540 - val_acc: 0.1985\n",
      "Epoch 709/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2923 - acc: 0.2153 - val_loss: 0.7932 - val_acc: 0.1985\n",
      "Epoch 710/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3554 - acc: 0.2148 - val_loss: 0.8159 - val_acc: 0.2004\n",
      "Epoch 711/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3422 - acc: 0.2148 - val_loss: 0.7791 - val_acc: 0.1985\n",
      "Epoch 712/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3202 - acc: 0.2153 - val_loss: 0.7583 - val_acc: 0.1985\n",
      "Epoch 713/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2999 - acc: 0.2158 - val_loss: 0.7159 - val_acc: 0.2004\n",
      "Epoch 714/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2931 - acc: 0.2158 - val_loss: 0.7417 - val_acc: 0.1985\n",
      "Epoch 715/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3226 - acc: 0.2153 - val_loss: 0.8575 - val_acc: 0.1985\n",
      "Epoch 716/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3114 - acc: 0.2158 - val_loss: 0.7601 - val_acc: 0.1985\n",
      "Epoch 717/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2979 - acc: 0.2158 - val_loss: 0.7017 - val_acc: 0.2004\n",
      "Epoch 718/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3246 - acc: 0.2167 - val_loss: 0.7195 - val_acc: 0.2004\n",
      "Epoch 719/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.3318 - acc: 0.2158 - val_loss: 0.8358 - val_acc: 0.2004\n",
      "Epoch 720/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.3551 - acc: 0.2153 - val_loss: 0.9217 - val_acc: 0.2004\n",
      "Epoch 721/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.3224 - acc: 0.2153 - val_loss: 0.8005 - val_acc: 0.1985\n",
      "Epoch 722/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3071 - acc: 0.2148 - val_loss: 0.7350 - val_acc: 0.2004\n",
      "Epoch 723/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3050 - acc: 0.2153 - val_loss: 1.1556 - val_acc: 0.2004\n",
      "Epoch 724/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3361 - acc: 0.2153 - val_loss: 0.7248 - val_acc: 0.2004\n",
      "Epoch 725/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3080 - acc: 0.2162 - val_loss: 1.1836 - val_acc: 0.1948\n",
      "Epoch 726/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3879 - acc: 0.2148 - val_loss: 0.7744 - val_acc: 0.1985\n",
      "Epoch 727/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3108 - acc: 0.2153 - val_loss: 0.7061 - val_acc: 0.2004\n",
      "Epoch 728/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.3243 - acc: 0.2158 - val_loss: 0.7886 - val_acc: 0.2004\n",
      "Epoch 729/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2983 - acc: 0.2162 - val_loss: 0.6787 - val_acc: 0.2004\n",
      "Epoch 730/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3192 - acc: 0.2153 - val_loss: 0.7758 - val_acc: 0.1985\n",
      "Epoch 731/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3266 - acc: 0.2158 - val_loss: 0.6902 - val_acc: 0.2004\n",
      "Epoch 732/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3035 - acc: 0.2153 - val_loss: 0.9433 - val_acc: 0.1985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 733/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3090 - acc: 0.2158 - val_loss: 0.7644 - val_acc: 0.2004\n",
      "Epoch 734/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.3384 - acc: 0.2148 - val_loss: 1.0691 - val_acc: 0.1985\n",
      "Epoch 735/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.3348 - acc: 0.2158 - val_loss: 0.7171 - val_acc: 0.2004\n",
      "Epoch 736/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3426 - acc: 0.2153 - val_loss: 0.8987 - val_acc: 0.2004\n",
      "Epoch 737/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3562 - acc: 0.2153 - val_loss: 0.9226 - val_acc: 0.2004\n",
      "Epoch 738/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3054 - acc: 0.2148 - val_loss: 0.8766 - val_acc: 0.1985\n",
      "Epoch 739/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3021 - acc: 0.2153 - val_loss: 0.7801 - val_acc: 0.1985\n",
      "Epoch 740/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3033 - acc: 0.2158 - val_loss: 0.7210 - val_acc: 0.2004\n",
      "Epoch 741/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.3164 - acc: 0.2148 - val_loss: 0.7200 - val_acc: 0.1985\n",
      "Epoch 742/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3089 - acc: 0.2162 - val_loss: 0.7498 - val_acc: 0.2004\n",
      "Epoch 743/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3071 - acc: 0.2158 - val_loss: 0.7247 - val_acc: 0.1985\n",
      "Epoch 744/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2947 - acc: 0.2158 - val_loss: 0.7471 - val_acc: 0.2004\n",
      "Epoch 745/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2931 - acc: 0.2153 - val_loss: 0.8545 - val_acc: 0.2004\n",
      "Epoch 746/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3334 - acc: 0.2162 - val_loss: 0.7663 - val_acc: 0.2004\n",
      "Epoch 747/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4009 - acc: 0.2153 - val_loss: 0.7535 - val_acc: 0.1985\n",
      "Epoch 748/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4351 - acc: 0.2158 - val_loss: 0.6935 - val_acc: 0.2004\n",
      "Epoch 749/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.3706 - acc: 0.2148 - val_loss: 0.7531 - val_acc: 0.1985\n",
      "Epoch 750/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3670 - acc: 0.2158 - val_loss: 0.9049 - val_acc: 0.2004\n",
      "Epoch 751/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3551 - acc: 0.2144 - val_loss: 0.6875 - val_acc: 0.1985\n",
      "Epoch 752/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3465 - acc: 0.2144 - val_loss: 0.7268 - val_acc: 0.1985\n",
      "Epoch 753/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3682 - acc: 0.2153 - val_loss: 0.9034 - val_acc: 0.1985\n",
      "Epoch 754/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4206 - acc: 0.2144 - val_loss: 0.8066 - val_acc: 0.2004\n",
      "Epoch 755/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3139 - acc: 0.2162 - val_loss: 0.7098 - val_acc: 0.2004\n",
      "Epoch 756/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2792 - acc: 0.2153 - val_loss: 0.7261 - val_acc: 0.2004\n",
      "Epoch 757/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2869 - acc: 0.2153 - val_loss: 0.6917 - val_acc: 0.2004\n",
      "Epoch 758/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2971 - acc: 0.2158 - val_loss: 0.7194 - val_acc: 0.1985\n",
      "Epoch 759/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3397 - acc: 0.2153 - val_loss: 0.7554 - val_acc: 0.2004\n",
      "Epoch 760/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3146 - acc: 0.2153 - val_loss: 0.8408 - val_acc: 0.1985\n",
      "Epoch 761/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3222 - acc: 0.2153 - val_loss: 0.7190 - val_acc: 0.1985\n",
      "Epoch 762/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2875 - acc: 0.2153 - val_loss: 0.7313 - val_acc: 0.2004\n",
      "Epoch 763/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2914 - acc: 0.2162 - val_loss: 0.7320 - val_acc: 0.2004\n",
      "Epoch 764/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2844 - acc: 0.2158 - val_loss: 0.7856 - val_acc: 0.2004\n",
      "Epoch 765/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2958 - acc: 0.2162 - val_loss: 0.7257 - val_acc: 0.2004\n",
      "Epoch 766/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3003 - acc: 0.2148 - val_loss: 0.7180 - val_acc: 0.1985\n",
      "Epoch 767/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2958 - acc: 0.2167 - val_loss: 0.7635 - val_acc: 0.1985\n",
      "Epoch 768/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3136 - acc: 0.2153 - val_loss: 0.7542 - val_acc: 0.2004\n",
      "Epoch 769/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3537 - acc: 0.2148 - val_loss: 0.8276 - val_acc: 0.2004\n",
      "Epoch 770/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3009 - acc: 0.2153 - val_loss: 0.7140 - val_acc: 0.2004\n",
      "Epoch 771/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2989 - acc: 0.2144 - val_loss: 0.7256 - val_acc: 0.2004\n",
      "Epoch 772/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3295 - acc: 0.2158 - val_loss: 0.8595 - val_acc: 0.1985\n",
      "Epoch 773/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3284 - acc: 0.2158 - val_loss: 0.7428 - val_acc: 0.1985\n",
      "Epoch 774/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3159 - acc: 0.2148 - val_loss: 0.7007 - val_acc: 0.2004\n",
      "Epoch 775/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3028 - acc: 0.2158 - val_loss: 0.7911 - val_acc: 0.1985\n",
      "Epoch 776/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3406 - acc: 0.2153 - val_loss: 0.7423 - val_acc: 0.1985\n",
      "Epoch 777/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2807 - acc: 0.2148 - val_loss: 0.7515 - val_acc: 0.2004\n",
      "Epoch 778/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2984 - acc: 0.2158 - val_loss: 0.8176 - val_acc: 0.1985\n",
      "Epoch 779/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3299 - acc: 0.2153 - val_loss: 0.8581 - val_acc: 0.2004\n",
      "Epoch 780/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3461 - acc: 0.2167 - val_loss: 0.6915 - val_acc: 0.2004\n",
      "Epoch 781/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.3227 - acc: 0.2148 - val_loss: 0.7870 - val_acc: 0.2004\n",
      "Epoch 782/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 0.3073 - acc: 0.2162 - val_loss: 0.7263 - val_acc: 0.2004\n",
      "Epoch 783/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2837 - acc: 0.2148 - val_loss: 0.7232 - val_acc: 0.1985\n",
      "Epoch 784/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2821 - acc: 0.2167 - val_loss: 0.7375 - val_acc: 0.1985\n",
      "Epoch 785/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2995 - acc: 0.2158 - val_loss: 0.7176 - val_acc: 0.1985\n",
      "Epoch 786/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3032 - acc: 0.2153 - val_loss: 0.7435 - val_acc: 0.1985\n",
      "Epoch 787/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3142 - acc: 0.2158 - val_loss: 0.9583 - val_acc: 0.2004\n",
      "Epoch 788/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3599 - acc: 0.2148 - val_loss: 0.6806 - val_acc: 0.1985\n",
      "Epoch 789/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3418 - acc: 0.2144 - val_loss: 1.1429 - val_acc: 0.2004\n",
      "Epoch 790/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4063 - acc: 0.2162 - val_loss: 0.6976 - val_acc: 0.1985\n",
      "Epoch 791/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3541 - acc: 0.2158 - val_loss: 0.7494 - val_acc: 0.2004\n",
      "Epoch 792/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2912 - acc: 0.2158 - val_loss: 0.7192 - val_acc: 0.2004\n",
      "Epoch 793/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2951 - acc: 0.2158 - val_loss: 0.7243 - val_acc: 0.2004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 794/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2965 - acc: 0.2153 - val_loss: 0.7198 - val_acc: 0.2004\n",
      "Epoch 795/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2968 - acc: 0.2158 - val_loss: 0.6961 - val_acc: 0.1985\n",
      "Epoch 796/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2869 - acc: 0.2158 - val_loss: 0.7834 - val_acc: 0.1985\n",
      "Epoch 797/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3126 - acc: 0.2153 - val_loss: 0.7205 - val_acc: 0.2004\n",
      "Epoch 798/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3011 - acc: 0.2144 - val_loss: 0.7047 - val_acc: 0.2004\n",
      "Epoch 799/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2932 - acc: 0.2153 - val_loss: 0.7418 - val_acc: 0.2004\n",
      "Epoch 800/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2972 - acc: 0.2158 - val_loss: 0.7447 - val_acc: 0.1985\n",
      "Epoch 801/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3296 - acc: 0.2148 - val_loss: 0.7542 - val_acc: 0.2004\n",
      "Epoch 802/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3083 - acc: 0.2153 - val_loss: 0.8205 - val_acc: 0.2004\n",
      "Epoch 803/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3012 - acc: 0.2153 - val_loss: 0.6978 - val_acc: 0.2004\n",
      "Epoch 804/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2874 - acc: 0.2162 - val_loss: 0.8644 - val_acc: 0.2004\n",
      "Epoch 805/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3188 - acc: 0.2148 - val_loss: 0.7114 - val_acc: 0.2004\n",
      "Epoch 806/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3030 - acc: 0.2153 - val_loss: 0.7177 - val_acc: 0.2004\n",
      "Epoch 807/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3308 - acc: 0.2153 - val_loss: 0.7278 - val_acc: 0.1985\n",
      "Epoch 808/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3024 - acc: 0.2158 - val_loss: 0.7444 - val_acc: 0.2004\n",
      "Epoch 809/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2859 - acc: 0.2153 - val_loss: 0.7031 - val_acc: 0.1985\n",
      "Epoch 810/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2922 - acc: 0.2167 - val_loss: 0.8062 - val_acc: 0.2004\n",
      "Epoch 811/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3140 - acc: 0.2153 - val_loss: 0.8175 - val_acc: 0.1985\n",
      "Epoch 812/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3212 - acc: 0.2148 - val_loss: 0.7150 - val_acc: 0.2004\n",
      "Epoch 813/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3402 - acc: 0.2158 - val_loss: 0.7494 - val_acc: 0.2004\n",
      "Epoch 814/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.5025 - acc: 0.2139 - val_loss: 0.9602 - val_acc: 0.1985\n",
      "Epoch 815/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4127 - acc: 0.2158 - val_loss: 0.8708 - val_acc: 0.2004\n",
      "Epoch 816/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3523 - acc: 0.2153 - val_loss: 0.7628 - val_acc: 0.1985\n",
      "Epoch 817/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3052 - acc: 0.2162 - val_loss: 0.7549 - val_acc: 0.2004\n",
      "Epoch 818/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3055 - acc: 0.2162 - val_loss: 0.6864 - val_acc: 0.2004\n",
      "Epoch 819/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2888 - acc: 0.2148 - val_loss: 0.7159 - val_acc: 0.2004\n",
      "Epoch 820/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3059 - acc: 0.2158 - val_loss: 0.7303 - val_acc: 0.1985\n",
      "Epoch 821/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2940 - acc: 0.2167 - val_loss: 0.6933 - val_acc: 0.1985\n",
      "Epoch 822/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3278 - acc: 0.2148 - val_loss: 0.8506 - val_acc: 0.1985\n",
      "Epoch 823/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2856 - acc: 0.2153 - val_loss: 0.6831 - val_acc: 0.2004\n",
      "Epoch 824/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2778 - acc: 0.2162 - val_loss: 0.7311 - val_acc: 0.2004\n",
      "Epoch 825/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3128 - acc: 0.2144 - val_loss: 0.7259 - val_acc: 0.2004\n",
      "Epoch 826/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3190 - acc: 0.2148 - val_loss: 0.7133 - val_acc: 0.2004\n",
      "Epoch 827/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2990 - acc: 0.2158 - val_loss: 0.8948 - val_acc: 0.1985\n",
      "Epoch 828/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3079 - acc: 0.2153 - val_loss: 0.7206 - val_acc: 0.1985\n",
      "Epoch 829/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2939 - acc: 0.2153 - val_loss: 0.7359 - val_acc: 0.1985\n",
      "Epoch 830/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2920 - acc: 0.2162 - val_loss: 0.7434 - val_acc: 0.1985\n",
      "Epoch 831/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3090 - acc: 0.2158 - val_loss: 0.7323 - val_acc: 0.1985\n",
      "Epoch 832/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3049 - acc: 0.2153 - val_loss: 0.7323 - val_acc: 0.1985\n",
      "Epoch 833/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2907 - acc: 0.2153 - val_loss: 0.7906 - val_acc: 0.1985\n",
      "Epoch 834/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3661 - acc: 0.2158 - val_loss: 0.7299 - val_acc: 0.2004\n",
      "Epoch 835/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2840 - acc: 0.2153 - val_loss: 0.7174 - val_acc: 0.2004\n",
      "Epoch 836/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2734 - acc: 0.2158 - val_loss: 0.8026 - val_acc: 0.2004\n",
      "Epoch 837/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2970 - acc: 0.2148 - val_loss: 0.7067 - val_acc: 0.2004\n",
      "Epoch 838/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2748 - acc: 0.2162 - val_loss: 0.7087 - val_acc: 0.2004\n",
      "Epoch 839/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2859 - acc: 0.2162 - val_loss: 0.7241 - val_acc: 0.1985\n",
      "Epoch 840/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2918 - acc: 0.2144 - val_loss: 0.7508 - val_acc: 0.2004\n",
      "Epoch 841/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3662 - acc: 0.2148 - val_loss: 0.8905 - val_acc: 0.1985\n",
      "Epoch 842/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2999 - acc: 0.2167 - val_loss: 0.7073 - val_acc: 0.2004\n",
      "Epoch 843/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2937 - acc: 0.2153 - val_loss: 0.7738 - val_acc: 0.1985\n",
      "Epoch 844/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2860 - acc: 0.2167 - val_loss: 0.7379 - val_acc: 0.2004\n",
      "Epoch 845/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2927 - acc: 0.2158 - val_loss: 0.8099 - val_acc: 0.2004\n",
      "Epoch 846/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3003 - acc: 0.2148 - val_loss: 0.7609 - val_acc: 0.2004\n",
      "Epoch 847/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3291 - acc: 0.2167 - val_loss: 0.7745 - val_acc: 0.1985\n",
      "Epoch 848/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2808 - acc: 0.2162 - val_loss: 0.7199 - val_acc: 0.1985\n",
      "Epoch 849/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2841 - acc: 0.2158 - val_loss: 0.7026 - val_acc: 0.2004\n",
      "Epoch 850/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2819 - acc: 0.2158 - val_loss: 0.7393 - val_acc: 0.1985\n",
      "Epoch 851/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2916 - acc: 0.2158 - val_loss: 0.6891 - val_acc: 0.2004\n",
      "Epoch 852/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2970 - acc: 0.2148 - val_loss: 0.7294 - val_acc: 0.2004\n",
      "Epoch 853/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2932 - acc: 0.2153 - val_loss: 0.7353 - val_acc: 0.2004\n",
      "Epoch 854/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2854 - acc: 0.2153 - val_loss: 0.7095 - val_acc: 0.2004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 855/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2871 - acc: 0.2162 - val_loss: 0.6674 - val_acc: 0.1985\n",
      "Epoch 856/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2902 - acc: 0.2162 - val_loss: 0.7628 - val_acc: 0.2004\n",
      "Epoch 857/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3322 - acc: 0.2162 - val_loss: 0.8319 - val_acc: 0.2004\n",
      "Epoch 858/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3039 - acc: 0.2153 - val_loss: 0.7401 - val_acc: 0.2004\n",
      "Epoch 859/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3674 - acc: 0.2167 - val_loss: 0.8988 - val_acc: 0.2004\n",
      "Epoch 860/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3917 - acc: 0.2162 - val_loss: 0.8970 - val_acc: 0.1985\n",
      "Epoch 861/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3519 - acc: 0.2148 - val_loss: 0.9967 - val_acc: 0.1985\n",
      "Epoch 862/4000\n",
      "68/68 [==============================] - 5s 72ms/step - loss: 0.4674 - acc: 0.2153 - val_loss: 1.0312 - val_acc: 0.2004\n",
      "Epoch 863/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.5180 - acc: 0.2153 - val_loss: 0.7443 - val_acc: 0.2004\n",
      "Epoch 864/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3853 - acc: 0.2153 - val_loss: 0.8002 - val_acc: 0.1985\n",
      "Epoch 865/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3180 - acc: 0.2153 - val_loss: 0.6472 - val_acc: 0.2004\n",
      "Epoch 866/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3233 - acc: 0.2158 - val_loss: 0.7549 - val_acc: 0.2004\n",
      "Epoch 867/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3426 - acc: 0.2158 - val_loss: 0.6841 - val_acc: 0.1985\n",
      "Epoch 868/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3111 - acc: 0.2162 - val_loss: 0.7039 - val_acc: 0.2004\n",
      "Epoch 869/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3165 - acc: 0.2148 - val_loss: 0.6953 - val_acc: 0.1985\n",
      "Epoch 870/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3158 - acc: 0.2153 - val_loss: 0.7251 - val_acc: 0.1985\n",
      "Epoch 871/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2857 - acc: 0.2167 - val_loss: 0.6874 - val_acc: 0.2004\n",
      "Epoch 872/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2811 - acc: 0.2162 - val_loss: 0.7071 - val_acc: 0.1985\n",
      "Epoch 873/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2971 - acc: 0.2158 - val_loss: 0.6989 - val_acc: 0.2004\n",
      "Epoch 874/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3407 - acc: 0.2144 - val_loss: 0.7148 - val_acc: 0.2004\n",
      "Epoch 875/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2794 - acc: 0.2162 - val_loss: 0.7105 - val_acc: 0.1985\n",
      "Epoch 876/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2842 - acc: 0.2153 - val_loss: 0.7126 - val_acc: 0.2004\n",
      "Epoch 877/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3005 - acc: 0.2162 - val_loss: 0.7090 - val_acc: 0.2004\n",
      "Epoch 878/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2910 - acc: 0.2148 - val_loss: 0.7592 - val_acc: 0.2004\n",
      "Epoch 879/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2824 - acc: 0.2158 - val_loss: 0.7247 - val_acc: 0.1985\n",
      "Epoch 880/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2952 - acc: 0.2158 - val_loss: 0.7416 - val_acc: 0.2004\n",
      "Epoch 881/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2769 - acc: 0.2153 - val_loss: 0.7024 - val_acc: 0.1985\n",
      "Epoch 882/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2938 - acc: 0.2158 - val_loss: 0.8189 - val_acc: 0.1985\n",
      "Epoch 883/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2888 - acc: 0.2148 - val_loss: 0.7051 - val_acc: 0.2004\n",
      "Epoch 884/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2812 - acc: 0.2158 - val_loss: 0.6761 - val_acc: 0.2004\n",
      "Epoch 885/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2670 - acc: 0.2162 - val_loss: 0.6858 - val_acc: 0.1985\n",
      "Epoch 886/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3130 - acc: 0.2162 - val_loss: 0.7238 - val_acc: 0.2004\n",
      "Epoch 887/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3018 - acc: 0.2153 - val_loss: 0.9438 - val_acc: 0.2004\n",
      "Epoch 888/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3195 - acc: 0.2148 - val_loss: 0.6983 - val_acc: 0.1985\n",
      "Epoch 889/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2812 - acc: 0.2148 - val_loss: 0.7387 - val_acc: 0.2004\n",
      "Epoch 890/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2632 - acc: 0.2158 - val_loss: 0.8071 - val_acc: 0.2004\n",
      "Epoch 891/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2792 - acc: 0.2162 - val_loss: 0.6842 - val_acc: 0.1985\n",
      "Epoch 892/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3075 - acc: 0.2153 - val_loss: 0.7227 - val_acc: 0.1985\n",
      "Epoch 893/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3057 - acc: 0.2167 - val_loss: 0.7594 - val_acc: 0.1985\n",
      "Epoch 894/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2841 - acc: 0.2158 - val_loss: 0.6939 - val_acc: 0.2004\n",
      "Epoch 895/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2833 - acc: 0.2158 - val_loss: 0.6982 - val_acc: 0.2004\n",
      "Epoch 896/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2819 - acc: 0.2158 - val_loss: 0.7490 - val_acc: 0.2004\n",
      "Epoch 897/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2705 - acc: 0.2162 - val_loss: 0.6905 - val_acc: 0.2004\n",
      "Epoch 898/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2721 - acc: 0.2162 - val_loss: 0.7293 - val_acc: 0.2004\n",
      "Epoch 899/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3029 - acc: 0.2167 - val_loss: 0.6889 - val_acc: 0.2004\n",
      "Epoch 900/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2973 - acc: 0.2162 - val_loss: 0.7626 - val_acc: 0.1985\n",
      "Epoch 901/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2835 - acc: 0.2153 - val_loss: 0.7869 - val_acc: 0.2004\n",
      "Epoch 902/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3338 - acc: 0.2153 - val_loss: 0.9311 - val_acc: 0.1985\n",
      "Epoch 903/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3513 - acc: 0.2158 - val_loss: 0.7742 - val_acc: 0.2004\n",
      "Epoch 904/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3129 - acc: 0.2158 - val_loss: 0.9195 - val_acc: 0.1985\n",
      "Epoch 905/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3425 - acc: 0.2167 - val_loss: 0.7353 - val_acc: 0.1985\n",
      "Epoch 906/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3004 - acc: 0.2148 - val_loss: 0.8355 - val_acc: 0.2004\n",
      "Epoch 907/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3277 - acc: 0.2144 - val_loss: 0.6890 - val_acc: 0.1985\n",
      "Epoch 908/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2762 - acc: 0.2148 - val_loss: 0.7263 - val_acc: 0.1985\n",
      "Epoch 909/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2955 - acc: 0.2158 - val_loss: 0.7191 - val_acc: 0.1985\n",
      "Epoch 910/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2874 - acc: 0.2153 - val_loss: 0.8085 - val_acc: 0.1985\n",
      "Epoch 911/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3075 - acc: 0.2139 - val_loss: 0.7539 - val_acc: 0.2004\n",
      "Epoch 912/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2858 - acc: 0.2162 - val_loss: 0.8013 - val_acc: 0.1985\n",
      "Epoch 913/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2892 - acc: 0.2153 - val_loss: 0.7208 - val_acc: 0.2004\n",
      "Epoch 914/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2793 - acc: 0.2158 - val_loss: 0.7032 - val_acc: 0.2004\n",
      "Epoch 915/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3024 - acc: 0.2153 - val_loss: 0.6975 - val_acc: 0.1985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 916/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2926 - acc: 0.2162 - val_loss: 0.7996 - val_acc: 0.1985\n",
      "Epoch 917/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3230 - acc: 0.2158 - val_loss: 0.7123 - val_acc: 0.1985\n",
      "Epoch 918/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3300 - acc: 0.2153 - val_loss: 0.7136 - val_acc: 0.2004\n",
      "Epoch 919/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2827 - acc: 0.2172 - val_loss: 0.8212 - val_acc: 0.1985\n",
      "Epoch 920/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3247 - acc: 0.2153 - val_loss: 0.7307 - val_acc: 0.1985\n",
      "Epoch 921/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2721 - acc: 0.2162 - val_loss: 0.7241 - val_acc: 0.1985\n",
      "Epoch 922/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2758 - acc: 0.2162 - val_loss: 0.7126 - val_acc: 0.2004\n",
      "Epoch 923/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2795 - acc: 0.2158 - val_loss: 0.7004 - val_acc: 0.2004\n",
      "Epoch 924/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3043 - acc: 0.2158 - val_loss: 0.7714 - val_acc: 0.1985\n",
      "Epoch 925/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2861 - acc: 0.2162 - val_loss: 0.7665 - val_acc: 0.2004\n",
      "Epoch 926/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3458 - acc: 0.2172 - val_loss: 0.7638 - val_acc: 0.1985\n",
      "Epoch 927/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2899 - acc: 0.2172 - val_loss: 0.6093 - val_acc: 0.2004\n",
      "Epoch 928/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3651 - acc: 0.2153 - val_loss: 0.8934 - val_acc: 0.1985\n",
      "Epoch 929/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.8296 - acc: 0.2162 - val_loss: 1.0426 - val_acc: 0.2004\n",
      "Epoch 930/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.9099 - acc: 0.2148 - val_loss: 0.6316 - val_acc: 0.2004\n",
      "Epoch 931/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.8541 - acc: 0.2167 - val_loss: 0.6839 - val_acc: 0.2004\n",
      "Epoch 932/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4934 - acc: 0.2167 - val_loss: 0.8480 - val_acc: 0.2004\n",
      "Epoch 933/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3355 - acc: 0.2167 - val_loss: 0.6641 - val_acc: 0.2004\n",
      "Epoch 934/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2835 - acc: 0.2167 - val_loss: 0.6674 - val_acc: 0.2004\n",
      "Epoch 935/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2723 - acc: 0.2167 - val_loss: 0.6625 - val_acc: 0.2004\n",
      "Epoch 936/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2625 - acc: 0.2167 - val_loss: 0.6737 - val_acc: 0.2004\n",
      "Epoch 937/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2945 - acc: 0.2167 - val_loss: 0.7391 - val_acc: 0.2004\n",
      "Epoch 938/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2662 - acc: 0.2162 - val_loss: 0.6705 - val_acc: 0.2004\n",
      "Epoch 939/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2799 - acc: 0.2158 - val_loss: 0.7549 - val_acc: 0.1985\n",
      "Epoch 940/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2643 - acc: 0.2158 - val_loss: 0.6706 - val_acc: 0.2004\n",
      "Epoch 941/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2634 - acc: 0.2162 - val_loss: 0.6836 - val_acc: 0.1985\n",
      "Epoch 942/4000\n",
      "68/68 [==============================] - 5s 72ms/step - loss: 0.2677 - acc: 0.2162 - val_loss: 0.7036 - val_acc: 0.2004\n",
      "Epoch 943/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3101 - acc: 0.2167 - val_loss: 0.6978 - val_acc: 0.2004\n",
      "Epoch 944/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2911 - acc: 0.2158 - val_loss: 0.6743 - val_acc: 0.2004\n",
      "Epoch 945/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3093 - acc: 0.2162 - val_loss: 0.8027 - val_acc: 0.1985\n",
      "Epoch 946/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2693 - acc: 0.2167 - val_loss: 0.7190 - val_acc: 0.1985\n",
      "Epoch 947/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2757 - acc: 0.2158 - val_loss: 0.7412 - val_acc: 0.2004\n",
      "Epoch 948/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2722 - acc: 0.2162 - val_loss: 0.6889 - val_acc: 0.2004\n",
      "Epoch 949/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.2689 - acc: 0.2153 - val_loss: 0.6838 - val_acc: 0.1985\n",
      "Epoch 950/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2749 - acc: 0.2167 - val_loss: 0.6975 - val_acc: 0.2004\n",
      "Epoch 951/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2757 - acc: 0.2158 - val_loss: 0.6937 - val_acc: 0.1985\n",
      "Epoch 952/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2694 - acc: 0.2167 - val_loss: 0.7247 - val_acc: 0.2004\n",
      "Epoch 953/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2816 - acc: 0.2162 - val_loss: 0.7026 - val_acc: 0.2004\n",
      "Epoch 954/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3189 - acc: 0.2144 - val_loss: 0.6911 - val_acc: 0.1985\n",
      "Epoch 955/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2963 - acc: 0.2162 - val_loss: 0.7837 - val_acc: 0.1985\n",
      "Epoch 956/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3110 - acc: 0.2153 - val_loss: 0.7198 - val_acc: 0.2004\n",
      "Epoch 957/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2831 - acc: 0.2162 - val_loss: 0.6915 - val_acc: 0.2004\n",
      "Epoch 958/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2984 - acc: 0.2167 - val_loss: 0.7137 - val_acc: 0.2004\n",
      "Epoch 959/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2928 - acc: 0.2158 - val_loss: 0.7113 - val_acc: 0.2004\n",
      "Epoch 960/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3005 - acc: 0.2153 - val_loss: 0.8048 - val_acc: 0.1985\n",
      "Epoch 961/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2981 - acc: 0.2162 - val_loss: 0.6627 - val_acc: 0.1985\n",
      "Epoch 962/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3009 - acc: 0.2153 - val_loss: 0.6903 - val_acc: 0.1985\n",
      "Epoch 963/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2868 - acc: 0.2148 - val_loss: 0.6713 - val_acc: 0.2004\n",
      "Epoch 964/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2941 - acc: 0.2144 - val_loss: 0.6953 - val_acc: 0.1985\n",
      "Epoch 965/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2853 - acc: 0.2162 - val_loss: 0.7031 - val_acc: 0.1985\n",
      "Epoch 966/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3317 - acc: 0.2153 - val_loss: 0.9125 - val_acc: 0.1985\n",
      "Epoch 967/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3240 - acc: 0.2148 - val_loss: 0.8368 - val_acc: 0.2004\n",
      "Epoch 968/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2922 - acc: 0.2162 - val_loss: 0.6767 - val_acc: 0.2004\n",
      "Epoch 969/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2893 - acc: 0.2162 - val_loss: 0.7224 - val_acc: 0.2004\n",
      "Epoch 970/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2763 - acc: 0.2162 - val_loss: 0.7027 - val_acc: 0.1985\n",
      "Epoch 971/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2761 - acc: 0.2162 - val_loss: 0.8925 - val_acc: 0.2004\n",
      "Epoch 972/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2776 - acc: 0.2167 - val_loss: 0.7680 - val_acc: 0.1985\n",
      "Epoch 973/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2846 - acc: 0.2153 - val_loss: 0.7372 - val_acc: 0.1985\n",
      "Epoch 974/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2856 - acc: 0.2158 - val_loss: 0.6957 - val_acc: 0.1985\n",
      "Epoch 975/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2820 - acc: 0.2167 - val_loss: 0.7138 - val_acc: 0.1985\n",
      "Epoch 976/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2928 - acc: 0.2153 - val_loss: 0.6958 - val_acc: 0.1985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 977/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3455 - acc: 0.2153 - val_loss: 0.7059 - val_acc: 0.2004\n",
      "Epoch 978/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.2837 - acc: 0.2158 - val_loss: 0.7397 - val_acc: 0.1985\n",
      "Epoch 979/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3269 - acc: 0.2153 - val_loss: 0.9396 - val_acc: 0.1985\n",
      "Epoch 980/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3137 - acc: 0.2153 - val_loss: 0.7299 - val_acc: 0.1985\n",
      "Epoch 981/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3387 - acc: 0.2148 - val_loss: 0.7002 - val_acc: 0.2004\n",
      "Epoch 982/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2752 - acc: 0.2153 - val_loss: 0.6693 - val_acc: 0.2004\n",
      "Epoch 983/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2815 - acc: 0.2158 - val_loss: 0.7077 - val_acc: 0.2004\n",
      "Epoch 984/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2716 - acc: 0.2167 - val_loss: 0.8476 - val_acc: 0.2004\n",
      "Epoch 985/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2747 - acc: 0.2158 - val_loss: 0.6792 - val_acc: 0.2004\n",
      "Epoch 986/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2649 - acc: 0.2158 - val_loss: 0.6677 - val_acc: 0.2004\n",
      "Epoch 987/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2696 - acc: 0.2158 - val_loss: 0.7039 - val_acc: 0.2004\n",
      "Epoch 988/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2835 - acc: 0.2153 - val_loss: 0.8167 - val_acc: 0.2004\n",
      "Epoch 989/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3153 - acc: 0.2148 - val_loss: 0.7785 - val_acc: 0.1985\n",
      "Epoch 990/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3333 - acc: 0.2153 - val_loss: 0.7314 - val_acc: 0.2004\n",
      "Epoch 991/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2729 - acc: 0.2162 - val_loss: 0.7142 - val_acc: 0.2004\n",
      "Epoch 992/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3105 - acc: 0.2148 - val_loss: 0.7332 - val_acc: 0.1985\n",
      "Epoch 993/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2762 - acc: 0.2162 - val_loss: 0.6839 - val_acc: 0.1985\n",
      "Epoch 994/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3148 - acc: 0.2153 - val_loss: 0.6786 - val_acc: 0.1985\n",
      "Epoch 995/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2835 - acc: 0.2153 - val_loss: 0.8148 - val_acc: 0.2004\n",
      "Epoch 996/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2995 - acc: 0.2162 - val_loss: 0.7683 - val_acc: 0.1985\n",
      "Epoch 997/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3168 - acc: 0.2167 - val_loss: 0.7133 - val_acc: 0.2004\n",
      "Epoch 998/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3116 - acc: 0.2162 - val_loss: 0.6605 - val_acc: 0.2004\n",
      "Epoch 999/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2673 - acc: 0.2153 - val_loss: 0.7242 - val_acc: 0.2004\n",
      "Epoch 1000/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2656 - acc: 0.2162 - val_loss: 0.6533 - val_acc: 0.2004\n",
      "Epoch 1001/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2693 - acc: 0.2158 - val_loss: 0.7016 - val_acc: 0.1985\n",
      "Epoch 1002/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2740 - acc: 0.2158 - val_loss: 0.8071 - val_acc: 0.1985\n",
      "Epoch 1003/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2814 - acc: 0.2153 - val_loss: 0.7166 - val_acc: 0.1985\n",
      "Epoch 1004/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2937 - acc: 0.2148 - val_loss: 0.7587 - val_acc: 0.1985\n",
      "Epoch 1005/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2902 - acc: 0.2158 - val_loss: 0.8528 - val_acc: 0.1985\n",
      "Epoch 1006/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3152 - acc: 0.2158 - val_loss: 0.6990 - val_acc: 0.1985\n",
      "Epoch 1007/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3187 - acc: 0.2153 - val_loss: 0.7890 - val_acc: 0.2004\n",
      "Epoch 1008/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3143 - acc: 0.2162 - val_loss: 0.6911 - val_acc: 0.2004\n",
      "Epoch 1009/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3496 - acc: 0.2162 - val_loss: 0.8673 - val_acc: 0.1985\n",
      "Epoch 1010/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3390 - acc: 0.2153 - val_loss: 0.7360 - val_acc: 0.2004\n",
      "Epoch 1011/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2826 - acc: 0.2158 - val_loss: 0.7794 - val_acc: 0.2004\n",
      "Epoch 1012/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3675 - acc: 0.2167 - val_loss: 0.7442 - val_acc: 0.2004\n",
      "Epoch 1013/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3616 - acc: 0.2162 - val_loss: 0.9822 - val_acc: 0.2004\n",
      "Epoch 1014/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3563 - acc: 0.2162 - val_loss: 0.7744 - val_acc: 0.2004\n",
      "Epoch 1015/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3083 - acc: 0.2167 - val_loss: 0.6209 - val_acc: 0.2004\n",
      "Epoch 1016/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3299 - acc: 0.2162 - val_loss: 0.8256 - val_acc: 0.1985\n",
      "Epoch 1017/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3061 - acc: 0.2153 - val_loss: 0.6806 - val_acc: 0.2004\n",
      "Epoch 1018/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2773 - acc: 0.2167 - val_loss: 0.6998 - val_acc: 0.1985\n",
      "Epoch 1019/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2632 - acc: 0.2167 - val_loss: 0.6544 - val_acc: 0.2004\n",
      "Epoch 1020/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2654 - acc: 0.2162 - val_loss: 0.7060 - val_acc: 0.2004\n",
      "Epoch 1021/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.2912 - acc: 0.2158 - val_loss: 0.6623 - val_acc: 0.1985\n",
      "Epoch 1022/4000\n",
      "68/68 [==============================] - 5s 69ms/step - loss: 0.2697 - acc: 0.2162 - val_loss: 0.7060 - val_acc: 0.2004\n",
      "Epoch 1023/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2756 - acc: 0.2158 - val_loss: 0.6640 - val_acc: 0.2004\n",
      "Epoch 1024/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2685 - acc: 0.2167 - val_loss: 0.7629 - val_acc: 0.1985\n",
      "Epoch 1025/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2793 - acc: 0.2162 - val_loss: 0.8119 - val_acc: 0.1985\n",
      "Epoch 1026/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2694 - acc: 0.2162 - val_loss: 0.6790 - val_acc: 0.2004\n",
      "Epoch 1027/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2707 - acc: 0.2162 - val_loss: 0.7473 - val_acc: 0.2004\n",
      "Epoch 1028/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2822 - acc: 0.2158 - val_loss: 0.7274 - val_acc: 0.1985\n",
      "Epoch 1029/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2941 - acc: 0.2162 - val_loss: 0.7192 - val_acc: 0.1985\n",
      "Epoch 1030/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3427 - acc: 0.2162 - val_loss: 0.8073 - val_acc: 0.1985\n",
      "Epoch 1031/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3258 - acc: 0.2162 - val_loss: 0.9347 - val_acc: 0.2004\n",
      "Epoch 1032/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3190 - acc: 0.2162 - val_loss: 0.7587 - val_acc: 0.2004\n",
      "Epoch 1033/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2711 - acc: 0.2158 - val_loss: 0.6686 - val_acc: 0.2004\n",
      "Epoch 1034/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2895 - acc: 0.2167 - val_loss: 0.7070 - val_acc: 0.1985\n",
      "Epoch 1035/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2829 - acc: 0.2162 - val_loss: 0.6766 - val_acc: 0.2004\n",
      "Epoch 1036/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2888 - acc: 0.2158 - val_loss: 0.6674 - val_acc: 0.1985\n",
      "Epoch 1037/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2794 - acc: 0.2162 - val_loss: 0.7124 - val_acc: 0.1985\n",
      "Epoch 1038/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2595 - acc: 0.2162 - val_loss: 0.7295 - val_acc: 0.1985\n",
      "Epoch 1039/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3102 - acc: 0.2148 - val_loss: 0.6789 - val_acc: 0.2004\n",
      "Epoch 1040/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2726 - acc: 0.2153 - val_loss: 0.7280 - val_acc: 0.2004\n",
      "Epoch 1041/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2892 - acc: 0.2158 - val_loss: 0.6640 - val_acc: 0.2004\n",
      "Epoch 1042/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2973 - acc: 0.2158 - val_loss: 0.7394 - val_acc: 0.1985\n",
      "Epoch 1043/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2677 - acc: 0.2167 - val_loss: 0.6711 - val_acc: 0.2004\n",
      "Epoch 1044/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3054 - acc: 0.2139 - val_loss: 0.7782 - val_acc: 0.1985\n",
      "Epoch 1045/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2625 - acc: 0.2162 - val_loss: 0.6995 - val_acc: 0.1985\n",
      "Epoch 1046/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2903 - acc: 0.2167 - val_loss: 0.6664 - val_acc: 0.2004\n",
      "Epoch 1047/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2638 - acc: 0.2167 - val_loss: 0.6773 - val_acc: 0.2004\n",
      "Epoch 1048/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2701 - acc: 0.2158 - val_loss: 0.6662 - val_acc: 0.2004\n",
      "Epoch 1049/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3050 - acc: 0.2148 - val_loss: 0.6553 - val_acc: 0.1985\n",
      "Epoch 1050/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2938 - acc: 0.2148 - val_loss: 0.6317 - val_acc: 0.2004\n",
      "Epoch 1051/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2818 - acc: 0.2162 - val_loss: 0.7606 - val_acc: 0.2004\n",
      "Epoch 1052/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3247 - acc: 0.2148 - val_loss: 0.6940 - val_acc: 0.2004\n",
      "Epoch 1053/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2840 - acc: 0.2158 - val_loss: 0.6744 - val_acc: 0.1985\n",
      "Epoch 1054/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2963 - acc: 0.2153 - val_loss: 0.6556 - val_acc: 0.2004\n",
      "Epoch 1055/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2818 - acc: 0.2153 - val_loss: 0.6595 - val_acc: 0.2004\n",
      "Epoch 1056/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2604 - acc: 0.2158 - val_loss: 0.6856 - val_acc: 0.2004\n",
      "Epoch 1057/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2772 - acc: 0.2158 - val_loss: 0.7381 - val_acc: 0.1985\n",
      "Epoch 1058/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2980 - acc: 0.2153 - val_loss: 0.6632 - val_acc: 0.2004\n",
      "Epoch 1059/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2808 - acc: 0.2158 - val_loss: 0.6724 - val_acc: 0.2004\n",
      "Epoch 1060/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2724 - acc: 0.2167 - val_loss: 0.6879 - val_acc: 0.1985\n",
      "Epoch 1061/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2671 - acc: 0.2158 - val_loss: 0.7054 - val_acc: 0.1985\n",
      "Epoch 1062/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4826 - acc: 0.2153 - val_loss: 1.2520 - val_acc: 0.2004\n",
      "Epoch 1063/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 1.6580 - acc: 0.2042 - val_loss: 1.3279 - val_acc: 0.2004\n",
      "Epoch 1064/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.8072 - acc: 0.2148 - val_loss: 1.5658 - val_acc: 0.2004\n",
      "Epoch 1065/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.6862 - acc: 0.2084 - val_loss: 0.6567 - val_acc: 0.2004\n",
      "Epoch 1066/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2825 - acc: 0.2167 - val_loss: 0.6553 - val_acc: 0.2004\n",
      "Epoch 1067/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2623 - acc: 0.2172 - val_loss: 0.6327 - val_acc: 0.2004\n",
      "Epoch 1068/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2555 - acc: 0.2167 - val_loss: 0.6420 - val_acc: 0.2004\n",
      "Epoch 1069/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2504 - acc: 0.2167 - val_loss: 0.6439 - val_acc: 0.2004\n",
      "Epoch 1070/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2828 - acc: 0.2158 - val_loss: 0.7150 - val_acc: 0.1985\n",
      "Epoch 1071/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.2894 - acc: 0.2162 - val_loss: 0.8612 - val_acc: 0.2004\n",
      "Epoch 1072/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2654 - acc: 0.2167 - val_loss: 0.7536 - val_acc: 0.1985\n",
      "Epoch 1073/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2641 - acc: 0.2167 - val_loss: 0.6664 - val_acc: 0.1985\n",
      "Epoch 1074/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2657 - acc: 0.2158 - val_loss: 0.6494 - val_acc: 0.2004\n",
      "Epoch 1075/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2641 - acc: 0.2158 - val_loss: 0.6524 - val_acc: 0.2004\n",
      "Epoch 1076/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2653 - acc: 0.2162 - val_loss: 0.6570 - val_acc: 0.2004\n",
      "Epoch 1077/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2607 - acc: 0.2158 - val_loss: 0.6190 - val_acc: 0.2004\n",
      "Epoch 1078/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2680 - acc: 0.2162 - val_loss: 0.6453 - val_acc: 0.2004\n",
      "Epoch 1079/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2665 - acc: 0.2158 - val_loss: 0.7000 - val_acc: 0.2004\n",
      "Epoch 1080/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2526 - acc: 0.2167 - val_loss: 0.6478 - val_acc: 0.2004\n",
      "Epoch 1081/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2980 - acc: 0.2153 - val_loss: 0.8365 - val_acc: 0.1985\n",
      "Epoch 1082/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3096 - acc: 0.2153 - val_loss: 0.6605 - val_acc: 0.2004\n",
      "Epoch 1083/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2593 - acc: 0.2167 - val_loss: 0.6721 - val_acc: 0.1985\n",
      "Epoch 1084/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2644 - acc: 0.2167 - val_loss: 0.6482 - val_acc: 0.2004\n",
      "Epoch 1085/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.2534 - acc: 0.2172 - val_loss: 0.7953 - val_acc: 0.2004\n",
      "Epoch 1086/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.2648 - acc: 0.2162 - val_loss: 0.6985 - val_acc: 0.1985\n",
      "Epoch 1087/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2741 - acc: 0.2153 - val_loss: 0.6729 - val_acc: 0.1985\n",
      "Epoch 1088/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2959 - acc: 0.2162 - val_loss: 0.7798 - val_acc: 0.1985\n",
      "Epoch 1089/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2714 - acc: 0.2167 - val_loss: 0.8467 - val_acc: 0.1985\n",
      "Epoch 1090/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2745 - acc: 0.2158 - val_loss: 0.6871 - val_acc: 0.2004\n",
      "Epoch 1091/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2719 - acc: 0.2167 - val_loss: 0.8543 - val_acc: 0.1985\n",
      "Epoch 1092/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.2726 - acc: 0.2158 - val_loss: 0.6480 - val_acc: 0.2004\n",
      "Epoch 1093/4000\n",
      "68/68 [==============================] - 5s 66ms/step - loss: 0.2624 - acc: 0.2153 - val_loss: 0.6703 - val_acc: 0.1985\n",
      "Epoch 1094/4000\n",
      "68/68 [==============================] - 5s 69ms/step - loss: 0.2705 - acc: 0.2162 - val_loss: 0.7038 - val_acc: 0.1985\n",
      "Epoch 1095/4000\n",
      "68/68 [==============================] - 5s 69ms/step - loss: 0.2921 - acc: 0.2153 - val_loss: 0.7753 - val_acc: 0.2004\n",
      "Epoch 1096/4000\n",
      "68/68 [==============================] - 5s 71ms/step - loss: 0.2687 - acc: 0.2162 - val_loss: 0.6572 - val_acc: 0.2004\n",
      "Epoch 1097/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 5s 66ms/step - loss: 0.2621 - acc: 0.2153 - val_loss: 0.7311 - val_acc: 0.2004\n",
      "Epoch 1098/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.3012 - acc: 0.2153 - val_loss: 0.6467 - val_acc: 0.2004\n",
      "Epoch 1099/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3063 - acc: 0.2162 - val_loss: 0.6466 - val_acc: 0.1985\n",
      "Epoch 1100/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3796 - acc: 0.2135 - val_loss: 0.7256 - val_acc: 0.2004\n",
      "Epoch 1101/4000\n",
      "68/68 [==============================] - 5s 73ms/step - loss: 0.3730 - acc: 0.2162 - val_loss: 0.6778 - val_acc: 0.2004\n",
      "Epoch 1102/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2862 - acc: 0.2162 - val_loss: 0.6877 - val_acc: 0.1985\n",
      "Epoch 1103/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2916 - acc: 0.2158 - val_loss: 0.6939 - val_acc: 0.2004\n",
      "Epoch 1104/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2568 - acc: 0.2162 - val_loss: 0.6401 - val_acc: 0.2004\n",
      "Epoch 1105/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2739 - acc: 0.2162 - val_loss: 0.6898 - val_acc: 0.1985\n",
      "Epoch 1106/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2835 - acc: 0.2158 - val_loss: 0.7029 - val_acc: 0.2004\n",
      "Epoch 1107/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2738 - acc: 0.2162 - val_loss: 0.7175 - val_acc: 0.1985\n",
      "Epoch 1108/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2666 - acc: 0.2148 - val_loss: 0.6874 - val_acc: 0.1985\n",
      "Epoch 1109/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2801 - acc: 0.2167 - val_loss: 0.7286 - val_acc: 0.2004\n",
      "Epoch 1110/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2885 - acc: 0.2158 - val_loss: 0.7158 - val_acc: 0.2004\n",
      "Epoch 1111/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2784 - acc: 0.2153 - val_loss: 0.7017 - val_acc: 0.2004\n",
      "Epoch 1112/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2880 - acc: 0.2158 - val_loss: 0.8262 - val_acc: 0.1985\n",
      "Epoch 1113/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2653 - acc: 0.2162 - val_loss: 0.6540 - val_acc: 0.2004\n",
      "Epoch 1114/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2935 - acc: 0.2158 - val_loss: 0.6962 - val_acc: 0.1985\n",
      "Epoch 1115/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2625 - acc: 0.2148 - val_loss: 0.6636 - val_acc: 0.2004\n",
      "Epoch 1116/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2853 - acc: 0.2144 - val_loss: 0.7349 - val_acc: 0.2004\n",
      "Epoch 1117/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2840 - acc: 0.2162 - val_loss: 0.6925 - val_acc: 0.1985\n",
      "Epoch 1118/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2653 - acc: 0.2162 - val_loss: 0.6772 - val_acc: 0.1985\n",
      "Epoch 1119/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2684 - acc: 0.2162 - val_loss: 0.6885 - val_acc: 0.2004\n",
      "Epoch 1120/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2957 - acc: 0.2158 - val_loss: 0.6758 - val_acc: 0.1985\n",
      "Epoch 1121/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2869 - acc: 0.2162 - val_loss: 0.6754 - val_acc: 0.1985\n",
      "Epoch 1122/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2734 - acc: 0.2158 - val_loss: 0.6399 - val_acc: 0.2004\n",
      "Epoch 1123/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2824 - acc: 0.2153 - val_loss: 0.7001 - val_acc: 0.2004\n",
      "Epoch 1124/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2825 - acc: 0.2158 - val_loss: 0.7221 - val_acc: 0.1985\n",
      "Epoch 1125/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2709 - acc: 0.2158 - val_loss: 0.7177 - val_acc: 0.1985\n",
      "Epoch 1126/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2678 - acc: 0.2158 - val_loss: 0.7022 - val_acc: 0.2004\n",
      "Epoch 1127/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2781 - acc: 0.2162 - val_loss: 0.7713 - val_acc: 0.1985\n",
      "Epoch 1128/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2927 - acc: 0.2158 - val_loss: 0.6603 - val_acc: 0.2004\n",
      "Epoch 1129/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2854 - acc: 0.2162 - val_loss: 0.6836 - val_acc: 0.2004\n",
      "Epoch 1130/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2840 - acc: 0.2158 - val_loss: 0.7599 - val_acc: 0.1985\n",
      "Epoch 1131/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2793 - acc: 0.2153 - val_loss: 0.6477 - val_acc: 0.2004\n",
      "Epoch 1132/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2591 - acc: 0.2167 - val_loss: 0.6904 - val_acc: 0.2004\n",
      "Epoch 1133/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2704 - acc: 0.2158 - val_loss: 0.6640 - val_acc: 0.1985\n",
      "Epoch 1134/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2722 - acc: 0.2148 - val_loss: 0.6546 - val_acc: 0.1985\n",
      "Epoch 1135/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2716 - acc: 0.2162 - val_loss: 0.6477 - val_acc: 0.2004\n",
      "Epoch 1136/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2640 - acc: 0.2162 - val_loss: 0.6525 - val_acc: 0.2004\n",
      "Epoch 1137/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2576 - acc: 0.2153 - val_loss: 0.6955 - val_acc: 0.2004\n",
      "Epoch 1138/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2668 - acc: 0.2153 - val_loss: 0.6555 - val_acc: 0.2004\n",
      "Epoch 1139/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2640 - acc: 0.2153 - val_loss: 0.7080 - val_acc: 0.1985\n",
      "Epoch 1140/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2692 - acc: 0.2158 - val_loss: 0.6913 - val_acc: 0.1985\n",
      "Epoch 1141/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2749 - acc: 0.2148 - val_loss: 0.6467 - val_acc: 0.2004\n",
      "Epoch 1142/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2574 - acc: 0.2158 - val_loss: 0.6508 - val_acc: 0.2004\n",
      "Epoch 1143/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2624 - acc: 0.2158 - val_loss: 0.7229 - val_acc: 0.1985\n",
      "Epoch 1144/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2540 - acc: 0.2148 - val_loss: 0.6356 - val_acc: 0.2004\n",
      "Epoch 1145/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2880 - acc: 0.2162 - val_loss: 0.6765 - val_acc: 0.1985\n",
      "Epoch 1146/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2607 - acc: 0.2153 - val_loss: 0.6819 - val_acc: 0.1985\n",
      "Epoch 1147/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2627 - acc: 0.2162 - val_loss: 0.6483 - val_acc: 0.2004\n",
      "Epoch 1148/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2673 - acc: 0.2158 - val_loss: 0.7191 - val_acc: 0.1985\n",
      "Epoch 1149/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2829 - acc: 0.2153 - val_loss: 0.6585 - val_acc: 0.2004\n",
      "Epoch 1150/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2785 - acc: 0.2162 - val_loss: 0.6601 - val_acc: 0.2004\n",
      "Epoch 1151/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2521 - acc: 0.2158 - val_loss: 0.6801 - val_acc: 0.2004\n",
      "Epoch 1152/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2966 - acc: 0.2158 - val_loss: 0.8998 - val_acc: 0.1985\n",
      "Epoch 1153/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2775 - acc: 0.2148 - val_loss: 0.7374 - val_acc: 0.2004\n",
      "Epoch 1154/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2719 - acc: 0.2167 - val_loss: 0.6239 - val_acc: 0.1985\n",
      "Epoch 1155/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3072 - acc: 0.2162 - val_loss: 0.7362 - val_acc: 0.2004\n",
      "Epoch 1156/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3182 - acc: 0.2158 - val_loss: 0.6862 - val_acc: 0.2004\n",
      "Epoch 1157/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.4948 - acc: 0.2139 - val_loss: 0.9728 - val_acc: 0.2004\n",
      "Epoch 1158/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.5114 - acc: 0.2153 - val_loss: 0.8434 - val_acc: 0.2004\n",
      "Epoch 1159/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4599 - acc: 0.2148 - val_loss: 0.7633 - val_acc: 0.1985\n",
      "Epoch 1160/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3014 - acc: 0.2167 - val_loss: 0.6178 - val_acc: 0.2004\n",
      "Epoch 1161/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3413 - acc: 0.2167 - val_loss: 0.5977 - val_acc: 0.2004\n",
      "Epoch 1162/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3253 - acc: 0.2167 - val_loss: 0.8186 - val_acc: 0.1985\n",
      "Epoch 1163/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3052 - acc: 0.2167 - val_loss: 0.6283 - val_acc: 0.2004\n",
      "Epoch 1164/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2797 - acc: 0.2162 - val_loss: 0.6405 - val_acc: 0.2004\n",
      "Epoch 1165/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2555 - acc: 0.2162 - val_loss: 0.6414 - val_acc: 0.2004\n",
      "Epoch 1166/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2548 - acc: 0.2158 - val_loss: 0.6500 - val_acc: 0.2004\n",
      "Epoch 1167/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2789 - acc: 0.2153 - val_loss: 0.7487 - val_acc: 0.2004\n",
      "Epoch 1168/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2872 - acc: 0.2162 - val_loss: 0.6788 - val_acc: 0.1985\n",
      "Epoch 1169/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2664 - acc: 0.2162 - val_loss: 0.6476 - val_acc: 0.2004\n",
      "Epoch 1170/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2700 - acc: 0.2158 - val_loss: 0.7494 - val_acc: 0.1985\n",
      "Epoch 1171/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2781 - acc: 0.2162 - val_loss: 0.6489 - val_acc: 0.2004\n",
      "Epoch 1172/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2656 - acc: 0.2167 - val_loss: 0.7222 - val_acc: 0.1985\n",
      "Epoch 1173/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2577 - acc: 0.2153 - val_loss: 0.8051 - val_acc: 0.1985\n",
      "Epoch 1174/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2778 - acc: 0.2162 - val_loss: 0.7131 - val_acc: 0.1985\n",
      "Epoch 1175/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2921 - acc: 0.2162 - val_loss: 0.6455 - val_acc: 0.2004\n",
      "Epoch 1176/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2652 - acc: 0.2158 - val_loss: 0.6867 - val_acc: 0.2004\n",
      "Epoch 1177/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2522 - acc: 0.2162 - val_loss: 0.6818 - val_acc: 0.2004\n",
      "Epoch 1178/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2673 - acc: 0.2158 - val_loss: 0.6470 - val_acc: 0.1985\n",
      "Epoch 1179/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2542 - acc: 0.2158 - val_loss: 0.7371 - val_acc: 0.1985\n",
      "Epoch 1180/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2449 - acc: 0.2158 - val_loss: 0.6426 - val_acc: 0.2004\n",
      "Epoch 1181/4000\n",
      "68/68 [==============================] - 5s 71ms/step - loss: 0.2515 - acc: 0.2162 - val_loss: 0.7417 - val_acc: 0.2004\n",
      "Epoch 1182/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.2870 - acc: 0.2162 - val_loss: 0.6508 - val_acc: 0.2004\n",
      "Epoch 1183/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2884 - acc: 0.2148 - val_loss: 0.6626 - val_acc: 0.2004\n",
      "Epoch 1184/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2574 - acc: 0.2158 - val_loss: 0.6638 - val_acc: 0.1985\n",
      "Epoch 1185/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2640 - acc: 0.2153 - val_loss: 0.6464 - val_acc: 0.2004\n",
      "Epoch 1186/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2772 - acc: 0.2158 - val_loss: 0.7288 - val_acc: 0.2004\n",
      "Epoch 1187/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2709 - acc: 0.2153 - val_loss: 0.6530 - val_acc: 0.2004\n",
      "Epoch 1188/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2784 - acc: 0.2158 - val_loss: 0.6802 - val_acc: 0.1985\n",
      "Epoch 1189/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2595 - acc: 0.2153 - val_loss: 0.6783 - val_acc: 0.2004\n",
      "Epoch 1190/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2644 - acc: 0.2158 - val_loss: 0.6761 - val_acc: 0.2004\n",
      "Epoch 1191/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2566 - acc: 0.2148 - val_loss: 0.6980 - val_acc: 0.1985\n",
      "Epoch 1192/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2860 - acc: 0.2162 - val_loss: 0.6521 - val_acc: 0.2004\n",
      "Epoch 1193/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2578 - acc: 0.2158 - val_loss: 0.6471 - val_acc: 0.2004\n",
      "Epoch 1194/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2785 - acc: 0.2158 - val_loss: 0.8797 - val_acc: 0.2004\n",
      "Epoch 1195/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2796 - acc: 0.2162 - val_loss: 0.6777 - val_acc: 0.2004\n",
      "Epoch 1196/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3120 - acc: 0.2148 - val_loss: 0.7389 - val_acc: 0.2004\n",
      "Epoch 1197/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2664 - acc: 0.2158 - val_loss: 0.8353 - val_acc: 0.1985\n",
      "Epoch 1198/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2882 - acc: 0.2158 - val_loss: 0.8079 - val_acc: 0.2004\n",
      "Epoch 1199/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2725 - acc: 0.2158 - val_loss: 0.6602 - val_acc: 0.2004\n",
      "Epoch 1200/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2470 - acc: 0.2162 - val_loss: 0.6645 - val_acc: 0.2004\n",
      "Epoch 1201/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2617 - acc: 0.2167 - val_loss: 0.6556 - val_acc: 0.2004\n",
      "Epoch 1202/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2505 - acc: 0.2158 - val_loss: 0.6568 - val_acc: 0.1985\n",
      "Epoch 1203/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2424 - acc: 0.2153 - val_loss: 0.6342 - val_acc: 0.2004\n",
      "Epoch 1204/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2520 - acc: 0.2162 - val_loss: 0.7377 - val_acc: 0.1985\n",
      "Epoch 1205/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2510 - acc: 0.2162 - val_loss: 0.6294 - val_acc: 0.2004\n",
      "Epoch 1206/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2615 - acc: 0.2162 - val_loss: 0.6606 - val_acc: 0.2004\n",
      "Epoch 1207/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2891 - acc: 0.2162 - val_loss: 0.7642 - val_acc: 0.1985\n",
      "Epoch 1208/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2943 - acc: 0.2148 - val_loss: 0.7033 - val_acc: 0.2004\n",
      "Epoch 1209/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2652 - acc: 0.2158 - val_loss: 0.6667 - val_acc: 0.1985\n",
      "Epoch 1210/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2790 - acc: 0.2158 - val_loss: 0.9280 - val_acc: 0.2004\n",
      "Epoch 1211/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2737 - acc: 0.2153 - val_loss: 0.6374 - val_acc: 0.2004\n",
      "Epoch 1212/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2447 - acc: 0.2167 - val_loss: 0.7410 - val_acc: 0.2004\n",
      "Epoch 1213/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2811 - acc: 0.2158 - val_loss: 0.6595 - val_acc: 0.2004\n",
      "Epoch 1214/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2728 - acc: 0.2153 - val_loss: 0.6727 - val_acc: 0.1985\n",
      "Epoch 1215/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2640 - acc: 0.2158 - val_loss: 0.6515 - val_acc: 0.2004\n",
      "Epoch 1216/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2532 - acc: 0.2158 - val_loss: 0.6810 - val_acc: 0.2004\n",
      "Epoch 1217/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2546 - acc: 0.2158 - val_loss: 0.6244 - val_acc: 0.2004\n",
      "Epoch 1218/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2660 - acc: 0.2153 - val_loss: 0.6621 - val_acc: 0.1985\n",
      "Epoch 1219/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2654 - acc: 0.2162 - val_loss: 0.6355 - val_acc: 0.1985\n",
      "Epoch 1220/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2930 - acc: 0.2158 - val_loss: 0.7066 - val_acc: 0.2004\n",
      "Epoch 1221/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2661 - acc: 0.2158 - val_loss: 0.6343 - val_acc: 0.2004\n",
      "Epoch 1222/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2704 - acc: 0.2167 - val_loss: 0.7254 - val_acc: 0.2004\n",
      "Epoch 1223/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2711 - acc: 0.2148 - val_loss: 0.7438 - val_acc: 0.1985\n",
      "Epoch 1224/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2549 - acc: 0.2167 - val_loss: 0.6435 - val_acc: 0.2004\n",
      "Epoch 1225/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2574 - acc: 0.2162 - val_loss: 0.6447 - val_acc: 0.1985\n",
      "Epoch 1226/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2646 - acc: 0.2153 - val_loss: 0.7092 - val_acc: 0.1985\n",
      "Epoch 1227/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3033 - acc: 0.2167 - val_loss: 0.6434 - val_acc: 0.1985\n",
      "Epoch 1228/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2579 - acc: 0.2158 - val_loss: 0.7274 - val_acc: 0.1985\n",
      "Epoch 1229/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2671 - acc: 0.2167 - val_loss: 0.6893 - val_acc: 0.1985\n",
      "Epoch 1230/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3200 - acc: 0.2148 - val_loss: 0.7200 - val_acc: 0.2004\n",
      "Epoch 1231/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2884 - acc: 0.2167 - val_loss: 0.6490 - val_acc: 0.2004\n",
      "Epoch 1232/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2778 - acc: 0.2158 - val_loss: 0.6451 - val_acc: 0.2004\n",
      "Epoch 1233/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2592 - acc: 0.2158 - val_loss: 0.6714 - val_acc: 0.2004\n",
      "Epoch 1234/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2580 - acc: 0.2162 - val_loss: 0.6406 - val_acc: 0.1985\n",
      "Epoch 1235/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2511 - acc: 0.2148 - val_loss: 0.6718 - val_acc: 0.2004\n",
      "Epoch 1236/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2663 - acc: 0.2158 - val_loss: 0.6572 - val_acc: 0.1985\n",
      "Epoch 1237/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2805 - acc: 0.2158 - val_loss: 0.6277 - val_acc: 0.2004\n",
      "Epoch 1238/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2552 - acc: 0.2158 - val_loss: 0.6702 - val_acc: 0.1985\n",
      "Epoch 1239/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2462 - acc: 0.2153 - val_loss: 0.6612 - val_acc: 0.2004\n",
      "Epoch 1240/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2883 - acc: 0.2158 - val_loss: 0.6567 - val_acc: 0.2004\n",
      "Epoch 1241/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2538 - acc: 0.2148 - val_loss: 0.6608 - val_acc: 0.2004\n",
      "Epoch 1242/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2526 - acc: 0.2158 - val_loss: 0.7703 - val_acc: 0.1985\n",
      "Epoch 1243/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2642 - acc: 0.2162 - val_loss: 0.7046 - val_acc: 0.2004\n",
      "Epoch 1244/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2630 - acc: 0.2158 - val_loss: 0.7538 - val_acc: 0.1985\n",
      "Epoch 1245/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2807 - acc: 0.2153 - val_loss: 0.6309 - val_acc: 0.2004\n",
      "Epoch 1246/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2624 - acc: 0.2153 - val_loss: 0.6776 - val_acc: 0.2004\n",
      "Epoch 1247/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2390 - acc: 0.2153 - val_loss: 0.6975 - val_acc: 0.1985\n",
      "Epoch 1248/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2821 - acc: 0.2153 - val_loss: 0.6746 - val_acc: 0.2004\n",
      "Epoch 1249/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2526 - acc: 0.2153 - val_loss: 0.6733 - val_acc: 0.1985\n",
      "Epoch 1250/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2812 - acc: 0.2158 - val_loss: 0.6706 - val_acc: 0.2004\n",
      "Epoch 1251/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2761 - acc: 0.2153 - val_loss: 0.6686 - val_acc: 0.1985\n",
      "Epoch 1252/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2583 - acc: 0.2148 - val_loss: 0.6818 - val_acc: 0.2004\n",
      "Epoch 1253/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2643 - acc: 0.2148 - val_loss: 0.6825 - val_acc: 0.2004\n",
      "Epoch 1254/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2492 - acc: 0.2158 - val_loss: 0.6601 - val_acc: 0.1985\n",
      "Epoch 1255/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2451 - acc: 0.2162 - val_loss: 0.7446 - val_acc: 0.2004\n",
      "Epoch 1256/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2656 - acc: 0.2158 - val_loss: 0.6407 - val_acc: 0.2004\n",
      "Epoch 1257/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3021 - acc: 0.2153 - val_loss: 0.6919 - val_acc: 0.2004\n",
      "Epoch 1258/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2586 - acc: 0.2162 - val_loss: 0.8112 - val_acc: 0.2004\n",
      "Epoch 1259/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3162 - acc: 0.2153 - val_loss: 0.6484 - val_acc: 0.2004\n",
      "Epoch 1260/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2787 - acc: 0.2158 - val_loss: 0.7133 - val_acc: 0.1985\n",
      "Epoch 1261/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 0.2806 - acc: 0.2167 - val_loss: 0.5993 - val_acc: 0.2004\n",
      "Epoch 1262/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.2769 - acc: 0.2162 - val_loss: 0.6982 - val_acc: 0.1985\n",
      "Epoch 1263/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3444 - acc: 0.2158 - val_loss: 0.9538 - val_acc: 0.1985\n",
      "Epoch 1264/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.4488 - acc: 0.2158 - val_loss: 0.8272 - val_acc: 0.2004\n",
      "Epoch 1265/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 1.1850 - acc: 0.2153 - val_loss: 1.1456 - val_acc: 0.1985\n",
      "Epoch 1266/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3973 - acc: 0.2162 - val_loss: 0.5600 - val_acc: 0.2004\n",
      "Epoch 1267/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3989 - acc: 0.2162 - val_loss: 0.5767 - val_acc: 0.2004\n",
      "Epoch 1268/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3264 - acc: 0.2167 - val_loss: 0.7719 - val_acc: 0.2004\n",
      "Epoch 1269/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2766 - acc: 0.2167 - val_loss: 0.6077 - val_acc: 0.2004\n",
      "Epoch 1270/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2441 - acc: 0.2167 - val_loss: 0.7278 - val_acc: 0.1985\n",
      "Epoch 1271/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2549 - acc: 0.2153 - val_loss: 0.6696 - val_acc: 0.2004\n",
      "Epoch 1272/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2806 - acc: 0.2153 - val_loss: 0.6471 - val_acc: 0.2004\n",
      "Epoch 1273/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2663 - acc: 0.2162 - val_loss: 0.6540 - val_acc: 0.2004\n",
      "Epoch 1274/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2830 - acc: 0.2158 - val_loss: 0.6215 - val_acc: 0.2004\n",
      "Epoch 1275/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2601 - acc: 0.2162 - val_loss: 0.6571 - val_acc: 0.2004\n",
      "Epoch 1276/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2562 - acc: 0.2167 - val_loss: 0.6237 - val_acc: 0.2004\n",
      "Epoch 1277/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2435 - acc: 0.2153 - val_loss: 0.6253 - val_acc: 0.2004\n",
      "Epoch 1278/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2500 - acc: 0.2167 - val_loss: 0.6459 - val_acc: 0.2004\n",
      "Epoch 1279/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2521 - acc: 0.2162 - val_loss: 0.6432 - val_acc: 0.1985\n",
      "Epoch 1280/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2679 - acc: 0.2162 - val_loss: 0.6394 - val_acc: 0.2004\n",
      "Epoch 1281/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2756 - acc: 0.2158 - val_loss: 0.6284 - val_acc: 0.1985\n",
      "Epoch 1282/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2605 - acc: 0.2167 - val_loss: 0.6284 - val_acc: 0.2004\n",
      "Epoch 1283/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2526 - acc: 0.2158 - val_loss: 0.6376 - val_acc: 0.2004\n",
      "Epoch 1284/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2392 - acc: 0.2162 - val_loss: 0.6412 - val_acc: 0.2004\n",
      "Epoch 1285/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2401 - acc: 0.2162 - val_loss: 0.6319 - val_acc: 0.2004\n",
      "Epoch 1286/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2451 - acc: 0.2162 - val_loss: 0.8031 - val_acc: 0.2004\n",
      "Epoch 1287/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2632 - acc: 0.2148 - val_loss: 0.7018 - val_acc: 0.1985\n",
      "Epoch 1288/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2508 - acc: 0.2162 - val_loss: 0.6906 - val_acc: 0.2004\n",
      "Epoch 1289/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2666 - acc: 0.2162 - val_loss: 0.6179 - val_acc: 0.2004\n",
      "Epoch 1290/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2510 - acc: 0.2162 - val_loss: 0.6644 - val_acc: 0.2004\n",
      "Epoch 1291/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2672 - acc: 0.2162 - val_loss: 0.6569 - val_acc: 0.1985\n",
      "Epoch 1292/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2537 - acc: 0.2167 - val_loss: 0.6458 - val_acc: 0.1985\n",
      "Epoch 1293/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2855 - acc: 0.2158 - val_loss: 0.7207 - val_acc: 0.2004\n",
      "Epoch 1294/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2852 - acc: 0.2162 - val_loss: 0.6640 - val_acc: 0.1985\n",
      "Epoch 1295/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2656 - acc: 0.2167 - val_loss: 0.6648 - val_acc: 0.2004\n",
      "Epoch 1296/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2537 - acc: 0.2162 - val_loss: 0.6610 - val_acc: 0.2004\n",
      "Epoch 1297/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2360 - acc: 0.2162 - val_loss: 0.6582 - val_acc: 0.2004\n",
      "Epoch 1298/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.2527 - acc: 0.2167 - val_loss: 0.6646 - val_acc: 0.1985\n",
      "Epoch 1299/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2753 - acc: 0.2153 - val_loss: 0.7067 - val_acc: 0.2004\n",
      "Epoch 1300/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2600 - acc: 0.2162 - val_loss: 0.7019 - val_acc: 0.2004\n",
      "Epoch 1301/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2604 - acc: 0.2162 - val_loss: 0.7804 - val_acc: 0.2004\n",
      "Epoch 1302/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2512 - acc: 0.2167 - val_loss: 0.6295 - val_acc: 0.1985\n",
      "Epoch 1303/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2415 - acc: 0.2167 - val_loss: 0.6446 - val_acc: 0.2004\n",
      "Epoch 1304/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2526 - acc: 0.2162 - val_loss: 0.7517 - val_acc: 0.2004\n",
      "Epoch 1305/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2862 - acc: 0.2144 - val_loss: 0.7009 - val_acc: 0.2004\n",
      "Epoch 1306/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2764 - acc: 0.2158 - val_loss: 0.6702 - val_acc: 0.1985\n",
      "Epoch 1307/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2528 - acc: 0.2162 - val_loss: 0.7078 - val_acc: 0.2004\n",
      "Epoch 1308/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2606 - acc: 0.2158 - val_loss: 0.7472 - val_acc: 0.2004\n",
      "Epoch 1309/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2826 - acc: 0.2162 - val_loss: 0.6731 - val_acc: 0.1985\n",
      "Epoch 1310/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2446 - acc: 0.2167 - val_loss: 0.6277 - val_acc: 0.2004\n",
      "Epoch 1311/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2510 - acc: 0.2153 - val_loss: 0.6352 - val_acc: 0.2004\n",
      "Epoch 1312/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2764 - acc: 0.2167 - val_loss: 0.6293 - val_acc: 0.2004\n",
      "Epoch 1313/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2753 - acc: 0.2144 - val_loss: 0.7476 - val_acc: 0.1985\n",
      "Epoch 1314/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2791 - acc: 0.2158 - val_loss: 0.6075 - val_acc: 0.2004\n",
      "Epoch 1315/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3066 - acc: 0.2153 - val_loss: 0.6914 - val_acc: 0.2004\n",
      "Epoch 1316/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2579 - acc: 0.2158 - val_loss: 0.6867 - val_acc: 0.1985\n",
      "Epoch 1317/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2629 - acc: 0.2158 - val_loss: 0.6817 - val_acc: 0.2004\n",
      "Epoch 1318/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2566 - acc: 0.2153 - val_loss: 0.6327 - val_acc: 0.1985\n",
      "Epoch 1319/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2810 - acc: 0.2162 - val_loss: 0.7494 - val_acc: 0.2004\n",
      "Epoch 1320/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2740 - acc: 0.2162 - val_loss: 0.6200 - val_acc: 0.2004\n",
      "Epoch 1321/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2478 - acc: 0.2162 - val_loss: 0.6734 - val_acc: 0.2004\n",
      "Epoch 1322/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2467 - acc: 0.2158 - val_loss: 0.7896 - val_acc: 0.1985\n",
      "Epoch 1323/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2685 - acc: 0.2148 - val_loss: 0.6763 - val_acc: 0.1985\n",
      "Epoch 1324/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2713 - acc: 0.2167 - val_loss: 0.6456 - val_acc: 0.2004\n",
      "Epoch 1325/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2676 - acc: 0.2148 - val_loss: 0.6307 - val_acc: 0.2004\n",
      "Epoch 1326/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2429 - acc: 0.2162 - val_loss: 0.6869 - val_acc: 0.2004\n",
      "Epoch 1327/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.2392 - acc: 0.2162 - val_loss: 0.6207 - val_acc: 0.2004\n",
      "Epoch 1328/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2398 - acc: 0.2162 - val_loss: 0.6961 - val_acc: 0.1985\n",
      "Epoch 1329/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2524 - acc: 0.2158 - val_loss: 0.6550 - val_acc: 0.2004\n",
      "Epoch 1330/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2744 - acc: 0.2162 - val_loss: 0.6633 - val_acc: 0.2004\n",
      "Epoch 1331/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2679 - acc: 0.2162 - val_loss: 0.6615 - val_acc: 0.2004\n",
      "Epoch 1332/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2519 - acc: 0.2162 - val_loss: 0.6308 - val_acc: 0.2004\n",
      "Epoch 1333/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2399 - acc: 0.2158 - val_loss: 0.6567 - val_acc: 0.2004\n",
      "Epoch 1334/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2706 - acc: 0.2167 - val_loss: 0.6655 - val_acc: 0.2004\n",
      "Epoch 1335/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2525 - acc: 0.2158 - val_loss: 0.6452 - val_acc: 0.2004\n",
      "Epoch 1336/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2572 - acc: 0.2167 - val_loss: 0.9294 - val_acc: 0.1967\n",
      "Epoch 1337/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2889 - acc: 0.2148 - val_loss: 0.6464 - val_acc: 0.2004\n",
      "Epoch 1338/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2873 - acc: 0.2135 - val_loss: 0.6611 - val_acc: 0.2004\n",
      "Epoch 1339/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2538 - acc: 0.2162 - val_loss: 0.8750 - val_acc: 0.2004\n",
      "Epoch 1340/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2451 - acc: 0.2167 - val_loss: 0.6886 - val_acc: 0.2004\n",
      "Epoch 1341/4000\n",
      "68/68 [==============================] - 5s 69ms/step - loss: 0.2547 - acc: 0.2158 - val_loss: 0.6394 - val_acc: 0.2004\n",
      "Epoch 1342/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.2457 - acc: 0.2167 - val_loss: 0.7524 - val_acc: 0.1985\n",
      "Epoch 1343/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2464 - acc: 0.2158 - val_loss: 0.6347 - val_acc: 0.1985\n",
      "Epoch 1344/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2606 - acc: 0.2153 - val_loss: 0.6307 - val_acc: 0.1985\n",
      "Epoch 1345/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2803 - acc: 0.2158 - val_loss: 0.6218 - val_acc: 0.2004\n",
      "Epoch 1346/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3084 - acc: 0.2153 - val_loss: 0.6231 - val_acc: 0.2004\n",
      "Epoch 1347/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2521 - acc: 0.2162 - val_loss: 0.6853 - val_acc: 0.2004\n",
      "Epoch 1348/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2734 - acc: 0.2162 - val_loss: 0.6302 - val_acc: 0.2004\n",
      "Epoch 1349/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2411 - acc: 0.2162 - val_loss: 0.6383 - val_acc: 0.1985\n",
      "Epoch 1350/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2812 - acc: 0.2167 - val_loss: 0.6423 - val_acc: 0.2004\n",
      "Epoch 1351/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2362 - acc: 0.2162 - val_loss: 0.6290 - val_acc: 0.2004\n",
      "Epoch 1352/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2355 - acc: 0.2158 - val_loss: 0.6294 - val_acc: 0.2004\n",
      "Epoch 1353/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2637 - acc: 0.2158 - val_loss: 0.6210 - val_acc: 0.2004\n",
      "Epoch 1354/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2801 - acc: 0.2139 - val_loss: 0.6353 - val_acc: 0.2004\n",
      "Epoch 1355/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2357 - acc: 0.2167 - val_loss: 0.7495 - val_acc: 0.2004\n",
      "Epoch 1356/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.2458 - acc: 0.2162 - val_loss: 0.7122 - val_acc: 0.1985\n",
      "Epoch 1357/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2699 - acc: 0.2162 - val_loss: 0.7098 - val_acc: 0.2004\n",
      "Epoch 1358/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2673 - acc: 0.2153 - val_loss: 0.6731 - val_acc: 0.1985\n",
      "Epoch 1359/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2702 - acc: 0.2148 - val_loss: 0.6585 - val_acc: 0.2004\n",
      "Epoch 1360/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2592 - acc: 0.2158 - val_loss: 0.6713 - val_acc: 0.1985\n",
      "Epoch 1361/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2707 - acc: 0.2148 - val_loss: 0.7242 - val_acc: 0.2004\n",
      "Epoch 1362/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2491 - acc: 0.2162 - val_loss: 0.6580 - val_acc: 0.2004\n",
      "Epoch 1363/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2371 - acc: 0.2167 - val_loss: 0.6160 - val_acc: 0.2004\n",
      "Epoch 1364/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2646 - acc: 0.2158 - val_loss: 0.6202 - val_acc: 0.2004\n",
      "Epoch 1365/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2585 - acc: 0.2162 - val_loss: 0.6275 - val_acc: 0.2004\n",
      "Epoch 1366/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2798 - acc: 0.2153 - val_loss: 0.6782 - val_acc: 0.1985\n",
      "Epoch 1367/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2634 - acc: 0.2153 - val_loss: 0.6675 - val_acc: 0.2004\n",
      "Epoch 1368/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2387 - acc: 0.2162 - val_loss: 0.7043 - val_acc: 0.1985\n",
      "Epoch 1369/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2992 - acc: 0.2162 - val_loss: 0.6881 - val_acc: 0.1985\n",
      "Epoch 1370/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2436 - acc: 0.2158 - val_loss: 0.6488 - val_acc: 0.1985\n",
      "Epoch 1371/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2379 - acc: 0.2162 - val_loss: 0.8281 - val_acc: 0.1985\n",
      "Epoch 1372/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2887 - acc: 0.2162 - val_loss: 0.6473 - val_acc: 0.2004\n",
      "Epoch 1373/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2476 - acc: 0.2162 - val_loss: 0.6355 - val_acc: 0.2004\n",
      "Epoch 1374/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2470 - acc: 0.2167 - val_loss: 0.6522 - val_acc: 0.1985\n",
      "Epoch 1375/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2568 - acc: 0.2162 - val_loss: 0.6273 - val_acc: 0.1985\n",
      "Epoch 1376/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3072 - acc: 0.2153 - val_loss: 0.6720 - val_acc: 0.2004\n",
      "Epoch 1377/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2888 - acc: 0.2158 - val_loss: 0.7723 - val_acc: 0.1985\n",
      "Epoch 1378/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2614 - acc: 0.2153 - val_loss: 0.6629 - val_acc: 0.2004\n",
      "Epoch 1379/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2429 - acc: 0.2153 - val_loss: 0.6392 - val_acc: 0.2004\n",
      "Epoch 1380/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2912 - acc: 0.2162 - val_loss: 0.6364 - val_acc: 0.1985\n",
      "Epoch 1381/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2611 - acc: 0.2153 - val_loss: 0.7970 - val_acc: 0.2004\n",
      "Epoch 1382/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2827 - acc: 0.2158 - val_loss: 0.6545 - val_acc: 0.2004\n",
      "Epoch 1383/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2563 - acc: 0.2162 - val_loss: 0.6214 - val_acc: 0.2004\n",
      "Epoch 1384/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2539 - acc: 0.2144 - val_loss: 0.6938 - val_acc: 0.2004\n",
      "Epoch 1385/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2437 - acc: 0.2167 - val_loss: 0.6174 - val_acc: 0.2004\n",
      "Epoch 1386/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2590 - acc: 0.2158 - val_loss: 0.6146 - val_acc: 0.2004\n",
      "Epoch 1387/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2445 - acc: 0.2158 - val_loss: 0.6515 - val_acc: 0.2004\n",
      "Epoch 1388/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2456 - acc: 0.2162 - val_loss: 0.6113 - val_acc: 0.2004\n",
      "Epoch 1389/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2338 - acc: 0.2162 - val_loss: 0.7385 - val_acc: 0.1985\n",
      "Epoch 1390/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2728 - acc: 0.2158 - val_loss: 0.6369 - val_acc: 0.2004\n",
      "Epoch 1391/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2574 - acc: 0.2167 - val_loss: 0.6717 - val_acc: 0.1985\n",
      "Epoch 1392/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3119 - acc: 0.2148 - val_loss: 1.0828 - val_acc: 0.1929\n",
      "Epoch 1393/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2548 - acc: 0.2158 - val_loss: 0.6156 - val_acc: 0.2004\n",
      "Epoch 1394/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2433 - acc: 0.2162 - val_loss: 0.8537 - val_acc: 0.1985\n",
      "Epoch 1395/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2608 - acc: 0.2162 - val_loss: 0.6803 - val_acc: 0.1985\n",
      "Epoch 1396/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2387 - acc: 0.2158 - val_loss: 0.7203 - val_acc: 0.2004\n",
      "Epoch 1397/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2638 - acc: 0.2153 - val_loss: 0.6597 - val_acc: 0.1985\n",
      "Epoch 1398/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2600 - acc: 0.2158 - val_loss: 0.6843 - val_acc: 0.1985\n",
      "Epoch 1399/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2423 - acc: 0.2162 - val_loss: 0.6499 - val_acc: 0.1985\n",
      "Epoch 1400/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2454 - acc: 0.2162 - val_loss: 0.6941 - val_acc: 0.1985\n",
      "Epoch 1401/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2521 - acc: 0.2158 - val_loss: 0.7689 - val_acc: 0.2004\n",
      "Epoch 1402/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2794 - acc: 0.2158 - val_loss: 0.6285 - val_acc: 0.2004\n",
      "Epoch 1403/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2488 - acc: 0.2158 - val_loss: 0.6734 - val_acc: 0.2004\n",
      "Epoch 1404/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2359 - acc: 0.2162 - val_loss: 0.7226 - val_acc: 0.2004\n",
      "Epoch 1405/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2537 - acc: 0.2167 - val_loss: 0.6512 - val_acc: 0.2004\n",
      "Epoch 1406/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2588 - acc: 0.2158 - val_loss: 0.7021 - val_acc: 0.2004\n",
      "Epoch 1407/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2604 - acc: 0.2167 - val_loss: 0.7043 - val_acc: 0.1985\n",
      "Epoch 1408/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2441 - acc: 0.2153 - val_loss: 0.7049 - val_acc: 0.2004\n",
      "Epoch 1409/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2626 - acc: 0.2153 - val_loss: 0.7024 - val_acc: 0.2004\n",
      "Epoch 1410/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2621 - acc: 0.2153 - val_loss: 0.6754 - val_acc: 0.2004\n",
      "Epoch 1411/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3038 - acc: 0.2153 - val_loss: 0.6010 - val_acc: 0.2004\n",
      "Epoch 1412/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2428 - acc: 0.2158 - val_loss: 0.6382 - val_acc: 0.2004\n",
      "Epoch 1413/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2380 - acc: 0.2167 - val_loss: 0.8080 - val_acc: 0.2004\n",
      "Epoch 1414/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3111 - acc: 0.2162 - val_loss: 0.6746 - val_acc: 0.2004\n",
      "Epoch 1415/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3838 - acc: 0.2158 - val_loss: 0.7874 - val_acc: 0.2004\n",
      "Epoch 1416/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.6299 - acc: 0.2144 - val_loss: 0.6928 - val_acc: 0.2004\n",
      "Epoch 1417/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2936 - acc: 0.2167 - val_loss: 0.5512 - val_acc: 0.2004\n",
      "Epoch 1418/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3113 - acc: 0.2167 - val_loss: 0.6068 - val_acc: 0.2004\n",
      "Epoch 1419/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2921 - acc: 0.2153 - val_loss: 0.7176 - val_acc: 0.2004\n",
      "Epoch 1420/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.2991 - acc: 0.2158 - val_loss: 0.7441 - val_acc: 0.1985\n",
      "Epoch 1421/4000\n",
      "68/68 [==============================] - 5s 79ms/step - loss: 0.2771 - acc: 0.2158 - val_loss: 0.6458 - val_acc: 0.2004\n",
      "Epoch 1422/4000\n",
      "68/68 [==============================] - 4s 56ms/step - loss: 0.2745 - acc: 0.2167 - val_loss: 0.6355 - val_acc: 0.2004\n",
      "Epoch 1423/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.2310 - acc: 0.2167 - val_loss: 0.6409 - val_acc: 0.1985\n",
      "Epoch 1424/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2406 - acc: 0.2167 - val_loss: 0.6211 - val_acc: 0.2004\n",
      "Epoch 1425/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2409 - acc: 0.2167 - val_loss: 0.6441 - val_acc: 0.2004\n",
      "Epoch 1426/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2536 - acc: 0.2172 - val_loss: 0.9356 - val_acc: 0.2004\n",
      "Epoch 1427/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2966 - acc: 0.2139 - val_loss: 0.6957 - val_acc: 0.1985\n",
      "Epoch 1428/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2402 - acc: 0.2158 - val_loss: 0.6244 - val_acc: 0.2004\n",
      "Epoch 1429/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.2287 - acc: 0.2158 - val_loss: 0.6401 - val_acc: 0.2004\n",
      "Epoch 1430/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2317 - acc: 0.2167 - val_loss: 0.6672 - val_acc: 0.2004\n",
      "Epoch 1431/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2598 - acc: 0.2158 - val_loss: 0.8328 - val_acc: 0.1985\n",
      "Epoch 1432/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2505 - acc: 0.2153 - val_loss: 0.6328 - val_acc: 0.2004\n",
      "Epoch 1433/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2521 - acc: 0.2153 - val_loss: 0.6376 - val_acc: 0.2004\n",
      "Epoch 1434/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2561 - acc: 0.2172 - val_loss: 0.6523 - val_acc: 0.2004\n",
      "Epoch 1435/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2398 - acc: 0.2153 - val_loss: 0.6465 - val_acc: 0.2004\n",
      "Epoch 1436/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2557 - acc: 0.2158 - val_loss: 0.6061 - val_acc: 0.2004\n",
      "Epoch 1437/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2360 - acc: 0.2162 - val_loss: 0.7014 - val_acc: 0.1985\n",
      "Epoch 1438/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2388 - acc: 0.2158 - val_loss: 0.6229 - val_acc: 0.2004\n",
      "Epoch 1439/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2358 - acc: 0.2162 - val_loss: 0.6598 - val_acc: 0.1985\n",
      "Epoch 1440/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2367 - acc: 0.2162 - val_loss: 0.6841 - val_acc: 0.2004\n",
      "Epoch 1441/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2398 - acc: 0.2162 - val_loss: 0.6421 - val_acc: 0.2004\n",
      "Epoch 1442/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2555 - acc: 0.2158 - val_loss: 0.6712 - val_acc: 0.2004\n",
      "Epoch 1443/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2742 - acc: 0.2153 - val_loss: 0.6579 - val_acc: 0.1985\n",
      "Epoch 1444/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2439 - acc: 0.2167 - val_loss: 0.6568 - val_acc: 0.1985\n",
      "Epoch 1445/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2836 - acc: 0.2144 - val_loss: 0.7343 - val_acc: 0.1985\n",
      "Epoch 1446/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2679 - acc: 0.2153 - val_loss: 0.6436 - val_acc: 0.1985\n",
      "Epoch 1447/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2699 - acc: 0.2167 - val_loss: 0.6568 - val_acc: 0.2004\n",
      "Epoch 1448/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2523 - acc: 0.2158 - val_loss: 0.6699 - val_acc: 0.1985\n",
      "Epoch 1449/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2329 - acc: 0.2158 - val_loss: 0.6324 - val_acc: 0.2004\n",
      "Epoch 1450/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2427 - acc: 0.2148 - val_loss: 0.6961 - val_acc: 0.1985\n",
      "Epoch 1451/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2569 - acc: 0.2153 - val_loss: 0.6776 - val_acc: 0.2004\n",
      "Epoch 1452/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2446 - acc: 0.2167 - val_loss: 0.6419 - val_acc: 0.1985\n",
      "Epoch 1453/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2371 - acc: 0.2158 - val_loss: 0.7885 - val_acc: 0.1985\n",
      "Epoch 1454/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2455 - acc: 0.2148 - val_loss: 0.7693 - val_acc: 0.2004\n",
      "Epoch 1455/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2368 - acc: 0.2158 - val_loss: 0.6438 - val_acc: 0.2004\n",
      "Epoch 1456/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2564 - acc: 0.2162 - val_loss: 0.6920 - val_acc: 0.1985\n",
      "Epoch 1457/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2371 - acc: 0.2158 - val_loss: 0.6661 - val_acc: 0.2004\n",
      "Epoch 1458/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2319 - acc: 0.2153 - val_loss: 0.6146 - val_acc: 0.2004\n",
      "Epoch 1459/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2334 - acc: 0.2162 - val_loss: 0.6307 - val_acc: 0.2004\n",
      "Epoch 1460/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2437 - acc: 0.2162 - val_loss: 0.8556 - val_acc: 0.1985\n",
      "Epoch 1461/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2526 - acc: 0.2158 - val_loss: 0.7629 - val_acc: 0.1985\n",
      "Epoch 1462/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2520 - acc: 0.2158 - val_loss: 0.6719 - val_acc: 0.2004\n",
      "Epoch 1463/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2862 - acc: 0.2144 - val_loss: 0.6491 - val_acc: 0.2004\n",
      "Epoch 1464/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2421 - acc: 0.2162 - val_loss: 0.7552 - val_acc: 0.2004\n",
      "Epoch 1465/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2419 - acc: 0.2167 - val_loss: 0.5999 - val_acc: 0.2004\n",
      "Epoch 1466/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2590 - acc: 0.2158 - val_loss: 0.6726 - val_acc: 0.2004\n",
      "Epoch 1467/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2423 - acc: 0.2158 - val_loss: 0.6879 - val_acc: 0.2004\n",
      "Epoch 1468/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2552 - acc: 0.2167 - val_loss: 0.6876 - val_acc: 0.2004\n",
      "Epoch 1469/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2636 - acc: 0.2153 - val_loss: 0.6338 - val_acc: 0.2004\n",
      "Epoch 1470/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2542 - acc: 0.2148 - val_loss: 0.6702 - val_acc: 0.2004\n",
      "Epoch 1471/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2356 - acc: 0.2167 - val_loss: 0.6906 - val_acc: 0.2004\n",
      "Epoch 1472/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2518 - acc: 0.2158 - val_loss: 0.6471 - val_acc: 0.2004\n",
      "Epoch 1473/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2751 - acc: 0.2158 - val_loss: 0.6460 - val_acc: 0.1985\n",
      "Epoch 1474/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2589 - acc: 0.2158 - val_loss: 0.6726 - val_acc: 0.2004\n",
      "Epoch 1475/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2301 - acc: 0.2162 - val_loss: 0.6595 - val_acc: 0.2004\n",
      "Epoch 1476/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2467 - acc: 0.2148 - val_loss: 0.6706 - val_acc: 0.2004\n",
      "Epoch 1477/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2500 - acc: 0.2153 - val_loss: 0.6912 - val_acc: 0.2004\n",
      "Epoch 1478/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2425 - acc: 0.2167 - val_loss: 0.6255 - val_acc: 0.2004\n",
      "Epoch 1479/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2464 - acc: 0.2158 - val_loss: 0.6288 - val_acc: 0.2004\n",
      "Epoch 1480/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2294 - acc: 0.2162 - val_loss: 0.6313 - val_acc: 0.1985\n",
      "Epoch 1481/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2659 - acc: 0.2158 - val_loss: 0.8924 - val_acc: 0.1985\n",
      "Epoch 1482/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3077 - acc: 0.2158 - val_loss: 0.6578 - val_acc: 0.2004\n",
      "Epoch 1483/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2337 - acc: 0.2158 - val_loss: 0.6292 - val_acc: 0.2004\n",
      "Epoch 1484/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2852 - acc: 0.2158 - val_loss: 0.7179 - val_acc: 0.2004\n",
      "Epoch 1485/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2650 - acc: 0.2153 - val_loss: 0.5706 - val_acc: 0.2004\n",
      "Epoch 1486/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2616 - acc: 0.2158 - val_loss: 0.7212 - val_acc: 0.2004\n",
      "Epoch 1487/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3332 - acc: 0.2158 - val_loss: 0.6956 - val_acc: 0.2004\n",
      "Epoch 1488/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3699 - acc: 0.2162 - val_loss: 0.9549 - val_acc: 0.2004\n",
      "Epoch 1489/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3848 - acc: 0.2148 - val_loss: 0.8226 - val_acc: 0.2004\n",
      "Epoch 1490/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.5162 - acc: 0.2162 - val_loss: 0.6801 - val_acc: 0.2004\n",
      "Epoch 1491/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2822 - acc: 0.2167 - val_loss: 0.7770 - val_acc: 0.2004\n",
      "Epoch 1492/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.5244 - acc: 0.2135 - val_loss: 0.7541 - val_acc: 0.2004\n",
      "Epoch 1493/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3562 - acc: 0.2158 - val_loss: 0.6288 - val_acc: 0.2004\n",
      "Epoch 1494/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.2482 - acc: 0.2162 - val_loss: 0.6120 - val_acc: 0.2004\n",
      "Epoch 1495/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2317 - acc: 0.2167 - val_loss: 0.6518 - val_acc: 0.1985\n",
      "Epoch 1496/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2550 - acc: 0.2162 - val_loss: 0.6230 - val_acc: 0.2004\n",
      "Epoch 1497/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2399 - acc: 0.2167 - val_loss: 0.6084 - val_acc: 0.2004\n",
      "Epoch 1498/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2581 - acc: 0.2153 - val_loss: 0.6176 - val_acc: 0.1985\n",
      "Epoch 1499/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2479 - acc: 0.2153 - val_loss: 0.7581 - val_acc: 0.1985\n",
      "Epoch 1500/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2566 - acc: 0.2167 - val_loss: 0.6435 - val_acc: 0.2004\n",
      "Epoch 1501/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.2256 - acc: 0.2167 - val_loss: 0.6187 - val_acc: 0.2004\n",
      "Epoch 1502/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.2272 - acc: 0.2158 - val_loss: 0.6243 - val_acc: 0.2004\n",
      "Epoch 1503/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2312 - acc: 0.2158 - val_loss: 0.6082 - val_acc: 0.2004\n",
      "Epoch 1504/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2297 - acc: 0.2158 - val_loss: 0.6860 - val_acc: 0.2004\n",
      "Epoch 1505/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2726 - acc: 0.2158 - val_loss: 0.6084 - val_acc: 0.2004\n",
      "Epoch 1506/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2311 - acc: 0.2158 - val_loss: 0.6821 - val_acc: 0.2004\n",
      "Epoch 1507/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2305 - acc: 0.2158 - val_loss: 0.6180 - val_acc: 0.1985\n",
      "Epoch 1508/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2321 - acc: 0.2158 - val_loss: 0.6268 - val_acc: 0.2004\n",
      "Epoch 1509/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2770 - acc: 0.2158 - val_loss: 0.6517 - val_acc: 0.1985\n",
      "Epoch 1510/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2802 - acc: 0.2158 - val_loss: 0.6105 - val_acc: 0.2004\n",
      "Epoch 1511/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2410 - acc: 0.2167 - val_loss: 0.6446 - val_acc: 0.1985\n",
      "Epoch 1512/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2247 - acc: 0.2167 - val_loss: 0.6314 - val_acc: 0.1985\n",
      "Epoch 1513/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2396 - acc: 0.2162 - val_loss: 0.6040 - val_acc: 0.2004\n",
      "Epoch 1514/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2636 - acc: 0.2153 - val_loss: 0.6138 - val_acc: 0.2004\n",
      "Epoch 1515/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2459 - acc: 0.2158 - val_loss: 0.6475 - val_acc: 0.2004\n",
      "Epoch 1516/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2396 - acc: 0.2167 - val_loss: 0.7109 - val_acc: 0.2004\n",
      "Epoch 1517/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2334 - acc: 0.2162 - val_loss: 0.6379 - val_acc: 0.2004\n",
      "Epoch 1518/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2316 - acc: 0.2167 - val_loss: 0.6220 - val_acc: 0.2004\n",
      "Epoch 1519/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2324 - acc: 0.2162 - val_loss: 0.6036 - val_acc: 0.2004\n",
      "Epoch 1520/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2249 - acc: 0.2158 - val_loss: 0.6431 - val_acc: 0.1985\n",
      "Epoch 1521/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2328 - acc: 0.2162 - val_loss: 0.6504 - val_acc: 0.1985\n",
      "Epoch 1522/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2254 - acc: 0.2167 - val_loss: 0.6182 - val_acc: 0.2004\n",
      "Epoch 1523/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2410 - acc: 0.2162 - val_loss: 0.6381 - val_acc: 0.1985\n",
      "Epoch 1524/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2504 - acc: 0.2158 - val_loss: 0.6617 - val_acc: 0.2004\n",
      "Epoch 1525/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2330 - acc: 0.2153 - val_loss: 0.6769 - val_acc: 0.1985\n",
      "Epoch 1526/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2419 - acc: 0.2167 - val_loss: 0.6224 - val_acc: 0.2004\n",
      "Epoch 1527/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2332 - acc: 0.2162 - val_loss: 0.5964 - val_acc: 0.2004\n",
      "Epoch 1528/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2315 - acc: 0.2158 - val_loss: 0.6709 - val_acc: 0.2004\n",
      "Epoch 1529/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2388 - acc: 0.2158 - val_loss: 0.6151 - val_acc: 0.2004\n",
      "Epoch 1530/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2328 - acc: 0.2153 - val_loss: 0.6630 - val_acc: 0.2004\n",
      "Epoch 1531/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2544 - acc: 0.2148 - val_loss: 0.6369 - val_acc: 0.1985\n",
      "Epoch 1532/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2849 - acc: 0.2158 - val_loss: 0.8568 - val_acc: 0.1985\n",
      "Epoch 1533/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3029 - acc: 0.2153 - val_loss: 0.6301 - val_acc: 0.2004\n",
      "Epoch 1534/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2567 - acc: 0.2162 - val_loss: 0.7862 - val_acc: 0.1985\n",
      "Epoch 1535/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2698 - acc: 0.2153 - val_loss: 0.6201 - val_acc: 0.2004\n",
      "Epoch 1536/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2344 - acc: 0.2162 - val_loss: 0.6500 - val_acc: 0.2004\n",
      "Epoch 1537/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2853 - acc: 0.2153 - val_loss: 0.6226 - val_acc: 0.2004\n",
      "Epoch 1538/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2653 - acc: 0.2139 - val_loss: 0.6365 - val_acc: 0.1985\n",
      "Epoch 1539/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2590 - acc: 0.2153 - val_loss: 0.6164 - val_acc: 0.1985\n",
      "Epoch 1540/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2390 - acc: 0.2153 - val_loss: 0.6542 - val_acc: 0.2004\n",
      "Epoch 1541/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2418 - acc: 0.2153 - val_loss: 1.0066 - val_acc: 0.1948\n",
      "Epoch 1542/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2509 - acc: 0.2148 - val_loss: 0.6468 - val_acc: 0.2004\n",
      "Epoch 1543/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2530 - acc: 0.2144 - val_loss: 0.7362 - val_acc: 0.1985\n",
      "Epoch 1544/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2467 - acc: 0.2162 - val_loss: 0.6234 - val_acc: 0.2004\n",
      "Epoch 1545/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2219 - acc: 0.2158 - val_loss: 0.6518 - val_acc: 0.1985\n",
      "Epoch 1546/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2438 - acc: 0.2172 - val_loss: 0.6225 - val_acc: 0.2004\n",
      "Epoch 1547/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2578 - acc: 0.2153 - val_loss: 0.9249 - val_acc: 0.1985\n",
      "Epoch 1548/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2597 - acc: 0.2148 - val_loss: 0.6777 - val_acc: 0.1985\n",
      "Epoch 1549/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2434 - acc: 0.2162 - val_loss: 0.6301 - val_acc: 0.2004\n",
      "Epoch 1550/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2537 - acc: 0.2148 - val_loss: 0.7345 - val_acc: 0.1985\n",
      "Epoch 1551/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2673 - acc: 0.2139 - val_loss: 0.6400 - val_acc: 0.1985\n",
      "Epoch 1552/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2415 - acc: 0.2167 - val_loss: 0.6227 - val_acc: 0.2004\n",
      "Epoch 1553/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2396 - acc: 0.2153 - val_loss: 0.6724 - val_acc: 0.2004\n",
      "Epoch 1554/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2408 - acc: 0.2158 - val_loss: 0.6997 - val_acc: 0.1985\n",
      "Epoch 1555/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2270 - acc: 0.2153 - val_loss: 0.6271 - val_acc: 0.2004\n",
      "Epoch 1556/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2232 - acc: 0.2162 - val_loss: 0.6175 - val_acc: 0.2004\n",
      "Epoch 1557/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2294 - acc: 0.2148 - val_loss: 0.6144 - val_acc: 0.2004\n",
      "Epoch 1558/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2352 - acc: 0.2158 - val_loss: 0.6142 - val_acc: 0.1985\n",
      "Epoch 1559/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2407 - acc: 0.2158 - val_loss: 0.6332 - val_acc: 0.2004\n",
      "Epoch 1560/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2396 - acc: 0.2148 - val_loss: 0.6226 - val_acc: 0.1985\n",
      "Epoch 1561/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2345 - acc: 0.2158 - val_loss: 0.6432 - val_acc: 0.2004\n",
      "Epoch 1562/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2402 - acc: 0.2158 - val_loss: 0.6513 - val_acc: 0.1985\n",
      "Epoch 1563/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2675 - acc: 0.2162 - val_loss: 0.6678 - val_acc: 0.2004\n",
      "Epoch 1564/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2492 - acc: 0.2148 - val_loss: 0.6890 - val_acc: 0.1985\n",
      "Epoch 1565/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2448 - acc: 0.2158 - val_loss: 0.6425 - val_acc: 0.2004\n",
      "Epoch 1566/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2355 - acc: 0.2167 - val_loss: 0.7183 - val_acc: 0.2004\n",
      "Epoch 1567/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2375 - acc: 0.2167 - val_loss: 0.6290 - val_acc: 0.2004\n",
      "Epoch 1568/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2635 - acc: 0.2153 - val_loss: 0.7854 - val_acc: 0.2004\n",
      "Epoch 1569/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2328 - acc: 0.2167 - val_loss: 0.6837 - val_acc: 0.1985\n",
      "Epoch 1570/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2379 - acc: 0.2158 - val_loss: 0.8073 - val_acc: 0.1985\n",
      "Epoch 1571/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2564 - acc: 0.2153 - val_loss: 0.7411 - val_acc: 0.2004\n",
      "Epoch 1572/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.4372 - acc: 0.2144 - val_loss: 0.8641 - val_acc: 0.2004\n",
      "Epoch 1573/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3751 - acc: 0.2158 - val_loss: 0.6802 - val_acc: 0.2004\n",
      "Epoch 1574/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.8688 - acc: 0.2130 - val_loss: 0.6984 - val_acc: 0.2004\n",
      "Epoch 1575/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4331 - acc: 0.2144 - val_loss: 0.6458 - val_acc: 0.2004\n",
      "Epoch 1576/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3411 - acc: 0.2167 - val_loss: 0.7507 - val_acc: 0.2004\n",
      "Epoch 1577/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2836 - acc: 0.2158 - val_loss: 0.5991 - val_acc: 0.2004\n",
      "Epoch 1578/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2340 - acc: 0.2158 - val_loss: 0.6419 - val_acc: 0.2004\n",
      "Epoch 1579/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2314 - acc: 0.2158 - val_loss: 0.6564 - val_acc: 0.1985\n",
      "Epoch 1580/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2353 - acc: 0.2153 - val_loss: 0.6312 - val_acc: 0.1985\n",
      "Epoch 1581/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.2329 - acc: 0.2167 - val_loss: 0.6396 - val_acc: 0.1985\n",
      "Epoch 1582/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.2220 - acc: 0.2158 - val_loss: 0.6846 - val_acc: 0.2004\n",
      "Epoch 1583/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2416 - acc: 0.2158 - val_loss: 0.6275 - val_acc: 0.2004\n",
      "Epoch 1584/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2252 - acc: 0.2153 - val_loss: 0.6365 - val_acc: 0.1985\n",
      "Epoch 1585/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2266 - acc: 0.2162 - val_loss: 0.6819 - val_acc: 0.1985\n",
      "Epoch 1586/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2523 - acc: 0.2158 - val_loss: 0.6384 - val_acc: 0.2004\n",
      "Epoch 1587/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2352 - acc: 0.2158 - val_loss: 0.6195 - val_acc: 0.2004\n",
      "Epoch 1588/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2246 - acc: 0.2162 - val_loss: 0.6854 - val_acc: 0.1985\n",
      "Epoch 1589/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2225 - acc: 0.2162 - val_loss: 0.6213 - val_acc: 0.2004\n",
      "Epoch 1590/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2378 - acc: 0.2162 - val_loss: 0.6203 - val_acc: 0.2004\n",
      "Epoch 1591/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2436 - acc: 0.2162 - val_loss: 0.6608 - val_acc: 0.1985\n",
      "Epoch 1592/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2298 - acc: 0.2158 - val_loss: 0.7036 - val_acc: 0.2004\n",
      "Epoch 1593/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2711 - acc: 0.2162 - val_loss: 0.6817 - val_acc: 0.1985\n",
      "Epoch 1594/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2319 - acc: 0.2162 - val_loss: 0.6184 - val_acc: 0.2004\n",
      "Epoch 1595/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2172 - acc: 0.2158 - val_loss: 0.6591 - val_acc: 0.2004\n",
      "Epoch 1596/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2227 - acc: 0.2162 - val_loss: 0.6157 - val_acc: 0.2004\n",
      "Epoch 1597/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2251 - acc: 0.2167 - val_loss: 0.6464 - val_acc: 0.1985\n",
      "Epoch 1598/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2460 - acc: 0.2162 - val_loss: 0.7065 - val_acc: 0.1985\n",
      "Epoch 1599/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2390 - acc: 0.2162 - val_loss: 0.7888 - val_acc: 0.2004\n",
      "Epoch 1600/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2249 - acc: 0.2162 - val_loss: 0.6315 - val_acc: 0.2004\n",
      "Epoch 1601/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2247 - acc: 0.2172 - val_loss: 0.6544 - val_acc: 0.1985\n",
      "Epoch 1602/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2323 - acc: 0.2148 - val_loss: 0.6549 - val_acc: 0.2004\n",
      "Epoch 1603/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2544 - acc: 0.2158 - val_loss: 0.6367 - val_acc: 0.2004\n",
      "Epoch 1604/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2276 - acc: 0.2153 - val_loss: 0.6043 - val_acc: 0.2004\n",
      "Epoch 1605/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2521 - acc: 0.2153 - val_loss: 0.8246 - val_acc: 0.1985\n",
      "Epoch 1606/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2456 - acc: 0.2153 - val_loss: 0.6602 - val_acc: 0.2004\n",
      "Epoch 1607/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2280 - acc: 0.2167 - val_loss: 0.6272 - val_acc: 0.2004\n",
      "Epoch 1608/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3019 - acc: 0.2139 - val_loss: 0.6573 - val_acc: 0.1985\n",
      "Epoch 1609/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2500 - acc: 0.2148 - val_loss: 0.6121 - val_acc: 0.2004\n",
      "Epoch 1610/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2648 - acc: 0.2148 - val_loss: 0.7706 - val_acc: 0.1985\n",
      "Epoch 1611/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2430 - acc: 0.2167 - val_loss: 0.6719 - val_acc: 0.1985\n",
      "Epoch 1612/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2395 - acc: 0.2158 - val_loss: 0.6207 - val_acc: 0.2004\n",
      "Epoch 1613/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2436 - acc: 0.2162 - val_loss: 0.6214 - val_acc: 0.2004\n",
      "Epoch 1614/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2529 - acc: 0.2162 - val_loss: 0.6373 - val_acc: 0.1985\n",
      "Epoch 1615/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2330 - acc: 0.2153 - val_loss: 0.6110 - val_acc: 0.2004\n",
      "Epoch 1616/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2287 - acc: 0.2167 - val_loss: 0.5881 - val_acc: 0.2004\n",
      "Epoch 1617/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2441 - acc: 0.2153 - val_loss: 0.6697 - val_acc: 0.1985\n",
      "Epoch 1618/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2463 - acc: 0.2153 - val_loss: 0.6676 - val_acc: 0.1985\n",
      "Epoch 1619/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2426 - acc: 0.2148 - val_loss: 0.6436 - val_acc: 0.2004\n",
      "Epoch 1620/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2193 - acc: 0.2158 - val_loss: 0.6113 - val_acc: 0.2004\n",
      "Epoch 1621/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2162 - acc: 0.2158 - val_loss: 0.6471 - val_acc: 0.1985\n",
      "Epoch 1622/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2331 - acc: 0.2139 - val_loss: 0.6559 - val_acc: 0.2004\n",
      "Epoch 1623/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2306 - acc: 0.2167 - val_loss: 0.6482 - val_acc: 0.2004\n",
      "Epoch 1624/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2311 - acc: 0.2148 - val_loss: 0.6180 - val_acc: 0.2004\n",
      "Epoch 1625/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.2223 - acc: 0.2153 - val_loss: 0.6312 - val_acc: 0.1985\n",
      "Epoch 1626/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.2269 - acc: 0.2167 - val_loss: 0.6821 - val_acc: 0.1985\n",
      "Epoch 1627/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2499 - acc: 0.2158 - val_loss: 0.6216 - val_acc: 0.2004\n",
      "Epoch 1628/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2282 - acc: 0.2158 - val_loss: 0.6237 - val_acc: 0.2004\n",
      "Epoch 1629/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2305 - acc: 0.2153 - val_loss: 0.6301 - val_acc: 0.2004\n",
      "Epoch 1630/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2297 - acc: 0.2144 - val_loss: 0.6245 - val_acc: 0.2004\n",
      "Epoch 1631/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2742 - acc: 0.2139 - val_loss: 0.6829 - val_acc: 0.1985\n",
      "Epoch 1632/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2351 - acc: 0.2158 - val_loss: 0.6467 - val_acc: 0.1985\n",
      "Epoch 1633/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2402 - acc: 0.2144 - val_loss: 0.7156 - val_acc: 0.1985\n",
      "Epoch 1634/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2624 - acc: 0.2158 - val_loss: 0.6485 - val_acc: 0.1985\n",
      "Epoch 1635/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2312 - acc: 0.2148 - val_loss: 0.6760 - val_acc: 0.2004\n",
      "Epoch 1636/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2290 - acc: 0.2153 - val_loss: 0.6923 - val_acc: 0.1985\n",
      "Epoch 1637/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2424 - acc: 0.2144 - val_loss: 0.7144 - val_acc: 0.2004\n",
      "Epoch 1638/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2498 - acc: 0.2144 - val_loss: 0.6199 - val_acc: 0.2004\n",
      "Epoch 1639/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2392 - acc: 0.2162 - val_loss: 0.6236 - val_acc: 0.2004\n",
      "Epoch 1640/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2347 - acc: 0.2167 - val_loss: 0.6484 - val_acc: 0.2004\n",
      "Epoch 1641/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2378 - acc: 0.2167 - val_loss: 0.6197 - val_acc: 0.2004\n",
      "Epoch 1642/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2278 - acc: 0.2162 - val_loss: 0.6950 - val_acc: 0.2004\n",
      "Epoch 1643/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2352 - acc: 0.2148 - val_loss: 0.6304 - val_acc: 0.2004\n",
      "Epoch 1644/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2542 - acc: 0.2148 - val_loss: 0.6435 - val_acc: 0.1985\n",
      "Epoch 1645/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2269 - acc: 0.2153 - val_loss: 0.6231 - val_acc: 0.1985\n",
      "Epoch 1646/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2467 - acc: 0.2162 - val_loss: 0.5907 - val_acc: 0.2004\n",
      "Epoch 1647/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2308 - acc: 0.2158 - val_loss: 0.6488 - val_acc: 0.1985\n",
      "Epoch 1648/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2341 - acc: 0.2153 - val_loss: 0.6278 - val_acc: 0.2004\n",
      "Epoch 1649/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2263 - acc: 0.2158 - val_loss: 0.8529 - val_acc: 0.1985\n",
      "Epoch 1650/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2481 - acc: 0.2148 - val_loss: 0.7125 - val_acc: 0.2004\n",
      "Epoch 1651/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2541 - acc: 0.2153 - val_loss: 0.6273 - val_acc: 0.2004\n",
      "Epoch 1652/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2611 - acc: 0.2158 - val_loss: 0.8156 - val_acc: 0.1985\n",
      "Epoch 1653/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2569 - acc: 0.2148 - val_loss: 0.6516 - val_acc: 0.2004\n",
      "Epoch 1654/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2481 - acc: 0.2162 - val_loss: 0.6768 - val_acc: 0.1985\n",
      "Epoch 1655/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2344 - acc: 0.2162 - val_loss: 0.6405 - val_acc: 0.2004\n",
      "Epoch 1656/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2282 - acc: 0.2162 - val_loss: 0.6313 - val_acc: 0.1985\n",
      "Epoch 1657/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2295 - acc: 0.2162 - val_loss: 0.6356 - val_acc: 0.2004\n",
      "Epoch 1658/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2454 - acc: 0.2158 - val_loss: 0.6590 - val_acc: 0.2004\n",
      "Epoch 1659/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2508 - acc: 0.2158 - val_loss: 0.6274 - val_acc: 0.2004\n",
      "Epoch 1660/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2577 - acc: 0.2158 - val_loss: 0.6132 - val_acc: 0.2004\n",
      "Epoch 1661/4000\n",
      "68/68 [==============================] - 5s 72ms/step - loss: 0.2317 - acc: 0.2158 - val_loss: 0.7486 - val_acc: 0.1985\n",
      "Epoch 1662/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2880 - acc: 0.2158 - val_loss: 0.6211 - val_acc: 0.2004\n",
      "Epoch 1663/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2339 - acc: 0.2158 - val_loss: 0.6440 - val_acc: 0.2004\n",
      "Epoch 1664/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2335 - acc: 0.2167 - val_loss: 0.5805 - val_acc: 0.2004\n",
      "Epoch 1665/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.2747 - acc: 0.2167 - val_loss: 1.0310 - val_acc: 0.2004\n",
      "Epoch 1666/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4013 - acc: 0.2144 - val_loss: 0.9459 - val_acc: 0.1911\n",
      "Epoch 1667/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4028 - acc: 0.2139 - val_loss: 0.8517 - val_acc: 0.1985\n",
      "Epoch 1668/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 1.2213 - acc: 0.2079 - val_loss: 1.3772 - val_acc: 0.1800\n",
      "Epoch 1669/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 1.7662 - acc: 0.1981 - val_loss: 0.7787 - val_acc: 0.1985\n",
      "Epoch 1670/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.3553 - acc: 0.2162 - val_loss: 0.5666 - val_acc: 0.2004\n",
      "Epoch 1671/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3429 - acc: 0.2162 - val_loss: 0.6487 - val_acc: 0.2004\n",
      "Epoch 1672/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2612 - acc: 0.2162 - val_loss: 0.5896 - val_acc: 0.2004\n",
      "Epoch 1673/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2263 - acc: 0.2172 - val_loss: 0.6003 - val_acc: 0.1985\n",
      "Epoch 1674/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2223 - acc: 0.2162 - val_loss: 0.6149 - val_acc: 0.2004\n",
      "Epoch 1675/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2197 - acc: 0.2153 - val_loss: 0.6720 - val_acc: 0.2004\n",
      "Epoch 1676/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2153 - acc: 0.2162 - val_loss: 0.6546 - val_acc: 0.2004\n",
      "Epoch 1677/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2255 - acc: 0.2153 - val_loss: 0.6125 - val_acc: 0.1985\n",
      "Epoch 1678/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2355 - acc: 0.2162 - val_loss: 0.7213 - val_acc: 0.1985\n",
      "Epoch 1679/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2193 - acc: 0.2162 - val_loss: 0.6062 - val_acc: 0.2004\n",
      "Epoch 1680/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2148 - acc: 0.2158 - val_loss: 0.6082 - val_acc: 0.2004\n",
      "Epoch 1681/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2155 - acc: 0.2162 - val_loss: 0.6144 - val_acc: 0.2004\n",
      "Epoch 1682/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2115 - acc: 0.2162 - val_loss: 0.6194 - val_acc: 0.2004\n",
      "Epoch 1683/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2197 - acc: 0.2162 - val_loss: 0.6150 - val_acc: 0.2004\n",
      "Epoch 1684/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2112 - acc: 0.2162 - val_loss: 0.6690 - val_acc: 0.2004\n",
      "Epoch 1685/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2228 - acc: 0.2162 - val_loss: 0.6417 - val_acc: 0.2004\n",
      "Epoch 1686/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2402 - acc: 0.2167 - val_loss: 0.6288 - val_acc: 0.1985\n",
      "Epoch 1687/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2187 - acc: 0.2162 - val_loss: 0.6506 - val_acc: 0.1985\n",
      "Epoch 1688/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2280 - acc: 0.2148 - val_loss: 0.6027 - val_acc: 0.2004\n",
      "Epoch 1689/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2162 - acc: 0.2167 - val_loss: 0.6897 - val_acc: 0.2004\n",
      "Epoch 1690/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2255 - acc: 0.2167 - val_loss: 0.6316 - val_acc: 0.1985\n",
      "Epoch 1691/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2370 - acc: 0.2158 - val_loss: 0.6237 - val_acc: 0.2004\n",
      "Epoch 1692/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2314 - acc: 0.2148 - val_loss: 0.6314 - val_acc: 0.2004\n",
      "Epoch 1693/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2387 - acc: 0.2162 - val_loss: 0.6107 - val_acc: 0.2004\n",
      "Epoch 1694/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2367 - acc: 0.2148 - val_loss: 0.6122 - val_acc: 0.2004\n",
      "Epoch 1695/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2262 - acc: 0.2172 - val_loss: 0.6300 - val_acc: 0.1985\n",
      "Epoch 1696/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2358 - acc: 0.2158 - val_loss: 0.6130 - val_acc: 0.2004\n",
      "Epoch 1697/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2505 - acc: 0.2158 - val_loss: 0.6218 - val_acc: 0.1985\n",
      "Epoch 1698/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2229 - acc: 0.2153 - val_loss: 0.6149 - val_acc: 0.2004\n",
      "Epoch 1699/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2308 - acc: 0.2172 - val_loss: 0.6093 - val_acc: 0.2004\n",
      "Epoch 1700/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2286 - acc: 0.2167 - val_loss: 0.7240 - val_acc: 0.1985\n",
      "Epoch 1701/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2484 - acc: 0.2162 - val_loss: 0.6259 - val_acc: 0.2004\n",
      "Epoch 1702/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2308 - acc: 0.2158 - val_loss: 0.6762 - val_acc: 0.2004\n",
      "Epoch 1703/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2782 - acc: 0.2144 - val_loss: 0.6094 - val_acc: 0.2004\n",
      "Epoch 1704/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2490 - acc: 0.2162 - val_loss: 0.5950 - val_acc: 0.2004\n",
      "Epoch 1705/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2235 - acc: 0.2158 - val_loss: 0.6130 - val_acc: 0.2004\n",
      "Epoch 1706/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2225 - acc: 0.2162 - val_loss: 0.6318 - val_acc: 0.2004\n",
      "Epoch 1707/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2263 - acc: 0.2153 - val_loss: 0.6106 - val_acc: 0.2004\n",
      "Epoch 1708/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2345 - acc: 0.2167 - val_loss: 0.6078 - val_acc: 0.2004\n",
      "Epoch 1709/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2284 - acc: 0.2153 - val_loss: 0.6207 - val_acc: 0.2004\n",
      "Epoch 1710/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2261 - acc: 0.2167 - val_loss: 0.6267 - val_acc: 0.2004\n",
      "Epoch 1711/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2384 - acc: 0.2162 - val_loss: 0.5934 - val_acc: 0.2004\n",
      "Epoch 1712/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2180 - acc: 0.2158 - val_loss: 0.6064 - val_acc: 0.2004\n",
      "Epoch 1713/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2156 - acc: 0.2148 - val_loss: 0.6185 - val_acc: 0.2004\n",
      "Epoch 1714/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2263 - acc: 0.2162 - val_loss: 0.7162 - val_acc: 0.2004\n",
      "Epoch 1715/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2430 - acc: 0.2153 - val_loss: 0.5954 - val_acc: 0.2004\n",
      "Epoch 1716/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2451 - acc: 0.2153 - val_loss: 0.6574 - val_acc: 0.2004\n",
      "Epoch 1717/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2250 - acc: 0.2158 - val_loss: 0.6900 - val_acc: 0.1985\n",
      "Epoch 1718/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2625 - acc: 0.2167 - val_loss: 0.5902 - val_acc: 0.2004\n",
      "Epoch 1719/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2300 - acc: 0.2162 - val_loss: 0.6231 - val_acc: 0.2004\n",
      "Epoch 1720/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2200 - acc: 0.2153 - val_loss: 0.6209 - val_acc: 0.2004\n",
      "Epoch 1721/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2156 - acc: 0.2162 - val_loss: 0.6148 - val_acc: 0.2004\n",
      "Epoch 1722/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2191 - acc: 0.2158 - val_loss: 0.6359 - val_acc: 0.2004\n",
      "Epoch 1723/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2203 - acc: 0.2158 - val_loss: 0.6004 - val_acc: 0.2004\n",
      "Epoch 1724/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2235 - acc: 0.2162 - val_loss: 0.6426 - val_acc: 0.2004\n",
      "Epoch 1725/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2390 - acc: 0.2158 - val_loss: 0.6325 - val_acc: 0.2004\n",
      "Epoch 1726/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2683 - acc: 0.2153 - val_loss: 0.6329 - val_acc: 0.2004\n",
      "Epoch 1727/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2384 - acc: 0.2158 - val_loss: 0.6444 - val_acc: 0.2004\n",
      "Epoch 1728/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2305 - acc: 0.2162 - val_loss: 0.6610 - val_acc: 0.2004\n",
      "Epoch 1729/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2436 - acc: 0.2162 - val_loss: 0.6372 - val_acc: 0.2004\n",
      "Epoch 1730/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2331 - acc: 0.2158 - val_loss: 0.6390 - val_acc: 0.2004\n",
      "Epoch 1731/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2785 - acc: 0.2148 - val_loss: 0.6762 - val_acc: 0.1985\n",
      "Epoch 1732/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2259 - acc: 0.2162 - val_loss: 0.6412 - val_acc: 0.1985\n",
      "Epoch 1733/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2521 - acc: 0.2158 - val_loss: 0.6155 - val_acc: 0.2004\n",
      "Epoch 1734/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2201 - acc: 0.2158 - val_loss: 0.6189 - val_acc: 0.2004\n",
      "Epoch 1735/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2271 - acc: 0.2158 - val_loss: 0.6077 - val_acc: 0.2004\n",
      "Epoch 1736/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2154 - acc: 0.2162 - val_loss: 0.6445 - val_acc: 0.2004\n",
      "Epoch 1737/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2405 - acc: 0.2148 - val_loss: 0.6577 - val_acc: 0.1985\n",
      "Epoch 1738/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2135 - acc: 0.2162 - val_loss: 0.6145 - val_acc: 0.2004\n",
      "Epoch 1739/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2322 - acc: 0.2153 - val_loss: 0.5915 - val_acc: 0.2004\n",
      "Epoch 1740/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2163 - acc: 0.2158 - val_loss: 0.6014 - val_acc: 0.2004\n",
      "Epoch 1741/4000\n",
      "68/68 [==============================] - 5s 71ms/step - loss: 0.2204 - acc: 0.2158 - val_loss: 0.6506 - val_acc: 0.2004\n",
      "Epoch 1742/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2339 - acc: 0.2158 - val_loss: 0.6410 - val_acc: 0.1985\n",
      "Epoch 1743/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2342 - acc: 0.2162 - val_loss: 0.5826 - val_acc: 0.2004\n",
      "Epoch 1744/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2325 - acc: 0.2158 - val_loss: 0.6535 - val_acc: 0.2004\n",
      "Epoch 1745/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2394 - acc: 0.2158 - val_loss: 0.7737 - val_acc: 0.2004\n",
      "Epoch 1746/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2362 - acc: 0.2167 - val_loss: 0.6727 - val_acc: 0.2004\n",
      "Epoch 1747/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2391 - acc: 0.2158 - val_loss: 0.7327 - val_acc: 0.2004\n",
      "Epoch 1748/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2539 - acc: 0.2158 - val_loss: 0.6696 - val_acc: 0.2004\n",
      "Epoch 1749/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2399 - acc: 0.2153 - val_loss: 0.7309 - val_acc: 0.1985\n",
      "Epoch 1750/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2290 - acc: 0.2148 - val_loss: 0.5895 - val_acc: 0.2004\n",
      "Epoch 1751/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2145 - acc: 0.2148 - val_loss: 0.6359 - val_acc: 0.2004\n",
      "Epoch 1752/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2175 - acc: 0.2158 - val_loss: 0.5994 - val_acc: 0.2004\n",
      "Epoch 1753/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2536 - acc: 0.2148 - val_loss: 0.6315 - val_acc: 0.1985\n",
      "Epoch 1754/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2645 - acc: 0.2153 - val_loss: 0.6197 - val_acc: 0.2004\n",
      "Epoch 1755/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2829 - acc: 0.2148 - val_loss: 0.6202 - val_acc: 0.1985\n",
      "Epoch 1756/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2254 - acc: 0.2162 - val_loss: 0.6174 - val_acc: 0.2004\n",
      "Epoch 1757/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2300 - acc: 0.2162 - val_loss: 0.7167 - val_acc: 0.1985\n",
      "Epoch 1758/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2374 - acc: 0.2153 - val_loss: 0.6342 - val_acc: 0.2004\n",
      "Epoch 1759/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2321 - acc: 0.2158 - val_loss: 0.8966 - val_acc: 0.2004\n",
      "Epoch 1760/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2754 - acc: 0.2144 - val_loss: 0.6475 - val_acc: 0.2004\n",
      "Epoch 1761/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2195 - acc: 0.2162 - val_loss: 0.6309 - val_acc: 0.2004\n",
      "Epoch 1762/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2573 - acc: 0.2153 - val_loss: 0.6210 - val_acc: 0.2004\n",
      "Epoch 1763/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2441 - acc: 0.2162 - val_loss: 0.9215 - val_acc: 0.1967\n",
      "Epoch 1764/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2898 - acc: 0.2162 - val_loss: 0.7003 - val_acc: 0.2004\n",
      "Epoch 1765/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2659 - acc: 0.2158 - val_loss: 0.6536 - val_acc: 0.2004\n",
      "Epoch 1766/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2536 - acc: 0.2148 - val_loss: 0.7988 - val_acc: 0.1985\n",
      "Epoch 1767/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2612 - acc: 0.2162 - val_loss: 0.7358 - val_acc: 0.2004\n",
      "Epoch 1768/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2488 - acc: 0.2162 - val_loss: 0.6250 - val_acc: 0.2004\n",
      "Epoch 1769/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2518 - acc: 0.2153 - val_loss: 0.5763 - val_acc: 0.2004\n",
      "Epoch 1770/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2357 - acc: 0.2162 - val_loss: 0.6581 - val_acc: 0.2004\n",
      "Epoch 1771/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2347 - acc: 0.2158 - val_loss: 0.5978 - val_acc: 0.2004\n",
      "Epoch 1772/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2134 - acc: 0.2158 - val_loss: 0.6537 - val_acc: 0.2004\n",
      "Epoch 1773/4000\n",
      "68/68 [==============================] - 4s 56ms/step - loss: 0.2247 - acc: 0.2162 - val_loss: 0.6009 - val_acc: 0.2004\n",
      "Epoch 1774/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2416 - acc: 0.2162 - val_loss: 0.6538 - val_acc: 0.1985\n",
      "Epoch 1775/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2393 - acc: 0.2158 - val_loss: 0.6771 - val_acc: 0.1985\n",
      "Epoch 1776/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2664 - acc: 0.2158 - val_loss: 0.6497 - val_acc: 0.1985\n",
      "Epoch 1777/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2251 - acc: 0.2158 - val_loss: 0.6781 - val_acc: 0.1985\n",
      "Epoch 1778/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2564 - acc: 0.2148 - val_loss: 0.6448 - val_acc: 0.2004\n",
      "Epoch 1779/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2451 - acc: 0.2158 - val_loss: 0.6102 - val_acc: 0.2004\n",
      "Epoch 1780/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.2257 - acc: 0.2158 - val_loss: 0.6308 - val_acc: 0.2004\n",
      "Epoch 1781/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2128 - acc: 0.2167 - val_loss: 0.6280 - val_acc: 0.2004\n",
      "Epoch 1782/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2215 - acc: 0.2167 - val_loss: 0.6801 - val_acc: 0.1985\n",
      "Epoch 1783/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2361 - acc: 0.2162 - val_loss: 0.6414 - val_acc: 0.2004\n",
      "Epoch 1784/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2301 - acc: 0.2153 - val_loss: 0.6127 - val_acc: 0.1985\n",
      "Epoch 1785/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2410 - acc: 0.2148 - val_loss: 0.6911 - val_acc: 0.1985\n",
      "Epoch 1786/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2696 - acc: 0.2130 - val_loss: 0.6054 - val_acc: 0.2004\n",
      "Epoch 1787/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2231 - acc: 0.2162 - val_loss: 0.6328 - val_acc: 0.1985\n",
      "Epoch 1788/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2125 - acc: 0.2162 - val_loss: 0.6033 - val_acc: 0.2004\n",
      "Epoch 1789/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2285 - acc: 0.2162 - val_loss: 0.7261 - val_acc: 0.1985\n",
      "Epoch 1790/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2331 - acc: 0.2148 - val_loss: 0.6869 - val_acc: 0.1985\n",
      "Epoch 1791/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2139 - acc: 0.2167 - val_loss: 0.7516 - val_acc: 0.1985\n",
      "Epoch 1792/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2629 - acc: 0.2158 - val_loss: 0.6773 - val_acc: 0.2004\n",
      "Epoch 1793/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2435 - acc: 0.2148 - val_loss: 0.5898 - val_acc: 0.1985\n",
      "Epoch 1794/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2388 - acc: 0.2162 - val_loss: 0.6134 - val_acc: 0.2004\n",
      "Epoch 1795/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2598 - acc: 0.2148 - val_loss: 0.5886 - val_acc: 0.2004\n",
      "Epoch 1796/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2674 - acc: 0.2162 - val_loss: 0.7310 - val_acc: 0.1985\n",
      "Epoch 1797/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2418 - acc: 0.2172 - val_loss: 0.6091 - val_acc: 0.1985\n",
      "Epoch 1798/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2530 - acc: 0.2162 - val_loss: 0.6623 - val_acc: 0.2004\n",
      "Epoch 1799/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2717 - acc: 0.2162 - val_loss: 0.6024 - val_acc: 0.2004\n",
      "Epoch 1800/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2373 - acc: 0.2162 - val_loss: 0.6301 - val_acc: 0.2004\n",
      "Epoch 1801/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2282 - acc: 0.2148 - val_loss: 0.6957 - val_acc: 0.2004\n",
      "Epoch 1802/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2231 - acc: 0.2158 - val_loss: 0.6124 - val_acc: 0.2004\n",
      "Epoch 1803/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2411 - acc: 0.2162 - val_loss: 0.6675 - val_acc: 0.1985\n",
      "Epoch 1804/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2363 - acc: 0.2153 - val_loss: 0.6401 - val_acc: 0.1985\n",
      "Epoch 1805/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2867 - acc: 0.2139 - val_loss: 0.8082 - val_acc: 0.2004\n",
      "Epoch 1806/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2413 - acc: 0.2153 - val_loss: 0.7106 - val_acc: 0.2004\n",
      "Epoch 1807/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2476 - acc: 0.2158 - val_loss: 0.6647 - val_acc: 0.2004\n",
      "Epoch 1808/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2438 - acc: 0.2148 - val_loss: 0.6237 - val_acc: 0.2004\n",
      "Epoch 1809/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2168 - acc: 0.2162 - val_loss: 0.6114 - val_acc: 0.2004\n",
      "Epoch 1810/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2137 - acc: 0.2162 - val_loss: 0.6547 - val_acc: 0.1985\n",
      "Epoch 1811/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2175 - acc: 0.2158 - val_loss: 0.6062 - val_acc: 0.2004\n",
      "Epoch 1812/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2233 - acc: 0.2162 - val_loss: 0.6520 - val_acc: 0.1985\n",
      "Epoch 1813/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2166 - acc: 0.2158 - val_loss: 0.6192 - val_acc: 0.2004\n",
      "Epoch 1814/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2180 - acc: 0.2153 - val_loss: 0.6665 - val_acc: 0.2004\n",
      "Epoch 1815/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2110 - acc: 0.2153 - val_loss: 0.6053 - val_acc: 0.2004\n",
      "Epoch 1816/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2469 - acc: 0.2153 - val_loss: 0.6860 - val_acc: 0.2004\n",
      "Epoch 1817/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2259 - acc: 0.2158 - val_loss: 0.6479 - val_acc: 0.1985\n",
      "Epoch 1818/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2224 - acc: 0.2153 - val_loss: 0.7493 - val_acc: 0.1985\n",
      "Epoch 1819/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2430 - acc: 0.2162 - val_loss: 0.6115 - val_acc: 0.1985\n",
      "Epoch 1820/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2417 - acc: 0.2144 - val_loss: 0.6371 - val_acc: 0.2004\n",
      "Epoch 1821/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 0.2255 - acc: 0.2158 - val_loss: 0.7031 - val_acc: 0.1985\n",
      "Epoch 1822/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.2450 - acc: 0.2167 - val_loss: 0.6470 - val_acc: 0.2004\n",
      "Epoch 1823/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2179 - acc: 0.2158 - val_loss: 0.6592 - val_acc: 0.1985\n",
      "Epoch 1824/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2137 - acc: 0.2153 - val_loss: 0.6248 - val_acc: 0.2004\n",
      "Epoch 1825/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2434 - acc: 0.2162 - val_loss: 0.6158 - val_acc: 0.2004\n",
      "Epoch 1826/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2261 - acc: 0.2162 - val_loss: 0.6355 - val_acc: 0.2004\n",
      "Epoch 1827/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2340 - acc: 0.2158 - val_loss: 0.6263 - val_acc: 0.2004\n",
      "Epoch 1828/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2327 - acc: 0.2148 - val_loss: 0.7102 - val_acc: 0.1985\n",
      "Epoch 1829/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2329 - acc: 0.2158 - val_loss: 0.6177 - val_acc: 0.2004\n",
      "Epoch 1830/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2276 - acc: 0.2162 - val_loss: 0.6448 - val_acc: 0.2004\n",
      "Epoch 1831/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2793 - acc: 0.2144 - val_loss: 0.7210 - val_acc: 0.2004\n",
      "Epoch 1832/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2137 - acc: 0.2153 - val_loss: 0.6189 - val_acc: 0.1985\n",
      "Epoch 1833/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.2069 - acc: 0.2158 - val_loss: 0.6216 - val_acc: 0.2004\n",
      "Epoch 1834/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2160 - acc: 0.2162 - val_loss: 0.6384 - val_acc: 0.1985\n",
      "Epoch 1835/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2508 - acc: 0.2153 - val_loss: 1.0292 - val_acc: 0.2004\n",
      "Epoch 1836/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2404 - acc: 0.2148 - val_loss: 0.6474 - val_acc: 0.2004\n",
      "Epoch 1837/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2733 - acc: 0.2153 - val_loss: 0.6946 - val_acc: 0.2004\n",
      "Epoch 1838/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2524 - acc: 0.2153 - val_loss: 0.6513 - val_acc: 0.2004\n",
      "Epoch 1839/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2297 - acc: 0.2162 - val_loss: 0.6254 - val_acc: 0.2004\n",
      "Epoch 1840/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3164 - acc: 0.2148 - val_loss: 0.6697 - val_acc: 0.2004\n",
      "Epoch 1841/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2477 - acc: 0.2153 - val_loss: 0.7516 - val_acc: 0.1985\n",
      "Epoch 1842/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2428 - acc: 0.2162 - val_loss: 0.6866 - val_acc: 0.2004\n",
      "Epoch 1843/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2619 - acc: 0.2144 - val_loss: 0.7745 - val_acc: 0.2004\n",
      "Epoch 1844/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2791 - acc: 0.2153 - val_loss: 0.6246 - val_acc: 0.1985\n",
      "Epoch 1845/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2959 - acc: 0.2162 - val_loss: 0.7742 - val_acc: 0.2004\n",
      "Epoch 1846/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2304 - acc: 0.2158 - val_loss: 0.5997 - val_acc: 0.1985\n",
      "Epoch 1847/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2291 - acc: 0.2158 - val_loss: 0.6994 - val_acc: 0.2004\n",
      "Epoch 1848/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2248 - acc: 0.2167 - val_loss: 0.6372 - val_acc: 0.2004\n",
      "Epoch 1849/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2431 - acc: 0.2148 - val_loss: 0.6352 - val_acc: 0.2004\n",
      "Epoch 1850/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2247 - acc: 0.2158 - val_loss: 0.6177 - val_acc: 0.1985\n",
      "Epoch 1851/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2216 - acc: 0.2167 - val_loss: 0.6251 - val_acc: 0.2004\n",
      "Epoch 1852/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2385 - acc: 0.2158 - val_loss: 0.6200 - val_acc: 0.2004\n",
      "Epoch 1853/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2191 - acc: 0.2153 - val_loss: 0.6257 - val_acc: 0.1985\n",
      "Epoch 1854/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2141 - acc: 0.2158 - val_loss: 0.5957 - val_acc: 0.2004\n",
      "Epoch 1855/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2136 - acc: 0.2153 - val_loss: 0.6145 - val_acc: 0.2004\n",
      "Epoch 1856/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2130 - acc: 0.2162 - val_loss: 0.6292 - val_acc: 0.1985\n",
      "Epoch 1857/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2217 - acc: 0.2158 - val_loss: 0.6314 - val_acc: 0.2004\n",
      "Epoch 1858/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2186 - acc: 0.2162 - val_loss: 0.6079 - val_acc: 0.2004\n",
      "Epoch 1859/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2242 - acc: 0.2148 - val_loss: 0.6241 - val_acc: 0.2004\n",
      "Epoch 1860/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2198 - acc: 0.2158 - val_loss: 0.6375 - val_acc: 0.2004\n",
      "Epoch 1861/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2353 - acc: 0.2158 - val_loss: 0.6154 - val_acc: 0.2004\n",
      "Epoch 1862/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2202 - acc: 0.2148 - val_loss: 0.6933 - val_acc: 0.2004\n",
      "Epoch 1863/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2466 - acc: 0.2153 - val_loss: 0.6318 - val_acc: 0.2004\n",
      "Epoch 1864/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2190 - acc: 0.2153 - val_loss: 0.7019 - val_acc: 0.2004\n",
      "Epoch 1865/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2954 - acc: 0.2130 - val_loss: 0.6448 - val_acc: 0.2004\n",
      "Epoch 1866/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2059 - acc: 0.2162 - val_loss: 0.6837 - val_acc: 0.1985\n",
      "Epoch 1867/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2294 - acc: 0.2153 - val_loss: 0.6241 - val_acc: 0.2004\n",
      "Epoch 1868/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2269 - acc: 0.2144 - val_loss: 0.7343 - val_acc: 0.2004\n",
      "Epoch 1869/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2219 - acc: 0.2158 - val_loss: 0.6306 - val_acc: 0.2004\n",
      "Epoch 1870/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2180 - acc: 0.2148 - val_loss: 0.6182 - val_acc: 0.2004\n",
      "Epoch 1871/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2293 - acc: 0.2158 - val_loss: 0.6747 - val_acc: 0.1985\n",
      "Epoch 1872/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2187 - acc: 0.2158 - val_loss: 0.6696 - val_acc: 0.2004\n",
      "Epoch 1873/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2202 - acc: 0.2153 - val_loss: 0.6116 - val_acc: 0.1985\n",
      "Epoch 1874/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2521 - acc: 0.2162 - val_loss: 0.6076 - val_acc: 0.2004\n",
      "Epoch 1875/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2399 - acc: 0.2172 - val_loss: 0.6633 - val_acc: 0.2004\n",
      "Epoch 1876/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2291 - acc: 0.2167 - val_loss: 0.7252 - val_acc: 0.2004\n",
      "Epoch 1877/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2277 - acc: 0.2158 - val_loss: 0.6286 - val_acc: 0.2004\n",
      "Epoch 1878/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2346 - acc: 0.2158 - val_loss: 0.6157 - val_acc: 0.2004\n",
      "Epoch 1879/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2098 - acc: 0.2158 - val_loss: 0.6467 - val_acc: 0.1985\n",
      "Epoch 1880/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2361 - acc: 0.2153 - val_loss: 0.6779 - val_acc: 0.2004\n",
      "Epoch 1881/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2338 - acc: 0.2148 - val_loss: 0.7785 - val_acc: 0.2004\n",
      "Epoch 1882/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2153 - acc: 0.2162 - val_loss: 0.6231 - val_acc: 0.2004\n",
      "Epoch 1883/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2295 - acc: 0.2148 - val_loss: 0.6348 - val_acc: 0.1985\n",
      "Epoch 1884/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2227 - acc: 0.2148 - val_loss: 0.6440 - val_acc: 0.1985\n",
      "Epoch 1885/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2090 - acc: 0.2172 - val_loss: 0.6513 - val_acc: 0.2004\n",
      "Epoch 1886/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2134 - acc: 0.2158 - val_loss: 0.6253 - val_acc: 0.1985\n",
      "Epoch 1887/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2299 - acc: 0.2158 - val_loss: 0.6113 - val_acc: 0.2004\n",
      "Epoch 1888/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2271 - acc: 0.2139 - val_loss: 0.6414 - val_acc: 0.1985\n",
      "Epoch 1889/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2392 - acc: 0.2153 - val_loss: 0.6189 - val_acc: 0.2004\n",
      "Epoch 1890/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2687 - acc: 0.2153 - val_loss: 0.6236 - val_acc: 0.2004\n",
      "Epoch 1891/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2165 - acc: 0.2158 - val_loss: 0.6366 - val_acc: 0.2004\n",
      "Epoch 1892/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2061 - acc: 0.2158 - val_loss: 0.6648 - val_acc: 0.2004\n",
      "Epoch 1893/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2535 - acc: 0.2148 - val_loss: 0.6184 - val_acc: 0.2004\n",
      "Epoch 1894/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2120 - acc: 0.2162 - val_loss: 0.6105 - val_acc: 0.2004\n",
      "Epoch 1895/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2301 - acc: 0.2158 - val_loss: 0.5978 - val_acc: 0.2004\n",
      "Epoch 1896/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2199 - acc: 0.2144 - val_loss: 0.6338 - val_acc: 0.2004\n",
      "Epoch 1897/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2316 - acc: 0.2158 - val_loss: 0.6994 - val_acc: 0.1985\n",
      "Epoch 1898/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2581 - acc: 0.2172 - val_loss: 0.5964 - val_acc: 0.2004\n",
      "Epoch 1899/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2455 - acc: 0.2162 - val_loss: 0.5956 - val_acc: 0.2004\n",
      "Epoch 1900/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2470 - acc: 0.2158 - val_loss: 0.6852 - val_acc: 0.2004\n",
      "Epoch 1901/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2765 - acc: 0.2158 - val_loss: 0.6793 - val_acc: 0.2004\n",
      "Epoch 1902/4000\n",
      "68/68 [==============================] - 5s 71ms/step - loss: 0.2551 - acc: 0.2158 - val_loss: 0.6345 - val_acc: 0.1985\n",
      "Epoch 1903/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3829 - acc: 0.2148 - val_loss: 0.6445 - val_acc: 0.2004\n",
      "Epoch 1904/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3336 - acc: 0.2162 - val_loss: 0.6168 - val_acc: 0.2004\n",
      "Epoch 1905/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2420 - acc: 0.2158 - val_loss: 0.6410 - val_acc: 0.2004\n",
      "Epoch 1906/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3357 - acc: 0.2167 - val_loss: 0.7215 - val_acc: 0.2004\n",
      "Epoch 1907/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.5517 - acc: 0.2144 - val_loss: 1.0086 - val_acc: 0.1985\n",
      "Epoch 1908/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.9497 - acc: 0.2042 - val_loss: 0.8520 - val_acc: 0.2004\n",
      "Epoch 1909/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.3244 - acc: 0.2153 - val_loss: 0.5691 - val_acc: 0.2004\n",
      "Epoch 1910/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.4330 - acc: 0.2162 - val_loss: 0.5770 - val_acc: 0.2004\n",
      "Epoch 1911/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2750 - acc: 0.2167 - val_loss: 0.6538 - val_acc: 0.2004\n",
      "Epoch 1912/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2245 - acc: 0.2162 - val_loss: 0.5566 - val_acc: 0.2004\n",
      "Epoch 1913/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2160 - acc: 0.2162 - val_loss: 0.5963 - val_acc: 0.2004\n",
      "Epoch 1914/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2228 - acc: 0.2162 - val_loss: 0.6658 - val_acc: 0.1985\n",
      "Epoch 1915/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2119 - acc: 0.2153 - val_loss: 0.5968 - val_acc: 0.2004\n",
      "Epoch 1916/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2411 - acc: 0.2153 - val_loss: 0.5842 - val_acc: 0.2004\n",
      "Epoch 1917/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2054 - acc: 0.2162 - val_loss: 0.6001 - val_acc: 0.2004\n",
      "Epoch 1918/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2109 - acc: 0.2158 - val_loss: 0.6672 - val_acc: 0.1985\n",
      "Epoch 1919/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2345 - acc: 0.2153 - val_loss: 0.6627 - val_acc: 0.1985\n",
      "Epoch 1920/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2119 - acc: 0.2162 - val_loss: 0.6288 - val_acc: 0.1985\n",
      "Epoch 1921/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2376 - acc: 0.2153 - val_loss: 0.7072 - val_acc: 0.2004\n",
      "Epoch 1922/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2210 - acc: 0.2153 - val_loss: 0.6333 - val_acc: 0.1985\n",
      "Epoch 1923/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2183 - acc: 0.2158 - val_loss: 0.5946 - val_acc: 0.2004\n",
      "Epoch 1924/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2046 - acc: 0.2153 - val_loss: 0.5777 - val_acc: 0.2004\n",
      "Epoch 1925/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2244 - acc: 0.2158 - val_loss: 0.6536 - val_acc: 0.2004\n",
      "Epoch 1926/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2170 - acc: 0.2158 - val_loss: 0.6502 - val_acc: 0.2004\n",
      "Epoch 1927/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2357 - acc: 0.2162 - val_loss: 0.5999 - val_acc: 0.2004\n",
      "Epoch 1928/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2225 - acc: 0.2158 - val_loss: 0.6120 - val_acc: 0.2004\n",
      "Epoch 1929/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2346 - acc: 0.2144 - val_loss: 0.5893 - val_acc: 0.2004\n",
      "Epoch 1930/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2119 - acc: 0.2158 - val_loss: 0.5774 - val_acc: 0.2004\n",
      "Epoch 1931/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2226 - acc: 0.2158 - val_loss: 0.6140 - val_acc: 0.2004\n",
      "Epoch 1932/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2138 - acc: 0.2144 - val_loss: 0.7311 - val_acc: 0.2004\n",
      "Epoch 1933/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2164 - acc: 0.2162 - val_loss: 0.5975 - val_acc: 0.2004\n",
      "Epoch 1934/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2225 - acc: 0.2148 - val_loss: 0.5896 - val_acc: 0.2004\n",
      "Epoch 1935/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2656 - acc: 0.2148 - val_loss: 0.7262 - val_acc: 0.1985\n",
      "Epoch 1936/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2424 - acc: 0.2162 - val_loss: 0.6064 - val_acc: 0.2004\n",
      "Epoch 1937/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2110 - acc: 0.2162 - val_loss: 0.5694 - val_acc: 0.2004\n",
      "Epoch 1938/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2552 - acc: 0.2162 - val_loss: 0.6112 - val_acc: 0.2004\n",
      "Epoch 1939/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2415 - acc: 0.2153 - val_loss: 0.6000 - val_acc: 0.2004\n",
      "Epoch 1940/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2470 - acc: 0.2148 - val_loss: 0.6405 - val_acc: 0.2004\n",
      "Epoch 1941/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2201 - acc: 0.2162 - val_loss: 0.6180 - val_acc: 0.2004\n",
      "Epoch 1942/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2100 - acc: 0.2162 - val_loss: 0.5761 - val_acc: 0.2004\n",
      "Epoch 1943/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2078 - acc: 0.2153 - val_loss: 0.6256 - val_acc: 0.2004\n",
      "Epoch 1944/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2109 - acc: 0.2148 - val_loss: 0.5885 - val_acc: 0.2004\n",
      "Epoch 1945/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2323 - acc: 0.2153 - val_loss: 0.7677 - val_acc: 0.1985\n",
      "Epoch 1946/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2497 - acc: 0.2158 - val_loss: 0.6300 - val_acc: 0.2004\n",
      "Epoch 1947/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2248 - acc: 0.2158 - val_loss: 0.6097 - val_acc: 0.2004\n",
      "Epoch 1948/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2073 - acc: 0.2162 - val_loss: 0.6122 - val_acc: 0.2004\n",
      "Epoch 1949/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2187 - acc: 0.2153 - val_loss: 0.5957 - val_acc: 0.2004\n",
      "Epoch 1950/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2527 - acc: 0.2144 - val_loss: 0.6826 - val_acc: 0.2004\n",
      "Epoch 1951/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2131 - acc: 0.2162 - val_loss: 0.6388 - val_acc: 0.1985\n",
      "Epoch 1952/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2110 - acc: 0.2153 - val_loss: 0.6355 - val_acc: 0.2004\n",
      "Epoch 1953/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2284 - acc: 0.2153 - val_loss: 0.6545 - val_acc: 0.2004\n",
      "Epoch 1954/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2103 - acc: 0.2153 - val_loss: 0.6898 - val_acc: 0.2004\n",
      "Epoch 1955/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2185 - acc: 0.2148 - val_loss: 0.6402 - val_acc: 0.2004\n",
      "Epoch 1956/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2283 - acc: 0.2158 - val_loss: 0.6718 - val_acc: 0.1985\n",
      "Epoch 1957/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2231 - acc: 0.2158 - val_loss: 0.6294 - val_acc: 0.2004\n",
      "Epoch 1958/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2268 - acc: 0.2139 - val_loss: 0.5907 - val_acc: 0.2004\n",
      "Epoch 1959/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2132 - acc: 0.2158 - val_loss: 0.6345 - val_acc: 0.2004\n",
      "Epoch 1960/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2209 - acc: 0.2158 - val_loss: 0.6379 - val_acc: 0.2004\n",
      "Epoch 1961/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2470 - acc: 0.2148 - val_loss: 0.6357 - val_acc: 0.2004\n",
      "Epoch 1962/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2121 - acc: 0.2148 - val_loss: 0.5839 - val_acc: 0.2004\n",
      "Epoch 1963/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2542 - acc: 0.2153 - val_loss: 0.6632 - val_acc: 0.1985\n",
      "Epoch 1964/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2190 - acc: 0.2162 - val_loss: 0.6598 - val_acc: 0.2004\n",
      "Epoch 1965/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2051 - acc: 0.2162 - val_loss: 0.6280 - val_acc: 0.2004\n",
      "Epoch 1966/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2381 - acc: 0.2162 - val_loss: 0.6301 - val_acc: 0.2004\n",
      "Epoch 1967/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.2075 - acc: 0.2148 - val_loss: 0.6083 - val_acc: 0.2004\n",
      "Epoch 1968/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2045 - acc: 0.2148 - val_loss: 0.6689 - val_acc: 0.1985\n",
      "Epoch 1969/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2211 - acc: 0.2153 - val_loss: 0.6008 - val_acc: 0.2004\n",
      "Epoch 1970/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2118 - acc: 0.2153 - val_loss: 0.6422 - val_acc: 0.2004\n",
      "Epoch 1971/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2154 - acc: 0.2153 - val_loss: 0.7122 - val_acc: 0.2004\n",
      "Epoch 1972/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2401 - acc: 0.2158 - val_loss: 0.6121 - val_acc: 0.2004\n",
      "Epoch 1973/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2389 - acc: 0.2158 - val_loss: 0.5966 - val_acc: 0.2004\n",
      "Epoch 1974/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2094 - acc: 0.2153 - val_loss: 0.6204 - val_acc: 0.2004\n",
      "Epoch 1975/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2118 - acc: 0.2153 - val_loss: 0.7090 - val_acc: 0.1985\n",
      "Epoch 1976/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2265 - acc: 0.2148 - val_loss: 0.6661 - val_acc: 0.2004\n",
      "Epoch 1977/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2243 - acc: 0.2158 - val_loss: 0.7121 - val_acc: 0.1985\n",
      "Epoch 1978/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2452 - acc: 0.2158 - val_loss: 0.6757 - val_acc: 0.1985\n",
      "Epoch 1979/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2421 - acc: 0.2162 - val_loss: 0.7928 - val_acc: 0.1985\n",
      "Epoch 1980/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2165 - acc: 0.2158 - val_loss: 0.6388 - val_acc: 0.2004\n",
      "Epoch 1981/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2303 - acc: 0.2153 - val_loss: 0.6269 - val_acc: 0.2004\n",
      "Epoch 1982/4000\n",
      "68/68 [==============================] - 5s 71ms/step - loss: 0.2188 - acc: 0.2153 - val_loss: 0.6538 - val_acc: 0.1985\n",
      "Epoch 1983/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.2189 - acc: 0.2162 - val_loss: 0.6050 - val_acc: 0.2004\n",
      "Epoch 1984/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2161 - acc: 0.2162 - val_loss: 0.5864 - val_acc: 0.2004\n",
      "Epoch 1985/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2081 - acc: 0.2162 - val_loss: 0.6129 - val_acc: 0.2004\n",
      "Epoch 1986/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2144 - acc: 0.2153 - val_loss: 0.6111 - val_acc: 0.2004\n",
      "Epoch 1987/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2092 - acc: 0.2162 - val_loss: 0.6649 - val_acc: 0.1985\n",
      "Epoch 1988/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2364 - acc: 0.2158 - val_loss: 0.7066 - val_acc: 0.1985\n",
      "Epoch 1989/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2423 - acc: 0.2158 - val_loss: 0.9450 - val_acc: 0.2004\n",
      "Epoch 1990/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2516 - acc: 0.2158 - val_loss: 0.5935 - val_acc: 0.2004\n",
      "Epoch 1991/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2079 - acc: 0.2167 - val_loss: 0.6461 - val_acc: 0.1985\n",
      "Epoch 1992/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2232 - acc: 0.2158 - val_loss: 0.6621 - val_acc: 0.1985\n",
      "Epoch 1993/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2137 - acc: 0.2158 - val_loss: 0.5823 - val_acc: 0.2004\n",
      "Epoch 1994/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2131 - acc: 0.2148 - val_loss: 0.6417 - val_acc: 0.2004\n",
      "Epoch 1995/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2062 - acc: 0.2162 - val_loss: 0.6181 - val_acc: 0.2004\n",
      "Epoch 1996/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2184 - acc: 0.2153 - val_loss: 0.6391 - val_acc: 0.2004\n",
      "Epoch 1997/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2142 - acc: 0.2158 - val_loss: 0.5830 - val_acc: 0.2004\n",
      "Epoch 1998/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2216 - acc: 0.2158 - val_loss: 0.6244 - val_acc: 0.2004\n",
      "Epoch 1999/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2197 - acc: 0.2158 - val_loss: 0.7190 - val_acc: 0.1985\n",
      "Epoch 2000/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2350 - acc: 0.2148 - val_loss: 0.5881 - val_acc: 0.2004\n",
      "Epoch 2001/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2125 - acc: 0.2153 - val_loss: 0.6239 - val_acc: 0.2004\n",
      "Epoch 2002/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2364 - acc: 0.2158 - val_loss: 0.5571 - val_acc: 0.2004\n",
      "Epoch 2003/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2862 - acc: 0.2144 - val_loss: 0.5832 - val_acc: 0.2004\n",
      "Epoch 2004/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2203 - acc: 0.2158 - val_loss: 0.6364 - val_acc: 0.2004\n",
      "Epoch 2005/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2047 - acc: 0.2162 - val_loss: 0.6170 - val_acc: 0.2004\n",
      "Epoch 2006/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2196 - acc: 0.2139 - val_loss: 0.6046 - val_acc: 0.2004\n",
      "Epoch 2007/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2176 - acc: 0.2158 - val_loss: 0.6320 - val_acc: 0.1985\n",
      "Epoch 2008/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2082 - acc: 0.2158 - val_loss: 0.5722 - val_acc: 0.2004\n",
      "Epoch 2009/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2161 - acc: 0.2162 - val_loss: 0.7060 - val_acc: 0.2004\n",
      "Epoch 2010/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2393 - acc: 0.2158 - val_loss: 0.6873 - val_acc: 0.2004\n",
      "Epoch 2011/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2751 - acc: 0.2153 - val_loss: 0.7837 - val_acc: 0.2004\n",
      "Epoch 2012/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2495 - acc: 0.2144 - val_loss: 0.6557 - val_acc: 0.1985\n",
      "Epoch 2013/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2260 - acc: 0.2153 - val_loss: 0.5794 - val_acc: 0.1985\n",
      "Epoch 2014/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2314 - acc: 0.2139 - val_loss: 0.6426 - val_acc: 0.1985\n",
      "Epoch 2015/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2532 - acc: 0.2153 - val_loss: 0.6759 - val_acc: 0.2004\n",
      "Epoch 2016/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2389 - acc: 0.2158 - val_loss: 0.9177 - val_acc: 0.2004\n",
      "Epoch 2017/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.4476 - acc: 0.2144 - val_loss: 0.6156 - val_acc: 0.1985\n",
      "Epoch 2018/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2427 - acc: 0.2158 - val_loss: 0.6459 - val_acc: 0.2004\n",
      "Epoch 2019/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2643 - acc: 0.2158 - val_loss: 0.7044 - val_acc: 0.1985\n",
      "Epoch 2020/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2694 - acc: 0.2148 - val_loss: 0.6995 - val_acc: 0.2004\n",
      "Epoch 2021/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2399 - acc: 0.2162 - val_loss: 0.5837 - val_acc: 0.2004\n",
      "Epoch 2022/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2202 - acc: 0.2153 - val_loss: 0.6284 - val_acc: 0.2004\n",
      "Epoch 2023/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2165 - acc: 0.2158 - val_loss: 0.7190 - val_acc: 0.1985\n",
      "Epoch 2024/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2204 - acc: 0.2153 - val_loss: 0.6319 - val_acc: 0.1985\n",
      "Epoch 2025/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2046 - acc: 0.2153 - val_loss: 0.6214 - val_acc: 0.2004\n",
      "Epoch 2026/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2223 - acc: 0.2148 - val_loss: 0.5970 - val_acc: 0.2004\n",
      "Epoch 2027/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2141 - acc: 0.2153 - val_loss: 0.6120 - val_acc: 0.2004\n",
      "Epoch 2028/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2175 - acc: 0.2153 - val_loss: 0.6288 - val_acc: 0.1985\n",
      "Epoch 2029/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2180 - acc: 0.2153 - val_loss: 0.6016 - val_acc: 0.2004\n",
      "Epoch 2030/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1998 - acc: 0.2162 - val_loss: 0.6332 - val_acc: 0.2004\n",
      "Epoch 2031/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2285 - acc: 0.2153 - val_loss: 0.6180 - val_acc: 0.2004\n",
      "Epoch 2032/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2176 - acc: 0.2144 - val_loss: 0.6086 - val_acc: 0.2004\n",
      "Epoch 2033/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2118 - acc: 0.2158 - val_loss: 0.6583 - val_acc: 0.1985\n",
      "Epoch 2034/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1990 - acc: 0.2158 - val_loss: 0.6717 - val_acc: 0.2004\n",
      "Epoch 2035/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2036 - acc: 0.2153 - val_loss: 0.6513 - val_acc: 0.1985\n",
      "Epoch 2036/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2144 - acc: 0.2162 - val_loss: 0.6353 - val_acc: 0.2004\n",
      "Epoch 2037/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2358 - acc: 0.2144 - val_loss: 0.5696 - val_acc: 0.2004\n",
      "Epoch 2038/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2160 - acc: 0.2158 - val_loss: 0.5968 - val_acc: 0.2004\n",
      "Epoch 2039/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2391 - acc: 0.2153 - val_loss: 0.6247 - val_acc: 0.2004\n",
      "Epoch 2040/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2159 - acc: 0.2167 - val_loss: 0.6138 - val_acc: 0.2004\n",
      "Epoch 2041/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2035 - acc: 0.2162 - val_loss: 0.5975 - val_acc: 0.2004\n",
      "Epoch 2042/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2073 - acc: 0.2158 - val_loss: 0.5922 - val_acc: 0.2004\n",
      "Epoch 2043/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2141 - acc: 0.2148 - val_loss: 0.6029 - val_acc: 0.2004\n",
      "Epoch 2044/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2138 - acc: 0.2167 - val_loss: 0.5815 - val_acc: 0.2004\n",
      "Epoch 2045/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2164 - acc: 0.2153 - val_loss: 0.6227 - val_acc: 0.2004\n",
      "Epoch 2046/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2107 - acc: 0.2153 - val_loss: 0.6324 - val_acc: 0.1985\n",
      "Epoch 2047/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2137 - acc: 0.2167 - val_loss: 0.6026 - val_acc: 0.2004\n",
      "Epoch 2048/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2386 - acc: 0.2148 - val_loss: 0.7104 - val_acc: 0.2004\n",
      "Epoch 2049/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2304 - acc: 0.2153 - val_loss: 0.6474 - val_acc: 0.2004\n",
      "Epoch 2050/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2044 - acc: 0.2158 - val_loss: 0.6208 - val_acc: 0.2004\n",
      "Epoch 2051/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2102 - acc: 0.2167 - val_loss: 0.6187 - val_acc: 0.2004\n",
      "Epoch 2052/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2039 - acc: 0.2153 - val_loss: 0.6526 - val_acc: 0.2004\n",
      "Epoch 2053/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2045 - acc: 0.2158 - val_loss: 0.5912 - val_acc: 0.1985\n",
      "Epoch 2054/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2050 - acc: 0.2153 - val_loss: 0.8788 - val_acc: 0.1948\n",
      "Epoch 2055/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2337 - acc: 0.2153 - val_loss: 0.6542 - val_acc: 0.2004\n",
      "Epoch 2056/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2051 - acc: 0.2158 - val_loss: 0.6188 - val_acc: 0.2004\n",
      "Epoch 2057/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2102 - acc: 0.2158 - val_loss: 0.6091 - val_acc: 0.2004\n",
      "Epoch 2058/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2150 - acc: 0.2158 - val_loss: 0.6272 - val_acc: 0.1985\n",
      "Epoch 2059/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2199 - acc: 0.2158 - val_loss: 0.6360 - val_acc: 0.1985\n",
      "Epoch 2060/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2371 - acc: 0.2144 - val_loss: 0.6829 - val_acc: 0.2004\n",
      "Epoch 2061/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2174 - acc: 0.2153 - val_loss: 0.6705 - val_acc: 0.2004\n",
      "Epoch 2062/4000\n",
      "68/68 [==============================] - 5s 72ms/step - loss: 0.2274 - acc: 0.2162 - val_loss: 0.5695 - val_acc: 0.2004\n",
      "Epoch 2063/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2199 - acc: 0.2158 - val_loss: 0.6186 - val_acc: 0.2004\n",
      "Epoch 2064/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2307 - acc: 0.2144 - val_loss: 0.6256 - val_acc: 0.2004\n",
      "Epoch 2065/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2275 - acc: 0.2162 - val_loss: 0.6154 - val_acc: 0.2004\n",
      "Epoch 2066/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2211 - acc: 0.2162 - val_loss: 0.7041 - val_acc: 0.1985\n",
      "Epoch 2067/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2214 - acc: 0.2167 - val_loss: 0.6162 - val_acc: 0.2004\n",
      "Epoch 2068/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2075 - acc: 0.2158 - val_loss: 0.6457 - val_acc: 0.1985\n",
      "Epoch 2069/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2164 - acc: 0.2162 - val_loss: 0.6133 - val_acc: 0.2004\n",
      "Epoch 2070/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2476 - acc: 0.2144 - val_loss: 0.6375 - val_acc: 0.2004\n",
      "Epoch 2071/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2207 - acc: 0.2162 - val_loss: 0.7171 - val_acc: 0.2004\n",
      "Epoch 2072/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2120 - acc: 0.2153 - val_loss: 0.6296 - val_acc: 0.2004\n",
      "Epoch 2073/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2163 - acc: 0.2162 - val_loss: 0.6283 - val_acc: 0.1985\n",
      "Epoch 2074/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2295 - acc: 0.2158 - val_loss: 0.6286 - val_acc: 0.2004\n",
      "Epoch 2075/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2048 - acc: 0.2158 - val_loss: 0.6028 - val_acc: 0.2004\n",
      "Epoch 2076/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2073 - acc: 0.2158 - val_loss: 0.6337 - val_acc: 0.1985\n",
      "Epoch 2077/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2261 - acc: 0.2148 - val_loss: 0.5775 - val_acc: 0.2004\n",
      "Epoch 2078/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2543 - acc: 0.2153 - val_loss: 0.6792 - val_acc: 0.2004\n",
      "Epoch 2079/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2223 - acc: 0.2158 - val_loss: 0.5842 - val_acc: 0.2004\n",
      "Epoch 2080/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2253 - acc: 0.2158 - val_loss: 0.6666 - val_acc: 0.2004\n",
      "Epoch 2081/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2280 - acc: 0.2148 - val_loss: 0.5945 - val_acc: 0.2004\n",
      "Epoch 2082/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2289 - acc: 0.2158 - val_loss: 0.7677 - val_acc: 0.1985\n",
      "Epoch 2083/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2467 - acc: 0.2158 - val_loss: 0.9359 - val_acc: 0.1874\n",
      "Epoch 2084/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2517 - acc: 0.2153 - val_loss: 0.6908 - val_acc: 0.2004\n",
      "Epoch 2085/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2435 - acc: 0.2158 - val_loss: 0.8330 - val_acc: 0.1985\n",
      "Epoch 2086/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.4329 - acc: 0.2088 - val_loss: 0.6808 - val_acc: 0.1985\n",
      "Epoch 2087/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3791 - acc: 0.2144 - val_loss: 0.6104 - val_acc: 0.2004\n",
      "Epoch 2088/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3034 - acc: 0.2153 - val_loss: 0.6589 - val_acc: 0.2004\n",
      "Epoch 2089/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2683 - acc: 0.2162 - val_loss: 0.5917 - val_acc: 0.1985\n",
      "Epoch 2090/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2095 - acc: 0.2158 - val_loss: 0.6217 - val_acc: 0.2004\n",
      "Epoch 2091/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2112 - acc: 0.2148 - val_loss: 0.6047 - val_acc: 0.2004\n",
      "Epoch 2092/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2280 - acc: 0.2158 - val_loss: 0.6745 - val_acc: 0.2004\n",
      "Epoch 2093/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2578 - acc: 0.2158 - val_loss: 0.5964 - val_acc: 0.2004\n",
      "Epoch 2094/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2236 - acc: 0.2162 - val_loss: 0.6208 - val_acc: 0.2004\n",
      "Epoch 2095/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2255 - acc: 0.2158 - val_loss: 0.6209 - val_acc: 0.2004\n",
      "Epoch 2096/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2193 - acc: 0.2162 - val_loss: 0.7645 - val_acc: 0.1985\n",
      "Epoch 2097/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2070 - acc: 0.2153 - val_loss: 0.6054 - val_acc: 0.2004\n",
      "Epoch 2098/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2123 - acc: 0.2158 - val_loss: 0.6065 - val_acc: 0.2004\n",
      "Epoch 2099/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1994 - acc: 0.2153 - val_loss: 0.6036 - val_acc: 0.2004\n",
      "Epoch 2100/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2061 - acc: 0.2148 - val_loss: 0.5986 - val_acc: 0.2004\n",
      "Epoch 2101/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2114 - acc: 0.2162 - val_loss: 0.5876 - val_acc: 0.2004\n",
      "Epoch 2102/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2048 - acc: 0.2167 - val_loss: 0.6437 - val_acc: 0.1985\n",
      "Epoch 2103/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2146 - acc: 0.2148 - val_loss: 0.9027 - val_acc: 0.2004\n",
      "Epoch 2104/4000\n",
      "68/68 [==============================] - 5s 75ms/step - loss: 0.2437 - acc: 0.2158 - val_loss: 0.6196 - val_acc: 0.1985\n",
      "Epoch 2105/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2296 - acc: 0.2158 - val_loss: 0.6770 - val_acc: 0.2004\n",
      "Epoch 2106/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2445 - acc: 0.2144 - val_loss: 0.5994 - val_acc: 0.2004\n",
      "Epoch 2107/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2125 - acc: 0.2162 - val_loss: 0.6041 - val_acc: 0.2004\n",
      "Epoch 2108/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2108 - acc: 0.2162 - val_loss: 0.5813 - val_acc: 0.2004\n",
      "Epoch 2109/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1975 - acc: 0.2158 - val_loss: 0.6262 - val_acc: 0.2004\n",
      "Epoch 2110/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2061 - acc: 0.2153 - val_loss: 0.6276 - val_acc: 0.1985\n",
      "Epoch 2111/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2093 - acc: 0.2158 - val_loss: 0.5939 - val_acc: 0.2004\n",
      "Epoch 2112/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2036 - acc: 0.2153 - val_loss: 0.5904 - val_acc: 0.2004\n",
      "Epoch 2113/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2714 - acc: 0.2148 - val_loss: 0.6241 - val_acc: 0.2004\n",
      "Epoch 2114/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1985 - acc: 0.2162 - val_loss: 0.6049 - val_acc: 0.1985\n",
      "Epoch 2115/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1990 - acc: 0.2162 - val_loss: 0.6230 - val_acc: 0.2004\n",
      "Epoch 2116/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2098 - acc: 0.2158 - val_loss: 0.6119 - val_acc: 0.2004\n",
      "Epoch 2117/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2172 - acc: 0.2153 - val_loss: 0.6927 - val_acc: 0.2004\n",
      "Epoch 2118/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2407 - acc: 0.2153 - val_loss: 0.5871 - val_acc: 0.2004\n",
      "Epoch 2119/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.1985 - acc: 0.2158 - val_loss: 0.6165 - val_acc: 0.2004\n",
      "Epoch 2120/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2299 - acc: 0.2153 - val_loss: 0.6662 - val_acc: 0.1985\n",
      "Epoch 2121/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2189 - acc: 0.2153 - val_loss: 0.6020 - val_acc: 0.2004\n",
      "Epoch 2122/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2074 - acc: 0.2148 - val_loss: 0.6116 - val_acc: 0.2004\n",
      "Epoch 2123/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.2058 - acc: 0.2158 - val_loss: 0.6437 - val_acc: 0.2004\n",
      "Epoch 2124/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2241 - acc: 0.2158 - val_loss: 0.9606 - val_acc: 0.2004\n",
      "Epoch 2125/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.2416 - acc: 0.2148 - val_loss: 0.6040 - val_acc: 0.2004\n",
      "Epoch 2126/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2197 - acc: 0.2162 - val_loss: 0.6061 - val_acc: 0.2004\n",
      "Epoch 2127/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2159 - acc: 0.2158 - val_loss: 0.6566 - val_acc: 0.2004\n",
      "Epoch 2128/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2213 - acc: 0.2144 - val_loss: 0.6823 - val_acc: 0.1985\n",
      "Epoch 2129/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2056 - acc: 0.2158 - val_loss: 0.6570 - val_acc: 0.1985\n",
      "Epoch 2130/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2408 - acc: 0.2158 - val_loss: 0.7459 - val_acc: 0.1985\n",
      "Epoch 2131/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.2681 - acc: 0.2162 - val_loss: 0.6536 - val_acc: 0.2004\n",
      "Epoch 2132/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.6129 - acc: 0.2139 - val_loss: 0.9806 - val_acc: 0.1985\n",
      "Epoch 2133/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.6062 - acc: 0.2144 - val_loss: 1.1861 - val_acc: 0.2004\n",
      "Epoch 2134/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.9698 - acc: 0.2060 - val_loss: 0.6640 - val_acc: 0.2004\n",
      "Epoch 2135/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2309 - acc: 0.2162 - val_loss: 0.6014 - val_acc: 0.2004\n",
      "Epoch 2136/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2227 - acc: 0.2158 - val_loss: 0.6023 - val_acc: 0.2004\n",
      "Epoch 2137/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2119 - acc: 0.2158 - val_loss: 0.5502 - val_acc: 0.2004\n",
      "Epoch 2138/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2198 - acc: 0.2148 - val_loss: 0.6177 - val_acc: 0.1985\n",
      "Epoch 2139/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2016 - acc: 0.2167 - val_loss: 0.5840 - val_acc: 0.2004\n",
      "Epoch 2140/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2030 - acc: 0.2158 - val_loss: 0.5817 - val_acc: 0.2004\n",
      "Epoch 2141/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1997 - acc: 0.2158 - val_loss: 0.5742 - val_acc: 0.2004\n",
      "Epoch 2142/4000\n",
      "68/68 [==============================] - 5s 69ms/step - loss: 0.2069 - acc: 0.2153 - val_loss: 0.5873 - val_acc: 0.2004\n",
      "Epoch 2143/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2035 - acc: 0.2162 - val_loss: 0.5789 - val_acc: 0.2004\n",
      "Epoch 2144/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2155 - acc: 0.2158 - val_loss: 0.6385 - val_acc: 0.1985\n",
      "Epoch 2145/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2356 - acc: 0.2153 - val_loss: 0.5489 - val_acc: 0.2004\n",
      "Epoch 2146/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2045 - acc: 0.2158 - val_loss: 0.5933 - val_acc: 0.2004\n",
      "Epoch 2147/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2008 - acc: 0.2162 - val_loss: 0.5978 - val_acc: 0.2004\n",
      "Epoch 2148/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2190 - acc: 0.2148 - val_loss: 0.7876 - val_acc: 0.2004\n",
      "Epoch 2149/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2229 - acc: 0.2158 - val_loss: 0.7061 - val_acc: 0.2004\n",
      "Epoch 2150/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2266 - acc: 0.2158 - val_loss: 0.5940 - val_acc: 0.1985\n",
      "Epoch 2151/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2086 - acc: 0.2153 - val_loss: 0.6135 - val_acc: 0.1985\n",
      "Epoch 2152/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2194 - acc: 0.2158 - val_loss: 0.6229 - val_acc: 0.2004\n",
      "Epoch 2153/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.2087 - acc: 0.2167 - val_loss: 0.5771 - val_acc: 0.2004\n",
      "Epoch 2154/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2111 - acc: 0.2153 - val_loss: 0.5832 - val_acc: 0.2004\n",
      "Epoch 2155/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2053 - acc: 0.2153 - val_loss: 0.5834 - val_acc: 0.2004\n",
      "Epoch 2156/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2017 - acc: 0.2158 - val_loss: 0.6021 - val_acc: 0.2004\n",
      "Epoch 2157/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1906 - acc: 0.2158 - val_loss: 0.5824 - val_acc: 0.2004\n",
      "Epoch 2158/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2175 - acc: 0.2158 - val_loss: 0.6316 - val_acc: 0.1985\n",
      "Epoch 2159/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2296 - acc: 0.2153 - val_loss: 0.5874 - val_acc: 0.2004\n",
      "Epoch 2160/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2052 - acc: 0.2158 - val_loss: 0.6005 - val_acc: 0.2004\n",
      "Epoch 2161/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2265 - acc: 0.2148 - val_loss: 0.6047 - val_acc: 0.2004\n",
      "Epoch 2162/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2067 - acc: 0.2148 - val_loss: 0.6039 - val_acc: 0.2004\n",
      "Epoch 2163/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2130 - acc: 0.2162 - val_loss: 0.6341 - val_acc: 0.2004\n",
      "Epoch 2164/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2146 - acc: 0.2162 - val_loss: 0.5914 - val_acc: 0.2004\n",
      "Epoch 2165/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2021 - acc: 0.2167 - val_loss: 0.5777 - val_acc: 0.2004\n",
      "Epoch 2166/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2100 - acc: 0.2153 - val_loss: 0.6186 - val_acc: 0.2004\n",
      "Epoch 2167/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2269 - acc: 0.2158 - val_loss: 0.6694 - val_acc: 0.1985\n",
      "Epoch 2168/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1987 - acc: 0.2153 - val_loss: 0.5796 - val_acc: 0.2004\n",
      "Epoch 2169/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1981 - acc: 0.2162 - val_loss: 0.6154 - val_acc: 0.2004\n",
      "Epoch 2170/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1977 - acc: 0.2158 - val_loss: 0.6023 - val_acc: 0.1985\n",
      "Epoch 2171/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2010 - acc: 0.2162 - val_loss: 0.5970 - val_acc: 0.2004\n",
      "Epoch 2172/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2239 - acc: 0.2158 - val_loss: 0.6572 - val_acc: 0.2004\n",
      "Epoch 2173/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2210 - acc: 0.2148 - val_loss: 0.8185 - val_acc: 0.1967\n",
      "Epoch 2174/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2120 - acc: 0.2158 - val_loss: 0.5928 - val_acc: 0.2004\n",
      "Epoch 2175/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2077 - acc: 0.2153 - val_loss: 0.6040 - val_acc: 0.1985\n",
      "Epoch 2176/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2148 - acc: 0.2148 - val_loss: 0.6543 - val_acc: 0.1985\n",
      "Epoch 2177/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2203 - acc: 0.2148 - val_loss: 0.6296 - val_acc: 0.1985\n",
      "Epoch 2178/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2324 - acc: 0.2148 - val_loss: 0.5953 - val_acc: 0.2004\n",
      "Epoch 2179/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2181 - acc: 0.2153 - val_loss: 0.5880 - val_acc: 0.2004\n",
      "Epoch 2180/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2025 - acc: 0.2162 - val_loss: 0.6594 - val_acc: 0.2004\n",
      "Epoch 2181/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2006 - acc: 0.2144 - val_loss: 0.6377 - val_acc: 0.1985\n",
      "Epoch 2182/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2045 - acc: 0.2158 - val_loss: 0.6050 - val_acc: 0.2004\n",
      "Epoch 2183/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2303 - acc: 0.2158 - val_loss: 0.6516 - val_acc: 0.1985\n",
      "Epoch 2184/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2142 - acc: 0.2162 - val_loss: 0.6203 - val_acc: 0.2004\n",
      "Epoch 2185/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2077 - acc: 0.2148 - val_loss: 0.5932 - val_acc: 0.2004\n",
      "Epoch 2186/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2064 - acc: 0.2158 - val_loss: 0.5843 - val_acc: 0.2004\n",
      "Epoch 2187/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2243 - acc: 0.2158 - val_loss: 0.6020 - val_acc: 0.2004\n",
      "Epoch 2188/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2392 - acc: 0.2158 - val_loss: 0.5951 - val_acc: 0.2004\n",
      "Epoch 2189/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2059 - acc: 0.2144 - val_loss: 0.6162 - val_acc: 0.2004\n",
      "Epoch 2190/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2195 - acc: 0.2158 - val_loss: 0.6748 - val_acc: 0.1985\n",
      "Epoch 2191/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2124 - acc: 0.2148 - val_loss: 0.5945 - val_acc: 0.2004\n",
      "Epoch 2192/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2267 - acc: 0.2153 - val_loss: 0.5952 - val_acc: 0.2004\n",
      "Epoch 2193/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2075 - acc: 0.2158 - val_loss: 0.6318 - val_acc: 0.2004\n",
      "Epoch 2194/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1992 - acc: 0.2148 - val_loss: 0.6288 - val_acc: 0.2004\n",
      "Epoch 2195/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2054 - acc: 0.2153 - val_loss: 0.7024 - val_acc: 0.2004\n",
      "Epoch 2196/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2032 - acc: 0.2153 - val_loss: 0.6434 - val_acc: 0.1985\n",
      "Epoch 2197/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2082 - acc: 0.2162 - val_loss: 0.6258 - val_acc: 0.2004\n",
      "Epoch 2198/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2192 - acc: 0.2162 - val_loss: 0.5901 - val_acc: 0.2004\n",
      "Epoch 2199/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2060 - acc: 0.2158 - val_loss: 0.6035 - val_acc: 0.2004\n",
      "Epoch 2200/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2051 - acc: 0.2167 - val_loss: 0.6947 - val_acc: 0.1985\n",
      "Epoch 2201/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2303 - acc: 0.2139 - val_loss: 0.6322 - val_acc: 0.1985\n",
      "Epoch 2202/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2161 - acc: 0.2153 - val_loss: 0.6267 - val_acc: 0.1985\n",
      "Epoch 2203/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2446 - acc: 0.2158 - val_loss: 0.6187 - val_acc: 0.2004\n",
      "Epoch 2204/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2158 - acc: 0.2153 - val_loss: 0.7218 - val_acc: 0.2004\n",
      "Epoch 2205/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2234 - acc: 0.2162 - val_loss: 0.6211 - val_acc: 0.2004\n",
      "Epoch 2206/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2047 - acc: 0.2162 - val_loss: 0.6776 - val_acc: 0.1985\n",
      "Epoch 2207/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2069 - acc: 0.2158 - val_loss: 0.6070 - val_acc: 0.2004\n",
      "Epoch 2208/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2095 - acc: 0.2153 - val_loss: 0.5973 - val_acc: 0.2004\n",
      "Epoch 2209/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2031 - acc: 0.2158 - val_loss: 0.5990 - val_acc: 0.1985\n",
      "Epoch 2210/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2314 - acc: 0.2148 - val_loss: 0.6066 - val_acc: 0.2004\n",
      "Epoch 2211/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2546 - acc: 0.2158 - val_loss: 0.8302 - val_acc: 0.1985\n",
      "Epoch 2212/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2387 - acc: 0.2148 - val_loss: 0.6020 - val_acc: 0.2004\n",
      "Epoch 2213/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2113 - acc: 0.2158 - val_loss: 0.6685 - val_acc: 0.2004\n",
      "Epoch 2214/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2382 - acc: 0.2153 - val_loss: 0.6972 - val_acc: 0.2004\n",
      "Epoch 2215/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2094 - acc: 0.2162 - val_loss: 0.6605 - val_acc: 0.1985\n",
      "Epoch 2216/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2564 - acc: 0.2153 - val_loss: 0.6033 - val_acc: 0.2004\n",
      "Epoch 2217/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2180 - acc: 0.2153 - val_loss: 0.6105 - val_acc: 0.2004\n",
      "Epoch 2218/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2111 - acc: 0.2158 - val_loss: 0.5476 - val_acc: 0.2004\n",
      "Epoch 2219/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2941 - acc: 0.2116 - val_loss: 1.0502 - val_acc: 0.1874\n",
      "Epoch 2220/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2519 - acc: 0.2158 - val_loss: 0.6181 - val_acc: 0.2004\n",
      "Epoch 2221/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1956 - acc: 0.2158 - val_loss: 0.6191 - val_acc: 0.2004\n",
      "Epoch 2222/4000\n",
      "68/68 [==============================] - 5s 69ms/step - loss: 0.1934 - acc: 0.2153 - val_loss: 0.6507 - val_acc: 0.1985\n",
      "Epoch 2223/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2145 - acc: 0.2144 - val_loss: 0.6722 - val_acc: 0.2004\n",
      "Epoch 2224/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2072 - acc: 0.2162 - val_loss: 0.6848 - val_acc: 0.2004\n",
      "Epoch 2225/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2000 - acc: 0.2162 - val_loss: 0.5979 - val_acc: 0.2004\n",
      "Epoch 2226/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1926 - acc: 0.2153 - val_loss: 0.5922 - val_acc: 0.2004\n",
      "Epoch 2227/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2151 - acc: 0.2153 - val_loss: 0.5923 - val_acc: 0.2004\n",
      "Epoch 2228/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2000 - acc: 0.2153 - val_loss: 0.7430 - val_acc: 0.1985\n",
      "Epoch 2229/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2325 - acc: 0.2144 - val_loss: 0.8693 - val_acc: 0.2004\n",
      "Epoch 2230/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.2488 - acc: 0.2158 - val_loss: 0.6195 - val_acc: 0.1985\n",
      "Epoch 2231/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2013 - acc: 0.2162 - val_loss: 0.6323 - val_acc: 0.2004\n",
      "Epoch 2232/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2313 - acc: 0.2153 - val_loss: 0.6592 - val_acc: 0.1985\n",
      "Epoch 2233/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2079 - acc: 0.2148 - val_loss: 0.5823 - val_acc: 0.2004\n",
      "Epoch 2234/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2125 - acc: 0.2148 - val_loss: 0.7762 - val_acc: 0.2004\n",
      "Epoch 2235/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2198 - acc: 0.2158 - val_loss: 0.5973 - val_acc: 0.1985\n",
      "Epoch 2236/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2020 - acc: 0.2158 - val_loss: 0.5965 - val_acc: 0.2004\n",
      "Epoch 2237/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2231 - acc: 0.2158 - val_loss: 0.7238 - val_acc: 0.2004\n",
      "Epoch 2238/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2393 - acc: 0.2139 - val_loss: 0.6273 - val_acc: 0.2004\n",
      "Epoch 2239/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2310 - acc: 0.2148 - val_loss: 0.6687 - val_acc: 0.1985\n",
      "Epoch 2240/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2423 - acc: 0.2139 - val_loss: 0.6679 - val_acc: 0.1985\n",
      "Epoch 2241/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1947 - acc: 0.2158 - val_loss: 0.6222 - val_acc: 0.2004\n",
      "Epoch 2242/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.1994 - acc: 0.2153 - val_loss: 0.6257 - val_acc: 0.1985\n",
      "Epoch 2243/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2064 - acc: 0.2153 - val_loss: 0.6135 - val_acc: 0.1985\n",
      "Epoch 2244/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2005 - acc: 0.2148 - val_loss: 0.5981 - val_acc: 0.2004\n",
      "Epoch 2245/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2143 - acc: 0.2158 - val_loss: 0.6203 - val_acc: 0.2004\n",
      "Epoch 2246/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2098 - acc: 0.2148 - val_loss: 0.7021 - val_acc: 0.1985\n",
      "Epoch 2247/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2161 - acc: 0.2158 - val_loss: 0.8220 - val_acc: 0.1929\n",
      "Epoch 2248/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2510 - acc: 0.2158 - val_loss: 0.6156 - val_acc: 0.2004\n",
      "Epoch 2249/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2251 - acc: 0.2158 - val_loss: 0.5854 - val_acc: 0.2004\n",
      "Epoch 2250/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2186 - acc: 0.2148 - val_loss: 0.6064 - val_acc: 0.2004\n",
      "Epoch 2251/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2146 - acc: 0.2144 - val_loss: 0.6251 - val_acc: 0.2004\n",
      "Epoch 2252/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2056 - acc: 0.2162 - val_loss: 0.6451 - val_acc: 0.2004\n",
      "Epoch 2253/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2053 - acc: 0.2153 - val_loss: 0.6081 - val_acc: 0.2004\n",
      "Epoch 2254/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2097 - acc: 0.2158 - val_loss: 0.6908 - val_acc: 0.2004\n",
      "Epoch 2255/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2081 - acc: 0.2153 - val_loss: 0.7901 - val_acc: 0.1967\n",
      "Epoch 2256/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2318 - acc: 0.2148 - val_loss: 0.6096 - val_acc: 0.2004\n",
      "Epoch 2257/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1941 - acc: 0.2158 - val_loss: 0.5813 - val_acc: 0.1985\n",
      "Epoch 2258/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1952 - acc: 0.2158 - val_loss: 0.6428 - val_acc: 0.2004\n",
      "Epoch 2259/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2246 - acc: 0.2158 - val_loss: 0.6221 - val_acc: 0.2004\n",
      "Epoch 2260/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2143 - acc: 0.2153 - val_loss: 0.6129 - val_acc: 0.2004\n",
      "Epoch 2261/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2097 - acc: 0.2158 - val_loss: 0.6333 - val_acc: 0.1985\n",
      "Epoch 2262/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1989 - acc: 0.2158 - val_loss: 0.6083 - val_acc: 0.1985\n",
      "Epoch 2263/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2132 - acc: 0.2153 - val_loss: 0.6663 - val_acc: 0.1985\n",
      "Epoch 2264/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2109 - acc: 0.2162 - val_loss: 0.6179 - val_acc: 0.2004\n",
      "Epoch 2265/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2098 - acc: 0.2162 - val_loss: 0.6375 - val_acc: 0.2004\n",
      "Epoch 2266/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1979 - acc: 0.2148 - val_loss: 0.6097 - val_acc: 0.1985\n",
      "Epoch 2267/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2051 - acc: 0.2158 - val_loss: 0.6471 - val_acc: 0.1985\n",
      "Epoch 2268/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2056 - acc: 0.2158 - val_loss: 0.5728 - val_acc: 0.2004\n",
      "Epoch 2269/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1966 - acc: 0.2162 - val_loss: 0.6061 - val_acc: 0.2004\n",
      "Epoch 2270/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2235 - acc: 0.2158 - val_loss: 0.6287 - val_acc: 0.2004\n",
      "Epoch 2271/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1953 - acc: 0.2158 - val_loss: 0.5672 - val_acc: 0.2004\n",
      "Epoch 2272/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2073 - acc: 0.2162 - val_loss: 0.6553 - val_acc: 0.2004\n",
      "Epoch 2273/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2626 - acc: 0.2148 - val_loss: 0.6767 - val_acc: 0.2004\n",
      "Epoch 2274/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2225 - acc: 0.2162 - val_loss: 0.6251 - val_acc: 0.1985\n",
      "Epoch 2275/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2449 - acc: 0.2153 - val_loss: 0.5961 - val_acc: 0.2004\n",
      "Epoch 2276/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.8623 - acc: 0.2070 - val_loss: 24.6677 - val_acc: 0.0019\n",
      "Epoch 2277/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 2.2372 - acc: 0.1949 - val_loss: 0.4905 - val_acc: 0.2004\n",
      "Epoch 2278/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3268 - acc: 0.2158 - val_loss: 0.6362 - val_acc: 0.2004\n",
      "Epoch 2279/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2752 - acc: 0.2162 - val_loss: 0.6125 - val_acc: 0.2004\n",
      "Epoch 2280/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2089 - acc: 0.2167 - val_loss: 0.6330 - val_acc: 0.1985\n",
      "Epoch 2281/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1921 - acc: 0.2158 - val_loss: 0.5626 - val_acc: 0.2004\n",
      "Epoch 2282/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1830 - acc: 0.2162 - val_loss: 0.5611 - val_acc: 0.2004\n",
      "Epoch 2283/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1893 - acc: 0.2162 - val_loss: 0.5587 - val_acc: 0.2004\n",
      "Epoch 2284/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2115 - acc: 0.2162 - val_loss: 0.5609 - val_acc: 0.2004\n",
      "Epoch 2285/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1896 - acc: 0.2153 - val_loss: 0.5749 - val_acc: 0.2004\n",
      "Epoch 2286/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2207 - acc: 0.2158 - val_loss: 0.5497 - val_acc: 0.2004\n",
      "Epoch 2287/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1829 - acc: 0.2148 - val_loss: 0.5667 - val_acc: 0.2004\n",
      "Epoch 2288/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1949 - acc: 0.2162 - val_loss: 0.5792 - val_acc: 0.1985\n",
      "Epoch 2289/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1968 - acc: 0.2162 - val_loss: 0.5734 - val_acc: 0.2004\n",
      "Epoch 2290/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2054 - acc: 0.2158 - val_loss: 0.5584 - val_acc: 0.2004\n",
      "Epoch 2291/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1862 - acc: 0.2158 - val_loss: 0.5652 - val_acc: 0.2004\n",
      "Epoch 2292/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1836 - acc: 0.2162 - val_loss: 0.5704 - val_acc: 0.2004\n",
      "Epoch 2293/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1929 - acc: 0.2153 - val_loss: 0.5606 - val_acc: 0.2004\n",
      "Epoch 2294/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1869 - acc: 0.2153 - val_loss: 0.5664 - val_acc: 0.2004\n",
      "Epoch 2295/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1841 - acc: 0.2158 - val_loss: 0.5941 - val_acc: 0.1985\n",
      "Epoch 2296/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1972 - acc: 0.2167 - val_loss: 0.6601 - val_acc: 0.1985\n",
      "Epoch 2297/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2081 - acc: 0.2167 - val_loss: 0.5771 - val_acc: 0.2004\n",
      "Epoch 2298/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2025 - acc: 0.2162 - val_loss: 0.6465 - val_acc: 0.1985\n",
      "Epoch 2299/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1954 - acc: 0.2162 - val_loss: 0.6154 - val_acc: 0.2004\n",
      "Epoch 2300/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1844 - acc: 0.2167 - val_loss: 0.5989 - val_acc: 0.2004\n",
      "Epoch 2301/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1894 - acc: 0.2158 - val_loss: 0.5766 - val_acc: 0.2004\n",
      "Epoch 2302/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1910 - acc: 0.2162 - val_loss: 0.6329 - val_acc: 0.2004\n",
      "Epoch 2303/4000\n",
      "68/68 [==============================] - 5s 72ms/step - loss: 0.1984 - acc: 0.2158 - val_loss: 0.6478 - val_acc: 0.2004\n",
      "Epoch 2304/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2059 - acc: 0.2153 - val_loss: 0.6015 - val_acc: 0.1985\n",
      "Epoch 2305/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1951 - acc: 0.2158 - val_loss: 0.5775 - val_acc: 0.2004\n",
      "Epoch 2306/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1921 - acc: 0.2158 - val_loss: 0.5978 - val_acc: 0.1985\n",
      "Epoch 2307/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2069 - acc: 0.2153 - val_loss: 0.5733 - val_acc: 0.2004\n",
      "Epoch 2308/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2002 - acc: 0.2158 - val_loss: 0.5989 - val_acc: 0.2004\n",
      "Epoch 2309/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1862 - acc: 0.2162 - val_loss: 0.5803 - val_acc: 0.2004\n",
      "Epoch 2310/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2122 - acc: 0.2153 - val_loss: 0.5847 - val_acc: 0.1985\n",
      "Epoch 2311/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1999 - acc: 0.2158 - val_loss: 0.6214 - val_acc: 0.2004\n",
      "Epoch 2312/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2072 - acc: 0.2153 - val_loss: 0.5899 - val_acc: 0.2004\n",
      "Epoch 2313/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2143 - acc: 0.2158 - val_loss: 0.5791 - val_acc: 0.2004\n",
      "Epoch 2314/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2124 - acc: 0.2167 - val_loss: 0.5901 - val_acc: 0.2004\n",
      "Epoch 2315/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1857 - acc: 0.2153 - val_loss: 0.5839 - val_acc: 0.2004\n",
      "Epoch 2316/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1933 - acc: 0.2158 - val_loss: 0.6033 - val_acc: 0.2004\n",
      "Epoch 2317/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2034 - acc: 0.2162 - val_loss: 0.5912 - val_acc: 0.2004\n",
      "Epoch 2318/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1874 - acc: 0.2162 - val_loss: 0.5831 - val_acc: 0.2004\n",
      "Epoch 2319/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2028 - acc: 0.2162 - val_loss: 0.6967 - val_acc: 0.2004\n",
      "Epoch 2320/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1999 - acc: 0.2153 - val_loss: 0.5649 - val_acc: 0.2004\n",
      "Epoch 2321/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2314 - acc: 0.2144 - val_loss: 0.6937 - val_acc: 0.2004\n",
      "Epoch 2322/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2060 - acc: 0.2158 - val_loss: 0.5463 - val_acc: 0.2004\n",
      "Epoch 2323/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2102 - acc: 0.2158 - val_loss: 0.7107 - val_acc: 0.2004\n",
      "Epoch 2324/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2240 - acc: 0.2158 - val_loss: 0.5677 - val_acc: 0.2004\n",
      "Epoch 2325/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2006 - acc: 0.2153 - val_loss: 0.6106 - val_acc: 0.2004\n",
      "Epoch 2326/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2025 - acc: 0.2158 - val_loss: 0.5996 - val_acc: 0.2004\n",
      "Epoch 2327/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1968 - acc: 0.2153 - val_loss: 0.5722 - val_acc: 0.2004\n",
      "Epoch 2328/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2127 - acc: 0.2148 - val_loss: 0.5848 - val_acc: 0.2004\n",
      "Epoch 2329/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1912 - acc: 0.2153 - val_loss: 0.5856 - val_acc: 0.2004\n",
      "Epoch 2330/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2035 - acc: 0.2158 - val_loss: 0.6349 - val_acc: 0.1985\n",
      "Epoch 2331/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1856 - acc: 0.2162 - val_loss: 0.5839 - val_acc: 0.2004\n",
      "Epoch 2332/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2024 - acc: 0.2153 - val_loss: 0.5674 - val_acc: 0.2004\n",
      "Epoch 2333/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2146 - acc: 0.2162 - val_loss: 0.5738 - val_acc: 0.2004\n",
      "Epoch 2334/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2079 - acc: 0.2148 - val_loss: 0.6416 - val_acc: 0.1985\n",
      "Epoch 2335/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2092 - acc: 0.2139 - val_loss: 0.6868 - val_acc: 0.2004\n",
      "Epoch 2336/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2308 - acc: 0.2148 - val_loss: 0.5971 - val_acc: 0.2004\n",
      "Epoch 2337/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2467 - acc: 0.2158 - val_loss: 0.5809 - val_acc: 0.2004\n",
      "Epoch 2338/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2230 - acc: 0.2153 - val_loss: 0.5919 - val_acc: 0.2004\n",
      "Epoch 2339/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2269 - acc: 0.2148 - val_loss: 0.5844 - val_acc: 0.2004\n",
      "Epoch 2340/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1940 - acc: 0.2158 - val_loss: 0.5644 - val_acc: 0.2004\n",
      "Epoch 2341/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1951 - acc: 0.2153 - val_loss: 0.5952 - val_acc: 0.2004\n",
      "Epoch 2342/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2136 - acc: 0.2162 - val_loss: 0.5642 - val_acc: 0.2004\n",
      "Epoch 2343/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2334 - acc: 0.2162 - val_loss: 0.6037 - val_acc: 0.1985\n",
      "Epoch 2344/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2374 - acc: 0.2153 - val_loss: 0.6700 - val_acc: 0.1985\n",
      "Epoch 2345/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2118 - acc: 0.2153 - val_loss: 0.7105 - val_acc: 0.1985\n",
      "Epoch 2346/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2134 - acc: 0.2148 - val_loss: 0.5895 - val_acc: 0.2004\n",
      "Epoch 2347/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2087 - acc: 0.2162 - val_loss: 0.5997 - val_acc: 0.2004\n",
      "Epoch 2348/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1990 - acc: 0.2158 - val_loss: 0.6572 - val_acc: 0.1985\n",
      "Epoch 2349/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2047 - acc: 0.2153 - val_loss: 0.6402 - val_acc: 0.2004\n",
      "Epoch 2350/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2071 - acc: 0.2139 - val_loss: 0.5840 - val_acc: 0.1985\n",
      "Epoch 2351/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2145 - acc: 0.2162 - val_loss: 0.5906 - val_acc: 0.2004\n",
      "Epoch 2352/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2223 - acc: 0.2172 - val_loss: 0.8738 - val_acc: 0.1948\n",
      "Epoch 2353/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2161 - acc: 0.2153 - val_loss: 0.5886 - val_acc: 0.2004\n",
      "Epoch 2354/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1859 - acc: 0.2162 - val_loss: 0.6404 - val_acc: 0.1985\n",
      "Epoch 2355/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2272 - acc: 0.2158 - val_loss: 0.5749 - val_acc: 0.2004\n",
      "Epoch 2356/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2078 - acc: 0.2148 - val_loss: 0.5900 - val_acc: 0.2004\n",
      "Epoch 2357/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2041 - acc: 0.2158 - val_loss: 0.5910 - val_acc: 0.1985\n",
      "Epoch 2358/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2373 - acc: 0.2148 - val_loss: 0.5731 - val_acc: 0.2004\n",
      "Epoch 2359/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2037 - acc: 0.2153 - val_loss: 0.6911 - val_acc: 0.1985\n",
      "Epoch 2360/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2115 - acc: 0.2162 - val_loss: 0.6836 - val_acc: 0.1985\n",
      "Epoch 2361/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2497 - acc: 0.2158 - val_loss: 0.6135 - val_acc: 0.2004\n",
      "Epoch 2362/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.2107 - acc: 0.2158 - val_loss: 0.6032 - val_acc: 0.2004\n",
      "Epoch 2363/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1937 - acc: 0.2158 - val_loss: 0.6480 - val_acc: 0.2004\n",
      "Epoch 2364/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2200 - acc: 0.2144 - val_loss: 0.7139 - val_acc: 0.1985\n",
      "Epoch 2365/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2470 - acc: 0.2162 - val_loss: 0.5899 - val_acc: 0.2004\n",
      "Epoch 2366/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2137 - acc: 0.2158 - val_loss: 0.6048 - val_acc: 0.2004\n",
      "Epoch 2367/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2016 - acc: 0.2153 - val_loss: 0.5883 - val_acc: 0.2004\n",
      "Epoch 2368/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1952 - acc: 0.2153 - val_loss: 0.5853 - val_acc: 0.2004\n",
      "Epoch 2369/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2163 - acc: 0.2148 - val_loss: 0.6327 - val_acc: 0.1985\n",
      "Epoch 2370/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1959 - acc: 0.2158 - val_loss: 0.5860 - val_acc: 0.2004\n",
      "Epoch 2371/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1998 - acc: 0.2158 - val_loss: 0.6513 - val_acc: 0.2004\n",
      "Epoch 2372/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1995 - acc: 0.2167 - val_loss: 0.6038 - val_acc: 0.1985\n",
      "Epoch 2373/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2089 - acc: 0.2153 - val_loss: 0.6215 - val_acc: 0.2004\n",
      "Epoch 2374/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2063 - acc: 0.2158 - val_loss: 0.6210 - val_acc: 0.1985\n",
      "Epoch 2375/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2011 - acc: 0.2162 - val_loss: 0.6482 - val_acc: 0.2004\n",
      "Epoch 2376/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2363 - acc: 0.2158 - val_loss: 0.6339 - val_acc: 0.2004\n",
      "Epoch 2377/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2511 - acc: 0.2158 - val_loss: 0.7259 - val_acc: 0.1985\n",
      "Epoch 2378/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2102 - acc: 0.2153 - val_loss: 0.6802 - val_acc: 0.2004\n",
      "Epoch 2379/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2043 - acc: 0.2158 - val_loss: 0.6085 - val_acc: 0.2004\n",
      "Epoch 2380/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2524 - acc: 0.2153 - val_loss: 0.5390 - val_acc: 0.2004\n",
      "Epoch 2381/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.7210 - acc: 0.2023 - val_loss: 0.8275 - val_acc: 0.2004\n",
      "Epoch 2382/4000\n",
      "68/68 [==============================] - 5s 69ms/step - loss: 0.3269 - acc: 0.2158 - val_loss: 0.5972 - val_acc: 0.2004\n",
      "Epoch 2383/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.2852 - acc: 0.2162 - val_loss: 0.6340 - val_acc: 0.1985\n",
      "Epoch 2384/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2225 - acc: 0.2158 - val_loss: 0.6119 - val_acc: 0.2004\n",
      "Epoch 2385/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2250 - acc: 0.2162 - val_loss: 0.5931 - val_acc: 0.2004\n",
      "Epoch 2386/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2189 - acc: 0.2158 - val_loss: 0.5816 - val_acc: 0.2004\n",
      "Epoch 2387/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1926 - acc: 0.2162 - val_loss: 0.5932 - val_acc: 0.2004\n",
      "Epoch 2388/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2241 - acc: 0.2153 - val_loss: 0.7321 - val_acc: 0.2004\n",
      "Epoch 2389/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2158 - acc: 0.2148 - val_loss: 0.5837 - val_acc: 0.2004\n",
      "Epoch 2390/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2012 - acc: 0.2158 - val_loss: 0.5743 - val_acc: 0.2004\n",
      "Epoch 2391/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1947 - acc: 0.2162 - val_loss: 0.5980 - val_acc: 0.1985\n",
      "Epoch 2392/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2075 - acc: 0.2158 - val_loss: 0.5812 - val_acc: 0.2004\n",
      "Epoch 2393/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1978 - acc: 0.2158 - val_loss: 0.6061 - val_acc: 0.1985\n",
      "Epoch 2394/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1914 - acc: 0.2158 - val_loss: 0.5940 - val_acc: 0.2004\n",
      "Epoch 2395/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1958 - acc: 0.2158 - val_loss: 0.5790 - val_acc: 0.2004\n",
      "Epoch 2396/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2222 - acc: 0.2162 - val_loss: 0.6109 - val_acc: 0.2004\n",
      "Epoch 2397/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2096 - acc: 0.2148 - val_loss: 0.6203 - val_acc: 0.1985\n",
      "Epoch 2398/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1942 - acc: 0.2158 - val_loss: 0.6369 - val_acc: 0.1985\n",
      "Epoch 2399/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2164 - acc: 0.2148 - val_loss: 0.5576 - val_acc: 0.2004\n",
      "Epoch 2400/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2225 - acc: 0.2148 - val_loss: 0.6203 - val_acc: 0.1985\n",
      "Epoch 2401/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2140 - acc: 0.2153 - val_loss: 0.5785 - val_acc: 0.2004\n",
      "Epoch 2402/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2158 - acc: 0.2158 - val_loss: 0.6746 - val_acc: 0.1967\n",
      "Epoch 2403/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2250 - acc: 0.2153 - val_loss: 0.6936 - val_acc: 0.1985\n",
      "Epoch 2404/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2006 - acc: 0.2148 - val_loss: 0.6100 - val_acc: 0.2004\n",
      "Epoch 2405/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1950 - acc: 0.2162 - val_loss: 0.5794 - val_acc: 0.2004\n",
      "Epoch 2406/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2006 - acc: 0.2153 - val_loss: 0.6914 - val_acc: 0.1985\n",
      "Epoch 2407/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2206 - acc: 0.2144 - val_loss: 0.5896 - val_acc: 0.2004\n",
      "Epoch 2408/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2170 - acc: 0.2153 - val_loss: 0.6248 - val_acc: 0.1985\n",
      "Epoch 2409/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1863 - acc: 0.2153 - val_loss: 0.6260 - val_acc: 0.1985\n",
      "Epoch 2410/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2225 - acc: 0.2139 - val_loss: 0.7092 - val_acc: 0.1985\n",
      "Epoch 2411/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2201 - acc: 0.2153 - val_loss: 0.6375 - val_acc: 0.2004\n",
      "Epoch 2412/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1984 - acc: 0.2162 - val_loss: 0.5826 - val_acc: 0.2004\n",
      "Epoch 2413/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1943 - acc: 0.2158 - val_loss: 0.5982 - val_acc: 0.1985\n",
      "Epoch 2414/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1912 - acc: 0.2158 - val_loss: 0.5749 - val_acc: 0.2004\n",
      "Epoch 2415/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2061 - acc: 0.2158 - val_loss: 0.6119 - val_acc: 0.2004\n",
      "Epoch 2416/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1907 - acc: 0.2162 - val_loss: 0.5811 - val_acc: 0.2004\n",
      "Epoch 2417/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1981 - acc: 0.2153 - val_loss: 0.6188 - val_acc: 0.2004\n",
      "Epoch 2418/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1896 - acc: 0.2153 - val_loss: 0.6776 - val_acc: 0.2004\n",
      "Epoch 2419/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2138 - acc: 0.2158 - val_loss: 0.6692 - val_acc: 0.2004\n",
      "Epoch 2420/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2021 - acc: 0.2153 - val_loss: 0.5929 - val_acc: 0.1985\n",
      "Epoch 2421/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2000 - acc: 0.2158 - val_loss: 0.6061 - val_acc: 0.2004\n",
      "Epoch 2422/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2039 - acc: 0.2162 - val_loss: 0.6425 - val_acc: 0.1985\n",
      "Epoch 2423/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2187 - acc: 0.2162 - val_loss: 0.6341 - val_acc: 0.2004\n",
      "Epoch 2424/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2856 - acc: 0.2148 - val_loss: 0.6087 - val_acc: 0.1985\n",
      "Epoch 2425/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2011 - acc: 0.2153 - val_loss: 0.5835 - val_acc: 0.2004\n",
      "Epoch 2426/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2091 - acc: 0.2158 - val_loss: 0.6042 - val_acc: 0.2004\n",
      "Epoch 2427/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2205 - acc: 0.2153 - val_loss: 0.5956 - val_acc: 0.2004\n",
      "Epoch 2428/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1951 - acc: 0.2158 - val_loss: 0.5950 - val_acc: 0.2004\n",
      "Epoch 2429/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2019 - acc: 0.2158 - val_loss: 0.7043 - val_acc: 0.2004\n",
      "Epoch 2430/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2190 - acc: 0.2158 - val_loss: 0.5608 - val_acc: 0.1985\n",
      "Epoch 2431/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2080 - acc: 0.2144 - val_loss: 0.6905 - val_acc: 0.1985\n",
      "Epoch 2432/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2047 - acc: 0.2158 - val_loss: 0.6179 - val_acc: 0.2004\n",
      "Epoch 2433/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2319 - acc: 0.2158 - val_loss: 0.8699 - val_acc: 0.2004\n",
      "Epoch 2434/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2249 - acc: 0.2144 - val_loss: 0.5865 - val_acc: 0.2004\n",
      "Epoch 2435/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2026 - acc: 0.2158 - val_loss: 0.6196 - val_acc: 0.2004\n",
      "Epoch 2436/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2196 - acc: 0.2158 - val_loss: 0.5749 - val_acc: 0.2004\n",
      "Epoch 2437/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2061 - acc: 0.2148 - val_loss: 0.6081 - val_acc: 0.1985\n",
      "Epoch 2438/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1934 - acc: 0.2162 - val_loss: 0.6055 - val_acc: 0.2004\n",
      "Epoch 2439/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1914 - acc: 0.2162 - val_loss: 0.6904 - val_acc: 0.1985\n",
      "Epoch 2440/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2013 - acc: 0.2158 - val_loss: 0.8679 - val_acc: 0.1929\n",
      "Epoch 2441/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2419 - acc: 0.2135 - val_loss: 0.7740 - val_acc: 0.1985\n",
      "Epoch 2442/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2300 - acc: 0.2144 - val_loss: 0.6190 - val_acc: 0.2004\n",
      "Epoch 2443/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2089 - acc: 0.2144 - val_loss: 0.7634 - val_acc: 0.2004\n",
      "Epoch 2444/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2179 - acc: 0.2162 - val_loss: 0.5757 - val_acc: 0.2004\n",
      "Epoch 2445/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2052 - acc: 0.2167 - val_loss: 0.6216 - val_acc: 0.2004\n",
      "Epoch 2446/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2173 - acc: 0.2148 - val_loss: 0.6089 - val_acc: 0.2004\n",
      "Epoch 2447/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2089 - acc: 0.2158 - val_loss: 0.6231 - val_acc: 0.2004\n",
      "Epoch 2448/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2140 - acc: 0.2153 - val_loss: 0.5826 - val_acc: 0.2004\n",
      "Epoch 2449/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2144 - acc: 0.2139 - val_loss: 0.5964 - val_acc: 0.2004\n",
      "Epoch 2450/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2168 - acc: 0.2148 - val_loss: 0.5958 - val_acc: 0.1985\n",
      "Epoch 2451/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2089 - acc: 0.2148 - val_loss: 0.5847 - val_acc: 0.2004\n",
      "Epoch 2452/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2060 - acc: 0.2158 - val_loss: 0.5956 - val_acc: 0.2004\n",
      "Epoch 2453/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1959 - acc: 0.2167 - val_loss: 0.6083 - val_acc: 0.2004\n",
      "Epoch 2454/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2048 - acc: 0.2158 - val_loss: 0.5813 - val_acc: 0.2004\n",
      "Epoch 2455/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2101 - acc: 0.2148 - val_loss: 0.6531 - val_acc: 0.2004\n",
      "Epoch 2456/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2749 - acc: 0.2158 - val_loss: 0.6216 - val_acc: 0.1985\n",
      "Epoch 2457/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2571 - acc: 0.2148 - val_loss: 0.6374 - val_acc: 0.2004\n",
      "Epoch 2458/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4938 - acc: 0.2144 - val_loss: 1.0854 - val_acc: 0.1911\n",
      "Epoch 2459/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.8312 - acc: 0.2121 - val_loss: 0.5729 - val_acc: 0.2004\n",
      "Epoch 2460/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.6949 - acc: 0.2148 - val_loss: 0.6239 - val_acc: 0.2004\n",
      "Epoch 2461/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3654 - acc: 0.2162 - val_loss: 0.6208 - val_acc: 0.2004\n",
      "Epoch 2462/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.2041 - acc: 0.2153 - val_loss: 0.5727 - val_acc: 0.2004\n",
      "Epoch 2463/4000\n",
      "68/68 [==============================] - 5s 72ms/step - loss: 0.2169 - acc: 0.2153 - val_loss: 0.6849 - val_acc: 0.2004\n",
      "Epoch 2464/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1973 - acc: 0.2153 - val_loss: 0.5925 - val_acc: 0.1985\n",
      "Epoch 2465/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1954 - acc: 0.2158 - val_loss: 0.6150 - val_acc: 0.2004\n",
      "Epoch 2466/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2208 - acc: 0.2162 - val_loss: 0.5904 - val_acc: 0.1985\n",
      "Epoch 2467/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1942 - acc: 0.2167 - val_loss: 0.6125 - val_acc: 0.1985\n",
      "Epoch 2468/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1859 - acc: 0.2153 - val_loss: 0.5873 - val_acc: 0.1985\n",
      "Epoch 2469/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1972 - acc: 0.2158 - val_loss: 0.5677 - val_acc: 0.2004\n",
      "Epoch 2470/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1848 - acc: 0.2158 - val_loss: 0.5996 - val_acc: 0.1985\n",
      "Epoch 2471/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2063 - acc: 0.2158 - val_loss: 0.5892 - val_acc: 0.2004\n",
      "Epoch 2472/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1869 - acc: 0.2158 - val_loss: 0.6003 - val_acc: 0.1985\n",
      "Epoch 2473/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1873 - acc: 0.2153 - val_loss: 0.5798 - val_acc: 0.2004\n",
      "Epoch 2474/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2263 - acc: 0.2153 - val_loss: 0.7707 - val_acc: 0.2004\n",
      "Epoch 2475/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2252 - acc: 0.2158 - val_loss: 0.6133 - val_acc: 0.2004\n",
      "Epoch 2476/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.1941 - acc: 0.2167 - val_loss: 0.5869 - val_acc: 0.1985\n",
      "Epoch 2477/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1905 - acc: 0.2158 - val_loss: 0.5774 - val_acc: 0.2004\n",
      "Epoch 2478/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2108 - acc: 0.2153 - val_loss: 0.6073 - val_acc: 0.2004\n",
      "Epoch 2479/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2026 - acc: 0.2144 - val_loss: 0.5863 - val_acc: 0.2004\n",
      "Epoch 2480/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1899 - acc: 0.2153 - val_loss: 0.6119 - val_acc: 0.1985\n",
      "Epoch 2481/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2037 - acc: 0.2153 - val_loss: 0.5804 - val_acc: 0.2004\n",
      "Epoch 2482/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.2103 - acc: 0.2153 - val_loss: 0.6055 - val_acc: 0.2004\n",
      "Epoch 2483/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2168 - acc: 0.2153 - val_loss: 0.5690 - val_acc: 0.2004\n",
      "Epoch 2484/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2164 - acc: 0.2148 - val_loss: 0.6117 - val_acc: 0.1985\n",
      "Epoch 2485/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1890 - acc: 0.2153 - val_loss: 0.5853 - val_acc: 0.2004\n",
      "Epoch 2486/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1951 - acc: 0.2158 - val_loss: 0.5643 - val_acc: 0.2004\n",
      "Epoch 2487/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2004 - acc: 0.2148 - val_loss: 0.5668 - val_acc: 0.2004\n",
      "Epoch 2488/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1949 - acc: 0.2148 - val_loss: 0.5840 - val_acc: 0.2004\n",
      "Epoch 2489/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.1927 - acc: 0.2153 - val_loss: 0.6319 - val_acc: 0.2004\n",
      "Epoch 2490/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2417 - acc: 0.2153 - val_loss: 0.6594 - val_acc: 0.2004\n",
      "Epoch 2491/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2264 - acc: 0.2148 - val_loss: 0.5908 - val_acc: 0.2004\n",
      "Epoch 2492/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1947 - acc: 0.2162 - val_loss: 0.6152 - val_acc: 0.1985\n",
      "Epoch 2493/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1900 - acc: 0.2153 - val_loss: 0.7020 - val_acc: 0.2004\n",
      "Epoch 2494/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2306 - acc: 0.2167 - val_loss: 0.6396 - val_acc: 0.1985\n",
      "Epoch 2495/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1979 - acc: 0.2158 - val_loss: 0.5795 - val_acc: 0.2004\n",
      "Epoch 2496/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.1917 - acc: 0.2167 - val_loss: 0.5639 - val_acc: 0.2004\n",
      "Epoch 2497/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1999 - acc: 0.2162 - val_loss: 0.5792 - val_acc: 0.2004\n",
      "Epoch 2498/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2066 - acc: 0.2162 - val_loss: 0.7042 - val_acc: 0.1967\n",
      "Epoch 2499/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2111 - acc: 0.2158 - val_loss: 0.6291 - val_acc: 0.2004\n",
      "Epoch 2500/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1971 - acc: 0.2153 - val_loss: 0.5801 - val_acc: 0.2004\n",
      "Epoch 2501/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.1981 - acc: 0.2158 - val_loss: 0.5934 - val_acc: 0.2004\n",
      "Epoch 2502/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2096 - acc: 0.2153 - val_loss: 0.5850 - val_acc: 0.2004\n",
      "Epoch 2503/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2055 - acc: 0.2153 - val_loss: 0.6068 - val_acc: 0.2004\n",
      "Epoch 2504/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.2046 - acc: 0.2148 - val_loss: 0.6409 - val_acc: 0.2004\n",
      "Epoch 2505/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1988 - acc: 0.2148 - val_loss: 0.6090 - val_acc: 0.1985\n",
      "Epoch 2506/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1943 - acc: 0.2162 - val_loss: 0.5889 - val_acc: 0.2004\n",
      "Epoch 2507/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1850 - acc: 0.2167 - val_loss: 0.5821 - val_acc: 0.1985\n",
      "Epoch 2508/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2001 - acc: 0.2153 - val_loss: 0.6029 - val_acc: 0.2004\n",
      "Epoch 2509/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2068 - acc: 0.2158 - val_loss: 0.6393 - val_acc: 0.2004\n",
      "Epoch 2510/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1927 - acc: 0.2148 - val_loss: 0.7053 - val_acc: 0.2004\n",
      "Epoch 2511/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2135 - acc: 0.2158 - val_loss: 0.6041 - val_acc: 0.2004\n",
      "Epoch 2512/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1907 - acc: 0.2158 - val_loss: 0.6268 - val_acc: 0.2004\n",
      "Epoch 2513/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2013 - acc: 0.2158 - val_loss: 0.6908 - val_acc: 0.2004\n",
      "Epoch 2514/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1939 - acc: 0.2162 - val_loss: 0.5795 - val_acc: 0.2004\n",
      "Epoch 2515/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1978 - acc: 0.2153 - val_loss: 0.6212 - val_acc: 0.2004\n",
      "Epoch 2516/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2106 - acc: 0.2144 - val_loss: 0.6241 - val_acc: 0.1985\n",
      "Epoch 2517/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1991 - acc: 0.2162 - val_loss: 0.6193 - val_acc: 0.2004\n",
      "Epoch 2518/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2050 - acc: 0.2158 - val_loss: 0.5874 - val_acc: 0.2004\n",
      "Epoch 2519/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2173 - acc: 0.2158 - val_loss: 0.6118 - val_acc: 0.1985\n",
      "Epoch 2520/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2051 - acc: 0.2148 - val_loss: 0.6204 - val_acc: 0.2004\n",
      "Epoch 2521/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2025 - acc: 0.2139 - val_loss: 0.5720 - val_acc: 0.2004\n",
      "Epoch 2522/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1990 - acc: 0.2162 - val_loss: 0.7082 - val_acc: 0.1967\n",
      "Epoch 2523/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2124 - acc: 0.2158 - val_loss: 0.6298 - val_acc: 0.1985\n",
      "Epoch 2524/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2258 - acc: 0.2139 - val_loss: 0.5824 - val_acc: 0.2004\n",
      "Epoch 2525/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2092 - acc: 0.2162 - val_loss: 0.6068 - val_acc: 0.2004\n",
      "Epoch 2526/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1900 - acc: 0.2158 - val_loss: 0.5906 - val_acc: 0.2004\n",
      "Epoch 2527/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1952 - acc: 0.2158 - val_loss: 0.5831 - val_acc: 0.2004\n",
      "Epoch 2528/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1970 - acc: 0.2158 - val_loss: 0.6161 - val_acc: 0.1985\n",
      "Epoch 2529/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2065 - acc: 0.2153 - val_loss: 0.6338 - val_acc: 0.2004\n",
      "Epoch 2530/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2152 - acc: 0.2162 - val_loss: 0.5727 - val_acc: 0.2004\n",
      "Epoch 2531/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2048 - acc: 0.2158 - val_loss: 0.5786 - val_acc: 0.2004\n",
      "Epoch 2532/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2000 - acc: 0.2153 - val_loss: 0.5823 - val_acc: 0.2004\n",
      "Epoch 2533/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2035 - acc: 0.2148 - val_loss: 0.5912 - val_acc: 0.2004\n",
      "Epoch 2534/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2395 - acc: 0.2148 - val_loss: 0.6173 - val_acc: 0.2004\n",
      "Epoch 2535/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1967 - acc: 0.2167 - val_loss: 0.6063 - val_acc: 0.2004\n",
      "Epoch 2536/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2284 - acc: 0.2162 - val_loss: 0.6027 - val_acc: 0.2004\n",
      "Epoch 2537/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1846 - acc: 0.2158 - val_loss: 0.5628 - val_acc: 0.2004\n",
      "Epoch 2538/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2093 - acc: 0.2148 - val_loss: 0.5939 - val_acc: 0.2004\n",
      "Epoch 2539/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2344 - acc: 0.2153 - val_loss: 0.9031 - val_acc: 0.1911\n",
      "Epoch 2540/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2216 - acc: 0.2153 - val_loss: 0.6043 - val_acc: 0.2004\n",
      "Epoch 2541/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2013 - acc: 0.2153 - val_loss: 0.6289 - val_acc: 0.1985\n",
      "Epoch 2542/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2127 - acc: 0.2153 - val_loss: 0.7520 - val_acc: 0.2004\n",
      "Epoch 2543/4000\n",
      "68/68 [==============================] - 5s 68ms/step - loss: 0.2087 - acc: 0.2158 - val_loss: 0.5826 - val_acc: 0.2004\n",
      "Epoch 2544/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.1919 - acc: 0.2148 - val_loss: 0.6121 - val_acc: 0.2004\n",
      "Epoch 2545/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.2146 - acc: 0.2158 - val_loss: 0.6157 - val_acc: 0.1985\n",
      "Epoch 2546/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1988 - acc: 0.2153 - val_loss: 0.6438 - val_acc: 0.1985\n",
      "Epoch 2547/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3010 - acc: 0.2135 - val_loss: 0.6081 - val_acc: 0.2004\n",
      "Epoch 2548/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2597 - acc: 0.2153 - val_loss: 0.5738 - val_acc: 0.1985\n",
      "Epoch 2549/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2641 - acc: 0.2158 - val_loss: 0.6304 - val_acc: 0.2004\n",
      "Epoch 2550/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2770 - acc: 0.2135 - val_loss: 0.6283 - val_acc: 0.2004\n",
      "Epoch 2551/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2215 - acc: 0.2153 - val_loss: 0.5823 - val_acc: 0.1985\n",
      "Epoch 2552/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1964 - acc: 0.2153 - val_loss: 0.5839 - val_acc: 0.2004\n",
      "Epoch 2553/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2292 - acc: 0.2162 - val_loss: 0.6938 - val_acc: 0.1985\n",
      "Epoch 2554/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2145 - acc: 0.2153 - val_loss: 0.5753 - val_acc: 0.2004\n",
      "Epoch 2555/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1940 - acc: 0.2162 - val_loss: 0.6592 - val_acc: 0.1985\n",
      "Epoch 2556/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1923 - acc: 0.2158 - val_loss: 0.5946 - val_acc: 0.2004\n",
      "Epoch 2557/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2052 - acc: 0.2135 - val_loss: 0.5983 - val_acc: 0.2004\n",
      "Epoch 2558/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1860 - acc: 0.2172 - val_loss: 0.6075 - val_acc: 0.2004\n",
      "Epoch 2559/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1986 - acc: 0.2162 - val_loss: 0.6306 - val_acc: 0.1985\n",
      "Epoch 2560/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2613 - acc: 0.2144 - val_loss: 0.5934 - val_acc: 0.2004\n",
      "Epoch 2561/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.1941 - acc: 0.2148 - val_loss: 0.5673 - val_acc: 0.2004\n",
      "Epoch 2562/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.1873 - acc: 0.2153 - val_loss: 0.6117 - val_acc: 0.2004\n",
      "Epoch 2563/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2100 - acc: 0.2153 - val_loss: 0.5745 - val_acc: 0.2004\n",
      "Epoch 2564/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1897 - acc: 0.2162 - val_loss: 0.6237 - val_acc: 0.2004\n",
      "Epoch 2565/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2032 - acc: 0.2167 - val_loss: 0.6106 - val_acc: 0.2004\n",
      "Epoch 2566/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2128 - acc: 0.2158 - val_loss: 0.6013 - val_acc: 0.2004\n",
      "Epoch 2567/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1869 - acc: 0.2153 - val_loss: 0.5916 - val_acc: 0.2004\n",
      "Epoch 2568/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1938 - acc: 0.2162 - val_loss: 0.5919 - val_acc: 0.2004\n",
      "Epoch 2569/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1889 - acc: 0.2158 - val_loss: 0.6215 - val_acc: 0.2004\n",
      "Epoch 2570/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1914 - acc: 0.2158 - val_loss: 0.6024 - val_acc: 0.2004\n",
      "Epoch 2571/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1881 - acc: 0.2158 - val_loss: 0.6227 - val_acc: 0.2004\n",
      "Epoch 2572/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1807 - acc: 0.2158 - val_loss: 0.5769 - val_acc: 0.2004\n",
      "Epoch 2573/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1843 - acc: 0.2158 - val_loss: 0.6077 - val_acc: 0.2004\n",
      "Epoch 2574/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2004 - acc: 0.2153 - val_loss: 0.5785 - val_acc: 0.2004\n",
      "Epoch 2575/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2116 - acc: 0.2144 - val_loss: 0.6140 - val_acc: 0.2004\n",
      "Epoch 2576/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2550 - acc: 0.2121 - val_loss: 0.6108 - val_acc: 0.2004\n",
      "Epoch 2577/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.2371 - acc: 0.2148 - val_loss: 0.5796 - val_acc: 0.2004\n",
      "Epoch 2578/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1970 - acc: 0.2158 - val_loss: 0.5887 - val_acc: 0.2004\n",
      "Epoch 2579/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1984 - acc: 0.2144 - val_loss: 0.5946 - val_acc: 0.2004\n",
      "Epoch 2580/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1889 - acc: 0.2162 - val_loss: 0.6319 - val_acc: 0.1985\n",
      "Epoch 2581/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1915 - acc: 0.2158 - val_loss: 0.6280 - val_acc: 0.2004\n",
      "Epoch 2582/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2000 - acc: 0.2148 - val_loss: 0.6024 - val_acc: 0.2004\n",
      "Epoch 2583/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1933 - acc: 0.2162 - val_loss: 0.5632 - val_acc: 0.2004\n",
      "Epoch 2584/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2025 - acc: 0.2153 - val_loss: 0.6009 - val_acc: 0.2004\n",
      "Epoch 2585/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2057 - acc: 0.2153 - val_loss: 0.5995 - val_acc: 0.2004\n",
      "Epoch 2586/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2012 - acc: 0.2153 - val_loss: 0.5984 - val_acc: 0.2004\n",
      "Epoch 2587/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1934 - acc: 0.2158 - val_loss: 0.5931 - val_acc: 0.2004\n",
      "Epoch 2588/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2509 - acc: 0.2158 - val_loss: 0.7642 - val_acc: 0.2004\n",
      "Epoch 2589/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2292 - acc: 0.2148 - val_loss: 0.6414 - val_acc: 0.1985\n",
      "Epoch 2590/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1959 - acc: 0.2148 - val_loss: 0.6199 - val_acc: 0.1985\n",
      "Epoch 2591/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2197 - acc: 0.2139 - val_loss: 0.6696 - val_acc: 0.1985\n",
      "Epoch 2592/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2233 - acc: 0.2158 - val_loss: 0.8033 - val_acc: 0.2004\n",
      "Epoch 2593/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2076 - acc: 0.2148 - val_loss: 0.6040 - val_acc: 0.2004\n",
      "Epoch 2594/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1921 - acc: 0.2162 - val_loss: 0.6592 - val_acc: 0.1985\n",
      "Epoch 2595/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1982 - acc: 0.2158 - val_loss: 0.6626 - val_acc: 0.2004\n",
      "Epoch 2596/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2040 - acc: 0.2144 - val_loss: 0.5892 - val_acc: 0.2004\n",
      "Epoch 2597/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2016 - acc: 0.2148 - val_loss: 0.6254 - val_acc: 0.2004\n",
      "Epoch 2598/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1928 - acc: 0.2158 - val_loss: 0.6039 - val_acc: 0.2004\n",
      "Epoch 2599/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1904 - acc: 0.2153 - val_loss: 0.5968 - val_acc: 0.2004\n",
      "Epoch 2600/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2088 - acc: 0.2153 - val_loss: 0.6188 - val_acc: 0.2004\n",
      "Epoch 2601/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2096 - acc: 0.2162 - val_loss: 0.6328 - val_acc: 0.1985\n",
      "Epoch 2602/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2054 - acc: 0.2144 - val_loss: 0.5990 - val_acc: 0.2004\n",
      "Epoch 2603/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2034 - acc: 0.2153 - val_loss: 0.6425 - val_acc: 0.1967\n",
      "Epoch 2604/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2033 - acc: 0.2167 - val_loss: 0.6098 - val_acc: 0.2004\n",
      "Epoch 2605/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2034 - acc: 0.2153 - val_loss: 0.5960 - val_acc: 0.2004\n",
      "Epoch 2606/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2063 - acc: 0.2158 - val_loss: 0.8273 - val_acc: 0.2004\n",
      "Epoch 2607/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2050 - acc: 0.2153 - val_loss: 0.6051 - val_acc: 0.2004\n",
      "Epoch 2608/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1899 - acc: 0.2148 - val_loss: 0.6610 - val_acc: 0.2004\n",
      "Epoch 2609/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2190 - acc: 0.2153 - val_loss: 0.5676 - val_acc: 0.2004\n",
      "Epoch 2610/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1987 - acc: 0.2153 - val_loss: 0.6032 - val_acc: 0.2004\n",
      "Epoch 2611/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2041 - acc: 0.2162 - val_loss: 0.6619 - val_acc: 0.2004\n",
      "Epoch 2612/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2030 - acc: 0.2148 - val_loss: 0.6191 - val_acc: 0.2004\n",
      "Epoch 2613/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2156 - acc: 0.2148 - val_loss: 0.6362 - val_acc: 0.2004\n",
      "Epoch 2614/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2132 - acc: 0.2144 - val_loss: 0.6502 - val_acc: 0.2004\n",
      "Epoch 2615/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2303 - acc: 0.2153 - val_loss: 0.6673 - val_acc: 0.2004\n",
      "Epoch 2616/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2458 - acc: 0.2144 - val_loss: 0.5524 - val_acc: 0.2004\n",
      "Epoch 2617/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2030 - acc: 0.2153 - val_loss: 0.6032 - val_acc: 0.1985\n",
      "Epoch 2618/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2255 - acc: 0.2158 - val_loss: 0.7218 - val_acc: 0.2004\n",
      "Epoch 2619/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2093 - acc: 0.2148 - val_loss: 0.6049 - val_acc: 0.2004\n",
      "Epoch 2620/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1902 - acc: 0.2158 - val_loss: 0.5856 - val_acc: 0.2004\n",
      "Epoch 2621/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2036 - acc: 0.2144 - val_loss: 0.5976 - val_acc: 0.2004\n",
      "Epoch 2622/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2388 - acc: 0.2158 - val_loss: 0.6068 - val_acc: 0.2004\n",
      "Epoch 2623/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1805 - acc: 0.2158 - val_loss: 0.5817 - val_acc: 0.2004\n",
      "Epoch 2624/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.2106 - acc: 0.2153 - val_loss: 0.6351 - val_acc: 0.1985\n",
      "Epoch 2625/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.1887 - acc: 0.2158 - val_loss: 0.6189 - val_acc: 0.2004\n",
      "Epoch 2626/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2187 - acc: 0.2162 - val_loss: 0.7136 - val_acc: 0.2004\n",
      "Epoch 2627/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2175 - acc: 0.2148 - val_loss: 0.6101 - val_acc: 0.2004\n",
      "Epoch 2628/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1850 - acc: 0.2148 - val_loss: 0.6182 - val_acc: 0.2004\n",
      "Epoch 2629/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1990 - acc: 0.2153 - val_loss: 0.6847 - val_acc: 0.2004\n",
      "Epoch 2630/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1937 - acc: 0.2162 - val_loss: 0.6359 - val_acc: 0.1985\n",
      "Epoch 2631/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1917 - acc: 0.2158 - val_loss: 0.6381 - val_acc: 0.2004\n",
      "Epoch 2632/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1990 - acc: 0.2144 - val_loss: 0.6011 - val_acc: 0.2004\n",
      "Epoch 2633/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2144 - acc: 0.2148 - val_loss: 0.6772 - val_acc: 0.2004\n",
      "Epoch 2634/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2247 - acc: 0.2148 - val_loss: 0.5997 - val_acc: 0.2004\n",
      "Epoch 2635/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1970 - acc: 0.2158 - val_loss: 0.6356 - val_acc: 0.1985\n",
      "Epoch 2636/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1993 - acc: 0.2153 - val_loss: 0.6044 - val_acc: 0.2004\n",
      "Epoch 2637/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1901 - acc: 0.2158 - val_loss: 0.6314 - val_acc: 0.1985\n",
      "Epoch 2638/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2048 - acc: 0.2162 - val_loss: 0.5889 - val_acc: 0.2004\n",
      "Epoch 2639/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1962 - acc: 0.2153 - val_loss: 0.7136 - val_acc: 0.1967\n",
      "Epoch 2640/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2237 - acc: 0.2158 - val_loss: 0.5946 - val_acc: 0.2004\n",
      "Epoch 2641/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1941 - acc: 0.2167 - val_loss: 0.6314 - val_acc: 0.2004\n",
      "Epoch 2642/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2078 - acc: 0.2158 - val_loss: 0.6469 - val_acc: 0.1985\n",
      "Epoch 2643/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2226 - acc: 0.2144 - val_loss: 0.6070 - val_acc: 0.2004\n",
      "Epoch 2644/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2062 - acc: 0.2153 - val_loss: 0.6212 - val_acc: 0.2004\n",
      "Epoch 2645/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1974 - acc: 0.2158 - val_loss: 0.6245 - val_acc: 0.2004\n",
      "Epoch 2646/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2620 - acc: 0.2111 - val_loss: 0.8243 - val_acc: 0.1967\n",
      "Epoch 2647/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2186 - acc: 0.2148 - val_loss: 0.6323 - val_acc: 0.2004\n",
      "Epoch 2648/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1905 - acc: 0.2153 - val_loss: 0.5913 - val_acc: 0.2004\n",
      "Epoch 2649/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1817 - acc: 0.2158 - val_loss: 0.6209 - val_acc: 0.1985\n",
      "Epoch 2650/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2253 - acc: 0.2158 - val_loss: 0.7751 - val_acc: 0.1967\n",
      "Epoch 2651/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.6933 - acc: 0.2139 - val_loss: 0.6893 - val_acc: 0.2004\n",
      "Epoch 2652/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.4224 - acc: 0.2158 - val_loss: 0.8558 - val_acc: 0.2004\n",
      "Epoch 2653/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 2.0873 - acc: 0.1949 - val_loss: 1.3372 - val_acc: 0.2004\n",
      "Epoch 2654/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4079 - acc: 0.2148 - val_loss: 0.5298 - val_acc: 0.2004\n",
      "Epoch 2655/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2191 - acc: 0.2167 - val_loss: 0.5628 - val_acc: 0.2004\n",
      "Epoch 2656/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1936 - acc: 0.2162 - val_loss: 0.5511 - val_acc: 0.2004\n",
      "Epoch 2657/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1894 - acc: 0.2158 - val_loss: 0.5767 - val_acc: 0.2004\n",
      "Epoch 2658/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1928 - acc: 0.2153 - val_loss: 0.5269 - val_acc: 0.2004\n",
      "Epoch 2659/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2158 - acc: 0.2153 - val_loss: 0.5666 - val_acc: 0.2004\n",
      "Epoch 2660/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1932 - acc: 0.2167 - val_loss: 0.5805 - val_acc: 0.2004\n",
      "Epoch 2661/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1839 - acc: 0.2158 - val_loss: 0.6594 - val_acc: 0.2004\n",
      "Epoch 2662/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1867 - acc: 0.2158 - val_loss: 0.5512 - val_acc: 0.2004\n",
      "Epoch 2663/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1785 - acc: 0.2153 - val_loss: 0.5465 - val_acc: 0.2004\n",
      "Epoch 2664/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2063 - acc: 0.2153 - val_loss: 0.5706 - val_acc: 0.2004\n",
      "Epoch 2665/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1790 - acc: 0.2158 - val_loss: 0.5706 - val_acc: 0.2004\n",
      "Epoch 2666/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1864 - acc: 0.2162 - val_loss: 0.5647 - val_acc: 0.2004\n",
      "Epoch 2667/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1882 - acc: 0.2148 - val_loss: 0.5914 - val_acc: 0.1985\n",
      "Epoch 2668/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1853 - acc: 0.2162 - val_loss: 0.5915 - val_acc: 0.2004\n",
      "Epoch 2669/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1790 - acc: 0.2158 - val_loss: 0.6119 - val_acc: 0.2004\n",
      "Epoch 2670/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1805 - acc: 0.2162 - val_loss: 0.6928 - val_acc: 0.1967\n",
      "Epoch 2671/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1880 - acc: 0.2162 - val_loss: 0.6282 - val_acc: 0.1985\n",
      "Epoch 2672/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1923 - acc: 0.2148 - val_loss: 0.5828 - val_acc: 0.2004\n",
      "Epoch 2673/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2048 - acc: 0.2153 - val_loss: 0.5764 - val_acc: 0.2004\n",
      "Epoch 2674/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1982 - acc: 0.2162 - val_loss: 0.5649 - val_acc: 0.2004\n",
      "Epoch 2675/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2267 - acc: 0.2153 - val_loss: 0.5591 - val_acc: 0.2004\n",
      "Epoch 2676/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1835 - acc: 0.2162 - val_loss: 0.5762 - val_acc: 0.2004\n",
      "Epoch 2677/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2038 - acc: 0.2148 - val_loss: 0.6087 - val_acc: 0.2004\n",
      "Epoch 2678/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1972 - acc: 0.2158 - val_loss: 0.5948 - val_acc: 0.2004\n",
      "Epoch 2679/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1861 - acc: 0.2153 - val_loss: 0.6490 - val_acc: 0.2004\n",
      "Epoch 2680/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2008 - acc: 0.2148 - val_loss: 0.6058 - val_acc: 0.2004\n",
      "Epoch 2681/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2220 - acc: 0.2162 - val_loss: 0.6375 - val_acc: 0.2004\n",
      "Epoch 2682/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2016 - acc: 0.2158 - val_loss: 0.6473 - val_acc: 0.2004\n",
      "Epoch 2683/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1954 - acc: 0.2162 - val_loss: 0.5479 - val_acc: 0.2004\n",
      "Epoch 2684/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2120 - acc: 0.2162 - val_loss: 0.5991 - val_acc: 0.2004\n",
      "Epoch 2685/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2231 - acc: 0.2144 - val_loss: 0.6248 - val_acc: 0.2004\n",
      "Epoch 2686/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1830 - acc: 0.2158 - val_loss: 0.5954 - val_acc: 0.2004\n",
      "Epoch 2687/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1878 - acc: 0.2162 - val_loss: 0.5974 - val_acc: 0.2004\n",
      "Epoch 2688/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2000 - acc: 0.2158 - val_loss: 0.5729 - val_acc: 0.2004\n",
      "Epoch 2689/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1834 - acc: 0.2158 - val_loss: 0.6055 - val_acc: 0.2004\n",
      "Epoch 2690/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2187 - acc: 0.2153 - val_loss: 0.6199 - val_acc: 0.2004\n",
      "Epoch 2691/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1934 - acc: 0.2153 - val_loss: 0.5866 - val_acc: 0.2004\n",
      "Epoch 2692/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1884 - acc: 0.2162 - val_loss: 0.6125 - val_acc: 0.2004\n",
      "Epoch 2693/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1860 - acc: 0.2158 - val_loss: 0.5842 - val_acc: 0.2004\n",
      "Epoch 2694/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1954 - acc: 0.2148 - val_loss: 0.6637 - val_acc: 0.1985\n",
      "Epoch 2695/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1834 - acc: 0.2162 - val_loss: 0.6793 - val_acc: 0.1985\n",
      "Epoch 2696/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2161 - acc: 0.2162 - val_loss: 0.6008 - val_acc: 0.2004\n",
      "Epoch 2697/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1883 - acc: 0.2148 - val_loss: 0.6106 - val_acc: 0.1985\n",
      "Epoch 2698/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1974 - acc: 0.2162 - val_loss: 0.6160 - val_acc: 0.1985\n",
      "Epoch 2699/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1898 - acc: 0.2172 - val_loss: 0.5814 - val_acc: 0.2004\n",
      "Epoch 2700/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1815 - acc: 0.2158 - val_loss: 0.6097 - val_acc: 0.2004\n",
      "Epoch 2701/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1970 - acc: 0.2158 - val_loss: 1.0038 - val_acc: 0.2004\n",
      "Epoch 2702/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2498 - acc: 0.2153 - val_loss: 0.6395 - val_acc: 0.2004\n",
      "Epoch 2703/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2215 - acc: 0.2158 - val_loss: 0.6810 - val_acc: 0.1967\n",
      "Epoch 2704/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1961 - acc: 0.2158 - val_loss: 0.6087 - val_acc: 0.2004\n",
      "Epoch 2705/4000\n",
      "68/68 [==============================] - 5s 74ms/step - loss: 0.2141 - acc: 0.2135 - val_loss: 0.5888 - val_acc: 0.2004\n",
      "Epoch 2706/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2121 - acc: 0.2148 - val_loss: 0.6604 - val_acc: 0.2004\n",
      "Epoch 2707/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2362 - acc: 0.2162 - val_loss: 0.6418 - val_acc: 0.2004\n",
      "Epoch 2708/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2340 - acc: 0.2162 - val_loss: 0.7466 - val_acc: 0.2004\n",
      "Epoch 2709/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2142 - acc: 0.2158 - val_loss: 0.5951 - val_acc: 0.2004\n",
      "Epoch 2710/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1978 - acc: 0.2153 - val_loss: 0.6127 - val_acc: 0.2004\n",
      "Epoch 2711/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2040 - acc: 0.2162 - val_loss: 0.7131 - val_acc: 0.2004\n",
      "Epoch 2712/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2157 - acc: 0.2158 - val_loss: 0.5861 - val_acc: 0.2004\n",
      "Epoch 2713/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1993 - acc: 0.2144 - val_loss: 0.5811 - val_acc: 0.2004\n",
      "Epoch 2714/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1880 - acc: 0.2162 - val_loss: 0.5959 - val_acc: 0.2004\n",
      "Epoch 2715/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1952 - acc: 0.2153 - val_loss: 0.5899 - val_acc: 0.2004\n",
      "Epoch 2716/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1827 - acc: 0.2167 - val_loss: 0.5870 - val_acc: 0.2004\n",
      "Epoch 2717/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1953 - acc: 0.2158 - val_loss: 0.6331 - val_acc: 0.2004\n",
      "Epoch 2718/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1869 - acc: 0.2162 - val_loss: 0.6004 - val_acc: 0.1985\n",
      "Epoch 2719/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1901 - acc: 0.2158 - val_loss: 0.6393 - val_acc: 0.2004\n",
      "Epoch 2720/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1975 - acc: 0.2153 - val_loss: 0.5976 - val_acc: 0.1985\n",
      "Epoch 2721/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1958 - acc: 0.2148 - val_loss: 0.6172 - val_acc: 0.2004\n",
      "Epoch 2722/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1873 - acc: 0.2162 - val_loss: 0.6715 - val_acc: 0.1985\n",
      "Epoch 2723/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2846 - acc: 0.2139 - val_loss: 0.7103 - val_acc: 0.2004\n",
      "Epoch 2724/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2103 - acc: 0.2144 - val_loss: 0.6293 - val_acc: 0.1985\n",
      "Epoch 2725/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1882 - acc: 0.2153 - val_loss: 0.6405 - val_acc: 0.2004\n",
      "Epoch 2726/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2002 - acc: 0.2162 - val_loss: 0.6102 - val_acc: 0.2004\n",
      "Epoch 2727/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1987 - acc: 0.2148 - val_loss: 0.5623 - val_acc: 0.1985\n",
      "Epoch 2728/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1866 - acc: 0.2153 - val_loss: 0.6475 - val_acc: 0.1985\n",
      "Epoch 2729/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1972 - acc: 0.2162 - val_loss: 0.6067 - val_acc: 0.2004\n",
      "Epoch 2730/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2090 - acc: 0.2158 - val_loss: 0.5775 - val_acc: 0.2004\n",
      "Epoch 2731/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1907 - acc: 0.2162 - val_loss: 0.7857 - val_acc: 0.2004\n",
      "Epoch 2732/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1930 - acc: 0.2153 - val_loss: 0.5806 - val_acc: 0.2004\n",
      "Epoch 2733/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1866 - acc: 0.2153 - val_loss: 0.5997 - val_acc: 0.2004\n",
      "Epoch 2734/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2014 - acc: 0.2158 - val_loss: 0.6737 - val_acc: 0.1967\n",
      "Epoch 2735/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1858 - acc: 0.2153 - val_loss: 0.6060 - val_acc: 0.2004\n",
      "Epoch 2736/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1815 - acc: 0.2148 - val_loss: 0.5773 - val_acc: 0.2004\n",
      "Epoch 2737/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1867 - acc: 0.2153 - val_loss: 0.6308 - val_acc: 0.1985\n",
      "Epoch 2738/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2001 - acc: 0.2148 - val_loss: 0.6332 - val_acc: 0.1985\n",
      "Epoch 2739/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2057 - acc: 0.2148 - val_loss: 0.6322 - val_acc: 0.1985\n",
      "Epoch 2740/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1920 - acc: 0.2158 - val_loss: 0.6127 - val_acc: 0.1985\n",
      "Epoch 2741/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2356 - acc: 0.2153 - val_loss: 0.6836 - val_acc: 0.1985\n",
      "Epoch 2742/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2182 - acc: 0.2144 - val_loss: 0.6678 - val_acc: 0.2004\n",
      "Epoch 2743/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2105 - acc: 0.2148 - val_loss: 0.6107 - val_acc: 0.2004\n",
      "Epoch 2744/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2004 - acc: 0.2158 - val_loss: 0.6514 - val_acc: 0.1985\n",
      "Epoch 2745/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2097 - acc: 0.2148 - val_loss: 0.6076 - val_acc: 0.1985\n",
      "Epoch 2746/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2574 - acc: 0.2158 - val_loss: 0.6094 - val_acc: 0.2004\n",
      "Epoch 2747/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1964 - acc: 0.2153 - val_loss: 0.5934 - val_acc: 0.2004\n",
      "Epoch 2748/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1881 - acc: 0.2158 - val_loss: 0.6051 - val_acc: 0.2004\n",
      "Epoch 2749/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1986 - acc: 0.2162 - val_loss: 0.7517 - val_acc: 0.1967\n",
      "Epoch 2750/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2047 - acc: 0.2153 - val_loss: 0.5936 - val_acc: 0.2004\n",
      "Epoch 2751/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2373 - acc: 0.2162 - val_loss: 0.5846 - val_acc: 0.2004\n",
      "Epoch 2752/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1975 - acc: 0.2153 - val_loss: 0.6610 - val_acc: 0.1985\n",
      "Epoch 2753/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1877 - acc: 0.2158 - val_loss: 0.5963 - val_acc: 0.2004\n",
      "Epoch 2754/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2015 - acc: 0.2153 - val_loss: 0.8061 - val_acc: 0.2004\n",
      "Epoch 2755/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1931 - acc: 0.2158 - val_loss: 0.6061 - val_acc: 0.2004\n",
      "Epoch 2756/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1869 - acc: 0.2158 - val_loss: 0.6152 - val_acc: 0.2004\n",
      "Epoch 2757/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1825 - acc: 0.2153 - val_loss: 0.6004 - val_acc: 0.2004\n",
      "Epoch 2758/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2070 - acc: 0.2162 - val_loss: 0.5653 - val_acc: 0.2004\n",
      "Epoch 2759/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2039 - acc: 0.2162 - val_loss: 0.6167 - val_acc: 0.2004\n",
      "Epoch 2760/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1827 - acc: 0.2167 - val_loss: 0.6041 - val_acc: 0.2004\n",
      "Epoch 2761/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1894 - acc: 0.2158 - val_loss: 0.6017 - val_acc: 0.2004\n",
      "Epoch 2762/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2028 - acc: 0.2162 - val_loss: 0.5939 - val_acc: 0.2004\n",
      "Epoch 2763/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2006 - acc: 0.2158 - val_loss: 0.6172 - val_acc: 0.1985\n",
      "Epoch 2764/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2044 - acc: 0.2167 - val_loss: 0.5958 - val_acc: 0.2004\n",
      "Epoch 2765/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1918 - acc: 0.2162 - val_loss: 0.6094 - val_acc: 0.2004\n",
      "Epoch 2766/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1947 - acc: 0.2153 - val_loss: 0.6529 - val_acc: 0.1985\n",
      "Epoch 2767/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2010 - acc: 0.2162 - val_loss: 0.6297 - val_acc: 0.2004\n",
      "Epoch 2768/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1916 - acc: 0.2148 - val_loss: 0.6201 - val_acc: 0.1985\n",
      "Epoch 2769/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2028 - acc: 0.2158 - val_loss: 0.6685 - val_acc: 0.2004\n",
      "Epoch 2770/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1890 - acc: 0.2153 - val_loss: 0.5974 - val_acc: 0.1985\n",
      "Epoch 2771/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2022 - acc: 0.2158 - val_loss: 0.7647 - val_acc: 0.2004\n",
      "Epoch 2772/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2600 - acc: 0.2162 - val_loss: 0.7136 - val_acc: 0.2004\n",
      "Epoch 2773/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2247 - acc: 0.2148 - val_loss: 0.6257 - val_acc: 0.1985\n",
      "Epoch 2774/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2053 - acc: 0.2148 - val_loss: 0.6262 - val_acc: 0.1985\n",
      "Epoch 2775/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1927 - acc: 0.2148 - val_loss: 0.6261 - val_acc: 0.2004\n",
      "Epoch 2776/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1838 - acc: 0.2162 - val_loss: 0.6427 - val_acc: 0.2004\n",
      "Epoch 2777/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2291 - acc: 0.2158 - val_loss: 0.6078 - val_acc: 0.2004\n",
      "Epoch 2778/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1938 - acc: 0.2153 - val_loss: 0.6449 - val_acc: 0.1985\n",
      "Epoch 2779/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2021 - acc: 0.2167 - val_loss: 0.6201 - val_acc: 0.2004\n",
      "Epoch 2780/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1885 - acc: 0.2153 - val_loss: 0.6416 - val_acc: 0.2004\n",
      "Epoch 2781/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2142 - acc: 0.2158 - val_loss: 0.6182 - val_acc: 0.2004\n",
      "Epoch 2782/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1918 - acc: 0.2148 - val_loss: 0.5995 - val_acc: 0.2004\n",
      "Epoch 2783/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.4878 - acc: 0.2158 - val_loss: 0.7940 - val_acc: 0.2004\n",
      "Epoch 2784/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.6738 - acc: 0.2125 - val_loss: 0.7541 - val_acc: 0.2004\n",
      "Epoch 2785/4000\n",
      "68/68 [==============================] - 5s 71ms/step - loss: 0.3955 - acc: 0.2153 - val_loss: 0.6441 - val_acc: 0.2004\n",
      "Epoch 2786/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3249 - acc: 0.2158 - val_loss: 0.5971 - val_acc: 0.2004\n",
      "Epoch 2787/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2071 - acc: 0.2162 - val_loss: 0.6146 - val_acc: 0.2004\n",
      "Epoch 2788/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2102 - acc: 0.2167 - val_loss: 0.6679 - val_acc: 0.1985\n",
      "Epoch 2789/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1895 - acc: 0.2167 - val_loss: 0.6245 - val_acc: 0.2004\n",
      "Epoch 2790/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2077 - acc: 0.2167 - val_loss: 0.5697 - val_acc: 0.2004\n",
      "Epoch 2791/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1961 - acc: 0.2162 - val_loss: 0.6443 - val_acc: 0.1985\n",
      "Epoch 2792/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1892 - acc: 0.2158 - val_loss: 0.6057 - val_acc: 0.2004\n",
      "Epoch 2793/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1832 - acc: 0.2158 - val_loss: 0.6226 - val_acc: 0.2004\n",
      "Epoch 2794/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2029 - acc: 0.2153 - val_loss: 0.6048 - val_acc: 0.2004\n",
      "Epoch 2795/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2108 - acc: 0.2158 - val_loss: 0.5829 - val_acc: 0.2004\n",
      "Epoch 2796/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1874 - acc: 0.2153 - val_loss: 0.6349 - val_acc: 0.2004\n",
      "Epoch 2797/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2043 - acc: 0.2144 - val_loss: 0.6164 - val_acc: 0.2004\n",
      "Epoch 2798/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2116 - acc: 0.2144 - val_loss: 0.5968 - val_acc: 0.2004\n",
      "Epoch 2799/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1909 - acc: 0.2158 - val_loss: 0.5849 - val_acc: 0.2004\n",
      "Epoch 2800/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.1936 - acc: 0.2148 - val_loss: 0.6722 - val_acc: 0.1985\n",
      "Epoch 2801/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1850 - acc: 0.2148 - val_loss: 0.6310 - val_acc: 0.1985\n",
      "Epoch 2802/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1896 - acc: 0.2153 - val_loss: 0.6195 - val_acc: 0.2004\n",
      "Epoch 2803/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2058 - acc: 0.2153 - val_loss: 0.6040 - val_acc: 0.2004\n",
      "Epoch 2804/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1978 - acc: 0.2144 - val_loss: 0.5987 - val_acc: 0.2004\n",
      "Epoch 2805/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1888 - acc: 0.2162 - val_loss: 0.5930 - val_acc: 0.2004\n",
      "Epoch 2806/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1829 - acc: 0.2153 - val_loss: 0.6223 - val_acc: 0.2004\n",
      "Epoch 2807/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.1766 - acc: 0.2158 - val_loss: 0.6059 - val_acc: 0.2004\n",
      "Epoch 2808/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1870 - acc: 0.2158 - val_loss: 0.5935 - val_acc: 0.2004\n",
      "Epoch 2809/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2022 - acc: 0.2153 - val_loss: 0.6028 - val_acc: 0.2004\n",
      "Epoch 2810/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1951 - acc: 0.2148 - val_loss: 0.8170 - val_acc: 0.2004\n",
      "Epoch 2811/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1999 - acc: 0.2148 - val_loss: 0.6071 - val_acc: 0.2004\n",
      "Epoch 2812/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1809 - acc: 0.2148 - val_loss: 0.6021 - val_acc: 0.2004\n",
      "Epoch 2813/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2223 - acc: 0.2158 - val_loss: 0.7541 - val_acc: 0.1967\n",
      "Epoch 2814/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2002 - acc: 0.2148 - val_loss: 0.6852 - val_acc: 0.1985\n",
      "Epoch 2815/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2004 - acc: 0.2162 - val_loss: 0.5975 - val_acc: 0.2004\n",
      "Epoch 2816/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2187 - acc: 0.2153 - val_loss: 0.7540 - val_acc: 0.1967\n",
      "Epoch 2817/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2024 - acc: 0.2158 - val_loss: 0.5861 - val_acc: 0.2004\n",
      "Epoch 2818/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1844 - acc: 0.2158 - val_loss: 0.6862 - val_acc: 0.1967\n",
      "Epoch 2819/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1835 - acc: 0.2158 - val_loss: 0.6195 - val_acc: 0.2004\n",
      "Epoch 2820/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1897 - acc: 0.2153 - val_loss: 0.7492 - val_acc: 0.1967\n",
      "Epoch 2821/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2186 - acc: 0.2148 - val_loss: 0.6924 - val_acc: 0.1985\n",
      "Epoch 2822/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2101 - acc: 0.2144 - val_loss: 0.6475 - val_acc: 0.1985\n",
      "Epoch 2823/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1891 - acc: 0.2139 - val_loss: 0.6373 - val_acc: 0.2004\n",
      "Epoch 2824/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1866 - acc: 0.2158 - val_loss: 0.6073 - val_acc: 0.2004\n",
      "Epoch 2825/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1856 - acc: 0.2167 - val_loss: 0.5794 - val_acc: 0.2004\n",
      "Epoch 2826/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.3193 - acc: 0.2037 - val_loss: 0.5943 - val_acc: 0.2004\n",
      "Epoch 2827/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1797 - acc: 0.2158 - val_loss: 0.6707 - val_acc: 0.1967\n",
      "Epoch 2828/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1869 - acc: 0.2158 - val_loss: 0.6634 - val_acc: 0.1985\n",
      "Epoch 2829/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2004 - acc: 0.2153 - val_loss: 0.6007 - val_acc: 0.1985\n",
      "Epoch 2830/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1826 - acc: 0.2158 - val_loss: 0.6186 - val_acc: 0.2004\n",
      "Epoch 2831/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1961 - acc: 0.2144 - val_loss: 0.6239 - val_acc: 0.2004\n",
      "Epoch 2832/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1903 - acc: 0.2158 - val_loss: 0.6142 - val_acc: 0.2004\n",
      "Epoch 2833/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.1795 - acc: 0.2158 - val_loss: 0.6014 - val_acc: 0.2004\n",
      "Epoch 2834/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1903 - acc: 0.2153 - val_loss: 0.5938 - val_acc: 0.2004\n",
      "Epoch 2835/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1975 - acc: 0.2158 - val_loss: 0.6118 - val_acc: 0.2004\n",
      "Epoch 2836/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1893 - acc: 0.2162 - val_loss: 0.5990 - val_acc: 0.2004\n",
      "Epoch 2837/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1797 - acc: 0.2144 - val_loss: 0.6246 - val_acc: 0.2004\n",
      "Epoch 2838/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1954 - acc: 0.2153 - val_loss: 0.6537 - val_acc: 0.1967\n",
      "Epoch 2839/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1891 - acc: 0.2158 - val_loss: 0.6287 - val_acc: 0.1985\n",
      "Epoch 2840/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.1810 - acc: 0.2153 - val_loss: 0.6668 - val_acc: 0.2004\n",
      "Epoch 2841/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2226 - acc: 0.2158 - val_loss: 0.6573 - val_acc: 0.2004\n",
      "Epoch 2842/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1967 - acc: 0.2162 - val_loss: 0.6085 - val_acc: 0.2004\n",
      "Epoch 2843/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1792 - acc: 0.2153 - val_loss: 0.6112 - val_acc: 0.1985\n",
      "Epoch 2844/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1832 - acc: 0.2167 - val_loss: 0.5907 - val_acc: 0.2004\n",
      "Epoch 2845/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2105 - acc: 0.2153 - val_loss: 0.6009 - val_acc: 0.2004\n",
      "Epoch 2846/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1874 - acc: 0.2162 - val_loss: 0.6035 - val_acc: 0.2004\n",
      "Epoch 2847/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2050 - acc: 0.2153 - val_loss: 0.7042 - val_acc: 0.1967\n",
      "Epoch 2848/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.2190 - acc: 0.2167 - val_loss: 0.5942 - val_acc: 0.2004\n",
      "Epoch 2849/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1875 - acc: 0.2158 - val_loss: 0.6081 - val_acc: 0.2004\n",
      "Epoch 2850/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1928 - acc: 0.2148 - val_loss: 0.6894 - val_acc: 0.2004\n",
      "Epoch 2851/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1975 - acc: 0.2148 - val_loss: 0.6145 - val_acc: 0.2004\n",
      "Epoch 2852/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1996 - acc: 0.2153 - val_loss: 0.5947 - val_acc: 0.2004\n",
      "Epoch 2853/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2003 - acc: 0.2153 - val_loss: 0.7037 - val_acc: 0.1967\n",
      "Epoch 2854/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2056 - acc: 0.2148 - val_loss: 0.6372 - val_acc: 0.2004\n",
      "Epoch 2855/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.1963 - acc: 0.2158 - val_loss: 0.5881 - val_acc: 0.2004\n",
      "Epoch 2856/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1927 - acc: 0.2158 - val_loss: 0.5924 - val_acc: 0.2004\n",
      "Epoch 2857/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1994 - acc: 0.2153 - val_loss: 0.6463 - val_acc: 0.1985\n",
      "Epoch 2858/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1992 - acc: 0.2153 - val_loss: 0.7114 - val_acc: 0.1967\n",
      "Epoch 2859/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2112 - acc: 0.2162 - val_loss: 0.6710 - val_acc: 0.2004\n",
      "Epoch 2860/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2047 - acc: 0.2167 - val_loss: 0.6305 - val_acc: 0.2004\n",
      "Epoch 2861/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2096 - acc: 0.2158 - val_loss: 0.6123 - val_acc: 0.2004\n",
      "Epoch 2862/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1848 - acc: 0.2153 - val_loss: 0.5846 - val_acc: 0.2004\n",
      "Epoch 2863/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1898 - acc: 0.2153 - val_loss: 0.7334 - val_acc: 0.2004\n",
      "Epoch 2864/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1829 - acc: 0.2162 - val_loss: 0.5994 - val_acc: 0.2004\n",
      "Epoch 2865/4000\n",
      "68/68 [==============================] - 5s 71ms/step - loss: 0.2295 - acc: 0.2144 - val_loss: 0.7067 - val_acc: 0.2004\n",
      "Epoch 2866/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2001 - acc: 0.2162 - val_loss: 0.6009 - val_acc: 0.2004\n",
      "Epoch 2867/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2140 - acc: 0.2158 - val_loss: 0.6334 - val_acc: 0.2004\n",
      "Epoch 2868/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2327 - acc: 0.2153 - val_loss: 0.5734 - val_acc: 0.2004\n",
      "Epoch 2869/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2926 - acc: 0.2162 - val_loss: 0.7642 - val_acc: 0.1985\n",
      "Epoch 2870/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2633 - acc: 0.2153 - val_loss: 0.5739 - val_acc: 0.1985\n",
      "Epoch 2871/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2581 - acc: 0.2148 - val_loss: 0.5823 - val_acc: 0.2004\n",
      "Epoch 2872/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2748 - acc: 0.2144 - val_loss: 0.5561 - val_acc: 0.2004\n",
      "Epoch 2873/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3659 - acc: 0.2158 - val_loss: 0.7920 - val_acc: 0.2004\n",
      "Epoch 2874/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3008 - acc: 0.2153 - val_loss: 0.6632 - val_acc: 0.2004\n",
      "Epoch 2875/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.4490 - acc: 0.2148 - val_loss: 0.5580 - val_acc: 0.2004\n",
      "Epoch 2876/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2274 - acc: 0.2158 - val_loss: 0.7390 - val_acc: 0.2004\n",
      "Epoch 2877/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2413 - acc: 0.2139 - val_loss: 0.5807 - val_acc: 0.2004\n",
      "Epoch 2878/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2088 - acc: 0.2162 - val_loss: 0.5759 - val_acc: 0.1985\n",
      "Epoch 2879/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2178 - acc: 0.2162 - val_loss: 0.5898 - val_acc: 0.2004\n",
      "Epoch 2880/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2326 - acc: 0.2162 - val_loss: 0.7750 - val_acc: 0.2004\n",
      "Epoch 2881/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2045 - acc: 0.2162 - val_loss: 0.5823 - val_acc: 0.2004\n",
      "Epoch 2882/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1980 - acc: 0.2153 - val_loss: 0.6142 - val_acc: 0.2004\n",
      "Epoch 2883/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2074 - acc: 0.2148 - val_loss: 0.6669 - val_acc: 0.1985\n",
      "Epoch 2884/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1897 - acc: 0.2158 - val_loss: 0.5584 - val_acc: 0.2004\n",
      "Epoch 2885/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1943 - acc: 0.2153 - val_loss: 0.7209 - val_acc: 0.2004\n",
      "Epoch 2886/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1852 - acc: 0.2158 - val_loss: 0.7161 - val_acc: 0.1967\n",
      "Epoch 2887/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1981 - acc: 0.2158 - val_loss: 0.5876 - val_acc: 0.2004\n",
      "Epoch 2888/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1787 - acc: 0.2167 - val_loss: 0.5869 - val_acc: 0.2004\n",
      "Epoch 2889/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1895 - acc: 0.2167 - val_loss: 0.6610 - val_acc: 0.2004\n",
      "Epoch 2890/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2034 - acc: 0.2158 - val_loss: 0.5736 - val_acc: 0.2004\n",
      "Epoch 2891/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2011 - acc: 0.2158 - val_loss: 0.6240 - val_acc: 0.2004\n",
      "Epoch 2892/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2222 - acc: 0.2162 - val_loss: 0.6077 - val_acc: 0.2004\n",
      "Epoch 2893/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1962 - acc: 0.2148 - val_loss: 0.5688 - val_acc: 0.2004\n",
      "Epoch 2894/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1827 - acc: 0.2148 - val_loss: 0.6652 - val_acc: 0.2004\n",
      "Epoch 2895/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1936 - acc: 0.2148 - val_loss: 0.6035 - val_acc: 0.2004\n",
      "Epoch 2896/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1967 - acc: 0.2153 - val_loss: 0.5787 - val_acc: 0.2004\n",
      "Epoch 2897/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1781 - acc: 0.2167 - val_loss: 0.5936 - val_acc: 0.1985\n",
      "Epoch 2898/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1836 - acc: 0.2153 - val_loss: 0.6207 - val_acc: 0.1985\n",
      "Epoch 2899/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1931 - acc: 0.2162 - val_loss: 0.6323 - val_acc: 0.2004\n",
      "Epoch 2900/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2120 - acc: 0.2162 - val_loss: 0.5860 - val_acc: 0.2004\n",
      "Epoch 2901/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2048 - acc: 0.2153 - val_loss: 0.5910 - val_acc: 0.2004\n",
      "Epoch 2902/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2463 - acc: 0.2153 - val_loss: 0.5859 - val_acc: 0.1985\n",
      "Epoch 2903/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1969 - acc: 0.2148 - val_loss: 0.5760 - val_acc: 0.2004\n",
      "Epoch 2904/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1817 - acc: 0.2153 - val_loss: 0.5964 - val_acc: 0.2004\n",
      "Epoch 2905/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1802 - acc: 0.2172 - val_loss: 0.5819 - val_acc: 0.2004\n",
      "Epoch 2906/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1845 - acc: 0.2162 - val_loss: 0.6592 - val_acc: 0.2004\n",
      "Epoch 2907/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2023 - acc: 0.2144 - val_loss: 0.6050 - val_acc: 0.2004\n",
      "Epoch 2908/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2106 - acc: 0.2144 - val_loss: 0.6662 - val_acc: 0.2004\n",
      "Epoch 2909/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1933 - acc: 0.2153 - val_loss: 0.6043 - val_acc: 0.1985\n",
      "Epoch 2910/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1893 - acc: 0.2162 - val_loss: 0.5851 - val_acc: 0.2004\n",
      "Epoch 2911/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1787 - acc: 0.2144 - val_loss: 0.6502 - val_acc: 0.2004\n",
      "Epoch 2912/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1952 - acc: 0.2153 - val_loss: 0.7064 - val_acc: 0.2004\n",
      "Epoch 2913/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2037 - acc: 0.2153 - val_loss: 0.8040 - val_acc: 0.1929\n",
      "Epoch 2914/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2084 - acc: 0.2153 - val_loss: 0.6139 - val_acc: 0.2004\n",
      "Epoch 2915/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1956 - acc: 0.2144 - val_loss: 0.6029 - val_acc: 0.2004\n",
      "Epoch 2916/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1794 - acc: 0.2162 - val_loss: 0.5678 - val_acc: 0.2004\n",
      "Epoch 2917/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1978 - acc: 0.2153 - val_loss: 0.5933 - val_acc: 0.2004\n",
      "Epoch 2918/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1796 - acc: 0.2158 - val_loss: 0.5708 - val_acc: 0.2004\n",
      "Epoch 2919/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2028 - acc: 0.2148 - val_loss: 0.8954 - val_acc: 0.2004\n",
      "Epoch 2920/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2039 - acc: 0.2158 - val_loss: 0.6364 - val_acc: 0.1985\n",
      "Epoch 2921/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1859 - acc: 0.2148 - val_loss: 0.6014 - val_acc: 0.2004\n",
      "Epoch 2922/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1882 - acc: 0.2162 - val_loss: 0.5738 - val_acc: 0.2004\n",
      "Epoch 2923/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1858 - acc: 0.2158 - val_loss: 0.5965 - val_acc: 0.2004\n",
      "Epoch 2924/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2174 - acc: 0.2158 - val_loss: 0.5981 - val_acc: 0.2004\n",
      "Epoch 2925/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1983 - acc: 0.2153 - val_loss: 0.6171 - val_acc: 0.2004\n",
      "Epoch 2926/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2195 - acc: 0.2167 - val_loss: 0.6477 - val_acc: 0.2004\n",
      "Epoch 2927/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1895 - acc: 0.2167 - val_loss: 0.6103 - val_acc: 0.2004\n",
      "Epoch 2928/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1831 - acc: 0.2153 - val_loss: 0.6038 - val_acc: 0.1985\n",
      "Epoch 2929/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2297 - acc: 0.2144 - val_loss: 0.5946 - val_acc: 0.1985\n",
      "Epoch 2930/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1928 - acc: 0.2158 - val_loss: 0.5577 - val_acc: 0.2004\n",
      "Epoch 2931/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1928 - acc: 0.2153 - val_loss: 0.6229 - val_acc: 0.2004\n",
      "Epoch 2932/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1796 - acc: 0.2153 - val_loss: 0.5870 - val_acc: 0.2004\n",
      "Epoch 2933/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1839 - acc: 0.2162 - val_loss: 0.7620 - val_acc: 0.2004\n",
      "Epoch 2934/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1987 - acc: 0.2153 - val_loss: 0.5724 - val_acc: 0.2004\n",
      "Epoch 2935/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2257 - acc: 0.2148 - val_loss: 0.6010 - val_acc: 0.2004\n",
      "Epoch 2936/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1995 - acc: 0.2148 - val_loss: 0.6026 - val_acc: 0.2004\n",
      "Epoch 2937/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1891 - acc: 0.2148 - val_loss: 0.5893 - val_acc: 0.2004\n",
      "Epoch 2938/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1815 - acc: 0.2158 - val_loss: 0.6154 - val_acc: 0.1985\n",
      "Epoch 2939/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1850 - acc: 0.2158 - val_loss: 0.6811 - val_acc: 0.1967\n",
      "Epoch 2940/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2497 - acc: 0.2144 - val_loss: 0.6251 - val_acc: 0.2004\n",
      "Epoch 2941/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2203 - acc: 0.2144 - val_loss: 0.6936 - val_acc: 0.2004\n",
      "Epoch 2942/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2014 - acc: 0.2162 - val_loss: 0.6908 - val_acc: 0.2004\n",
      "Epoch 2943/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2185 - acc: 0.2153 - val_loss: 0.5783 - val_acc: 0.2004\n",
      "Epoch 2944/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2067 - acc: 0.2167 - val_loss: 0.6076 - val_acc: 0.2004\n",
      "Epoch 2945/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1896 - acc: 0.2158 - val_loss: 0.5955 - val_acc: 0.2004\n",
      "Epoch 2946/4000\n",
      "68/68 [==============================] - 5s 73ms/step - loss: 0.1819 - acc: 0.2144 - val_loss: 0.6032 - val_acc: 0.2004\n",
      "Epoch 2947/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1827 - acc: 0.2158 - val_loss: 0.6067 - val_acc: 0.2004\n",
      "Epoch 2948/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1964 - acc: 0.2153 - val_loss: 0.5688 - val_acc: 0.2004\n",
      "Epoch 2949/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1961 - acc: 0.2153 - val_loss: 0.6237 - val_acc: 0.1985\n",
      "Epoch 2950/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1938 - acc: 0.2162 - val_loss: 0.5950 - val_acc: 0.2004\n",
      "Epoch 2951/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1861 - acc: 0.2172 - val_loss: 0.5931 - val_acc: 0.2004\n",
      "Epoch 2952/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2237 - acc: 0.2130 - val_loss: 0.6371 - val_acc: 0.2004\n",
      "Epoch 2953/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1819 - acc: 0.2153 - val_loss: 0.6022 - val_acc: 0.2004\n",
      "Epoch 2954/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2099 - acc: 0.2148 - val_loss: 0.6227 - val_acc: 0.2004\n",
      "Epoch 2955/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1892 - acc: 0.2153 - val_loss: 0.6195 - val_acc: 0.2004\n",
      "Epoch 2956/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1928 - acc: 0.2153 - val_loss: 0.6185 - val_acc: 0.2004\n",
      "Epoch 2957/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1788 - acc: 0.2148 - val_loss: 0.6158 - val_acc: 0.2004\n",
      "Epoch 2958/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1889 - acc: 0.2148 - val_loss: 0.6201 - val_acc: 0.2004\n",
      "Epoch 2959/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1866 - acc: 0.2158 - val_loss: 0.5834 - val_acc: 0.2004\n",
      "Epoch 2960/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2338 - acc: 0.2162 - val_loss: 0.7116 - val_acc: 0.2004\n",
      "Epoch 2961/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.1971 - acc: 0.2144 - val_loss: 0.5789 - val_acc: 0.2004\n",
      "Epoch 2962/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2316 - acc: 0.2139 - val_loss: 0.7303 - val_acc: 0.1967\n",
      "Epoch 2963/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2121 - acc: 0.2153 - val_loss: 0.6358 - val_acc: 0.2004\n",
      "Epoch 2964/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1854 - acc: 0.2153 - val_loss: 0.5778 - val_acc: 0.2004\n",
      "Epoch 2965/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1770 - acc: 0.2162 - val_loss: 0.5594 - val_acc: 0.2004\n",
      "Epoch 2966/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1956 - acc: 0.2162 - val_loss: 0.7198 - val_acc: 0.2004\n",
      "Epoch 2967/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2234 - acc: 0.2144 - val_loss: 0.7713 - val_acc: 0.1967\n",
      "Epoch 2968/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2050 - acc: 0.2153 - val_loss: 0.6372 - val_acc: 0.1967\n",
      "Epoch 2969/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2119 - acc: 0.2148 - val_loss: 0.6194 - val_acc: 0.2004\n",
      "Epoch 2970/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1890 - acc: 0.2158 - val_loss: 0.5963 - val_acc: 0.2004\n",
      "Epoch 2971/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1808 - acc: 0.2153 - val_loss: 0.6375 - val_acc: 0.2004\n",
      "Epoch 2972/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1958 - acc: 0.2153 - val_loss: 0.6488 - val_acc: 0.2004\n",
      "Epoch 2973/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1894 - acc: 0.2158 - val_loss: 0.6128 - val_acc: 0.2004\n",
      "Epoch 2974/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1937 - acc: 0.2153 - val_loss: 0.6522 - val_acc: 0.1985\n",
      "Epoch 2975/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1913 - acc: 0.2158 - val_loss: 0.6051 - val_acc: 0.2004\n",
      "Epoch 2976/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1846 - acc: 0.2158 - val_loss: 0.5834 - val_acc: 0.2004\n",
      "Epoch 2977/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2067 - acc: 0.2153 - val_loss: 0.6426 - val_acc: 0.2004\n",
      "Epoch 2978/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1983 - acc: 0.2153 - val_loss: 0.7276 - val_acc: 0.2004\n",
      "Epoch 2979/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2097 - acc: 0.2153 - val_loss: 0.8072 - val_acc: 0.1948\n",
      "Epoch 2980/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2000 - acc: 0.2158 - val_loss: 0.5959 - val_acc: 0.2004\n",
      "Epoch 2981/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1823 - acc: 0.2172 - val_loss: 0.6100 - val_acc: 0.2004\n",
      "Epoch 2982/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1752 - acc: 0.2144 - val_loss: 0.6224 - val_acc: 0.2004\n",
      "Epoch 2983/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1843 - acc: 0.2162 - val_loss: 0.5946 - val_acc: 0.2004\n",
      "Epoch 2984/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2211 - acc: 0.2153 - val_loss: 0.5960 - val_acc: 0.2004\n",
      "Epoch 2985/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1823 - acc: 0.2158 - val_loss: 0.6592 - val_acc: 0.1967\n",
      "Epoch 2986/4000\n",
      "68/68 [==============================] - 5s 70ms/step - loss: 0.1893 - acc: 0.2148 - val_loss: 0.5907 - val_acc: 0.2004\n",
      "Epoch 2987/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1915 - acc: 0.2153 - val_loss: 0.5857 - val_acc: 0.2004\n",
      "Epoch 2988/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1897 - acc: 0.2148 - val_loss: 0.6665 - val_acc: 0.2004\n",
      "Epoch 2989/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1873 - acc: 0.2153 - val_loss: 0.5964 - val_acc: 0.1985\n",
      "Epoch 2990/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1780 - acc: 0.2158 - val_loss: 0.6249 - val_acc: 0.1967\n",
      "Epoch 2991/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1857 - acc: 0.2158 - val_loss: 0.6066 - val_acc: 0.2004\n",
      "Epoch 2992/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1948 - acc: 0.2144 - val_loss: 0.5957 - val_acc: 0.2004\n",
      "Epoch 2993/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2450 - acc: 0.2148 - val_loss: 0.8203 - val_acc: 0.2004\n",
      "Epoch 2994/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2054 - acc: 0.2139 - val_loss: 0.5978 - val_acc: 0.2004\n",
      "Epoch 2995/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2050 - acc: 0.2162 - val_loss: 0.6143 - val_acc: 0.1967\n",
      "Epoch 2996/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1930 - acc: 0.2153 - val_loss: 0.6087 - val_acc: 0.2004\n",
      "Epoch 2997/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2080 - acc: 0.2148 - val_loss: 0.7139 - val_acc: 0.2004\n",
      "Epoch 2998/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1910 - acc: 0.2148 - val_loss: 0.6326 - val_acc: 0.2004\n",
      "Epoch 2999/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1999 - acc: 0.2148 - val_loss: 0.7087 - val_acc: 0.2004\n",
      "Epoch 3000/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2022 - acc: 0.2153 - val_loss: 0.5984 - val_acc: 0.2004\n",
      "Epoch 3001/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1919 - acc: 0.2144 - val_loss: 0.5875 - val_acc: 0.2004\n",
      "Epoch 3002/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1838 - acc: 0.2148 - val_loss: 0.6395 - val_acc: 0.2004\n",
      "Epoch 3003/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1839 - acc: 0.2158 - val_loss: 0.5936 - val_acc: 0.2004\n",
      "Epoch 3004/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1979 - acc: 0.2148 - val_loss: 0.6120 - val_acc: 0.2004\n",
      "Epoch 3005/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1987 - acc: 0.2153 - val_loss: 0.6377 - val_acc: 0.2004\n",
      "Epoch 3006/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1980 - acc: 0.2148 - val_loss: 0.6578 - val_acc: 0.2004\n",
      "Epoch 3007/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1831 - acc: 0.2144 - val_loss: 0.6121 - val_acc: 0.2004\n",
      "Epoch 3008/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2171 - acc: 0.2135 - val_loss: 0.7383 - val_acc: 0.1967\n",
      "Epoch 3009/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.7589 - acc: 0.2000 - val_loss: 1.1211 - val_acc: 0.2004\n",
      "Epoch 3010/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.7090 - acc: 0.2121 - val_loss: 1.0776 - val_acc: 0.2004\n",
      "Epoch 3011/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.5693 - acc: 0.2148 - val_loss: 0.6257 - val_acc: 0.2004\n",
      "Epoch 3012/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3834 - acc: 0.2162 - val_loss: 0.6698 - val_acc: 0.2004\n",
      "Epoch 3013/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2475 - acc: 0.2144 - val_loss: 0.6049 - val_acc: 0.2004\n",
      "Epoch 3014/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1869 - acc: 0.2158 - val_loss: 0.5897 - val_acc: 0.2004\n",
      "Epoch 3015/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1739 - acc: 0.2148 - val_loss: 0.6173 - val_acc: 0.2004\n",
      "Epoch 3016/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2107 - acc: 0.2162 - val_loss: 0.6296 - val_acc: 0.1985\n",
      "Epoch 3017/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1842 - acc: 0.2158 - val_loss: 0.6082 - val_acc: 0.2004\n",
      "Epoch 3018/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1755 - acc: 0.2153 - val_loss: 0.6470 - val_acc: 0.2004\n",
      "Epoch 3019/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1836 - acc: 0.2158 - val_loss: 0.5850 - val_acc: 0.2004\n",
      "Epoch 3020/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1858 - acc: 0.2144 - val_loss: 0.5954 - val_acc: 0.2004\n",
      "Epoch 3021/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1789 - acc: 0.2162 - val_loss: 0.5944 - val_acc: 0.1985\n",
      "Epoch 3022/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1861 - acc: 0.2158 - val_loss: 0.5791 - val_acc: 0.2004\n",
      "Epoch 3023/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1947 - acc: 0.2158 - val_loss: 0.5832 - val_acc: 0.2004\n",
      "Epoch 3024/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1732 - acc: 0.2158 - val_loss: 0.5837 - val_acc: 0.2004\n",
      "Epoch 3025/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2102 - acc: 0.2158 - val_loss: 0.6695 - val_acc: 0.2004\n",
      "Epoch 3026/4000\n",
      "68/68 [==============================] - 5s 70ms/step - loss: 0.2468 - acc: 0.2148 - val_loss: 0.5979 - val_acc: 0.2004\n",
      "Epoch 3027/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1955 - acc: 0.2172 - val_loss: 0.6546 - val_acc: 0.2004\n",
      "Epoch 3028/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2120 - acc: 0.2158 - val_loss: 0.5927 - val_acc: 0.2004\n",
      "Epoch 3029/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1917 - acc: 0.2158 - val_loss: 0.6017 - val_acc: 0.2004\n",
      "Epoch 3030/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1740 - acc: 0.2162 - val_loss: 0.5845 - val_acc: 0.2004\n",
      "Epoch 3031/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1732 - acc: 0.2153 - val_loss: 0.6058 - val_acc: 0.2004\n",
      "Epoch 3032/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1848 - acc: 0.2153 - val_loss: 0.5756 - val_acc: 0.2004\n",
      "Epoch 3033/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1982 - acc: 0.2153 - val_loss: 0.5996 - val_acc: 0.2004\n",
      "Epoch 3034/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1928 - acc: 0.2162 - val_loss: 0.5890 - val_acc: 0.2004\n",
      "Epoch 3035/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1776 - acc: 0.2162 - val_loss: 0.5904 - val_acc: 0.2004\n",
      "Epoch 3036/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1866 - acc: 0.2158 - val_loss: 0.6534 - val_acc: 0.2004\n",
      "Epoch 3037/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1857 - acc: 0.2158 - val_loss: 0.6195 - val_acc: 0.1985\n",
      "Epoch 3038/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1985 - acc: 0.2153 - val_loss: 0.6001 - val_acc: 0.2004\n",
      "Epoch 3039/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1916 - acc: 0.2167 - val_loss: 0.6858 - val_acc: 0.1967\n",
      "Epoch 3040/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1731 - acc: 0.2153 - val_loss: 0.6287 - val_acc: 0.1985\n",
      "Epoch 3041/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1849 - acc: 0.2167 - val_loss: 0.6562 - val_acc: 0.1985\n",
      "Epoch 3042/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1802 - acc: 0.2158 - val_loss: 0.5848 - val_acc: 0.2004\n",
      "Epoch 3043/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1791 - acc: 0.2162 - val_loss: 0.6399 - val_acc: 0.2004\n",
      "Epoch 3044/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1887 - acc: 0.2158 - val_loss: 0.6196 - val_acc: 0.1985\n",
      "Epoch 3045/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1789 - acc: 0.2158 - val_loss: 0.5785 - val_acc: 0.2004\n",
      "Epoch 3046/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1724 - acc: 0.2153 - val_loss: 0.5871 - val_acc: 0.2004\n",
      "Epoch 3047/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1833 - acc: 0.2158 - val_loss: 0.7488 - val_acc: 0.2004\n",
      "Epoch 3048/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2208 - acc: 0.2153 - val_loss: 0.6354 - val_acc: 0.1985\n",
      "Epoch 3049/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1827 - acc: 0.2158 - val_loss: 0.5955 - val_acc: 0.2004\n",
      "Epoch 3050/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1941 - acc: 0.2158 - val_loss: 0.6375 - val_acc: 0.2004\n",
      "Epoch 3051/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1896 - acc: 0.2158 - val_loss: 0.6521 - val_acc: 0.2004\n",
      "Epoch 3052/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1958 - acc: 0.2158 - val_loss: 0.7115 - val_acc: 0.2004\n",
      "Epoch 3053/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2210 - acc: 0.2162 - val_loss: 0.6103 - val_acc: 0.1985\n",
      "Epoch 3054/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2355 - acc: 0.2139 - val_loss: 0.5999 - val_acc: 0.2004\n",
      "Epoch 3055/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1805 - acc: 0.2153 - val_loss: 0.6225 - val_acc: 0.2004\n",
      "Epoch 3056/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1895 - acc: 0.2167 - val_loss: 0.5972 - val_acc: 0.2004\n",
      "Epoch 3057/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1875 - acc: 0.2158 - val_loss: 0.5995 - val_acc: 0.2004\n",
      "Epoch 3058/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1705 - acc: 0.2153 - val_loss: 0.6424 - val_acc: 0.1985\n",
      "Epoch 3059/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2073 - acc: 0.2144 - val_loss: 0.6131 - val_acc: 0.2004\n",
      "Epoch 3060/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1874 - acc: 0.2153 - val_loss: 0.5844 - val_acc: 0.2004\n",
      "Epoch 3061/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1917 - acc: 0.2158 - val_loss: 0.6142 - val_acc: 0.2004\n",
      "Epoch 3062/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1922 - acc: 0.2139 - val_loss: 0.6075 - val_acc: 0.2004\n",
      "Epoch 3063/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1867 - acc: 0.2162 - val_loss: 0.6172 - val_acc: 0.2004\n",
      "Epoch 3064/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1894 - acc: 0.2167 - val_loss: 0.6560 - val_acc: 0.1985\n",
      "Epoch 3065/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1729 - acc: 0.2162 - val_loss: 0.5808 - val_acc: 0.2004\n",
      "Epoch 3066/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1988 - acc: 0.2148 - val_loss: 0.6073 - val_acc: 0.2004\n",
      "Epoch 3067/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1889 - acc: 0.2162 - val_loss: 0.6229 - val_acc: 0.2004\n",
      "Epoch 3068/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1814 - acc: 0.2158 - val_loss: 0.5899 - val_acc: 0.2004\n",
      "Epoch 3069/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1928 - acc: 0.2162 - val_loss: 0.6954 - val_acc: 0.1967\n",
      "Epoch 3070/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1850 - acc: 0.2153 - val_loss: 0.6222 - val_acc: 0.2004\n",
      "Epoch 3071/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1932 - acc: 0.2158 - val_loss: 0.6382 - val_acc: 0.2004\n",
      "Epoch 3072/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2252 - acc: 0.2153 - val_loss: 0.8182 - val_acc: 0.2004\n",
      "Epoch 3073/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2151 - acc: 0.2148 - val_loss: 0.6380 - val_acc: 0.2004\n",
      "Epoch 3074/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1923 - acc: 0.2158 - val_loss: 0.6139 - val_acc: 0.2004\n",
      "Epoch 3075/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1882 - acc: 0.2158 - val_loss: 0.6246 - val_acc: 0.2004\n",
      "Epoch 3076/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1844 - acc: 0.2167 - val_loss: 0.5990 - val_acc: 0.2004\n",
      "Epoch 3077/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1960 - acc: 0.2148 - val_loss: 0.6207 - val_acc: 0.1967\n",
      "Epoch 3078/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1996 - acc: 0.2153 - val_loss: 0.6164 - val_acc: 0.2004\n",
      "Epoch 3079/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1806 - acc: 0.2148 - val_loss: 0.5830 - val_acc: 0.2004\n",
      "Epoch 3080/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1875 - acc: 0.2148 - val_loss: 0.6537 - val_acc: 0.1985\n",
      "Epoch 3081/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1983 - acc: 0.2153 - val_loss: 0.7216 - val_acc: 0.2004\n",
      "Epoch 3082/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1809 - acc: 0.2153 - val_loss: 0.5760 - val_acc: 0.2004\n",
      "Epoch 3083/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1690 - acc: 0.2148 - val_loss: 0.5942 - val_acc: 0.2004\n",
      "Epoch 3084/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1874 - acc: 0.2148 - val_loss: 0.8994 - val_acc: 0.2004\n",
      "Epoch 3085/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2192 - acc: 0.2139 - val_loss: 0.6015 - val_acc: 0.2004\n",
      "Epoch 3086/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1817 - acc: 0.2153 - val_loss: 0.6504 - val_acc: 0.2004\n",
      "Epoch 3087/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1795 - acc: 0.2153 - val_loss: 0.7890 - val_acc: 0.2004\n",
      "Epoch 3088/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2148 - acc: 0.2153 - val_loss: 0.6078 - val_acc: 0.2004\n",
      "Epoch 3089/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1855 - acc: 0.2148 - val_loss: 0.6232 - val_acc: 0.2004\n",
      "Epoch 3090/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1990 - acc: 0.2144 - val_loss: 0.6298 - val_acc: 0.2004\n",
      "Epoch 3091/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2307 - acc: 0.2158 - val_loss: 0.6079 - val_acc: 0.2004\n",
      "Epoch 3092/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1984 - acc: 0.2158 - val_loss: 0.6113 - val_acc: 0.2004\n",
      "Epoch 3093/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1912 - acc: 0.2153 - val_loss: 0.5880 - val_acc: 0.2004\n",
      "Epoch 3094/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1860 - acc: 0.2153 - val_loss: 0.5958 - val_acc: 0.2004\n",
      "Epoch 3095/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1777 - acc: 0.2162 - val_loss: 0.6140 - val_acc: 0.2004\n",
      "Epoch 3096/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1996 - acc: 0.2158 - val_loss: 0.6181 - val_acc: 0.2004\n",
      "Epoch 3097/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2396 - acc: 0.2158 - val_loss: 0.8411 - val_acc: 0.1929\n",
      "Epoch 3098/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2103 - acc: 0.2162 - val_loss: 0.6474 - val_acc: 0.2004\n",
      "Epoch 3099/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2126 - acc: 0.2148 - val_loss: 0.6735 - val_acc: 0.2004\n",
      "Epoch 3100/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1943 - acc: 0.2139 - val_loss: 0.6059 - val_acc: 0.2004\n",
      "Epoch 3101/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1853 - acc: 0.2144 - val_loss: 0.6321 - val_acc: 0.2004\n",
      "Epoch 3102/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1919 - acc: 0.2167 - val_loss: 0.6570 - val_acc: 0.1967\n",
      "Epoch 3103/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1868 - acc: 0.2158 - val_loss: 0.6528 - val_acc: 0.1985\n",
      "Epoch 3104/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1974 - acc: 0.2162 - val_loss: 0.6485 - val_acc: 0.2004\n",
      "Epoch 3105/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1781 - acc: 0.2153 - val_loss: 0.5929 - val_acc: 0.2004\n",
      "Epoch 3106/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.1956 - acc: 0.2153 - val_loss: 0.6071 - val_acc: 0.2004\n",
      "Epoch 3107/4000\n",
      "68/68 [==============================] - 5s 69ms/step - loss: 0.1817 - acc: 0.2158 - val_loss: 0.6454 - val_acc: 0.2004\n",
      "Epoch 3108/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1888 - acc: 0.2162 - val_loss: 0.6195 - val_acc: 0.2004\n",
      "Epoch 3109/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1872 - acc: 0.2153 - val_loss: 0.6277 - val_acc: 0.2004\n",
      "Epoch 3110/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1935 - acc: 0.2153 - val_loss: 0.6300 - val_acc: 0.2004\n",
      "Epoch 3111/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1706 - acc: 0.2162 - val_loss: 0.6477 - val_acc: 0.2004\n",
      "Epoch 3112/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1967 - acc: 0.2167 - val_loss: 0.7217 - val_acc: 0.1967\n",
      "Epoch 3113/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2149 - acc: 0.2158 - val_loss: 0.7309 - val_acc: 0.1967\n",
      "Epoch 3114/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2434 - acc: 0.2153 - val_loss: 0.6187 - val_acc: 0.2004\n",
      "Epoch 3115/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1744 - acc: 0.2153 - val_loss: 0.5791 - val_acc: 0.2004\n",
      "Epoch 3116/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1871 - acc: 0.2158 - val_loss: 0.6098 - val_acc: 0.2004\n",
      "Epoch 3117/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2197 - acc: 0.2144 - val_loss: 0.7356 - val_acc: 0.1967\n",
      "Epoch 3118/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1776 - acc: 0.2162 - val_loss: 0.5858 - val_acc: 0.2004\n",
      "Epoch 3119/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1844 - acc: 0.2153 - val_loss: 0.6000 - val_acc: 0.2004\n",
      "Epoch 3120/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1739 - acc: 0.2148 - val_loss: 0.6314 - val_acc: 0.2004\n",
      "Epoch 3121/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1932 - acc: 0.2162 - val_loss: 0.6211 - val_acc: 0.2004\n",
      "Epoch 3122/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1811 - acc: 0.2153 - val_loss: 0.6096 - val_acc: 0.2004\n",
      "Epoch 3123/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1886 - acc: 0.2158 - val_loss: 0.6147 - val_acc: 0.2004\n",
      "Epoch 3124/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2025 - acc: 0.2153 - val_loss: 0.6654 - val_acc: 0.1967\n",
      "Epoch 3125/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2121 - acc: 0.2144 - val_loss: 0.5967 - val_acc: 0.2004\n",
      "Epoch 3126/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2533 - acc: 0.2135 - val_loss: 0.7154 - val_acc: 0.2004\n",
      "Epoch 3127/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1949 - acc: 0.2153 - val_loss: 0.5674 - val_acc: 0.2004\n",
      "Epoch 3128/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2482 - acc: 0.2153 - val_loss: 0.6663 - val_acc: 0.2004\n",
      "Epoch 3129/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1844 - acc: 0.2148 - val_loss: 0.6555 - val_acc: 0.2004\n",
      "Epoch 3130/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2351 - acc: 0.2158 - val_loss: 0.8233 - val_acc: 0.2004\n",
      "Epoch 3131/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4344 - acc: 0.2153 - val_loss: 0.5490 - val_acc: 0.2004\n",
      "Epoch 3132/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3510 - acc: 0.2144 - val_loss: 0.7235 - val_acc: 0.2004\n",
      "Epoch 3133/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3578 - acc: 0.2153 - val_loss: 0.6489 - val_acc: 0.1985\n",
      "Epoch 3134/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.5041 - acc: 0.2139 - val_loss: 0.9644 - val_acc: 0.2004\n",
      "Epoch 3135/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3573 - acc: 0.2144 - val_loss: 0.7860 - val_acc: 0.2004\n",
      "Epoch 3136/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.3723 - acc: 0.2144 - val_loss: 0.5753 - val_acc: 0.2004\n",
      "Epoch 3137/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2102 - acc: 0.2148 - val_loss: 0.5895 - val_acc: 0.2004\n",
      "Epoch 3138/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3781 - acc: 0.2158 - val_loss: 0.7318 - val_acc: 0.1985\n",
      "Epoch 3139/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2093 - acc: 0.2139 - val_loss: 0.6347 - val_acc: 0.1985\n",
      "Epoch 3140/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1785 - acc: 0.2153 - val_loss: 0.5854 - val_acc: 0.2004\n",
      "Epoch 3141/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1767 - acc: 0.2153 - val_loss: 0.5951 - val_acc: 0.2004\n",
      "Epoch 3142/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1801 - acc: 0.2162 - val_loss: 0.5869 - val_acc: 0.2004\n",
      "Epoch 3143/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1865 - acc: 0.2162 - val_loss: 0.5861 - val_acc: 0.2004\n",
      "Epoch 3144/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1732 - acc: 0.2158 - val_loss: 0.6388 - val_acc: 0.1985\n",
      "Epoch 3145/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1724 - acc: 0.2158 - val_loss: 0.5978 - val_acc: 0.2004\n",
      "Epoch 3146/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1775 - acc: 0.2167 - val_loss: 0.5829 - val_acc: 0.2004\n",
      "Epoch 3147/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1797 - acc: 0.2158 - val_loss: 0.5979 - val_acc: 0.2004\n",
      "Epoch 3148/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1730 - acc: 0.2139 - val_loss: 0.5935 - val_acc: 0.2004\n",
      "Epoch 3149/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1833 - acc: 0.2162 - val_loss: 0.5894 - val_acc: 0.2004\n",
      "Epoch 3150/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1785 - acc: 0.2162 - val_loss: 0.5817 - val_acc: 0.2004\n",
      "Epoch 3151/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1967 - acc: 0.2158 - val_loss: 0.6053 - val_acc: 0.1985\n",
      "Epoch 3152/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2076 - acc: 0.2158 - val_loss: 0.5833 - val_acc: 0.2004\n",
      "Epoch 3153/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1900 - acc: 0.2167 - val_loss: 0.5833 - val_acc: 0.2004\n",
      "Epoch 3154/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1702 - acc: 0.2162 - val_loss: 0.6176 - val_acc: 0.2004\n",
      "Epoch 3155/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1822 - acc: 0.2158 - val_loss: 0.6387 - val_acc: 0.1985\n",
      "Epoch 3156/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1765 - acc: 0.2158 - val_loss: 0.5778 - val_acc: 0.2004\n",
      "Epoch 3157/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1772 - acc: 0.2153 - val_loss: 0.6230 - val_acc: 0.2004\n",
      "Epoch 3158/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1770 - acc: 0.2144 - val_loss: 0.6467 - val_acc: 0.1985\n",
      "Epoch 3159/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1721 - acc: 0.2158 - val_loss: 0.6160 - val_acc: 0.1985\n",
      "Epoch 3160/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1885 - acc: 0.2153 - val_loss: 0.6180 - val_acc: 0.2004\n",
      "Epoch 3161/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1823 - acc: 0.2153 - val_loss: 0.6180 - val_acc: 0.1985\n",
      "Epoch 3162/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1771 - acc: 0.2162 - val_loss: 0.5922 - val_acc: 0.1985\n",
      "Epoch 3163/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1912 - acc: 0.2167 - val_loss: 0.6458 - val_acc: 0.1967\n",
      "Epoch 3164/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2142 - acc: 0.2139 - val_loss: 0.9548 - val_acc: 0.1874\n",
      "Epoch 3165/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2060 - acc: 0.2144 - val_loss: 0.6207 - val_acc: 0.1985\n",
      "Epoch 3166/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1734 - acc: 0.2162 - val_loss: 0.6262 - val_acc: 0.1985\n",
      "Epoch 3167/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1666 - acc: 0.2148 - val_loss: 0.6102 - val_acc: 0.2004\n",
      "Epoch 3168/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2034 - acc: 0.2144 - val_loss: 0.5815 - val_acc: 0.2004\n",
      "Epoch 3169/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1810 - acc: 0.2139 - val_loss: 0.6342 - val_acc: 0.2004\n",
      "Epoch 3170/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1828 - acc: 0.2158 - val_loss: 0.5994 - val_acc: 0.1985\n",
      "Epoch 3171/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1899 - acc: 0.2148 - val_loss: 0.5795 - val_acc: 0.2004\n",
      "Epoch 3172/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1815 - acc: 0.2158 - val_loss: 0.6448 - val_acc: 0.1985\n",
      "Epoch 3173/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2130 - acc: 0.2148 - val_loss: 0.6363 - val_acc: 0.1985\n",
      "Epoch 3174/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1863 - acc: 0.2153 - val_loss: 0.6338 - val_acc: 0.2004\n",
      "Epoch 3175/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1739 - acc: 0.2158 - val_loss: 0.6712 - val_acc: 0.2004\n",
      "Epoch 3176/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1919 - acc: 0.2158 - val_loss: 0.5927 - val_acc: 0.1985\n",
      "Epoch 3177/4000\n",
      "68/68 [==============================] - 4s 56ms/step - loss: 0.1817 - acc: 0.2162 - val_loss: 0.5942 - val_acc: 0.2004\n",
      "Epoch 3178/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1889 - acc: 0.2148 - val_loss: 0.6221 - val_acc: 0.2004\n",
      "Epoch 3179/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1975 - acc: 0.2153 - val_loss: 0.6577 - val_acc: 0.2004\n",
      "Epoch 3180/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1841 - acc: 0.2144 - val_loss: 0.7006 - val_acc: 0.2004\n",
      "Epoch 3181/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1993 - acc: 0.2144 - val_loss: 0.6290 - val_acc: 0.2004\n",
      "Epoch 3182/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1796 - acc: 0.2153 - val_loss: 0.6479 - val_acc: 0.2004\n",
      "Epoch 3183/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1958 - acc: 0.2139 - val_loss: 0.6212 - val_acc: 0.2004\n",
      "Epoch 3184/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.1819 - acc: 0.2162 - val_loss: 0.6090 - val_acc: 0.2004\n",
      "Epoch 3185/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1850 - acc: 0.2162 - val_loss: 0.6038 - val_acc: 0.2004\n",
      "Epoch 3186/4000\n",
      "68/68 [==============================] - 5s 71ms/step - loss: 0.1734 - acc: 0.2153 - val_loss: 0.5881 - val_acc: 0.2004\n",
      "Epoch 3187/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1851 - acc: 0.2158 - val_loss: 0.6176 - val_acc: 0.2004\n",
      "Epoch 3188/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2016 - acc: 0.2153 - val_loss: 0.5990 - val_acc: 0.2004\n",
      "Epoch 3189/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1910 - acc: 0.2162 - val_loss: 0.6015 - val_acc: 0.1985\n",
      "Epoch 3190/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1942 - acc: 0.2162 - val_loss: 0.5918 - val_acc: 0.2004\n",
      "Epoch 3191/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1759 - acc: 0.2144 - val_loss: 0.5995 - val_acc: 0.2004\n",
      "Epoch 3192/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1832 - acc: 0.2158 - val_loss: 0.6044 - val_acc: 0.2004\n",
      "Epoch 3193/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1750 - acc: 0.2153 - val_loss: 0.5746 - val_acc: 0.2004\n",
      "Epoch 3194/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2024 - acc: 0.2153 - val_loss: 0.6190 - val_acc: 0.2004\n",
      "Epoch 3195/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1883 - acc: 0.2139 - val_loss: 0.6216 - val_acc: 0.1985\n",
      "Epoch 3196/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1775 - acc: 0.2158 - val_loss: 0.6204 - val_acc: 0.1985\n",
      "Epoch 3197/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2023 - acc: 0.2153 - val_loss: 0.5810 - val_acc: 0.2004\n",
      "Epoch 3198/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.2176 - acc: 0.2148 - val_loss: 0.6389 - val_acc: 0.2004\n",
      "Epoch 3199/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1798 - acc: 0.2158 - val_loss: 0.5553 - val_acc: 0.2004\n",
      "Epoch 3200/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1836 - acc: 0.2153 - val_loss: 0.5934 - val_acc: 0.2004\n",
      "Epoch 3201/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2037 - acc: 0.2144 - val_loss: 0.7019 - val_acc: 0.2004\n",
      "Epoch 3202/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2562 - acc: 0.2162 - val_loss: 0.5750 - val_acc: 0.2004\n",
      "Epoch 3203/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2157 - acc: 0.2153 - val_loss: 0.6464 - val_acc: 0.1985\n",
      "Epoch 3204/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2286 - acc: 0.2153 - val_loss: 0.5976 - val_acc: 0.2004\n",
      "Epoch 3205/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.5543 - acc: 0.2023 - val_loss: 0.9626 - val_acc: 0.2004\n",
      "Epoch 3206/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.3938 - acc: 0.2158 - val_loss: 0.7204 - val_acc: 0.2004\n",
      "Epoch 3207/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2567 - acc: 0.2153 - val_loss: 0.5581 - val_acc: 0.2004\n",
      "Epoch 3208/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2629 - acc: 0.2162 - val_loss: 0.5937 - val_acc: 0.2004\n",
      "Epoch 3209/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2105 - acc: 0.2162 - val_loss: 0.6137 - val_acc: 0.2004\n",
      "Epoch 3210/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1794 - acc: 0.2162 - val_loss: 0.5819 - val_acc: 0.2004\n",
      "Epoch 3211/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1800 - acc: 0.2158 - val_loss: 0.6880 - val_acc: 0.1967\n",
      "Epoch 3212/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1855 - acc: 0.2153 - val_loss: 0.5948 - val_acc: 0.2004\n",
      "Epoch 3213/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2194 - acc: 0.2139 - val_loss: 0.7309 - val_acc: 0.2004\n",
      "Epoch 3214/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1805 - acc: 0.2153 - val_loss: 0.5749 - val_acc: 0.2004\n",
      "Epoch 3215/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1704 - acc: 0.2148 - val_loss: 0.6135 - val_acc: 0.2004\n",
      "Epoch 3216/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1709 - acc: 0.2158 - val_loss: 0.6326 - val_acc: 0.2004\n",
      "Epoch 3217/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1700 - acc: 0.2158 - val_loss: 0.5996 - val_acc: 0.2004\n",
      "Epoch 3218/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1699 - acc: 0.2153 - val_loss: 0.5802 - val_acc: 0.2004\n",
      "Epoch 3219/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1798 - acc: 0.2153 - val_loss: 0.7687 - val_acc: 0.1967\n",
      "Epoch 3220/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2118 - acc: 0.2144 - val_loss: 0.5817 - val_acc: 0.2004\n",
      "Epoch 3221/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1792 - acc: 0.2153 - val_loss: 0.5838 - val_acc: 0.2004\n",
      "Epoch 3222/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1702 - acc: 0.2162 - val_loss: 0.5918 - val_acc: 0.2004\n",
      "Epoch 3223/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1676 - acc: 0.2158 - val_loss: 0.5937 - val_acc: 0.2004\n",
      "Epoch 3224/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1682 - acc: 0.2158 - val_loss: 0.5977 - val_acc: 0.2004\n",
      "Epoch 3225/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1906 - acc: 0.2162 - val_loss: 0.5871 - val_acc: 0.2004\n",
      "Epoch 3226/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1942 - acc: 0.2153 - val_loss: 0.5968 - val_acc: 0.2004\n",
      "Epoch 3227/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1877 - acc: 0.2167 - val_loss: 0.5983 - val_acc: 0.2004\n",
      "Epoch 3228/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2046 - acc: 0.2158 - val_loss: 0.6211 - val_acc: 0.2004\n",
      "Epoch 3229/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1809 - acc: 0.2172 - val_loss: 0.5871 - val_acc: 0.2004\n",
      "Epoch 3230/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1716 - acc: 0.2148 - val_loss: 0.6101 - val_acc: 0.2004\n",
      "Epoch 3231/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1798 - acc: 0.2162 - val_loss: 0.6709 - val_acc: 0.2004\n",
      "Epoch 3232/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1777 - acc: 0.2162 - val_loss: 0.5894 - val_acc: 0.2004\n",
      "Epoch 3233/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1730 - acc: 0.2167 - val_loss: 0.6009 - val_acc: 0.2004\n",
      "Epoch 3234/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1664 - acc: 0.2158 - val_loss: 0.6187 - val_acc: 0.2004\n",
      "Epoch 3235/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1816 - acc: 0.2153 - val_loss: 0.6029 - val_acc: 0.2004\n",
      "Epoch 3236/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1833 - acc: 0.2162 - val_loss: 0.5814 - val_acc: 0.2004\n",
      "Epoch 3237/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1920 - acc: 0.2153 - val_loss: 0.6100 - val_acc: 0.2004\n",
      "Epoch 3238/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1831 - acc: 0.2158 - val_loss: 0.5974 - val_acc: 0.2004\n",
      "Epoch 3239/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1836 - acc: 0.2144 - val_loss: 0.5887 - val_acc: 0.2004\n",
      "Epoch 3240/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1957 - acc: 0.2158 - val_loss: 0.6736 - val_acc: 0.1967\n",
      "Epoch 3241/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2097 - acc: 0.2153 - val_loss: 0.6588 - val_acc: 0.2004\n",
      "Epoch 3242/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2050 - acc: 0.2162 - val_loss: 0.5864 - val_acc: 0.2004\n",
      "Epoch 3243/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1720 - acc: 0.2148 - val_loss: 0.5960 - val_acc: 0.2004\n",
      "Epoch 3244/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1764 - acc: 0.2158 - val_loss: 0.5944 - val_acc: 0.2004\n",
      "Epoch 3245/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1776 - acc: 0.2148 - val_loss: 0.5990 - val_acc: 0.2004\n",
      "Epoch 3246/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1767 - acc: 0.2153 - val_loss: 0.6320 - val_acc: 0.2004\n",
      "Epoch 3247/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1852 - acc: 0.2148 - val_loss: 0.5922 - val_acc: 0.2004\n",
      "Epoch 3248/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1863 - acc: 0.2148 - val_loss: 0.6292 - val_acc: 0.1985\n",
      "Epoch 3249/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1917 - acc: 0.2148 - val_loss: 0.6457 - val_acc: 0.2004\n",
      "Epoch 3250/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1886 - acc: 0.2148 - val_loss: 0.5879 - val_acc: 0.2004\n",
      "Epoch 3251/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1785 - acc: 0.2167 - val_loss: 0.5777 - val_acc: 0.2004\n",
      "Epoch 3252/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1905 - acc: 0.2158 - val_loss: 0.7189 - val_acc: 0.2004\n",
      "Epoch 3253/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1883 - acc: 0.2162 - val_loss: 0.6279 - val_acc: 0.2004\n",
      "Epoch 3254/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1821 - acc: 0.2162 - val_loss: 0.6238 - val_acc: 0.2004\n",
      "Epoch 3255/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1894 - acc: 0.2153 - val_loss: 0.6112 - val_acc: 0.2004\n",
      "Epoch 3256/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2015 - acc: 0.2158 - val_loss: 0.6515 - val_acc: 0.2004\n",
      "Epoch 3257/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1841 - acc: 0.2167 - val_loss: 0.5899 - val_acc: 0.2004\n",
      "Epoch 3258/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1736 - acc: 0.2158 - val_loss: 0.6185 - val_acc: 0.2004\n",
      "Epoch 3259/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1693 - acc: 0.2158 - val_loss: 0.6135 - val_acc: 0.2004\n",
      "Epoch 3260/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1782 - acc: 0.2148 - val_loss: 0.5912 - val_acc: 0.2004\n",
      "Epoch 3261/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1804 - acc: 0.2153 - val_loss: 0.5992 - val_acc: 0.2004\n",
      "Epoch 3262/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1903 - acc: 0.2153 - val_loss: 0.6438 - val_acc: 0.1967\n",
      "Epoch 3263/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1782 - acc: 0.2162 - val_loss: 0.6925 - val_acc: 0.2004\n",
      "Epoch 3264/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2035 - acc: 0.2148 - val_loss: 0.6078 - val_acc: 0.2004\n",
      "Epoch 3265/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1850 - acc: 0.2158 - val_loss: 0.6410 - val_acc: 0.1985\n",
      "Epoch 3266/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.1872 - acc: 0.2153 - val_loss: 0.6128 - val_acc: 0.2004\n",
      "Epoch 3267/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.1825 - acc: 0.2153 - val_loss: 0.6205 - val_acc: 0.2004\n",
      "Epoch 3268/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1921 - acc: 0.2158 - val_loss: 0.6532 - val_acc: 0.2004\n",
      "Epoch 3269/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1850 - acc: 0.2148 - val_loss: 0.6239 - val_acc: 0.2004\n",
      "Epoch 3270/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2285 - acc: 0.2148 - val_loss: 0.5963 - val_acc: 0.2004\n",
      "Epoch 3271/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1943 - acc: 0.2144 - val_loss: 0.6214 - val_acc: 0.2004\n",
      "Epoch 3272/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1742 - acc: 0.2158 - val_loss: 0.6140 - val_acc: 0.2004\n",
      "Epoch 3273/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1776 - acc: 0.2167 - val_loss: 0.6280 - val_acc: 0.2004\n",
      "Epoch 3274/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1818 - acc: 0.2153 - val_loss: 0.6383 - val_acc: 0.1985\n",
      "Epoch 3275/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1964 - acc: 0.2153 - val_loss: 0.6016 - val_acc: 0.2004\n",
      "Epoch 3276/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1962 - acc: 0.2153 - val_loss: 0.6042 - val_acc: 0.2004\n",
      "Epoch 3277/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1788 - acc: 0.2153 - val_loss: 0.6335 - val_acc: 0.2004\n",
      "Epoch 3278/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1730 - acc: 0.2162 - val_loss: 0.5760 - val_acc: 0.2004\n",
      "Epoch 3279/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1668 - acc: 0.2153 - val_loss: 0.6775 - val_acc: 0.1967\n",
      "Epoch 3280/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2168 - acc: 0.2148 - val_loss: 0.8302 - val_acc: 0.1929\n",
      "Epoch 3281/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2240 - acc: 0.2153 - val_loss: 0.6606 - val_acc: 0.2004\n",
      "Epoch 3282/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2435 - acc: 0.2144 - val_loss: 0.7146 - val_acc: 0.1967\n",
      "Epoch 3283/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2432 - acc: 0.2144 - val_loss: 0.8963 - val_acc: 0.2004\n",
      "Epoch 3284/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2260 - acc: 0.2153 - val_loss: 0.6283 - val_acc: 0.2004\n",
      "Epoch 3285/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1942 - acc: 0.2158 - val_loss: 0.7658 - val_acc: 0.1967\n",
      "Epoch 3286/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1827 - acc: 0.2162 - val_loss: 0.6026 - val_acc: 0.2004\n",
      "Epoch 3287/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1880 - acc: 0.2162 - val_loss: 0.6528 - val_acc: 0.1985\n",
      "Epoch 3288/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1734 - acc: 0.2167 - val_loss: 0.6014 - val_acc: 0.2004\n",
      "Epoch 3289/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1824 - acc: 0.2153 - val_loss: 0.6195 - val_acc: 0.2004\n",
      "Epoch 3290/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2066 - acc: 0.2158 - val_loss: 0.6240 - val_acc: 0.2004\n",
      "Epoch 3291/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1906 - acc: 0.2158 - val_loss: 0.6136 - val_acc: 0.2004\n",
      "Epoch 3292/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1738 - acc: 0.2153 - val_loss: 0.5989 - val_acc: 0.2004\n",
      "Epoch 3293/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1847 - acc: 0.2162 - val_loss: 0.6098 - val_acc: 0.2004\n",
      "Epoch 3294/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1856 - acc: 0.2158 - val_loss: 0.5761 - val_acc: 0.2004\n",
      "Epoch 3295/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1810 - acc: 0.2153 - val_loss: 0.5924 - val_acc: 0.2004\n",
      "Epoch 3296/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1860 - acc: 0.2148 - val_loss: 0.6324 - val_acc: 0.2004\n",
      "Epoch 3297/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1855 - acc: 0.2158 - val_loss: 0.5969 - val_acc: 0.2004\n",
      "Epoch 3298/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1770 - acc: 0.2148 - val_loss: 0.6486 - val_acc: 0.2004\n",
      "Epoch 3299/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1787 - acc: 0.2148 - val_loss: 0.6203 - val_acc: 0.2004\n",
      "Epoch 3300/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1926 - acc: 0.2158 - val_loss: 0.5786 - val_acc: 0.2004\n",
      "Epoch 3301/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2122 - acc: 0.2139 - val_loss: 0.6066 - val_acc: 0.2004\n",
      "Epoch 3302/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2042 - acc: 0.2158 - val_loss: 0.5993 - val_acc: 0.2004\n",
      "Epoch 3303/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2149 - acc: 0.2144 - val_loss: 0.6594 - val_acc: 0.2004\n",
      "Epoch 3304/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1779 - acc: 0.2167 - val_loss: 0.6044 - val_acc: 0.2004\n",
      "Epoch 3305/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1718 - acc: 0.2158 - val_loss: 0.6091 - val_acc: 0.2004\n",
      "Epoch 3306/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1794 - acc: 0.2153 - val_loss: 0.6387 - val_acc: 0.2004\n",
      "Epoch 3307/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1743 - acc: 0.2162 - val_loss: 0.6725 - val_acc: 0.1985\n",
      "Epoch 3308/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2026 - acc: 0.2158 - val_loss: 0.6993 - val_acc: 0.2004\n",
      "Epoch 3309/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1952 - acc: 0.2158 - val_loss: 0.6340 - val_acc: 0.2004\n",
      "Epoch 3310/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1776 - acc: 0.2158 - val_loss: 0.7463 - val_acc: 0.1967\n",
      "Epoch 3311/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1948 - acc: 0.2162 - val_loss: 0.6104 - val_acc: 0.2004\n",
      "Epoch 3312/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1665 - acc: 0.2162 - val_loss: 0.6336 - val_acc: 0.2004\n",
      "Epoch 3313/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1859 - acc: 0.2153 - val_loss: 0.6404 - val_acc: 0.2004\n",
      "Epoch 3314/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2009 - acc: 0.2162 - val_loss: 0.6833 - val_acc: 0.1967\n",
      "Epoch 3315/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1772 - acc: 0.2153 - val_loss: 0.6410 - val_acc: 0.2004\n",
      "Epoch 3316/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1765 - acc: 0.2158 - val_loss: 0.5822 - val_acc: 0.2004\n",
      "Epoch 3317/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1847 - acc: 0.2158 - val_loss: 0.6821 - val_acc: 0.2004\n",
      "Epoch 3318/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1937 - acc: 0.2158 - val_loss: 0.6037 - val_acc: 0.2004\n",
      "Epoch 3319/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1852 - acc: 0.2153 - val_loss: 0.6279 - val_acc: 0.2004\n",
      "Epoch 3320/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1757 - acc: 0.2162 - val_loss: 0.5891 - val_acc: 0.2004\n",
      "Epoch 3321/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1674 - acc: 0.2167 - val_loss: 0.6109 - val_acc: 0.2004\n",
      "Epoch 3322/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1795 - acc: 0.2158 - val_loss: 0.7764 - val_acc: 0.1948\n",
      "Epoch 3323/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2123 - acc: 0.2148 - val_loss: 0.5923 - val_acc: 0.2004\n",
      "Epoch 3324/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1669 - acc: 0.2158 - val_loss: 0.6240 - val_acc: 0.2004\n",
      "Epoch 3325/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1695 - acc: 0.2148 - val_loss: 0.5938 - val_acc: 0.2004\n",
      "Epoch 3326/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1824 - acc: 0.2148 - val_loss: 0.7593 - val_acc: 0.2004\n",
      "Epoch 3327/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2174 - acc: 0.2153 - val_loss: 0.6890 - val_acc: 0.2004\n",
      "Epoch 3328/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2091 - acc: 0.2148 - val_loss: 0.6535 - val_acc: 0.2004\n",
      "Epoch 3329/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1982 - acc: 0.2135 - val_loss: 0.6492 - val_acc: 0.1985\n",
      "Epoch 3330/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1943 - acc: 0.2158 - val_loss: 0.7540 - val_acc: 0.2004\n",
      "Epoch 3331/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4948 - acc: 0.2144 - val_loss: 0.6326 - val_acc: 0.2004\n",
      "Epoch 3332/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3456 - acc: 0.2153 - val_loss: 0.7877 - val_acc: 0.1967\n",
      "Epoch 3333/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2852 - acc: 0.2153 - val_loss: 0.8277 - val_acc: 0.2004\n",
      "Epoch 3334/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2330 - acc: 0.2148 - val_loss: 0.6088 - val_acc: 0.1985\n",
      "Epoch 3335/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1925 - acc: 0.2144 - val_loss: 0.5993 - val_acc: 0.2004\n",
      "Epoch 3336/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1983 - acc: 0.2153 - val_loss: 0.6616 - val_acc: 0.2004\n",
      "Epoch 3337/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1742 - acc: 0.2153 - val_loss: 0.6206 - val_acc: 0.1985\n",
      "Epoch 3338/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1758 - acc: 0.2153 - val_loss: 0.6344 - val_acc: 0.1985\n",
      "Epoch 3339/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1999 - acc: 0.2139 - val_loss: 0.5953 - val_acc: 0.2004\n",
      "Epoch 3340/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1728 - acc: 0.2167 - val_loss: 0.7670 - val_acc: 0.2004\n",
      "Epoch 3341/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1929 - acc: 0.2162 - val_loss: 0.5693 - val_acc: 0.2004\n",
      "Epoch 3342/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1668 - acc: 0.2162 - val_loss: 0.6473 - val_acc: 0.1967\n",
      "Epoch 3343/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1767 - acc: 0.2158 - val_loss: 0.5777 - val_acc: 0.2004\n",
      "Epoch 3344/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1781 - acc: 0.2162 - val_loss: 0.5719 - val_acc: 0.2004\n",
      "Epoch 3345/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1711 - acc: 0.2162 - val_loss: 0.6319 - val_acc: 0.1985\n",
      "Epoch 3346/4000\n",
      "68/68 [==============================] - 5s 69ms/step - loss: 0.1953 - acc: 0.2144 - val_loss: 0.7132 - val_acc: 0.2004\n",
      "Epoch 3347/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.1780 - acc: 0.2158 - val_loss: 0.5976 - val_acc: 0.2004\n",
      "Epoch 3348/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1697 - acc: 0.2158 - val_loss: 0.5974 - val_acc: 0.2004\n",
      "Epoch 3349/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1724 - acc: 0.2148 - val_loss: 0.5904 - val_acc: 0.2004\n",
      "Epoch 3350/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1833 - acc: 0.2153 - val_loss: 0.6009 - val_acc: 0.2004\n",
      "Epoch 3351/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1697 - acc: 0.2158 - val_loss: 0.5992 - val_acc: 0.2004\n",
      "Epoch 3352/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1662 - acc: 0.2158 - val_loss: 0.6022 - val_acc: 0.2004\n",
      "Epoch 3353/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1633 - acc: 0.2162 - val_loss: 0.6073 - val_acc: 0.2004\n",
      "Epoch 3354/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1781 - acc: 0.2158 - val_loss: 0.6049 - val_acc: 0.2004\n",
      "Epoch 3355/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1932 - acc: 0.2148 - val_loss: 0.6343 - val_acc: 0.1985\n",
      "Epoch 3356/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1973 - acc: 0.2148 - val_loss: 0.5864 - val_acc: 0.2004\n",
      "Epoch 3357/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1837 - acc: 0.2153 - val_loss: 0.6036 - val_acc: 0.2004\n",
      "Epoch 3358/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1876 - acc: 0.2139 - val_loss: 0.5688 - val_acc: 0.2004\n",
      "Epoch 3359/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1882 - acc: 0.2158 - val_loss: 0.6168 - val_acc: 0.2004\n",
      "Epoch 3360/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2081 - acc: 0.2135 - val_loss: 1.1796 - val_acc: 0.2004\n",
      "Epoch 3361/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2313 - acc: 0.2148 - val_loss: 0.6456 - val_acc: 0.1985\n",
      "Epoch 3362/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1752 - acc: 0.2158 - val_loss: 0.5977 - val_acc: 0.2004\n",
      "Epoch 3363/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1869 - acc: 0.2162 - val_loss: 0.6777 - val_acc: 0.2004\n",
      "Epoch 3364/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1842 - acc: 0.2139 - val_loss: 0.6475 - val_acc: 0.2004\n",
      "Epoch 3365/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1768 - acc: 0.2153 - val_loss: 0.6022 - val_acc: 0.2004\n",
      "Epoch 3366/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1813 - acc: 0.2148 - val_loss: 0.6091 - val_acc: 0.2004\n",
      "Epoch 3367/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1920 - acc: 0.2148 - val_loss: 0.6249 - val_acc: 0.2004\n",
      "Epoch 3368/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1662 - acc: 0.2162 - val_loss: 0.6096 - val_acc: 0.2004\n",
      "Epoch 3369/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1799 - acc: 0.2148 - val_loss: 0.6265 - val_acc: 0.1967\n",
      "Epoch 3370/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1801 - acc: 0.2162 - val_loss: 0.6543 - val_acc: 0.2004\n",
      "Epoch 3371/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1706 - acc: 0.2153 - val_loss: 0.6053 - val_acc: 0.2004\n",
      "Epoch 3372/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1671 - acc: 0.2158 - val_loss: 0.6021 - val_acc: 0.2004\n",
      "Epoch 3373/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1906 - acc: 0.2162 - val_loss: 0.6119 - val_acc: 0.2004\n",
      "Epoch 3374/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2035 - acc: 0.2158 - val_loss: 0.6929 - val_acc: 0.1985\n",
      "Epoch 3375/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1892 - acc: 0.2144 - val_loss: 0.6033 - val_acc: 0.2004\n",
      "Epoch 3376/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1783 - acc: 0.2153 - val_loss: 0.6629 - val_acc: 0.2004\n",
      "Epoch 3377/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1766 - acc: 0.2148 - val_loss: 0.6003 - val_acc: 0.2004\n",
      "Epoch 3378/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1815 - acc: 0.2158 - val_loss: 0.6054 - val_acc: 0.2004\n",
      "Epoch 3379/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2482 - acc: 0.2153 - val_loss: 0.5940 - val_acc: 0.2004\n",
      "Epoch 3380/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1730 - acc: 0.2148 - val_loss: 0.8014 - val_acc: 0.2004\n",
      "Epoch 3381/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1941 - acc: 0.2162 - val_loss: 0.6004 - val_acc: 0.2004\n",
      "Epoch 3382/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1924 - acc: 0.2153 - val_loss: 0.7244 - val_acc: 0.1967\n",
      "Epoch 3383/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1890 - acc: 0.2153 - val_loss: 0.6764 - val_acc: 0.2004\n",
      "Epoch 3384/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1742 - acc: 0.2158 - val_loss: 0.6013 - val_acc: 0.2004\n",
      "Epoch 3385/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1876 - acc: 0.2148 - val_loss: 0.6034 - val_acc: 0.2004\n",
      "Epoch 3386/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2186 - acc: 0.2144 - val_loss: 0.7089 - val_acc: 0.2004\n",
      "Epoch 3387/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2052 - acc: 0.2144 - val_loss: 0.5916 - val_acc: 0.2004\n",
      "Epoch 3388/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1871 - acc: 0.2158 - val_loss: 0.6404 - val_acc: 0.2004\n",
      "Epoch 3389/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1694 - acc: 0.2162 - val_loss: 0.6334 - val_acc: 0.2004\n",
      "Epoch 3390/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1783 - acc: 0.2158 - val_loss: 0.6169 - val_acc: 0.2004\n",
      "Epoch 3391/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1835 - acc: 0.2153 - val_loss: 0.5955 - val_acc: 0.2004\n",
      "Epoch 3392/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1743 - acc: 0.2148 - val_loss: 0.6087 - val_acc: 0.2004\n",
      "Epoch 3393/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1829 - acc: 0.2153 - val_loss: 0.6210 - val_acc: 0.2004\n",
      "Epoch 3394/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2010 - acc: 0.2153 - val_loss: 0.6328 - val_acc: 0.2004\n",
      "Epoch 3395/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1795 - acc: 0.2162 - val_loss: 0.6421 - val_acc: 0.2004\n",
      "Epoch 3396/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1890 - acc: 0.2158 - val_loss: 0.6941 - val_acc: 0.2004\n",
      "Epoch 3397/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2637 - acc: 0.2153 - val_loss: 1.1146 - val_acc: 0.2004\n",
      "Epoch 3398/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.5882 - acc: 0.2088 - val_loss: 0.7200 - val_acc: 0.2004\n",
      "Epoch 3399/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2378 - acc: 0.2153 - val_loss: 0.6383 - val_acc: 0.2004\n",
      "Epoch 3400/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2173 - acc: 0.2158 - val_loss: 0.6642 - val_acc: 0.2004\n",
      "Epoch 3401/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1822 - acc: 0.2148 - val_loss: 0.5589 - val_acc: 0.2004\n",
      "Epoch 3402/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1897 - acc: 0.2158 - val_loss: 0.6090 - val_acc: 0.2004\n",
      "Epoch 3403/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1664 - acc: 0.2158 - val_loss: 0.5966 - val_acc: 0.2004\n",
      "Epoch 3404/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1687 - acc: 0.2153 - val_loss: 0.6042 - val_acc: 0.2004\n",
      "Epoch 3405/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1663 - acc: 0.2167 - val_loss: 0.6018 - val_acc: 0.2004\n",
      "Epoch 3406/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1610 - acc: 0.2158 - val_loss: 0.6780 - val_acc: 0.1967\n",
      "Epoch 3407/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1754 - acc: 0.2153 - val_loss: 0.6116 - val_acc: 0.1985\n",
      "Epoch 3408/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1720 - acc: 0.2158 - val_loss: 0.6132 - val_acc: 0.2004\n",
      "Epoch 3409/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1714 - acc: 0.2153 - val_loss: 0.5916 - val_acc: 0.2004\n",
      "Epoch 3410/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1789 - acc: 0.2153 - val_loss: 0.6318 - val_acc: 0.1985\n",
      "Epoch 3411/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1876 - acc: 0.2153 - val_loss: 0.6109 - val_acc: 0.2004\n",
      "Epoch 3412/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1762 - acc: 0.2167 - val_loss: 0.6241 - val_acc: 0.2004\n",
      "Epoch 3413/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1946 - acc: 0.2139 - val_loss: 0.6147 - val_acc: 0.2004\n",
      "Epoch 3414/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1799 - acc: 0.2158 - val_loss: 0.6002 - val_acc: 0.2004\n",
      "Epoch 3415/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1754 - acc: 0.2158 - val_loss: 0.5888 - val_acc: 0.2004\n",
      "Epoch 3416/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1755 - acc: 0.2162 - val_loss: 0.6347 - val_acc: 0.2004\n",
      "Epoch 3417/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1692 - acc: 0.2162 - val_loss: 0.6573 - val_acc: 0.1985\n",
      "Epoch 3418/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1932 - acc: 0.2153 - val_loss: 0.6126 - val_acc: 0.2004\n",
      "Epoch 3419/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1664 - acc: 0.2158 - val_loss: 0.6237 - val_acc: 0.2004\n",
      "Epoch 3420/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1775 - acc: 0.2139 - val_loss: 0.6081 - val_acc: 0.2004\n",
      "Epoch 3421/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1755 - acc: 0.2148 - val_loss: 0.6016 - val_acc: 0.2004\n",
      "Epoch 3422/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1740 - acc: 0.2144 - val_loss: 0.6248 - val_acc: 0.2004\n",
      "Epoch 3423/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1799 - acc: 0.2158 - val_loss: 0.6626 - val_acc: 0.2004\n",
      "Epoch 3424/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1732 - acc: 0.2148 - val_loss: 0.6031 - val_acc: 0.2004\n",
      "Epoch 3425/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1651 - acc: 0.2162 - val_loss: 0.6346 - val_acc: 0.2004\n",
      "Epoch 3426/4000\n",
      "68/68 [==============================] - 5s 74ms/step - loss: 0.1775 - acc: 0.2153 - val_loss: 0.6224 - val_acc: 0.2004\n",
      "Epoch 3427/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1762 - acc: 0.2139 - val_loss: 0.6027 - val_acc: 0.2004\n",
      "Epoch 3428/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1971 - acc: 0.2162 - val_loss: 0.7352 - val_acc: 0.2004\n",
      "Epoch 3429/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1960 - acc: 0.2148 - val_loss: 0.6555 - val_acc: 0.1967\n",
      "Epoch 3430/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2173 - acc: 0.2153 - val_loss: 0.6907 - val_acc: 0.2004\n",
      "Epoch 3431/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1747 - acc: 0.2158 - val_loss: 0.6325 - val_acc: 0.1985\n",
      "Epoch 3432/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1809 - acc: 0.2153 - val_loss: 0.6959 - val_acc: 0.2004\n",
      "Epoch 3433/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1857 - acc: 0.2158 - val_loss: 0.6178 - val_acc: 0.2004\n",
      "Epoch 3434/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1840 - acc: 0.2162 - val_loss: 0.6343 - val_acc: 0.2004\n",
      "Epoch 3435/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1753 - acc: 0.2162 - val_loss: 0.6232 - val_acc: 0.1985\n",
      "Epoch 3436/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1726 - acc: 0.2153 - val_loss: 0.6206 - val_acc: 0.2004\n",
      "Epoch 3437/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1777 - acc: 0.2153 - val_loss: 0.7826 - val_acc: 0.2004\n",
      "Epoch 3438/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1872 - acc: 0.2153 - val_loss: 0.6151 - val_acc: 0.2004\n",
      "Epoch 3439/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1849 - acc: 0.2148 - val_loss: 0.6319 - val_acc: 0.2004\n",
      "Epoch 3440/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1878 - acc: 0.2144 - val_loss: 0.6117 - val_acc: 0.2004\n",
      "Epoch 3441/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1709 - acc: 0.2162 - val_loss: 0.6157 - val_acc: 0.2004\n",
      "Epoch 3442/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2061 - acc: 0.2158 - val_loss: 0.6334 - val_acc: 0.2004\n",
      "Epoch 3443/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1832 - acc: 0.2153 - val_loss: 0.6942 - val_acc: 0.1967\n",
      "Epoch 3444/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2003 - acc: 0.2158 - val_loss: 0.7162 - val_acc: 0.2004\n",
      "Epoch 3445/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1943 - acc: 0.2153 - val_loss: 0.6409 - val_acc: 0.2004\n",
      "Epoch 3446/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1682 - acc: 0.2158 - val_loss: 0.6093 - val_acc: 0.1967\n",
      "Epoch 3447/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.1772 - acc: 0.2144 - val_loss: 0.6290 - val_acc: 0.2004\n",
      "Epoch 3448/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1887 - acc: 0.2144 - val_loss: 0.6849 - val_acc: 0.1967\n",
      "Epoch 3449/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1954 - acc: 0.2153 - val_loss: 0.6210 - val_acc: 0.2004\n",
      "Epoch 3450/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1863 - acc: 0.2162 - val_loss: 0.6045 - val_acc: 0.2004\n",
      "Epoch 3451/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2085 - acc: 0.2144 - val_loss: 0.6682 - val_acc: 0.1985\n",
      "Epoch 3452/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1799 - acc: 0.2158 - val_loss: 0.6034 - val_acc: 0.2004\n",
      "Epoch 3453/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1797 - acc: 0.2153 - val_loss: 0.7301 - val_acc: 0.2004\n",
      "Epoch 3454/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1983 - acc: 0.2153 - val_loss: 0.6726 - val_acc: 0.1967\n",
      "Epoch 3455/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1843 - acc: 0.2153 - val_loss: 0.6311 - val_acc: 0.2004\n",
      "Epoch 3456/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1783 - acc: 0.2153 - val_loss: 0.6420 - val_acc: 0.2004\n",
      "Epoch 3457/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1817 - acc: 0.2162 - val_loss: 0.6914 - val_acc: 0.1967\n",
      "Epoch 3458/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1931 - acc: 0.2153 - val_loss: 0.6091 - val_acc: 0.2004\n",
      "Epoch 3459/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1849 - acc: 0.2158 - val_loss: 0.7195 - val_acc: 0.2004\n",
      "Epoch 3460/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2350 - acc: 0.2153 - val_loss: 0.6250 - val_acc: 0.2004\n",
      "Epoch 3461/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2007 - acc: 0.2158 - val_loss: 0.6866 - val_acc: 0.2004\n",
      "Epoch 3462/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1718 - acc: 0.2167 - val_loss: 0.7226 - val_acc: 0.2004\n",
      "Epoch 3463/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1959 - acc: 0.2148 - val_loss: 0.6043 - val_acc: 0.2004\n",
      "Epoch 3464/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1771 - acc: 0.2158 - val_loss: 0.6197 - val_acc: 0.2004\n",
      "Epoch 3465/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1894 - acc: 0.2158 - val_loss: 0.6778 - val_acc: 0.1985\n",
      "Epoch 3466/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1886 - acc: 0.2148 - val_loss: 0.6250 - val_acc: 0.2004\n",
      "Epoch 3467/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1983 - acc: 0.2148 - val_loss: 0.8293 - val_acc: 0.2004\n",
      "Epoch 3468/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2112 - acc: 0.2158 - val_loss: 0.6034 - val_acc: 0.2004\n",
      "Epoch 3469/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1927 - acc: 0.2162 - val_loss: 0.7231 - val_acc: 0.1967\n",
      "Epoch 3470/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1919 - acc: 0.2148 - val_loss: 0.6332 - val_acc: 0.2004\n",
      "Epoch 3471/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1883 - acc: 0.2167 - val_loss: 0.6352 - val_acc: 0.2004\n",
      "Epoch 3472/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1974 - acc: 0.2139 - val_loss: 0.6671 - val_acc: 0.1967\n",
      "Epoch 3473/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1960 - acc: 0.2158 - val_loss: 0.6779 - val_acc: 0.2004\n",
      "Epoch 3474/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1771 - acc: 0.2167 - val_loss: 0.6409 - val_acc: 0.1967\n",
      "Epoch 3475/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1920 - acc: 0.2144 - val_loss: 0.6553 - val_acc: 0.2004\n",
      "Epoch 3476/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1744 - acc: 0.2162 - val_loss: 0.6639 - val_acc: 0.1967\n",
      "Epoch 3477/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1915 - acc: 0.2148 - val_loss: 0.7179 - val_acc: 0.1967\n",
      "Epoch 3478/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1748 - acc: 0.2158 - val_loss: 0.6064 - val_acc: 0.2004\n",
      "Epoch 3479/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1893 - acc: 0.2162 - val_loss: 0.6511 - val_acc: 0.2004\n",
      "Epoch 3480/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1767 - acc: 0.2153 - val_loss: 0.6068 - val_acc: 0.2004\n",
      "Epoch 3481/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1748 - acc: 0.2153 - val_loss: 0.6938 - val_acc: 0.2004\n",
      "Epoch 3482/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1801 - acc: 0.2148 - val_loss: 0.6157 - val_acc: 0.2004\n",
      "Epoch 3483/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1668 - acc: 0.2162 - val_loss: 0.6208 - val_acc: 0.2004\n",
      "Epoch 3484/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1778 - acc: 0.2158 - val_loss: 0.6143 - val_acc: 0.2004\n",
      "Epoch 3485/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1768 - acc: 0.2158 - val_loss: 0.6377 - val_acc: 0.2004\n",
      "Epoch 3486/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1633 - acc: 0.2158 - val_loss: 0.6149 - val_acc: 0.2004\n",
      "Epoch 3487/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1764 - acc: 0.2162 - val_loss: 0.6717 - val_acc: 0.2004\n",
      "Epoch 3488/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1822 - acc: 0.2148 - val_loss: 0.6348 - val_acc: 0.1985\n",
      "Epoch 3489/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1910 - acc: 0.2162 - val_loss: 0.7442 - val_acc: 0.2004\n",
      "Epoch 3490/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1881 - acc: 0.2148 - val_loss: 0.5937 - val_acc: 0.2004\n",
      "Epoch 3491/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1755 - acc: 0.2148 - val_loss: 0.6524 - val_acc: 0.1985\n",
      "Epoch 3492/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2114 - acc: 0.2148 - val_loss: 0.7213 - val_acc: 0.2004\n",
      "Epoch 3493/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1768 - acc: 0.2158 - val_loss: 0.6608 - val_acc: 0.2004\n",
      "Epoch 3494/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1902 - acc: 0.2158 - val_loss: 0.6705 - val_acc: 0.1967\n",
      "Epoch 3495/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1915 - acc: 0.2144 - val_loss: 0.6395 - val_acc: 0.2004\n",
      "Epoch 3496/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1731 - acc: 0.2167 - val_loss: 0.6490 - val_acc: 0.2004\n",
      "Epoch 3497/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1740 - acc: 0.2162 - val_loss: 0.6386 - val_acc: 0.2004\n",
      "Epoch 3498/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1951 - acc: 0.2153 - val_loss: 0.5768 - val_acc: 0.2004\n",
      "Epoch 3499/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2399 - acc: 0.2144 - val_loss: 0.7164 - val_acc: 0.2004\n",
      "Epoch 3500/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2691 - acc: 0.2158 - val_loss: 0.6365 - val_acc: 0.2004\n",
      "Epoch 3501/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3030 - acc: 0.2153 - val_loss: 0.7657 - val_acc: 0.2004\n",
      "Epoch 3502/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3142 - acc: 0.2139 - val_loss: 0.9864 - val_acc: 0.1948\n",
      "Epoch 3503/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2775 - acc: 0.2153 - val_loss: 0.5902 - val_acc: 0.2004\n",
      "Epoch 3504/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3306 - acc: 0.2162 - val_loss: 0.7383 - val_acc: 0.1948\n",
      "Epoch 3505/4000\n",
      "68/68 [==============================] - 5s 72ms/step - loss: 0.2412 - acc: 0.2153 - val_loss: 0.5700 - val_acc: 0.2004\n",
      "Epoch 3506/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2523 - acc: 0.2167 - val_loss: 0.8073 - val_acc: 0.2004\n",
      "Epoch 3507/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2713 - acc: 0.2158 - val_loss: 0.5786 - val_acc: 0.2004\n",
      "Epoch 3508/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1941 - acc: 0.2153 - val_loss: 0.6150 - val_acc: 0.2004\n",
      "Epoch 3509/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1728 - acc: 0.2162 - val_loss: 0.5981 - val_acc: 0.2004\n",
      "Epoch 3510/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1906 - acc: 0.2158 - val_loss: 0.6177 - val_acc: 0.2004\n",
      "Epoch 3511/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1841 - acc: 0.2162 - val_loss: 0.7129 - val_acc: 0.2004\n",
      "Epoch 3512/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1909 - acc: 0.2158 - val_loss: 0.5945 - val_acc: 0.2004\n",
      "Epoch 3513/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1854 - acc: 0.2158 - val_loss: 0.6861 - val_acc: 0.1967\n",
      "Epoch 3514/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1895 - acc: 0.2148 - val_loss: 0.6465 - val_acc: 0.2004\n",
      "Epoch 3515/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2022 - acc: 0.2167 - val_loss: 0.6578 - val_acc: 0.2004\n",
      "Epoch 3516/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1804 - acc: 0.2162 - val_loss: 0.6182 - val_acc: 0.2004\n",
      "Epoch 3517/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1841 - acc: 0.2162 - val_loss: 0.6224 - val_acc: 0.2004\n",
      "Epoch 3518/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1691 - acc: 0.2158 - val_loss: 0.6217 - val_acc: 0.2004\n",
      "Epoch 3519/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1649 - acc: 0.2158 - val_loss: 0.6093 - val_acc: 0.2004\n",
      "Epoch 3520/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1723 - acc: 0.2162 - val_loss: 0.6096 - val_acc: 0.2004\n",
      "Epoch 3521/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1634 - acc: 0.2162 - val_loss: 0.6159 - val_acc: 0.2004\n",
      "Epoch 3522/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1845 - acc: 0.2148 - val_loss: 0.6697 - val_acc: 0.2004\n",
      "Epoch 3523/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2108 - acc: 0.2153 - val_loss: 0.6128 - val_acc: 0.2004\n",
      "Epoch 3524/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1816 - acc: 0.2167 - val_loss: 0.6713 - val_acc: 0.2004\n",
      "Epoch 3525/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1856 - acc: 0.2144 - val_loss: 0.8552 - val_acc: 0.2004\n",
      "Epoch 3526/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2059 - acc: 0.2162 - val_loss: 0.6130 - val_acc: 0.2004\n",
      "Epoch 3527/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2055 - acc: 0.2144 - val_loss: 0.6224 - val_acc: 0.2004\n",
      "Epoch 3528/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.1741 - acc: 0.2162 - val_loss: 0.6430 - val_acc: 0.2004\n",
      "Epoch 3529/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.1774 - acc: 0.2153 - val_loss: 0.6800 - val_acc: 0.1967\n",
      "Epoch 3530/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2260 - acc: 0.2139 - val_loss: 0.6509 - val_acc: 0.2004\n",
      "Epoch 3531/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1921 - acc: 0.2162 - val_loss: 0.6233 - val_acc: 0.2004\n",
      "Epoch 3532/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1727 - acc: 0.2158 - val_loss: 0.6435 - val_acc: 0.2004\n",
      "Epoch 3533/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1751 - acc: 0.2153 - val_loss: 0.6109 - val_acc: 0.2004\n",
      "Epoch 3534/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1713 - acc: 0.2162 - val_loss: 0.6286 - val_acc: 0.2004\n",
      "Epoch 3535/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1868 - acc: 0.2158 - val_loss: 0.5963 - val_acc: 0.2004\n",
      "Epoch 3536/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1643 - acc: 0.2148 - val_loss: 0.6150 - val_acc: 0.2004\n",
      "Epoch 3537/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1849 - acc: 0.2162 - val_loss: 0.7466 - val_acc: 0.2004\n",
      "Epoch 3538/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1818 - acc: 0.2162 - val_loss: 0.6919 - val_acc: 0.2004\n",
      "Epoch 3539/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1689 - acc: 0.2153 - val_loss: 0.6389 - val_acc: 0.2004\n",
      "Epoch 3540/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1665 - acc: 0.2153 - val_loss: 0.6484 - val_acc: 0.2004\n",
      "Epoch 3541/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1843 - acc: 0.2148 - val_loss: 0.6699 - val_acc: 0.2004\n",
      "Epoch 3542/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.1894 - acc: 0.2148 - val_loss: 0.6388 - val_acc: 0.2004\n",
      "Epoch 3543/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2004 - acc: 0.2144 - val_loss: 0.6078 - val_acc: 0.2004\n",
      "Epoch 3544/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1743 - acc: 0.2153 - val_loss: 0.6252 - val_acc: 0.2004\n",
      "Epoch 3545/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2259 - acc: 0.2130 - val_loss: 0.6600 - val_acc: 0.2004\n",
      "Epoch 3546/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1910 - acc: 0.2153 - val_loss: 0.6558 - val_acc: 0.1985\n",
      "Epoch 3547/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1684 - acc: 0.2167 - val_loss: 0.7576 - val_acc: 0.2004\n",
      "Epoch 3548/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1736 - acc: 0.2148 - val_loss: 0.7280 - val_acc: 0.2004\n",
      "Epoch 3549/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1947 - acc: 0.2158 - val_loss: 0.6104 - val_acc: 0.2004\n",
      "Epoch 3550/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2011 - acc: 0.2153 - val_loss: 0.6398 - val_acc: 0.2004\n",
      "Epoch 3551/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1876 - acc: 0.2144 - val_loss: 0.6342 - val_acc: 0.2004\n",
      "Epoch 3552/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1904 - acc: 0.2148 - val_loss: 0.7090 - val_acc: 0.2004\n",
      "Epoch 3553/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1821 - acc: 0.2158 - val_loss: 0.6675 - val_acc: 0.1967\n",
      "Epoch 3554/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2176 - acc: 0.2158 - val_loss: 0.6176 - val_acc: 0.2004\n",
      "Epoch 3555/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1723 - acc: 0.2162 - val_loss: 0.6092 - val_acc: 0.2004\n",
      "Epoch 3556/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1648 - acc: 0.2158 - val_loss: 0.6105 - val_acc: 0.2004\n",
      "Epoch 3557/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1825 - acc: 0.2158 - val_loss: 0.5905 - val_acc: 0.2004\n",
      "Epoch 3558/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1705 - acc: 0.2144 - val_loss: 0.6649 - val_acc: 0.1985\n",
      "Epoch 3559/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1821 - acc: 0.2158 - val_loss: 0.6531 - val_acc: 0.2004\n",
      "Epoch 3560/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1938 - acc: 0.2144 - val_loss: 0.6461 - val_acc: 0.2004\n",
      "Epoch 3561/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1845 - acc: 0.2153 - val_loss: 0.6580 - val_acc: 0.2004\n",
      "Epoch 3562/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1760 - acc: 0.2162 - val_loss: 0.6188 - val_acc: 0.2004\n",
      "Epoch 3563/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1798 - acc: 0.2153 - val_loss: 0.6861 - val_acc: 0.1967\n",
      "Epoch 3564/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1915 - acc: 0.2153 - val_loss: 0.6512 - val_acc: 0.2004\n",
      "Epoch 3565/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1710 - acc: 0.2153 - val_loss: 0.6684 - val_acc: 0.1985\n",
      "Epoch 3566/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1900 - acc: 0.2158 - val_loss: 0.6453 - val_acc: 0.2004\n",
      "Epoch 3567/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1908 - acc: 0.2148 - val_loss: 0.7368 - val_acc: 0.1967\n",
      "Epoch 3568/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1807 - acc: 0.2153 - val_loss: 0.6771 - val_acc: 0.2004\n",
      "Epoch 3569/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1988 - acc: 0.2144 - val_loss: 0.5993 - val_acc: 0.2004\n",
      "Epoch 3570/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1725 - acc: 0.2158 - val_loss: 0.6166 - val_acc: 0.2004\n",
      "Epoch 3571/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1681 - acc: 0.2167 - val_loss: 0.6709 - val_acc: 0.2004\n",
      "Epoch 3572/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1699 - acc: 0.2162 - val_loss: 0.6926 - val_acc: 0.1967\n",
      "Epoch 3573/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1803 - acc: 0.2158 - val_loss: 0.6823 - val_acc: 0.1967\n",
      "Epoch 3574/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1791 - acc: 0.2148 - val_loss: 0.6430 - val_acc: 0.2004\n",
      "Epoch 3575/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1832 - acc: 0.2158 - val_loss: 0.6387 - val_acc: 0.2004\n",
      "Epoch 3576/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1674 - acc: 0.2148 - val_loss: 0.6105 - val_acc: 0.2004\n",
      "Epoch 3577/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1722 - acc: 0.2153 - val_loss: 0.6473 - val_acc: 0.2004\n",
      "Epoch 3578/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1708 - acc: 0.2158 - val_loss: 0.6764 - val_acc: 0.1967\n",
      "Epoch 3579/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1982 - acc: 0.2148 - val_loss: 0.6227 - val_acc: 0.2004\n",
      "Epoch 3580/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1751 - acc: 0.2158 - val_loss: 0.6255 - val_acc: 0.2004\n",
      "Epoch 3581/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1766 - acc: 0.2162 - val_loss: 0.6594 - val_acc: 0.2004\n",
      "Epoch 3582/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1727 - acc: 0.2162 - val_loss: 0.6527 - val_acc: 0.2004\n",
      "Epoch 3583/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1782 - acc: 0.2167 - val_loss: 0.6447 - val_acc: 0.2004\n",
      "Epoch 3584/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1946 - acc: 0.2158 - val_loss: 0.7337 - val_acc: 0.2004\n",
      "Epoch 3585/4000\n",
      "68/68 [==============================] - 5s 69ms/step - loss: 0.2764 - acc: 0.2111 - val_loss: 2.2960 - val_acc: 0.2004\n",
      "Epoch 3586/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.4239 - acc: 0.2116 - val_loss: 0.6999 - val_acc: 0.2004\n",
      "Epoch 3587/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1930 - acc: 0.2158 - val_loss: 0.6378 - val_acc: 0.2004\n",
      "Epoch 3588/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.3730 - acc: 0.2162 - val_loss: 0.8752 - val_acc: 0.2004\n",
      "Epoch 3589/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2357 - acc: 0.2162 - val_loss: 0.7640 - val_acc: 0.1967\n",
      "Epoch 3590/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2156 - acc: 0.2153 - val_loss: 0.5490 - val_acc: 0.2004\n",
      "Epoch 3591/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1996 - acc: 0.2158 - val_loss: 0.6083 - val_acc: 0.2004\n",
      "Epoch 3592/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1887 - acc: 0.2144 - val_loss: 0.6960 - val_acc: 0.2004\n",
      "Epoch 3593/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2210 - acc: 0.2144 - val_loss: 0.6217 - val_acc: 0.2004\n",
      "Epoch 3594/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1766 - acc: 0.2162 - val_loss: 0.5981 - val_acc: 0.2004\n",
      "Epoch 3595/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1679 - acc: 0.2162 - val_loss: 0.6607 - val_acc: 0.2004\n",
      "Epoch 3596/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1722 - acc: 0.2158 - val_loss: 0.7168 - val_acc: 0.2004\n",
      "Epoch 3597/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1702 - acc: 0.2139 - val_loss: 0.6305 - val_acc: 0.2004\n",
      "Epoch 3598/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1752 - acc: 0.2158 - val_loss: 0.6288 - val_acc: 0.2004\n",
      "Epoch 3599/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1920 - acc: 0.2144 - val_loss: 0.6277 - val_acc: 0.2004\n",
      "Epoch 3600/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1648 - acc: 0.2148 - val_loss: 0.6522 - val_acc: 0.2004\n",
      "Epoch 3601/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1918 - acc: 0.2139 - val_loss: 0.6266 - val_acc: 0.2004\n",
      "Epoch 3602/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1715 - acc: 0.2153 - val_loss: 0.6914 - val_acc: 0.1967\n",
      "Epoch 3603/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1771 - acc: 0.2162 - val_loss: 0.6085 - val_acc: 0.2004\n",
      "Epoch 3604/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1699 - acc: 0.2153 - val_loss: 0.6773 - val_acc: 0.1967\n",
      "Epoch 3605/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1657 - acc: 0.2162 - val_loss: 0.6690 - val_acc: 0.2004\n",
      "Epoch 3606/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1666 - acc: 0.2158 - val_loss: 0.6862 - val_acc: 0.2004\n",
      "Epoch 3607/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1771 - acc: 0.2148 - val_loss: 0.7034 - val_acc: 0.2004\n",
      "Epoch 3608/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1825 - acc: 0.2148 - val_loss: 0.6748 - val_acc: 0.2004\n",
      "Epoch 3609/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1717 - acc: 0.2158 - val_loss: 0.6058 - val_acc: 0.2004\n",
      "Epoch 3610/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1781 - acc: 0.2158 - val_loss: 0.6411 - val_acc: 0.2004\n",
      "Epoch 3611/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1673 - acc: 0.2153 - val_loss: 0.6225 - val_acc: 0.2004\n",
      "Epoch 3612/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1681 - acc: 0.2148 - val_loss: 0.7706 - val_acc: 0.1967\n",
      "Epoch 3613/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1739 - acc: 0.2139 - val_loss: 0.6571 - val_acc: 0.2004\n",
      "Epoch 3614/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1788 - acc: 0.2153 - val_loss: 0.9559 - val_acc: 0.1874\n",
      "Epoch 3615/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2426 - acc: 0.2097 - val_loss: 0.6366 - val_acc: 0.2004\n",
      "Epoch 3616/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1606 - acc: 0.2167 - val_loss: 0.6428 - val_acc: 0.2004\n",
      "Epoch 3617/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1758 - acc: 0.2162 - val_loss: 0.6884 - val_acc: 0.2004\n",
      "Epoch 3618/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1772 - acc: 0.2153 - val_loss: 0.6577 - val_acc: 0.2004\n",
      "Epoch 3619/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1730 - acc: 0.2158 - val_loss: 0.7423 - val_acc: 0.2004\n",
      "Epoch 3620/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1742 - acc: 0.2162 - val_loss: 0.6068 - val_acc: 0.2004\n",
      "Epoch 3621/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1808 - acc: 0.2148 - val_loss: 0.6381 - val_acc: 0.2004\n",
      "Epoch 3622/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1711 - acc: 0.2162 - val_loss: 0.6475 - val_acc: 0.2004\n",
      "Epoch 3623/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1679 - acc: 0.2148 - val_loss: 0.6493 - val_acc: 0.2004\n",
      "Epoch 3624/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1776 - acc: 0.2167 - val_loss: 0.6802 - val_acc: 0.2004\n",
      "Epoch 3625/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1701 - acc: 0.2162 - val_loss: 0.7636 - val_acc: 0.1948\n",
      "Epoch 3626/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1806 - acc: 0.2148 - val_loss: 0.6828 - val_acc: 0.2004\n",
      "Epoch 3627/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2226 - acc: 0.2153 - val_loss: 0.6180 - val_acc: 0.2004\n",
      "Epoch 3628/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1665 - acc: 0.2162 - val_loss: 0.6246 - val_acc: 0.2004\n",
      "Epoch 3629/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2078 - acc: 0.2139 - val_loss: 0.7624 - val_acc: 0.2004\n",
      "Epoch 3630/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1675 - acc: 0.2167 - val_loss: 0.6431 - val_acc: 0.2004\n",
      "Epoch 3631/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1615 - acc: 0.2153 - val_loss: 0.6415 - val_acc: 0.2004\n",
      "Epoch 3632/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1728 - acc: 0.2158 - val_loss: 0.6546 - val_acc: 0.2004\n",
      "Epoch 3633/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1634 - acc: 0.2162 - val_loss: 0.6746 - val_acc: 0.2004\n",
      "Epoch 3634/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1871 - acc: 0.2153 - val_loss: 0.6497 - val_acc: 0.2004\n",
      "Epoch 3635/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1668 - acc: 0.2158 - val_loss: 0.7149 - val_acc: 0.1967\n",
      "Epoch 3636/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1643 - acc: 0.2162 - val_loss: 0.6633 - val_acc: 0.2004\n",
      "Epoch 3637/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1800 - acc: 0.2158 - val_loss: 0.8885 - val_acc: 0.2004\n",
      "Epoch 3638/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1857 - acc: 0.2158 - val_loss: 0.6828 - val_acc: 0.2004\n",
      "Epoch 3639/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1754 - acc: 0.2148 - val_loss: 0.6397 - val_acc: 0.2004\n",
      "Epoch 3640/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1757 - acc: 0.2153 - val_loss: 0.6163 - val_acc: 0.2004\n",
      "Epoch 3641/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1707 - acc: 0.2153 - val_loss: 0.6109 - val_acc: 0.2004\n",
      "Epoch 3642/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1832 - acc: 0.2148 - val_loss: 0.6459 - val_acc: 0.2004\n",
      "Epoch 3643/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1859 - acc: 0.2153 - val_loss: 0.6479 - val_acc: 0.2004\n",
      "Epoch 3644/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1647 - acc: 0.2153 - val_loss: 0.6825 - val_acc: 0.2004\n",
      "Epoch 3645/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1774 - acc: 0.2162 - val_loss: 0.6049 - val_acc: 0.2004\n",
      "Epoch 3646/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1855 - acc: 0.2162 - val_loss: 0.7084 - val_acc: 0.1967\n",
      "Epoch 3647/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1896 - acc: 0.2153 - val_loss: 0.7172 - val_acc: 0.2004\n",
      "Epoch 3648/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1852 - acc: 0.2139 - val_loss: 0.6797 - val_acc: 0.2004\n",
      "Epoch 3649/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1742 - acc: 0.2158 - val_loss: 0.6096 - val_acc: 0.2004\n",
      "Epoch 3650/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1785 - acc: 0.2148 - val_loss: 0.6658 - val_acc: 0.2004\n",
      "Epoch 3651/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1726 - acc: 0.2153 - val_loss: 0.6410 - val_acc: 0.1985\n",
      "Epoch 3652/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1853 - acc: 0.2153 - val_loss: 0.6608 - val_acc: 0.2004\n",
      "Epoch 3653/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1913 - acc: 0.2167 - val_loss: 0.7426 - val_acc: 0.2004\n",
      "Epoch 3654/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2725 - acc: 0.2148 - val_loss: 0.7557 - val_acc: 0.1967\n",
      "Epoch 3655/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.2118 - acc: 0.2153 - val_loss: 0.7368 - val_acc: 0.2004\n",
      "Epoch 3656/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1935 - acc: 0.2167 - val_loss: 0.6570 - val_acc: 0.2004\n",
      "Epoch 3657/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1859 - acc: 0.2144 - val_loss: 0.6770 - val_acc: 0.1967\n",
      "Epoch 3658/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1901 - acc: 0.2158 - val_loss: 0.7324 - val_acc: 0.1967\n",
      "Epoch 3659/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1791 - acc: 0.2153 - val_loss: 0.6917 - val_acc: 0.2004\n",
      "Epoch 3660/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1604 - acc: 0.2162 - val_loss: 0.6474 - val_acc: 0.2004\n",
      "Epoch 3661/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1752 - acc: 0.2162 - val_loss: 0.7010 - val_acc: 0.1967\n",
      "Epoch 3662/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1690 - acc: 0.2135 - val_loss: 0.6374 - val_acc: 0.2004\n",
      "Epoch 3663/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1948 - acc: 0.2158 - val_loss: 0.6288 - val_acc: 0.2004\n",
      "Epoch 3664/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1674 - acc: 0.2158 - val_loss: 0.7183 - val_acc: 0.2004\n",
      "Epoch 3665/4000\n",
      "68/68 [==============================] - 5s 70ms/step - loss: 0.1804 - acc: 0.2153 - val_loss: 0.6536 - val_acc: 0.2004\n",
      "Epoch 3666/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1697 - acc: 0.2153 - val_loss: 0.7142 - val_acc: 0.1967\n",
      "Epoch 3667/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1708 - acc: 0.2158 - val_loss: 0.7118 - val_acc: 0.1967\n",
      "Epoch 3668/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1792 - acc: 0.2153 - val_loss: 0.6015 - val_acc: 0.2004\n",
      "Epoch 3669/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1978 - acc: 0.2158 - val_loss: 0.7530 - val_acc: 0.1967\n",
      "Epoch 3670/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1789 - acc: 0.2162 - val_loss: 0.6668 - val_acc: 0.2004\n",
      "Epoch 3671/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2715 - acc: 0.2139 - val_loss: 0.6620 - val_acc: 0.2004\n",
      "Epoch 3672/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2048 - acc: 0.2153 - val_loss: 0.6388 - val_acc: 0.2004\n",
      "Epoch 3673/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1858 - acc: 0.2158 - val_loss: 0.6098 - val_acc: 0.2004\n",
      "Epoch 3674/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1919 - acc: 0.2153 - val_loss: 0.6245 - val_acc: 0.2004\n",
      "Epoch 3675/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2505 - acc: 0.2153 - val_loss: 0.6498 - val_acc: 0.2004\n",
      "Epoch 3676/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1920 - acc: 0.2148 - val_loss: 0.7100 - val_acc: 0.2004\n",
      "Epoch 3677/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2232 - acc: 0.2158 - val_loss: 0.6442 - val_acc: 0.2004\n",
      "Epoch 3678/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1663 - acc: 0.2153 - val_loss: 0.6396 - val_acc: 0.2004\n",
      "Epoch 3679/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1890 - acc: 0.2144 - val_loss: 0.8245 - val_acc: 0.1929\n",
      "Epoch 3680/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1955 - acc: 0.2153 - val_loss: 0.6517 - val_acc: 0.2004\n",
      "Epoch 3681/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1659 - acc: 0.2158 - val_loss: 0.7448 - val_acc: 0.2004\n",
      "Epoch 3682/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1692 - acc: 0.2162 - val_loss: 0.6227 - val_acc: 0.2004\n",
      "Epoch 3683/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1868 - acc: 0.2158 - val_loss: 0.6271 - val_acc: 0.2004\n",
      "Epoch 3684/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1691 - acc: 0.2162 - val_loss: 0.7853 - val_acc: 0.1967\n",
      "Epoch 3685/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1782 - acc: 0.2148 - val_loss: 0.6507 - val_acc: 0.2004\n",
      "Epoch 3686/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1979 - acc: 0.2162 - val_loss: 0.6501 - val_acc: 0.2004\n",
      "Epoch 3687/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1649 - acc: 0.2158 - val_loss: 0.6668 - val_acc: 0.2004\n",
      "Epoch 3688/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1618 - acc: 0.2162 - val_loss: 0.6337 - val_acc: 0.2004\n",
      "Epoch 3689/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1861 - acc: 0.2148 - val_loss: 0.6813 - val_acc: 0.2004\n",
      "Epoch 3690/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1792 - acc: 0.2158 - val_loss: 0.6647 - val_acc: 0.2004\n",
      "Epoch 3691/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1787 - acc: 0.2139 - val_loss: 0.6625 - val_acc: 0.2004\n",
      "Epoch 3692/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1878 - acc: 0.2144 - val_loss: 0.6346 - val_acc: 0.2004\n",
      "Epoch 3693/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1691 - acc: 0.2162 - val_loss: 0.6574 - val_acc: 0.2004\n",
      "Epoch 3694/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1886 - acc: 0.2148 - val_loss: 0.6763 - val_acc: 0.2004\n",
      "Epoch 3695/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1849 - acc: 0.2148 - val_loss: 0.6395 - val_acc: 0.2004\n",
      "Epoch 3696/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1766 - acc: 0.2153 - val_loss: 0.6833 - val_acc: 0.1967\n",
      "Epoch 3697/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1640 - acc: 0.2167 - val_loss: 0.6355 - val_acc: 0.2004\n",
      "Epoch 3698/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1733 - acc: 0.2158 - val_loss: 0.7641 - val_acc: 0.2004\n",
      "Epoch 3699/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2257 - acc: 0.2139 - val_loss: 0.6202 - val_acc: 0.2004\n",
      "Epoch 3700/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1723 - acc: 0.2162 - val_loss: 0.7171 - val_acc: 0.1967\n",
      "Epoch 3701/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1807 - acc: 0.2153 - val_loss: 0.6196 - val_acc: 0.2004\n",
      "Epoch 3702/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1587 - acc: 0.2158 - val_loss: 0.6375 - val_acc: 0.2004\n",
      "Epoch 3703/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1747 - acc: 0.2153 - val_loss: 0.6683 - val_acc: 0.2004\n",
      "Epoch 3704/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1759 - acc: 0.2144 - val_loss: 0.6397 - val_acc: 0.2004\n",
      "Epoch 3705/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1691 - acc: 0.2162 - val_loss: 0.7636 - val_acc: 0.2004\n",
      "Epoch 3706/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1778 - acc: 0.2162 - val_loss: 0.6814 - val_acc: 0.1967\n",
      "Epoch 3707/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1745 - acc: 0.2158 - val_loss: 0.6448 - val_acc: 0.2004\n",
      "Epoch 3708/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1704 - acc: 0.2167 - val_loss: 0.6537 - val_acc: 0.2004\n",
      "Epoch 3709/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1805 - acc: 0.2148 - val_loss: 0.6492 - val_acc: 0.2004\n",
      "Epoch 3710/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1792 - acc: 0.2148 - val_loss: 0.6753 - val_acc: 0.2004\n",
      "Epoch 3711/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2142 - acc: 0.2135 - val_loss: 0.7131 - val_acc: 0.2004\n",
      "Epoch 3712/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2630 - acc: 0.2148 - val_loss: 0.6369 - val_acc: 0.2004\n",
      "Epoch 3713/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2151 - acc: 0.2148 - val_loss: 0.6853 - val_acc: 0.2004\n",
      "Epoch 3714/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1681 - acc: 0.2167 - val_loss: 0.5935 - val_acc: 0.2004\n",
      "Epoch 3715/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1887 - acc: 0.2148 - val_loss: 0.6414 - val_acc: 0.2004\n",
      "Epoch 3716/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.1904 - acc: 0.2148 - val_loss: 0.6304 - val_acc: 0.2004\n",
      "Epoch 3717/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1750 - acc: 0.2158 - val_loss: 0.6706 - val_acc: 0.2004\n",
      "Epoch 3718/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1992 - acc: 0.2148 - val_loss: 0.6295 - val_acc: 0.2004\n",
      "Epoch 3719/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2047 - acc: 0.2158 - val_loss: 0.6418 - val_acc: 0.2004\n",
      "Epoch 3720/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1582 - acc: 0.2158 - val_loss: 0.6585 - val_acc: 0.2004\n",
      "Epoch 3721/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1813 - acc: 0.2148 - val_loss: 0.6367 - val_acc: 0.2004\n",
      "Epoch 3722/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1728 - acc: 0.2162 - val_loss: 0.6752 - val_acc: 0.1967\n",
      "Epoch 3723/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1744 - acc: 0.2148 - val_loss: 0.6884 - val_acc: 0.2004\n",
      "Epoch 3724/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1758 - acc: 0.2158 - val_loss: 0.6258 - val_acc: 0.2004\n",
      "Epoch 3725/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1684 - acc: 0.2148 - val_loss: 0.6884 - val_acc: 0.2004\n",
      "Epoch 3726/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1722 - acc: 0.2158 - val_loss: 0.6771 - val_acc: 0.2004\n",
      "Epoch 3727/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1742 - acc: 0.2162 - val_loss: 0.7161 - val_acc: 0.1985\n",
      "Epoch 3728/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1773 - acc: 0.2162 - val_loss: 0.7394 - val_acc: 0.1967\n",
      "Epoch 3729/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1701 - acc: 0.2158 - val_loss: 0.6358 - val_acc: 0.2004\n",
      "Epoch 3730/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1828 - acc: 0.2167 - val_loss: 0.6629 - val_acc: 0.2004\n",
      "Epoch 3731/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2113 - acc: 0.2153 - val_loss: 0.7337 - val_acc: 0.1967\n",
      "Epoch 3732/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1745 - acc: 0.2153 - val_loss: 0.6571 - val_acc: 0.2004\n",
      "Epoch 3733/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1663 - acc: 0.2158 - val_loss: 0.7050 - val_acc: 0.1967\n",
      "Epoch 3734/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1818 - acc: 0.2153 - val_loss: 0.7278 - val_acc: 0.2004\n",
      "Epoch 3735/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1741 - acc: 0.2162 - val_loss: 0.6104 - val_acc: 0.2004\n",
      "Epoch 3736/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1709 - acc: 0.2162 - val_loss: 0.6264 - val_acc: 0.2004\n",
      "Epoch 3737/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1768 - acc: 0.2162 - val_loss: 0.8989 - val_acc: 0.2004\n",
      "Epoch 3738/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1812 - acc: 0.2153 - val_loss: 0.6063 - val_acc: 0.2004\n",
      "Epoch 3739/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1663 - acc: 0.2162 - val_loss: 0.6822 - val_acc: 0.1985\n",
      "Epoch 3740/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1686 - acc: 0.2153 - val_loss: 0.6823 - val_acc: 0.2004\n",
      "Epoch 3741/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2720 - acc: 0.2130 - val_loss: 0.6277 - val_acc: 0.2004\n",
      "Epoch 3742/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1950 - acc: 0.2162 - val_loss: 0.6312 - val_acc: 0.2004\n",
      "Epoch 3743/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1763 - acc: 0.2158 - val_loss: 0.6446 - val_acc: 0.2004\n",
      "Epoch 3744/4000\n",
      "68/68 [==============================] - 4s 65ms/step - loss: 0.1608 - acc: 0.2162 - val_loss: 0.6323 - val_acc: 0.2004\n",
      "Epoch 3745/4000\n",
      "68/68 [==============================] - 5s 69ms/step - loss: 0.1604 - acc: 0.2158 - val_loss: 0.6730 - val_acc: 0.2004\n",
      "Epoch 3746/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1723 - acc: 0.2139 - val_loss: 0.7320 - val_acc: 0.1967\n",
      "Epoch 3747/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1748 - acc: 0.2148 - val_loss: 0.6501 - val_acc: 0.2004\n",
      "Epoch 3748/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1749 - acc: 0.2158 - val_loss: 0.6460 - val_acc: 0.1985\n",
      "Epoch 3749/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1880 - acc: 0.2148 - val_loss: 0.6214 - val_acc: 0.2004\n",
      "Epoch 3750/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1675 - acc: 0.2158 - val_loss: 0.6346 - val_acc: 0.2004\n",
      "Epoch 3751/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1768 - acc: 0.2158 - val_loss: 0.7049 - val_acc: 0.2004\n",
      "Epoch 3752/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1695 - acc: 0.2167 - val_loss: 0.6264 - val_acc: 0.2004\n",
      "Epoch 3753/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1839 - acc: 0.2158 - val_loss: 0.7512 - val_acc: 0.2004\n",
      "Epoch 3754/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1850 - acc: 0.2144 - val_loss: 0.6352 - val_acc: 0.2004\n",
      "Epoch 3755/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1807 - acc: 0.2153 - val_loss: 0.6666 - val_acc: 0.1985\n",
      "Epoch 3756/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1730 - acc: 0.2153 - val_loss: 0.6556 - val_acc: 0.2004\n",
      "Epoch 3757/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1713 - acc: 0.2148 - val_loss: 0.6314 - val_acc: 0.2004\n",
      "Epoch 3758/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1745 - acc: 0.2158 - val_loss: 0.6291 - val_acc: 0.2004\n",
      "Epoch 3759/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1608 - acc: 0.2153 - val_loss: 0.6768 - val_acc: 0.1985\n",
      "Epoch 3760/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1846 - acc: 0.2144 - val_loss: 0.6572 - val_acc: 0.2004\n",
      "Epoch 3761/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1852 - acc: 0.2153 - val_loss: 0.8054 - val_acc: 0.1929\n",
      "Epoch 3762/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1815 - acc: 0.2162 - val_loss: 0.6659 - val_acc: 0.2004\n",
      "Epoch 3763/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1856 - acc: 0.2148 - val_loss: 0.6282 - val_acc: 0.2004\n",
      "Epoch 3764/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1784 - acc: 0.2148 - val_loss: 0.6760 - val_acc: 0.2004\n",
      "Epoch 3765/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1711 - acc: 0.2167 - val_loss: 0.6421 - val_acc: 0.2004\n",
      "Epoch 3766/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1793 - acc: 0.2148 - val_loss: 0.7041 - val_acc: 0.1967\n",
      "Epoch 3767/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2017 - acc: 0.2144 - val_loss: 0.6220 - val_acc: 0.2004\n",
      "Epoch 3768/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1686 - acc: 0.2158 - val_loss: 0.6863 - val_acc: 0.2004\n",
      "Epoch 3769/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1880 - acc: 0.2153 - val_loss: 0.6483 - val_acc: 0.2004\n",
      "Epoch 3770/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1955 - acc: 0.2148 - val_loss: 0.7259 - val_acc: 0.1967\n",
      "Epoch 3771/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1596 - acc: 0.2162 - val_loss: 0.6263 - val_acc: 0.2004\n",
      "Epoch 3772/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1712 - acc: 0.2167 - val_loss: 0.7643 - val_acc: 0.2004\n",
      "Epoch 3773/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1762 - acc: 0.2144 - val_loss: 0.6533 - val_acc: 0.2004\n",
      "Epoch 3774/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1808 - acc: 0.2148 - val_loss: 0.7102 - val_acc: 0.2004\n",
      "Epoch 3775/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1764 - acc: 0.2158 - val_loss: 0.6752 - val_acc: 0.2004\n",
      "Epoch 3776/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1804 - acc: 0.2153 - val_loss: 0.6440 - val_acc: 0.2004\n",
      "Epoch 3777/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1724 - acc: 0.2153 - val_loss: 0.6774 - val_acc: 0.1985\n",
      "Epoch 3778/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2009 - acc: 0.2158 - val_loss: 0.6399 - val_acc: 0.2004\n",
      "Epoch 3779/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2422 - acc: 0.2148 - val_loss: 0.6118 - val_acc: 0.2004\n",
      "Epoch 3780/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.3290 - acc: 0.2153 - val_loss: 0.7711 - val_acc: 0.2004\n",
      "Epoch 3781/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.4018 - acc: 0.2144 - val_loss: 0.7165 - val_acc: 0.2004\n",
      "Epoch 3782/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.3179 - acc: 0.2162 - val_loss: 1.0998 - val_acc: 0.2004\n",
      "Epoch 3783/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2966 - acc: 0.2139 - val_loss: 0.6811 - val_acc: 0.2004\n",
      "Epoch 3784/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2011 - acc: 0.2158 - val_loss: 0.7019 - val_acc: 0.2004\n",
      "Epoch 3785/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1893 - acc: 0.2153 - val_loss: 0.6551 - val_acc: 0.2004\n",
      "Epoch 3786/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1686 - acc: 0.2162 - val_loss: 0.6667 - val_acc: 0.2004\n",
      "Epoch 3787/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1668 - acc: 0.2153 - val_loss: 0.6963 - val_acc: 0.2004\n",
      "Epoch 3788/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1674 - acc: 0.2167 - val_loss: 0.6437 - val_acc: 0.2004\n",
      "Epoch 3789/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1689 - acc: 0.2158 - val_loss: 0.6330 - val_acc: 0.2004\n",
      "Epoch 3790/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1705 - acc: 0.2153 - val_loss: 0.7001 - val_acc: 0.1967\n",
      "Epoch 3791/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1656 - acc: 0.2162 - val_loss: 0.7100 - val_acc: 0.2004\n",
      "Epoch 3792/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1692 - acc: 0.2162 - val_loss: 0.6344 - val_acc: 0.2004\n",
      "Epoch 3793/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1698 - acc: 0.2158 - val_loss: 0.6382 - val_acc: 0.2004\n",
      "Epoch 3794/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1646 - acc: 0.2158 - val_loss: 0.6385 - val_acc: 0.2004\n",
      "Epoch 3795/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1676 - acc: 0.2148 - val_loss: 0.7490 - val_acc: 0.2004\n",
      "Epoch 3796/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1688 - acc: 0.2158 - val_loss: 0.6299 - val_acc: 0.2004\n",
      "Epoch 3797/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1689 - acc: 0.2153 - val_loss: 0.6435 - val_acc: 0.2004\n",
      "Epoch 3798/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1841 - acc: 0.2148 - val_loss: 0.6525 - val_acc: 0.2004\n",
      "Epoch 3799/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1989 - acc: 0.2148 - val_loss: 0.6715 - val_acc: 0.2004\n",
      "Epoch 3800/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1787 - acc: 0.2158 - val_loss: 0.6513 - val_acc: 0.2004\n",
      "Epoch 3801/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1803 - acc: 0.2144 - val_loss: 0.6374 - val_acc: 0.2004\n",
      "Epoch 3802/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1714 - acc: 0.2158 - val_loss: 0.7181 - val_acc: 0.1967\n",
      "Epoch 3803/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1751 - acc: 0.2158 - val_loss: 0.6796 - val_acc: 0.2004\n",
      "Epoch 3804/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1650 - acc: 0.2158 - val_loss: 0.6722 - val_acc: 0.2004\n",
      "Epoch 3805/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1663 - acc: 0.2158 - val_loss: 0.6403 - val_acc: 0.2004\n",
      "Epoch 3806/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1570 - acc: 0.2167 - val_loss: 0.6474 - val_acc: 0.2004\n",
      "Epoch 3807/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1563 - acc: 0.2153 - val_loss: 0.6410 - val_acc: 0.2004\n",
      "Epoch 3808/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1826 - acc: 0.2153 - val_loss: 0.6619 - val_acc: 0.2004\n",
      "Epoch 3809/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1780 - acc: 0.2148 - val_loss: 0.6447 - val_acc: 0.2004\n",
      "Epoch 3810/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1862 - acc: 0.2153 - val_loss: 0.6488 - val_acc: 0.1967\n",
      "Epoch 3811/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1680 - acc: 0.2153 - val_loss: 0.6480 - val_acc: 0.2004\n",
      "Epoch 3812/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1978 - acc: 0.2153 - val_loss: 0.6982 - val_acc: 0.2004\n",
      "Epoch 3813/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1698 - acc: 0.2167 - val_loss: 0.6530 - val_acc: 0.2004\n",
      "Epoch 3814/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1872 - acc: 0.2153 - val_loss: 0.7196 - val_acc: 0.1985\n",
      "Epoch 3815/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1923 - acc: 0.2158 - val_loss: 0.6443 - val_acc: 0.2004\n",
      "Epoch 3816/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1644 - acc: 0.2153 - val_loss: 0.6822 - val_acc: 0.1985\n",
      "Epoch 3817/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1761 - acc: 0.2144 - val_loss: 0.6607 - val_acc: 0.2004\n",
      "Epoch 3818/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1735 - acc: 0.2153 - val_loss: 0.7264 - val_acc: 0.2004\n",
      "Epoch 3819/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2061 - acc: 0.2139 - val_loss: 0.6977 - val_acc: 0.2004\n",
      "Epoch 3820/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1769 - acc: 0.2144 - val_loss: 0.6727 - val_acc: 0.2004\n",
      "Epoch 3821/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1939 - acc: 0.2148 - val_loss: 0.6994 - val_acc: 0.2004\n",
      "Epoch 3822/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1721 - acc: 0.2162 - val_loss: 0.7260 - val_acc: 0.1985\n",
      "Epoch 3823/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1687 - acc: 0.2158 - val_loss: 0.6456 - val_acc: 0.2004\n",
      "Epoch 3824/4000\n",
      "68/68 [==============================] - 5s 73ms/step - loss: 0.1698 - acc: 0.2162 - val_loss: 0.6632 - val_acc: 0.2004\n",
      "Epoch 3825/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1679 - acc: 0.2162 - val_loss: 0.7049 - val_acc: 0.2004\n",
      "Epoch 3826/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1935 - acc: 0.2162 - val_loss: 0.6453 - val_acc: 0.2004\n",
      "Epoch 3827/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1694 - acc: 0.2148 - val_loss: 0.8756 - val_acc: 0.2004\n",
      "Epoch 3828/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2156 - acc: 0.2153 - val_loss: 0.6726 - val_acc: 0.2004\n",
      "Epoch 3829/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1811 - acc: 0.2162 - val_loss: 0.6913 - val_acc: 0.2004\n",
      "Epoch 3830/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2177 - acc: 0.2158 - val_loss: 0.6554 - val_acc: 0.2004\n",
      "Epoch 3831/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1673 - acc: 0.2148 - val_loss: 0.6667 - val_acc: 0.2004\n",
      "Epoch 3832/4000\n",
      "68/68 [==============================] - 4s 64ms/step - loss: 0.2309 - acc: 0.2158 - val_loss: 0.7089 - val_acc: 0.2004\n",
      "Epoch 3833/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1923 - acc: 0.2153 - val_loss: 0.6766 - val_acc: 0.2004\n",
      "Epoch 3834/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2537 - acc: 0.2162 - val_loss: 0.6423 - val_acc: 0.2004\n",
      "Epoch 3835/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2904 - acc: 0.2148 - val_loss: 0.8368 - val_acc: 0.1948\n",
      "Epoch 3836/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2382 - acc: 0.2158 - val_loss: 0.7178 - val_acc: 0.2004\n",
      "Epoch 3837/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1936 - acc: 0.2158 - val_loss: 0.6543 - val_acc: 0.2004\n",
      "Epoch 3838/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1676 - acc: 0.2158 - val_loss: 0.6480 - val_acc: 0.2004\n",
      "Epoch 3839/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1688 - acc: 0.2162 - val_loss: 0.6815 - val_acc: 0.2004\n",
      "Epoch 3840/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1619 - acc: 0.2153 - val_loss: 0.6445 - val_acc: 0.2004\n",
      "Epoch 3841/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1745 - acc: 0.2153 - val_loss: 0.6312 - val_acc: 0.2004\n",
      "Epoch 3842/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1611 - acc: 0.2158 - val_loss: 0.6388 - val_acc: 0.2004\n",
      "Epoch 3843/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1541 - acc: 0.2162 - val_loss: 0.8364 - val_acc: 0.1948\n",
      "Epoch 3844/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1738 - acc: 0.2153 - val_loss: 0.6484 - val_acc: 0.2004\n",
      "Epoch 3845/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1787 - acc: 0.2153 - val_loss: 0.6998 - val_acc: 0.1967\n",
      "Epoch 3846/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2375 - acc: 0.2135 - val_loss: 0.7545 - val_acc: 0.1967\n",
      "Epoch 3847/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1872 - acc: 0.2144 - val_loss: 0.6619 - val_acc: 0.2004\n",
      "Epoch 3848/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1703 - acc: 0.2158 - val_loss: 0.6233 - val_acc: 0.2004\n",
      "Epoch 3849/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1671 - acc: 0.2158 - val_loss: 0.6622 - val_acc: 0.2004\n",
      "Epoch 3850/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1680 - acc: 0.2162 - val_loss: 0.6513 - val_acc: 0.2004\n",
      "Epoch 3851/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1845 - acc: 0.2153 - val_loss: 0.6647 - val_acc: 0.2004\n",
      "Epoch 3852/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1802 - acc: 0.2158 - val_loss: 0.6786 - val_acc: 0.2004\n",
      "Epoch 3853/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1641 - acc: 0.2162 - val_loss: 0.7034 - val_acc: 0.1967\n",
      "Epoch 3854/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1928 - acc: 0.2158 - val_loss: 0.6617 - val_acc: 0.2004\n",
      "Epoch 3855/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1830 - acc: 0.2153 - val_loss: 0.6663 - val_acc: 0.2004\n",
      "Epoch 3856/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1657 - acc: 0.2153 - val_loss: 0.6434 - val_acc: 0.2004\n",
      "Epoch 3857/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1739 - acc: 0.2153 - val_loss: 0.6636 - val_acc: 0.2004\n",
      "Epoch 3858/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1718 - acc: 0.2158 - val_loss: 0.6705 - val_acc: 0.2004\n",
      "Epoch 3859/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1872 - acc: 0.2148 - val_loss: 0.6580 - val_acc: 0.2004\n",
      "Epoch 3860/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1767 - acc: 0.2158 - val_loss: 0.6819 - val_acc: 0.1967\n",
      "Epoch 3861/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1687 - acc: 0.2153 - val_loss: 0.6682 - val_acc: 0.2004\n",
      "Epoch 3862/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1647 - acc: 0.2148 - val_loss: 0.7458 - val_acc: 0.1967\n",
      "Epoch 3863/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1777 - acc: 0.2153 - val_loss: 0.6655 - val_acc: 0.2004\n",
      "Epoch 3864/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2122 - acc: 0.2144 - val_loss: 0.6769 - val_acc: 0.2004\n",
      "Epoch 3865/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1889 - acc: 0.2144 - val_loss: 0.6497 - val_acc: 0.2004\n",
      "Epoch 3866/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1650 - acc: 0.2153 - val_loss: 0.6773 - val_acc: 0.2004\n",
      "Epoch 3867/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1646 - acc: 0.2158 - val_loss: 0.6286 - val_acc: 0.2004\n",
      "Epoch 3868/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1695 - acc: 0.2158 - val_loss: 0.6618 - val_acc: 0.1985\n",
      "Epoch 3869/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1758 - acc: 0.2158 - val_loss: 0.6510 - val_acc: 0.2004\n",
      "Epoch 3870/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1706 - acc: 0.2153 - val_loss: 0.6895 - val_acc: 0.2004\n",
      "Epoch 3871/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1935 - acc: 0.2144 - val_loss: 0.7198 - val_acc: 0.1985\n",
      "Epoch 3872/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1632 - acc: 0.2162 - val_loss: 0.7178 - val_acc: 0.1967\n",
      "Epoch 3873/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1865 - acc: 0.2158 - val_loss: 0.6728 - val_acc: 0.2004\n",
      "Epoch 3874/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1925 - acc: 0.2153 - val_loss: 0.6527 - val_acc: 0.2004\n",
      "Epoch 3875/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1787 - acc: 0.2153 - val_loss: 0.6528 - val_acc: 0.2004\n",
      "Epoch 3876/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1736 - acc: 0.2158 - val_loss: 0.6357 - val_acc: 0.2004\n",
      "Epoch 3877/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1685 - acc: 0.2153 - val_loss: 0.6795 - val_acc: 0.2004\n",
      "Epoch 3878/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1890 - acc: 0.2144 - val_loss: 0.6334 - val_acc: 0.1967\n",
      "Epoch 3879/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.2103 - acc: 0.2153 - val_loss: 0.6349 - val_acc: 0.2004\n",
      "Epoch 3880/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.1996 - acc: 0.2158 - val_loss: 0.6756 - val_acc: 0.2004\n",
      "Epoch 3881/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1895 - acc: 0.2158 - val_loss: 0.6662 - val_acc: 0.2004\n",
      "Epoch 3882/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2265 - acc: 0.2148 - val_loss: 0.7050 - val_acc: 0.2004\n",
      "Epoch 3883/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1923 - acc: 0.2144 - val_loss: 0.6575 - val_acc: 0.2004\n",
      "Epoch 3884/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2527 - acc: 0.2153 - val_loss: 0.6741 - val_acc: 0.2004\n",
      "Epoch 3885/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2779 - acc: 0.2158 - val_loss: 0.6655 - val_acc: 0.2004\n",
      "Epoch 3886/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1956 - acc: 0.2153 - val_loss: 0.7306 - val_acc: 0.1985\n",
      "Epoch 3887/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1752 - acc: 0.2153 - val_loss: 0.6357 - val_acc: 0.2004\n",
      "Epoch 3888/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2205 - acc: 0.2167 - val_loss: 0.6805 - val_acc: 0.2004\n",
      "Epoch 3889/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1633 - acc: 0.2162 - val_loss: 0.6977 - val_acc: 0.2004\n",
      "Epoch 3890/4000\n",
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1702 - acc: 0.2162 - val_loss: 0.7667 - val_acc: 0.2004\n",
      "Epoch 3891/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2088 - acc: 0.2144 - val_loss: 0.7290 - val_acc: 0.1967\n",
      "Epoch 3892/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1723 - acc: 0.2153 - val_loss: 0.7601 - val_acc: 0.1967\n",
      "Epoch 3893/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1625 - acc: 0.2167 - val_loss: 0.6646 - val_acc: 0.2004\n",
      "Epoch 3894/4000\n",
      "68/68 [==============================] - 4s 57ms/step - loss: 0.1836 - acc: 0.2162 - val_loss: 0.6317 - val_acc: 0.2004\n",
      "Epoch 3895/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1580 - acc: 0.2158 - val_loss: 0.6472 - val_acc: 0.2004\n",
      "Epoch 3896/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1758 - acc: 0.2158 - val_loss: 0.6643 - val_acc: 0.2004\n",
      "Epoch 3897/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1887 - acc: 0.2153 - val_loss: 0.6363 - val_acc: 0.2004\n",
      "Epoch 3898/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1754 - acc: 0.2144 - val_loss: 0.6492 - val_acc: 0.2004\n",
      "Epoch 3899/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1669 - acc: 0.2153 - val_loss: 0.6362 - val_acc: 0.2004\n",
      "Epoch 3900/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1584 - acc: 0.2162 - val_loss: 0.6823 - val_acc: 0.1985\n",
      "Epoch 3901/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1660 - acc: 0.2162 - val_loss: 0.6551 - val_acc: 0.2004\n",
      "Epoch 3902/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1840 - acc: 0.2139 - val_loss: 0.7716 - val_acc: 0.2004\n",
      "Epoch 3903/4000\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 0.1809 - acc: 0.2158 - val_loss: 0.6414 - val_acc: 0.2004\n",
      "Epoch 3904/4000\n",
      "68/68 [==============================] - 5s 72ms/step - loss: 0.1692 - acc: 0.2158 - val_loss: 0.6623 - val_acc: 0.2004\n",
      "Epoch 3905/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1857 - acc: 0.2153 - val_loss: 0.6227 - val_acc: 0.2004\n",
      "Epoch 3906/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1769 - acc: 0.2148 - val_loss: 0.6646 - val_acc: 0.2004\n",
      "Epoch 3907/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1680 - acc: 0.2153 - val_loss: 0.7624 - val_acc: 0.2004\n",
      "Epoch 3908/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1785 - acc: 0.2158 - val_loss: 0.6731 - val_acc: 0.1985\n",
      "Epoch 3909/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1914 - acc: 0.2144 - val_loss: 0.6739 - val_acc: 0.2004\n",
      "Epoch 3910/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1655 - acc: 0.2162 - val_loss: 0.6787 - val_acc: 0.2004\n",
      "Epoch 3911/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1619 - acc: 0.2162 - val_loss: 0.6711 - val_acc: 0.2004\n",
      "Epoch 3912/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1745 - acc: 0.2139 - val_loss: 0.6394 - val_acc: 0.2004\n",
      "Epoch 3913/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1993 - acc: 0.2158 - val_loss: 0.6633 - val_acc: 0.2004\n",
      "Epoch 3914/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1905 - acc: 0.2158 - val_loss: 0.6152 - val_acc: 0.2004\n",
      "Epoch 3915/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1736 - acc: 0.2158 - val_loss: 0.6803 - val_acc: 0.2004\n",
      "Epoch 3916/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1796 - acc: 0.2153 - val_loss: 0.6493 - val_acc: 0.2004\n",
      "Epoch 3917/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1682 - acc: 0.2158 - val_loss: 0.6542 - val_acc: 0.2004\n",
      "Epoch 3918/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1745 - acc: 0.2162 - val_loss: 0.6464 - val_acc: 0.2004\n",
      "Epoch 3919/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1587 - acc: 0.2158 - val_loss: 0.6378 - val_acc: 0.2004\n",
      "Epoch 3920/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1655 - acc: 0.2158 - val_loss: 0.8318 - val_acc: 0.2004\n",
      "Epoch 3921/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1846 - acc: 0.2144 - val_loss: 0.6541 - val_acc: 0.2004\n",
      "Epoch 3922/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1717 - acc: 0.2162 - val_loss: 0.6777 - val_acc: 0.2004\n",
      "Epoch 3923/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1678 - acc: 0.2153 - val_loss: 0.7168 - val_acc: 0.2004\n",
      "Epoch 3924/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1614 - acc: 0.2148 - val_loss: 0.6263 - val_acc: 0.2004\n",
      "Epoch 3925/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1730 - acc: 0.2144 - val_loss: 0.6603 - val_acc: 0.2004\n",
      "Epoch 3926/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1751 - acc: 0.2162 - val_loss: 0.6423 - val_acc: 0.2004\n",
      "Epoch 3927/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1757 - acc: 0.2144 - val_loss: 0.6435 - val_acc: 0.2004\n",
      "Epoch 3928/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1852 - acc: 0.2167 - val_loss: 0.6426 - val_acc: 0.2004\n",
      "Epoch 3929/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1903 - acc: 0.2158 - val_loss: 0.6737 - val_acc: 0.2004\n",
      "Epoch 3930/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1632 - acc: 0.2162 - val_loss: 0.6743 - val_acc: 0.2004\n",
      "Epoch 3931/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1766 - acc: 0.2148 - val_loss: 0.6547 - val_acc: 0.2004\n",
      "Epoch 3932/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1626 - acc: 0.2162 - val_loss: 0.6778 - val_acc: 0.2004\n",
      "Epoch 3933/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1709 - acc: 0.2144 - val_loss: 0.6534 - val_acc: 0.2004\n",
      "Epoch 3934/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1637 - acc: 0.2153 - val_loss: 0.6724 - val_acc: 0.1985\n",
      "Epoch 3935/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1840 - acc: 0.2153 - val_loss: 0.7446 - val_acc: 0.2004\n",
      "Epoch 3936/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1604 - acc: 0.2158 - val_loss: 0.6448 - val_acc: 0.2004\n",
      "Epoch 3937/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1720 - acc: 0.2162 - val_loss: 0.6267 - val_acc: 0.2004\n",
      "Epoch 3938/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1691 - acc: 0.2158 - val_loss: 0.6800 - val_acc: 0.2004\n",
      "Epoch 3939/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1689 - acc: 0.2153 - val_loss: 0.6545 - val_acc: 0.2004\n",
      "Epoch 3940/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1800 - acc: 0.2148 - val_loss: 0.7828 - val_acc: 0.2004\n",
      "Epoch 3941/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1980 - acc: 0.2153 - val_loss: 0.6612 - val_acc: 0.2004\n",
      "Epoch 3942/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1711 - acc: 0.2148 - val_loss: 0.6611 - val_acc: 0.2004\n",
      "Epoch 3943/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1663 - acc: 0.2144 - val_loss: 0.6523 - val_acc: 0.2004\n",
      "Epoch 3944/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1695 - acc: 0.2158 - val_loss: 0.6343 - val_acc: 0.2004\n",
      "Epoch 3945/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1590 - acc: 0.2148 - val_loss: 0.6897 - val_acc: 0.2004\n",
      "Epoch 3946/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1776 - acc: 0.2153 - val_loss: 0.6231 - val_acc: 0.2004\n",
      "Epoch 3947/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1918 - acc: 0.2158 - val_loss: 0.6826 - val_acc: 0.2004\n",
      "Epoch 3948/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1650 - acc: 0.2153 - val_loss: 0.7075 - val_acc: 0.1985\n",
      "Epoch 3949/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1666 - acc: 0.2153 - val_loss: 0.6901 - val_acc: 0.2004\n",
      "Epoch 3950/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1769 - acc: 0.2148 - val_loss: 0.6529 - val_acc: 0.2004\n",
      "Epoch 3951/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1907 - acc: 0.2148 - val_loss: 0.7195 - val_acc: 0.2004\n",
      "Epoch 3952/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1585 - acc: 0.2162 - val_loss: 0.6487 - val_acc: 0.2004\n",
      "Epoch 3953/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1724 - acc: 0.2162 - val_loss: 0.6590 - val_acc: 0.2004\n",
      "Epoch 3954/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2042 - acc: 0.2139 - val_loss: 0.6361 - val_acc: 0.2004\n",
      "Epoch 3955/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1945 - acc: 0.2158 - val_loss: 0.7940 - val_acc: 0.1967\n",
      "Epoch 3956/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1895 - acc: 0.2162 - val_loss: 0.7731 - val_acc: 0.2004\n",
      "Epoch 3957/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1715 - acc: 0.2153 - val_loss: 0.6867 - val_acc: 0.2004\n",
      "Epoch 3958/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1720 - acc: 0.2158 - val_loss: 0.7497 - val_acc: 0.1967\n",
      "Epoch 3959/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1689 - acc: 0.2144 - val_loss: 0.6685 - val_acc: 0.2004\n",
      "Epoch 3960/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1606 - acc: 0.2153 - val_loss: 0.7425 - val_acc: 0.1967\n",
      "Epoch 3961/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1917 - acc: 0.2148 - val_loss: 0.7132 - val_acc: 0.1985\n",
      "Epoch 3962/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1739 - acc: 0.2153 - val_loss: 0.6569 - val_acc: 0.2004\n",
      "Epoch 3963/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1622 - acc: 0.2162 - val_loss: 0.7533 - val_acc: 0.2004\n",
      "Epoch 3964/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1674 - acc: 0.2158 - val_loss: 0.6414 - val_acc: 0.2004\n",
      "Epoch 3965/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1714 - acc: 0.2148 - val_loss: 0.7354 - val_acc: 0.2004\n",
      "Epoch 3966/4000\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1796 - acc: 0.2158 - val_loss: 0.6750 - val_acc: 0.2004\n",
      "Epoch 3967/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1731 - acc: 0.2144 - val_loss: 0.6875 - val_acc: 0.2004\n",
      "Epoch 3968/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1620 - acc: 0.2153 - val_loss: 0.6395 - val_acc: 0.2004\n",
      "Epoch 3969/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1683 - acc: 0.2162 - val_loss: 0.6973 - val_acc: 0.1985\n",
      "Epoch 3970/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1555 - acc: 0.2162 - val_loss: 0.6708 - val_acc: 0.2004\n",
      "Epoch 3971/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1798 - acc: 0.2158 - val_loss: 0.6171 - val_acc: 0.2004\n",
      "Epoch 3972/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1715 - acc: 0.2158 - val_loss: 0.6799 - val_acc: 0.2004\n",
      "Epoch 3973/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1599 - acc: 0.2162 - val_loss: 0.6769 - val_acc: 0.2004\n",
      "Epoch 3974/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1836 - acc: 0.2153 - val_loss: 0.7097 - val_acc: 0.2004\n",
      "Epoch 3975/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1956 - acc: 0.2153 - val_loss: 0.7309 - val_acc: 0.1967\n",
      "Epoch 3976/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1970 - acc: 0.2144 - val_loss: 0.6990 - val_acc: 0.2004\n",
      "Epoch 3977/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 4s 62ms/step - loss: 0.1846 - acc: 0.2158 - val_loss: 0.6983 - val_acc: 0.1985\n",
      "Epoch 3978/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2003 - acc: 0.2148 - val_loss: 0.6403 - val_acc: 0.2004\n",
      "Epoch 3979/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2238 - acc: 0.2144 - val_loss: 0.6153 - val_acc: 0.2004\n",
      "Epoch 3980/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1890 - acc: 0.2158 - val_loss: 0.6614 - val_acc: 0.2004\n",
      "Epoch 3981/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2092 - acc: 0.2148 - val_loss: 0.6867 - val_acc: 0.1967\n",
      "Epoch 3982/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1768 - acc: 0.2162 - val_loss: 0.7751 - val_acc: 0.2004\n",
      "Epoch 3983/4000\n",
      "68/68 [==============================] - 4s 66ms/step - loss: 0.3776 - acc: 0.2139 - val_loss: 0.7420 - val_acc: 0.2004\n",
      "Epoch 3984/4000\n",
      "68/68 [==============================] - 5s 67ms/step - loss: 0.2346 - acc: 0.2158 - val_loss: 0.7114 - val_acc: 0.2004\n",
      "Epoch 3985/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2325 - acc: 0.2158 - val_loss: 0.6970 - val_acc: 0.2004\n",
      "Epoch 3986/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.2283 - acc: 0.2139 - val_loss: 0.7165 - val_acc: 0.2004\n",
      "Epoch 3987/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.2014 - acc: 0.2158 - val_loss: 0.6698 - val_acc: 0.2004\n",
      "Epoch 3988/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1853 - acc: 0.2158 - val_loss: 0.6903 - val_acc: 0.2004\n",
      "Epoch 3989/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1645 - acc: 0.2158 - val_loss: 0.7731 - val_acc: 0.2004\n",
      "Epoch 3990/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1726 - acc: 0.2158 - val_loss: 0.6592 - val_acc: 0.2004\n",
      "Epoch 3991/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1586 - acc: 0.2162 - val_loss: 0.6416 - val_acc: 0.2004\n",
      "Epoch 3992/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1707 - acc: 0.2139 - val_loss: 0.8705 - val_acc: 0.2004\n",
      "Epoch 3993/4000\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 0.1701 - acc: 0.2162 - val_loss: 0.6900 - val_acc: 0.2004\n",
      "Epoch 3994/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1597 - acc: 0.2158 - val_loss: 0.6614 - val_acc: 0.2004\n",
      "Epoch 3995/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1602 - acc: 0.2153 - val_loss: 0.6439 - val_acc: 0.2004\n",
      "Epoch 3996/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.2058 - acc: 0.2153 - val_loss: 0.6562 - val_acc: 0.2004\n",
      "Epoch 3997/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1706 - acc: 0.2148 - val_loss: 0.6448 - val_acc: 0.2004\n",
      "Epoch 3998/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1550 - acc: 0.2158 - val_loss: 0.6449 - val_acc: 0.2004\n",
      "Epoch 3999/4000\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.1647 - acc: 0.2144 - val_loss: 0.7307 - val_acc: 0.2004\n",
      "Epoch 4000/4000\n",
      "68/68 [==============================] - 4s 59ms/step - loss: 0.1806 - acc: 0.2158 - val_loss: 0.7279 - val_acc: 0.1967\n"
     ]
    }
   ],
   "source": [
    "size_history = cnn_size_model.fit([size_x_train1, size_x_train2, size_x_train3], size_y_train, epochs=4000, validation_data=([size_x_test1,size_x_test2,size_x_test3], size_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 17ms/step - loss: 0.7279 - acc: 0.1967\n",
      "Test loss: 0.7279127240180969\n",
      "Test accuracy: 0.19666048884391785\n"
     ]
    }
   ],
   "source": [
    "# モデルの評価(大きさ)\n",
    "score = cnn_size_model.evaluate([size_x_test1, size_x_test2, size_x_test3], size_y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAAAm20lEQVR4nO3de3xU9bnv8c8zSbgIARE1UFGQ6tYq1EsQsW6tqNuqtVovLVpr1VbZL+tu7eXYUmuPbreeuutpbffZnlprUbRYpGpPrfdbELAiEgoCooJIJHjhYrhEDJCZ5/yxVpJJmIRMMmtmkvV9v16TrPvvWb+ZedZav3UZc3dERCQ+EoUOQERE8kuJX0QkZpT4RURiRolfRCRmlPhFRGKmtNABdMbee+/to0aN6tK8H3/8MQMGDMhtQDmguLKjuLKjuLJXrLF1J67q6uoN7r7PLiPcvehflZWV3lVVVVVdnjdKiis7iis7iit7xRpbd+ICFniGnKqmHhGRmFHiFxGJmcgSv5ntb2ZVZva6mS0zs2vC4Tea2VozWxS+zowqBhER2VWUJ3cbgR+6+0IzKweqzezZcNzt7v6/IyxbRHqBnTt3UltbS0NDQ+RlDR48mOXLl0deTrY6E1e/fv0YMWIEZWVlnVpmZInf3d8H3g+7t5rZcmC/qMoTkd6ntraW8vJyRo0ahZlFWtbWrVspLy+PtIyu2F1c7s7GjRupra3lwAMP7NQy89LGb2ajgKOAV8JB/2Zmr5nZVDMbko8YRKTnaWhoYOjQoZEn/Z7MzBg6dGhWR0XmET+d08wGAi8Ct7j7I2ZWAWwAHPgPYLi7fzPDfJOByQAVFRWVM2bM6FL59fX1DBw4sKvhR0ZxZScucQ3a/AZ7blrKpj3HsGXwoUUTV65kG9fgwYM56KCDIoyoRTKZpKSkJC9lZaOzca1cuZLNmze3GjZx4sRqdx+3y8SZrvHM1QsoA54GftDO+FHA0t0tR9fx54/iyk5O43r3Fff/2Nf9hsHu/1ER9HdRb6mv119/PZpAMtiyZUveyspGZ+PKVFfk+zp+C47N/gAsd/dfpQ0fnjbZucDSqGIQ6VFWz4HGBsAhuSPol4IqxqOmXIjyqp7jgUuAJWa2KBx2HXCRmR1J0NSzGvjXCGMQ6TlGnQAY4FBSGvaL5F5ke/zuPtfdzd0/6+5Hhq8n3P0Sdx8bDj/bg6t/RGT/8TBw36D7vN8H/ZK16po67qhaSXVNXc6W6e5ce+21jBkzhrFjx/Lggw8C8P7773PiiSdy5JFHMmbMGObMmUMymeSyyy5rnvb222/PWRy50iMe0iYSG6V9g//DjyhsHEXo3/+2jNff29LhNFsbdvLGB1tJOSQMDh1WTnm/9q9tP+xTg7jhS4fvtuxHHnmERYsWsXjxYjZs2MAxxxzDiSeeyAMPPMAXvvAFfvrTn5JMJtm2bRuLFi1i7dq1LF0atGJv2rQpq/XMBz2yQUR6jS0NjaTCCxVTHvTnwty5c7nooosoKSmhoqKCz3/+87z66qscc8wx3HPPPdx4440sWbKE8vJyRo8ezapVq/jOd77DU089xaBBg3ISQy5pj19EeoTO7JlX19Rx8d3z2NmYoqw0wW8uPIrKkdHdKnTiiScye/ZsHn/8cS677DJ+8IMf8I1vfIPFixfz9NNPc+eddzJz5kymTp0aWQxdoT1+Eek1KkcOYfoVE/jBaYcw/YoJOUv6J5xwAg8++CDJZJL169cze/Zsxo8fT01NDRUVFVx55ZVcccUVLFy4kA0bNpBKpTj//PO5+eabWbhwYU5iyCXt8YtIr1I5ckjO9/LPPfdcXn75ZY444gjMjF/84hcMGzaMadOmcdttt1FWVsbAgQO57777WLt2LZdffjmpVAqAn//85zmNJReU+EVE2lFfXw8Ej0W47bbbuO2221qNv/TSS7n00kt3ma8Y9/LTqalHpBhF/CgViTclfhGRmFHiFylGehqlREiJX0QkZpT4RURiRolfRCRmlPhFRGJGiV9EJEc6en7/6tWrGTNmTB6jaZ8Sv4j0Lmvmw5xfBv8lI925KyI9w5NT4IMlHU+zfQt8uBQ8BZaAijHQt4OnYw4bC2fc2u7oKVOmsP/++3P11VcDcOONN1JaWkpVVRV1dXXs3LmTm2++mXPOOSerVWloaOCqq65iwYIFlJaW8qtf/YqJEyeybNkyLr/8cnbs2EEqleLhhx+mvLycCy+8kNraWpLJJD/72c+YNGlSVuW1pcQvUox0527XNGwOkj4E/xs2d5z4d2PSpEl873vfa078M2fO5Omnn+a73/0ugwYNYsOGDUyYMIGzzz4by+LeizvuuAMzY8mSJbzxxhucdtppvPXWW9x5551cc801XHzxxezYsYNkMsnDDz/Mpz71KR5//HGAXX5QvSuU+EWkZ+hgz7zZmvkw7ezgN4tL+sD5d3frl8yOOuoo1q1bx3vvvcf69esZMmQIw4YN4/vf/z6zZ88mkUiwdu1aPvzwQ4YNG9bp5c6dO5fvfOc7ABx66KGMHDmSt956i+OOO45bbrmF2tpazjvvPA4++GAOO+wwrr/+en784x9z1llnccIJ3f9JTrXxixQj3bnbNfuPh0sfhZN/GvzPwc9XfuUrX+Ghhx7iwQcfZNKkSUyfPp3169dTXV3NokWLqKiooKGhIQfBw9e+9jUeffRR+vfvz5lnnskLL7zAwQcfzMKFCxk7dizXX389N910U7fL0R6/iPQu+4/P6e8VT5o0iSuvvJINGzbw4osvMnPmTPbdd1/KysqoqqqipqYm62WecMIJTJ8+nZNPPpm33nqLd999l0MOOYRVq1YxevRovvvd7/Luu+/y2muvMWLECA444AC+/vWvs+eee3L33Xd3e52U+EVEOnD44YezdetW9ttvP4YPH87FF1/Ml770JcaOHcu4ceM49NBDs17mt7/9ba666irGjh1LaWkp9957L3379mXmzJncf//9lJWVMWzYMK677jpefPFFLrjgAhKJBGVlZfz2t7/t9jop8YuI7MaSJS1XE+299968/PLLGadren5/JqNGjWr+AfZ+/fpxzz337DLNlClTmDJlSqthp556Kueee25Xwm6X2vhFRGJGe/wiIjm0ZMkSLrnkklbD+vbtyyuvvFKgiHalxC8iRc3ds7pGvtDGjh3LokWL8lqmZ3nfh5p6RKRo9evXj40bN2ad2OLE3dm4cSP9+vXr9Dza4xcpRkp0AIwYMYLa2lrWr18feVkNDQ1ZJc986Uxc/fr1Y8SIEZ1ephK/iBStsrIyDjzwwLyUNWvWLI466qi8lJWNKOJSU49IMepBbdrS8yjxi4jEjBK/iEjMKPGLiMRMZInfzPY3syoze93MlpnZNeHwvczsWTNbEf4fElUMIiKyqyj3+BuBH7r7YcAE4GozOwyYAjzv7gcDz4f9IiKSJ5Elfnd/390Xht1bgeXAfsA5wLRwsmnAl6OKQUREdmX5uCPOzEYBs4ExwLvuvmc43IC6pv4280wGJgNUVFRUzpgxo0tl19fXd/jL94WiuLITl7iOnXcl/RvWMe/Yu2joX1E0ceVKscYFxRtbd+KaOHFitbuP22WEu0f6AgYC1cB5Yf+mNuPrdreMyspK76qqqqouzxslxZWd2MR1+xj3Gwa5b1zVrcXEpr5yqFhj605cwALPkFMjvarHzMqAh4Hp7v5IOPhDMxsejh8OrIsyBpGeRTduSfSivKrHgD8Ay939V2mjHgUuDbsvBf4aVQwiPY+e0SPRi/JZPccDlwBLzGxROOw64FZgppl9C6gBvhphDCI9kx7ZIBGKLPG7+1zaP249JapyRUSkY7pzV0QkZpT4RURiRolfRCRmlPhFRGJGiV+kGOmnFyVCSvwiRUWXcUr0lPhFRGJGiV+kqKiJR6KnxC9SjHTnrkRIiV9EJGaU+EVEYkaJX0QkZpT4RURiRolfRCRmlPhFipHu3JUIKfGLFBVdxinRU+IXEYkZJX6RoqImHomeEr9IMdKduxIhJX4RkZhR4hcRiRklfhGRmFHiFxGJGSV+EZGYUeIXKUa6c1cipMQvUlR0GadET4lfRCRmlPhFioqaeCR6SvwixUh37kqElPhFRGJGiV9EJGYiS/xmNtXM1pnZ0rRhN5rZWjNbFL7OjKp8ERHJLMo9/nuB0zMMv93djwxfT0RYvoiIZBBZ4nf32cBHUS1fRES6xjzCOwTNbBTwmLuPCftvBC4DtgALgB+6e107804GJgNUVFRUzpgxo0sx1NfXM3DgwC7NGyXFlZ24xHXsvCvp37COecf+job+w4omrlwp1rigeGPrTlwTJ06sdvdxu4xw98hewChgaVp/BVBCcKRxCzC1M8uprKz0rqqqquryvFFSXNmJTVy3j3W/YZD7xlXdWkxs6iuHijW27sQFLPAMOTWvV/W4+4funnT3FPB7YHw+yxcRkTxfzmlmw9N6zwWWtjetSDzpzl2JXmlUCzazPwEnAXubWS1wA3CSmR1J8OleDfxrVOWL9Gi6c1ciFFnid/eLMgz+Q1TliYhI5+jOXRGRmFHiFxGJGSV+EZGYUeIXKUb66UWJkBK/SFHR1TwSPSV+EZGYUeIXEYkZJX4RkZhR4hcpKjqpK9HrVOI3s2vMbJAF/mBmC83stKiDE4ktPbJBItTZPf5vuvsW4DRgCHAJcGtkUYmISGQ6m/ibdj/OBO5392XoujMRkR6ps4m/2syeIUj8T5tZOZCKLiwREYlKZ5/O+S3gSGCVu28zs72AyyOLSiTudOeuRKize/zHAW+6+yYz+zpwPbA5urBE4kotqBK9zib+3wLbzOwI4IfA28B9kUUlIiKR6Wzibwx/uPcc4L/d/Q6gPLqwREQkKp1t499qZj8huIzzBDNLAGXRhSUiIlHp7B7/JGA7wfX8HwAjgNsii0oktnRSV6LXqcQfJvvpwGAzOwtocHe18YtERXfuSoQ6+8iGrwLzga8AXwVeMbMLogxMRESi0dk2/p8Cx7j7OgAz2wd4DngoqsBERCQanW3jTzQl/dDGLOYVEZEi0tk9/qfM7GngT2H/JOCJaEISEd25K1HqVOJ392vN7Hzg+HDQXe7+l+jCEokrndSV6HV2jx93fxh4OMJYREQkDzpM/Ga2lcwXFhvg7j4okqhERCQyHSZ+d9djGUREehldmSNSVHRSV6KnxC9SjHTnrkRIiV9EJGYiS/xmNtXM1pnZ0rRhe5nZs2a2Ivw/JKryRUQksyj3+O8FTm8zbArwvLsfDDwf9ouISB5FlvjdfTbwUZvB5wDTwu5pwJejKl+kR9OduxKhfLfxV7j7+2H3B0BFnssXKXI6qSvRM49wz8LMRgGPufuYsH+Tu++ZNr7O3TO285vZZGAyQEVFReWMGTO6FEN9fT0DBw7s0rxRUlzZiUtcx86bTP+GD5l37O9o6D+saOLKlWKNC4o3tu7ENXHixGp3H7fLCHeP7AWMApam9b8JDA+7hwNvdmY5lZWV3lVVVVVdnjdKiis7sYnr9rHuNwxy37iqW4uJTX3lULHG1p24gAWeIafmu6nnUeDSsPtS4K95Ll9EJPaivJzzT8DLwCFmVmtm3wJuBf7FzFYAp4b9ItJMJ3Ulep1+Ome23P2idkadElWZIr2G7tyVCOnOXRGRmFHiFxGJGSV+kWKkG7gkQkr8IkVFbfsSPSV+EZGYUeIXEYkZJX4RkZhR4hcRiRklfhGRmFHiFykquoxToqfEL1KM9MgGiZASv4hIzCjxixQj3bkrEVLiFykqauKR6Cnxi4jEjBK/iEjMKPGLiMSMEr+ISMwo8YuIxIwSv0hR0WWcEj0lfpFipDt3JUJK/CIiMaPEL1KMdOeuREiJX6SoqIlHoqfELyISM0r8IiIxo8QvIhIzSvwiIjGjxC8iEjNK/CJFRZdxSvSU+EWKke7clQgp8YuIxExpIQo1s9XAViAJNLr7uELEIVK0dOeuRKggiT800d03FLB8kSKkJh6Jnpp6RERixrwAh5Rm9g5QR3AJw+/c/a4M00wGJgNUVFRUzpgxo0tl1dfXM3DgwG5EGw3FlZ24xHXsvMn0b/iQecf+job+w4omrlwp1rigeGPrTlwTJ06sztiU7u55fwH7hf/3BRYDJ3Y0fWVlpXdVVVVVl+eNkuLKTmziun2s+w2D3Deu6tZiYlNfOVSssXUnLmCBZ8ipBWnqcfe14f91wF+A8YWIQ0QkjvKe+M1sgJmVN3UDpwFL8x2HiEhcFeKqngrgLxbcoFIKPODuTxUgDpEipMs4JXp5T/zuvgo4It/livQounNXIqTLOUWKkW7gkggp8YsUFe3pS/SU+EVEYkaJX0QkZpT4RURiRolfRCRmlPhFRGJGiV9EJGaU+EWKiq7fl+gp8YuIxIwSv0hR0p6/REeJX6So6M5diZ4Sv4hIzCjxi4jEjBK/SBHZ3pgCYMnaLQWORAB49xWY/UtYM7/QkeSUEr9IkaiuqWPd1u0A/GDmP6iuqctbuXdUrcxbeT3Gmvkw9TR44SaYdnavSv69OvE/89SjbJvzf1jxhyt61ZsmvdO8VRvx8Dn8Oxudeas2Rl5mdU0dX/v9PH75zJtcfPc8Jf90q+e0dCd3tO7v4Xpt4n/mqUeZ+PI3OKPxOQ56988kp56h5C9FbcLooc0X9ZQkLOiP2LxVG9nemCLlsLMxlZeNTY8x6oSW7pI+rft7uF6b+Pd49b8pxTELfsUu4Y2w+IFIytKhcvHpie9J5cgh9CkpAeDKE0ZTOXJI5GWmb1zKShN52dj0GPuPb+m+9NHW/T1cIX5sPS9GJVe1HuDw4duvUZHjcqpr6njk9zdzmr3C/3vhWLji+rx8YfOluqaOeas2MmH00B6zXtU1dVx418vsTDr9yhJMv2JCj4m9JNzjHzl0j7yUl14vPame8q4XJX3oxXv8VrbrFye1aU3Oy9k89/fcXHI3JyaWcFPibjbP/X12C1gzH+YU51UD1TV1/PJ3d7HzuVu47e77esze87xVG9mZbGor75nNF4W4jUtJPz567R7/zmP+FV66rtWwvZIbgyQ76oScbcErP54NBM1J7k39P2qZYM384KRQpjLXzIdpZ0GyERIlcNTX4YiLimbv4p1/VDG97H9hBtv9Uf72j/2pHHleocParQmjh3K0vcWExHIWJg5nwujPFTqkTivEgxqa6oo1+xTNZ0+i1WsT/6jTrmbH3OvpY6nmYX0siT9/E0lKqf3cTYzasQKwlmSbKUl3lLiBwUdfAO+FZ/st7G+yZj7cexakdkJJ313bCRdNh8bg8j2SSVhwDyz6U+vp3p4Fa+bBp0/O+5fyxE+ew8Jdzz40cuInzwHFn/grEyuY0edmSkjiJX0pTRwHKKFltGY+D/S5hVIaYdqjva4tWzLrtYkfIEkJ7qnmE7xNSryRA166DrfgkDpVPY039z6NQzc8g3kKLAEHTICyAbDyWcAhUQpn/hLGXdaSjAcOg09amhH8kC9iFYcFPWvmw6yfQzJI7J7cga2e0/ylGrT5DVg8vU3EHmwImqZbMx/uPycYNeeXrY8IXp0Ky/8Kh50bxNRUZgcbqWzta5tbeqxNfye8Mf85Ni57nqFjTuHQY05tf8Icx7120TPsZ40ANCZ3BP2FTGZr5sPK5+GgU6JLql2tw9Vz6Gc7g+6mSxYjrKvh7z0N9/8GPnNOy+c2Ku++AqvnwoHh1Tg5/Ix1So4/17nUqxP/0sEnMW7LsxnHGS3tqJZKcui6J1s2Dp6Empdaz5BqhMe+D8v/Bm8/l3mZbz4Obz4BfQbAjo9xvLmMVCrFmk/6MQqg5mUOXHVfcCSQJjjMT2HV02DtwtYLT+6ABVNhwb0w7HD4YEkwfNUsqHsHDv0i3HNGEGeiDI6+pGUjseDeYCOR/mVr50M5aPMbMKc6GD5wn1b1ld7f0TIA3nj1OUY/PolDaGTH6rt4gwczJ/8182Hal4L1y3RUFJYxaPMA4KROfZleTh5G03FXkkSr/g514YivU8ucejp4kuTs21hx5szW9ZCL5JCpDjsr0yWLUSWsBffyT2/936D77ReC/+0l/6YY+g8Ndq5GZZm8m26+gmC9PBW8Mn3GwukPqHkI1uyRednZ1snujvYLrFcn/mN++BA7fjaEskSq1R6/tTlz1ra/fal2kz40bUgcdtSn9QcSOAf8/Tr4e3DeIdNpNCM4T+CbarBNNe3H0JT0m7z0a5j32yDpQ/BhWzA1eO0xFLaFRyVvvwAv/Qa2b8G3bQCCo6LSsecH65Uo46j69UEZVgKHnNG6nJXPw7M3QL9BwRfyiR+2bGiOuzr4YpQPh+OvYefCByijETPo443sXPgANCW8pg3RsM/CB69BY0MwvHE7zPlV8H/4Z2H7Zlj4R0g1cqSVwn794MlrgwRnJbw/5kpW15cw5LCTWyXTcXu8n1bvKcbsN6j1erS3IfxDmChK+zUnz9TUMzBvxBN9SFz+eOsNwptPMujjiiBZtE1S7y2CxTNgSy3uSQxIpJKs+dvP+XjfyuBE6oJ74bFrwkCDI8pU2Mhfs/FjJqTHnCkRNh0VPjUFb2wIPj9NR5ZUtp6vMxuz028NPoD3ntlxktyd9pa//K+tT1ov/2vr+l/8AGAw7Ah48keQ3AmkgASUhKkq1bhrXG3fz6aj7SbJnTSfPUk/qmmu073giWs5MNUI9/yp5cg+3b1fDD/rpR2fi2ta5uba5qN9kjuCdVv8ANSvh4H7tp6/vfpqu9OTQ9Z0p2AxGzdunC9YsKBL807+99u5M3VjsIevJ97uwr1z9eJkd6VJEqMk/LK5QzJRSqkn05aWHQestF/zRsLTFpMCvE85pUNHQZ9yePfvrefb8wD45x8GCXP54/BedcuC+5RDWX/YvqVlAwTQdzCNqRSlO7e2rEOfcko//Xko2wOWzGxZfmfXwWGb92H90GMYddgxwUY4rS4c2O6l9LNGTt15O/85+VwqEyuChLHwfkg1Nk/tVkJizPmw5CGcVHMMjZ5g06fPps/6ZQwa0A8+XBYk8aamyrp34O//FQyzEhgyEj4KL30u6QuHngnL/tIS9N6HwN4Hwyd1sGkN9NkjaOLc8CbsdSCMGB+cl9q2ERIJ6D8EPl4fLj8Bn/su1M6HD5bBzk8gtaOl3sZ+FbZtgL57wuuP7Kb2rFVdcegX4fjvBTs9bzzeMnyv0S3rk0miFPY/FjashI8/bH+6AftAxVhY9ULHYSVKYa9Pw/at8MkmaNy2m/VIU7oHNH5Cy3oloKSsZYMRSmEkzvp1l5rGzKza3cftMry3J/5Zs2ax8blfcF5JS9ONNgA9T7YbnlyX6WFPd2Po7Ia2MRXk0bbXWzfN3148nhZ0trF2po5z9T6kwvXI53valOl62tffAbMEfPPprI++2kv8vfY6/nTn3/wEv208i/DS7qA5JXxJz1CIL2t6mblKUp3d6SjNkPTT528vnqbhXYm1M/Pk6n1I5DnpQ9frpdAMgiOoHD4rKBaJH+Dbt0znpD0e4ZHk8STTkn76RiCqVy7KSZfNBkvbNpGerfk7nMNnBfXqk7ttzZ1yCtU1RzN+2qt8tG0nR9tb3FZyJyMTHzRP096WMJVhXNMdAglaHwKnT9t0WJ7eJp2t5kP7ND0l+TftoXY23kzrmmlYV5fVleW23UtPnyd9/ZqW1946py+n7TIyLbO7OmpWatVklKHM9OFt16051uZ2sI5j3mW+ptmt9Wez6eKG9HjSy0ovIj2EVk1yGeJJH5beFNYqlvT1blNQR/N1qO3KNQ1ruyKZ1q3tvH3Kc3pVUEESv5mdDvwGKAHudvdb81V25cghLPyfwdUbtz4xmjNfOoTtO6JLjU13Rc5LfYaF/k9dXsZ5JXPYm81sYDBbvD/HJV6nzJOU28cYsMUHUG4f05ed7KCMLT6AnVbKKh/G52wpe9lWEjiG00AfyryRsrSb21IZyu3uoXH6l70zG75MG8mubjh3N19nl9vexiFTMks/umtebJv1aJ42/NM2jq5u5NrT0bIyxZ4eX3oizvi/nXVrr6yO3temjcAu5TaNb5m1dXxp/ZnibjvMYZcPe/oGqO34VnFm+pJ0Vtvg24zrqPo+Sg7gmTP+zte6UXxbeT+5a2YlwFvAvwC1wKvARe7+envzdPfk7kknndSpaatr6rj1yeW8urquS2VJa00bLIBHkifsdsOXaSPZ1Q3n7ubr7HIvTDzPpJKq5o3sdvoyNXk6M1KntFq/palR7GX1fOQDGZNYvcs6/6jkAc4peYk6H8QiP6h5XNs4flTyAJNLHms+YtxBCYnwGHKN78MKH9Eqvj2pZ4htZaeXUmaNDPBPGJKo5x0fzh+Tp3JSYjGfsdXNOwTv+d6sZD+2eH8OT9TwZHI8X0lUcURiVXMirfEKrm28ilMTCzi95FX+kTqIt30EH/lA9rL6XersaHuLm0ru4eBELY2UUOcDGWANbKcPi1IHMSt1xC7ztV3v9P5/sjVMKqniQ9+Lu5JnNY//UckMPp1Yy9u+H79ovBCACYnlu9Q5wOSSxzjQ3ucdH85dybOap830fnf0Oc3FjluuPHzV57J+nlLRXNVjZscBN7r7F8L+nwC4+8/bmydfib8j1TV1PLywlpdWbGDNR9u6tfEXEcnWtV84hKsnHpTVPO0l/kI09ewHpD8msxY4tu1EZjYZmAxQUVHBrFmzulRYfX19l+dt67QhcNp4AwZ0azkr65JU1XzCJ8mg+t/ZnGTLjuBKju0F36J0pTEzHxRXdhRX9oo1tiCuvptqmDWrNidLLNqTu+5+F3AXBHv8Xd1rz9Uefy6dBBxUhHFBcdYXFDaupqM9A847egRvfrCVJ5e+zxljhrPtvRWsYl9eWrGB2rptYLD/kD04/qC9Ke9byp9efZetnwR3MCfTDq5LDBKJIMmk3EmluncSvm0beHEmMCjeuKBYYyvBmNmFZp6OFCLxrwX2T+sfEQ4TKUqVI4e0+tJVjhzC1449AIBZs1ZxxUlj2513ypmfiTy+TLQBz16xxjZr1qyc/1ZCIa7jfxU42MwONLM+wIVAFk+VEhGR7sj7Hr+7N5rZvwFPE1zOOdXdl+U7DhGRuCpIG7+7PwE8UYiyRUTiLjaPbBARkYASv4hIzCjxi4jETI94Hr+ZrQdqujj73sCGHIaTK4orO4orO4ore8UaW3fiGunu+7Qd2CMSf3eY2YJMtywXmuLKjuLKjuLKXrHGFkVcauoREYkZJX4RkZiJQ+K/q9ABtENxZUdxZUdxZa9YY8t5XL2+jV9ERFqLwx6/iIikUeIXEYmZXp34zex0M3vTzFaa2ZQClL/azJaY2SIzWxAO28vMnjWzFeH/IeFwM7P/CmN9zcyOzmEcU81snZktTRuWdRxmdmk4/QozuzSiuG40s7VhnS0yszPTxv0kjOtNM/tC2vCcvs9mtr+ZVZnZ62a2zMyuCYcXtM46iKugdWZm/cxsvpktDuP693D4gWb2SljGg+HTeDGzvmH/ynD8qN3Fm+O47jWzd9Lq68hweN4+++EyS8zsH2b2WNifv/py9175Injy59vAaKAPsBg4LM8xrAb2bjPsF8CUsHsK8J9h95nAkwS/BjEBeCWHcZwIHA0s7WocwF7AqvD/kLB7SARx3Qj8jwzTHha+h32BA8P3tiSK9xkYDhwddpcT/Eb0YYWusw7iKmidhes9MOwuA14J62EmcGE4/E7gqrD728CdYfeFwIMdxRtBXPcCF2SYPm+f/XC5PwAeAB4L+/NWX715j388sNLdV7n7DmAGcE6BY4Ighmlh9zTgy2nD7/PAPGBPMxueiwLdfTbwUTfj+ALwrLt/5O51wLPA6RHE1Z5zgBnuvt3d3wFWErzHOX+f3f19d18Ydm8FlhP8ZGhB66yDuNqTlzoL17s+7C0LXw6cDDwUDm9bX031+BBwiplZB/HmOq725O2zb2YjgC8Cd4f9Rh7rqzcn/ky/7dvRlyQKDjxjZtUW/IYwQIW7vx92fwBUhN35jjfbOPIZ37+Fh9pTm5pTChVXeFh9FMHeYtHUWZu4oMB1FjZbLALWESTGt4FN7t6YoYzm8sPxm4Gh+YjL3Zvq65awvm43s75t42pTfhTv46+BHwFNv7I9lDzWV29O/MXgn939aOAM4GozOzF9pAfHawW/nrZY4gj9Fvg0cCTwPvDLQgViZgOBh4HvufuW9HGFrLMMcRW8ztw96e5HEvyU6njg0HzHkEnbuMxsDPATgviOIWi++XE+YzKzs4B17l6dz3LT9ebEX/Df9nX3teH/dcBfCL4QHzY14YT/14WT5zvebOPIS3zu/mH4ZU0Bv6fl0DWvcZlZGUFyne7uj4SDC15nmeIqljoLY9kEVAHHETSVNP3YU3oZzeWH4wcDG/MU1+lhk5m7+3bgHvJfX8cDZ5vZaoJmtpOB35DP+uruCYpifRH8utgqgpMeTSewDs9j+QOA8rTuvxO0C95G6xOEvwi7v0jrE0vzcxzPKFqfRM0qDoI9o3cITm4NCbv3iiCu4Wnd3ydowwQ4nNYnslYRnKTM+fscrvt9wK/bDC9onXUQV0HrDNgH2DPs7g/MAc4C/kzrk5XfDruvpvXJypkdxRtBXMPT6vPXwK2F+OyHyz6JlpO7eauvnCWWYnwRnKV/i6C98ad5Lnt0+KYsBpY1lU/QNvc8sAJ4rukDFH7Y7ghjXQKMy2EsfyJoAthJ0A74ra7EAXyT4ATSSuDyiOK6Pyz3NeBRWie1n4ZxvQmcEdX7DPwzQTPOa8Ci8HVmoeusg7gKWmfAZ4F/hOUvBf5n2ndgfrjufwb6hsP7hf0rw/GjdxdvjuN6IayvpcAfabnyJ2+f/bTlnkRL4s9bfemRDSIiMdOb2/hFRCQDJX4RkZhR4hcRiRklfhGRmFHiFxGJGSV+kYiZ2UlNT2AUKQZK/CIiMaPELxIys6+Hz29fZGa/Cx/wVR8+yGuZmT1vZvuE0x5pZvPCB339xVqezX+QmT0XPgN+oZl9Olz8QDN7yMzeMLPp4dMVRQpCiV8EMLPPAJOA4z14qFcSuJjgcRsL3P1w4EXghnCW+4Afu/tnCe7ybBo+HbjD3Y8APkdwZzIET9L8HsEz1EcTPK9FpCBKdz+JSCycAlQCr4Y74/0JHsKWAh4Mp/kj8IiZDSZ4BsyL4fBpwJ/NrBzYz93/AuDuDQDh8ua7e23Yv4jgGUVzI18rkQyU+EUCBkxz95+0Gmj2szbTdfUZJ9vTupPouycFpKYekcDzwAVmti80/77uSILvyAXhNF8D5rr7ZqDOzE4Ih18CvOjBr2LVmtmXw2X0NbM98rkSIp2hvQ4RwN1fN7PrCX4xLUHwxNCrgY8JfsDjeoKmn0nhLJcCd4aJfRVweTj8EuB3ZnZTuIyv5HE1RDpFT+cU6YCZ1bv7wELHIZJLauoREYkZ7fGLiMSM9vhFRGJGiV9EJGaU+EVEYkaJX0QkZpT4RURi5v8DopaAjvxlHTIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 学習経過の可視化(大きさ)\n",
    "loss     = size_history.history['loss']\n",
    "val_loss = size_history.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss,     marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大きさ1の正答率：0.7962962962962963\n",
      "大きさ2の正答率：0.192\n",
      "大きさ3の正答率：0.8598130841121495\n",
      "大きさ4の正答率：0.8\n",
      "大きさ5の正答率：0.75\n"
     ]
    }
   ],
   "source": [
    "#大きさごとの推定精度の確認：20%以下\n",
    "size_predict = cnn_size_model.predict([size_x_test1,size_x_test2,size_x_test3])\n",
    "size_answer = size_y_test\n",
    "one_total = 0\n",
    "one_ok = 0\n",
    "two_total = 0\n",
    "two_ok = 0\n",
    "three_total = 0\n",
    "three_ok = 0\n",
    "four_total = 0\n",
    "four_ok = 0\n",
    "five_total = 0\n",
    "five_ok = 0\n",
    "for i in range(len(size_predict)):\n",
    "    if size_answer[i] == 1:\n",
    "        one_total = one_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.2):\n",
    "            one_ok = one_ok + 1\n",
    "    if size_answer[i] == 2:\n",
    "        two_total = two_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.4):\n",
    "            two_ok = two_ok + 1\n",
    "    if size_answer[i] == 3:\n",
    "        three_total = three_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.6):\n",
    "            three_ok = three_ok + 1\n",
    "    if size_answer[i] == 4:\n",
    "        four_total = four_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.8):\n",
    "            four_ok = four_ok + 1\n",
    "    if size_answer[i] == 5:\n",
    "        five_total = five_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 1):\n",
    "            five_ok = five_ok + 1\n",
    "print(\"大きさ1の正答率：\"+str(one_ok/one_total))\n",
    "print(\"大きさ2の正答率：\"+str(two_ok/two_total))\n",
    "print(\"大きさ3の正答率：\"+str(three_ok/three_total))\n",
    "print(\"大きさ4の正答率：\"+str(four_ok/four_total))\n",
    "print(\"大きさ5の正答率：\"+str(five_ok/five_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "left = np.array([1,2,3,4,5])\n",
    "height = np.array([one_ok/one_total,two_ok/two_total,three_ok/three_total,four_ok/four_total,five_ok/five_total])\n",
    "plt.bar(left, height)\n",
    "plt.xlabel(\"size\")\n",
    "plt.ylabel(\"size acc\")\n",
    "plt.ylim(top=1, bottom=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大きさ1の正答率：0.9351851851851852\n",
      "大きさ2の正答率：0.312\n",
      "大きさ3の正答率：0.822429906542056\n",
      "大きさ4の正答率：0.5684210526315789\n",
      "大きさ5の正答率：0.4230769230769231\n"
     ]
    }
   ],
   "source": [
    "#大きさごとの推定精度の確認：最も近く予測\n",
    "size_predict = cnn_size_model.predict([size_x_test1,size_x_test2,size_x_test3])\n",
    "size_answer = size_y_test\n",
    "one_total = 0\n",
    "one_ok = 0\n",
    "two_total = 0\n",
    "two_ok = 0\n",
    "three_total = 0\n",
    "three_ok = 0\n",
    "four_total = 0\n",
    "four_ok = 0\n",
    "five_total = 0\n",
    "five_ok = 0\n",
    "for i in range(len(size_predict)):\n",
    "    if size_answer[i] == 1:\n",
    "        one_total = one_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.5):\n",
    "            one_ok = one_ok + 1\n",
    "    if size_answer[i] == 2:\n",
    "        two_total = two_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.5):\n",
    "            two_ok = two_ok + 1\n",
    "    if size_answer[i] == 3:\n",
    "        three_total = three_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.5):\n",
    "            three_ok = three_ok + 1\n",
    "    if size_answer[i] == 4:\n",
    "        four_total = four_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.5):\n",
    "            four_ok = four_ok + 1\n",
    "    if size_answer[i] == 5:\n",
    "        five_total = five_total + 1\n",
    "        if (abs(size_predict[i] - size_answer[i]) < 0.5):\n",
    "            five_ok = five_ok + 1\n",
    "print(\"大きさ1の正答率：\"+str(one_ok/one_total))\n",
    "print(\"大きさ2の正答率：\"+str(two_ok/two_total))\n",
    "print(\"大きさ3の正答率：\"+str(three_ok/three_total))\n",
    "print(\"大きさ4の正答率：\"+str(four_ok/four_total))\n",
    "print(\"大きさ5の正答率：\"+str(five_ok/five_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "left = np.array([1,2,3,4,5])\n",
    "height = np.array([one_ok/one_total,two_ok/two_total,three_ok/three_total,four_ok/four_total,five_ok/five_total])\n",
    "plt.bar(left, height)\n",
    "plt.xlabel(\"size\")\n",
    "plt.ylabel(\"size acc\")\n",
    "plt.ylim(top=1, bottom=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
