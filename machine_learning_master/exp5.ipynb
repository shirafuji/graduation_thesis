{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全ての実験を踏まえた学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 必要なライブラリのimport\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, Flatten, Input, concatenate\n",
    "from keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## データについて\n",
    "\n",
    "### データファイルのpath\n",
    "no_hole_path = './../vibration_simulation/vibration_data/no_hole_data.csv'\n",
    "one_hole_path = './../vibration_simulation/vibration_data/one_hole_data.csv'\n",
    "four_holes_path = './../vibration_simulation/vibration_data/four_holes_data.csv'\n",
    "nine_holes_path = './../vibration_simulation/vibration_data/nine_holes_data.csv'\n",
    "sixteen_holes_path = './../vibration_simulation/vibration_data/sixteen_holes_data.csv'\n",
    "twentyfive_holes_path = './../vibration_simulation/vibration_data/twentyfive_holes_data.csv'\n",
    "\n",
    "### 入力データと正解データ\n",
    "size_x_data_list1 = []\n",
    "size_x_data_list2 = []\n",
    "size_x_data_list3 = []\n",
    "y_size_data_array = []\n",
    "no_hole_data1 = []\n",
    "one_one_one1 = []\n",
    "one_two_two1 = []\n",
    "one_three_three1 = []\n",
    "one_four_four1 = []\n",
    "one_five_five1 = []\n",
    "two_one_two1 = []\n",
    "two_two_three1 = []\n",
    "two_three_four1 = []\n",
    "two_four_five1 = []\n",
    "two_five_one1 = []\n",
    "three_one_three1 = []\n",
    "three_two_four1 = []\n",
    "three_three_five1 = []\n",
    "three_four_one1 = []\n",
    "three_five_two1 = []\n",
    "four_one_four1 = []\n",
    "four_two_five1 = []\n",
    "four_three_one1 = []\n",
    "four_four_two1 = []\n",
    "four_five_three1 = []\n",
    "five_one_five1 = []\n",
    "five_two_one1 = []\n",
    "five_three_two1 = []\n",
    "five_four_three1 = []\n",
    "five_five_four1 = []\n",
    "no_hole_data2 = []\n",
    "one_one_one2 = []\n",
    "one_two_two2 = []\n",
    "one_three_three2 = []\n",
    "one_four_four2 = []\n",
    "one_five_five2 = []\n",
    "two_one_two2 = []\n",
    "two_two_three2 = []\n",
    "two_three_four2 = []\n",
    "two_four_five2 = []\n",
    "two_five_one2 = []\n",
    "three_one_three2 = []\n",
    "three_two_four2 = []\n",
    "three_three_five2 = []\n",
    "three_four_one2 = []\n",
    "three_five_two2 = []\n",
    "four_one_four2 = []\n",
    "four_two_five2 = []\n",
    "four_three_one2 = []\n",
    "four_four_two2 = []\n",
    "four_five_three2 = []\n",
    "five_one_five2 = []\n",
    "five_two_one2 = []\n",
    "five_three_two2 = []\n",
    "five_four_three2 = []\n",
    "five_five_four2 = []\n",
    "no_hole_data3 = []\n",
    "one_one_one3 = []\n",
    "one_two_two3 = []\n",
    "one_three_three3 = []\n",
    "one_four_four3 = []\n",
    "one_five_five3 = []\n",
    "two_one_two3 = []\n",
    "two_two_three3 = []\n",
    "two_three_four3 = []\n",
    "two_four_five3 = []\n",
    "two_five_one3 = []\n",
    "three_one_three3 = []\n",
    "three_two_four3 = []\n",
    "three_three_five3 = []\n",
    "three_four_one3 = []\n",
    "three_five_two3 = []\n",
    "four_one_four3 = []\n",
    "four_two_five3 = []\n",
    "four_three_one3 = []\n",
    "four_four_two3 = []\n",
    "four_five_three3 = []\n",
    "five_one_five3 = []\n",
    "five_two_one3 = []\n",
    "five_three_two3 = []\n",
    "five_four_three3 = []\n",
    "five_five_four3 = []\n",
    "rep_freq_array1 = []\n",
    "rep_freq_array2 = []\n",
    "rep_freq_array3 = []\n",
    "\n",
    "### ファイル読み込み\n",
    "\n",
    "#### 欠陥がない場合のデータ\n",
    "with open(no_hole_path) as f:\n",
    "    for line in f:\n",
    "        data_array = line.split(' ')\n",
    "        no_hole_data1 = data_array[0:1251]\n",
    "        no_hole_data2 = data_array[1251:2502]\n",
    "        no_hole_data3 = data_array[2502:-1]\n",
    "\n",
    "#### データ分類\n",
    "with open(one_hole_path) as fs1:\n",
    "  for line in fs1:\n",
    "    data_array = line.split(' ')\n",
    "    position = np.array(data_array[1:3], dtype=float)\n",
    "    if (0<position[0] and position[0]<10 and 0 < position[1] and position[1] < 10):\n",
    "        one_one_one1.append(data_array[3:1254])\n",
    "        one_one_one2.append(data_array[1254:2505])\n",
    "        one_one_one3.append(data_array[2505:-1])\n",
    "    if (10<position[0] and position[0]<20 and 10 < position[1] and position[1] < 20):\n",
    "        one_two_two1.append(data_array[3:1254])\n",
    "        one_two_two2.append(data_array[1254:2505])\n",
    "        one_two_two3.append(data_array[2505:-1])\n",
    "    if (20<position[0] and position[0]<30 and 20 < position[1] and position[1] < 30):\n",
    "        one_three_three1.append(data_array[3:1254])\n",
    "        one_three_three2.append(data_array[1254:2505])\n",
    "        one_three_three3.append(data_array[2505:-1])\n",
    "    if (30<position[0] and position[0]<40 and 30 < position[1] and position[1] < 40):\n",
    "        one_four_four1.append(data_array[3:1254])\n",
    "        one_four_four2.append(data_array[1254:2505])\n",
    "        one_four_four3.append(data_array[2505:-1])\n",
    "    if (40<position[0] and position[0]<50 and 40 < position[1] and position[1] < 50):\n",
    "        one_five_five1.append(data_array[3:1254])\n",
    "        one_five_five2.append(data_array[1254:2505])\n",
    "        one_five_five3.append(data_array[2505:-1])\n",
    "with open(four_holes_path) as fs2:\n",
    "  for line in fs2:\n",
    "    data_array = line.split(' ')\n",
    "    position = np.array(data_array[1:3], dtype=float)\n",
    "    if (0<position[0] and position[0]<10 and 10 < position[1] and position[1] < 20):\n",
    "        two_one_two1.append(data_array[3:1254])\n",
    "        two_one_two2.append(data_array[1254:2505])\n",
    "        two_one_two3.append(data_array[2505:-1])\n",
    "    if (10<position[0] and position[0]<20 and 20 < position[1] and position[1] < 30):\n",
    "        two_two_three1.append(data_array[3:1254])\n",
    "        two_two_three2.append(data_array[1254:2505])\n",
    "        two_two_three3.append(data_array[2505:-1])\n",
    "    if (20<position[0] and position[0]<30 and 30 < position[1] and position[1] < 40):\n",
    "        two_three_four1.append(data_array[3:1254])\n",
    "        two_three_four2.append(data_array[1254:2505])\n",
    "        two_three_four3.append(data_array[2505:-1])\n",
    "    if (30<position[0] and position[0]<40 and 40 < position[1] and position[1] < 50):\n",
    "        two_four_five1.append(data_array[3:1254])\n",
    "        two_four_five2.append(data_array[1254:2505])\n",
    "        two_four_five3.append(data_array[2505:-1])\n",
    "    if (40<position[0] and position[0]<50 and 0 < position[1] and position[1] < 10):\n",
    "        two_five_one1.append(data_array[3:1254])\n",
    "        two_five_one2.append(data_array[1254:2505])\n",
    "        two_five_one3.append(data_array[2505:-1])\n",
    "with open(nine_holes_path) as fs3:\n",
    "  for line in fs3:\n",
    "    data_array = line.split(' ')\n",
    "    position = np.array(data_array[1:3], dtype=float)\n",
    "    if (0<position[0] and position[0]<10 and 20 < position[1] and position[1] < 30):\n",
    "        three_one_three1.append(data_array[3:1254])\n",
    "        three_one_three2.append(data_array[1254:2505])\n",
    "        three_one_three3.append(data_array[2505:-1])\n",
    "    if (10<position[0] and position[0]<20 and 30 < position[1] and position[1] < 40):\n",
    "        three_two_four1.append(data_array[3:1254])\n",
    "        three_two_four2.append(data_array[1254:2505])\n",
    "        three_two_four3.append(data_array[2505:-1])\n",
    "    if (20<position[0] and position[0]<30 and 40 < position[1] and position[1] < 50):\n",
    "        three_three_five1.append(data_array[3:1254])\n",
    "        three_three_five2.append(data_array[1254:2505])\n",
    "        three_three_five3.append(data_array[2505:-1])\n",
    "    if (30<position[0] and position[0]<40 and 0 < position[1] and position[1] < 10):\n",
    "        three_four_one1.append(data_array[3:1254])\n",
    "        three_four_one2.append(data_array[1254:2505])\n",
    "        three_four_one3.append(data_array[2505:-1])\n",
    "    if (40<position[0] and position[0]<50 and 10 < position[1] and position[1] < 20):\n",
    "        three_five_two1.append(data_array[3:1254])\n",
    "        three_five_two2.append(data_array[1254:2505])\n",
    "        three_five_two3.append(data_array[2505:-1])\n",
    "with open(sixteen_holes_path) as fs4:\n",
    "  for line in fs4:\n",
    "    data_array = line.split(' ')\n",
    "    position = np.array(data_array[1:3], dtype=float)\n",
    "    if (0<position[0] and position[0]<10 and 30 < position[1] and position[1] < 40):\n",
    "        four_one_four1.append(data_array[3:1254])\n",
    "        four_one_four2.append(data_array[1254:2505])\n",
    "        four_one_four3.append(data_array[2505:-1])\n",
    "    if (10<position[0] and position[0]<20 and 40 < position[1] and position[1] < 50):\n",
    "        four_two_five1.append(data_array[3:1254])\n",
    "        four_two_five2.append(data_array[1254:2505])\n",
    "        four_two_five3.append(data_array[2505:-1])\n",
    "    if (20<position[0] and position[0]<30 and 0 < position[1] and position[1] < 10):\n",
    "        four_three_one1.append(data_array[3:1254])\n",
    "        four_three_one2.append(data_array[1254:2505])\n",
    "        four_three_one3.append(data_array[2505:-1])\n",
    "    if (30<position[0] and position[0]<40 and 10 < position[1] and position[1] < 20):\n",
    "        four_four_two1.append(data_array[3:1254])\n",
    "        four_four_two2.append(data_array[1254:2505])\n",
    "        four_four_two3.append(data_array[2505:-1])\n",
    "    if (40<position[0] and position[0]<50 and 20 < position[1] and position[1] < 30):\n",
    "        four_five_three1.append(data_array[3:1254])\n",
    "        four_five_three2.append(data_array[1254:2505])\n",
    "        four_five_three3.append(data_array[2505:-1])\n",
    "with open(twentyfive_holes_path) as fs5:\n",
    "  for line in fs5:\n",
    "    data_array = line.split(' ')\n",
    "    position = np.array(data_array[1:3], dtype=float)\n",
    "    if (0<position[0] and position[0]<10 and 40 < position[1] and position[1] < 50):\n",
    "        five_one_five1.append(data_array[3:1254])\n",
    "        five_one_five2.append(data_array[1254:2505])\n",
    "        five_one_five3.append(data_array[2505:-1])\n",
    "    if (10<position[0] and position[0]<20 and 0 < position[1] and position[1] < 10):\n",
    "        five_two_one1.append(data_array[3:1254])\n",
    "        five_two_one2.append(data_array[1254:2505])\n",
    "        five_two_one3.append(data_array[2505:-1])\n",
    "    if (20<position[0] and position[0]<30 and 10 < position[1] and position[1] < 20):\n",
    "        five_three_two1.append(data_array[3:1254])\n",
    "        five_three_two2.append(data_array[1254:2505])\n",
    "        five_three_two3.append(data_array[2505:-1])\n",
    "    if (30<position[0] and position[0]<40 and 20 < position[1] and position[1] < 30):\n",
    "        five_four_three1.append(data_array[3:1254])\n",
    "        five_four_three2.append(data_array[1254:2505])\n",
    "        five_four_three3.append(data_array[2505:-1])\n",
    "    if (40<position[0] and position[0]<50 and 30 < position[1] and position[1] < 40):\n",
    "        five_five_four1.append(data_array[3:1254])\n",
    "        five_five_four2.append(data_array[1254:2505])\n",
    "        five_five_four3.append(data_array[2505:-1])\n",
    "### 利用データの決定\n",
    "for j in range(1):\n",
    "    size_x_data1 = []\n",
    "    size_x_data2 = []\n",
    "    size_x_data3 = []\n",
    "    size_y_data = []\n",
    "#     position_x_data = []\n",
    "#     position_y_data = []\n",
    "    #### one_one_oneについて\n",
    "    index = []\n",
    "    for i in range(len(one_one_one1)):\n",
    "        index.append(i)\n",
    "    data_count = 10\n",
    "    used_index = random.sample(index, data_count)\n",
    "    for i in used_index:\n",
    "        data_array1 = one_one_one1[i]\n",
    "        size_x_data1.append(data_array1)\n",
    "        data_array2 = one_one_one2[i]\n",
    "        size_x_data2.append(data_array2)\n",
    "        data_array3 = one_one_one3[i]\n",
    "        size_x_data3.append(data_array3)\n",
    "        size_y_data.append(1)\n",
    "    #### one_two_twoについて\n",
    "    index = []\n",
    "    for i in range(len(one_two_two1)):\n",
    "        index.append(i)\n",
    "    data_count = 10\n",
    "    used_index = random.sample(index, data_count)\n",
    "    for i in used_index:\n",
    "        data_array1 = one_two_two1[i]\n",
    "        size_x_data1.append(data_array1)\n",
    "        data_array2 = one_two_two2[i]\n",
    "        size_x_data2.append(data_array2)\n",
    "        data_array3 = one_two_two3[i]\n",
    "        size_x_data3.append(data_array3)\n",
    "        size_y_data.append(1)\n",
    "    #### one_three_threeについて\n",
    "    index = []\n",
    "    for i in range(len(one_three_three1)):\n",
    "        index.append(i)\n",
    "    data_count = 10\n",
    "    used_index = random.sample(index, data_count)\n",
    "    for i in used_index:\n",
    "        data_array1 = one_three_three1[i]\n",
    "        size_x_data1.append(data_array1)\n",
    "        data_array2 = one_three_three2[i]\n",
    "        size_x_data2.append(data_array2)\n",
    "        data_array3 = one_three_three3[i]\n",
    "        size_x_data3.append(data_array3)\n",
    "        size_y_data.append(1)\n",
    "    #### one_four_fourについて\n",
    "    index = []\n",
    "    for i in range(len(one_four_four1)):\n",
    "        index.append(i)\n",
    "    data_count = 10\n",
    "    used_index = random.sample(index, data_count)\n",
    "    for i in used_index:\n",
    "        data_array1 = one_four_four1[i]\n",
    "        size_x_data1.append(data_array1)\n",
    "        data_array2 = one_four_four2[i]\n",
    "        size_x_data2.append(data_array2)\n",
    "        data_array3 = one_four_four3[i]\n",
    "        size_x_data3.append(data_array3)\n",
    "        size_y_data.append(1)\n",
    "    #### one_five_fiveについて\n",
    "    index = []\n",
    "    for i in range(len(one_five_five1)):\n",
    "        index.append(i)\n",
    "    data_count = 10\n",
    "    used_index = random.sample(index, data_count)\n",
    "    for i in used_index:\n",
    "        data_array1 = one_five_five1[i]\n",
    "        size_x_data1.append(data_array1)\n",
    "        data_array2 = one_five_five2[i]\n",
    "        size_x_data2.append(data_array2)\n",
    "        data_array3 = one_five_five3[i]\n",
    "        size_x_data3.append(data_array3)\n",
    "        size_y_data.append(1)\n",
    "    #### two_one_twoについて\n",
    "    index = []\n",
    "    for i in range(len(two_one_two1)):\n",
    "        index.append(i)\n",
    "    data_count = 10\n",
    "    used_index = random.sample(index, data_count)\n",
    "    for i in used_index:\n",
    "        data_array1 = two_one_two1[i]\n",
    "        size_x_data1.append(data_array1)\n",
    "        data_array2 = two_one_two2[i]\n",
    "        size_x_data2.append(data_array2)\n",
    "        data_array3 = two_one_two3[i]\n",
    "        size_x_data3.append(data_array3)\n",
    "        size_y_data.append(2)\n",
    "    #### two_two_threeについて\n",
    "    index = []\n",
    "    for i in range(len(two_two_three1)):\n",
    "        index.append(i)\n",
    "    data_count = 10\n",
    "    used_index = random.sample(index, data_count)\n",
    "    for i in used_index:\n",
    "        data_array1 = two_two_three1[i]\n",
    "        size_x_data1.append(data_array1)\n",
    "        data_array2 = two_two_three2[i]\n",
    "        size_x_data2.append(data_array2)\n",
    "        data_array3 = two_two_three3[i]\n",
    "        size_x_data3.append(data_array3)\n",
    "        size_y_data.append(2)\n",
    "    #### two_three_fourについて\n",
    "    index = []\n",
    "    for i in range(len(two_three_four1)):\n",
    "        index.append(i)\n",
    "    data_count = 10\n",
    "    used_index = random.sample(index, data_count)\n",
    "    for i in used_index:\n",
    "        data_array1 = two_three_four1[i]\n",
    "        size_x_data1.append(data_array1)\n",
    "        data_array2 = two_three_four2[i]\n",
    "        size_x_data2.append(data_array2)\n",
    "        data_array3 = two_three_four3[i]\n",
    "        size_x_data3.append(data_array3)\n",
    "        size_y_data.append(2)\n",
    "    #### two_four_fiveについて\n",
    "    index = []\n",
    "    for i in range(len(two_four_five1)):\n",
    "        index.append(i)\n",
    "    data_count = 10\n",
    "    used_index = random.sample(index, data_count)\n",
    "    for i in used_index:\n",
    "        data_array1 = two_four_five1[i]\n",
    "        size_x_data1.append(data_array1)\n",
    "        data_array2 = two_four_five2[i]\n",
    "        size_x_data2.append(data_array2)\n",
    "        data_array3 = two_four_five3[i]\n",
    "        size_x_data3.append(data_array3)\n",
    "        size_y_data.append(2)\n",
    "    #### two_five_oneについて\n",
    "    index = []\n",
    "    for i in range(len(two_five_one1)):\n",
    "        index.append(i)\n",
    "    data_count = 10\n",
    "    used_index = random.sample(index, data_count)\n",
    "    for i in used_index:\n",
    "        data_array1 = two_five_one1[i]\n",
    "        size_x_data1.append(data_array1)\n",
    "        data_array2 = two_five_one2[i]\n",
    "        size_x_data2.append(data_array2)\n",
    "        data_array3 = two_five_one3[i]\n",
    "        size_x_data3.append(data_array3)\n",
    "        size_y_data.append(2)\n",
    "    #### three_one_threeについて\n",
    "    index = []\n",
    "    for i in range(len(three_one_three1)):\n",
    "        index.append(i)\n",
    "    data_count = 10\n",
    "    used_index = random.sample(index, data_count)\n",
    "    for i in used_index:\n",
    "        data_array1 = three_one_three1[i]\n",
    "        size_x_data1.append(data_array1)\n",
    "        data_array2 = three_one_three2[i]\n",
    "        size_x_data2.append(data_array2)\n",
    "        data_array3 = three_one_three3[i]\n",
    "        size_x_data3.append(data_array3)\n",
    "        size_y_data.append(3)\n",
    "    #### three_two_fourについて\n",
    "    index = []\n",
    "    for i in range(len(three_two_four1)):\n",
    "        index.append(i)\n",
    "    data_count = 10\n",
    "    used_index = random.sample(index, data_count)\n",
    "    for i in used_index:\n",
    "        data_array1 = three_two_four1[i]\n",
    "        size_x_data1.append(data_array1)\n",
    "        data_array2 = three_two_four2[i]\n",
    "        size_x_data2.append(data_array2)\n",
    "        data_array3 = three_two_four3[i]\n",
    "        size_x_data3.append(data_array3)\n",
    "        size_y_data.append(3)\n",
    "    #### three_three_fiveについて\n",
    "    index = []\n",
    "    for i in range(len(three_three_five1)):\n",
    "        index.append(i)\n",
    "    data_count = 10\n",
    "    used_index = random.sample(index, data_count)\n",
    "    for i in used_index:\n",
    "        data_array1 = three_three_five1[i]\n",
    "        size_x_data1.append(data_array1)\n",
    "        data_array2 = three_three_five2[i]\n",
    "        size_x_data2.append(data_array2)\n",
    "        data_array3 = three_three_five3[i]\n",
    "        size_x_data3.append(data_array3)\n",
    "        size_y_data.append(3)\n",
    "    #### three_four_oneについて\n",
    "    index = []\n",
    "    for i in range(len(three_four_one1)):\n",
    "        index.append(i)\n",
    "    data_count = 10\n",
    "    used_index = random.sample(index, data_count)\n",
    "    for i in used_index:\n",
    "        data_array1 = three_four_one1[i]\n",
    "        size_x_data1.append(data_array1)\n",
    "        data_array2 = three_four_one2[i]\n",
    "        size_x_data2.append(data_array2)\n",
    "        data_array3 = three_four_one3[i]\n",
    "        size_x_data3.append(data_array3)\n",
    "        size_y_data.append(3)\n",
    "    #### three_five_twoについて\n",
    "    index = []\n",
    "    for i in range(len(three_five_two1)):\n",
    "        index.append(i)\n",
    "    data_count = 10\n",
    "    used_index = random.sample(index, data_count)\n",
    "    for i in used_index:\n",
    "        data_array1 = three_five_two1[i]\n",
    "        size_x_data1.append(data_array1)\n",
    "        data_array2 = three_five_two2[i]\n",
    "        size_x_data2.append(data_array2)\n",
    "        data_array3 = three_five_two3[i]\n",
    "        size_x_data3.append(data_array3)\n",
    "        size_y_data.append(3)\n",
    "    #### four_one_fourについて\n",
    "    index = []\n",
    "    for i in range(len(four_one_four1)):\n",
    "        index.append(i)\n",
    "    data_count = 10\n",
    "    used_index = random.sample(index, data_count)\n",
    "    for i in used_index:\n",
    "        data_array1 = four_one_four1[i]\n",
    "        size_x_data1.append(data_array1)\n",
    "        data_array2 = four_one_four2[i]\n",
    "        size_x_data2.append(data_array2)\n",
    "        data_array3 = four_one_four3[i]\n",
    "        size_x_data3.append(data_array3)\n",
    "        size_y_data.append(4)\n",
    "    #### four_two_fiveについて\n",
    "    index = []\n",
    "    for i in range(len(four_two_five1)):\n",
    "        index.append(i)\n",
    "    data_count = 10\n",
    "    used_index = random.sample(index, data_count)\n",
    "    for i in used_index:\n",
    "        data_array1 = four_two_five1[i]\n",
    "        size_x_data1.append(data_array1)\n",
    "        data_array2 = four_two_five2[i]\n",
    "        size_x_data2.append(data_array2)\n",
    "        data_array3 = four_two_five3[i]\n",
    "        size_x_data3.append(data_array3)\n",
    "        size_y_data.append(4)\n",
    "    #### four_three_oneについて\n",
    "    index = []\n",
    "    for i in range(len(four_three_one1)):\n",
    "        index.append(i)\n",
    "    data_count = 10\n",
    "    used_index = random.sample(index, data_count)\n",
    "    for i in used_index:\n",
    "        data_array1 = four_three_one1[i]\n",
    "        size_x_data1.append(data_array1)\n",
    "        data_array2 = four_three_one2[i]\n",
    "        size_x_data2.append(data_array2)\n",
    "        data_array3 = four_three_one3[i]\n",
    "        size_x_data3.append(data_array3)\n",
    "        size_y_data.append(4)\n",
    "    #### four_four_twoについて\n",
    "    index = []\n",
    "    for i in range(len(four_four_two1)):\n",
    "        index.append(i)\n",
    "    data_count = 10\n",
    "    used_index = random.sample(index, data_count)\n",
    "    for i in used_index:\n",
    "        data_array1 = four_four_two1[i]\n",
    "        size_x_data1.append(data_array1)\n",
    "        data_array2 = four_four_two2[i]\n",
    "        size_x_data2.append(data_array2)\n",
    "        data_array3 = four_four_two3[i]\n",
    "        size_x_data3.append(data_array3)\n",
    "        size_y_data.append(4)\n",
    "    #### four_five_threeについて\n",
    "    index = []\n",
    "    for i in range(len(four_five_three1)):\n",
    "        index.append(i)\n",
    "    data_count = 10\n",
    "    used_index = random.sample(index, data_count)\n",
    "    for i in used_index:\n",
    "        data_array1 = four_five_three1[i]\n",
    "        size_x_data1.append(data_array1)\n",
    "        data_array2 = four_five_three2[i]\n",
    "        size_x_data2.append(data_array2)\n",
    "        data_array3 = four_five_three3[i]\n",
    "        size_x_data3.append(data_array3)\n",
    "        size_y_data.append(4)\n",
    "    #### five_one_fiveについて\n",
    "    index = []\n",
    "    for i in range(len(five_one_five1)):\n",
    "        index.append(i)\n",
    "    data_count = 10\n",
    "    used_index = random.sample(index, data_count)\n",
    "    for i in used_index:\n",
    "        data_array1 = five_one_five1[i]\n",
    "        size_x_data1.append(data_array1)\n",
    "        data_array2 = five_one_five2[i]\n",
    "        size_x_data2.append(data_array2)\n",
    "        data_array3 = five_one_five3[i]\n",
    "        size_x_data3.append(data_array3)\n",
    "        size_y_data.append(5)\n",
    "    #### five_two_oneについて\n",
    "    index = []\n",
    "    for i in range(len(five_two_one1)):\n",
    "        index.append(i)\n",
    "    data_count = 10\n",
    "    used_index = random.sample(index, data_count)\n",
    "    for i in used_index:\n",
    "        data_array1 = five_two_one1[i]\n",
    "        size_x_data1.append(data_array1)\n",
    "        data_array2 = five_two_one2[i]\n",
    "        size_x_data2.append(data_array2)\n",
    "        data_array3 = five_two_one3[i]\n",
    "        size_x_data3.append(data_array3)\n",
    "        size_y_data.append(5)\n",
    "    #### five_three_twoについて\n",
    "    index = []\n",
    "    for i in range(len(five_three_two1)):\n",
    "        index.append(i)\n",
    "    data_count = 10\n",
    "    used_index = random.sample(index, data_count)\n",
    "    for i in used_index:\n",
    "        data_array1 = five_three_two1[i]\n",
    "        size_x_data1.append(data_array1)\n",
    "        data_array2 = five_three_two2[i]\n",
    "        size_x_data2.append(data_array2)\n",
    "        data_array3 = five_three_two3[i]\n",
    "        size_x_data3.append(data_array3)\n",
    "        size_y_data.append(5)\n",
    "    #### five_four_threeについて\n",
    "    index = []\n",
    "    for i in range(len(five_four_three1)):\n",
    "        index.append(i)\n",
    "    data_count = 10\n",
    "    used_index = random.sample(index, data_count)\n",
    "    for i in used_index:\n",
    "        data_array1 = five_four_three1[i]\n",
    "        size_x_data1.append(data_array1)\n",
    "        data_array2 = five_four_three2[i]\n",
    "        size_x_data2.append(data_array2)\n",
    "        data_array3 = five_four_three3[i]\n",
    "        size_x_data3.append(data_array3)\n",
    "        size_y_data.append(5)\n",
    "    #### five_five_fourについて\n",
    "    index = []\n",
    "    for i in range(len(five_five_four1)):\n",
    "        index.append(i)\n",
    "    data_count = 10\n",
    "    used_index = random.sample(index, data_count)\n",
    "    for i in used_index:\n",
    "        data_array1 = five_five_four1[i]\n",
    "        size_x_data1.append(data_array1)\n",
    "        data_array2 = five_five_four2[i]\n",
    "        size_x_data2.append(data_array2)\n",
    "        data_array3 = five_five_four3[i]\n",
    "        size_x_data3.append(data_array3)\n",
    "        size_y_data.append(5)\n",
    "\n",
    "    ### 各配列をnp.array型にして各要素を型変換\n",
    "    no_hole_data1 = np.array(no_hole_data1, dtype=float)\n",
    "    no_hole_data2 = np.array(no_hole_data2, dtype=float)\n",
    "    no_hole_data3 = np.array(no_hole_data3, dtype=float)\n",
    "    size_x_data1 = np.array(size_x_data1, dtype=float)\n",
    "    size_x_data2 = np.array(size_x_data2, dtype=float)\n",
    "    size_x_data3 = np.array(size_x_data3, dtype=float)\n",
    "    size_y_data = np.array(size_y_data, dtype=float)\n",
    "    \n",
    "    size_x_data_list1.append(size_x_data1)\n",
    "    size_x_data_list2.append(size_x_data2)\n",
    "    size_x_data_list3.append(size_x_data3)\n",
    "    y_size_data_array.append(size_y_data)\n",
    "\n",
    "#各振動を高速フーリエ変換→代表周波数のリスト作成→該当周波数のみの振幅を入力とする\n",
    "## 欠陥なしデータ\n",
    "F_no_hole1 = np.fft.fft(no_hole_data1)\n",
    "N = len(no_hole_data1)\n",
    "Amp_no_hole1 = np.abs(F_no_hole1/(N/2))\n",
    "maxid_no_hole1 = signal.argrelmax(Amp_no_hole1[1:int(N/2)], order=1)\n",
    "rep_index_no_hole1 = maxid_no_hole1[0]\n",
    "for i in range(len(rep_index_no_hole1)):\n",
    "    if (rep_index_no_hole1[i] in rep_freq_array1) == False:\n",
    "        rep_freq_array1.append(rep_index_no_hole1[i])\n",
    "F_no_hole2 = np.fft.fft(no_hole_data2)\n",
    "Amp_no_hole2 = np.abs(F_no_hole2/(N/2))\n",
    "maxid_no_hole2 = signal.argrelmax(Amp_no_hole2[1:int(N/2)], order=1)\n",
    "rep_index_no_hole2 = maxid_no_hole2[0]\n",
    "for i in range(len(rep_index_no_hole2)):\n",
    "    if (rep_index_no_hole2[i] in rep_freq_array2) == False:\n",
    "        rep_freq_array2.append(rep_index_no_hole2[i])\n",
    "F_no_hole3 = np.fft.fft(no_hole_data3)\n",
    "Amp_no_hole3 = np.abs(F_no_hole3/(N/2))\n",
    "maxid_no_hole3 = signal.argrelmax(Amp_no_hole3[1:int(N/2)], order=1)\n",
    "rep_index_no_hole3 = maxid_no_hole3[0]\n",
    "for i in range(len(rep_index_no_hole3)):\n",
    "    if (rep_index_no_hole3[i] in rep_freq_array3) == False:\n",
    "        rep_freq_array3.append(rep_index_no_hole3[i])\n",
    "# 欠陥ありデータ\n",
    "N = len(no_hole_data1)\n",
    "fft_size_x_data_array1 = []\n",
    "fft_size_x_data_array2 = []\n",
    "fft_size_x_data_array3 = []\n",
    "for i in range(len(size_x_data_list1)):\n",
    "    fft_size_x_data1 = []\n",
    "    fft_size_x_data2 = []\n",
    "    fft_size_x_data3 = []\n",
    "    size_x_data1 = size_x_data_list1[i]\n",
    "    size_x_data2 = size_x_data_list2[i]\n",
    "    size_x_data3 = size_x_data_list3[i]\n",
    "    ### 観測点1\n",
    "    for j in range(len(size_x_data1)):\n",
    "        F = np.fft.fft(size_x_data1[j])\n",
    "        Amp = np.abs(F/(N/2))\n",
    "        fft_size_x_data1.append(Amp)\n",
    "        maxid = signal.argrelmax(Amp[1:int(N/2)], order=1)\n",
    "        rep_index = maxid[0]\n",
    "        for k in range(len(rep_index)):\n",
    "            if (rep_index[k] in rep_freq_array1) == False:\n",
    "                rep_freq_array1.append(rep_index[k])\n",
    "    ### 観測点2\n",
    "    for j in range(len(size_x_data2)):\n",
    "        F = np.fft.fft(size_x_data2[j])\n",
    "        Amp = np.abs(F/(N/2))\n",
    "        fft_size_x_data2.append(Amp)\n",
    "        maxid = signal.argrelmax(Amp[1:int(N/2)], order=1)\n",
    "        rep_index = maxid[0]\n",
    "        for k in range(len(rep_index)):\n",
    "            if (rep_index[k] in rep_freq_array2) == False:\n",
    "                rep_freq_array2.append(rep_index[k])\n",
    "    ### 観測点3\n",
    "    for j in range(len(size_x_data3)):\n",
    "        F = np.fft.fft(size_x_data3[j])\n",
    "        Amp = np.abs(F/(N/2))\n",
    "        fft_size_x_data3.append(Amp)\n",
    "        maxid = signal.argrelmax(Amp[1:int(N/2)], order=1)\n",
    "        rep_index = maxid[0]\n",
    "        for k in range(len(rep_index)):\n",
    "            if (rep_index[k] in rep_freq_array3) == False:\n",
    "                rep_freq_array3.append(rep_index[k])\n",
    "    fft_size_x_data_array1.append(fft_size_x_data1)\n",
    "    fft_size_x_data_array2.append(fft_size_x_data2)\n",
    "    fft_size_x_data_array3.append(fft_size_x_data3)\n",
    "#入力値の更新(振動→代表周波数の振幅)\n",
    "x_size_data_array1 = []\n",
    "x_size_data_array2 = []\n",
    "x_size_data_array3 = []\n",
    "for i in range(len(size_x_data_list1)):\n",
    "    ## 観測点1\n",
    "    fft_size_x_data1 = fft_size_x_data_array1[i]\n",
    "    size_x_data1 = []\n",
    "    for j in range(len(fft_size_x_data1)):\n",
    "        rep_amp = []\n",
    "        for k in range(len(rep_freq_array1)):\n",
    "            rep_amp.append(fft_size_x_data1[j][k]-Amp_no_hole1[k])\n",
    "        size_x_data1.append(rep_amp)\n",
    "    x_size_data_array1.append(size_x_data1)\n",
    "    ## 観測点2\n",
    "    fft_size_x_data2 = fft_size_x_data_array2[i]\n",
    "    size_x_data2 = []\n",
    "    for j in range(len(fft_size_x_data2)):\n",
    "        rep_amp = []\n",
    "        for k in range(len(rep_freq_array2)):\n",
    "            rep_amp.append(fft_size_x_data2[j][k]-Amp_no_hole2[k])\n",
    "        size_x_data2.append(rep_amp)\n",
    "    x_size_data_array2.append(size_x_data2)\n",
    "    ## 観測点3\n",
    "    fft_size_x_data3 = fft_size_x_data_array3[i]\n",
    "    size_x_data3 = []\n",
    "    for j in range(len(fft_size_x_data3)):\n",
    "        rep_amp = []\n",
    "        for k in range(len(rep_freq_array3)):\n",
    "            rep_amp.append(fft_size_x_data3[j][k]-Amp_no_hole3[k])\n",
    "        size_x_data3.append(rep_amp)\n",
    "    x_size_data_array3.append(size_x_data3)\n",
    "\n",
    "    \n",
    "## データの加工\n",
    "###最大値で割る\n",
    "max_displacement1 = 0\n",
    "max_displacement2 = 0\n",
    "max_displacement3 = 0\n",
    "for i in range(len(x_size_data_array1)):\n",
    "    x_size_data1 = x_size_data_array1[i]\n",
    "    for j in range(len(x_size_data1)):\n",
    "        displacement1 = x_size_data1[j]\n",
    "        for k in range(len(displacement1)):\n",
    "            if max_displacement1 < displacement1[k]:\n",
    "                max_displacement1 = displacement1[k]\n",
    "for i in range(len(x_size_data_array2)):\n",
    "    x_size_data2 = x_size_data_array2[i]\n",
    "    for j in range(len(x_size_data2)):\n",
    "        displacement2 = x_size_data2[j]\n",
    "        for k in range(len(displacement2)):\n",
    "            if max_displacement2 < displacement2[k]:\n",
    "                max_displacement2 = displacement2[k]\n",
    "for i in range(len(x_size_data_array3)):\n",
    "    x_size_data3 = x_size_data_array3[i]\n",
    "    for j in range(len(x_size_data3)):\n",
    "        displacement3 = x_size_data3[j]\n",
    "        for k in range(len(displacement3)):\n",
    "            if max_displacement3 < displacement3[k]:\n",
    "                max_displacement3 = displacement3[k]\n",
    "for i in range(len(x_size_data_array1)):\n",
    "    for j in range(len(x_size_data_array1[i])):\n",
    "        for k in range(len(x_size_data_array1[i][j])):\n",
    "            x_size_data_array1[i][j][k] = x_size_data_array1[i][j][k]/max_displacement1\n",
    "for i in range(len(x_size_data_array2)):\n",
    "    for j in range(len(x_size_data_array2[i])):\n",
    "        for k in range(len(x_size_data_array2[i][j])):\n",
    "            x_size_data_array2[i][j][k] = x_size_data_array2[i][j][k]/max_displacement2\n",
    "for i in range(len(x_size_data_array3)):\n",
    "    for j in range(len(x_size_data_array3[i])):\n",
    "        for k in range(len(x_size_data_array3[i][j])):\n",
    "            x_size_data_array3[i][j][k] = x_size_data_array3[i][j][k]/max_displacement3\n",
    "\n",
    "### train用とtest用に分割(9:1)\n",
    "x_size_train_array1 = []\n",
    "x_size_train_array2 = []\n",
    "x_size_train_array3 = []\n",
    "x_size_test_array1 = []\n",
    "x_size_test_array2 = []\n",
    "x_size_test_array3 = []\n",
    "y_size_train_array = []\n",
    "y_size_test_array = []\n",
    "for i in range(1):\n",
    "    x_size_train1, x_size_test1, x_size_train2, x_size_test2, x_size_train3, x_size_test3, y_size_train, y_size_test = train_test_split(x_size_data_array1[i], x_size_data_array2[i], x_size_data_array3[i], y_size_data_array[i], test_size=0.10)\n",
    "    x_size_train_array1.append(np.array(x_size_train1))\n",
    "    x_size_train_array2.append(np.array(x_size_train2))\n",
    "    x_size_train_array3.append(np.array(x_size_train3))\n",
    "    x_size_test_array1.append(np.array(x_size_test1))\n",
    "    x_size_test_array2.append(np.array(x_size_test2))\n",
    "    x_size_test_array3.append(np.array(x_size_test3))\n",
    "    y_size_train_array.append(np.array(y_size_train))\n",
    "    y_size_test_array.append(np.array(y_size_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "50\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(x_size_train_array1[0][0]))\n",
    "print(len(x_size_train_array2[0][0]))\n",
    "print(len(x_size_train_array3[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 大きさ推定のモデル\n",
    "model_size_array = []\n",
    "\n",
    "for i in range(1):\n",
    "    # 入力を定義\n",
    "    input1 = Input(shape=(35,1))\n",
    "    input2 = Input(shape=(50,1))\n",
    "    input3 = Input(shape=(40,1))\n",
    "\n",
    "    # 入力1から結合前まで\n",
    "    x = Conv1D(32, 3, padding='same', activation='tanh')(input1)\n",
    "    x = MaxPooling1D(2, padding='same')(x)\n",
    "    x = Model(inputs=input1, outputs=x)\n",
    "    # 入力2から結合前まで\n",
    "    y = Conv1D(32, 3, padding='same', activation='tanh')(input2)\n",
    "    y = MaxPooling1D(2, padding='same')(y)\n",
    "    y = Model(inputs=input2, outputs=y)\n",
    "    # 入力3から結合前まで\n",
    "    z = Conv1D(32, 3, padding='same', activation='tanh')(input3)\n",
    "    z = MaxPooling1D(2, padding='same')(z)\n",
    "    z = Model(inputs=input3, outputs=z)\n",
    "\n",
    "    # 結合\n",
    "    combined = concatenate([x.output, y.output, z.output], axis = 1)\n",
    "\n",
    "    # 密結合\n",
    "    cnn = Flatten()(combined)\n",
    "    cnn = Dense(1, activation=\"linear\")(cnn)\n",
    "\n",
    "    # モデル定義とコンパイル\n",
    "    cnn_size_model = Model(inputs=[x.input, y.input, z.input], outputs=cnn)\n",
    "    cnn_size_model.compile(loss='mse', optimizer='adam', metrics=['acc'])\n",
    "    model_size_array.append(cnn_size_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/650\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 10.8877 - acc: 0.0000e+00 - val_loss: 11.7731 - val_acc: 0.0000e+00\n",
      "Epoch 2/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 10.6517 - acc: 0.0000e+00 - val_loss: 11.4887 - val_acc: 0.0000e+00\n",
      "Epoch 3/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 10.3747 - acc: 0.0000e+00 - val_loss: 11.1417 - val_acc: 0.0000e+00\n",
      "Epoch 4/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 10.0254 - acc: 0.0000e+00 - val_loss: 10.7241 - val_acc: 0.0000e+00\n",
      "Epoch 5/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 9.6157 - acc: 0.0000e+00 - val_loss: 10.2311 - val_acc: 0.0000e+00\n",
      "Epoch 6/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 9.1241 - acc: 0.0000e+00 - val_loss: 9.6620 - val_acc: 0.0000e+00\n",
      "Epoch 7/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 8.5728 - acc: 0.0000e+00 - val_loss: 9.0192 - val_acc: 0.0000e+00\n",
      "Epoch 8/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 7.9420 - acc: 0.0978 - val_loss: 8.3098 - val_acc: 0.2400\n",
      "Epoch 9/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 7.2371 - acc: 0.1956 - val_loss: 7.5453 - val_acc: 0.2400\n",
      "Epoch 10/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 6.5177 - acc: 0.1956 - val_loss: 6.7408 - val_acc: 0.2400\n",
      "Epoch 11/650\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 5.7370 - acc: 0.1956 - val_loss: 5.9210 - val_acc: 0.2400\n",
      "Epoch 12/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 4.9579 - acc: 0.1956 - val_loss: 5.1122 - val_acc: 0.2400\n",
      "Epoch 13/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 4.1863 - acc: 0.1956 - val_loss: 4.3478 - val_acc: 0.2400\n",
      "Epoch 14/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 3.4830 - acc: 0.1956 - val_loss: 3.6620 - val_acc: 0.2400\n",
      "Epoch 15/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.8858 - acc: 0.1956 - val_loss: 3.0904 - val_acc: 0.2400\n",
      "Epoch 16/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.4116 - acc: 0.1956 - val_loss: 2.6653 - val_acc: 0.2400\n",
      "Epoch 17/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.0760 - acc: 0.1956 - val_loss: 2.4034 - val_acc: 0.2400\n",
      "Epoch 18/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.8645 - acc: 0.1956 - val_loss: 2.2960 - val_acc: 0.2400\n",
      "Epoch 19/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.8641 - acc: 0.1956 - val_loss: 2.3052 - val_acc: 0.2400\n",
      "Epoch 20/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.9129 - acc: 0.1956 - val_loss: 2.3739 - val_acc: 0.2400\n",
      "Epoch 21/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.0162 - acc: 0.1956 - val_loss: 2.4424 - val_acc: 0.2400\n",
      "Epoch 22/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.1027 - acc: 0.1956 - val_loss: 2.4727 - val_acc: 0.2400\n",
      "Epoch 23/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.1239 - acc: 0.1956 - val_loss: 2.4504 - val_acc: 0.2400\n",
      "Epoch 24/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.0911 - acc: 0.1956 - val_loss: 2.3929 - val_acc: 0.2400\n",
      "Epoch 25/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.0185 - acc: 0.1956 - val_loss: 2.3282 - val_acc: 0.2400\n",
      "Epoch 26/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.9365 - acc: 0.1956 - val_loss: 2.2758 - val_acc: 0.2400\n",
      "Epoch 27/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.8661 - acc: 0.1956 - val_loss: 2.2456 - val_acc: 0.2400\n",
      "Epoch 28/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.8366 - acc: 0.1956 - val_loss: 2.2383 - val_acc: 0.2400\n",
      "Epoch 29/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.8109 - acc: 0.1956 - val_loss: 2.2479 - val_acc: 0.2400\n",
      "Epoch 30/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.8133 - acc: 0.1956 - val_loss: 2.2648 - val_acc: 0.2400\n",
      "Epoch 31/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.8190 - acc: 0.1956 - val_loss: 2.2793 - val_acc: 0.2400\n",
      "Epoch 32/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.8300 - acc: 0.1956 - val_loss: 2.2873 - val_acc: 0.2400\n",
      "Epoch 33/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.8323 - acc: 0.1956 - val_loss: 2.2839 - val_acc: 0.2400\n",
      "Epoch 34/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.8304 - acc: 0.1956 - val_loss: 2.2717 - val_acc: 0.2400\n",
      "Epoch 35/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.8214 - acc: 0.1956 - val_loss: 2.2549 - val_acc: 0.2400\n",
      "Epoch 36/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.8110 - acc: 0.1956 - val_loss: 2.2345 - val_acc: 0.2400\n",
      "Epoch 37/650\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.7994 - acc: 0.1956 - val_loss: 2.2142 - val_acc: 0.2400\n",
      "Epoch 38/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.7868 - acc: 0.1956 - val_loss: 2.1967 - val_acc: 0.2400\n",
      "Epoch 39/650\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.7795 - acc: 0.1956 - val_loss: 2.1817 - val_acc: 0.2400\n",
      "Epoch 40/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7771 - acc: 0.1956 - val_loss: 2.1696 - val_acc: 0.2400\n",
      "Epoch 41/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.7724 - acc: 0.1956 - val_loss: 2.1605 - val_acc: 0.2400\n",
      "Epoch 42/650\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.7693 - acc: 0.1956 - val_loss: 2.1530 - val_acc: 0.2400\n",
      "Epoch 43/650\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.7682 - acc: 0.1956 - val_loss: 2.1458 - val_acc: 0.2400\n",
      "Epoch 44/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7646 - acc: 0.1956 - val_loss: 2.1393 - val_acc: 0.2400\n",
      "Epoch 45/650\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.7607 - acc: 0.1956 - val_loss: 2.1327 - val_acc: 0.2400\n",
      "Epoch 46/650\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.7563 - acc: 0.1956 - val_loss: 2.1269 - val_acc: 0.2400\n",
      "Epoch 47/650\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.7522 - acc: 0.1956 - val_loss: 2.1217 - val_acc: 0.2400\n",
      "Epoch 48/650\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.7450 - acc: 0.1956 - val_loss: 2.1160 - val_acc: 0.2400\n",
      "Epoch 49/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7404 - acc: 0.1956 - val_loss: 2.1106 - val_acc: 0.2400\n",
      "Epoch 50/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.7363 - acc: 0.1956 - val_loss: 2.1056 - val_acc: 0.2400\n",
      "Epoch 51/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.7348 - acc: 0.1956 - val_loss: 2.1009 - val_acc: 0.2400\n",
      "Epoch 52/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.7288 - acc: 0.1956 - val_loss: 2.0940 - val_acc: 0.2400\n",
      "Epoch 53/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.7245 - acc: 0.1956 - val_loss: 2.0860 - val_acc: 0.2400\n",
      "Epoch 54/650\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.7202 - acc: 0.1956 - val_loss: 2.0775 - val_acc: 0.2400\n",
      "Epoch 55/650\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.7160 - acc: 0.1956 - val_loss: 2.0693 - val_acc: 0.2400\n",
      "Epoch 56/650\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.7130 - acc: 0.1956 - val_loss: 2.0591 - val_acc: 0.2400\n",
      "Epoch 57/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7064 - acc: 0.1956 - val_loss: 2.0502 - val_acc: 0.2400\n",
      "Epoch 58/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7020 - acc: 0.1956 - val_loss: 2.0414 - val_acc: 0.2400\n",
      "Epoch 59/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6972 - acc: 0.1956 - val_loss: 2.0331 - val_acc: 0.2400\n",
      "Epoch 60/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6927 - acc: 0.1956 - val_loss: 2.0247 - val_acc: 0.2400\n",
      "Epoch 61/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6879 - acc: 0.1956 - val_loss: 2.0154 - val_acc: 0.2400\n",
      "Epoch 62/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6835 - acc: 0.1956 - val_loss: 2.0061 - val_acc: 0.2400\n",
      "Epoch 63/650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 24ms/step - loss: 1.6783 - acc: 0.1956 - val_loss: 1.9977 - val_acc: 0.2400\n",
      "Epoch 64/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.6737 - acc: 0.1956 - val_loss: 1.9885 - val_acc: 0.2400\n",
      "Epoch 65/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.6690 - acc: 0.1956 - val_loss: 1.9803 - val_acc: 0.2400\n",
      "Epoch 66/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6635 - acc: 0.1956 - val_loss: 1.9713 - val_acc: 0.2400\n",
      "Epoch 67/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6587 - acc: 0.1956 - val_loss: 1.9620 - val_acc: 0.2400\n",
      "Epoch 68/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6536 - acc: 0.1956 - val_loss: 1.9531 - val_acc: 0.2400\n",
      "Epoch 69/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.6493 - acc: 0.1956 - val_loss: 1.9435 - val_acc: 0.2400\n",
      "Epoch 70/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.6437 - acc: 0.1956 - val_loss: 1.9349 - val_acc: 0.2400\n",
      "Epoch 71/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.6381 - acc: 0.1956 - val_loss: 1.9264 - val_acc: 0.2400\n",
      "Epoch 72/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.6331 - acc: 0.1956 - val_loss: 1.9173 - val_acc: 0.2400\n",
      "Epoch 73/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6284 - acc: 0.1956 - val_loss: 1.9071 - val_acc: 0.2400\n",
      "Epoch 74/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6226 - acc: 0.1956 - val_loss: 1.8976 - val_acc: 0.2400\n",
      "Epoch 75/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6172 - acc: 0.1956 - val_loss: 1.8880 - val_acc: 0.2400\n",
      "Epoch 76/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.6117 - acc: 0.1956 - val_loss: 1.8784 - val_acc: 0.2400\n",
      "Epoch 77/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.6069 - acc: 0.1956 - val_loss: 1.8681 - val_acc: 0.2400\n",
      "Epoch 78/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6012 - acc: 0.1956 - val_loss: 1.8584 - val_acc: 0.2400\n",
      "Epoch 79/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5955 - acc: 0.1956 - val_loss: 1.8483 - val_acc: 0.2400\n",
      "Epoch 80/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.5908 - acc: 0.1956 - val_loss: 1.8374 - val_acc: 0.2400\n",
      "Epoch 81/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5850 - acc: 0.1956 - val_loss: 1.8275 - val_acc: 0.2400\n",
      "Epoch 82/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.5791 - acc: 0.1956 - val_loss: 1.8163 - val_acc: 0.2400\n",
      "Epoch 83/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.5739 - acc: 0.1956 - val_loss: 1.8053 - val_acc: 0.2400\n",
      "Epoch 84/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5687 - acc: 0.1956 - val_loss: 1.7945 - val_acc: 0.2400\n",
      "Epoch 85/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.5625 - acc: 0.1956 - val_loss: 1.7843 - val_acc: 0.2400\n",
      "Epoch 86/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.5573 - acc: 0.1956 - val_loss: 1.7747 - val_acc: 0.2400\n",
      "Epoch 87/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.5516 - acc: 0.1956 - val_loss: 1.7641 - val_acc: 0.2400\n",
      "Epoch 88/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5456 - acc: 0.1956 - val_loss: 1.7535 - val_acc: 0.2400\n",
      "Epoch 89/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.5408 - acc: 0.1956 - val_loss: 1.7432 - val_acc: 0.2400\n",
      "Epoch 90/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.5348 - acc: 0.1956 - val_loss: 1.7319 - val_acc: 0.2400\n",
      "Epoch 91/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5292 - acc: 0.1956 - val_loss: 1.7206 - val_acc: 0.2400\n",
      "Epoch 92/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.5239 - acc: 0.1956 - val_loss: 1.7098 - val_acc: 0.2400\n",
      "Epoch 93/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.5181 - acc: 0.1956 - val_loss: 1.6992 - val_acc: 0.2400\n",
      "Epoch 94/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.5134 - acc: 0.1956 - val_loss: 1.6887 - val_acc: 0.2400\n",
      "Epoch 95/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5072 - acc: 0.1956 - val_loss: 1.6777 - val_acc: 0.2400\n",
      "Epoch 96/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.5029 - acc: 0.1956 - val_loss: 1.6663 - val_acc: 0.2400\n",
      "Epoch 97/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.4973 - acc: 0.1956 - val_loss: 1.6565 - val_acc: 0.2400\n",
      "Epoch 98/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.4912 - acc: 0.1956 - val_loss: 1.6460 - val_acc: 0.2400\n",
      "Epoch 99/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.4861 - acc: 0.1956 - val_loss: 1.6353 - val_acc: 0.2400\n",
      "Epoch 100/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.4813 - acc: 0.1956 - val_loss: 1.6245 - val_acc: 0.2400\n",
      "Epoch 101/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.4757 - acc: 0.1956 - val_loss: 1.6144 - val_acc: 0.2400\n",
      "Epoch 102/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.4706 - acc: 0.1956 - val_loss: 1.6050 - val_acc: 0.2400\n",
      "Epoch 103/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.4654 - acc: 0.1956 - val_loss: 1.5951 - val_acc: 0.2400\n",
      "Epoch 104/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.4604 - acc: 0.1956 - val_loss: 1.5849 - val_acc: 0.2400\n",
      "Epoch 105/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.4553 - acc: 0.1956 - val_loss: 1.5751 - val_acc: 0.2400\n",
      "Epoch 106/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.4508 - acc: 0.1956 - val_loss: 1.5658 - val_acc: 0.2400\n",
      "Epoch 107/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.4457 - acc: 0.1956 - val_loss: 1.5555 - val_acc: 0.2400\n",
      "Epoch 108/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.4413 - acc: 0.1956 - val_loss: 1.5457 - val_acc: 0.2400\n",
      "Epoch 109/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.4364 - acc: 0.1956 - val_loss: 1.5354 - val_acc: 0.2400\n",
      "Epoch 110/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.4313 - acc: 0.1956 - val_loss: 1.5245 - val_acc: 0.2400\n",
      "Epoch 111/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.4274 - acc: 0.1956 - val_loss: 1.5144 - val_acc: 0.2400\n",
      "Epoch 112/650\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.4223 - acc: 0.1956 - val_loss: 1.5037 - val_acc: 0.2400\n",
      "Epoch 113/650\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.4192 - acc: 0.1956 - val_loss: 1.4935 - val_acc: 0.2400\n",
      "Epoch 114/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.4151 - acc: 0.1956 - val_loss: 1.4846 - val_acc: 0.2400\n",
      "Epoch 115/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.4107 - acc: 0.1956 - val_loss: 1.4761 - val_acc: 0.2400\n",
      "Epoch 116/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.4055 - acc: 0.1956 - val_loss: 1.4675 - val_acc: 0.2400\n",
      "Epoch 117/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.4013 - acc: 0.1956 - val_loss: 1.4590 - val_acc: 0.2400\n",
      "Epoch 118/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.3974 - acc: 0.1956 - val_loss: 1.4510 - val_acc: 0.2400\n",
      "Epoch 119/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.3934 - acc: 0.1956 - val_loss: 1.4439 - val_acc: 0.2400\n",
      "Epoch 120/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.3890 - acc: 0.1956 - val_loss: 1.4369 - val_acc: 0.2400\n",
      "Epoch 121/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.3855 - acc: 0.1956 - val_loss: 1.4298 - val_acc: 0.2400\n",
      "Epoch 122/650\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.3822 - acc: 0.1956 - val_loss: 1.4219 - val_acc: 0.2400\n",
      "Epoch 123/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3786 - acc: 0.1956 - val_loss: 1.4143 - val_acc: 0.2400\n",
      "Epoch 124/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.3753 - acc: 0.1956 - val_loss: 1.4068 - val_acc: 0.2400\n",
      "Epoch 125/650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 20ms/step - loss: 1.3719 - acc: 0.1956 - val_loss: 1.3987 - val_acc: 0.2400\n",
      "Epoch 126/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.3683 - acc: 0.1956 - val_loss: 1.3896 - val_acc: 0.2400\n",
      "Epoch 127/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.3651 - acc: 0.1956 - val_loss: 1.3798 - val_acc: 0.2400\n",
      "Epoch 128/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.3609 - acc: 0.1956 - val_loss: 1.3716 - val_acc: 0.2400\n",
      "Epoch 129/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.3577 - acc: 0.1956 - val_loss: 1.3637 - val_acc: 0.2400\n",
      "Epoch 130/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.3587 - acc: 0.1956 - val_loss: 1.3558 - val_acc: 0.2400\n",
      "Epoch 131/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.3526 - acc: 0.1956 - val_loss: 1.3495 - val_acc: 0.2400\n",
      "Epoch 132/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.3499 - acc: 0.1956 - val_loss: 1.3442 - val_acc: 0.2400\n",
      "Epoch 133/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.3470 - acc: 0.1956 - val_loss: 1.3392 - val_acc: 0.2400\n",
      "Epoch 134/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.3435 - acc: 0.1956 - val_loss: 1.3332 - val_acc: 0.2400\n",
      "Epoch 135/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.3405 - acc: 0.1956 - val_loss: 1.3269 - val_acc: 0.2400\n",
      "Epoch 136/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.3391 - acc: 0.1956 - val_loss: 1.3209 - val_acc: 0.2400\n",
      "Epoch 137/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.3351 - acc: 0.1956 - val_loss: 1.3133 - val_acc: 0.2400\n",
      "Epoch 138/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.3323 - acc: 0.1956 - val_loss: 1.3063 - val_acc: 0.2400\n",
      "Epoch 139/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.3302 - acc: 0.1956 - val_loss: 1.2998 - val_acc: 0.2400\n",
      "Epoch 140/650\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.3278 - acc: 0.1956 - val_loss: 1.2941 - val_acc: 0.2400\n",
      "Epoch 141/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3257 - acc: 0.1956 - val_loss: 1.2886 - val_acc: 0.2400\n",
      "Epoch 142/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.3233 - acc: 0.1956 - val_loss: 1.2837 - val_acc: 0.2400\n",
      "Epoch 143/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.3209 - acc: 0.1956 - val_loss: 1.2794 - val_acc: 0.2400\n",
      "Epoch 144/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.3183 - acc: 0.1956 - val_loss: 1.2751 - val_acc: 0.2400\n",
      "Epoch 145/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3162 - acc: 0.1956 - val_loss: 1.2703 - val_acc: 0.2400\n",
      "Epoch 146/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3166 - acc: 0.1956 - val_loss: 1.2667 - val_acc: 0.2400\n",
      "Epoch 147/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.3123 - acc: 0.1956 - val_loss: 1.2614 - val_acc: 0.2400\n",
      "Epoch 148/650\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.3098 - acc: 0.1956 - val_loss: 1.2556 - val_acc: 0.2400\n",
      "Epoch 149/650\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.3080 - acc: 0.1956 - val_loss: 1.2501 - val_acc: 0.2400\n",
      "Epoch 150/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.3063 - acc: 0.1956 - val_loss: 1.2453 - val_acc: 0.2400\n",
      "Epoch 151/650\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.3044 - acc: 0.1956 - val_loss: 1.2409 - val_acc: 0.2400\n",
      "Epoch 152/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.3028 - acc: 0.1956 - val_loss: 1.2376 - val_acc: 0.2400\n",
      "Epoch 153/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3004 - acc: 0.1956 - val_loss: 1.2341 - val_acc: 0.2400\n",
      "Epoch 154/650\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2984 - acc: 0.1956 - val_loss: 1.2303 - val_acc: 0.2400\n",
      "Epoch 155/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.2966 - acc: 0.1956 - val_loss: 1.2266 - val_acc: 0.2400\n",
      "Epoch 156/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2946 - acc: 0.1956 - val_loss: 1.2233 - val_acc: 0.2400\n",
      "Epoch 157/650\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2943 - acc: 0.1956 - val_loss: 1.2207 - val_acc: 0.2400\n",
      "Epoch 158/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2916 - acc: 0.1956 - val_loss: 1.2161 - val_acc: 0.2400\n",
      "Epoch 159/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.2894 - acc: 0.1956 - val_loss: 1.2121 - val_acc: 0.2400\n",
      "Epoch 160/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.2881 - acc: 0.1956 - val_loss: 1.2077 - val_acc: 0.2400\n",
      "Epoch 161/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2857 - acc: 0.1956 - val_loss: 1.2042 - val_acc: 0.2400\n",
      "Epoch 162/650\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.2846 - acc: 0.1956 - val_loss: 1.2002 - val_acc: 0.2400\n",
      "Epoch 163/650\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.2845 - acc: 0.1956 - val_loss: 1.1975 - val_acc: 0.2400\n",
      "Epoch 164/650\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.2813 - acc: 0.1956 - val_loss: 1.1933 - val_acc: 0.2400\n",
      "Epoch 165/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.2790 - acc: 0.1956 - val_loss: 1.1898 - val_acc: 0.2400\n",
      "Epoch 166/650\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.2782 - acc: 0.1956 - val_loss: 1.1860 - val_acc: 0.2400\n",
      "Epoch 167/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2758 - acc: 0.1956 - val_loss: 1.1834 - val_acc: 0.2400\n",
      "Epoch 168/650\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2742 - acc: 0.1956 - val_loss: 1.1805 - val_acc: 0.2400\n",
      "Epoch 169/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2729 - acc: 0.1956 - val_loss: 1.1782 - val_acc: 0.2400\n",
      "Epoch 170/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.2712 - acc: 0.1956 - val_loss: 1.1750 - val_acc: 0.2400\n",
      "Epoch 171/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2696 - acc: 0.1956 - val_loss: 1.1720 - val_acc: 0.2400\n",
      "Epoch 172/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.2679 - acc: 0.1956 - val_loss: 1.1689 - val_acc: 0.2400\n",
      "Epoch 173/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.2663 - acc: 0.1956 - val_loss: 1.1655 - val_acc: 0.2400\n",
      "Epoch 174/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.2648 - acc: 0.1956 - val_loss: 1.1622 - val_acc: 0.2400\n",
      "Epoch 175/650\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.2632 - acc: 0.1956 - val_loss: 1.1593 - val_acc: 0.2400\n",
      "Epoch 176/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.2617 - acc: 0.1956 - val_loss: 1.1563 - val_acc: 0.2400\n",
      "Epoch 177/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.2603 - acc: 0.1956 - val_loss: 1.1535 - val_acc: 0.2400\n",
      "Epoch 178/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.2589 - acc: 0.1956 - val_loss: 1.1511 - val_acc: 0.2400\n",
      "Epoch 179/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2572 - acc: 0.1956 - val_loss: 1.1494 - val_acc: 0.2400\n",
      "Epoch 180/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2560 - acc: 0.1956 - val_loss: 1.1478 - val_acc: 0.2400\n",
      "Epoch 181/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.2539 - acc: 0.1956 - val_loss: 1.1453 - val_acc: 0.2400\n",
      "Epoch 182/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2524 - acc: 0.1956 - val_loss: 1.1428 - val_acc: 0.2400\n",
      "Epoch 183/650\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.2509 - acc: 0.1956 - val_loss: 1.1404 - val_acc: 0.2400\n",
      "Epoch 184/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.2495 - acc: 0.1956 - val_loss: 1.1382 - val_acc: 0.2400\n",
      "Epoch 185/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.2479 - acc: 0.1956 - val_loss: 1.1361 - val_acc: 0.2400\n",
      "Epoch 186/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2462 - acc: 0.1956 - val_loss: 1.1346 - val_acc: 0.2400\n",
      "Epoch 187/650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 28ms/step - loss: 1.2449 - acc: 0.1956 - val_loss: 1.1328 - val_acc: 0.2400\n",
      "Epoch 188/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.2434 - acc: 0.1956 - val_loss: 1.1304 - val_acc: 0.2400\n",
      "Epoch 189/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.2421 - acc: 0.1956 - val_loss: 1.1275 - val_acc: 0.2400\n",
      "Epoch 190/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.2407 - acc: 0.1956 - val_loss: 1.1255 - val_acc: 0.2400\n",
      "Epoch 191/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2384 - acc: 0.1956 - val_loss: 1.1225 - val_acc: 0.2400\n",
      "Epoch 192/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.2369 - acc: 0.1956 - val_loss: 1.1197 - val_acc: 0.2400\n",
      "Epoch 193/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2353 - acc: 0.1956 - val_loss: 1.1173 - val_acc: 0.2400\n",
      "Epoch 194/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.2339 - acc: 0.1956 - val_loss: 1.1148 - val_acc: 0.2400\n",
      "Epoch 195/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.2324 - acc: 0.1956 - val_loss: 1.1126 - val_acc: 0.2400\n",
      "Epoch 196/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.2315 - acc: 0.1956 - val_loss: 1.1104 - val_acc: 0.2400\n",
      "Epoch 197/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2294 - acc: 0.1956 - val_loss: 1.1088 - val_acc: 0.2400\n",
      "Epoch 198/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.2272 - acc: 0.1956 - val_loss: 1.1078 - val_acc: 0.2400\n",
      "Epoch 199/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.2257 - acc: 0.1956 - val_loss: 1.1075 - val_acc: 0.2400\n",
      "Epoch 200/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2246 - acc: 0.1956 - val_loss: 1.1067 - val_acc: 0.2400\n",
      "Epoch 201/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.2241 - acc: 0.1956 - val_loss: 1.1044 - val_acc: 0.2400\n",
      "Epoch 202/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.2222 - acc: 0.1956 - val_loss: 1.1020 - val_acc: 0.2400\n",
      "Epoch 203/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2203 - acc: 0.1956 - val_loss: 1.0994 - val_acc: 0.2400\n",
      "Epoch 204/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.2183 - acc: 0.1956 - val_loss: 1.0972 - val_acc: 0.2400\n",
      "Epoch 205/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.2166 - acc: 0.1956 - val_loss: 1.0946 - val_acc: 0.2400\n",
      "Epoch 206/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.2148 - acc: 0.1956 - val_loss: 1.0915 - val_acc: 0.2400\n",
      "Epoch 207/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.2128 - acc: 0.1956 - val_loss: 1.0884 - val_acc: 0.2400\n",
      "Epoch 208/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.2118 - acc: 0.1956 - val_loss: 1.0851 - val_acc: 0.2400\n",
      "Epoch 209/650\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.2099 - acc: 0.1956 - val_loss: 1.0827 - val_acc: 0.2400\n",
      "Epoch 210/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.2087 - acc: 0.1956 - val_loss: 1.0806 - val_acc: 0.2400\n",
      "Epoch 211/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.2070 - acc: 0.1956 - val_loss: 1.0788 - val_acc: 0.2400\n",
      "Epoch 212/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.2051 - acc: 0.1956 - val_loss: 1.0774 - val_acc: 0.2400\n",
      "Epoch 213/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.2057 - acc: 0.1956 - val_loss: 1.0770 - val_acc: 0.2400\n",
      "Epoch 214/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.2013 - acc: 0.1956 - val_loss: 1.0749 - val_acc: 0.2400\n",
      "Epoch 215/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.1995 - acc: 0.1956 - val_loss: 1.0728 - val_acc: 0.2400\n",
      "Epoch 216/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1979 - acc: 0.1956 - val_loss: 1.0712 - val_acc: 0.2400\n",
      "Epoch 217/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1962 - acc: 0.1956 - val_loss: 1.0690 - val_acc: 0.2400\n",
      "Epoch 218/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1944 - acc: 0.1956 - val_loss: 1.0669 - val_acc: 0.2400\n",
      "Epoch 219/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1926 - acc: 0.1956 - val_loss: 1.0652 - val_acc: 0.2400\n",
      "Epoch 220/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1909 - acc: 0.1956 - val_loss: 1.0632 - val_acc: 0.2400\n",
      "Epoch 221/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1891 - acc: 0.1956 - val_loss: 1.0614 - val_acc: 0.2400\n",
      "Epoch 222/650\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.1880 - acc: 0.1956 - val_loss: 1.0594 - val_acc: 0.2400\n",
      "Epoch 223/650\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1868 - acc: 0.1956 - val_loss: 1.0582 - val_acc: 0.2400\n",
      "Epoch 224/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1839 - acc: 0.1956 - val_loss: 1.0558 - val_acc: 0.2400\n",
      "Epoch 225/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1842 - acc: 0.1956 - val_loss: 1.0533 - val_acc: 0.2400\n",
      "Epoch 226/650\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1804 - acc: 0.1956 - val_loss: 1.0519 - val_acc: 0.2400\n",
      "Epoch 227/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1786 - acc: 0.1956 - val_loss: 1.0501 - val_acc: 0.2400\n",
      "Epoch 228/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.1769 - acc: 0.1956 - val_loss: 1.0480 - val_acc: 0.2400\n",
      "Epoch 229/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1750 - acc: 0.1956 - val_loss: 1.0457 - val_acc: 0.2400\n",
      "Epoch 230/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.1734 - acc: 0.1956 - val_loss: 1.0434 - val_acc: 0.2400\n",
      "Epoch 231/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1716 - acc: 0.1956 - val_loss: 1.0406 - val_acc: 0.2400\n",
      "Epoch 232/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.1695 - acc: 0.1956 - val_loss: 1.0384 - val_acc: 0.2400\n",
      "Epoch 233/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1687 - acc: 0.1956 - val_loss: 1.0367 - val_acc: 0.2400\n",
      "Epoch 234/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.1659 - acc: 0.1956 - val_loss: 1.0343 - val_acc: 0.2400\n",
      "Epoch 235/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1648 - acc: 0.1956 - val_loss: 1.0320 - val_acc: 0.2400\n",
      "Epoch 236/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.1626 - acc: 0.1956 - val_loss: 1.0301 - val_acc: 0.2400\n",
      "Epoch 237/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1606 - acc: 0.1956 - val_loss: 1.0281 - val_acc: 0.2400\n",
      "Epoch 238/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.1586 - acc: 0.1956 - val_loss: 1.0264 - val_acc: 0.2400\n",
      "Epoch 239/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1566 - acc: 0.1956 - val_loss: 1.0248 - val_acc: 0.2400\n",
      "Epoch 240/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1549 - acc: 0.1956 - val_loss: 1.0229 - val_acc: 0.2400\n",
      "Epoch 241/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1531 - acc: 0.1956 - val_loss: 1.0213 - val_acc: 0.2400\n",
      "Epoch 242/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1523 - acc: 0.1956 - val_loss: 1.0196 - val_acc: 0.2400\n",
      "Epoch 243/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.1501 - acc: 0.1956 - val_loss: 1.0165 - val_acc: 0.2400\n",
      "Epoch 244/650\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.1475 - acc: 0.1956 - val_loss: 1.0142 - val_acc: 0.2400\n",
      "Epoch 245/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1459 - acc: 0.1956 - val_loss: 1.0113 - val_acc: 0.2400\n",
      "Epoch 246/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.1442 - acc: 0.1956 - val_loss: 1.0090 - val_acc: 0.2400\n",
      "Epoch 247/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1420 - acc: 0.1956 - val_loss: 1.0071 - val_acc: 0.2400\n",
      "Epoch 248/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1403 - acc: 0.1956 - val_loss: 1.0054 - val_acc: 0.2400\n",
      "Epoch 249/650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 19ms/step - loss: 1.1379 - acc: 0.1956 - val_loss: 1.0033 - val_acc: 0.2400\n",
      "Epoch 250/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.1371 - acc: 0.1956 - val_loss: 1.0012 - val_acc: 0.2400\n",
      "Epoch 251/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.1342 - acc: 0.1956 - val_loss: 0.9998 - val_acc: 0.2400\n",
      "Epoch 252/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1323 - acc: 0.1956 - val_loss: 0.9981 - val_acc: 0.2400\n",
      "Epoch 253/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1304 - acc: 0.1956 - val_loss: 0.9962 - val_acc: 0.2400\n",
      "Epoch 254/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1285 - acc: 0.1956 - val_loss: 0.9943 - val_acc: 0.2400\n",
      "Epoch 255/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.1263 - acc: 0.1956 - val_loss: 0.9926 - val_acc: 0.2400\n",
      "Epoch 256/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.1245 - acc: 0.1956 - val_loss: 0.9907 - val_acc: 0.2400\n",
      "Epoch 257/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1226 - acc: 0.1956 - val_loss: 0.9885 - val_acc: 0.2400\n",
      "Epoch 258/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.1206 - acc: 0.1956 - val_loss: 0.9863 - val_acc: 0.2400\n",
      "Epoch 259/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1185 - acc: 0.1956 - val_loss: 0.9839 - val_acc: 0.2400\n",
      "Epoch 260/650\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1168 - acc: 0.1956 - val_loss: 0.9815 - val_acc: 0.2400\n",
      "Epoch 261/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1151 - acc: 0.1956 - val_loss: 0.9798 - val_acc: 0.2400\n",
      "Epoch 262/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.1128 - acc: 0.1956 - val_loss: 0.9778 - val_acc: 0.2400\n",
      "Epoch 263/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.1111 - acc: 0.1956 - val_loss: 0.9758 - val_acc: 0.2400\n",
      "Epoch 264/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.1092 - acc: 0.1956 - val_loss: 0.9742 - val_acc: 0.2400\n",
      "Epoch 265/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.1075 - acc: 0.1956 - val_loss: 0.9728 - val_acc: 0.2400\n",
      "Epoch 266/650\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.1051 - acc: 0.1956 - val_loss: 0.9706 - val_acc: 0.2400\n",
      "Epoch 267/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.1027 - acc: 0.1956 - val_loss: 0.9688 - val_acc: 0.2400\n",
      "Epoch 268/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.1012 - acc: 0.1956 - val_loss: 0.9667 - val_acc: 0.2400\n",
      "Epoch 269/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0984 - acc: 0.1956 - val_loss: 0.9651 - val_acc: 0.2400\n",
      "Epoch 270/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0966 - acc: 0.1956 - val_loss: 0.9636 - val_acc: 0.2400\n",
      "Epoch 271/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.0971 - acc: 0.1956 - val_loss: 0.9623 - val_acc: 0.2400\n",
      "Epoch 272/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.0928 - acc: 0.1956 - val_loss: 0.9593 - val_acc: 0.2400\n",
      "Epoch 273/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0911 - acc: 0.1956 - val_loss: 0.9568 - val_acc: 0.2400\n",
      "Epoch 274/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.0885 - acc: 0.1956 - val_loss: 0.9547 - val_acc: 0.2400\n",
      "Epoch 275/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.0865 - acc: 0.1956 - val_loss: 0.9529 - val_acc: 0.2400\n",
      "Epoch 276/650\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.0844 - acc: 0.1956 - val_loss: 0.9511 - val_acc: 0.2400\n",
      "Epoch 277/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0828 - acc: 0.1956 - val_loss: 0.9494 - val_acc: 0.2400\n",
      "Epoch 278/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0809 - acc: 0.1956 - val_loss: 0.9473 - val_acc: 0.2400\n",
      "Epoch 279/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.0781 - acc: 0.1956 - val_loss: 0.9457 - val_acc: 0.2400\n",
      "Epoch 280/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.0763 - acc: 0.1956 - val_loss: 0.9442 - val_acc: 0.2400\n",
      "Epoch 281/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.0739 - acc: 0.1956 - val_loss: 0.9423 - val_acc: 0.2400\n",
      "Epoch 282/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.0726 - acc: 0.1956 - val_loss: 0.9404 - val_acc: 0.2400\n",
      "Epoch 283/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0699 - acc: 0.1956 - val_loss: 0.9381 - val_acc: 0.2400\n",
      "Epoch 284/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.0677 - acc: 0.1956 - val_loss: 0.9359 - val_acc: 0.2400\n",
      "Epoch 285/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.0656 - acc: 0.1956 - val_loss: 0.9337 - val_acc: 0.2400\n",
      "Epoch 286/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0640 - acc: 0.1956 - val_loss: 0.9317 - val_acc: 0.2400\n",
      "Epoch 287/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.0615 - acc: 0.1956 - val_loss: 0.9295 - val_acc: 0.2400\n",
      "Epoch 288/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0595 - acc: 0.1956 - val_loss: 0.9275 - val_acc: 0.2400\n",
      "Epoch 289/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.0577 - acc: 0.1956 - val_loss: 0.9257 - val_acc: 0.2400\n",
      "Epoch 290/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.0555 - acc: 0.1956 - val_loss: 0.9239 - val_acc: 0.2400\n",
      "Epoch 291/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.0554 - acc: 0.1956 - val_loss: 0.9224 - val_acc: 0.2400\n",
      "Epoch 292/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.0510 - acc: 0.1956 - val_loss: 0.9203 - val_acc: 0.2400\n",
      "Epoch 293/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0492 - acc: 0.1956 - val_loss: 0.9180 - val_acc: 0.2400\n",
      "Epoch 294/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.0471 - acc: 0.1956 - val_loss: 0.9162 - val_acc: 0.2400\n",
      "Epoch 295/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.0447 - acc: 0.1956 - val_loss: 0.9140 - val_acc: 0.2400\n",
      "Epoch 296/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.0427 - acc: 0.1956 - val_loss: 0.9119 - val_acc: 0.2400\n",
      "Epoch 297/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.0403 - acc: 0.1956 - val_loss: 0.9098 - val_acc: 0.2400\n",
      "Epoch 298/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.0396 - acc: 0.1956 - val_loss: 0.9077 - val_acc: 0.2400\n",
      "Epoch 299/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.0363 - acc: 0.1956 - val_loss: 0.9059 - val_acc: 0.2400\n",
      "Epoch 300/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.0346 - acc: 0.1956 - val_loss: 0.9045 - val_acc: 0.2400\n",
      "Epoch 301/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0327 - acc: 0.1956 - val_loss: 0.9028 - val_acc: 0.2400\n",
      "Epoch 302/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.0298 - acc: 0.1956 - val_loss: 0.9016 - val_acc: 0.2400\n",
      "Epoch 303/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.0289 - acc: 0.1956 - val_loss: 0.9003 - val_acc: 0.2400\n",
      "Epoch 304/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.0259 - acc: 0.1956 - val_loss: 0.8979 - val_acc: 0.2400\n",
      "Epoch 305/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.0235 - acc: 0.1956 - val_loss: 0.8956 - val_acc: 0.2400\n",
      "Epoch 306/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.0213 - acc: 0.1956 - val_loss: 0.8932 - val_acc: 0.2400\n",
      "Epoch 307/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.0191 - acc: 0.1956 - val_loss: 0.8908 - val_acc: 0.2400\n",
      "Epoch 308/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.0173 - acc: 0.1956 - val_loss: 0.8887 - val_acc: 0.2400\n",
      "Epoch 309/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.0185 - acc: 0.1956 - val_loss: 0.8867 - val_acc: 0.2400\n",
      "Epoch 310/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.0139 - acc: 0.1956 - val_loss: 0.8844 - val_acc: 0.2400\n",
      "Epoch 311/650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 18ms/step - loss: 1.0111 - acc: 0.1956 - val_loss: 0.8826 - val_acc: 0.2400\n",
      "Epoch 312/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.0086 - acc: 0.1956 - val_loss: 0.8810 - val_acc: 0.2400\n",
      "Epoch 313/650\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.0083 - acc: 0.1956 - val_loss: 0.8801 - val_acc: 0.2400\n",
      "Epoch 314/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.0050 - acc: 0.1956 - val_loss: 0.8779 - val_acc: 0.2400\n",
      "Epoch 315/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.0029 - acc: 0.1956 - val_loss: 0.8756 - val_acc: 0.2400\n",
      "Epoch 316/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.0006 - acc: 0.1956 - val_loss: 0.8730 - val_acc: 0.2400\n",
      "Epoch 317/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.0002 - acc: 0.1956 - val_loss: 0.8703 - val_acc: 0.2400\n",
      "Epoch 318/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.9962 - acc: 0.1956 - val_loss: 0.8683 - val_acc: 0.2400\n",
      "Epoch 319/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.9942 - acc: 0.1956 - val_loss: 0.8663 - val_acc: 0.2400\n",
      "Epoch 320/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.9922 - acc: 0.1956 - val_loss: 0.8643 - val_acc: 0.2400\n",
      "Epoch 321/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.9912 - acc: 0.1956 - val_loss: 0.8624 - val_acc: 0.2400\n",
      "Epoch 322/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.9879 - acc: 0.1956 - val_loss: 0.8602 - val_acc: 0.2400\n",
      "Epoch 323/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.9866 - acc: 0.1956 - val_loss: 0.8585 - val_acc: 0.2400\n",
      "Epoch 324/650\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.9837 - acc: 0.1956 - val_loss: 0.8564 - val_acc: 0.2400\n",
      "Epoch 325/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.9816 - acc: 0.1956 - val_loss: 0.8544 - val_acc: 0.2400\n",
      "Epoch 326/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.9801 - acc: 0.1956 - val_loss: 0.8525 - val_acc: 0.2400\n",
      "Epoch 327/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.9776 - acc: 0.1956 - val_loss: 0.8505 - val_acc: 0.2400\n",
      "Epoch 328/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.9759 - acc: 0.1956 - val_loss: 0.8487 - val_acc: 0.2400\n",
      "Epoch 329/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.9730 - acc: 0.1956 - val_loss: 0.8469 - val_acc: 0.2400\n",
      "Epoch 330/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.9713 - acc: 0.1956 - val_loss: 0.8454 - val_acc: 0.2400\n",
      "Epoch 331/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.9691 - acc: 0.1956 - val_loss: 0.8438 - val_acc: 0.2400\n",
      "Epoch 332/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.9672 - acc: 0.1956 - val_loss: 0.8418 - val_acc: 0.2400\n",
      "Epoch 333/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.9669 - acc: 0.1956 - val_loss: 0.8401 - val_acc: 0.2400\n",
      "Epoch 334/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.9628 - acc: 0.1956 - val_loss: 0.8374 - val_acc: 0.2400\n",
      "Epoch 335/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.9610 - acc: 0.1956 - val_loss: 0.8350 - val_acc: 0.2400\n",
      "Epoch 336/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.9596 - acc: 0.1956 - val_loss: 0.8332 - val_acc: 0.2400\n",
      "Epoch 337/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.9569 - acc: 0.1956 - val_loss: 0.8312 - val_acc: 0.2400\n",
      "Epoch 338/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.9551 - acc: 0.1956 - val_loss: 0.8293 - val_acc: 0.2400\n",
      "Epoch 339/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.9530 - acc: 0.1956 - val_loss: 0.8275 - val_acc: 0.2400\n",
      "Epoch 340/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.9502 - acc: 0.1956 - val_loss: 0.8256 - val_acc: 0.2400\n",
      "Epoch 341/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.9483 - acc: 0.1956 - val_loss: 0.8236 - val_acc: 0.2400\n",
      "Epoch 342/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.9472 - acc: 0.1956 - val_loss: 0.8220 - val_acc: 0.2400\n",
      "Epoch 343/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.9445 - acc: 0.1956 - val_loss: 0.8197 - val_acc: 0.2400\n",
      "Epoch 344/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.9429 - acc: 0.1956 - val_loss: 0.8175 - val_acc: 0.2400\n",
      "Epoch 345/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.9400 - acc: 0.1956 - val_loss: 0.8155 - val_acc: 0.2400\n",
      "Epoch 346/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.9385 - acc: 0.1956 - val_loss: 0.8135 - val_acc: 0.2400\n",
      "Epoch 347/650\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.9367 - acc: 0.1956 - val_loss: 0.8115 - val_acc: 0.2400\n",
      "Epoch 348/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.9341 - acc: 0.1956 - val_loss: 0.8097 - val_acc: 0.2400\n",
      "Epoch 349/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.9323 - acc: 0.1956 - val_loss: 0.8078 - val_acc: 0.2400\n",
      "Epoch 350/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.9298 - acc: 0.1956 - val_loss: 0.8061 - val_acc: 0.2400\n",
      "Epoch 351/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.9277 - acc: 0.1956 - val_loss: 0.8042 - val_acc: 0.2400\n",
      "Epoch 352/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.9258 - acc: 0.1956 - val_loss: 0.8025 - val_acc: 0.2400\n",
      "Epoch 353/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.9255 - acc: 0.1956 - val_loss: 0.8006 - val_acc: 0.2400\n",
      "Epoch 354/650\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.9223 - acc: 0.1956 - val_loss: 0.7981 - val_acc: 0.2400\n",
      "Epoch 355/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.9216 - acc: 0.1956 - val_loss: 0.7959 - val_acc: 0.2400\n",
      "Epoch 356/650\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9180 - acc: 0.1956 - val_loss: 0.7939 - val_acc: 0.2400\n",
      "Epoch 357/650\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.9159 - acc: 0.1956 - val_loss: 0.7918 - val_acc: 0.2400\n",
      "Epoch 358/650\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.9137 - acc: 0.1956 - val_loss: 0.7899 - val_acc: 0.2400\n",
      "Epoch 359/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.9117 - acc: 0.1956 - val_loss: 0.7879 - val_acc: 0.2400\n",
      "Epoch 360/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.9099 - acc: 0.1956 - val_loss: 0.7858 - val_acc: 0.2400\n",
      "Epoch 361/650\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.9076 - acc: 0.1956 - val_loss: 0.7837 - val_acc: 0.2400\n",
      "Epoch 362/650\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.9056 - acc: 0.1956 - val_loss: 0.7817 - val_acc: 0.2400\n",
      "Epoch 363/650\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.9036 - acc: 0.1956 - val_loss: 0.7798 - val_acc: 0.2400\n",
      "Epoch 364/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.9018 - acc: 0.1956 - val_loss: 0.7779 - val_acc: 0.2400\n",
      "Epoch 365/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.9002 - acc: 0.1956 - val_loss: 0.7759 - val_acc: 0.2400\n",
      "Epoch 366/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.8984 - acc: 0.1956 - val_loss: 0.7741 - val_acc: 0.2400\n",
      "Epoch 367/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.8958 - acc: 0.1956 - val_loss: 0.7722 - val_acc: 0.2400\n",
      "Epoch 368/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.8939 - acc: 0.1956 - val_loss: 0.7704 - val_acc: 0.2400\n",
      "Epoch 369/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.8919 - acc: 0.1956 - val_loss: 0.7686 - val_acc: 0.2400\n",
      "Epoch 370/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.8909 - acc: 0.1956 - val_loss: 0.7668 - val_acc: 0.2400\n",
      "Epoch 371/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.8889 - acc: 0.1956 - val_loss: 0.7650 - val_acc: 0.2400\n",
      "Epoch 372/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.8861 - acc: 0.1956 - val_loss: 0.7634 - val_acc: 0.2400\n",
      "Epoch 373/650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 24ms/step - loss: 0.8840 - acc: 0.1956 - val_loss: 0.7616 - val_acc: 0.2400\n",
      "Epoch 374/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.8830 - acc: 0.1956 - val_loss: 0.7602 - val_acc: 0.2400\n",
      "Epoch 375/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.8804 - acc: 0.1956 - val_loss: 0.7584 - val_acc: 0.2400\n",
      "Epoch 376/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.8805 - acc: 0.1956 - val_loss: 0.7565 - val_acc: 0.2400\n",
      "Epoch 377/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.8764 - acc: 0.1956 - val_loss: 0.7546 - val_acc: 0.2400\n",
      "Epoch 378/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.8746 - acc: 0.1956 - val_loss: 0.7527 - val_acc: 0.2400\n",
      "Epoch 379/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.8738 - acc: 0.1956 - val_loss: 0.7512 - val_acc: 0.2400\n",
      "Epoch 380/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.8711 - acc: 0.1956 - val_loss: 0.7494 - val_acc: 0.2400\n",
      "Epoch 381/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.8686 - acc: 0.1956 - val_loss: 0.7473 - val_acc: 0.2400\n",
      "Epoch 382/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.8667 - acc: 0.1956 - val_loss: 0.7454 - val_acc: 0.2400\n",
      "Epoch 383/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.8667 - acc: 0.1956 - val_loss: 0.7437 - val_acc: 0.2400\n",
      "Epoch 384/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.8638 - acc: 0.1956 - val_loss: 0.7418 - val_acc: 0.2400\n",
      "Epoch 385/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.8613 - acc: 0.1956 - val_loss: 0.7401 - val_acc: 0.2400\n",
      "Epoch 386/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.8593 - acc: 0.1956 - val_loss: 0.7383 - val_acc: 0.2400\n",
      "Epoch 387/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.8576 - acc: 0.1956 - val_loss: 0.7366 - val_acc: 0.2400\n",
      "Epoch 388/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.8559 - acc: 0.1956 - val_loss: 0.7353 - val_acc: 0.2400\n",
      "Epoch 389/650\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8540 - acc: 0.1956 - val_loss: 0.7337 - val_acc: 0.2400\n",
      "Epoch 390/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.8534 - acc: 0.1956 - val_loss: 0.7314 - val_acc: 0.2400\n",
      "Epoch 391/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.8499 - acc: 0.1956 - val_loss: 0.7296 - val_acc: 0.2400\n",
      "Epoch 392/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.8479 - acc: 0.1956 - val_loss: 0.7275 - val_acc: 0.2400\n",
      "Epoch 393/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.8461 - acc: 0.1956 - val_loss: 0.7257 - val_acc: 0.2400\n",
      "Epoch 394/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.8441 - acc: 0.1956 - val_loss: 0.7239 - val_acc: 0.2400\n",
      "Epoch 395/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.8422 - acc: 0.1956 - val_loss: 0.7223 - val_acc: 0.2400\n",
      "Epoch 396/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.8409 - acc: 0.1956 - val_loss: 0.7206 - val_acc: 0.2400\n",
      "Epoch 397/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.8392 - acc: 0.1956 - val_loss: 0.7192 - val_acc: 0.2400\n",
      "Epoch 398/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.8378 - acc: 0.1956 - val_loss: 0.7174 - val_acc: 0.2400\n",
      "Epoch 399/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.8348 - acc: 0.1956 - val_loss: 0.7162 - val_acc: 0.2400\n",
      "Epoch 400/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.8328 - acc: 0.1956 - val_loss: 0.7148 - val_acc: 0.2400\n",
      "Epoch 401/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.8311 - acc: 0.1956 - val_loss: 0.7136 - val_acc: 0.2400\n",
      "Epoch 402/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.8296 - acc: 0.1956 - val_loss: 0.7121 - val_acc: 0.2400\n",
      "Epoch 403/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.8278 - acc: 0.1956 - val_loss: 0.7102 - val_acc: 0.2400\n",
      "Epoch 404/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.8259 - acc: 0.1956 - val_loss: 0.7085 - val_acc: 0.2400\n",
      "Epoch 405/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.8239 - acc: 0.1956 - val_loss: 0.7065 - val_acc: 0.2400\n",
      "Epoch 406/650\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8218 - acc: 0.1956 - val_loss: 0.7047 - val_acc: 0.2400\n",
      "Epoch 407/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.8214 - acc: 0.1956 - val_loss: 0.7031 - val_acc: 0.2400\n",
      "Epoch 408/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.8207 - acc: 0.1956 - val_loss: 0.7017 - val_acc: 0.2400\n",
      "Epoch 409/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.8170 - acc: 0.1956 - val_loss: 0.7002 - val_acc: 0.2400\n",
      "Epoch 410/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.8162 - acc: 0.1956 - val_loss: 0.6986 - val_acc: 0.2400\n",
      "Epoch 411/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.8132 - acc: 0.1956 - val_loss: 0.6970 - val_acc: 0.2400\n",
      "Epoch 412/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.8115 - acc: 0.1956 - val_loss: 0.6953 - val_acc: 0.2400\n",
      "Epoch 413/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.8095 - acc: 0.1956 - val_loss: 0.6938 - val_acc: 0.2400\n",
      "Epoch 414/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.8077 - acc: 0.1956 - val_loss: 0.6922 - val_acc: 0.2400\n",
      "Epoch 415/650\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8061 - acc: 0.1956 - val_loss: 0.6908 - val_acc: 0.2400\n",
      "Epoch 416/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.8046 - acc: 0.1956 - val_loss: 0.6887 - val_acc: 0.2400\n",
      "Epoch 417/650\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8025 - acc: 0.1956 - val_loss: 0.6873 - val_acc: 0.2400\n",
      "Epoch 418/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.8014 - acc: 0.1956 - val_loss: 0.6854 - val_acc: 0.2400\n",
      "Epoch 419/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.7996 - acc: 0.1956 - val_loss: 0.6838 - val_acc: 0.2400\n",
      "Epoch 420/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.7974 - acc: 0.1956 - val_loss: 0.6830 - val_acc: 0.2400\n",
      "Epoch 421/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.7955 - acc: 0.1956 - val_loss: 0.6818 - val_acc: 0.2400\n",
      "Epoch 422/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.7939 - acc: 0.1956 - val_loss: 0.6804 - val_acc: 0.2400\n",
      "Epoch 423/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.7935 - acc: 0.1956 - val_loss: 0.6779 - val_acc: 0.2400\n",
      "Epoch 424/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.7905 - acc: 0.1956 - val_loss: 0.6767 - val_acc: 0.2400\n",
      "Epoch 425/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.7885 - acc: 0.1956 - val_loss: 0.6748 - val_acc: 0.2400\n",
      "Epoch 426/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.7867 - acc: 0.1956 - val_loss: 0.6731 - val_acc: 0.2400\n",
      "Epoch 427/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.7850 - acc: 0.1956 - val_loss: 0.6714 - val_acc: 0.2400\n",
      "Epoch 428/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.7834 - acc: 0.1956 - val_loss: 0.6700 - val_acc: 0.2400\n",
      "Epoch 429/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.7815 - acc: 0.1956 - val_loss: 0.6685 - val_acc: 0.2400\n",
      "Epoch 430/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.7800 - acc: 0.1956 - val_loss: 0.6668 - val_acc: 0.2400\n",
      "Epoch 431/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.7790 - acc: 0.1956 - val_loss: 0.6657 - val_acc: 0.2400\n",
      "Epoch 432/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.7765 - acc: 0.1956 - val_loss: 0.6637 - val_acc: 0.2400\n",
      "Epoch 433/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.7752 - acc: 0.1956 - val_loss: 0.6623 - val_acc: 0.2400\n",
      "Epoch 434/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.7738 - acc: 0.1956 - val_loss: 0.6602 - val_acc: 0.2400\n",
      "Epoch 435/650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 21ms/step - loss: 0.7722 - acc: 0.1956 - val_loss: 0.6585 - val_acc: 0.2400\n",
      "Epoch 436/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.7700 - acc: 0.1956 - val_loss: 0.6575 - val_acc: 0.2400\n",
      "Epoch 437/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.7680 - acc: 0.1956 - val_loss: 0.6566 - val_acc: 0.2400\n",
      "Epoch 438/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.7664 - acc: 0.1956 - val_loss: 0.6554 - val_acc: 0.2400\n",
      "Epoch 439/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.7648 - acc: 0.1956 - val_loss: 0.6541 - val_acc: 0.2400\n",
      "Epoch 440/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.7632 - acc: 0.1956 - val_loss: 0.6528 - val_acc: 0.2400\n",
      "Epoch 441/650\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7614 - acc: 0.1956 - val_loss: 0.6512 - val_acc: 0.2400\n",
      "Epoch 442/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.7597 - acc: 0.1956 - val_loss: 0.6495 - val_acc: 0.2400\n",
      "Epoch 443/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.7581 - acc: 0.1956 - val_loss: 0.6478 - val_acc: 0.2400\n",
      "Epoch 444/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.7567 - acc: 0.1956 - val_loss: 0.6462 - val_acc: 0.2400\n",
      "Epoch 445/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.7552 - acc: 0.1956 - val_loss: 0.6447 - val_acc: 0.2400\n",
      "Epoch 446/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.7544 - acc: 0.1956 - val_loss: 0.6442 - val_acc: 0.2400\n",
      "Epoch 447/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.7518 - acc: 0.1956 - val_loss: 0.6428 - val_acc: 0.2400\n",
      "Epoch 448/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.7505 - acc: 0.1956 - val_loss: 0.6423 - val_acc: 0.2400\n",
      "Epoch 449/650\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7483 - acc: 0.1956 - val_loss: 0.6409 - val_acc: 0.2400\n",
      "Epoch 450/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.7467 - acc: 0.1956 - val_loss: 0.6395 - val_acc: 0.2400\n",
      "Epoch 451/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.7451 - acc: 0.1956 - val_loss: 0.6379 - val_acc: 0.2400\n",
      "Epoch 452/650\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.7439 - acc: 0.1956 - val_loss: 0.6362 - val_acc: 0.2400\n",
      "Epoch 453/650\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.7426 - acc: 0.1956 - val_loss: 0.6350 - val_acc: 0.2400\n",
      "Epoch 454/650\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.7405 - acc: 0.1956 - val_loss: 0.6349 - val_acc: 0.2400\n",
      "Epoch 455/650\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.7395 - acc: 0.1956 - val_loss: 0.6345 - val_acc: 0.2400\n",
      "Epoch 456/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.7373 - acc: 0.1956 - val_loss: 0.6326 - val_acc: 0.2400\n",
      "Epoch 457/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.7358 - acc: 0.1956 - val_loss: 0.6312 - val_acc: 0.2400\n",
      "Epoch 458/650\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7338 - acc: 0.1956 - val_loss: 0.6292 - val_acc: 0.2400\n",
      "Epoch 459/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.7323 - acc: 0.1956 - val_loss: 0.6274 - val_acc: 0.2400\n",
      "Epoch 460/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.7310 - acc: 0.1956 - val_loss: 0.6260 - val_acc: 0.2400\n",
      "Epoch 461/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.7295 - acc: 0.1956 - val_loss: 0.6251 - val_acc: 0.2400\n",
      "Epoch 462/650\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.7279 - acc: 0.1956 - val_loss: 0.6245 - val_acc: 0.2400\n",
      "Epoch 463/650\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.7262 - acc: 0.1956 - val_loss: 0.6236 - val_acc: 0.2400\n",
      "Epoch 464/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.7246 - acc: 0.1956 - val_loss: 0.6235 - val_acc: 0.2400\n",
      "Epoch 465/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.7232 - acc: 0.1956 - val_loss: 0.6231 - val_acc: 0.2400\n",
      "Epoch 466/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.7216 - acc: 0.1956 - val_loss: 0.6218 - val_acc: 0.2400\n",
      "Epoch 467/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.7200 - acc: 0.1956 - val_loss: 0.6203 - val_acc: 0.2400\n",
      "Epoch 468/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.7184 - acc: 0.1956 - val_loss: 0.6182 - val_acc: 0.2400\n",
      "Epoch 469/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.7168 - acc: 0.1956 - val_loss: 0.6162 - val_acc: 0.2400\n",
      "Epoch 470/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.7155 - acc: 0.1956 - val_loss: 0.6145 - val_acc: 0.2400\n",
      "Epoch 471/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.7148 - acc: 0.1956 - val_loss: 0.6135 - val_acc: 0.2400\n",
      "Epoch 472/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.7129 - acc: 0.1956 - val_loss: 0.6123 - val_acc: 0.2400\n",
      "Epoch 473/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.7109 - acc: 0.1956 - val_loss: 0.6107 - val_acc: 0.2400\n",
      "Epoch 474/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.7095 - acc: 0.1956 - val_loss: 0.6097 - val_acc: 0.2400\n",
      "Epoch 475/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.7086 - acc: 0.1956 - val_loss: 0.6087 - val_acc: 0.2400\n",
      "Epoch 476/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.7072 - acc: 0.1956 - val_loss: 0.6092 - val_acc: 0.2400\n",
      "Epoch 477/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.7059 - acc: 0.1956 - val_loss: 0.6083 - val_acc: 0.2400\n",
      "Epoch 478/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.7031 - acc: 0.1956 - val_loss: 0.6086 - val_acc: 0.2400\n",
      "Epoch 479/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.7019 - acc: 0.1956 - val_loss: 0.6091 - val_acc: 0.2400\n",
      "Epoch 480/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.7017 - acc: 0.1956 - val_loss: 0.6103 - val_acc: 0.2400\n",
      "Epoch 481/650\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.6999 - acc: 0.1956 - val_loss: 0.6081 - val_acc: 0.2400\n",
      "Epoch 482/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.6979 - acc: 0.1956 - val_loss: 0.6059 - val_acc: 0.2400\n",
      "Epoch 483/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.6958 - acc: 0.1956 - val_loss: 0.6031 - val_acc: 0.2400\n",
      "Epoch 484/650\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6943 - acc: 0.1956 - val_loss: 0.6007 - val_acc: 0.2400\n",
      "Epoch 485/650\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.6940 - acc: 0.1956 - val_loss: 0.5989 - val_acc: 0.2400\n",
      "Epoch 486/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.6921 - acc: 0.1956 - val_loss: 0.5983 - val_acc: 0.2400\n",
      "Epoch 487/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6906 - acc: 0.1956 - val_loss: 0.5985 - val_acc: 0.2400\n",
      "Epoch 488/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.6885 - acc: 0.1956 - val_loss: 0.5989 - val_acc: 0.2400\n",
      "Epoch 489/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6872 - acc: 0.1956 - val_loss: 0.5987 - val_acc: 0.2400\n",
      "Epoch 490/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6861 - acc: 0.1956 - val_loss: 0.5998 - val_acc: 0.2400\n",
      "Epoch 491/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.6851 - acc: 0.1956 - val_loss: 0.5995 - val_acc: 0.2400\n",
      "Epoch 492/650\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6836 - acc: 0.1956 - val_loss: 0.5966 - val_acc: 0.2400\n",
      "Epoch 493/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6816 - acc: 0.1956 - val_loss: 0.5952 - val_acc: 0.2400\n",
      "Epoch 494/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6799 - acc: 0.1956 - val_loss: 0.5930 - val_acc: 0.2400\n",
      "Epoch 495/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6798 - acc: 0.1956 - val_loss: 0.5909 - val_acc: 0.2400\n",
      "Epoch 496/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.6775 - acc: 0.1956 - val_loss: 0.5906 - val_acc: 0.2400\n",
      "Epoch 497/650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 21ms/step - loss: 0.6758 - acc: 0.1956 - val_loss: 0.5909 - val_acc: 0.2400\n",
      "Epoch 498/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6744 - acc: 0.1956 - val_loss: 0.5920 - val_acc: 0.2400\n",
      "Epoch 499/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6734 - acc: 0.1956 - val_loss: 0.5915 - val_acc: 0.2400\n",
      "Epoch 500/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.6715 - acc: 0.1956 - val_loss: 0.5920 - val_acc: 0.2400\n",
      "Epoch 501/650\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6704 - acc: 0.1956 - val_loss: 0.5919 - val_acc: 0.2400\n",
      "Epoch 502/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6698 - acc: 0.1956 - val_loss: 0.5911 - val_acc: 0.2400\n",
      "Epoch 503/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6675 - acc: 0.1956 - val_loss: 0.5880 - val_acc: 0.2400\n",
      "Epoch 504/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6672 - acc: 0.1956 - val_loss: 0.5851 - val_acc: 0.2400\n",
      "Epoch 505/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.6666 - acc: 0.1956 - val_loss: 0.5835 - val_acc: 0.2400\n",
      "Epoch 506/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6634 - acc: 0.1956 - val_loss: 0.5841 - val_acc: 0.2400\n",
      "Epoch 507/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.6616 - acc: 0.1956 - val_loss: 0.5856 - val_acc: 0.2400\n",
      "Epoch 508/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.6610 - acc: 0.1956 - val_loss: 0.5875 - val_acc: 0.2400\n",
      "Epoch 509/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.6595 - acc: 0.1956 - val_loss: 0.5869 - val_acc: 0.2400\n",
      "Epoch 510/650\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6582 - acc: 0.1956 - val_loss: 0.5850 - val_acc: 0.2400\n",
      "Epoch 511/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6568 - acc: 0.1956 - val_loss: 0.5834 - val_acc: 0.2400\n",
      "Epoch 512/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6551 - acc: 0.1956 - val_loss: 0.5801 - val_acc: 0.2400\n",
      "Epoch 513/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6543 - acc: 0.1956 - val_loss: 0.5779 - val_acc: 0.2400\n",
      "Epoch 514/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6532 - acc: 0.1956 - val_loss: 0.5778 - val_acc: 0.2400\n",
      "Epoch 515/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.6511 - acc: 0.1956 - val_loss: 0.5773 - val_acc: 0.2400\n",
      "Epoch 516/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6505 - acc: 0.1956 - val_loss: 0.5766 - val_acc: 0.2400\n",
      "Epoch 517/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.6485 - acc: 0.1956 - val_loss: 0.5780 - val_acc: 0.2400\n",
      "Epoch 518/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.6470 - acc: 0.1956 - val_loss: 0.5791 - val_acc: 0.2400\n",
      "Epoch 519/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6458 - acc: 0.1956 - val_loss: 0.5789 - val_acc: 0.2400\n",
      "Epoch 520/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.6444 - acc: 0.1956 - val_loss: 0.5790 - val_acc: 0.2400\n",
      "Epoch 521/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.6433 - acc: 0.1956 - val_loss: 0.5777 - val_acc: 0.2400\n",
      "Epoch 522/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.6418 - acc: 0.1956 - val_loss: 0.5766 - val_acc: 0.2400\n",
      "Epoch 523/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.6410 - acc: 0.1956 - val_loss: 0.5758 - val_acc: 0.2400\n",
      "Epoch 524/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6398 - acc: 0.1956 - val_loss: 0.5729 - val_acc: 0.2400\n",
      "Epoch 525/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6380 - acc: 0.1956 - val_loss: 0.5718 - val_acc: 0.2400\n",
      "Epoch 526/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.6367 - acc: 0.1956 - val_loss: 0.5717 - val_acc: 0.2400\n",
      "Epoch 527/650\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6353 - acc: 0.1956 - val_loss: 0.5723 - val_acc: 0.2400\n",
      "Epoch 528/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.6339 - acc: 0.1956 - val_loss: 0.5731 - val_acc: 0.2400\n",
      "Epoch 529/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.6332 - acc: 0.1956 - val_loss: 0.5740 - val_acc: 0.2400\n",
      "Epoch 530/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.6320 - acc: 0.1956 - val_loss: 0.5736 - val_acc: 0.2400\n",
      "Epoch 531/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6300 - acc: 0.1956 - val_loss: 0.5712 - val_acc: 0.2400\n",
      "Epoch 532/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6292 - acc: 0.1956 - val_loss: 0.5686 - val_acc: 0.2400\n",
      "Epoch 533/650\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.6277 - acc: 0.1956 - val_loss: 0.5675 - val_acc: 0.2400\n",
      "Epoch 534/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.6265 - acc: 0.1956 - val_loss: 0.5677 - val_acc: 0.2400\n",
      "Epoch 535/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6257 - acc: 0.1956 - val_loss: 0.5673 - val_acc: 0.2400\n",
      "Epoch 536/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.6236 - acc: 0.1956 - val_loss: 0.5688 - val_acc: 0.2400\n",
      "Epoch 537/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.6225 - acc: 0.1956 - val_loss: 0.5711 - val_acc: 0.2400\n",
      "Epoch 538/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.6217 - acc: 0.1956 - val_loss: 0.5721 - val_acc: 0.2400\n",
      "Epoch 539/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.6206 - acc: 0.1956 - val_loss: 0.5701 - val_acc: 0.2400\n",
      "Epoch 540/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6190 - acc: 0.1956 - val_loss: 0.5680 - val_acc: 0.2400\n",
      "Epoch 541/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.6177 - acc: 0.1956 - val_loss: 0.5660 - val_acc: 0.2400\n",
      "Epoch 542/650\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.6177 - acc: 0.1956 - val_loss: 0.5645 - val_acc: 0.2400\n",
      "Epoch 543/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.6150 - acc: 0.1956 - val_loss: 0.5659 - val_acc: 0.2400\n",
      "Epoch 544/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.6136 - acc: 0.1956 - val_loss: 0.5669 - val_acc: 0.2400\n",
      "Epoch 545/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.6125 - acc: 0.1956 - val_loss: 0.5668 - val_acc: 0.2400\n",
      "Epoch 546/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.6114 - acc: 0.1956 - val_loss: 0.5666 - val_acc: 0.2400\n",
      "Epoch 547/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6101 - acc: 0.1956 - val_loss: 0.5674 - val_acc: 0.2400\n",
      "Epoch 548/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6089 - acc: 0.1956 - val_loss: 0.5663 - val_acc: 0.2400\n",
      "Epoch 549/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.6077 - acc: 0.1956 - val_loss: 0.5650 - val_acc: 0.2400\n",
      "Epoch 550/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.6068 - acc: 0.1956 - val_loss: 0.5649 - val_acc: 0.2400\n",
      "Epoch 551/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6060 - acc: 0.1956 - val_loss: 0.5623 - val_acc: 0.2400\n",
      "Epoch 552/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6039 - acc: 0.1956 - val_loss: 0.5618 - val_acc: 0.2400\n",
      "Epoch 553/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.6027 - acc: 0.1956 - val_loss: 0.5622 - val_acc: 0.2400\n",
      "Epoch 554/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6016 - acc: 0.1956 - val_loss: 0.5625 - val_acc: 0.2400\n",
      "Epoch 555/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6002 - acc: 0.1956 - val_loss: 0.5639 - val_acc: 0.2400\n",
      "Epoch 556/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5991 - acc: 0.1956 - val_loss: 0.5647 - val_acc: 0.2400\n",
      "Epoch 557/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5981 - acc: 0.1956 - val_loss: 0.5641 - val_acc: 0.2400\n",
      "Epoch 558/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.5968 - acc: 0.1956 - val_loss: 0.5636 - val_acc: 0.2400\n",
      "Epoch 559/650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5956 - acc: 0.1956 - val_loss: 0.5627 - val_acc: 0.2400\n",
      "Epoch 560/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5943 - acc: 0.1956 - val_loss: 0.5615 - val_acc: 0.2400\n",
      "Epoch 561/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5934 - acc: 0.1956 - val_loss: 0.5606 - val_acc: 0.2400\n",
      "Epoch 562/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5918 - acc: 0.1956 - val_loss: 0.5586 - val_acc: 0.2400\n",
      "Epoch 563/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5908 - acc: 0.1956 - val_loss: 0.5569 - val_acc: 0.2400\n",
      "Epoch 564/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.5899 - acc: 0.1956 - val_loss: 0.5566 - val_acc: 0.2400\n",
      "Epoch 565/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5887 - acc: 0.1956 - val_loss: 0.5564 - val_acc: 0.2400\n",
      "Epoch 566/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5884 - acc: 0.1956 - val_loss: 0.5582 - val_acc: 0.2400\n",
      "Epoch 567/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5863 - acc: 0.1956 - val_loss: 0.5579 - val_acc: 0.2400\n",
      "Epoch 568/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5855 - acc: 0.1956 - val_loss: 0.5596 - val_acc: 0.2400\n",
      "Epoch 569/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5839 - acc: 0.1956 - val_loss: 0.5590 - val_acc: 0.2400\n",
      "Epoch 570/650\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5828 - acc: 0.1956 - val_loss: 0.5593 - val_acc: 0.2400\n",
      "Epoch 571/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5815 - acc: 0.1956 - val_loss: 0.5584 - val_acc: 0.2400\n",
      "Epoch 572/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5802 - acc: 0.1956 - val_loss: 0.5571 - val_acc: 0.2400\n",
      "Epoch 573/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5796 - acc: 0.1956 - val_loss: 0.5566 - val_acc: 0.2400\n",
      "Epoch 574/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5781 - acc: 0.1956 - val_loss: 0.5551 - val_acc: 0.2400\n",
      "Epoch 575/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5769 - acc: 0.1956 - val_loss: 0.5539 - val_acc: 0.2400\n",
      "Epoch 576/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5761 - acc: 0.1956 - val_loss: 0.5528 - val_acc: 0.2400\n",
      "Epoch 577/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5751 - acc: 0.1956 - val_loss: 0.5533 - val_acc: 0.2400\n",
      "Epoch 578/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.5737 - acc: 0.1956 - val_loss: 0.5549 - val_acc: 0.2400\n",
      "Epoch 579/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5724 - acc: 0.1956 - val_loss: 0.5568 - val_acc: 0.2400\n",
      "Epoch 580/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5714 - acc: 0.1956 - val_loss: 0.5576 - val_acc: 0.2400\n",
      "Epoch 581/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5721 - acc: 0.1956 - val_loss: 0.5604 - val_acc: 0.2400\n",
      "Epoch 582/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.5692 - acc: 0.1956 - val_loss: 0.5585 - val_acc: 0.2400\n",
      "Epoch 583/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5682 - acc: 0.1956 - val_loss: 0.5550 - val_acc: 0.2400\n",
      "Epoch 584/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5671 - acc: 0.1956 - val_loss: 0.5541 - val_acc: 0.2400\n",
      "Epoch 585/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5661 - acc: 0.1956 - val_loss: 0.5523 - val_acc: 0.2400\n",
      "Epoch 586/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.5650 - acc: 0.1956 - val_loss: 0.5528 - val_acc: 0.2400\n",
      "Epoch 587/650\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5637 - acc: 0.1956 - val_loss: 0.5538 - val_acc: 0.2400\n",
      "Epoch 588/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5624 - acc: 0.1956 - val_loss: 0.5553 - val_acc: 0.2400\n",
      "Epoch 589/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5611 - acc: 0.1956 - val_loss: 0.5579 - val_acc: 0.2400\n",
      "Epoch 590/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5606 - acc: 0.1956 - val_loss: 0.5589 - val_acc: 0.2400\n",
      "Epoch 591/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5594 - acc: 0.1956 - val_loss: 0.5615 - val_acc: 0.2400\n",
      "Epoch 592/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5587 - acc: 0.1956 - val_loss: 0.5599 - val_acc: 0.2400\n",
      "Epoch 593/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5572 - acc: 0.1956 - val_loss: 0.5583 - val_acc: 0.2400\n",
      "Epoch 594/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5558 - acc: 0.1956 - val_loss: 0.5564 - val_acc: 0.2400\n",
      "Epoch 595/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5570 - acc: 0.1956 - val_loss: 0.5530 - val_acc: 0.2400\n",
      "Epoch 596/650\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5536 - acc: 0.1956 - val_loss: 0.5540 - val_acc: 0.2400\n",
      "Epoch 597/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.5527 - acc: 0.1956 - val_loss: 0.5549 - val_acc: 0.2400\n",
      "Epoch 598/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5517 - acc: 0.1956 - val_loss: 0.5579 - val_acc: 0.2400\n",
      "Epoch 599/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5506 - acc: 0.1956 - val_loss: 0.5587 - val_acc: 0.2400\n",
      "Epoch 600/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5496 - acc: 0.1956 - val_loss: 0.5577 - val_acc: 0.2400\n",
      "Epoch 601/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5484 - acc: 0.1956 - val_loss: 0.5545 - val_acc: 0.2400\n",
      "Epoch 602/650\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5480 - acc: 0.1956 - val_loss: 0.5519 - val_acc: 0.2400\n",
      "Epoch 603/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.5461 - acc: 0.1956 - val_loss: 0.5525 - val_acc: 0.2400\n",
      "Epoch 604/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5453 - acc: 0.1956 - val_loss: 0.5542 - val_acc: 0.2400\n",
      "Epoch 605/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5442 - acc: 0.1956 - val_loss: 0.5536 - val_acc: 0.2400\n",
      "Epoch 606/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5428 - acc: 0.1956 - val_loss: 0.5549 - val_acc: 0.2400\n",
      "Epoch 607/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5420 - acc: 0.1956 - val_loss: 0.5559 - val_acc: 0.2400\n",
      "Epoch 608/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5411 - acc: 0.1956 - val_loss: 0.5558 - val_acc: 0.2400\n",
      "Epoch 609/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.5397 - acc: 0.1956 - val_loss: 0.5528 - val_acc: 0.2400\n",
      "Epoch 610/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.5395 - acc: 0.1956 - val_loss: 0.5523 - val_acc: 0.2400\n",
      "Epoch 611/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5380 - acc: 0.1956 - val_loss: 0.5493 - val_acc: 0.2400\n",
      "Epoch 612/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5368 - acc: 0.1956 - val_loss: 0.5495 - val_acc: 0.2400\n",
      "Epoch 613/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.5361 - acc: 0.1956 - val_loss: 0.5505 - val_acc: 0.2400\n",
      "Epoch 614/650\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5345 - acc: 0.1956 - val_loss: 0.5546 - val_acc: 0.2400\n",
      "Epoch 615/650\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5331 - acc: 0.1956 - val_loss: 0.5575 - val_acc: 0.2400\n",
      "Epoch 616/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5324 - acc: 0.1956 - val_loss: 0.5589 - val_acc: 0.2400\n",
      "Epoch 617/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5316 - acc: 0.1956 - val_loss: 0.5581 - val_acc: 0.2400\n",
      "Epoch 618/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5304 - acc: 0.1956 - val_loss: 0.5569 - val_acc: 0.2400\n",
      "Epoch 619/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5291 - acc: 0.1956 - val_loss: 0.5549 - val_acc: 0.2400\n",
      "Epoch 620/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5280 - acc: 0.1956 - val_loss: 0.5527 - val_acc: 0.2400\n",
      "Epoch 621/650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 23ms/step - loss: 0.5269 - acc: 0.1956 - val_loss: 0.5503 - val_acc: 0.2400\n",
      "Epoch 622/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5268 - acc: 0.1956 - val_loss: 0.5490 - val_acc: 0.2400\n",
      "Epoch 623/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5255 - acc: 0.1956 - val_loss: 0.5511 - val_acc: 0.2400\n",
      "Epoch 624/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5240 - acc: 0.1956 - val_loss: 0.5538 - val_acc: 0.2400\n",
      "Epoch 625/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5228 - acc: 0.1956 - val_loss: 0.5560 - val_acc: 0.2400\n",
      "Epoch 626/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5220 - acc: 0.1956 - val_loss: 0.5577 - val_acc: 0.2400\n",
      "Epoch 627/650\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5212 - acc: 0.1956 - val_loss: 0.5599 - val_acc: 0.2400\n",
      "Epoch 628/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5210 - acc: 0.1956 - val_loss: 0.5603 - val_acc: 0.2400\n",
      "Epoch 629/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5215 - acc: 0.1956 - val_loss: 0.5545 - val_acc: 0.2400\n",
      "Epoch 630/650\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5179 - acc: 0.1956 - val_loss: 0.5536 - val_acc: 0.2400\n",
      "Epoch 631/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5171 - acc: 0.1956 - val_loss: 0.5529 - val_acc: 0.2400\n",
      "Epoch 632/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5170 - acc: 0.1956 - val_loss: 0.5549 - val_acc: 0.2400\n",
      "Epoch 633/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.5152 - acc: 0.1956 - val_loss: 0.5532 - val_acc: 0.2400\n",
      "Epoch 634/650\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5140 - acc: 0.1956 - val_loss: 0.5534 - val_acc: 0.2400\n",
      "Epoch 635/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5129 - acc: 0.1956 - val_loss: 0.5550 - val_acc: 0.2400\n",
      "Epoch 636/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5121 - acc: 0.1956 - val_loss: 0.5565 - val_acc: 0.2400\n",
      "Epoch 637/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.5110 - acc: 0.1956 - val_loss: 0.5560 - val_acc: 0.2400\n",
      "Epoch 638/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5100 - acc: 0.1956 - val_loss: 0.5561 - val_acc: 0.2400\n",
      "Epoch 639/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5091 - acc: 0.1956 - val_loss: 0.5548 - val_acc: 0.2400\n",
      "Epoch 640/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5081 - acc: 0.1956 - val_loss: 0.5540 - val_acc: 0.2400\n",
      "Epoch 641/650\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5078 - acc: 0.1956 - val_loss: 0.5556 - val_acc: 0.2400\n",
      "Epoch 642/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5065 - acc: 0.1956 - val_loss: 0.5556 - val_acc: 0.2400\n",
      "Epoch 643/650\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5057 - acc: 0.1956 - val_loss: 0.5528 - val_acc: 0.2400\n",
      "Epoch 644/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.5043 - acc: 0.1956 - val_loss: 0.5535 - val_acc: 0.2400\n",
      "Epoch 645/650\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.5033 - acc: 0.1956 - val_loss: 0.5543 - val_acc: 0.2400\n",
      "Epoch 646/650\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5022 - acc: 0.1956 - val_loss: 0.5562 - val_acc: 0.2400\n",
      "Epoch 647/650\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5016 - acc: 0.1956 - val_loss: 0.5572 - val_acc: 0.2400\n",
      "Epoch 648/650\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.5003 - acc: 0.1956 - val_loss: 0.5598 - val_acc: 0.2400\n",
      "Epoch 649/650\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4995 - acc: 0.1956 - val_loss: 0.5608 - val_acc: 0.2400\n",
      "Epoch 650/650\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4987 - acc: 0.1956 - val_loss: 0.5607 - val_acc: 0.2400\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-970605184550>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m650\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mhistory_size_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_size_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_size_train_array1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_size_train_array2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_size_train_array3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_size_train_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_size_test_array1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_size_test_array2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_size_test_array3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_size_test_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# 学習ループ\n",
    "history_size_array = []\n",
    "for i in range(len(model_size_array)):\n",
    "    epochs = 650\n",
    "    batch_size = 128\n",
    "    history_size_array.append(model_size_array[i].fit([x_size_train_array1[i], x_size_train_array2[i], x_size_train_array3[i]], y_size_train_array[i], batch_size=batch_size, epochs=epochs, verbose=1, validation_data=([x_size_test_array1[i], x_size_test_array2[i], x_size_test_array3[i]], y_size_test_array[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tensorflow.python.keras.callbacks.History object at 0x7f99714624d0>]\n"
     ]
    }
   ],
   "source": [
    "print(history_size_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5607 - acc: 0.2400\n",
      "Test loss: 0.5606998205184937\n",
      "Test accuracy: 0.23999999463558197\n"
     ]
    }
   ],
   "source": [
    "# モデルの評価(大きさ)\n",
    "score = model_size_array[0].evaluate([x_size_test_array1[0], x_size_test_array2[0], x_size_test_array3[0]], y_size_test_array[0], verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 学習経過の可視化(大きさ)\n",
    "loss     = history_size_array[0].history['loss']\n",
    "val_loss = history_size_array[0].history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss,     marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f99765edf50>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 散布図表示(テストデータ25個)\n",
    "size_predict = model_size_array[0].predict([x_size_test_array1[0], x_size_test_array2[0], x_size_test_array3[0]])\n",
    "size_answer = y_size_test_array[0]\n",
    "\n",
    "plt.scatter(size_answer, size_predict)\n",
    "plt.xlabel(\"size\")\n",
    "plt.ylabel(\"prediction\")\n",
    "plt.grid(True)\n",
    "## y=xの直線をひく\n",
    "x = []\n",
    "for i in range(60):\n",
    "    x.append(i*0.1)\n",
    "y = []\n",
    "for i in range(60):\n",
    "    y.append(i*0.1)\n",
    "plt.plot(x, y, color='black')\n",
    "## 誤差-30%の直線を引く\n",
    "y = []\n",
    "for i in range(60):\n",
    "    y.append(i*0.1*0.7)\n",
    "plt.plot(x, y, color='red')\n",
    "## 誤差+30%の直線を引く\n",
    "y = []\n",
    "for i in range(60):\n",
    "    y.append(i*0.1*1.3)\n",
    "plt.plot(x, y, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## データについて\n",
    "\n",
    "### データファイルのpath\n",
    "no_hole_path = './../vibration_simulation/vibration_data/no_hole_data.csv'\n",
    "one_hole_path = './../vibration_simulation/vibration_data/one_hole_data.csv'\n",
    "four_holes_path = './../vibration_simulation/vibration_data/four_holes_data.csv'\n",
    "nine_holes_path = './../vibration_simulation/vibration_data/nine_holes_data.csv'\n",
    "sixteen_holes_path = './../vibration_simulation/vibration_data/sixteen_holes_data.csv'\n",
    "twentyfive_holes_path = './../vibration_simulation/vibration_data/twentyfive_holes_data.csv'\n",
    "\n",
    "### 入力データと正解データ\n",
    "no_hole_data1 = []\n",
    "no_hole_data2 = []\n",
    "no_hole_data3 = []\n",
    "size_x_data = []\n",
    "size_x_data1 = []\n",
    "size_x_data2 = []\n",
    "size_x_data3 = []\n",
    "size_y_data = []\n",
    "position_x_data = []\n",
    "position_x_data1 = []\n",
    "position_x_data2 = []\n",
    "position_x_data3 = []\n",
    "position_one_data1 = []\n",
    "position_one_data2 = []\n",
    "position_one_data3 = []\n",
    "position_two_data1 = []\n",
    "position_two_data2 = []\n",
    "position_two_data3 = []\n",
    "position_three_data1 = []\n",
    "position_three_data2 = []\n",
    "position_three_data3 = []\n",
    "position_four_data1 = []\n",
    "position_four_data2 = []\n",
    "position_four_data3 = []\n",
    "position_five_data1 = []\n",
    "position_five_data2 = []\n",
    "position_five_data3 = []\n",
    "position_y_data = []\n",
    "\n",
    "### ファイル読み込み\n",
    "\n",
    "#### 欠陥がない場合のデータ\n",
    "with open(no_hole_path) as f:\n",
    "    for line in f:\n",
    "        data_array = line.split(' ')\n",
    "        no_hole_data1 = data_array[0:1251]\n",
    "        no_hole_data2 = data_array[1251:2502]\n",
    "        no_hole_data3 = data_array[2502:-1]\n",
    "        \n",
    "#### 大きさに関するデータ\n",
    "with open(one_hole_path) as fs1:\n",
    "  for line in fs1:\n",
    "    data_array = line.split(' ')\n",
    "    size_x_data1.append(data_array[3:1254])\n",
    "    size_x_data2.append(data_array[1254:2505])\n",
    "    size_x_data3.append(data_array[2505:-1])\n",
    "    size_y_data.append(data_array[0])\n",
    "with open(four_holes_path) as fs2:\n",
    "  for line in fs2:\n",
    "    data_array = line.split(' ')\n",
    "    size_x_data1.append(data_array[3:1254])\n",
    "    size_x_data2.append(data_array[1254:2505])\n",
    "    size_x_data3.append(data_array[2505:-1])\n",
    "    size_y_data.append(data_array[0])\n",
    "with open(nine_holes_path) as fs3:\n",
    "  for line in fs3:\n",
    "    data_array = line.split(' ')\n",
    "    size_x_data1.append(data_array[3:1254])\n",
    "    size_x_data2.append(data_array[1254:2505])\n",
    "    size_x_data3.append(data_array[2505:-1])\n",
    "    size_y_data.append(data_array[0])\n",
    "with open(sixteen_holes_path) as fs4:\n",
    "  for line in fs4:\n",
    "    data_array = line.split(' ')\n",
    "    size_x_data1.append(data_array[3:1254])\n",
    "    size_x_data2.append(data_array[1254:2505])\n",
    "    size_x_data3.append(data_array[2505:-1])\n",
    "    size_y_data.append(data_array[0])\n",
    "with open(twentyfive_holes_path) as fs5:\n",
    "  for line in fs5:\n",
    "    data_array = line.split(' ')\n",
    "    size_x_data1.append(data_array[3:1254])\n",
    "    size_x_data2.append(data_array[1254:2505])\n",
    "    size_x_data3.append(data_array[2505:-1])\n",
    "    size_y_data.append(data_array[0])\n",
    "\n",
    "#### 位置に関するデータ\n",
    "with open(one_hole_path) as fp1:\n",
    "  for line in fp1:\n",
    "    data_array = line.split(' ')\n",
    "    position_x_data1.append(data_array[3:1254])\n",
    "    position_x_data2.append(data_array[1254:2505])\n",
    "    position_x_data3.append(data_array[2505:-1])\n",
    "    position_one_data1.append(data_array[3:1254])\n",
    "    position_one_data2.append(data_array[1254:2505])\n",
    "    position_one_data3.append(data_array[2505:-1])\n",
    "    position_y_data.append(data_array[1:3])\n",
    "with open(four_holes_path) as fp2:\n",
    "  for line in fp2:\n",
    "    data_array = line.split(' ')\n",
    "    position_x_data1.append(data_array[3:1254])\n",
    "    position_x_data2.append(data_array[1254:2505])\n",
    "    position_x_data3.append(data_array[2505:-1])\n",
    "    position_two_data1.append(data_array[3:1254])\n",
    "    position_two_data2.append(data_array[1254:2505])\n",
    "    position_two_data3.append(data_array[2505:-1])\n",
    "    position_y_data.append(data_array[1:3])\n",
    "with open(nine_holes_path) as fp3:\n",
    "  for line in fp3:\n",
    "    data_array = line.split(' ')\n",
    "    position_x_data1.append(data_array[3:1254])\n",
    "    position_x_data2.append(data_array[1254:2505])\n",
    "    position_x_data3.append(data_array[2505:-1])\n",
    "    position_three_data1.append(data_array[3:1254])\n",
    "    position_three_data2.append(data_array[1254:2505])\n",
    "    position_three_data3.append(data_array[2505:-1])\n",
    "    position_y_data.append(data_array[1:3])\n",
    "with open(sixteen_holes_path) as fp4:\n",
    "  for line in fp4:\n",
    "    data_array = line.split(' ')\n",
    "    position_x_data1.append(data_array[3:1254])\n",
    "    position_x_data2.append(data_array[1254:2505])\n",
    "    position_x_data3.append(data_array[2505:-1])\n",
    "    position_four_data1.append(data_array[3:1254])\n",
    "    position_four_data2.append(data_array[1254:2505])\n",
    "    position_four_data3.append(data_array[2505:-1])\n",
    "    position_y_data.append(data_array[1:3])\n",
    "with open(twentyfive_holes_path) as fp5:\n",
    "  for line in fp5:\n",
    "    data_array = line.split(' ')\n",
    "    position_x_data1.append(data_array[3:1254])\n",
    "    position_x_data2.append(data_array[1254:2505])\n",
    "    position_x_data3.append(data_array[2505:-1])\n",
    "    position_five_data1.append(data_array[3:1254])\n",
    "    position_five_data2.append(data_array[1254:2505])\n",
    "    position_five_data3.append(data_array[2505:-1])\n",
    "    position_y_data.append(data_array[1:3])\n",
    "\n",
    "### 各配列をnp.array型にして各要素を型変換\n",
    "no_hole_data1 = np.array(no_hole_data1, dtype=float)\n",
    "no_hole_data2 = np.array(no_hole_data2, dtype=float)\n",
    "no_hole_data3 = np.array(no_hole_data3, dtype=float)\n",
    "size_x_data1 = np.array(size_x_data1, dtype=float)\n",
    "size_x_data2 = np.array(size_x_data2, dtype=float)\n",
    "size_x_data3 = np.array(size_x_data3, dtype=float)\n",
    "size_y_data = np.array(size_y_data, dtype=int)\n",
    "position_x_data1 = np.array(position_x_data1, dtype=float)\n",
    "position_x_data2 = np.array(position_x_data2, dtype=float)\n",
    "position_x_data3 = np.array(position_x_data3, dtype=float)\n",
    "position_one_data1 = np.array(position_one_data1, dtype=float)\n",
    "position_two_data1 = np.array(position_two_data1, dtype=float)\n",
    "position_three_data1 = np.array(position_three_data1, dtype=float)\n",
    "position_four_data1 = np.array(position_four_data1, dtype=float)\n",
    "position_five_data1 = np.array(position_five_data1, dtype=float)\n",
    "position_one_data2 = np.array(position_one_data2, dtype=float)\n",
    "position_two_data2 = np.array(position_two_data2, dtype=float)\n",
    "position_three_data2 = np.array(position_three_data2, dtype=float)\n",
    "position_four_data2 = np.array(position_four_data2, dtype=float)\n",
    "position_five_data2 = np.array(position_five_data2, dtype=float)\n",
    "position_one_data3 = np.array(position_one_data3, dtype=float)\n",
    "position_two_data3 = np.array(position_two_data3, dtype=float)\n",
    "position_three_data3 = np.array(position_three_data3, dtype=float)\n",
    "position_four_data3 = np.array(position_four_data3, dtype=float)\n",
    "position_five_data3 = np.array(position_five_data3, dtype=float)\n",
    "position_y_data = np.array(position_y_data, dtype=float)\n",
    "\n",
    "### データの加工\n",
    "# 最大値で割る\n",
    "max_displacement = size_x_data2.max()\n",
    "size_x_data1 = size_x_data1/max_displacement\n",
    "size_x_data2 = size_x_data2/max_displacement\n",
    "size_x_data3 = size_x_data3/max_displacement\n",
    "position_x_data1 = position_x_data1/max_displacement\n",
    "position_x_data2 = position_x_data2/max_displacement\n",
    "position_x_data3 = position_x_data3/max_displacement\n",
    "position_one_data1 = position_one_data1/max_displacement\n",
    "position_one_data2 = position_one_data2/max_displacement\n",
    "position_one_data3 = position_one_data3/max_displacement\n",
    "position_two_data1 = position_two_data1/max_displacement\n",
    "position_two_data2 = position_two_data2/max_displacement\n",
    "position_two_data3 = position_two_data3/max_displacement\n",
    "position_three_data1 = position_three_data1/max_displacement\n",
    "position_three_data2 = position_three_data2/max_displacement\n",
    "position_three_data3 = position_three_data3/max_displacement\n",
    "position_four_data1 = position_four_data1/max_displacement\n",
    "position_four_data2 = position_four_data2/max_displacement\n",
    "position_four_data3 = position_four_data3/max_displacement\n",
    "position_five_data1 = position_five_data1/max_displacement\n",
    "position_five_data2 = position_five_data2/max_displacement\n",
    "position_five_data3 = position_five_data3/max_displacement\n",
    "\n",
    "# 実験2:差をとると精度が向上するか\n",
    "# size_x_data = (size_x_data-no_hole_data)\n",
    "# position_x_data = (position_x_data-no_hole_data)\n",
    "\n",
    "# position_one_data = (position_one_data-no_hole_data)\n",
    "# position_two_data = (position_two_data-no_hole_data)\n",
    "# position_three_data = (position_three_data-no_hole_data)\n",
    "# position_four_data = (position_four_data-no_hole_data)\n",
    "# position_five_data = (position_five_data-no_hole_data)\n",
    "position_y_data = position_y_data/50\n",
    "\n",
    "### train用とtest用に分割(9:1)\n",
    "size_x_train1, size_x_test1, size_x_train2, size_x_test2, size_x_train3, size_x_test3, size_y_train, size_y_test = train_test_split(size_x_data1, size_x_data2, size_x_data3, size_y_data, test_size=0.10)\n",
    "position_x_train1, position_x_test1, position_x_train2, position_x_test2, position_x_train3, position_x_test3, position_y_train, position_y_test = train_test_split(position_x_data1, position_x_data2, position_x_data3, position_y_data, test_size=0.10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270\n",
      "270\n"
     ]
    }
   ],
   "source": [
    "print(len(size_y_test))\n",
    "print(len(size_x_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 35, 1) for input Tensor(\"input_61:0\", shape=(None, 35, 1), dtype=float32), but it was called on an input with incompatible shape (None, 1251, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 50, 1) for input Tensor(\"input_62:0\", shape=(None, 50, 1), dtype=float32), but it was called on an input with incompatible shape (None, 1251, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 40, 1) for input Tensor(\"input_63:0\", shape=(None, 40, 1), dtype=float32), but it was called on an input with incompatible shape (None, 1251, 1).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /opt/anaconda3/envs/graduation_thesis/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1147 predict_function  *\n        outputs = self.distribute_strategy.run(\n    /opt/anaconda3/envs/graduation_thesis/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/anaconda3/envs/graduation_thesis/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/anaconda3/envs/graduation_thesis/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/anaconda3/envs/graduation_thesis/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1122 predict_step  **\n        return self(x, training=False)\n    /opt/anaconda3/envs/graduation_thesis/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /opt/anaconda3/envs/graduation_thesis/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py:719 call\n        convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n    /opt/anaconda3/envs/graduation_thesis/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py:888 _run_internal_graph\n        output_tensors = layer(computed_tensors, **kwargs)\n    /opt/anaconda3/envs/graduation_thesis/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:886 __call__\n        self.name)\n    /opt/anaconda3/envs/graduation_thesis/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer dense_20 is incompatible with the layer: expected axis -1 of input shape to have value 2016 but received input with shape [None, 60096]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-528b82e0d954>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 散布図表示(テストデータ270個)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msize_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_size_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msize_x_test1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_x_test2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_x_test3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msize_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize_y_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_answer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/graduation_thesis/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m/opt/anaconda3/envs/graduation_thesis/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1266\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m             \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/graduation_thesis/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/graduation_thesis/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/opt/anaconda3/envs/graduation_thesis/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2417\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/graduation_thesis/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2772\u001b[0m           \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2773\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[0;32m-> 2774\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/graduation_thesis/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2704\u001b[0m         relaxed_arg_shapes)\n\u001b[1;32m   2705\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 2706\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   2707\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/graduation_thesis/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/graduation_thesis/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/graduation_thesis/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/graduation_thesis/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/anaconda3/envs/graduation_thesis/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1147 predict_function  *\n        outputs = self.distribute_strategy.run(\n    /opt/anaconda3/envs/graduation_thesis/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/anaconda3/envs/graduation_thesis/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/anaconda3/envs/graduation_thesis/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/anaconda3/envs/graduation_thesis/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1122 predict_step  **\n        return self(x, training=False)\n    /opt/anaconda3/envs/graduation_thesis/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /opt/anaconda3/envs/graduation_thesis/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py:719 call\n        convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n    /opt/anaconda3/envs/graduation_thesis/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py:888 _run_internal_graph\n        output_tensors = layer(computed_tensors, **kwargs)\n    /opt/anaconda3/envs/graduation_thesis/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:886 __call__\n        self.name)\n    /opt/anaconda3/envs/graduation_thesis/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer dense_20 is incompatible with the layer: expected axis -1 of input shape to have value 2016 but received input with shape [None, 60096]\n"
     ]
    }
   ],
   "source": [
    "# 散布図表示(テストデータ270個)\n",
    "size_predict = model_size_array[0].predict([size_x_test1, size_x_test2, size_x_test3])\n",
    "size_answer = size_y_test\n",
    "\n",
    "plt.scatter(size_answer, size_predict)\n",
    "plt.xlabel(\"size\")\n",
    "plt.ylabel(\"prediction\")\n",
    "plt.grid(True)\n",
    "## y=xの直線をひく\n",
    "x = []\n",
    "for i in range(60):\n",
    "    x.append(i*0.1)\n",
    "y = []\n",
    "for i in range(60):\n",
    "    y.append(i*0.1)\n",
    "plt.plot(x, y, color='black')\n",
    "## 誤差-30%の直線を引く\n",
    "y = []\n",
    "for i in range(60):\n",
    "    y.append(i*0.1*0.7)\n",
    "plt.plot(x, y, color='red')\n",
    "## 誤差+30%の直線を引く\n",
    "y = []\n",
    "for i in range(60):\n",
    "    y.append(i*0.1*1.3)\n",
    "plt.plot(x, y, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
